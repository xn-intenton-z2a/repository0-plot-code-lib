\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIntroducing the Serverless MCPServerless TeamApr 17, 2025Introducing Serverless Container FrameworkServerless TeamFeb 4, 2025Introducing The AWS AI StackServerless TeamSep 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProducts Documentation PricingCompany Toggle themeSearch⌘ KLoginSign UpToggle navigation menu\nProducts Documentation PricingCompany Toggle themeSearch⌘ KLoginSign UpToggle navigation menu\nProducts Documentation PricingCompany Toggle themeSearch⌘ KLoginSign UpToggle navigation menu\nProducts Documentation PricingCompany\nToggle themeSearch⌘ KLoginSign Up\nToggle navigation menu\nMenuToggle navigation menuServerless PluginsAuthorServerless99xAa2kbAbemediaAccentureACloudGuruActivescottAdieuadieuAditmalik-synechronAgutoliAheissenbergerAjmathAlex-murashkinAlex20465Alhazmy13AlikianAliyunAmazon-archivesAmplify-educationAnantabAndrewcuriosoAntonBazhalApancuttAr90nAraboldAregierAwslabsBarstoolSportsBealeartsBespoken-cookbookBirdcatcherBramhovenBrefphpBubblydooButterwireBwinantCapitaloneCaptainsiddCfchouChechuChris-feistCipri-pCivicteamClaygregoryCloudflareCloudSnorkelCoalesceSoftwareCodecentricCodeRecipe-devCommandeerCommercetoolsConcon121CoorpAcademyDanepowellDaniel-cottoneDataDogDavidgfDavidWellsDeep-securityDeliveryheroDheraultDianaIonitaDieProduktMacherDigitalmaasDitttoDoapp-ryanpDomdomeggDong-dohaiDougmoscropDrexlerDroplrDuanefieldsDvlaE-e-eEconomysizegeekEddmannEliasjcjuniorEliuXEmmkongEnigmatic-SmileEnykeevEpsagonEvgenykireevEvolv-aiFdaciukFernando-mcFivepapertigersFloydspaceFormidableLabsFourTheoremFruffinFunctionaloneFunkybobGaaraZhuGertjvrGetliftGFGGfragosoGilmarsquinelatoGmetzkerGo-dimaGoldwasserexchangeGozupHenhalHieuunguyeenHonarpourHorike37HubSpotWebTeamHypoportIcarus-sullivanIlayanambi86IliasbhalImran99InokappaInqnuamIopipeIs2eiIsudzumiJacob-meachamJaredCEJaumardJeremydalyJimdoJitsecurityJlopezJmaleonardJoshuaflanaganJuancarestreJuanjoDiazJubel-hanJweyrichK1LoWKandstenKangcifongKatallaxieKevinrambaudKevinsewellKrysKrukKumologicaHQLeftclickbenLeoPlatformLithinLoanmarketLocalstackLogandkLumigo-ioMaciejtrederMadSkills-ioManelferreiraManoManoTechManwaringMarcy-teruiMartinlindenbergMatt-filionMechanicalRockMedikooMeemawMiguel-a-calles-mbaMikepatrickMikesouzaMikestaubMitipiMj1618Mutual-of-enumclawMvilaNavarasuNeiman-marcusNervous-systemsNeverendingqsNfourNickaNikaeraNlangNordcloudNordstromNya1OnlicarOptimator999Paul-PSDigitalPaulSambolinPianomansamPidz-developmentPiercusPretty-fun-therapyPuresecRafPeRajingtonRawphpRhythminmeRobzskRogerBarretoRogersgtRondineliRrahul963RubentrancosoRurriRyanmurakamiSantiagocardenasSapessiSashkopavlenkoSbstjnSC5ScalewaySddSean9keenanSeek-ossSergioramosServerless-appsyncServerless-heavenServerless-nextjsServerless-operationsSid88inSilvermineSinofsevenSmoketurnerSoftpropsStackStormStarschemaStyleTributeITSuorSvdgraafTalbotpTeddy-gustiauxTemandoTencentyunTgfischerTho-actrecipeThomasmichaelwallaceThoreinsteinThreadheapTradleTrek10incTsibelmanTsubUbaniabalogunUnbillUsefulioUswitchVacasaossVkkis93VortarianWangshaWeixu365WhardierWilliamsandonzYndlingsfarYonomiZaruZephraxServerless Offlineby dheraultEmulate AWS λ and API Gateway locally when developing your Serverle...39.7m5.2kServerless Prune Pluginby claygregoryDeletes old versions of functions from AWS, preserving recent and a...22.3m355Serverless Webpackby serverless-heavenServerless plugin to bundle your lambdas with Webpack19.3m1.7kServerless Domain Managerby amplify-educationServerless plugin for managing custom domains with API Gateways.15.9m936Serverless Esbuildby floydspaceServerless plugin to bundle JavaScript and TypeScript lambdas with ...15.5m445Serverless HTTPby dougmoscropUse your existing middleware framework (e.g. Express, Koa) in AWS L...11.9m1.7kServerless Dotenv Pluginby neverendingqsPreload environment variables from `.env` into serverless.10.1m346Serverless Step Functionsby serverless-operationsAWS Step Functions plugin for Serverless Framework9.5m1.0kServerless Plugin Datadogby DataDogMonitoring, tracing, and real-time metrics for your Lambda functions9.2m94Serverless Plugin Typescriptby serverlessServerless plugin for zero-config Typescript support.9.0m784Serverless IAM Roles Per Functionby functionaloneServerless Plugin for easily defining IAM roles per function via th...8.6m411Serverless Python Requirementsby serverlessServerless plugin to bundle Python packages8.0m1.1kPrevious12345More pages29Next\nMenuToggle navigation menuServerless PluginsAuthorServerless99xAa2kbAbemediaAccentureACloudGuruActivescottAdieuadieuAditmalik-synechronAgutoliAheissenbergerAjmathAlex-murashkinAlex20465Alhazmy13AlikianAliyunAmazon-archivesAmplify-educationAnantabAndrewcuriosoAntonBazhalApancuttAr90nAraboldAregierAwslabsBarstoolSportsBealeartsBespoken-cookbookBirdcatcherBramhovenBrefphpBubblydooButterwireBwinantCapitaloneCaptainsiddCfchouChechuChris-feistCipri-pCivicteamClaygregoryCloudflareCloudSnorkelCoalesceSoftwareCodecentricCodeRecipe-devCommandeerCommercetoolsConcon121CoorpAcademyDanepowellDaniel-cottoneDataDogDavidgfDavidWellsDeep-securityDeliveryheroDheraultDianaIonitaDieProduktMacherDigitalmaasDitttoDoapp-ryanpDomdomeggDong-dohaiDougmoscropDrexlerDroplrDuanefieldsDvlaE-e-eEconomysizegeekEddmannEliasjcjuniorEliuXEmmkongEnigmatic-SmileEnykeevEpsagonEvgenykireevEvolv-aiFdaciukFernando-mcFivepapertigersFloydspaceFormidableLabsFourTheoremFruffinFunctionaloneFunkybobGaaraZhuGertjvrGetliftGFGGfragosoGilmarsquinelatoGmetzkerGo-dimaGoldwasserexchangeGozupHenhalHieuunguyeenHonarpourHorike37HubSpotWebTeamHypoportIcarus-sullivanIlayanambi86IliasbhalImran99InokappaInqnuamIopipeIs2eiIsudzumiJacob-meachamJaredCEJaumardJeremydalyJimdoJitsecurityJlopezJmaleonardJoshuaflanaganJuancarestreJuanjoDiazJubel-hanJweyrichK1LoWKandstenKangcifongKatallaxieKevinrambaudKevinsewellKrysKrukKumologicaHQLeftclickbenLeoPlatformLithinLoanmarketLocalstackLogandkLumigo-ioMaciejtrederMadSkills-ioManelferreiraManoManoTechManwaringMarcy-teruiMartinlindenbergMatt-filionMechanicalRockMedikooMeemawMiguel-a-calles-mbaMikepatrickMikesouzaMikestaubMitipiMj1618Mutual-of-enumclawMvilaNavarasuNeiman-marcusNervous-systemsNeverendingqsNfourNickaNikaeraNlangNordcloudNordstromNya1OnlicarOptimator999Paul-PSDigitalPaulSambolinPianomansamPidz-developmentPiercusPretty-fun-therapyPuresecRafPeRajingtonRawphpRhythminmeRobzskRogerBarretoRogersgtRondineliRrahul963RubentrancosoRurriRyanmurakamiSantiagocardenasSapessiSashkopavlenkoSbstjnSC5ScalewaySddSean9keenanSeek-ossSergioramosServerless-appsyncServerless-heavenServerless-nextjsServerless-operationsSid88inSilvermineSinofsevenSmoketurnerSoftpropsStackStormStarschemaStyleTributeITSuorSvdgraafTalbotpTeddy-gustiauxTemandoTencentyunTgfischerTho-actrecipeThomasmichaelwallaceThoreinsteinThreadheapTradleTrek10incTsibelmanTsubUbaniabalogunUnbillUsefulioUswitchVacasaossVkkis93VortarianWangshaWeixu365WhardierWilliamsandonzYndlingsfarYonomiZaruZephraxServerless Offlineby dheraultEmulate AWS λ and API Gateway locally when developing your Serverle...39.7m5.2kServerless Prune Pluginby claygregoryDeletes old versions of functions from AWS, preserving recent and a...22.3m355Serverless Webpackby serverless-heavenServerless plugin to bundle your lambdas with Webpack19.3m1.7kServerless Domain Managerby amplify-educationServerless plugin for managing custom domains with API Gateways.15.9m936Serverless Esbuildby floydspaceServerless plugin to bundle JavaScript and TypeScript lambdas with ...15.5m445Serverless HTTPby dougmoscropUse your existing middleware framework (e.g. Express, Koa) in AWS L...11.9m1.7kServerless Dotenv Pluginby neverendingqsPreload environment variables from `.env` into serverless.10.1m346Serverless Step Functionsby serverless-operationsAWS Step Functions plugin for Serverless Framework9.5m1.0kServerless Plugin Datadogby DataDogMonitoring, tracing, and real-time metrics for your Lambda functions9.2m94Serverless Plugin Typescriptby serverlessServerless plugin for zero-config Typescript support.9.0m784Serverless IAM Roles Per Functionby functionaloneServerless Plugin for easily defining IAM roles per function via th...8.6m411Serverless Python Requirementsby serverlessServerless plugin to bundle Python packages8.0m1.1kPrevious12345More pages29Next\nMenuToggle navigation menu\nToggle navigation menu\nServerless PluginsAuthorServerless99xAa2kbAbemediaAccentureACloudGuruActivescottAdieuadieuAditmalik-synechronAgutoliAheissenbergerAjmathAlex-murashkinAlex20465Alhazmy13AlikianAliyunAmazon-archivesAmplify-educationAnantabAndrewcuriosoAntonBazhalApancuttAr90nAraboldAregierAwslabsBarstoolSportsBealeartsBespoken-cookbookBirdcatcherBramhovenBrefphpBubblydooButterwireBwinantCapitaloneCaptainsiddCfchouChechuChris-feistCipri-pCivicteamClaygregoryCloudflareCloudSnorkelCoalesceSoftwareCodecentricCodeRecipe-devCommandeerCommercetoolsConcon121CoorpAcademyDanepowellDaniel-cottoneDataDogDavidgfDavidWellsDeep-securityDeliveryheroDheraultDianaIonitaDieProduktMacherDigitalmaasDitttoDoapp-ryanpDomdomeggDong-dohaiDougmoscropDrexlerDroplrDuanefieldsDvlaE-e-eEconomysizegeekEddmannEliasjcjuniorEliuXEmmkongEnigmatic-SmileEnykeevEpsagonEvgenykireevEvolv-aiFdaciukFernando-mcFivepapertigersFloydspaceFormidableLabsFourTheoremFruffinFunctionaloneFunkybobGaaraZhuGertjvrGetliftGFGGfragosoGilmarsquinelatoGmetzkerGo-dimaGoldwasserexchangeGozupHenhalHieuunguyeenHonarpourHorike37HubSpotWebTeamHypoportIcarus-sullivanIlayanambi86IliasbhalImran99InokappaInqnuamIopipeIs2eiIsudzumiJacob-meachamJaredCEJaumardJeremydalyJimdoJitsecurityJlopezJmaleonardJoshuaflanaganJuancarestreJuanjoDiazJubel-hanJweyrichK1LoWKandstenKangcifongKatallaxieKevinrambaudKevinsewellKrysKrukKumologicaHQLeftclickbenLeoPlatformLithinLoanmarketLocalstackLogandkLumigo-ioMaciejtrederMadSkills-ioManelferreiraManoManoTechManwaringMarcy-teruiMartinlindenbergMatt-filionMechanicalRockMedikooMeemawMiguel-a-calles-mbaMikepatrickMikesouzaMikestaubMitipiMj1618Mutual-of-enumclawMvilaNavarasuNeiman-marcusNervous-systemsNeverendingqsNfourNickaNikaeraNlangNordcloudNordstromNya1OnlicarOptimator999Paul-PSDigitalPaulSambolinPianomansamPidz-developmentPiercusPretty-fun-therapyPuresecRafPeRajingtonRawphpRhythminmeRobzskRogerBarretoRogersgtRondineliRrahul963RubentrancosoRurriRyanmurakamiSantiagocardenasSapessiSashkopavlenkoSbstjnSC5ScalewaySddSean9keenanSeek-ossSergioramosServerless-appsyncServerless-heavenServerless-nextjsServerless-operationsSid88inSilvermineSinofsevenSmoketurnerSoftpropsStackStormStarschemaStyleTributeITSuorSvdgraafTalbotpTeddy-gustiauxTemandoTencentyunTgfischerTho-actrecipeThomasmichaelwallaceThoreinsteinThreadheapTradleTrek10incTsibelmanTsubUbaniabalogunUnbillUsefulioUswitchVacasaossVkkis93VortarianWangshaWeixu365WhardierWilliamsandonzYndlingsfarYonomiZaruZephrax\nServerless PluginsAuthorServerless99xAa2kbAbemediaAccentureACloudGuruActivescottAdieuadieuAditmalik-synechronAgutoliAheissenbergerAjmathAlex-murashkinAlex20465Alhazmy13AlikianAliyunAmazon-archivesAmplify-educationAnantabAndrewcuriosoAntonBazhalApancuttAr90nAraboldAregierAwslabsBarstoolSportsBealeartsBespoken-cookbookBirdcatcherBramhovenBrefphpBubblydooButterwireBwinantCapitaloneCaptainsiddCfchouChechuChris-feistCipri-pCivicteamClaygregoryCloudflareCloudSnorkelCoalesceSoftwareCodecentricCodeRecipe-devCommandeerCommercetoolsConcon121CoorpAcademyDanepowellDaniel-cottoneDataDogDavidgfDavidWellsDeep-securityDeliveryheroDheraultDianaIonitaDieProduktMacherDigitalmaasDitttoDoapp-ryanpDomdomeggDong-dohaiDougmoscropDrexlerDroplrDuanefieldsDvlaE-e-eEconomysizegeekEddmannEliasjcjuniorEliuXEmmkongEnigmatic-SmileEnykeevEpsagonEvgenykireevEvolv-aiFdaciukFernando-mcFivepapertigersFloydspaceFormidableLabsFourTheoremFruffinFunctionaloneFunkybobGaaraZhuGertjvrGetliftGFGGfragosoGilmarsquinelatoGmetzkerGo-dimaGoldwasserexchangeGozupHenhalHieuunguyeenHonarpourHorike37HubSpotWebTeamHypoportIcarus-sullivanIlayanambi86IliasbhalImran99InokappaInqnuamIopipeIs2eiIsudzumiJacob-meachamJaredCEJaumardJeremydalyJimdoJitsecurityJlopezJmaleonardJoshuaflanaganJuancarestreJuanjoDiazJubel-hanJweyrichK1LoWKandstenKangcifongKatallaxieKevinrambaudKevinsewellKrysKrukKumologicaHQLeftclickbenLeoPlatformLithinLoanmarketLocalstackLogandkLumigo-ioMaciejtrederMadSkills-ioManelferreiraManoManoTechManwaringMarcy-teruiMartinlindenbergMatt-filionMechanicalRockMedikooMeemawMiguel-a-calles-mbaMikepatrickMikesouzaMikestaubMitipiMj1618Mutual-of-enumclawMvilaNavarasuNeiman-marcusNervous-systemsNeverendingqsNfourNickaNikaeraNlangNordcloudNordstromNya1OnlicarOptimator999Paul-PSDigitalPaulSambolinPianomansamPidz-developmentPiercusPretty-fun-therapyPuresecRafPeRajingtonRawphpRhythminmeRobzskRogerBarretoRogersgtRondineliRrahul963RubentrancosoRurriRyanmurakamiSantiagocardenasSapessiSashkopavlenkoSbstjnSC5ScalewaySddSean9keenanSeek-ossSergioramosServerless-appsyncServerless-heavenServerless-nextjsServerless-operationsSid88inSilvermineSinofsevenSmoketurnerSoftpropsStackStormStarschemaStyleTributeITSuorSvdgraafTalbotpTeddy-gustiauxTemandoTencentyunTgfischerTho-actrecipeThomasmichaelwallaceThoreinsteinThreadheapTradleTrek10incTsibelmanTsubUbaniabalogunUnbillUsefulioUswitchVacasaossVkkis93VortarianWangshaWeixu365WhardierWilliamsandonzYndlingsfarYonomiZaruZephrax\nServerless PluginsAuthorServerless99xAa2kbAbemediaAccentureACloudGuruActivescottAdieuadieuAditmalik-synechronAgutoliAheissenbergerAjmathAlex-murashkinAlex20465Alhazmy13AlikianAliyunAmazon-archivesAmplify-educationAnantabAndrewcuriosoAntonBazhalApancuttAr90nAraboldAregierAwslabsBarstoolSportsBealeartsBespoken-cookbookBirdcatcherBramhovenBrefphpBubblydooButterwireBwinantCapitaloneCaptainsiddCfchouChechuChris-feistCipri-pCivicteamClaygregoryCloudflareCloudSnorkelCoalesceSoftwareCodecentricCodeRecipe-devCommandeerCommercetoolsConcon121CoorpAcademyDanepowellDaniel-cottoneDataDogDavidgfDavidWellsDeep-securityDeliveryheroDheraultDianaIonitaDieProduktMacherDigitalmaasDitttoDoapp-ryanpDomdomeggDong-dohaiDougmoscropDrexlerDroplrDuanefieldsDvlaE-e-eEconomysizegeekEddmannEliasjcjuniorEliuXEmmkongEnigmatic-SmileEnykeevEpsagonEvgenykireevEvolv-aiFdaciukFernando-mcFivepapertigersFloydspaceFormidableLabsFourTheoremFruffinFunctionaloneFunkybobGaaraZhuGertjvrGetliftGFGGfragosoGilmarsquinelatoGmetzkerGo-dimaGoldwasserexchangeGozupHenhalHieuunguyeenHonarpourHorike37HubSpotWebTeamHypoportIcarus-sullivanIlayanambi86IliasbhalImran99InokappaInqnuamIopipeIs2eiIsudzumiJacob-meachamJaredCEJaumardJeremydalyJimdoJitsecurityJlopezJmaleonardJoshuaflanaganJuancarestreJuanjoDiazJubel-hanJweyrichK1LoWKandstenKangcifongKatallaxieKevinrambaudKevinsewellKrysKrukKumologicaHQLeftclickbenLeoPlatformLithinLoanmarketLocalstackLogandkLumigo-ioMaciejtrederMadSkills-ioManelferreiraManoManoTechManwaringMarcy-teruiMartinlindenbergMatt-filionMechanicalRockMedikooMeemawMiguel-a-calles-mbaMikepatrickMikesouzaMikestaubMitipiMj1618Mutual-of-enumclawMvilaNavarasuNeiman-marcusNervous-systemsNeverendingqsNfourNickaNikaeraNlangNordcloudNordstromNya1OnlicarOptimator999Paul-PSDigitalPaulSambolinPianomansamPidz-developmentPiercusPretty-fun-therapyPuresecRafPeRajingtonRawphpRhythminmeRobzskRogerBarretoRogersgtRondineliRrahul963RubentrancosoRurriRyanmurakamiSantiagocardenasSapessiSashkopavlenkoSbstjnSC5ScalewaySddSean9keenanSeek-ossSergioramosServerless-appsyncServerless-heavenServerless-nextjsServerless-operationsSid88inSilvermineSinofsevenSmoketurnerSoftpropsStackStormStarschemaStyleTributeITSuorSvdgraafTalbotpTeddy-gustiauxTemandoTencentyunTgfischerTho-actrecipeThomasmichaelwallaceThoreinsteinThreadheapTradleTrek10incTsibelmanTsubUbaniabalogunUnbillUsefulioUswitchVacasaossVkkis93VortarianWangshaWeixu365WhardierWilliamsandonzYndlingsfarYonomiZaruZephrax\nAuthorServerless99xAa2kbAbemediaAccentureACloudGuruActivescottAdieuadieuAditmalik-synechronAgutoliAheissenbergerAjmathAlex-murashkinAlex20465Alhazmy13AlikianAliyunAmazon-archivesAmplify-educationAnantabAndrewcuriosoAntonBazhalApancuttAr90nAraboldAregierAwslabsBarstoolSportsBealeartsBespoken-cookbookBirdcatcherBramhovenBrefphpBubblydooButterwireBwinantCapitaloneCaptainsiddCfchouChechuChris-feistCipri-pCivicteamClaygregoryCloudflareCloudSnorkelCoalesceSoftwareCodecentricCodeRecipe-devCommandeerCommercetoolsConcon121CoorpAcademyDanepowellDaniel-cottoneDataDogDavidgfDavidWellsDeep-securityDeliveryheroDheraultDianaIonitaDieProduktMacherDigitalmaasDitttoDoapp-ryanpDomdomeggDong-dohaiDougmoscropDrexlerDroplrDuanefieldsDvlaE-e-eEconomysizegeekEddmannEliasjcjuniorEliuXEmmkongEnigmatic-SmileEnykeevEpsagonEvgenykireevEvolv-aiFdaciukFernando-mcFivepapertigersFloydspaceFormidableLabsFourTheoremFruffinFunctionaloneFunkybobGaaraZhuGertjvrGetliftGFGGfragosoGilmarsquinelatoGmetzkerGo-dimaGoldwasserexchangeGozupHenhalHieuunguyeenHonarpourHorike37HubSpotWebTeamHypoportIcarus-sullivanIlayanambi86IliasbhalImran99InokappaInqnuamIopipeIs2eiIsudzumiJacob-meachamJaredCEJaumardJeremydalyJimdoJitsecurityJlopezJmaleonardJoshuaflanaganJuancarestreJuanjoDiazJubel-hanJweyrichK1LoWKandstenKangcifongKatallaxieKevinrambaudKevinsewellKrysKrukKumologicaHQLeftclickbenLeoPlatformLithinLoanmarketLocalstackLogandkLumigo-ioMaciejtrederMadSkills-ioManelferreiraManoManoTechManwaringMarcy-teruiMartinlindenbergMatt-filionMechanicalRockMedikooMeemawMiguel-a-calles-mbaMikepatrickMikesouzaMikestaubMitipiMj1618Mutual-of-enumclawMvilaNavarasuNeiman-marcusNervous-systemsNeverendingqsNfourNickaNikaeraNlangNordcloudNordstromNya1OnlicarOptimator999Paul-PSDigitalPaulSambolinPianomansamPidz-developmentPiercusPretty-fun-therapyPuresecRafPeRajingtonRawphpRhythminmeRobzskRogerBarretoRogersgtRondineliRrahul963RubentrancosoRurriRyanmurakamiSantiagocardenasSapessiSashkopavlenkoSbstjnSC5ScalewaySddSean9keenanSeek-ossSergioramosServerless-appsyncServerless-heavenServerless-nextjsServerless-operationsSid88inSilvermineSinofsevenSmoketurnerSoftpropsStackStormStarschemaStyleTributeITSuorSvdgraafTalbotpTeddy-gustiauxTemandoTencentyunTgfischerTho-actrecipeThomasmichaelwallaceThoreinsteinThreadheapTradleTrek10incTsibelmanTsubUbaniabalogunUnbillUsefulioUswitchVacasaossVkkis93VortarianWangshaWeixu365WhardierWilliamsandonzYndlingsfarYonomiZaruZephrax\nServerless99xAa2kbAbemediaAccentureACloudGuruActivescottAdieuadieuAditmalik-synechronAgutoliAheissenbergerAjmathAlex-murashkinAlex20465Alhazmy13AlikianAliyunAmazon-archivesAmplify-educationAnantabAndrewcuriosoAntonBazhalApancuttAr90nAraboldAregierAwslabsBarstoolSportsBealeartsBespoken-cookbookBirdcatcherBramhovenBrefphpBubblydooButterwireBwinantCapitaloneCaptainsiddCfchouChechuChris-feistCipri-pCivicteamClaygregoryCloudflareCloudSnorkelCoalesceSoftwareCodecentricCodeRecipe-devCommandeerCommercetoolsConcon121CoorpAcademyDanepowellDaniel-cottoneDataDogDavidgfDavidWellsDeep-securityDeliveryheroDheraultDianaIonitaDieProduktMacherDigitalmaasDitttoDoapp-ryanpDomdomeggDong-dohaiDougmoscropDrexlerDroplrDuanefieldsDvlaE-e-eEconomysizegeekEddmannEliasjcjuniorEliuXEmmkongEnigmatic-SmileEnykeevEpsagonEvgenykireevEvolv-aiFdaciukFernando-mcFivepapertigersFloydspaceFormidableLabsFourTheoremFruffinFunctionaloneFunkybobGaaraZhuGertjvrGetliftGFGGfragosoGilmarsquinelatoGmetzkerGo-dimaGoldwasserexchangeGozupHenhalHieuunguyeenHonarpourHorike37HubSpotWebTeamHypoportIcarus-sullivanIlayanambi86IliasbhalImran99InokappaInqnuamIopipeIs2eiIsudzumiJacob-meachamJaredCEJaumardJeremydalyJimdoJitsecurityJlopezJmaleonardJoshuaflanaganJuancarestreJuanjoDiazJubel-hanJweyrichK1LoWKandstenKangcifongKatallaxieKevinrambaudKevinsewellKrysKrukKumologicaHQLeftclickbenLeoPlatformLithinLoanmarketLocalstackLogandkLumigo-ioMaciejtrederMadSkills-ioManelferreiraManoManoTechManwaringMarcy-teruiMartinlindenbergMatt-filionMechanicalRockMedikooMeemawMiguel-a-calles-mbaMikepatrickMikesouzaMikestaubMitipiMj1618Mutual-of-enumclawMvilaNavarasuNeiman-marcusNervous-systemsNeverendingqsNfourNickaNikaeraNlangNordcloudNordstromNya1OnlicarOptimator999Paul-PSDigitalPaulSambolinPianomansamPidz-developmentPiercusPretty-fun-therapyPuresecRafPeRajingtonRawphpRhythminmeRobzskRogerBarretoRogersgtRondineliRrahul963RubentrancosoRurriRyanmurakamiSantiagocardenasSapessiSashkopavlenkoSbstjnSC5ScalewaySddSean9keenanSeek-ossSergioramosServerless-appsyncServerless-heavenServerless-nextjsServerless-operationsSid88inSilvermineSinofsevenSmoketurnerSoftpropsStackStormStarschemaStyleTributeITSuorSvdgraafTalbotpTeddy-gustiauxTemandoTencentyunTgfischerTho-actrecipeThomasmichaelwallaceThoreinsteinThreadheapTradleTrek10incTsibelmanTsubUbaniabalogunUnbillUsefulioUswitchVacasaossVkkis93VortarianWangshaWeixu365WhardierWilliamsandonzYndlingsfarYonomiZaruZephrax\nServerless-operations\nServerless-operations\nServerless Offlineby dheraultEmulate AWS λ and API Gateway locally when developing your Serverle...39.7m5.2kServerless Prune Pluginby claygregoryDeletes old versions of functions from AWS, preserving recent and a...22.3m355Serverless Webpackby serverless-heavenServerless plugin to bundle your lambdas with Webpack19.3m1.7kServerless Domain Managerby amplify-educationServerless plugin for managing custom domains with API Gateways.15.9m936Serverless Esbuildby floydspaceServerless plugin to bundle JavaScript and TypeScript lambdas with ...15.5m445Serverless HTTPby dougmoscropUse your existing middleware framework (e.g. Express, Koa) in AWS L...11.9m1.7kServerless Dotenv Pluginby neverendingqsPreload environment variables from `.env` into serverless.10.1m346Serverless Step Functionsby serverless-operationsAWS Step Functions plugin for Serverless Framework9.5m1.0kServerless Plugin Datadogby DataDogMonitoring, tracing, and real-time metrics for your Lambda functions9.2m94Serverless Plugin Typescriptby serverlessServerless plugin for zero-config Typescript support.9.0m784Serverless IAM Roles Per Functionby functionaloneServerless Plugin for easily defining IAM roles per function via th...8.6m411Serverless Python Requirementsby serverlessServerless plugin to bundle Python packages8.0m1.1kPrevious12345More pages29Next\nServerless Offlineby dheraultEmulate AWS λ and API Gateway locally when developing your Serverle...39.7m5.2kServerless Prune Pluginby claygregoryDeletes old versions of functions from AWS, preserving recent and a...22.3m355Serverless Webpackby serverless-heavenServerless plugin to bundle your lambdas with Webpack19.3m1.7kServerless Domain Managerby amplify-educationServerless plugin for managing custom domains with API Gateways.15.9m936Serverless Esbuildby floydspaceServerless plugin to bundle JavaScript and TypeScript lambdas with ...15.5m445Serverless HTTPby dougmoscropUse your existing middleware framework (e.g. Express, Koa) in AWS L...11.9m1.7kServerless Dotenv Pluginby neverendingqsPreload environment variables from `.env` into serverless.10.1m346Serverless Step Functionsby serverless-operationsAWS Step Functions plugin for Serverless Framework9.5m1.0kServerless Plugin Datadogby DataDogMonitoring, tracing, and real-time metrics for your Lambda functions9.2m94Serverless Plugin Typescriptby serverlessServerless plugin for zero-config Typescript support.9.0m784Serverless IAM Roles Per Functionby functionaloneServerless Plugin for easily defining IAM roles per function via th...8.6m411Serverless Python Requirementsby serverlessServerless plugin to bundle Python packages8.0m1.1k\nServerless Offlineby dheraultEmulate AWS λ and API Gateway locally when developing your Serverle...39.7m5.2k\nServerless Offlineby dherault\nServerless Offlineby dherault\nEmulate AWS λ and API Gateway locally when developing your Serverle...\nServerless Prune Pluginby claygregoryDeletes old versions of functions from AWS, preserving recent and a...22.3m355\nServerless Prune Pluginby claygregory\nServerless Prune Pluginby claygregory\nServerless Prune Plugin\nDeletes old versions of functions from AWS, preserving recent and a...\nServerless Webpackby serverless-heavenServerless plugin to bundle your lambdas with Webpack19.3m1.7k\nServerless Webpackby serverless-heaven\nServerless Webpackby serverless-heaven\nServerless plugin to bundle your lambdas with Webpack\nServerless Domain Managerby amplify-educationServerless plugin for managing custom domains with API Gateways.15.9m936\nServerless Domain Managerby amplify-education\nServerless Domain Managerby amplify-education\nServerless Domain Manager\nServerless plugin for managing custom domains with API Gateways.\nServerless Esbuildby floydspaceServerless plugin to bundle JavaScript and TypeScript lambdas with ...15.5m445\nServerless Esbuildby floydspace\nServerless Esbuildby floydspace\nServerless plugin to bundle JavaScript and TypeScript lambdas with ...\nServerless HTTPby dougmoscropUse your existing middleware framework (e.g. Express, Koa) in AWS L...11.9m1.7k\nServerless HTTPby dougmoscrop\nServerless HTTPby dougmoscrop\nUse your existing middleware framework (e.g. Express, Koa) in AWS L...\nServerless Dotenv Pluginby neverendingqsPreload environment variables from `.env` into serverless.10.1m346\nServerless Dotenv Pluginby neverendingqs\nServerless Dotenv Pluginby neverendingqs\nServerless Dotenv Plugin\nPreload environment variables from `.env` into serverless.\nServerless Step Functionsby serverless-operationsAWS Step Functions plugin for Serverless Framework9.5m1.0k\nServerless Step Functionsby serverless-operations\nServerless Step Functionsby serverless-operations\nServerless Step Functions\nby serverless-operations\nAWS Step Functions plugin for Serverless Framework\nServerless Plugin Datadogby DataDogMonitoring, tracing, and real-time metrics for your Lambda functions9.2m94\nServerless Plugin Datadogby DataDog\nServerless Plugin Datadogby DataDog\nServerless Plugin Datadog\nMonitoring, tracing, and real-time metrics for your Lambda functions\nServerless Plugin Typescriptby serverlessServerless plugin for zero-config Typescript support.9.0m784\nServerless Plugin Typescriptby serverless\nServerless Plugin Typescriptby serverless\nServerless Plugin Typescript\nServerless plugin for zero-config Typescript support.\nServerless IAM Roles Per Functionby functionaloneServerless Plugin for easily defining IAM roles per function via th...8.6m411\nServerless IAM Roles Per Functionby functionalone\nServerless IAM Roles Per Functionby functionalone\nServerless IAM Roles Per Function\nServerless Plugin for easily defining IAM roles per function via th...\nServerless Python Requirementsby serverlessServerless plugin to bundle Python packages8.0m1.1k\nServerless Python Requirementsby serverless\nServerless Python Requirementsby serverless\nServerless Python Requirements\nServerless plugin to bundle Python packages\n© 2025 Serverless, Inc. All rights reserved.Terms of ServicePrivacy Policy\n© 2025 Serverless, Inc. All rights reserved.\nTerms of ServicePrivacy Policy\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIntroducing the Serverless MCPServerless TeamApril 17, 2025Introducing Serverless Container FrameworkServerless TeamFebruary 4, 2025Introducing The AWS AI StackServerless TeamSeptember 11, 2024Slash AWS Lambda Observability Costs with Serverless Framework’s Axiom IntegrationServerless TeamAugust 26, 2024Serverless Framework Now Supports AWS SAM & CloudformationServerless TeamAugust 26, 2024Serverless Framework V4 Generally AvailableServerless TeamJune 13, 2024Serverless Framework V4: A New ModelServerless TeamOctober 26, 2023Serverless Cloud spins off as AmptAusten CollinsNovember 15, 2022Introducing Serverless Console V2Austen CollinsNovember 10, 2022\n\n\n\nProducts Documentation PricingCompany Toggle themeSearch⌘ KLoginSign UpToggle navigation menu\nProducts Documentation PricingCompany Toggle themeSearch⌘ KLoginSign UpToggle navigation menu\nProducts Documentation PricingCompany Toggle themeSearch⌘ KLoginSign UpToggle navigation menu\nProducts Documentation PricingCompany\nToggle themeSearch⌘ KLoginSign Up\nToggle navigation menu\nMenuToggle navigation menuServerless ExamplesLanguageNodeGoJavaPythonRubyRustPhpSwiftCsharpAuthor0x4D31Abbasdgr8Adam BergmanAdnanrahicAdrian MoraretAletheiaAlex CasalboniAlexcasalboniAllan ChuaAndreas HeissenbergerAndrei MaksimovAndreivmaksimovAndresAndrewFarleyAnna SpyszAnomaly InnovationsAusten CollinsAyoubEdBen FitzgeraldBennybauerBill KidwellBill WangBjörn BilgerBoazdejongBrianAndersen78Bruce EdgeBryan KillianBsdkurtBvincent1CalvintychanCaulagiCeilforsChan9390Chief WizardChristoph GysinConveyalCpleeCraftshipCraig SweatonDaisuke-awajiDaniel AniszkiewiczDaniel OlsonDarren HollandDidilDrocco007DschepDuong TranDylan MyersDzimineEetu TuomalaEliecer Hernandez GarbeyEmilien EscalleErez RokahEslam λ HefnawyFaultlineFlorian FußFrancisco OrtizFrançois FargeGarden AidGarrett SweeneyGismo RanasGodfrey HobbsHoseungJangIgorbakmanIttusIvanderbu2James ThomasJan LiesendahlJay DeshmukhJisuParkJoeseph RodriguesJohncmunsonJonatas BaldinJonee Ryan TyJordan HornblowJoseph YiJoshuaTothKai HendryKalin ChernevKalinchernevKenyippKimcoderKurshit KukrejaLakshmantgldLuciano Pellacani FrancaLukas AndersenLynnalooMarcus LumMário LuizMark SteeleMarkhobsonMarzeelabsMatt HernandezMatt WelkeMay JunMbsambangiMbudmMiguel FrazaoMsfidelisMugglmenzelNiJiaNikosNileshprasad137NoetixNsupyqOpen-botP0n2Patrick MichelbergerPeter ChuPharindokoPhilipp MuensPicsoungPmuensPramono WinataRafalWilinskiRandy FindleyRentropRhlsthrmRob AbbottRpidannyRupak GangulySbstjnSC5Scott BrennerSCPRSebastian BorzaSeojeeeSeonghyun OhServerless, inc.ServerlessbuchShahzeb K.SilvermulletSlashbitSlaytrSrbryStefan JudisSvdgraafTakahashimTakahiro HorikeTheburningmonkThomastoyeTimothy HopperTylorShinUnlyWalgarchWolfgang TeuberPlatformAWSAzureGCPKubelessOpenwhiskTwilioAWS Simple HTTP Endpoint Example In Node JSby Serverless, inc.This template demonstrates how to make a simple HTTP API with Node....Node Express API On AWSby Serverless, inc.This template demonstrates how to develop and deploy a simple Node ...Node Express API Service Backed By Dynamo DB On...by Serverless, inc.This template demonstrates how to develop and deploy a simple Node ...AWS Node Scheduled Cron Example In Node JSby Rob AbbottThis is an example of creating a function that runs as a cron job u...AWS Node JS Exampleby Serverless, inc.This template demonstrates how to deploy a simple NodeJS function r...AWS Simple HTTP Endpoint Example In Pythonby Serverless, inc.This template demonstrates how to make a simple HTTP API with Pytho...Python Flask API On AWSby Serverless, inc.This template demonstrates how to develop and deploy a simple Pytho...Python Flask API Backed By Dynamo DB On AWSby Serverless, inc.This template demonstrates how to develop and deploy a simple Pytho...AWS Python Scheduled Cron Example In Pythonby Rupak GangulyThis is an example of creating a function that runs as a cron job u...AWS Python Exampleby Serverless, inc.This template demonstrates how to deploy a Python function running ...AWS Simple HTTP Endpoint Example In Node JS Wit...by Serverless, inc.This template demonstrates how to make a simple REST API with Node....AWS Simple HTTP Endpoint Example In Node JSby Serverless, inc.This template demonstrates how to make a simple REST API with Node....Previous12345More pages19Next\nMenuToggle navigation menuServerless ExamplesLanguageNodeGoJavaPythonRubyRustPhpSwiftCsharpAuthor0x4D31Abbasdgr8Adam BergmanAdnanrahicAdrian MoraretAletheiaAlex CasalboniAlexcasalboniAllan ChuaAndreas HeissenbergerAndrei MaksimovAndreivmaksimovAndresAndrewFarleyAnna SpyszAnomaly InnovationsAusten CollinsAyoubEdBen FitzgeraldBennybauerBill KidwellBill WangBjörn BilgerBoazdejongBrianAndersen78Bruce EdgeBryan KillianBsdkurtBvincent1CalvintychanCaulagiCeilforsChan9390Chief WizardChristoph GysinConveyalCpleeCraftshipCraig SweatonDaisuke-awajiDaniel AniszkiewiczDaniel OlsonDarren HollandDidilDrocco007DschepDuong TranDylan MyersDzimineEetu TuomalaEliecer Hernandez GarbeyEmilien EscalleErez RokahEslam λ HefnawyFaultlineFlorian FußFrancisco OrtizFrançois FargeGarden AidGarrett SweeneyGismo RanasGodfrey HobbsHoseungJangIgorbakmanIttusIvanderbu2James ThomasJan LiesendahlJay DeshmukhJisuParkJoeseph RodriguesJohncmunsonJonatas BaldinJonee Ryan TyJordan HornblowJoseph YiJoshuaTothKai HendryKalin ChernevKalinchernevKenyippKimcoderKurshit KukrejaLakshmantgldLuciano Pellacani FrancaLukas AndersenLynnalooMarcus LumMário LuizMark SteeleMarkhobsonMarzeelabsMatt HernandezMatt WelkeMay JunMbsambangiMbudmMiguel FrazaoMsfidelisMugglmenzelNiJiaNikosNileshprasad137NoetixNsupyqOpen-botP0n2Patrick MichelbergerPeter ChuPharindokoPhilipp MuensPicsoungPmuensPramono WinataRafalWilinskiRandy FindleyRentropRhlsthrmRob AbbottRpidannyRupak GangulySbstjnSC5Scott BrennerSCPRSebastian BorzaSeojeeeSeonghyun OhServerless, inc.ServerlessbuchShahzeb K.SilvermulletSlashbitSlaytrSrbryStefan JudisSvdgraafTakahashimTakahiro HorikeTheburningmonkThomastoyeTimothy HopperTylorShinUnlyWalgarchWolfgang TeuberPlatformAWSAzureGCPKubelessOpenwhiskTwilioAWS Simple HTTP Endpoint Example In Node JSby Serverless, inc.This template demonstrates how to make a simple HTTP API with Node....Node Express API On AWSby Serverless, inc.This template demonstrates how to develop and deploy a simple Node ...Node Express API Service Backed By Dynamo DB On...by Serverless, inc.This template demonstrates how to develop and deploy a simple Node ...AWS Node Scheduled Cron Example In Node JSby Rob AbbottThis is an example of creating a function that runs as a cron job u...AWS Node JS Exampleby Serverless, inc.This template demonstrates how to deploy a simple NodeJS function r...AWS Simple HTTP Endpoint Example In Pythonby Serverless, inc.This template demonstrates how to make a simple HTTP API with Pytho...Python Flask API On AWSby Serverless, inc.This template demonstrates how to develop and deploy a simple Pytho...Python Flask API Backed By Dynamo DB On AWSby Serverless, inc.This template demonstrates how to develop and deploy a simple Pytho...AWS Python Scheduled Cron Example In Pythonby Rupak GangulyThis is an example of creating a function that runs as a cron job u...AWS Python Exampleby Serverless, inc.This template demonstrates how to deploy a Python function running ...AWS Simple HTTP Endpoint Example In Node JS Wit...by Serverless, inc.This template demonstrates how to make a simple REST API with Node....AWS Simple HTTP Endpoint Example In Node JSby Serverless, inc.This template demonstrates how to make a simple REST API with Node....Previous12345More pages19Next\nMenuToggle navigation menu\nToggle navigation menu\nServerless ExamplesLanguageNodeGoJavaPythonRubyRustPhpSwiftCsharpAuthor0x4D31Abbasdgr8Adam BergmanAdnanrahicAdrian MoraretAletheiaAlex CasalboniAlexcasalboniAllan ChuaAndreas HeissenbergerAndrei MaksimovAndreivmaksimovAndresAndrewFarleyAnna SpyszAnomaly InnovationsAusten CollinsAyoubEdBen FitzgeraldBennybauerBill KidwellBill WangBjörn BilgerBoazdejongBrianAndersen78Bruce EdgeBryan KillianBsdkurtBvincent1CalvintychanCaulagiCeilforsChan9390Chief WizardChristoph GysinConveyalCpleeCraftshipCraig SweatonDaisuke-awajiDaniel AniszkiewiczDaniel OlsonDarren HollandDidilDrocco007DschepDuong TranDylan MyersDzimineEetu TuomalaEliecer Hernandez GarbeyEmilien EscalleErez RokahEslam λ HefnawyFaultlineFlorian FußFrancisco OrtizFrançois FargeGarden AidGarrett SweeneyGismo RanasGodfrey HobbsHoseungJangIgorbakmanIttusIvanderbu2James ThomasJan LiesendahlJay DeshmukhJisuParkJoeseph RodriguesJohncmunsonJonatas BaldinJonee Ryan TyJordan HornblowJoseph YiJoshuaTothKai HendryKalin ChernevKalinchernevKenyippKimcoderKurshit KukrejaLakshmantgldLuciano Pellacani FrancaLukas AndersenLynnalooMarcus LumMário LuizMark SteeleMarkhobsonMarzeelabsMatt HernandezMatt WelkeMay JunMbsambangiMbudmMiguel FrazaoMsfidelisMugglmenzelNiJiaNikosNileshprasad137NoetixNsupyqOpen-botP0n2Patrick MichelbergerPeter ChuPharindokoPhilipp MuensPicsoungPmuensPramono WinataRafalWilinskiRandy FindleyRentropRhlsthrmRob AbbottRpidannyRupak GangulySbstjnSC5Scott BrennerSCPRSebastian BorzaSeojeeeSeonghyun OhServerless, inc.ServerlessbuchShahzeb K.SilvermulletSlashbitSlaytrSrbryStefan JudisSvdgraafTakahashimTakahiro HorikeTheburningmonkThomastoyeTimothy HopperTylorShinUnlyWalgarchWolfgang TeuberPlatformAWSAzureGCPKubelessOpenwhiskTwilio\nServerless ExamplesLanguageNodeGoJavaPythonRubyRustPhpSwiftCsharpAuthor0x4D31Abbasdgr8Adam BergmanAdnanrahicAdrian MoraretAletheiaAlex CasalboniAlexcasalboniAllan ChuaAndreas HeissenbergerAndrei MaksimovAndreivmaksimovAndresAndrewFarleyAnna SpyszAnomaly InnovationsAusten CollinsAyoubEdBen FitzgeraldBennybauerBill KidwellBill WangBjörn BilgerBoazdejongBrianAndersen78Bruce EdgeBryan KillianBsdkurtBvincent1CalvintychanCaulagiCeilforsChan9390Chief WizardChristoph GysinConveyalCpleeCraftshipCraig SweatonDaisuke-awajiDaniel AniszkiewiczDaniel OlsonDarren HollandDidilDrocco007DschepDuong TranDylan MyersDzimineEetu TuomalaEliecer Hernandez GarbeyEmilien EscalleErez RokahEslam λ HefnawyFaultlineFlorian FußFrancisco OrtizFrançois FargeGarden AidGarrett SweeneyGismo RanasGodfrey HobbsHoseungJangIgorbakmanIttusIvanderbu2James ThomasJan LiesendahlJay DeshmukhJisuParkJoeseph RodriguesJohncmunsonJonatas BaldinJonee Ryan TyJordan HornblowJoseph YiJoshuaTothKai HendryKalin ChernevKalinchernevKenyippKimcoderKurshit KukrejaLakshmantgldLuciano Pellacani FrancaLukas AndersenLynnalooMarcus LumMário LuizMark SteeleMarkhobsonMarzeelabsMatt HernandezMatt WelkeMay JunMbsambangiMbudmMiguel FrazaoMsfidelisMugglmenzelNiJiaNikosNileshprasad137NoetixNsupyqOpen-botP0n2Patrick MichelbergerPeter ChuPharindokoPhilipp MuensPicsoungPmuensPramono WinataRafalWilinskiRandy FindleyRentropRhlsthrmRob AbbottRpidannyRupak GangulySbstjnSC5Scott BrennerSCPRSebastian BorzaSeojeeeSeonghyun OhServerless, inc.ServerlessbuchShahzeb K.SilvermulletSlashbitSlaytrSrbryStefan JudisSvdgraafTakahashimTakahiro HorikeTheburningmonkThomastoyeTimothy HopperTylorShinUnlyWalgarchWolfgang TeuberPlatformAWSAzureGCPKubelessOpenwhiskTwilio\nServerless ExamplesLanguageNodeGoJavaPythonRubyRustPhpSwiftCsharpAuthor0x4D31Abbasdgr8Adam BergmanAdnanrahicAdrian MoraretAletheiaAlex CasalboniAlexcasalboniAllan ChuaAndreas HeissenbergerAndrei MaksimovAndreivmaksimovAndresAndrewFarleyAnna SpyszAnomaly InnovationsAusten CollinsAyoubEdBen FitzgeraldBennybauerBill KidwellBill WangBjörn BilgerBoazdejongBrianAndersen78Bruce EdgeBryan KillianBsdkurtBvincent1CalvintychanCaulagiCeilforsChan9390Chief WizardChristoph GysinConveyalCpleeCraftshipCraig SweatonDaisuke-awajiDaniel AniszkiewiczDaniel OlsonDarren HollandDidilDrocco007DschepDuong TranDylan MyersDzimineEetu TuomalaEliecer Hernandez GarbeyEmilien EscalleErez RokahEslam λ HefnawyFaultlineFlorian FußFrancisco OrtizFrançois FargeGarden AidGarrett SweeneyGismo RanasGodfrey HobbsHoseungJangIgorbakmanIttusIvanderbu2James ThomasJan LiesendahlJay DeshmukhJisuParkJoeseph RodriguesJohncmunsonJonatas BaldinJonee Ryan TyJordan HornblowJoseph YiJoshuaTothKai HendryKalin ChernevKalinchernevKenyippKimcoderKurshit KukrejaLakshmantgldLuciano Pellacani FrancaLukas AndersenLynnalooMarcus LumMário LuizMark SteeleMarkhobsonMarzeelabsMatt HernandezMatt WelkeMay JunMbsambangiMbudmMiguel FrazaoMsfidelisMugglmenzelNiJiaNikosNileshprasad137NoetixNsupyqOpen-botP0n2Patrick MichelbergerPeter ChuPharindokoPhilipp MuensPicsoungPmuensPramono WinataRafalWilinskiRandy FindleyRentropRhlsthrmRob AbbottRpidannyRupak GangulySbstjnSC5Scott BrennerSCPRSebastian BorzaSeojeeeSeonghyun OhServerless, inc.ServerlessbuchShahzeb K.SilvermulletSlashbitSlaytrSrbryStefan JudisSvdgraafTakahashimTakahiro HorikeTheburningmonkThomastoyeTimothy HopperTylorShinUnlyWalgarchWolfgang TeuberPlatformAWSAzureGCPKubelessOpenwhiskTwilio\nLanguageNodeGoJavaPythonRubyRustPhpSwiftCsharp\nNodeGoJavaPythonRubyRustPhpSwiftCsharp\nAuthor0x4D31Abbasdgr8Adam BergmanAdnanrahicAdrian MoraretAletheiaAlex CasalboniAlexcasalboniAllan ChuaAndreas HeissenbergerAndrei MaksimovAndreivmaksimovAndresAndrewFarleyAnna SpyszAnomaly InnovationsAusten CollinsAyoubEdBen FitzgeraldBennybauerBill KidwellBill WangBjörn BilgerBoazdejongBrianAndersen78Bruce EdgeBryan KillianBsdkurtBvincent1CalvintychanCaulagiCeilforsChan9390Chief WizardChristoph GysinConveyalCpleeCraftshipCraig SweatonDaisuke-awajiDaniel AniszkiewiczDaniel OlsonDarren HollandDidilDrocco007DschepDuong TranDylan MyersDzimineEetu TuomalaEliecer Hernandez GarbeyEmilien EscalleErez RokahEslam λ HefnawyFaultlineFlorian FußFrancisco OrtizFrançois FargeGarden AidGarrett SweeneyGismo RanasGodfrey HobbsHoseungJangIgorbakmanIttusIvanderbu2James ThomasJan LiesendahlJay DeshmukhJisuParkJoeseph RodriguesJohncmunsonJonatas BaldinJonee Ryan TyJordan HornblowJoseph YiJoshuaTothKai HendryKalin ChernevKalinchernevKenyippKimcoderKurshit KukrejaLakshmantgldLuciano Pellacani FrancaLukas AndersenLynnalooMarcus LumMário LuizMark SteeleMarkhobsonMarzeelabsMatt HernandezMatt WelkeMay JunMbsambangiMbudmMiguel FrazaoMsfidelisMugglmenzelNiJiaNikosNileshprasad137NoetixNsupyqOpen-botP0n2Patrick MichelbergerPeter ChuPharindokoPhilipp MuensPicsoungPmuensPramono WinataRafalWilinskiRandy FindleyRentropRhlsthrmRob AbbottRpidannyRupak GangulySbstjnSC5Scott BrennerSCPRSebastian BorzaSeojeeeSeonghyun OhServerless, inc.ServerlessbuchShahzeb K.SilvermulletSlashbitSlaytrSrbryStefan JudisSvdgraafTakahashimTakahiro HorikeTheburningmonkThomastoyeTimothy HopperTylorShinUnlyWalgarchWolfgang Teuber\n0x4D31Abbasdgr8Adam BergmanAdnanrahicAdrian MoraretAletheiaAlex CasalboniAlexcasalboniAllan ChuaAndreas HeissenbergerAndrei MaksimovAndreivmaksimovAndresAndrewFarleyAnna SpyszAnomaly InnovationsAusten CollinsAyoubEdBen FitzgeraldBennybauerBill KidwellBill WangBjörn BilgerBoazdejongBrianAndersen78Bruce EdgeBryan KillianBsdkurtBvincent1CalvintychanCaulagiCeilforsChan9390Chief WizardChristoph GysinConveyalCpleeCraftshipCraig SweatonDaisuke-awajiDaniel AniszkiewiczDaniel OlsonDarren HollandDidilDrocco007DschepDuong TranDylan MyersDzimineEetu TuomalaEliecer Hernandez GarbeyEmilien EscalleErez RokahEslam λ HefnawyFaultlineFlorian FußFrancisco OrtizFrançois FargeGarden AidGarrett SweeneyGismo RanasGodfrey HobbsHoseungJangIgorbakmanIttusIvanderbu2James ThomasJan LiesendahlJay DeshmukhJisuParkJoeseph RodriguesJohncmunsonJonatas BaldinJonee Ryan TyJordan HornblowJoseph YiJoshuaTothKai HendryKalin ChernevKalinchernevKenyippKimcoderKurshit KukrejaLakshmantgldLuciano Pellacani FrancaLukas AndersenLynnalooMarcus LumMário LuizMark SteeleMarkhobsonMarzeelabsMatt HernandezMatt WelkeMay JunMbsambangiMbudmMiguel FrazaoMsfidelisMugglmenzelNiJiaNikosNileshprasad137NoetixNsupyqOpen-botP0n2Patrick MichelbergerPeter ChuPharindokoPhilipp MuensPicsoungPmuensPramono WinataRafalWilinskiRandy FindleyRentropRhlsthrmRob AbbottRpidannyRupak GangulySbstjnSC5Scott BrennerSCPRSebastian BorzaSeojeeeSeonghyun OhServerless, inc.ServerlessbuchShahzeb K.SilvermulletSlashbitSlaytrSrbryStefan JudisSvdgraafTakahashimTakahiro HorikeTheburningmonkThomastoyeTimothy HopperTylorShinUnlyWalgarchWolfgang Teuber\nAndreas Heissenberger\nAndreas Heissenberger\nEliecer Hernandez Garbey\nEliecer Hernandez Garbey\nLuciano Pellacani Franca\nLuciano Pellacani Franca\nPlatformAWSAzureGCPKubelessOpenwhiskTwilio\nAWSAzureGCPKubelessOpenwhiskTwilio\nAWS Simple HTTP Endpoint Example In Node JSby Serverless, inc.This template demonstrates how to make a simple HTTP API with Node....Node Express API On AWSby Serverless, inc.This template demonstrates how to develop and deploy a simple Node ...Node Express API Service Backed By Dynamo DB On...by Serverless, inc.This template demonstrates how to develop and deploy a simple Node ...AWS Node Scheduled Cron Example In Node JSby Rob AbbottThis is an example of creating a function that runs as a cron job u...AWS Node JS Exampleby Serverless, inc.This template demonstrates how to deploy a simple NodeJS function r...AWS Simple HTTP Endpoint Example In Pythonby Serverless, inc.This template demonstrates how to make a simple HTTP API with Pytho...Python Flask API On AWSby Serverless, inc.This template demonstrates how to develop and deploy a simple Pytho...Python Flask API Backed By Dynamo DB On AWSby Serverless, inc.This template demonstrates how to develop and deploy a simple Pytho...AWS Python Scheduled Cron Example In Pythonby Rupak GangulyThis is an example of creating a function that runs as a cron job u...AWS Python Exampleby Serverless, inc.This template demonstrates how to deploy a Python function running ...AWS Simple HTTP Endpoint Example In Node JS Wit...by Serverless, inc.This template demonstrates how to make a simple REST API with Node....AWS Simple HTTP Endpoint Example In Node JSby Serverless, inc.This template demonstrates how to make a simple REST API with Node....Previous12345More pages19Next\nAWS Simple HTTP Endpoint Example In Node JSby Serverless, inc.This template demonstrates how to make a simple HTTP API with Node....Node Express API On AWSby Serverless, inc.This template demonstrates how to develop and deploy a simple Node ...Node Express API Service Backed By Dynamo DB On...by Serverless, inc.This template demonstrates how to develop and deploy a simple Node ...AWS Node Scheduled Cron Example In Node JSby Rob AbbottThis is an example of creating a function that runs as a cron job u...AWS Node JS Exampleby Serverless, inc.This template demonstrates how to deploy a simple NodeJS function r...AWS Simple HTTP Endpoint Example In Pythonby Serverless, inc.This template demonstrates how to make a simple HTTP API with Pytho...Python Flask API On AWSby Serverless, inc.This template demonstrates how to develop and deploy a simple Pytho...Python Flask API Backed By Dynamo DB On AWSby Serverless, inc.This template demonstrates how to develop and deploy a simple Pytho...AWS Python Scheduled Cron Example In Pythonby Rupak GangulyThis is an example of creating a function that runs as a cron job u...AWS Python Exampleby Serverless, inc.This template demonstrates how to deploy a Python function running ...AWS Simple HTTP Endpoint Example In Node JS Wit...by Serverless, inc.This template demonstrates how to make a simple REST API with Node....AWS Simple HTTP Endpoint Example In Node JSby Serverless, inc.This template demonstrates how to make a simple REST API with Node....\nAWS Simple HTTP Endpoint Example In Node JSby Serverless, inc.This template demonstrates how to make a simple HTTP API with Node....\nAWS Simple HTTP Endpoint Example In Node JSby Serverless, inc.\nAWS Simple HTTP Endpoint Example In Node JSby Serverless, inc.\nAWS Simple HTTP Endpoint Example In Node JS\nThis template demonstrates how to make a simple HTTP API with Node....\nNode Express API On AWSby Serverless, inc.This template demonstrates how to develop and deploy a simple Node ...\nNode Express API On AWSby Serverless, inc.\nNode Express API On AWSby Serverless, inc.\nNode Express API On AWS\nThis template demonstrates how to develop and deploy a simple Node ...\nNode Express API Service Backed By Dynamo DB On...by Serverless, inc.This template demonstrates how to develop and deploy a simple Node ...\nNode Express API Service Backed By Dynamo DB On...by Serverless, inc.\nNode Express API Service Backed By Dynamo DB On...by Serverless, inc.\nNode Express API Service Backed By Dynamo DB On...\nThis template demonstrates how to develop and deploy a simple Node ...\nAWS Node Scheduled Cron Example In Node JSby Rob AbbottThis is an example of creating a function that runs as a cron job u...\nAWS Node Scheduled Cron Example In Node JSby Rob Abbott\nAWS Node Scheduled Cron Example In Node JSby Rob Abbott\nAWS Node Scheduled Cron Example In Node JS\nThis is an example of creating a function that runs as a cron job u...\nAWS Node JS Exampleby Serverless, inc.This template demonstrates how to deploy a simple NodeJS function r...\nAWS Node JS Exampleby Serverless, inc.\nAWS Node JS Exampleby Serverless, inc.\nThis template demonstrates how to deploy a simple NodeJS function r...\nAWS Simple HTTP Endpoint Example In Pythonby Serverless, inc.This template demonstrates how to make a simple HTTP API with Pytho...\nAWS Simple HTTP Endpoint Example In Pythonby Serverless, inc.\nAWS Simple HTTP Endpoint Example In Pythonby Serverless, inc.\nAWS Simple HTTP Endpoint Example In Python\nThis template demonstrates how to make a simple HTTP API with Pytho...\nPython Flask API On AWSby Serverless, inc.This template demonstrates how to develop and deploy a simple Pytho...\nPython Flask API On AWSby Serverless, inc.\nPython Flask API On AWSby Serverless, inc.\nPython Flask API On AWS\nThis template demonstrates how to develop and deploy a simple Pytho...\nPython Flask API Backed By Dynamo DB On AWSby Serverless, inc.This template demonstrates how to develop and deploy a simple Pytho...\nPython Flask API Backed By Dynamo DB On AWSby Serverless, inc.\nPython Flask API Backed By Dynamo DB On AWSby Serverless, inc.\nPython Flask API Backed By Dynamo DB On AWS\nThis template demonstrates how to develop and deploy a simple Pytho...\nAWS Python Scheduled Cron Example In Pythonby Rupak GangulyThis is an example of creating a function that runs as a cron job u...\nAWS Python Scheduled Cron Example In Pythonby Rupak Ganguly\nAWS Python Scheduled Cron Example In Pythonby Rupak Ganguly\nAWS Python Scheduled Cron Example In Python\nThis is an example of creating a function that runs as a cron job u...\nAWS Python Exampleby Serverless, inc.This template demonstrates how to deploy a Python function running ...\nAWS Python Exampleby Serverless, inc.\nAWS Python Exampleby Serverless, inc.\nThis template demonstrates how to deploy a Python function running ...\nAWS Simple HTTP Endpoint Example In Node JS Wit...by Serverless, inc.This template demonstrates how to make a simple REST API with Node....\nAWS Simple HTTP Endpoint Example In Node JS Wit...by Serverless, inc.\nAWS Simple HTTP Endpoint Example In Node JS Wit...by Serverless, inc.\nAWS Simple HTTP Endpoint Example In Node JS Wit...\nThis template demonstrates how to make a simple REST API with Node....\nAWS Simple HTTP Endpoint Example In Node JSby Serverless, inc.This template demonstrates how to make a simple REST API with Node....\nAWS Simple HTTP Endpoint Example In Node JSby Serverless, inc.\nAWS Simple HTTP Endpoint Example In Node JSby Serverless, inc.\nAWS Simple HTTP Endpoint Example In Node JS\nThis template demonstrates how to make a simple REST API with Node....\n© 2025 Serverless, Inc. All rights reserved.Terms of ServicePrivacy Policy\n© 2025 Serverless, Inc. All rights reserved.\nTerms of ServicePrivacy Policy\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCreate a new workspace\nCreate a new workspace\nProductPricingSupportDownload the Slack appSign inCreate a new workspace\nDownload the Slack app\nDownload the Slack app\nCreate a new workspace\nCreate a new workspace\nCreate a new workspace\nWe're very sorry, but your browser is not supported!Please upgrade to a supported browser, or try one of our apps.Desktop AppsMacSee system requirementsv4.43.52WindowsSee system requirementsv4.43.52LinuxSee system requirementsv4.43.51Mobile AppsiOSAndroidDon't see the platform you're looking for? Let us know.\nWe're very sorry, but your browser is not supported!Please upgrade to a supported browser, or try one of our apps.Desktop AppsMacSee system requirementsv4.43.52WindowsSee system requirementsv4.43.52LinuxSee system requirementsv4.43.51Mobile AppsiOSAndroidDon't see the platform you're looking for? Let us know.\nWe're very sorry, but your browser is not supported!Please upgrade to a supported browser, or try one of our apps.\nWe're very sorry, but your browser is not supported!\nPlease upgrade to a supported browser, or try one of our apps.\nMacSee system requirementsv4.43.52WindowsSee system requirementsv4.43.52LinuxSee system requirementsv4.43.51\nMacSee system requirementsv4.43.52\nSee system requirements\nSee system requirements\nWindowsSee system requirementsv4.43.52\nSee system requirements\nSee system requirements\nLinuxSee system requirementsv4.43.51\nSee system requirements\nSee system requirements\nDon't see the platform you're looking for? Let us know.\nUsing SlackProductEnterprisePricingSupportSlack GuidesSlack MarketplaceAPISlack JobsCustomersDevelopersEventsBlogLegalPrivacySecurityTerms of ServicePoliciesHandy LinksDownload desktop appDownload mobile appBrand GuidelinesSlack at WorkStatus\nUsing SlackProductEnterprisePricingSupportSlack GuidesSlack MarketplaceAPI\nSlack JobsCustomersDevelopersEventsBlog\nLegalPrivacySecurityTerms of ServicePolicies\nHandy LinksDownload desktop appDownload mobile appBrand GuidelinesSlack at WorkStatus\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIntroducing the Serverless MCPServerless TeamApril 17, 2025Introducing Serverless Container FrameworkServerless TeamFebruary 4, 2025Introducing The AWS AI StackServerless TeamSeptember 11, 2024Slash AWS Lambda Observability Costs with Serverless Framework’s Axiom IntegrationServerless TeamAugust 26, 2024Serverless Framework Now Supports AWS SAM & CloudformationServerless TeamAugust 26, 2024Serverless Framework V4 Generally AvailableServerless TeamJune 13, 2024Serverless Framework V4: A New ModelServerless TeamOctober 26, 2023Introducing Serverless Console V2Austen CollinsNovember 10, 2022May 4th Community Call - Webinar RecapRichard GrantMay 10, 2022\n\n\n\n\n\n\n\n\n\nIntroducing the Serverless MCPServerless TeamApr 17, 2025Introducing Serverless Container FrameworkServerless TeamFeb 4, 2025Introducing The AWS AI StackServerless TeamSep 11, 2024\n\n\n\n\n\nIntroducing the Serverless MCPServerless TeamApr 17, 2025Introducing Serverless Container FrameworkServerless TeamFeb 4, 2025Introducing The AWS AI StackServerless TeamSep 11, 2024\n\n\n\n\n\nIntroducing the Serverless MCPServerless TeamApr 17, 2025Introducing Serverless Container FrameworkServerless TeamFeb 4, 2025Introducing The AWS AI StackServerless TeamSep 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nServerless Offline
⚠️
We are looking for maintainers! This package is entirely community-driven. Please send an email to dherault to start helping now.
⚠️

  
    
  
  
    
  
  
    
  
  
  
    
  
  
    
  
  
  
    
  
  
    
  

This Serverless plugin emulates AWS λ and API Gateway on your local machine to speed up your development cycles.
To do so, it starts an HTTP server that handles the request's lifecycle like APIG does and invokes your handlers.
Features

Node.js, Python, Ruby, Go, Java (incl. Kotlin, Groovy, Scala) λ runtimes.
Velocity templates support.
Lazy loading of your handler files.
And more: integrations, authorizers, proxies, timeouts, responseParameters, HTTPS, CORS, etc...

This plugin is updated by its users, I just do maintenance and ensure that PRs are relevant to the community. In other words, if you find a bug or want a new feature, please help us by becoming one of the contributors :v: ! See the contributing section.
Documentation

Installation
Usage and command line options
Run modes
Invoke Lambda
The process.env.IS_OFFLINE variable
Docker and Layers
Authorizers

Token authorizers
Custom authorizers
Remote authorizers
JWT authorizers
Serverless plugin authorizers


Custom headers
Environment variables
AWS API Gateway Features

Velocity Templates

Velocity nuances


CORS
Catch-all Path Variables
ANY method
Lambda and Lambda Proxy Integrations
HTTP Proxy
Response parameters


WebSocket
Debug process
Resource permissions and AWS profile
Simulation quality
Usage with other plugins
Credits and inspiration
License
Contributing
Contributors

Installation
First, add Serverless Offline to your project:
npm install serverless-offline --save-dev
Then inside your project's serverless.yml file add following entry to the plugins section: serverless-offline. If there is no plugin section you will need to add it to the file.
Note that the "plugin" section for serverless-offline must be at root level on serverless.yml.
It should look something like this:
plugins:  - serverless-offline
You can check whether you have successfully installed the plugin by running the serverless command line:
serverless --verbose
the console should display Offline as one of the plugins now available in your Serverless project.
Usage and command line options
In your project root run:
serverless offline or sls offline.
to list all the options for the plugin run:
sls offline --help
All CLI options are optional:
corsAllowHeaders
Used as default Access-Control-Allow-Headers header value for responses. Delimit multiple values with commas.
Default: 'accept,content-type,x-api-key'
corsAllowOrigin
Used as default Access-Control-Allow-Origin header value for responses. Delimit multiple values with commas.
Default: '*'
corsDisallowCredentials
When provided, the default Access-Control-Allow-Credentials header value will be passed as 'false'.
Default: true
corsExposedHeaders
Used as additional Access-Control-Exposed-Headers header value for responses. Delimit multiple values with commas.
Default: 'WWW-Authenticate,Server-Authorization'
disableCookieValidation
Used to disable cookie-validation on hapi.js-server.
dockerHost
The host name of Docker.
Default: localhost
dockerHostServicePath
Defines service path which is used by SLS running inside Docker container.
dockerNetwork
The network that the Docker container will connect to.
dockerReadOnly
Marks if the docker code layer should be read only.
Default: true
enforceSecureCookies
Enforce secure cookies
host
-o Host name to listen on.
Default: localhost
httpPort
Http port to listen on.
Default: 3000
httpsProtocol
-H To enable HTTPS, specify directory (relative to your cwd, typically your project dir) for both cert.pem and key.pem files.
ignoreJWTSignature
When using HttpApi with a JWT authorizer, don't check the signature of the JWT token.
lambdaPort
Lambda http port to listen on.
Default: 3002
layersDir
The directory layers should be stored in.
Default: ${codeDir}/.serverless-offline/layers'
localEnvironment
Copy local environment variables.
Default: false
noAuth
Turns off all authorizers.
noPrependStageInUrl
Don't prepend http routes with the stage.
noTimeout
-t Disables the timeout feature.
prefix
-p Adds a prefix to every path, to send your requests to http://localhost:3000/[prefix]/[your_path] instead.
Default: ''
reloadHandler
Reloads handler with each request.
resourceRoutes
Turns on loading of your HTTP proxy settings from serverless.yml.
terminateIdleLambdaTime
Number of seconds until an idle function is eligible for termination.
useDocker
Run handlers in a docker container.
useInProcess
Run handlers in the same process as 'serverless-offline'.
webSocketHardTimeout
Set WebSocket hard timeout in seconds to reproduce AWS limits (https://docs.aws.amazon.com/apigateway/latest/developerguide/limits.html#apigateway-execution-service-websocket-limits-table).
Default: 7200 (2 hours)
webSocketIdleTimeout
Set WebSocket idle timeout in seconds to reproduce AWS limits (https://docs.aws.amazon.com/apigateway/latest/developerguide/limits.html#apigateway-execution-service-websocket-limits-table).
Default: 600 (10 minutes)
websocketPort
WebSocket port to listen on.
Default: 3001
Any of the CLI options can be added to your serverless.yml. For example:
custom:  serverless-offline:    httpsProtocol: 'dev-certs'    httpPort: 4000      foo: 'bar'
Options passed on the command line override YAML options.
By default you can send your requests to http://localhost:3000/. Please note that:

You'll need to restart the plugin if you modify your serverless.yml or any of the default velocity template files.
When no Content-Type header is set on a request, API Gateway defaults to application/json, and so does the plugin.
But if you send an application/x-www-form-urlencoded or a multipart/form-data body with an application/json (or no) Content-Type, API Gateway won't parse your data (you'll get the ugly raw as input), whereas the plugin will answer 400 (malformed JSON).
Please consider explicitly setting your requests' Content-Type and using separate templates.

Run modes
node.js
Lambda handlers with serverless-offline for the node.js runtime can run in different execution modes and have some differences with a variety of pros and cons. they are currently mutually exclusive and it's not possible to use a combination, e.g. use in-process for one Lambda, and worker-threads for another. It is planned to combine the flags into one single flag in the future and also add support for combining run modes.
worker-threads (default)

handlers run in their own context
memory is not being shared between handlers, memory consumption is therefore higher
memory is being released when handlers reload or after usage
environment (process.env) is not being shared across handlers
global state is not being shared across handlers
easy debugging

NOTE:

native modules need to be a Node-API addon or be declared as context-aware using NODE_MODULE_INIT(): https://nodejs.org/docs/latest/api/addons.html#worker-support

in-process

handlers run in the same context (instance) as serverless and serverless-offline
memory is being shared across lambda handlers as well as with serverless and serverless-offline
no reloading capabilities as it is [currently] not possible to implement for commonjs handlers (without memory leaks) and for esm handlers
environment (process.env) is being shared across handlers as well as with serverless and serverless-offline
global state is being shared across lambda handlers as well as with serverless and serverless-offline
easy debugging

docker

handlers run in a docker container
memory is not being shared between handlers, memory consumption is therefore higher
memory is being released when handlers reload or after usage
environment (process.env) is not being shared across handlers
global state is not being shared across handlers
debugging more complicated

Python, Ruby, Go, Java (incl. Kotlin, Groovy, Scala)
the Lambda handler process is running in a child process.
Invoke Lambda
To use Lambda.invoke you need to set the lambda endpoint to the serverless-offline endpoint:
import { env } from "node:process"import aws from "aws-sdk"const lambda = new aws.Lambda({  apiVersion: "2015-03-31",  // endpoint needs to be set only if it deviates from the default  endpoint: env.IS_OFFLINE    ? "http://localhost:3002"    : "https://lambda.us-east-1.amazonaws.com",})
All your lambdas can then be invoked in a handler using
import { Buffer } from "node:buffer"import aws from "aws-sdk"const { stringify } = JSONconst lambda = new aws.Lambda({  apiVersion: "2015-03-31",  endpoint: "http://localhost:3002",})export async function handler() {  const clientContextData = stringify({    foo: "foo",  })  const payload = stringify({    data: "foo",  })  const params = {    ClientContext: Buffer.from(clientContextData).toString("base64"),    // FunctionName is composed of: service name - stage - function name, e.g.    FunctionName: "myServiceName-dev-invokedHandler",    InvocationType: "RequestResponse",    Payload: payload,  }  const response = await lambda.invoke(params).promise()  return {    body: stringify(response),    statusCode: 200,  }}
You can also invoke using the aws cli by specifying --endpoint-url
aws lambda invoke /dev/null \  --endpoint-url http://localhost:3002 \  --function-name myServiceName-dev-invokedHandler
List of available function names and their corresponding serverless.yml function keys
are listed after the server starts. This is important if you use a custom naming
scheme for your functions as serverless-offline will use your custom name.
The left side is the function's key in your serverless.yml
(invokedHandler in the example below) and the right side is the function name
that is used to call the function externally such as aws-sdk
(myServiceName-dev-invokedHandler in the example below):
serverless offline...offline: Starting Offline: local/us-east-1.offline: Offline [http for lambda] listening on http://localhost:3002offline: Function names exposed for local invocation by aws-sdk:           * invokedHandler: myServiceName-dev-invokedHandler
To list the available manual invocation paths exposed for targeting
by aws-sdk and aws-cli, use SLS_DEBUG=* with serverless offline. After the invoke server starts up, full list of endpoints will be displayed:
SLS_DEBUG=* serverless offline...offline: Starting Offline: local/us-east-1....offline: Offline [http for lambda] listening on http://localhost:3002offline: Function names exposed for local invocation by aws-sdk:           * invokedHandler: myServiceName-dev-invokedHandler[offline] Lambda Invocation Routes (for AWS SDK or AWS CLI):           * POST http://localhost:3002/2015-03-31/functions/myServiceName-dev-invokedHandler/invocations[offline] Lambda Async Invocation Routes (for AWS SDK or AWS CLI):           * POST http://localhost:3002/2014-11-13/functions/myServiceName-dev-invokedHandler/invoke-async/
You can manually target these endpoints with a REST client to debug your lambda
function if you want to. Your POST JSON body will be the Payload passed to your function if you were
to calling it via aws-sdk.
The process.env.IS_OFFLINE variable
Will be "true" in your handlers when using serverless-offline.
Docker and Layers
To use layers with serverless-offline, you need to have the useDocker option set to true. This can either be by using the --useDocker command, or in your serverless.yml like this:
custom:  serverless-offline:    useDocker: true
This will allow the docker container to look up any information about layers, download and use them. For this to work, you must be using:

AWS as a provider, it won't work with other provider types.
Layers that are compatible with your runtime.
ARNs for layers. Local layers aren't supported as yet.
A local AWS account set-up that can query and download layers.

If you're using least-privilege principals for your AWS roles, this policy should get you by:
{  "Statement": [    {      "Action": "lambda:GetLayerVersion",      "Effect": "Allow",      "Resource": "arn:aws:lambda:*:*:layer:*:*"    }  ],  "Version": "2012-10-17"}
Once you run a function that boots up the Docker container, it'll look through the layers for that function, download them in order to your layers folder, and save a hash of your layers so it can be re-used in future. You'll only need to re-download your layers if they change in the future. If you want your layers to re-download, simply remove your layers folder.
You should then be able to invoke functions as normal, and they're executed against the layers in your docker container.
Additional Options
There are 5 additional options available for Docker and Layer usage.

dockerHost
dockerHostServicePath
dockerNetwork
dockerReadOnly
layersDir

dockerHost
When running Docker Lambda inside another Docker container, you may need to configure the host name for the host machine to resolve networking issues between Docker Lambda and the host. Typically in such cases you would set this to host.docker.internal.
dockerHostServicePath
When running Docker Lambda inside another Docker container, you may need to override the code path that gets mounted to the Docker Lambda container relative to the host machine. Typically in such cases you would set this to ${PWD}.
dockerNetwork
When running Docker Lambda inside another Docker container, you may need to override network that Docker Lambda connects to in order to communicate with other containers.
dockerReadOnly
For certain programming languages and frameworks, it's desirable to be able to write to the filesystem for things like testing with local SQLite databases, or other testing-only modifications. For this, you can set dockerReadOnly: false, and this will allow local filesystem modifications. This does not strictly mimic AWS Lambda, as Lambda has a Read-Only filesystem, so this should be used as a last resort.
layersDir
By default layers are downloaded on a per-project basis, however, if you want to share them across projects, you can download them to a common place. For example, layersDir: /tmp/layers would allow them to be shared across projects. Make sure when using this setting that the directory you are writing layers to can be shared by docker.
Authorizers
Token authorizers
As defined in the Serverless Documentation you can use API Keys as a simple authentication method.
Serverless-offline will emulate the behaviour of APIG and create a random token that's printed on the screen. With this token you can access your private methods adding x-api-key: generatedToken to your request header. All api keys will share the same token.
Custom authorizers
Only custom authorizers are supported. Custom authorizers are executed before a Lambda function is executed and return an Error or a Policy document.
The Custom authorizer is passed an event object as below:
{  "authorizationToken": "<Incoming bearer token>",  "methodArn": "arn:aws:execute-api:<Region id>:<Account id>:<API id>/<Stage>/<Method>/<Resource path>",  "type": "TOKEN"}
The methodArn does not include the Account id or API id.
The plugin only supports retrieving Tokens from headers. You can configure the header as below:
"authorizer": {  "authorizerResultTtlInSeconds": "0",  "identitySource": "method.request.header.Authorization", // or method.request.header.SomeOtherHeader  "type": "TOKEN"}
Remote authorizers
You are able to mock the response from remote authorizers by setting the environmental variable AUTHORIZER before running sls offline start
Example:

Unix: export AUTHORIZER='{"principalId": "123"}'


Windows: SET AUTHORIZER='{"principalId": "123"}'

JWT authorizers
For HTTP APIs, JWT authorizers
defined in the serverless.yml can be used to validate the token and scopes in the token. However at this time,
the signature of the JWT is not validated with the defined issuer. Since this is a security risk, this feature is
only enabled with the --ignoreJWTSignature flag. Make sure to only set this flag for local development work.
Serverless plugin authorizers
If your authentication needs are custom and not satisfied by the existing capabilities of the Serverless offline project, you can inject your own authentication strategy. To inject a custom strategy for Lambda invocation, you define a custom variable under offline called customAuthenticationProvider in the serverless.yml file. The value of the custom variable will be used to require(your customAuthenticationProvider value) where the location is expected to return a function with the following signature.
offline:  customAuthenticationProvider: ./path/to/custom-authentication-provider
// ./path/to/customer-authentication-provider.jsmodule.exports = function (endpoint, functionKey, method, path) {  return {    getAuthenticateFunction() {      return {        async authenticate(request, h) {          // your implementation        },      }    },    name: "your strategy name",    scheme: "your scheme name",  }}
A working example of injecting a custom authorization provider can be found in the projects integration tests under the folder custom-authentication.
Custom headers
You are able to use some custom headers in your request to gain more control over the requestContext object.

























HeaderEvent keyExamplecognito-identity-idevent.requestContext.identity.cognitoIdentityIdcognito-authentication-providerevent.requestContext.identity.cognitoAuthenticationProvidersls-offline-authorizer-overrideevent.requestContext.authorizer{ "iam": {"cognitoUser": { "amr": ["unauthenticated"], "identityId": "abc123" }}}
By doing this you are now able to change those values using a custom header. This can help you with easier authentication or retrieving the userId from a cognitoAuthenticationProvider value.
Environment variables
You are able to use environment variables to customize identity params in event context.









































Environment VariableEvent keySLS_COGNITO_IDENTITY_POOL_IDevent.requestContext.identity.cognitoIdentityPoolIdSLS_ACCOUNT_IDevent.requestContext.identity.accountIdSLS_COGNITO_IDENTITY_IDevent.requestContext.identity.cognitoIdentityIdSLS_CALLERevent.requestContext.identity.callerSLS_API_KEYevent.requestContext.identity.apiKeySLS_API_KEY_IDevent.requestContext.identity.apiKeyIdSLS_COGNITO_AUTHENTICATION_TYPEevent.requestContext.identity.cognitoAuthenticationTypeSLS_COGNITO_AUTHENTICATION_PROVIDERevent.requestContext.identity.cognitoAuthenticationProvider
You can use serverless-dotenv-plugin to load environment variables from your .env file.
AWS API Gateway Features
Velocity Templates
Serverless doc
~ AWS doc
You can supply response and request templates for each function. This is optional. To do so you will have to place function specific template files in the same directory as your function file and add the .req.vm extension to the template filename.
For example,
if your function is in code-file: helloworld.js,
your response template should be in file: helloworld.res.vm and your request template in file helloworld.req.vm.
Velocity nuances
Consider this requestTemplate for a POST endpoint:
"application/json": {  "payload": "$input.json('$')",  "id_json": "$input.json('$.id')",  "id_path": "$input.path('$').id"}
Now let's make a request with this body: { "id": 1 }
AWS parses the event as such:
{  "payload": {    "id": 1  },  "id_json": 1,  "id_path": "1" // Notice the string}
Whereas Offline parses:
{  "payload": {    "id": 1  },  "id_json": 1,  "id_path": 1 // Notice the number}
Accessing an attribute after using $input.path will return a string on AWS (expect strings like "1" or "true") but not with Offline (1 or true).
You may find other differences.
CORS
Serverless doc
For HTTP APIs, the CORS configuration will work out of the box. Any CLI arguments
passed in will be ignored.
For REST APIs, if the endpoint config has CORS set to true, the plugin will use the CLI CORS options for the associated route.
Otherwise, no CORS headers will be added.
Catch-all Path Variables
AWS doc
Set greedy paths like /store/{proxy+} that will intercept requests made to /store/list-products, /store/add-product, etc...
ANY method
AWS doc
Works out of the box.
Lambda and Lambda Proxy Integrations
Serverless doc
~ AWS doc
Works out of the box. See examples in the manual_test directory.
HTTP Proxy
Serverless doc
~
AWS doc - AWS::ApiGateway::Method
~
AWS doc - AWS::ApiGateway::Resource
Example of enabling proxy:
custom:  serverless-offline:    resourceRoutes: true
or
    YourCloudFormationMethodId:      Properties:        ......        Integration:          Type: HTTP_PROXY          Uri: 'https://s3-${self:custom.region}.amazonaws.com/${self:custom.yourBucketName}/{proxy}'          ......      Type: AWS::ApiGateway::Method
custom:  serverless-offline:    resourceRoutes:      YourCloudFormationMethodId:        Uri: "http://localhost:3001/assets/{proxy}"
Response parameters
AWS doc
You can set your response's headers using ResponseParameters.
May not work properly. Please PR. (Difficulty: hard?)
Example response velocity template:
"responseParameters": {  "method.response.header.X-Powered-By": "Serverless", // a string  "method.response.header.Warning": "integration.response.body", // the whole response  "method.response.header.Location": "integration.response.body.some.key" // a pseudo JSON-path},
WebSocket
Usage in order to send messages back to clients:
POST http://localhost:3001/@connections/{connectionId}
Or,
import aws from 'aws-sdk'const apiGatewayManagementApi = new aws.ApiGatewayManagementApi({  apiVersion: '2018-11-29',  endpoint: 'http://localhost:3001',});apiGatewayManagementApi.postToConnection({  ConnectionId: ...,  Data: ...,});
Where the event is received in the lambda handler function.
There's support for websocketsApiRouteSelectionExpression in it's basic form: $request.body.x.y.z, where the default value is $request.body.action.
Debug process
Serverless offline plugin will respond to the overall framework settings and output additional information to the console in debug mode. In order to do this you will have to set the SLS_DEBUG environmental variable. You can run the following in the command line to switch to debug mode execution.

Unix: export SLS_DEBUG=*


Windows: SET SLS_DEBUG=*

Interactive debugging is also possible for your project if you have installed the node-inspector module and chrome browser. You can then run the following command line inside your project's root.
Initial installation:
npm install -g node-inspector
For each debug run:
node-debug sls offline
The system will start in wait status. This will also automatically start the chrome browser and wait for you to set breakpoints for inspection. Set the breakpoints as needed and, then, click the play button for the debugging to continue.
Depending on the breakpoint, you may need to call the URL path for your function in separate browser window for your serverless function to be run and made available for debugging.
Interactive Debugging with Visual Studio Code (VSC)
With newer versions of node (6.3+) the node inspector is already part of your node environment and you can take advantage of debugging inside your IDE with source-map support. Here is the example configuration to debug interactively with VSC. It has two steps.
Step 1 : Adding a launch configuration in IDE
Add a new launch configuration to VSC like this:
{  "cwd": "${workspaceFolder}",  "name": "Debug Serverless Offline",  "request": "launch",  "runtimeArgs": ["run", "debug"],  "runtimeExecutable": "npm",  "sourceMaps": true,  "type": "node"}
Step2 : Adding a debug script
You will also need to add a debug script reference in your package.json file
Add this to the scripts section:

Unix/Mac: "debug" : "export SLS_DEBUG=* && node --inspect /usr/local/bin/serverless offline"


Windows: "debug": "SET SLS_DEBUG=* && node --inspect node_modules\ erverless\\bin\ erverless offline"

Example:
...."scripts": {  "debug" : "SET SLS_DEBUG=* && node --inspect node_modules\ erverless\\bin\ erverless offline"}
In VSC, you can, then, add breakpoints to your code. To start a debug sessions you can either start your script in package.json by clicking the hovering debug intellisense icon or by going to your debug pane and selecting the Debug Serverless Offline configuration.
Resource permissions and AWS profile
Lambda functions assume an IAM role during execution: the framework creates this role and set all the permission provided in the iamRoleStatements section of serverless.yml.
However, serverless offline makes use of your local AWS profile credentials to run the lambda functions and that might result in a different set of permissions. By default, the aws-sdk would load credentials for you default AWS profile specified in your configuration file.
You can change this profile directly in the code or by setting proper environment variables. Setting the AWS_PROFILE environment variable before calling serverless offline to a different profile would effectively change the credentials, e.g.
AWS_PROFILE=<profile> serverless offline
Simulation quality
This plugin simulates API Gateway for many practical purposes, good enough for development - but is not a perfect simulator.
Specifically, Lambda currently runs on Node.js v12.x, v14.x and v16.x (AWS Docs), whereas Offline runs on your own runtime where no memory limits are enforced.
Usage with other plugins
When combining this plugin with other plugins there are a few things that you need to keep in mind.
You should run serverless offline start instead of serverless offline. The start command fires the offline:start:init and offline:start:end lifecycle hooks which can be used by other plugins to process your code, add resources, perform cleanups, etc.
The order in which plugins are added to serverless.yml is relevant.
Plugins are executed in order, so plugins that process your code or add resources should be added first so they are ready when this plugin starts.
For example:
plugins:  - serverless-middleware # modifies some of your handler based on configuration  - serverless-webpack # package your javascript handlers using webpack  - serverless-dynamodb # adds a local dynamo db  - serverless-offline # runs last so your code has been pre-processed and dynamo is ready
That works because all those plugins listen to the offline:start:init to do their processing.
Similarly they listen to offline:start:end to perform cleanup (stop dynamo db, remove temporary files, etc).
Credits and inspiration
This plugin was initially a fork of Nopik's Serverless-serve.
License
MIT
Contributing
Yes, thank you!
This plugin is community-driven, most of its features are from different authors.
Please update the docs and tests and add your name to the package.json file.
We try to follow Airbnb's JavaScript Style Guide.
Contributors



















dnalborczykdheraultcomputerpuncfrozenbonitoleonardoalifraco



















medikooapancuttchardosdaniel-cottonebryantbiggs



















pgrzesikmikestaubBilal-SqswinsonjuanjoDiaz



















zoellnerfrsechetjohncmckimdl748ThisIsNoZaku



















darthtrevinoNicolasSeilermiltadormoroinegertjvr



















bytekastjormaecheathomaschaafDorianMazurdortega3000



















tom-marshrwynnrobbtraisterjoubertredratjack-seek



















perkyguyansralianthueniversejames-relyeasulaysumaria



















ondrowanfranciscocpgAyushG3112AlexHaytonAndorbal



















andreipopoviciawwong1emmoistnercoyoteecdOrKoN



















trevor-leachbebbipaulhbarkernjriordanadieuadieu



















encounterleemhensonc24wBob-ThomasALOHACREPES345



















djcrabhatmarccampbellmatt-peckpurefanmzmiric5



















pmuenspierreisraySavignoneRawneselcukcihan



















shalvahfootballencartafrancisupatrickheeneyre1ro



















andidevarnasclschneid10-ccablythe



















pettyalexdomdomeggapalumborion18anishkny



















cameroncoopercmuto09dschepdimadk24dwbelliston



















efrain17eabadjievtqfipegarunskijeroenvollenbrock



















joewestcottLoganArnettperrin4869njyjnDocLM



















Trottrfrancouh-zzRaph22randytarampi



















PsychicCatpetetntthepontRichiCoder1rishi8094



















rloomansroberttaylor426wwsnogribnoysupsergiodurand



















sethettershineli-not-used-anymorestesiejeromemaciaskdybicz



















kenleytomlinkevinhankenskerueterkohaniankyusungpark



















lalifraco-devsparkDynamicSTOPbrazilianbytesMarcel-Gneverendingqs



















msjonkerTakenokelchmmjmacmohokh67



















AlexHladinojongeriusparasgerafuripon308hsz



















jeffhall4jgilbert01polaris340khanguyen88kobanyan



















leruitga-sslivingminelteachermartinmicundanick-w-nick



















nori3tsuppasmanikryanzyyadikaritom-stclair



















tvealconstbstevemaotrsrmittus



















Ankcornexpoe-codebuildtiagogoncalves89tuanmhGregoirevda



















vivganesgcphostYaroslavApatievzacacollierakinboboye



















allenhartwigctbairddemetriusnunesdependabot[bot]drace-rgare



















ericctsfBorjaMacedoBrandonEguerrerocarloschrismcleod



















icarus-sullivancnusschristophgysincdubzdanmactough



















GeneralistDevdesignfrontierdaniel0707dnicolsondbunker



















dobryninDavideSegullodomaslasauskasenolanEduardMcfly



















thejuanadam-nielsenagainerAlbertXingZhangaldenquimby



















alebianco-doxeekoterpillaraliclarkandersemtriptec



















m0pperscspotcodeAndrewCEmilmapsialiatsis



















akailaac360austin-payneBenjaminBergerMiansu



















gdinnMEGApixel23idmontieihendriksjacintoArias



















JacekDuszenkojgriggjanicduplessisjsnajdrhoryd



















jasonfungsingjaydp17jeremygibersonjosephwarrickjlsjonas



















jonathonadamsjoostfarlaTheTeaCateeroniemiminibikini



















em0neywebdevericfernyettheplantfernandomoraespanva



















Edweisfrodeaagbroquesganeygeoffmanningcleartrace



















grakic-glopalguillaumemebiboubalassybayoudhi













enapupeaardvarkk\n\nPluginsServerless OfflineServerless Offline
⚠️
We are looking for maintainers! This package is entirely community-driven. Please send an email to dherault to start helping now.
⚠️

  
    
  
  
    
  
  
    
  
  
  
    
  
  
    
  
  
  
    
  
  
    
  

This Serverless plugin emulates AWS λ and API Gateway on your local machine to speed up your development cycles.
To do so, it starts an HTTP server that handles the request's lifecycle like APIG does and invokes your handlers.
Features

Node.js, Python, Ruby, Go, Java (incl. Kotlin, Groovy, Scala) λ runtimes.
Velocity templates support.
Lazy loading of your handler files.
And more: integrations, authorizers, proxies, timeouts, responseParameters, HTTPS, CORS, etc...

This plugin is updated by its users, I just do maintenance and ensure that PRs are relevant to the community. In other words, if you find a bug or want a new feature, please help us by becoming one of the contributors :v: ! See the contributing section.
Documentation

Installation
Usage and command line options
Run modes
Invoke Lambda
The process.env.IS_OFFLINE variable
Docker and Layers
Authorizers

Token authorizers
Custom authorizers
Remote authorizers
JWT authorizers
Serverless plugin authorizers


Custom headers
Environment variables
AWS API Gateway Features

Velocity Templates

Velocity nuances


CORS
Catch-all Path Variables
ANY method
Lambda and Lambda Proxy Integrations
HTTP Proxy
Response parameters


WebSocket
Debug process
Resource permissions and AWS profile
Simulation quality
Usage with other plugins
Credits and inspiration
License
Contributing
Contributors

Installation
First, add Serverless Offline to your project:
npm install serverless-offline --save-dev
Then inside your project's serverless.yml file add following entry to the plugins section: serverless-offline. If there is no plugin section you will need to add it to the file.
Note that the "plugin" section for serverless-offline must be at root level on serverless.yml.
It should look something like this:
plugins:  - serverless-offline
You can check whether you have successfully installed the plugin by running the serverless command line:
serverless --verbose
the console should display Offline as one of the plugins now available in your Serverless project.
Usage and command line options
In your project root run:
serverless offline or sls offline.
to list all the options for the plugin run:
sls offline --help
All CLI options are optional:
corsAllowHeaders
Used as default Access-Control-Allow-Headers header value for responses. Delimit multiple values with commas.
Default: 'accept,content-type,x-api-key'
corsAllowOrigin
Used as default Access-Control-Allow-Origin header value for responses. Delimit multiple values with commas.
Default: '*'
corsDisallowCredentials
When provided, the default Access-Control-Allow-Credentials header value will be passed as 'false'.
Default: true
corsExposedHeaders
Used as additional Access-Control-Exposed-Headers header value for responses. Delimit multiple values with commas.
Default: 'WWW-Authenticate,Server-Authorization'
disableCookieValidation
Used to disable cookie-validation on hapi.js-server.
dockerHost
The host name of Docker.
Default: localhost
dockerHostServicePath
Defines service path which is used by SLS running inside Docker container.
dockerNetwork
The network that the Docker container will connect to.
dockerReadOnly
Marks if the docker code layer should be read only.
Default: true
enforceSecureCookies
Enforce secure cookies
host
-o Host name to listen on.
Default: localhost
httpPort
Http port to listen on.
Default: 3000
httpsProtocol
-H To enable HTTPS, specify directory (relative to your cwd, typically your project dir) for both cert.pem and key.pem files.
ignoreJWTSignature
When using HttpApi with a JWT authorizer, don't check the signature of the JWT token.
lambdaPort
Lambda http port to listen on.
Default: 3002
layersDir
The directory layers should be stored in.
Default: ${codeDir}/.serverless-offline/layers'
localEnvironment
Copy local environment variables.
Default: false
noAuth
Turns off all authorizers.
noPrependStageInUrl
Don't prepend http routes with the stage.
noTimeout
-t Disables the timeout feature.
prefix
-p Adds a prefix to every path, to send your requests to http://localhost:3000/[prefix]/[your_path] instead.
Default: ''
reloadHandler
Reloads handler with each request.
resourceRoutes
Turns on loading of your HTTP proxy settings from serverless.yml.
terminateIdleLambdaTime
Number of seconds until an idle function is eligible for termination.
useDocker
Run handlers in a docker container.
useInProcess
Run handlers in the same process as 'serverless-offline'.
webSocketHardTimeout
Set WebSocket hard timeout in seconds to reproduce AWS limits (https://docs.aws.amazon.com/apigateway/latest/developerguide/limits.html#apigateway-execution-service-websocket-limits-table).
Default: 7200 (2 hours)
webSocketIdleTimeout
Set WebSocket idle timeout in seconds to reproduce AWS limits (https://docs.aws.amazon.com/apigateway/latest/developerguide/limits.html#apigateway-execution-service-websocket-limits-table).
Default: 600 (10 minutes)
websocketPort
WebSocket port to listen on.
Default: 3001
Any of the CLI options can be added to your serverless.yml. For example:
custom:  serverless-offline:    httpsProtocol: 'dev-certs'    httpPort: 4000      foo: 'bar'
Options passed on the command line override YAML options.
By default you can send your requests to http://localhost:3000/. Please note that:

You'll need to restart the plugin if you modify your serverless.yml or any of the default velocity template files.
When no Content-Type header is set on a request, API Gateway defaults to application/json, and so does the plugin.
But if you send an application/x-www-form-urlencoded or a multipart/form-data body with an application/json (or no) Content-Type, API Gateway won't parse your data (you'll get the ugly raw as input), whereas the plugin will answer 400 (malformed JSON).
Please consider explicitly setting your requests' Content-Type and using separate templates.

Run modes
node.js
Lambda handlers with serverless-offline for the node.js runtime can run in different execution modes and have some differences with a variety of pros and cons. they are currently mutually exclusive and it's not possible to use a combination, e.g. use in-process for one Lambda, and worker-threads for another. It is planned to combine the flags into one single flag in the future and also add support for combining run modes.
worker-threads (default)

handlers run in their own context
memory is not being shared between handlers, memory consumption is therefore higher
memory is being released when handlers reload or after usage
environment (process.env) is not being shared across handlers
global state is not being shared across handlers
easy debugging

NOTE:

native modules need to be a Node-API addon or be declared as context-aware using NODE_MODULE_INIT(): https://nodejs.org/docs/latest/api/addons.html#worker-support

in-process

handlers run in the same context (instance) as serverless and serverless-offline
memory is being shared across lambda handlers as well as with serverless and serverless-offline
no reloading capabilities as it is [currently] not possible to implement for commonjs handlers (without memory leaks) and for esm handlers
environment (process.env) is being shared across handlers as well as with serverless and serverless-offline
global state is being shared across lambda handlers as well as with serverless and serverless-offline
easy debugging

docker

handlers run in a docker container
memory is not being shared between handlers, memory consumption is therefore higher
memory is being released when handlers reload or after usage
environment (process.env) is not being shared across handlers
global state is not being shared across handlers
debugging more complicated

Python, Ruby, Go, Java (incl. Kotlin, Groovy, Scala)
the Lambda handler process is running in a child process.
Invoke Lambda
To use Lambda.invoke you need to set the lambda endpoint to the serverless-offline endpoint:
import { env } from "node:process"import aws from "aws-sdk"const lambda = new aws.Lambda({  apiVersion: "2015-03-31",  // endpoint needs to be set only if it deviates from the default  endpoint: env.IS_OFFLINE    ? "http://localhost:3002"    : "https://lambda.us-east-1.amazonaws.com",})
All your lambdas can then be invoked in a handler using
import { Buffer } from "node:buffer"import aws from "aws-sdk"const { stringify } = JSONconst lambda = new aws.Lambda({  apiVersion: "2015-03-31",  endpoint: "http://localhost:3002",})export async function handler() {  const clientContextData = stringify({    foo: "foo",  })  const payload = stringify({    data: "foo",  })  const params = {    ClientContext: Buffer.from(clientContextData).toString("base64"),    // FunctionName is composed of: service name - stage - function name, e.g.    FunctionName: "myServiceName-dev-invokedHandler",    InvocationType: "RequestResponse",    Payload: payload,  }  const response = await lambda.invoke(params).promise()  return {    body: stringify(response),    statusCode: 200,  }}
You can also invoke using the aws cli by specifying --endpoint-url
aws lambda invoke /dev/null \  --endpoint-url http://localhost:3002 \  --function-name myServiceName-dev-invokedHandler
List of available function names and their corresponding serverless.yml function keys
are listed after the server starts. This is important if you use a custom naming
scheme for your functions as serverless-offline will use your custom name.
The left side is the function's key in your serverless.yml
(invokedHandler in the example below) and the right side is the function name
that is used to call the function externally such as aws-sdk
(myServiceName-dev-invokedHandler in the example below):
serverless offline...offline: Starting Offline: local/us-east-1.offline: Offline [http for lambda] listening on http://localhost:3002offline: Function names exposed for local invocation by aws-sdk:           * invokedHandler: myServiceName-dev-invokedHandler
To list the available manual invocation paths exposed for targeting
by aws-sdk and aws-cli, use SLS_DEBUG=* with serverless offline. After the invoke server starts up, full list of endpoints will be displayed:
SLS_DEBUG=* serverless offline...offline: Starting Offline: local/us-east-1....offline: Offline [http for lambda] listening on http://localhost:3002offline: Function names exposed for local invocation by aws-sdk:           * invokedHandler: myServiceName-dev-invokedHandler[offline] Lambda Invocation Routes (for AWS SDK or AWS CLI):           * POST http://localhost:3002/2015-03-31/functions/myServiceName-dev-invokedHandler/invocations[offline] Lambda Async Invocation Routes (for AWS SDK or AWS CLI):           * POST http://localhost:3002/2014-11-13/functions/myServiceName-dev-invokedHandler/invoke-async/
You can manually target these endpoints with a REST client to debug your lambda
function if you want to. Your POST JSON body will be the Payload passed to your function if you were
to calling it via aws-sdk.
The process.env.IS_OFFLINE variable
Will be "true" in your handlers when using serverless-offline.
Docker and Layers
To use layers with serverless-offline, you need to have the useDocker option set to true. This can either be by using the --useDocker command, or in your serverless.yml like this:
custom:  serverless-offline:    useDocker: true
This will allow the docker container to look up any information about layers, download and use them. For this to work, you must be using:

AWS as a provider, it won't work with other provider types.
Layers that are compatible with your runtime.
ARNs for layers. Local layers aren't supported as yet.
A local AWS account set-up that can query and download layers.

If you're using least-privilege principals for your AWS roles, this policy should get you by:
{  "Statement": [    {      "Action": "lambda:GetLayerVersion",      "Effect": "Allow",      "Resource": "arn:aws:lambda:*:*:layer:*:*"    }  ],  "Version": "2012-10-17"}
Once you run a function that boots up the Docker container, it'll look through the layers for that function, download them in order to your layers folder, and save a hash of your layers so it can be re-used in future. You'll only need to re-download your layers if they change in the future. If you want your layers to re-download, simply remove your layers folder.
You should then be able to invoke functions as normal, and they're executed against the layers in your docker container.
Additional Options
There are 5 additional options available for Docker and Layer usage.

dockerHost
dockerHostServicePath
dockerNetwork
dockerReadOnly
layersDir

dockerHost
When running Docker Lambda inside another Docker container, you may need to configure the host name for the host machine to resolve networking issues between Docker Lambda and the host. Typically in such cases you would set this to host.docker.internal.
dockerHostServicePath
When running Docker Lambda inside another Docker container, you may need to override the code path that gets mounted to the Docker Lambda container relative to the host machine. Typically in such cases you would set this to ${PWD}.
dockerNetwork
When running Docker Lambda inside another Docker container, you may need to override network that Docker Lambda connects to in order to communicate with other containers.
dockerReadOnly
For certain programming languages and frameworks, it's desirable to be able to write to the filesystem for things like testing with local SQLite databases, or other testing-only modifications. For this, you can set dockerReadOnly: false, and this will allow local filesystem modifications. This does not strictly mimic AWS Lambda, as Lambda has a Read-Only filesystem, so this should be used as a last resort.
layersDir
By default layers are downloaded on a per-project basis, however, if you want to share them across projects, you can download them to a common place. For example, layersDir: /tmp/layers would allow them to be shared across projects. Make sure when using this setting that the directory you are writing layers to can be shared by docker.
Authorizers
Token authorizers
As defined in the Serverless Documentation you can use API Keys as a simple authentication method.
Serverless-offline will emulate the behaviour of APIG and create a random token that's printed on the screen. With this token you can access your private methods adding x-api-key: generatedToken to your request header. All api keys will share the same token.
Custom authorizers
Only custom authorizers are supported. Custom authorizers are executed before a Lambda function is executed and return an Error or a Policy document.
The Custom authorizer is passed an event object as below:
{  "authorizationToken": "<Incoming bearer token>",  "methodArn": "arn:aws:execute-api:<Region id>:<Account id>:<API id>/<Stage>/<Method>/<Resource path>",  "type": "TOKEN"}
The methodArn does not include the Account id or API id.
The plugin only supports retrieving Tokens from headers. You can configure the header as below:
"authorizer": {  "authorizerResultTtlInSeconds": "0",  "identitySource": "method.request.header.Authorization", // or method.request.header.SomeOtherHeader  "type": "TOKEN"}
Remote authorizers
You are able to mock the response from remote authorizers by setting the environmental variable AUTHORIZER before running sls offline start
Example:

Unix: export AUTHORIZER='{"principalId": "123"}'


Windows: SET AUTHORIZER='{"principalId": "123"}'

JWT authorizers
For HTTP APIs, JWT authorizers
defined in the serverless.yml can be used to validate the token and scopes in the token. However at this time,
the signature of the JWT is not validated with the defined issuer. Since this is a security risk, this feature is
only enabled with the --ignoreJWTSignature flag. Make sure to only set this flag for local development work.
Serverless plugin authorizers
If your authentication needs are custom and not satisfied by the existing capabilities of the Serverless offline project, you can inject your own authentication strategy. To inject a custom strategy for Lambda invocation, you define a custom variable under offline called customAuthenticationProvider in the serverless.yml file. The value of the custom variable will be used to require(your customAuthenticationProvider value) where the location is expected to return a function with the following signature.
offline:  customAuthenticationProvider: ./path/to/custom-authentication-provider
// ./path/to/customer-authentication-provider.jsmodule.exports = function (endpoint, functionKey, method, path) {  return {    getAuthenticateFunction() {      return {        async authenticate(request, h) {          // your implementation        },      }    },    name: "your strategy name",    scheme: "your scheme name",  }}
A working example of injecting a custom authorization provider can be found in the projects integration tests under the folder custom-authentication.
Custom headers
You are able to use some custom headers in your request to gain more control over the requestContext object.

























HeaderEvent keyExamplecognito-identity-idevent.requestContext.identity.cognitoIdentityIdcognito-authentication-providerevent.requestContext.identity.cognitoAuthenticationProvidersls-offline-authorizer-overrideevent.requestContext.authorizer{ "iam": {"cognitoUser": { "amr": ["unauthenticated"], "identityId": "abc123" }}}
By doing this you are now able to change those values using a custom header. This can help you with easier authentication or retrieving the userId from a cognitoAuthenticationProvider value.
Environment variables
You are able to use environment variables to customize identity params in event context.









































Environment VariableEvent keySLS_COGNITO_IDENTITY_POOL_IDevent.requestContext.identity.cognitoIdentityPoolIdSLS_ACCOUNT_IDevent.requestContext.identity.accountIdSLS_COGNITO_IDENTITY_IDevent.requestContext.identity.cognitoIdentityIdSLS_CALLERevent.requestContext.identity.callerSLS_API_KEYevent.requestContext.identity.apiKeySLS_API_KEY_IDevent.requestContext.identity.apiKeyIdSLS_COGNITO_AUTHENTICATION_TYPEevent.requestContext.identity.cognitoAuthenticationTypeSLS_COGNITO_AUTHENTICATION_PROVIDERevent.requestContext.identity.cognitoAuthenticationProvider
You can use serverless-dotenv-plugin to load environment variables from your .env file.
AWS API Gateway Features
Velocity Templates
Serverless doc
~ AWS doc
You can supply response and request templates for each function. This is optional. To do so you will have to place function specific template files in the same directory as your function file and add the .req.vm extension to the template filename.
For example,
if your function is in code-file: helloworld.js,
your response template should be in file: helloworld.res.vm and your request template in file helloworld.req.vm.
Velocity nuances
Consider this requestTemplate for a POST endpoint:
"application/json": {  "payload": "$input.json('$')",  "id_json": "$input.json('$.id')",  "id_path": "$input.path('$').id"}
Now let's make a request with this body: { "id": 1 }
AWS parses the event as such:
{  "payload": {    "id": 1  },  "id_json": 1,  "id_path": "1" // Notice the string}
Whereas Offline parses:
{  "payload": {    "id": 1  },  "id_json": 1,  "id_path": 1 // Notice the number}
Accessing an attribute after using $input.path will return a string on AWS (expect strings like "1" or "true") but not with Offline (1 or true).
You may find other differences.
CORS
Serverless doc
For HTTP APIs, the CORS configuration will work out of the box. Any CLI arguments
passed in will be ignored.
For REST APIs, if the endpoint config has CORS set to true, the plugin will use the CLI CORS options for the associated route.
Otherwise, no CORS headers will be added.
Catch-all Path Variables
AWS doc
Set greedy paths like /store/{proxy+} that will intercept requests made to /store/list-products, /store/add-product, etc...
ANY method
AWS doc
Works out of the box.
Lambda and Lambda Proxy Integrations
Serverless doc
~ AWS doc
Works out of the box. See examples in the manual_test directory.
HTTP Proxy
Serverless doc
~
AWS doc - AWS::ApiGateway::Method
~
AWS doc - AWS::ApiGateway::Resource
Example of enabling proxy:
custom:  serverless-offline:    resourceRoutes: true
or
    YourCloudFormationMethodId:      Properties:        ......        Integration:          Type: HTTP_PROXY          Uri: 'https://s3-${self:custom.region}.amazonaws.com/${self:custom.yourBucketName}/{proxy}'          ......      Type: AWS::ApiGateway::Method
custom:  serverless-offline:    resourceRoutes:      YourCloudFormationMethodId:        Uri: "http://localhost:3001/assets/{proxy}"
Response parameters
AWS doc
You can set your response's headers using ResponseParameters.
May not work properly. Please PR. (Difficulty: hard?)
Example response velocity template:
"responseParameters": {  "method.response.header.X-Powered-By": "Serverless", // a string  "method.response.header.Warning": "integration.response.body", // the whole response  "method.response.header.Location": "integration.response.body.some.key" // a pseudo JSON-path},
WebSocket
Usage in order to send messages back to clients:
POST http://localhost:3001/@connections/{connectionId}
Or,
import aws from 'aws-sdk'const apiGatewayManagementApi = new aws.ApiGatewayManagementApi({  apiVersion: '2018-11-29',  endpoint: 'http://localhost:3001',});apiGatewayManagementApi.postToConnection({  ConnectionId: ...,  Data: ...,});
Where the event is received in the lambda handler function.
There's support for websocketsApiRouteSelectionExpression in it's basic form: $request.body.x.y.z, where the default value is $request.body.action.
Debug process
Serverless offline plugin will respond to the overall framework settings and output additional information to the console in debug mode. In order to do this you will have to set the SLS_DEBUG environmental variable. You can run the following in the command line to switch to debug mode execution.

Unix: export SLS_DEBUG=*


Windows: SET SLS_DEBUG=*

Interactive debugging is also possible for your project if you have installed the node-inspector module and chrome browser. You can then run the following command line inside your project's root.
Initial installation:
npm install -g node-inspector
For each debug run:
node-debug sls offline
The system will start in wait status. This will also automatically start the chrome browser and wait for you to set breakpoints for inspection. Set the breakpoints as needed and, then, click the play button for the debugging to continue.
Depending on the breakpoint, you may need to call the URL path for your function in separate browser window for your serverless function to be run and made available for debugging.
Interactive Debugging with Visual Studio Code (VSC)
With newer versions of node (6.3+) the node inspector is already part of your node environment and you can take advantage of debugging inside your IDE with source-map support. Here is the example configuration to debug interactively with VSC. It has two steps.
Step 1 : Adding a launch configuration in IDE
Add a new launch configuration to VSC like this:
{  "cwd": "${workspaceFolder}",  "name": "Debug Serverless Offline",  "request": "launch",  "runtimeArgs": ["run", "debug"],  "runtimeExecutable": "npm",  "sourceMaps": true,  "type": "node"}
Step2 : Adding a debug script
You will also need to add a debug script reference in your package.json file
Add this to the scripts section:

Unix/Mac: "debug" : "export SLS_DEBUG=* && node --inspect /usr/local/bin/serverless offline"


Windows: "debug": "SET SLS_DEBUG=* && node --inspect node_modules\ erverless\\bin\ erverless offline"

Example:
...."scripts": {  "debug" : "SET SLS_DEBUG=* && node --inspect node_modules\ erverless\\bin\ erverless offline"}
In VSC, you can, then, add breakpoints to your code. To start a debug sessions you can either start your script in package.json by clicking the hovering debug intellisense icon or by going to your debug pane and selecting the Debug Serverless Offline configuration.
Resource permissions and AWS profile
Lambda functions assume an IAM role during execution: the framework creates this role and set all the permission provided in the iamRoleStatements section of serverless.yml.
However, serverless offline makes use of your local AWS profile credentials to run the lambda functions and that might result in a different set of permissions. By default, the aws-sdk would load credentials for you default AWS profile specified in your configuration file.
You can change this profile directly in the code or by setting proper environment variables. Setting the AWS_PROFILE environment variable before calling serverless offline to a different profile would effectively change the credentials, e.g.
AWS_PROFILE=<profile> serverless offline
Simulation quality
This plugin simulates API Gateway for many practical purposes, good enough for development - but is not a perfect simulator.
Specifically, Lambda currently runs on Node.js v12.x, v14.x and v16.x (AWS Docs), whereas Offline runs on your own runtime where no memory limits are enforced.
Usage with other plugins
When combining this plugin with other plugins there are a few things that you need to keep in mind.
You should run serverless offline start instead of serverless offline. The start command fires the offline:start:init and offline:start:end lifecycle hooks which can be used by other plugins to process your code, add resources, perform cleanups, etc.
The order in which plugins are added to serverless.yml is relevant.
Plugins are executed in order, so plugins that process your code or add resources should be added first so they are ready when this plugin starts.
For example:
plugins:  - serverless-middleware # modifies some of your handler based on configuration  - serverless-webpack # package your javascript handlers using webpack  - serverless-dynamodb # adds a local dynamo db  - serverless-offline # runs last so your code has been pre-processed and dynamo is ready
That works because all those plugins listen to the offline:start:init to do their processing.
Similarly they listen to offline:start:end to perform cleanup (stop dynamo db, remove temporary files, etc).
Credits and inspiration
This plugin was initially a fork of Nopik's Serverless-serve.
License
MIT
Contributing
Yes, thank you!
This plugin is community-driven, most of its features are from different authors.
Please update the docs and tests and add your name to the package.json file.
We try to follow Airbnb's JavaScript Style Guide.
Contributors



















dnalborczykdheraultcomputerpuncfrozenbonitoleonardoalifraco



















medikooapancuttchardosdaniel-cottonebryantbiggs



















pgrzesikmikestaubBilal-SqswinsonjuanjoDiaz



















zoellnerfrsechetjohncmckimdl748ThisIsNoZaku



















darthtrevinoNicolasSeilermiltadormoroinegertjvr



















bytekastjormaecheathomaschaafDorianMazurdortega3000



















tom-marshrwynnrobbtraisterjoubertredratjack-seek



















perkyguyansralianthueniversejames-relyeasulaysumaria



















ondrowanfranciscocpgAyushG3112AlexHaytonAndorbal



















andreipopoviciawwong1emmoistnercoyoteecdOrKoN



















trevor-leachbebbipaulhbarkernjriordanadieuadieu



















encounterleemhensonc24wBob-ThomasALOHACREPES345



















djcrabhatmarccampbellmatt-peckpurefanmzmiric5



















pmuenspierreisraySavignoneRawneselcukcihan



















shalvahfootballencartafrancisupatrickheeneyre1ro



















andidevarnasclschneid10-ccablythe



















pettyalexdomdomeggapalumborion18anishkny



















cameroncoopercmuto09dschepdimadk24dwbelliston



















efrain17eabadjievtqfipegarunskijeroenvollenbrock



















joewestcottLoganArnettperrin4869njyjnDocLM



















Trottrfrancouh-zzRaph22randytarampi



















PsychicCatpetetntthepontRichiCoder1rishi8094



















rloomansroberttaylor426wwsnogribnoysupsergiodurand



















sethettershineli-not-used-anymorestesiejeromemaciaskdybicz



















kenleytomlinkevinhankenskerueterkohaniankyusungpark



















lalifraco-devsparkDynamicSTOPbrazilianbytesMarcel-Gneverendingqs



















msjonkerTakenokelchmmjmacmohokh67



















AlexHladinojongeriusparasgerafuripon308hsz



















jeffhall4jgilbert01polaris340khanguyen88kobanyan



















leruitga-sslivingminelteachermartinmicundanick-w-nick



















nori3tsuppasmanikryanzyyadikaritom-stclair



















tvealconstbstevemaotrsrmittus



















Ankcornexpoe-codebuildtiagogoncalves89tuanmhGregoirevda



















vivganesgcphostYaroslavApatievzacacollierakinboboye



















allenhartwigctbairddemetriusnunesdependabot[bot]drace-rgare



















ericctsfBorjaMacedoBrandonEguerrerocarloschrismcleod



















icarus-sullivancnusschristophgysincdubzdanmactough



















GeneralistDevdesignfrontierdaniel0707dnicolsondbunker



















dobryninDavideSegullodomaslasauskasenolanEduardMcfly



















thejuanadam-nielsenagainerAlbertXingZhangaldenquimby



















alebianco-doxeekoterpillaraliclarkandersemtriptec



















m0pperscspotcodeAndrewCEmilmapsialiatsis



















akailaac360austin-payneBenjaminBergerMiansu



















gdinnMEGApixel23idmontieihendriksjacintoArias



















JacekDuszenkojgriggjanicduplessisjsnajdrhoryd



















jasonfungsingjaydp17jeremygibersonjosephwarrickjlsjonas



















jonathonadamsjoostfarlaTheTeaCateeroniemiminibikini



















em0neywebdevericfernyettheplantfernandomoraespanva



















Edweisfrodeaagbroquesganeygeoffmanningcleartrace



















grakic-glopalguillaumemebiboubalassybayoudhi













enapupeaardvarkk\n\n\n\nServerless Prune Plugin
Following deployment, the Serverless Framework does not purge previous versions of functions from AWS, so the number of deployed versions can grow out of hand rather quickly. This plugin allows pruning of all but the most recent version(s) of managed functions from AWS. This plugin is compatible with Serverless 1.x and higher.


Installation
Install with npm:
npm install --save-dev serverless-prune-plugin
And then add the plugin to your serverless.yml file:
plugins:  - serverless-prune-plugin
Alternatively, install with the Serverless plugin command (Serverless Framework 1.22 or higher):
sls plugin install -n serverless-prune-plugin
Usage
In the project root, run:
sls prune -n <number of version to keep>
This will delete all but the n-most recent versions of each function deployed. Versions referenced by an alias are automatically preserved.
Single Function
A single function can be targeted for cleanup:
sls prune -n <number of version to keep> -f helloWorld
Region/Stage
The previous usage examples prune the default stage in the default region. Use --stage and --region to specify:
sls prune -n <number of version to keep> --stage production --region eu-central-1
Automatic Pruning
This plugin can also be configured to run automatically, following a deployment. Configuration of automatic pruning is within the custom property of serverless.yml. For example:
custom:  prune:    automatic: true    number: 3
To run automatically, the automatic property of prune must be set to true and the number of versions to keep must be specified.
It is possible to set number to 0. In this case, the plugin will delete all the function versions (except $LATEST); this is useful when disabling function versioning for an already-deployed stack.
Layers
This plugin can also prune Lambda Layers in the same manner that it prunes functions. You can specify a Lambda Layer, or add the flag, includeLayers:
custom:  prune:    automatic: true    includeLayers: true    number: 3
Dry Run
A dry-run will preview the deletion candidates, without actually performing the pruning operations:
sls prune -n <number of version to keep> --dryRun
Additional Help
See:
sls prune --help
Permissions Required
To run this plugin, the user will need to be allowed the following permissions in AWS:

lambda:listAliases
lambda:listVersionsByFunction
lambda:deleteFunction
lambda:listLayerVersions
lambda:deleteLayerVersion

Common Questions
How do I set up different pruning configurations per region/stage?
Several suggestions are available in this thread.
Can I just disable versioning entirely?
Absolutely. While Serverless Framework has it enabled by default, versioning can be disabled.
License
Copyright (c) 2017 Clay Gregory. See the included LICENSE for rights and limitations under the terms of the MIT license.\n\nPluginsServerless Prune PluginServerless Prune Plugin
Following deployment, the Serverless Framework does not purge previous versions of functions from AWS, so the number of deployed versions can grow out of hand rather quickly. This plugin allows pruning of all but the most recent version(s) of managed functions from AWS. This plugin is compatible with Serverless 1.x and higher.


Installation
Install with npm:
npm install --save-dev serverless-prune-plugin
And then add the plugin to your serverless.yml file:
plugins:  - serverless-prune-plugin
Alternatively, install with the Serverless plugin command (Serverless Framework 1.22 or higher):
sls plugin install -n serverless-prune-plugin
Usage
In the project root, run:
sls prune -n <number of version to keep>
This will delete all but the n-most recent versions of each function deployed. Versions referenced by an alias are automatically preserved.
Single Function
A single function can be targeted for cleanup:
sls prune -n <number of version to keep> -f helloWorld
Region/Stage
The previous usage examples prune the default stage in the default region. Use --stage and --region to specify:
sls prune -n <number of version to keep> --stage production --region eu-central-1
Automatic Pruning
This plugin can also be configured to run automatically, following a deployment. Configuration of automatic pruning is within the custom property of serverless.yml. For example:
custom:  prune:    automatic: true    number: 3
To run automatically, the automatic property of prune must be set to true and the number of versions to keep must be specified.
It is possible to set number to 0. In this case, the plugin will delete all the function versions (except $LATEST); this is useful when disabling function versioning for an already-deployed stack.
Layers
This plugin can also prune Lambda Layers in the same manner that it prunes functions. You can specify a Lambda Layer, or add the flag, includeLayers:
custom:  prune:    automatic: true    includeLayers: true    number: 3
Dry Run
A dry-run will preview the deletion candidates, without actually performing the pruning operations:
sls prune -n <number of version to keep> --dryRun
Additional Help
See:
sls prune --help
Permissions Required
To run this plugin, the user will need to be allowed the following permissions in AWS:

lambda:listAliases
lambda:listVersionsByFunction
lambda:deleteFunction
lambda:listLayerVersions
lambda:deleteLayerVersion

Common Questions
How do I set up different pruning configurations per region/stage?
Several suggestions are available in this thread.
Can I just disable versioning entirely?
Absolutely. While Serverless Framework has it enabled by default, versioning can be disabled.
License
Copyright (c) 2017 Clay Gregory. See the included LICENSE for rights and limitations under the terms of the MIT license.\n\n\n\nServerless Webpack






A Serverless Framework plugin to build your lambda functions with Webpack.
This plugin is for you if you want to use the latest Javascript version with Babel;
use custom resource loaders, optimize your packaged functions individually
and much more!
Highlights

Configuration possibilities range from zero-config to fully customizable
Support of serverless package, serverless deploy and serverless deploy function
Support of serverless invoke local and serverless invoke local --watch
Support of serverless run and serverless run --watch
Integrates with serverless-offline to simulate local API Gateway endpoints
When enabled in your service configuration, functions are packaged and compiled
individually, resulting in smaller Lambda packages that contain only the code and
dependencies needed to run the function. This allows the plugin to fully utilize
WebPack's Tree-Shaking optimization.
Webpack version 3, 4 and 5 support
Support NPM and Yarn for packaging
Support asynchronous webpack configuration

For the complete release notes see the end of this document.
Install
$ npm install serverless-webpack --save-dev
or
$ yarn add serverless-webpack --dev
Add the plugin to your serverless.yml file:
plugins:  - serverless-webpack
Configure
The configuration of the plugin is done by defining a custom: webpack object in your serverless.yml with your specific configuration. All settings are optional and will be set to reasonable defaults if missing.
See the sections below for detailed descriptions of the settings. The defaults are:
custom:  webpack:    webpackConfig: 'webpack.config.js' # Name of webpack configuration file    includeModules: false # Node modules configuration for packaging    packager: 'npm' # Packager that will be used to package your external modules    excludeFiles: src/**/*.test.js # Provide a glob for files to ignore
Webpack configuration file
By default the plugin will look for a webpack.config.js in the service directory. Alternatively, you can specify a different file or configuration in serverless.yml.
custom:  webpack:    webpackConfig: ./folder/my-webpack.config.js
A base Webpack configuration might look like this:
// webpack.config.jsmodule.exports = {  entry: './handler.js',  target: 'node',  module: {    loaders: [ ... ]  }};
Alternatively the Webpack configuration can export an asynchronous object (e.g. a promise or async function) which will be awaited by the plugin and resolves to the final configuration object. This is useful if the confguration depends on asynchronous functions, for example, defining the AccountId of the current aws user inside AWS lambda@edge which does not support defining normal process environment variables.
A basic Webpack promise configuration might look like this:
// Version if the local Node.js version supports async/await// webpack.config.jsconst webpack = require('webpack')const slsw = require('serverless-webpack');module.exports = (async () => {  const accountId = await slsw.lib.serverless.providers.aws.getAccountId();  return {    entry: './handler.js',    target: 'node',    plugins: [      new webpack.DefinePlugin({        AWS_ACCOUNT_ID: `${accountId}`,      }),    ],    module: {      loaders: [ ... ]    }  };})();
// Version with promises// webpack.config.jsconst webpack = require('webpack')const slsw = require('serverless-webpack');const BbPromise = require('bluebird');module.exports = BbPromise.try(() => {  return slsw.lib.serverless.providers.aws.getAccountId()  .then(accountId => ({    entry: './handler.js',    target: 'node',    plugins: [      new webpack.DefinePlugin({        AWS_ACCOUNT_ID: `${accountId}`,      }),    ],    module: {      loaders: [ ... ]    }  }));});
serverless-webpack lib export helper
serverless-webpack exposes a lib object, that can be used in your webpack.config.js
to make the configuration easier and to build fully dynamic configurations.
This is the preferred way to configure webpack - the plugin will take care of
as much of the configuration (and subsequent changes in your services) as it can.
Automatic entry resolution
You can let the plugin determine the correct handler entry points at build time.
Then you do not have to care anymore when you add or remove functions from your service:
// webpack.config.jsconst slsw = require('serverless-webpack');module.exports = {  ...  entry: slsw.lib.entries,  ...};
Custom entries that are not part of the SLS build process can be added too:
// webpack.config.jsconst _ = require('lodash');const slsw = require('serverless-webpack');module.exports = {  ...  entry: _.assign({    myCustomEntry1: './custom/path/something.js'  }, slsw.lib.entries),  ...};
Optional entry overrides
serverless-webpack generates Webpack entries from the handler value by default.
If your handler is different from the webpack entry, e.g. provided by a layer,
you may override the generated entry at function level via the entrypoint
option in serverless.yml.
functions:  my-function:    layers:      - LAYER-ARN    handler: layer.handler    entrypoint: src/index.handler
Full customization (for experts)
The lib export also provides the serverless and options properties, through
which you can access the Serverless instance and the options given on the command-line.
The current stage e.g is accessible through slsw.lib.options.stage
This enables you to have a fully customized dynamic configuration, that can evaluate
anything available in the Serverless framework. There are really no limits.
Samples are: The current stage and the complete service definition. You thereby
have access to anything that a Serverless plugin would have access to.
Both properties should be handled with care and should never be written to,
as that will modify the running framework and leads to unpredictable behavior!
If you have cool use cases with the full customization, we might add your solution
to the plugin examples as showcase.
Invocation state
lib.webpack contains state variables that can be used to configure the build
dynamically on a specific plugin state.
isLocal
lib.webpack.isLocal is a boolean property that is set to true, if any known
mechanism is used in the current Serverless invocation that runs code locally.
This allows to set properties in the webpack configuration differently depending
if the lambda code is run on the local machine or deployed.
A sample is to set the compile mode with Webpack 4:
mode: slsw.lib.webpack.isLocal ? "development" : "production"
Output
Note that, if the output configuration is not set, it will automatically be
generated to write bundles in the .webpack directory. If you set your own output
configuration make sure to add a libraryTarget
for best compatibility with external dependencies:
// webpack.config.jsconst path = require('path');module.exports = {  // ...  output: {    libraryTarget: 'commonjs',    path: path.resolve(__dirname, '.webpack'),    filename: '[name].js'  }  // ...};
Stats
By default, the plugin will print a quite verbose bundle information to your console. However, if
you are not satisfied with the current output info, you can overwrite it in your webpack.config.js
// webpack.config.jsmodule.exports = {  // ...  stats: 'minimal'  // ...};
All the stats config can be found in webpack's documentation
Node modules / externals
By default, the plugin will try to bundle all dependencies. However, you don't
want to include all modules in some cases such as selectively import, excluding
builtin package (ie: aws-sdk) and handling webpack-incompatible modules.
In this case you might add external modules in
Webpack's externals configuration.
Those modules can be included in the Serverless bundle with the custom: webpack: includeModules
option in serverless.yml:
// webpack.config.jsvar nodeExternals = require('webpack-node-externals');module.exports = {  // we use webpack-node-externals to excludes all node deps.  // You can manually set the externals too.  externals: [nodeExternals()]};
# serverless.ymlcustom:  webpack:    includeModules: true # enable auto-packing of external modules
All modules stated in externals will be excluded from bundled files. If an excluded module
is stated as dependencies in package.json and it is used by the webpack chunk, it will be
packed into the Serverless artifact under the node_modules directory.
By default, the plugin will use the package.json file in working directory, If you want to
use a different package file, set packagePath to your custom package.json:
# serverless.ymlcustom:  webpack:    includeModules:      packagePath: '../package.json' # relative path to custom package.json file.

Note that only relative path is supported at the moment.

peerDependencies of all above external dependencies will also be packed into the Serverless
artifact. By default, node_modules in the same directory as package.json (current working directory
or specified bypackagePath) will be used.
However in some configuration (like monorepo), node_modules is in parent directory which is different from
where package.json is. Set nodeModulesRelativeDir to specify the relative directory where node_modules is.
# serverless.ymlcustom:  webpack:    includeModules:      nodeModulesRelativeDir: '../../' # relative path to current working directory.
When using NPM 8, peerDependencies are automatically installed by default. In order to avoid adding all transitive dependencies to your package.json, we will use the package-lock.json when possible. If your project is included in a monorepo, you can specify the path to the package-lock.json:
# serverless.ymlcustom:  webpack:    includeModules:      nodeModulesRelativeDir: '../../' # relative path to current working directory.    packagerOptions:      lockFile: '../../package-lock.json' # relative path to package-lock.json
Runtime dependencies
If a runtime dependency is detected that is found in the devDependencies section and
so would not be packaged, the plugin will error until you explicitly exclude it (see forceExclude below)
or move it to the dependencies section.
AWS-SDK
An exception for the runtime dependency error is the AWS-SDK. All projects using the AWS-SDK normally
have it listed in devDependencies because AWS provides it already in their Lambda environment. In this case
the aws-sdk is automatically excluded and only an informational message is printed (in --verbose mode).
The main reason for the warning is, that silently ignoring anything contradicts the declarative nature
of Serverless' service definition. So the correct way to define the handling for the aws-sdk is, as
you would do for all other excluded modules (see forceExclude below).
# serverless.ymlcustom:  webpack:    includeModules:      forceExclude:        - aws-sdk
Packagers
You can select the packager that will be used to package your external modules.
The packager can be set with the packager configuration. Currently it can be 'npm'
or 'yarn' and defaults to using npm when not set.
# serverless.ymlcustom:  webpack:    packager: 'yarn' # Defaults to npm    packagerOptions: {} # Optional, depending on the selected packager
You should select the packager, that you use to develop your projects, because only
then locked versions will be handled correctly, i.e. the plugin uses the generated
(and usually committed) package lock file that is created by your favorite packager.
Each packager might support specific options that can be set in the packagerOptions
configuration setting. For details see below.
NPM
By default, the plugin uses NPM to package the external modules. However, if you use npm,
you should use any version <5.5 >=5.7.1 as the versions in-between have some nasty bugs.
The NPM packager supports the following packagerOptions:



































OptionTypeDefaultDescriptionignoreScriptsboolfalseDo not execute package.json hook scripts on installnoInstallboolfalseDo not run npm install (assume install completed)lockFilestring./package-lock.jsonRelative path to lock file to usecopyPackageSectionNamesstring[][]Entries in your package.json to copy to the output package.json (ie: ESM output)
When using NPM version >= 7.0.0, we will use the package-lock.json file instead of modules installed in node_modules. This improves the
supports of NPM >= 8.0.0 which installs peer-dependencies automatically. The plugin will be able to detect the correct version.
ESM output
If you need to generate ESM output, and you cannot safely produce a .mjs file
(e.g. because that breaks serverless-offline),
you can use copyPackageSectionNames to ensure the output package.json defaults to ESM.
custom:  webpack:    packagerOptions:      copyPackageSectionNames:        - type        - exports        - main
Yarn
Using yarn will switch the whole packaging pipeline to use yarn, so does it use a yarn.lock file.
The yarn packager supports the following packagerOptions:















































OptionTypeDefaultDescriptionignoreScriptsboolfalseDo not execute package.json hook scripts on installnoInstallboolfalseDo not run yarn install (assume install completed)noNonInteractiveboolfalseDisable interactive mode when using Yarn 2 or abovenoFrozenLockfileboolfalseDo not require an up-to-date yarn.locknetworkConcurrencyintSpecify number of concurrent network requestscopyPackageSectionNamesstring[]['resolutions']Entries in your package.json to copy to the output package.json
Common packager options
There are some settings that are common to all packagers and affect the packaging itself.
Custom scripts
You can specify custom scripts that are executed after the installation of the function/service packages
has been finished. These are standard packager scripts as they can be used in any package.json.
Warning: The use cases for them are very rare and specific and you should investigate first,
if your use case can be covered with webpack plugins first. They should never access files
outside of their current working directory which is the compiled function folder, if any.
A valid use case would be to start anything available as binary from node_modules.
custom:  webpack:    packagerOptions:      scripts:        - npm rebuild grpc --target=6.1.0 --target_arch=x64 --target_platform=linux --target_libc=glibc
Forced inclusion
Sometimes it might happen that you use dynamic requires in your code, i.e. you
require modules that are only known at runtime. Webpack is not able to detect
such externals and the compiled package will miss the needed dependencies.
In such cases you can force the plugin to include certain modules by setting
them in the forceInclude array property. However the module must appear in
your service's production dependencies in package.json.
# serverless.ymlcustom:  webpack:    includeModules:      forceInclude:        - module1        - module2
Forced exclusion
You can forcefully exclude detected external modules, e.g. if you have a module
in your dependencies that is already installed at your provider's environment.
Just add them to the forceExclude array property and they will not be packaged.
# serverless.ymlcustom:  webpack:    includeModules:      forceExclude:        - module1        - module2
If you specify a module in both arrays, forceInclude and forceExclude, the
exclude wins and the module will not be packaged.
Local modules
You can use file: version references in your package.json to use a node module
from a local folder (e.g. "mymodule": "file:../../myOtherProject/mymodule").
With that you can do test deployments from the local machine with different
module versions or modules before they are published officially.
Exclude Files with similar names
If you have a project structure that uses something like index.js and a
co-located index.test.js then you have likely seen an error like:
WARNING: More than one matching handlers found for index. Using index.js
This config option allows you to exclude files that match a glob from function
resolution. Just add: excludeFiles: **/*.test.js (with whatever glob you want
to exclude).
# serverless.ymlcustom:  webpack:    excludeFiles: **/*.test.js
This is also useful for projects that use TypeScript.
Exclude Files with Regular Expression
This config option allows you to filter files that match a regex pattern before
adding to the zip file. Just add: excludeRegex: \.ts|test|\.map (with whatever
regex you want to exclude).
# serverless.ymlcustom:  webpack:    excludeRegex: \.ts|test|\.map
Keep output directory after packaging
You can keep the output directory (defaults to .webpack) from being removed
after build.
Just add keepOutputDirectory: true
# serverless.ymlcustom:  webpack:    keepOutputDirectory: true
This can be useful, in case you want to upload the source maps to your Error
reporting system, or just have it available for some post processing.
Nodejs custom runtime
If you are using a nodejs custom runtime you can add the property allowCustomRuntime: true.
exampleFunction:  handler: path/to/your/handler.default  runtime: provided  allowCustomRuntime: true
⚠️ Note: this will only work if your custom runtime and function are written in JavaScript.
Make sure you know what you are doing when this option is set to true
Examples
You can find an example setups in the examples folder.
Service level packaging
If you do not enable individual packaging in your service (serverless.yml), the
plugin creates one ZIP file for all functions (the service package) that includes
all node modules used in the service. This is the fastest packaging, but not the
optimal one, as node modules are always packaged, that are not needed by some
functions.
Optimization / Individual packaging per function
A better way to do the packaging, is to enable individual packaging in your
service:
# serverless.yml---package:  individually: true
This will switch the plugin to per function packaging which makes use of the multi-compiler
feature of Webpack. That means, that Webpack compiles and optimizes each
function individually, removing unnecessary imports and reducing code sizes
significantly. Tree-Shaking only makes sense with this approach.
Now the needed external node modules are also detected by Webpack per function
and the plugin only packages the needed ones into the function artifacts. As a
result, the deployed artifacts are smaller, depending on the functions and
cold-start times (to install the functions into the cloud at runtime) are reduced
too.
The individual packaging will automatically apply the automatic entry resolution (see above) and
you will not be able to configure the entry config in webpack. An error will be thrown
if you are trying to override the entry in webpack.config.js with other unsupported values.
The individual packaging needs more time at the packaging phase, but you'll
get that paid back twice at runtime.
Individual packaging concurrency
# serverless.ymlcustom:  webpack:    concurrency: 5 # desired concurrency, defaults to the number of available cores    serializedCompile: true # backward compatible, this translates to concurrency: 1
Will run each webpack build one at a time which helps reduce memory usage and in some cases impoves overall build performance.
Support for Docker Images as Custom Runtimes
AWS Lambda and serverless started supporting the use of Docker images as custom runtimes in 2021. See the serverless documentation for details on how to configure a serverless.yml to use these features.
NOTE: You must provide an override for the Image CMD property in your function definitions.
See Dockerfile documentation for more information about the native Docker CMD property.
In the following example entrypoint is inherited from the shared Docker image, while command is provided as an override for each function:
# serverless.ymlfunctions:  myFunction1:    image:      name: public.ecr.aws/lambda/nodejs:12      command:        - app.handler1  myFunction2:    image:      name: public.ecr.aws/lambda/nodejs:12      command:        - app.handler2
If you want to use a remote docker image but still need the webpack process before doing so, you can specify it as indicated below:
# serverless.ymlfunctions:  myFunction1:    image: public.ecr.aws/lambda/nodejs:latest
Usage
Automatic bundling
The normal Serverless deploy procedure will automatically bundle with Webpack:

Create the Serverless project with serverless create -t aws-nodejs
Install Serverless Webpack as above
Deploy with serverless deploy

Run a function locally
The plugin fully integrates with serverless invoke local. To run your bundled functions
locally you can:
$ serverless invoke local --function <function-name>
All options that are supported by invoke local can be used as usual:

--function or -f (required) is the name of the function to run
--path or -p (optional) is a JSON file path used as the function input event
--data or -d (optional) inline JSON data used as the function input event


:exclamation: The old webpack invoke command has been disabled.

Run a function with an existing compiled output
On CI systems it is likely that you'll run multiple integration tests with invoke local
sequentially. To improve this, you can do one compile and run multiple invokes on the
compiled output - it is not necessary to compile again before each and every invoke.
Using the CLI option --skip-build
$ serverless webpack$ serverless invoke local --function <function-name-1> --skip-build$ serverless invoke local --function <function-name-2> --skip-build
Using the parameter noBuild
custom:  webpack:    noBuild: true
Run a function locally on source changes
Or to run a function every time the source files change use the --watch option
together with serverless invoke local:
$ serverless invoke local --function <function-name> --path event.json --watch
Everytime the sources are changed, the function will be executed again with the
changed sources. The command will watch until the process is terminated.
If you have your sources located on a file system that does not offer events,
you can enable polling with the --webpack-use-polling=<time in ms> option.
If you omit the value, it defaults to 3000 ms.
All options that are supported by invoke local can be used as usual:

--function or -f (required) is the name of the function to run
--path or -p (optional) is a JSON file path used as the function input event
--data or -d (optional) inline JSON data used as the function input event


:exclamation: The old webpack watch command has been disabled.

Usage with serverless run (Serverless Event Gateway)
The serverless run command is supported with the plugin. To test a local
service with the Serverless Emulator, you can use the serverless run
command as documented by Serverless. The command will compile the code before
it uploads it into the event gateway.
Serverless run with webpack watch mode
You can enable source watch mode with serverless run --watch. The plugin will
then watch for any source changes, recompile and redeploy the code to the event
gateway. So you can just keep the event gateway running and test new code immediately.
Usage with serverless-offline
The plugin integrates very well with serverless-offline to
simulate AWS Lambda and AWS API Gateway locally.
Add the plugins to your serverless.yml file and make sure that serverless-webpack
precedes serverless-offline as the order is important:
plugins: ...  - serverless-webpack  ...  - serverless-offline  ...
Run serverless offline or serverless offline start to start the Lambda/API simulation.
In comparison to serverless offline, the start command will fire an init and a end lifecycle hook which is needed for serverless-offline and e.g. serverless-dynamodb-local to switch off resources (see below).
You can find an example setup in the examples folder.
By default the plugin starts in watch mode when triggered through serverless offline, i.e.
it automatically recompiles your code if it detects a change in the used sources.
After a change it might take some seconds until the emulated endpoints are updated.
If you have your sources located on a file system that does not offer events,
e.g. a mounted volume in a Docker container, you can enable polling with the
--webpack-use-polling=<time in ms> option. If you omit the value, it defaults
to 3000 ms.
If you don't want the plugin to build when using serverless-offline, select the --skip-build option.
Custom paths
If you do not use the default path and override it in your Webpack configuration,
you have use the --location option.
serverless-dynamodb-local
Configure your service the same as mentioned above, but additionally add the serverless-dynamodb-local
plugin as follows:
plugins:  - serverless-webpack  - serverless-dynamodb-local  - serverless-offline
Run serverless offline start.
Other useful options
You can disable timeouts with --noTimeout when using serverless-offline.
If you use serverless offline to run your integration tests, you might want to
disable the automatic watch mode with the --webpack-no-watch switch.
Bundle with webpack
To just bundle and see the output result use:
$ serverless webpack --out dist
Options are:

--out or -o (optional) The output directory. Defaults to .webpack.

Simulate API Gateway locally
:exclamation: The serve command has been removed. See above how to achieve the
same functionality with the serverless-offline plugin.
vscode debugging
To debug your functions using serverless invoke local or serverless-offline
check this .vscode/launch.json example.
Example with Babel
In the examples folder there is a Serverless project using this
plugin with Babel. To try it, from inside the example folder:

npm install to install dependencies
serverless invoke local -f hello to run the example function

Provider Support
Plugin commands are supported by the following providers. ⁇ indicates that command has not been tested with that provider.

































AWS LambdaApache OpenWhiskAzure FunctionsGoogle Cloud Functionswebpack✔︎✔︎⁇⁇invoke local✔︎✔︎⁇⁇invoke local --watch✔︎✔︎⁇⁇
Plugin support
The following serverless plugins are explicitly supported with serverless-webpack

















PluginNPMserverless-offlineserverless-step-functions-offline
For developers
The plugin exposes a complete lifecycle model that can be hooked by other plugins to extend
the functionality of the plugin or add additional actions.
The event lifecycles and their hookable events (H)
All events (H) can be hooked by a plugin.
-> webpack:validate   -> webpack:validate:validate (H)-> webpack:compile   -> webpack:compile:compile (H)   -> webpack:compile:watch:compile (H)-> webpack:package   -> webpack:package:packExternalModules (H)   -> webpack:package:packageModules (H)
Integration of the lifecycles into the command invocations and hooks
The following list shows all lifecycles that are invoked/started by the
plugin when running a command or invoked by a hook.
-> before:package:createDeploymentArtifacts   -> webpack:validate   -> webpack:compile   -> webpack:package-> before:deploy:function:packageFunction   -> webpack:validate   -> webpack:compile   -> webpack:package-> before:invoke:local:invoke   -> webpack:validate   -> webpack:compile-> webpack   -> webpack:validate   -> webpack:compile   -> webpack:package-> before:offline:start   -> webpack:validate   -> webpack:compile-> before:offline:start:init   -> webpack:validate   -> webpack:compile
Thanks
Special thanks go to the initial author of serverless-webpack, Nicola Peduzzi, who allowed
me to take it over and continue working on the project. That helped to revive it and lead it to new horizons.
Release Notes
See the releases section\n\nPluginsServerless WebpackServerless Webpack






A Serverless Framework plugin to build your lambda functions with Webpack.
This plugin is for you if you want to use the latest Javascript version with Babel;
use custom resource loaders, optimize your packaged functions individually
and much more!
Highlights

Configuration possibilities range from zero-config to fully customizable
Support of serverless package, serverless deploy and serverless deploy function
Support of serverless invoke local and serverless invoke local --watch
Support of serverless run and serverless run --watch
Integrates with serverless-offline to simulate local API Gateway endpoints
When enabled in your service configuration, functions are packaged and compiled
individually, resulting in smaller Lambda packages that contain only the code and
dependencies needed to run the function. This allows the plugin to fully utilize
WebPack's Tree-Shaking optimization.
Webpack version 3, 4 and 5 support
Support NPM and Yarn for packaging
Support asynchronous webpack configuration

For the complete release notes see the end of this document.
Install
$ npm install serverless-webpack --save-dev
or
$ yarn add serverless-webpack --dev
Add the plugin to your serverless.yml file:
plugins:  - serverless-webpack
Configure
The configuration of the plugin is done by defining a custom: webpack object in your serverless.yml with your specific configuration. All settings are optional and will be set to reasonable defaults if missing.
See the sections below for detailed descriptions of the settings. The defaults are:
custom:  webpack:    webpackConfig: 'webpack.config.js' # Name of webpack configuration file    includeModules: false # Node modules configuration for packaging    packager: 'npm' # Packager that will be used to package your external modules    excludeFiles: src/**/*.test.js # Provide a glob for files to ignore
Webpack configuration file
By default the plugin will look for a webpack.config.js in the service directory. Alternatively, you can specify a different file or configuration in serverless.yml.
custom:  webpack:    webpackConfig: ./folder/my-webpack.config.js
A base Webpack configuration might look like this:
// webpack.config.jsmodule.exports = {  entry: './handler.js',  target: 'node',  module: {    loaders: [ ... ]  }};
Alternatively the Webpack configuration can export an asynchronous object (e.g. a promise or async function) which will be awaited by the plugin and resolves to the final configuration object. This is useful if the confguration depends on asynchronous functions, for example, defining the AccountId of the current aws user inside AWS lambda@edge which does not support defining normal process environment variables.
A basic Webpack promise configuration might look like this:
// Version if the local Node.js version supports async/await// webpack.config.jsconst webpack = require('webpack')const slsw = require('serverless-webpack');module.exports = (async () => {  const accountId = await slsw.lib.serverless.providers.aws.getAccountId();  return {    entry: './handler.js',    target: 'node',    plugins: [      new webpack.DefinePlugin({        AWS_ACCOUNT_ID: `${accountId}`,      }),    ],    module: {      loaders: [ ... ]    }  };})();
// Version with promises// webpack.config.jsconst webpack = require('webpack')const slsw = require('serverless-webpack');const BbPromise = require('bluebird');module.exports = BbPromise.try(() => {  return slsw.lib.serverless.providers.aws.getAccountId()  .then(accountId => ({    entry: './handler.js',    target: 'node',    plugins: [      new webpack.DefinePlugin({        AWS_ACCOUNT_ID: `${accountId}`,      }),    ],    module: {      loaders: [ ... ]    }  }));});
serverless-webpack lib export helper
serverless-webpack exposes a lib object, that can be used in your webpack.config.js
to make the configuration easier and to build fully dynamic configurations.
This is the preferred way to configure webpack - the plugin will take care of
as much of the configuration (and subsequent changes in your services) as it can.
Automatic entry resolution
You can let the plugin determine the correct handler entry points at build time.
Then you do not have to care anymore when you add or remove functions from your service:
// webpack.config.jsconst slsw = require('serverless-webpack');module.exports = {  ...  entry: slsw.lib.entries,  ...};
Custom entries that are not part of the SLS build process can be added too:
// webpack.config.jsconst _ = require('lodash');const slsw = require('serverless-webpack');module.exports = {  ...  entry: _.assign({    myCustomEntry1: './custom/path/something.js'  }, slsw.lib.entries),  ...};
Optional entry overrides
serverless-webpack generates Webpack entries from the handler value by default.
If your handler is different from the webpack entry, e.g. provided by a layer,
you may override the generated entry at function level via the entrypoint
option in serverless.yml.
functions:  my-function:    layers:      - LAYER-ARN    handler: layer.handler    entrypoint: src/index.handler
Full customization (for experts)
The lib export also provides the serverless and options properties, through
which you can access the Serverless instance and the options given on the command-line.
The current stage e.g is accessible through slsw.lib.options.stage
This enables you to have a fully customized dynamic configuration, that can evaluate
anything available in the Serverless framework. There are really no limits.
Samples are: The current stage and the complete service definition. You thereby
have access to anything that a Serverless plugin would have access to.
Both properties should be handled with care and should never be written to,
as that will modify the running framework and leads to unpredictable behavior!
If you have cool use cases with the full customization, we might add your solution
to the plugin examples as showcase.
Invocation state
lib.webpack contains state variables that can be used to configure the build
dynamically on a specific plugin state.
isLocal
lib.webpack.isLocal is a boolean property that is set to true, if any known
mechanism is used in the current Serverless invocation that runs code locally.
This allows to set properties in the webpack configuration differently depending
if the lambda code is run on the local machine or deployed.
A sample is to set the compile mode with Webpack 4:
mode: slsw.lib.webpack.isLocal ? "development" : "production"
Output
Note that, if the output configuration is not set, it will automatically be
generated to write bundles in the .webpack directory. If you set your own output
configuration make sure to add a libraryTarget
for best compatibility with external dependencies:
// webpack.config.jsconst path = require('path');module.exports = {  // ...  output: {    libraryTarget: 'commonjs',    path: path.resolve(__dirname, '.webpack'),    filename: '[name].js'  }  // ...};
Stats
By default, the plugin will print a quite verbose bundle information to your console. However, if
you are not satisfied with the current output info, you can overwrite it in your webpack.config.js
// webpack.config.jsmodule.exports = {  // ...  stats: 'minimal'  // ...};
All the stats config can be found in webpack's documentation
Node modules / externals
By default, the plugin will try to bundle all dependencies. However, you don't
want to include all modules in some cases such as selectively import, excluding
builtin package (ie: aws-sdk) and handling webpack-incompatible modules.
In this case you might add external modules in
Webpack's externals configuration.
Those modules can be included in the Serverless bundle with the custom: webpack: includeModules
option in serverless.yml:
// webpack.config.jsvar nodeExternals = require('webpack-node-externals');module.exports = {  // we use webpack-node-externals to excludes all node deps.  // You can manually set the externals too.  externals: [nodeExternals()]};
# serverless.ymlcustom:  webpack:    includeModules: true # enable auto-packing of external modules
All modules stated in externals will be excluded from bundled files. If an excluded module
is stated as dependencies in package.json and it is used by the webpack chunk, it will be
packed into the Serverless artifact under the node_modules directory.
By default, the plugin will use the package.json file in working directory, If you want to
use a different package file, set packagePath to your custom package.json:
# serverless.ymlcustom:  webpack:    includeModules:      packagePath: '../package.json' # relative path to custom package.json file.

Note that only relative path is supported at the moment.

peerDependencies of all above external dependencies will also be packed into the Serverless
artifact. By default, node_modules in the same directory as package.json (current working directory
or specified bypackagePath) will be used.
However in some configuration (like monorepo), node_modules is in parent directory which is different from
where package.json is. Set nodeModulesRelativeDir to specify the relative directory where node_modules is.
# serverless.ymlcustom:  webpack:    includeModules:      nodeModulesRelativeDir: '../../' # relative path to current working directory.
When using NPM 8, peerDependencies are automatically installed by default. In order to avoid adding all transitive dependencies to your package.json, we will use the package-lock.json when possible. If your project is included in a monorepo, you can specify the path to the package-lock.json:
# serverless.ymlcustom:  webpack:    includeModules:      nodeModulesRelativeDir: '../../' # relative path to current working directory.    packagerOptions:      lockFile: '../../package-lock.json' # relative path to package-lock.json
Runtime dependencies
If a runtime dependency is detected that is found in the devDependencies section and
so would not be packaged, the plugin will error until you explicitly exclude it (see forceExclude below)
or move it to the dependencies section.
AWS-SDK
An exception for the runtime dependency error is the AWS-SDK. All projects using the AWS-SDK normally
have it listed in devDependencies because AWS provides it already in their Lambda environment. In this case
the aws-sdk is automatically excluded and only an informational message is printed (in --verbose mode).
The main reason for the warning is, that silently ignoring anything contradicts the declarative nature
of Serverless' service definition. So the correct way to define the handling for the aws-sdk is, as
you would do for all other excluded modules (see forceExclude below).
# serverless.ymlcustom:  webpack:    includeModules:      forceExclude:        - aws-sdk
Packagers
You can select the packager that will be used to package your external modules.
The packager can be set with the packager configuration. Currently it can be 'npm'
or 'yarn' and defaults to using npm when not set.
# serverless.ymlcustom:  webpack:    packager: 'yarn' # Defaults to npm    packagerOptions: {} # Optional, depending on the selected packager
You should select the packager, that you use to develop your projects, because only
then locked versions will be handled correctly, i.e. the plugin uses the generated
(and usually committed) package lock file that is created by your favorite packager.
Each packager might support specific options that can be set in the packagerOptions
configuration setting. For details see below.
NPM
By default, the plugin uses NPM to package the external modules. However, if you use npm,
you should use any version <5.5 >=5.7.1 as the versions in-between have some nasty bugs.
The NPM packager supports the following packagerOptions:



































OptionTypeDefaultDescriptionignoreScriptsboolfalseDo not execute package.json hook scripts on installnoInstallboolfalseDo not run npm install (assume install completed)lockFilestring./package-lock.jsonRelative path to lock file to usecopyPackageSectionNamesstring[][]Entries in your package.json to copy to the output package.json (ie: ESM output)
When using NPM version >= 7.0.0, we will use the package-lock.json file instead of modules installed in node_modules. This improves the
supports of NPM >= 8.0.0 which installs peer-dependencies automatically. The plugin will be able to detect the correct version.
ESM output
If you need to generate ESM output, and you cannot safely produce a .mjs file
(e.g. because that breaks serverless-offline),
you can use copyPackageSectionNames to ensure the output package.json defaults to ESM.
custom:  webpack:    packagerOptions:      copyPackageSectionNames:        - type        - exports        - main
Yarn
Using yarn will switch the whole packaging pipeline to use yarn, so does it use a yarn.lock file.
The yarn packager supports the following packagerOptions:















































OptionTypeDefaultDescriptionignoreScriptsboolfalseDo not execute package.json hook scripts on installnoInstallboolfalseDo not run yarn install (assume install completed)noNonInteractiveboolfalseDisable interactive mode when using Yarn 2 or abovenoFrozenLockfileboolfalseDo not require an up-to-date yarn.locknetworkConcurrencyintSpecify number of concurrent network requestscopyPackageSectionNamesstring[]['resolutions']Entries in your package.json to copy to the output package.json
Common packager options
There are some settings that are common to all packagers and affect the packaging itself.
Custom scripts
You can specify custom scripts that are executed after the installation of the function/service packages
has been finished. These are standard packager scripts as they can be used in any package.json.
Warning: The use cases for them are very rare and specific and you should investigate first,
if your use case can be covered with webpack plugins first. They should never access files
outside of their current working directory which is the compiled function folder, if any.
A valid use case would be to start anything available as binary from node_modules.
custom:  webpack:    packagerOptions:      scripts:        - npm rebuild grpc --target=6.1.0 --target_arch=x64 --target_platform=linux --target_libc=glibc
Forced inclusion
Sometimes it might happen that you use dynamic requires in your code, i.e. you
require modules that are only known at runtime. Webpack is not able to detect
such externals and the compiled package will miss the needed dependencies.
In such cases you can force the plugin to include certain modules by setting
them in the forceInclude array property. However the module must appear in
your service's production dependencies in package.json.
# serverless.ymlcustom:  webpack:    includeModules:      forceInclude:        - module1        - module2
Forced exclusion
You can forcefully exclude detected external modules, e.g. if you have a module
in your dependencies that is already installed at your provider's environment.
Just add them to the forceExclude array property and they will not be packaged.
# serverless.ymlcustom:  webpack:    includeModules:      forceExclude:        - module1        - module2
If you specify a module in both arrays, forceInclude and forceExclude, the
exclude wins and the module will not be packaged.
Local modules
You can use file: version references in your package.json to use a node module
from a local folder (e.g. "mymodule": "file:../../myOtherProject/mymodule").
With that you can do test deployments from the local machine with different
module versions or modules before they are published officially.
Exclude Files with similar names
If you have a project structure that uses something like index.js and a
co-located index.test.js then you have likely seen an error like:
WARNING: More than one matching handlers found for index. Using index.js
This config option allows you to exclude files that match a glob from function
resolution. Just add: excludeFiles: **/*.test.js (with whatever glob you want
to exclude).
# serverless.ymlcustom:  webpack:    excludeFiles: **/*.test.js
This is also useful for projects that use TypeScript.
Exclude Files with Regular Expression
This config option allows you to filter files that match a regex pattern before
adding to the zip file. Just add: excludeRegex: \.ts|test|\.map (with whatever
regex you want to exclude).
# serverless.ymlcustom:  webpack:    excludeRegex: \.ts|test|\.map
Keep output directory after packaging
You can keep the output directory (defaults to .webpack) from being removed
after build.
Just add keepOutputDirectory: true
# serverless.ymlcustom:  webpack:    keepOutputDirectory: true
This can be useful, in case you want to upload the source maps to your Error
reporting system, or just have it available for some post processing.
Nodejs custom runtime
If you are using a nodejs custom runtime you can add the property allowCustomRuntime: true.
exampleFunction:  handler: path/to/your/handler.default  runtime: provided  allowCustomRuntime: true
⚠️ Note: this will only work if your custom runtime and function are written in JavaScript.
Make sure you know what you are doing when this option is set to true
Examples
You can find an example setups in the examples folder.
Service level packaging
If you do not enable individual packaging in your service (serverless.yml), the
plugin creates one ZIP file for all functions (the service package) that includes
all node modules used in the service. This is the fastest packaging, but not the
optimal one, as node modules are always packaged, that are not needed by some
functions.
Optimization / Individual packaging per function
A better way to do the packaging, is to enable individual packaging in your
service:
# serverless.yml---package:  individually: true
This will switch the plugin to per function packaging which makes use of the multi-compiler
feature of Webpack. That means, that Webpack compiles and optimizes each
function individually, removing unnecessary imports and reducing code sizes
significantly. Tree-Shaking only makes sense with this approach.
Now the needed external node modules are also detected by Webpack per function
and the plugin only packages the needed ones into the function artifacts. As a
result, the deployed artifacts are smaller, depending on the functions and
cold-start times (to install the functions into the cloud at runtime) are reduced
too.
The individual packaging will automatically apply the automatic entry resolution (see above) and
you will not be able to configure the entry config in webpack. An error will be thrown
if you are trying to override the entry in webpack.config.js with other unsupported values.
The individual packaging needs more time at the packaging phase, but you'll
get that paid back twice at runtime.
Individual packaging concurrency
# serverless.ymlcustom:  webpack:    concurrency: 5 # desired concurrency, defaults to the number of available cores    serializedCompile: true # backward compatible, this translates to concurrency: 1
Will run each webpack build one at a time which helps reduce memory usage and in some cases impoves overall build performance.
Support for Docker Images as Custom Runtimes
AWS Lambda and serverless started supporting the use of Docker images as custom runtimes in 2021. See the serverless documentation for details on how to configure a serverless.yml to use these features.
NOTE: You must provide an override for the Image CMD property in your function definitions.
See Dockerfile documentation for more information about the native Docker CMD property.
In the following example entrypoint is inherited from the shared Docker image, while command is provided as an override for each function:
# serverless.ymlfunctions:  myFunction1:    image:      name: public.ecr.aws/lambda/nodejs:12      command:        - app.handler1  myFunction2:    image:      name: public.ecr.aws/lambda/nodejs:12      command:        - app.handler2
If you want to use a remote docker image but still need the webpack process before doing so, you can specify it as indicated below:
# serverless.ymlfunctions:  myFunction1:    image: public.ecr.aws/lambda/nodejs:latest
Usage
Automatic bundling
The normal Serverless deploy procedure will automatically bundle with Webpack:

Create the Serverless project with serverless create -t aws-nodejs
Install Serverless Webpack as above
Deploy with serverless deploy

Run a function locally
The plugin fully integrates with serverless invoke local. To run your bundled functions
locally you can:
$ serverless invoke local --function <function-name>
All options that are supported by invoke local can be used as usual:

--function or -f (required) is the name of the function to run
--path or -p (optional) is a JSON file path used as the function input event
--data or -d (optional) inline JSON data used as the function input event


:exclamation: The old webpack invoke command has been disabled.

Run a function with an existing compiled output
On CI systems it is likely that you'll run multiple integration tests with invoke local
sequentially. To improve this, you can do one compile and run multiple invokes on the
compiled output - it is not necessary to compile again before each and every invoke.
Using the CLI option --skip-build
$ serverless webpack$ serverless invoke local --function <function-name-1> --skip-build$ serverless invoke local --function <function-name-2> --skip-build
Using the parameter noBuild
custom:  webpack:    noBuild: true
Run a function locally on source changes
Or to run a function every time the source files change use the --watch option
together with serverless invoke local:
$ serverless invoke local --function <function-name> --path event.json --watch
Everytime the sources are changed, the function will be executed again with the
changed sources. The command will watch until the process is terminated.
If you have your sources located on a file system that does not offer events,
you can enable polling with the --webpack-use-polling=<time in ms> option.
If you omit the value, it defaults to 3000 ms.
All options that are supported by invoke local can be used as usual:

--function or -f (required) is the name of the function to run
--path or -p (optional) is a JSON file path used as the function input event
--data or -d (optional) inline JSON data used as the function input event


:exclamation: The old webpack watch command has been disabled.

Usage with serverless run (Serverless Event Gateway)
The serverless run command is supported with the plugin. To test a local
service with the Serverless Emulator, you can use the serverless run
command as documented by Serverless. The command will compile the code before
it uploads it into the event gateway.
Serverless run with webpack watch mode
You can enable source watch mode with serverless run --watch. The plugin will
then watch for any source changes, recompile and redeploy the code to the event
gateway. So you can just keep the event gateway running and test new code immediately.
Usage with serverless-offline
The plugin integrates very well with serverless-offline to
simulate AWS Lambda and AWS API Gateway locally.
Add the plugins to your serverless.yml file and make sure that serverless-webpack
precedes serverless-offline as the order is important:
plugins: ...  - serverless-webpack  ...  - serverless-offline  ...
Run serverless offline or serverless offline start to start the Lambda/API simulation.
In comparison to serverless offline, the start command will fire an init and a end lifecycle hook which is needed for serverless-offline and e.g. serverless-dynamodb-local to switch off resources (see below).
You can find an example setup in the examples folder.
By default the plugin starts in watch mode when triggered through serverless offline, i.e.
it automatically recompiles your code if it detects a change in the used sources.
After a change it might take some seconds until the emulated endpoints are updated.
If you have your sources located on a file system that does not offer events,
e.g. a mounted volume in a Docker container, you can enable polling with the
--webpack-use-polling=<time in ms> option. If you omit the value, it defaults
to 3000 ms.
If you don't want the plugin to build when using serverless-offline, select the --skip-build option.
Custom paths
If you do not use the default path and override it in your Webpack configuration,
you have use the --location option.
serverless-dynamodb-local
Configure your service the same as mentioned above, but additionally add the serverless-dynamodb-local
plugin as follows:
plugins:  - serverless-webpack  - serverless-dynamodb-local  - serverless-offline
Run serverless offline start.
Other useful options
You can disable timeouts with --noTimeout when using serverless-offline.
If you use serverless offline to run your integration tests, you might want to
disable the automatic watch mode with the --webpack-no-watch switch.
Bundle with webpack
To just bundle and see the output result use:
$ serverless webpack --out dist
Options are:

--out or -o (optional) The output directory. Defaults to .webpack.

Simulate API Gateway locally
:exclamation: The serve command has been removed. See above how to achieve the
same functionality with the serverless-offline plugin.
vscode debugging
To debug your functions using serverless invoke local or serverless-offline
check this .vscode/launch.json example.
Example with Babel
In the examples folder there is a Serverless project using this
plugin with Babel. To try it, from inside the example folder:

npm install to install dependencies
serverless invoke local -f hello to run the example function

Provider Support
Plugin commands are supported by the following providers. ⁇ indicates that command has not been tested with that provider.

































AWS LambdaApache OpenWhiskAzure FunctionsGoogle Cloud Functionswebpack✔︎✔︎⁇⁇invoke local✔︎✔︎⁇⁇invoke local --watch✔︎✔︎⁇⁇
Plugin support
The following serverless plugins are explicitly supported with serverless-webpack

















PluginNPMserverless-offlineserverless-step-functions-offline
For developers
The plugin exposes a complete lifecycle model that can be hooked by other plugins to extend
the functionality of the plugin or add additional actions.
The event lifecycles and their hookable events (H)
All events (H) can be hooked by a plugin.
-> webpack:validate   -> webpack:validate:validate (H)-> webpack:compile   -> webpack:compile:compile (H)   -> webpack:compile:watch:compile (H)-> webpack:package   -> webpack:package:packExternalModules (H)   -> webpack:package:packageModules (H)
Integration of the lifecycles into the command invocations and hooks
The following list shows all lifecycles that are invoked/started by the
plugin when running a command or invoked by a hook.
-> before:package:createDeploymentArtifacts   -> webpack:validate   -> webpack:compile   -> webpack:package-> before:deploy:function:packageFunction   -> webpack:validate   -> webpack:compile   -> webpack:package-> before:invoke:local:invoke   -> webpack:validate   -> webpack:compile-> webpack   -> webpack:validate   -> webpack:compile   -> webpack:package-> before:offline:start   -> webpack:validate   -> webpack:compile-> before:offline:start:init   -> webpack:validate   -> webpack:compile
Thanks
Special thanks go to the initial author of serverless-webpack, Nicola Peduzzi, who allowed
me to take it over and continue working on the project. That helped to revive it and lead it to new horizons.
Release Notes
See the releases section\n\n\n\nserverless-domain-manager





Create custom domain names that your lambda can deploy to with serverless. Allows for base path mapping when deploying and deletion of domain names.
About Amplify
Amplify builds innovative and compelling digital educational products that empower teachers and students across the country. We have a long history as the leading innovator in K-12 education - and have been described as the best tech company in education and the best education company in tech. While others try to shrink the learning experience into the technology, we use technology to expand what is possible in real classrooms with real students and teachers.
Learn more at https://www.amplify.com
Getting Started
Prerequisites
Make sure you have the following installed before starting:

nodejs
npm
serverless

The IAM role that is deploying the lambda might need the following permissions:
acm:ListCertificates                   *acm:DescribeCertificate                *apigateway:AddCertificateToDomain      /domainnames*apigateway:RemoveCertificateFromDomain /domainnames*apigateway:GET                         /domainnames*, /apis*, /restapis*apigateway:DELETE                      /domainnames*, /apis*, /restapis*apigateway:POST                        /domainnames*, /apis*, /restapis*apigateway:PATCH                       /domainnames*, /apis*, /restapis*cloudformation:GET                     *cloudformation:ListStacks              *cloudformation:DescribeStacks          *cloudfront:UpdateDistribution          *route53:ListHostedZones                *route53:ChangeResourceRecordSets       hostedzone/{HostedZoneId}route53:GetHostedZone                  *route53:ListResourceRecordSets         *iam:CreateServiceLinkedRole            arn:aws:iam::${AWS::AccountId}: role/aws-service-role/ops.apigateway.amazonaws.com/AWSServiceRoleForAPIGateways3:ListBucket                          *s3:GetObject                           *
CloudFormation
Alternatively you can generate an least privileged IAM Managed Policy for deployment with this:
deployment policy cloudformation template
Installing
# From npm (recommended)npm install serverless-domain-manager --save-dev
Then make the following edits to your serverless.yaml file:
Add the plugin.
plugins:  - serverless-domain-manager
Add the plugin configuration (example for serverless.foo.com/api). For a single domain and API type the following structure can be used.
custom:  customDomain:    domainName: serverless.foo.com    stage: ci    basePath: api    certificateName: '*.foo.com'    createRoute53Record: true    createRoute53IPv6Record: true    endpointType: REGIONAL    securityPolicy: tls_1_2    apiType: rest    autoDomain: false
Multiple API types mapped to different domains can also be supported with the following structure. The key is the API Gateway API type.
custom:  customDomain:    rest:      domainName: rest.serverless.foo.com      stage: ci      basePath: api      certificateName: '*.foo.com'      createRoute53Record: true      createRoute53IPv6Record: true      endpointType: REGIONAL      securityPolicy: tls_1_2    http:      domainName: http.serverless.foo.com      stage: ci      basePath: api      certificateName: '*.foo.com'      createRoute53Record: true      createRoute53IPv6Record: true      endpointType: REGIONAL      securityPolicy: tls_1_2    websocket:      domainName: ws.serverless.foo.com      stage: ci      basePath: api      certificateName: '*.foo.com'      createRoute53Record: true      createRoute53IPv6Record: true      endpointType: REGIONAL      securityPolicy: tls_1_2
Or for multiple domains
custom:  customDomains:    - http:        domainName: http-api-${opt:RANDOM_STRING}.${env:TEST_DOMAIN}        basePath: ''        endpointType: REGIONAL    - http:        domainName: http-api-${opt:RANDOM_STRING}.${env:TEST_DOMAIN}.foo        basePath: ''        endpointType: REGIONAL
For multi-region deployments, a route53Params structure can be used to support latency or weighted routing policies
custom:  customDomain:    domainName: serverless.foo.com    stage: ci    basePath: api    certificateName: '*.foo.com'    createRoute53Record: true    endpointType: REGIONAL    securityPolicy: tls_1_2    route53Params:      routingPolicy: latency

















































































































































Parameter NameDefault ValueDescriptiondomainName (Required)The domain name to be created in API Gateway and Route53 (if enabled) for this API.basePath(none)The base path that will prepend all API endpoints.stageValue of --stage, or provider.stage (serverless will default to dev if unset)The stage to create the domain name for. This parameter allows you to specify a different stage for the domain name than the stage specified for the serverless deployment.certificateNameClosest matchThe name of a specific certificate from Certificate Manager to use with this API. If not specified, the closest match will be used (i.e. for a given domain name api.example.com, a certificate for api.example.com will take precedence over a *.example.com certificate).  Note: Edge-optimized endpoints require that the certificate be located in us-east-1 to be used with the CloudFront distribution.certificateArn(none)The arn of a specific certificate from Certificate Manager to use with this API.createRoute53RecordtrueToggles whether or not the plugin will create A Alias and AAAA Alias records in Route53 mapping the domainName to the generated distribution domain name. If false, does not create a record.createRoute53IPv6RecordtrueToggles whether or not the plugin will create an AAAA Alias record in Route53 mapping the domainName to the generated distribution domain name. If false, does not create a record.route53Profile(none)Profile to use for accessing Route53 resources when Route53 records are in a different accountroute53Region(none)Region to send Route53 services requests to (only applicable if also using route53Profile option)endpointTypeEDGEDefines the endpoint type, accepts REGIONAL or EDGE.apiTyperestDefines the api type, accepts rest, http or websocket.tlsTruststoreUriundefinedAn Amazon S3 url that specifies the truststore for mutual TLS authentication, for example s3://bucket-name/key-name. The truststore can contain certificates from public or private certificate authorities. Be aware mutual TLS is only available for regional APIs.tlsTruststoreVersionundefinedThe version of the S3 object that contains your truststore. To specify a version, you must have versioning enabled for the S3 bucket.hostedZoneIdIf hostedZoneId is set the route53 record set will be created in the matching zone, otherwise the hosted zone will be figured out from the domainName (hosted zone with matching domain).hostedZonePrivateIf hostedZonePrivate is set to true then only private hosted zones will be used for route 53 records. If it is set to false then only public hosted zones will be used for route53 records. Setting this parameter is specially useful if you have multiple hosted zones with the same domain name (e.g. a public and a private one). If records need to be set in both private and public hosted zones use splitHorizonDns parameter.splitHorizonDnsfalseWhen hostedZoneId and hostedZonePrivate are not set, setting this to true creates route53 records in both private and public hosted zones with matching domain.enabledtrueSometimes there are stages for which is not desired to have custom domain names. This flag allows the developer to disable the plugin for such cases. Accepts either boolean or string values and defaults to true for backwards compatibility.securityPolicytls_1_2The security policy to apply to the custom domain name.  Accepts tls_1_0 or tls_1_2allowPathMatchingfalseWhen updating an existing api mapping this will match on the basePath instead of the API ID to find existing mappings for an update.autoDomainfalseToggles whether or not the plugin will run create_domain/delete_domain as part of sls deploy/remove so that multiple commands are not required.autoDomainWaitFor120How long to wait for create_domain to finish before starting deployment if domain does not exist immediately.route53ParamsA set of options to customize Route 53 record creation. If left empty, A and AAAA records with simple routing will be created. If createRoute53Record is false, anything passed here will be ignored.route53Params:  routingPolicysimpleDefines the Route 53 routing policy, accepts simple, latency or weighted.route53Params:  weight200Sets the weight for weighted routing. Ignored for simple and latency routing.route53Params:  setIdentifierA unique identifier for records in a set of Route 53 records with the same domain name. Only relevant for latency and weighted routing. Defaults to the regional endpoint if not provided.route53Params:  healthCheckIdAn optional id for a Route 53 health check. If it is failing, Route 53 will stop routing to it. Only relevant for latency and weighted routing. If it is not provided, no health check will be associated with the record.preserveExternalPathMappingsfalseWhen autoDomain is set to true, and a deployment is removed, setting this to true checks for additional API Gateway base path mappings before automatically deleting the domain, and avoids doing so if they exist.
Running
To create the custom domain:
serverless create_domain
To deploy with the custom domain:
serverless deploy
To remove the created custom domain:
serverless delete_domain
How it works
Creating the custom domain takes advantage of Amazon's Certificate Manager to assign a certificate to the given domain name. Based on already created certificate names, the plugin will search for the certificate that resembles the custom domain's name the most and assign the ARN to that domain name. The plugin then creates the proper A Alias and AAAA Alias records for the domain through Route 53. Once the domain name is set it takes up to 40 minutes before it is initialized. After the certificate is initialized, sls deploy will create the base path mapping and assign the lambda to the custom domain name through CloudFront. All resources are created independent of CloudFormation. However, deploying will also output the domain name and distribution domain name to the CloudFormation stack outputs under the keys DomainName and DistributionDomainName, respectively.
Behavior Change in Version 3
In version 3, we decided to create/update/delete all resources through the API. Previously, only the basepath mapping was managed through CloudFormation. We moved away from creating anything through the stack for two reasons.


It seemed cleaner to have all resources be created in the same fashion, rather than just having one created elsewhere. Since multiple CloudFormation stacks can't create the same custom domain, we decided to have everything be done through the API.


We ran into issues such as #57 where the CloudFormation wasn't always being applied.


However, we still add the domain name and distribution domain name to the CloudFormation outputs, preserving the functionality requested in #43 implemented in #47.
Running Tests
To run unit tests:
npm test
To run integration tests, set an environment variable TEST_DOMAIN to the domain you will be testing for (i.e. example.com if creating a domain for api.example.com).
And ROUTE53_PROFILE for creating route53 record in one AWS account and deploy in another. Then,
export TEST_DOMAIN=example.comexport ROUTE53_PROFILE=defaultexport TLS_TRUSTSTORE_URI=s3://bucket-name/key-nameexport TLS_TRUSTSTORE_VERSION=defaultnpm run buildnpm run integration-test
All tests should pass. All unit tests should pass before merging. Integration tests will take an extremely long time, as DNS records have to propogate for the resources created - therefore, integration tests will not be run on every commit.
If there is an error update the node_modules inside the serverless-domain-manager folder:
npm install
Writing Integration Tests
Unit tests are found in test/unit-tests. Integration tests are found in test/integration-tests. Each folder in tests/integration-tests contains the serverless-domain-manager configuration being tested. To create a new integration test, create a new folder for the handler.js and serverless.yml with the same naming convention and update deploy.test.ts or create a separate one with the test.ts ending.
Changing API Types
AWS API Gateway has three different API types: REST, HTTP, and WebSocket. Special steps need to be taken when migrating from one api type to another. A common migration will be from a REST API to an HTTP API given the potential cost savings. Below are the steps required to change from REST to HTTP. A similar process can be applied for other API type migrations.
REST to HTTP

Confirm the Domain name is a Regional domain name. Edge domains are not supported by AWS for HTTP APIs. See this guide for migrating an edge-optimized custom domain name to regional.
Wait for all DNS changes to take effect/propagate and ensure all traffic is being routed to the regional domain name before proceeding.
Make sure you have setup new or modified existing routes to use httpApi event in your serverless.yml file.
Make the following changes to the customDomain properties in the serverless.yml confg:
endpointType: REGIONALapiType: httpallowPathMatching: true # Only for one deploy

Run sls deploy
Remove the allowPathMatching option, it should only be used once when migrating a base path from one API type to another.

NOTE: Always test this process in a lower level staging or development environment before performing it in production.
Known Issues

(5/23/2017) CloudFormation does not support changing the base path from empty to something or vice a versa. You must run sls remove to remove the base path mapping.
(1/17/2018) The create_domain command provided by this plugin does not currently update an existing Custom Domain's configuration. Instead, it only supports updating the Route 53 record pointing to the Custom Domain. For example, one must delete and recreate a Custom Domain to migrate it from regional to edge or vice versa, or to modify the certificate.
(8/22/2018) Creating a custom domain creates a CloudFront Distribution behind the scenes for fronting your API Gateway. This CloudFront Distribution is managed by AWS and cannot be viewed/managed by you. This is not a bug, but a quirk of how the Custom Domain feature works in API Gateway.
(2/12/2019) Users who upgraded from 2.x.x to version 3.0.4 (now unpublished) and then reverted back to 2.x.x will be unable to deploy because of a bug that will be fixed in 3.1.0. The workaround is to delete the basepath mapping manually, which will let them successfully revert back to 2.x.x.
(1/20/2022) Using route53Profile option requires having hosted zone for the domain in this profile and ACM certificate in the main profile (where functions are deployed).
(2/13/2024) ACM certificate must exist in the us-east-1 for the EDGE endpoint type. https://docs.aws.amazon.com/apigateway/latest/developerguide/how-to-edge-optimized-custom-domain-name.html

Responsible Disclosure
If you have any security issue to report, contact project maintainers privately.
You can reach us at github@amplify.com
Contributing
We welcome pull requests! For your pull request to be accepted smoothly, we suggest that you:

For any sizable change, first open a GitHub issue to discuss your idea.
Create a pull request.  Explain why you want to make the change and what it’s for.
We’ll try to answer any PR’s promptly.\n\nPluginsServerless Domain Managerserverless-domain-manager





Create custom domain names that your lambda can deploy to with serverless. Allows for base path mapping when deploying and deletion of domain names.
About Amplify
Amplify builds innovative and compelling digital educational products that empower teachers and students across the country. We have a long history as the leading innovator in K-12 education - and have been described as the best tech company in education and the best education company in tech. While others try to shrink the learning experience into the technology, we use technology to expand what is possible in real classrooms with real students and teachers.
Learn more at https://www.amplify.com
Getting Started
Prerequisites
Make sure you have the following installed before starting:

nodejs
npm
serverless

The IAM role that is deploying the lambda might need the following permissions:
acm:ListCertificates                   *acm:DescribeCertificate                *apigateway:AddCertificateToDomain      /domainnames*apigateway:RemoveCertificateFromDomain /domainnames*apigateway:GET                         /domainnames*, /apis*, /restapis*apigateway:DELETE                      /domainnames*, /apis*, /restapis*apigateway:POST                        /domainnames*, /apis*, /restapis*apigateway:PATCH                       /domainnames*, /apis*, /restapis*cloudformation:GET                     *cloudformation:ListStacks              *cloudformation:DescribeStacks          *cloudfront:UpdateDistribution          *route53:ListHostedZones                *route53:ChangeResourceRecordSets       hostedzone/{HostedZoneId}route53:GetHostedZone                  *route53:ListResourceRecordSets         *iam:CreateServiceLinkedRole            arn:aws:iam::${AWS::AccountId}: role/aws-service-role/ops.apigateway.amazonaws.com/AWSServiceRoleForAPIGateways3:ListBucket                          *s3:GetObject                           *
CloudFormation
Alternatively you can generate an least privileged IAM Managed Policy for deployment with this:
deployment policy cloudformation template
Installing
# From npm (recommended)npm install serverless-domain-manager --save-dev
Then make the following edits to your serverless.yaml file:
Add the plugin.
plugins:  - serverless-domain-manager
Add the plugin configuration (example for serverless.foo.com/api). For a single domain and API type the following structure can be used.
custom:  customDomain:    domainName: serverless.foo.com    stage: ci    basePath: api    certificateName: '*.foo.com'    createRoute53Record: true    createRoute53IPv6Record: true    endpointType: REGIONAL    securityPolicy: tls_1_2    apiType: rest    autoDomain: false
Multiple API types mapped to different domains can also be supported with the following structure. The key is the API Gateway API type.
custom:  customDomain:    rest:      domainName: rest.serverless.foo.com      stage: ci      basePath: api      certificateName: '*.foo.com'      createRoute53Record: true      createRoute53IPv6Record: true      endpointType: REGIONAL      securityPolicy: tls_1_2    http:      domainName: http.serverless.foo.com      stage: ci      basePath: api      certificateName: '*.foo.com'      createRoute53Record: true      createRoute53IPv6Record: true      endpointType: REGIONAL      securityPolicy: tls_1_2    websocket:      domainName: ws.serverless.foo.com      stage: ci      basePath: api      certificateName: '*.foo.com'      createRoute53Record: true      createRoute53IPv6Record: true      endpointType: REGIONAL      securityPolicy: tls_1_2
Or for multiple domains
custom:  customDomains:    - http:        domainName: http-api-${opt:RANDOM_STRING}.${env:TEST_DOMAIN}        basePath: ''        endpointType: REGIONAL    - http:        domainName: http-api-${opt:RANDOM_STRING}.${env:TEST_DOMAIN}.foo        basePath: ''        endpointType: REGIONAL
For multi-region deployments, a route53Params structure can be used to support latency or weighted routing policies
custom:  customDomain:    domainName: serverless.foo.com    stage: ci    basePath: api    certificateName: '*.foo.com'    createRoute53Record: true    endpointType: REGIONAL    securityPolicy: tls_1_2    route53Params:      routingPolicy: latency

















































































































































Parameter NameDefault ValueDescriptiondomainName (Required)The domain name to be created in API Gateway and Route53 (if enabled) for this API.basePath(none)The base path that will prepend all API endpoints.stageValue of --stage, or provider.stage (serverless will default to dev if unset)The stage to create the domain name for. This parameter allows you to specify a different stage for the domain name than the stage specified for the serverless deployment.certificateNameClosest matchThe name of a specific certificate from Certificate Manager to use with this API. If not specified, the closest match will be used (i.e. for a given domain name api.example.com, a certificate for api.example.com will take precedence over a *.example.com certificate).  Note: Edge-optimized endpoints require that the certificate be located in us-east-1 to be used with the CloudFront distribution.certificateArn(none)The arn of a specific certificate from Certificate Manager to use with this API.createRoute53RecordtrueToggles whether or not the plugin will create A Alias and AAAA Alias records in Route53 mapping the domainName to the generated distribution domain name. If false, does not create a record.createRoute53IPv6RecordtrueToggles whether or not the plugin will create an AAAA Alias record in Route53 mapping the domainName to the generated distribution domain name. If false, does not create a record.route53Profile(none)Profile to use for accessing Route53 resources when Route53 records are in a different accountroute53Region(none)Region to send Route53 services requests to (only applicable if also using route53Profile option)endpointTypeEDGEDefines the endpoint type, accepts REGIONAL or EDGE.apiTyperestDefines the api type, accepts rest, http or websocket.tlsTruststoreUriundefinedAn Amazon S3 url that specifies the truststore for mutual TLS authentication, for example s3://bucket-name/key-name. The truststore can contain certificates from public or private certificate authorities. Be aware mutual TLS is only available for regional APIs.tlsTruststoreVersionundefinedThe version of the S3 object that contains your truststore. To specify a version, you must have versioning enabled for the S3 bucket.hostedZoneIdIf hostedZoneId is set the route53 record set will be created in the matching zone, otherwise the hosted zone will be figured out from the domainName (hosted zone with matching domain).hostedZonePrivateIf hostedZonePrivate is set to true then only private hosted zones will be used for route 53 records. If it is set to false then only public hosted zones will be used for route53 records. Setting this parameter is specially useful if you have multiple hosted zones with the same domain name (e.g. a public and a private one). If records need to be set in both private and public hosted zones use splitHorizonDns parameter.splitHorizonDnsfalseWhen hostedZoneId and hostedZonePrivate are not set, setting this to true creates route53 records in both private and public hosted zones with matching domain.enabledtrueSometimes there are stages for which is not desired to have custom domain names. This flag allows the developer to disable the plugin for such cases. Accepts either boolean or string values and defaults to true for backwards compatibility.securityPolicytls_1_2The security policy to apply to the custom domain name.  Accepts tls_1_0 or tls_1_2allowPathMatchingfalseWhen updating an existing api mapping this will match on the basePath instead of the API ID to find existing mappings for an update.autoDomainfalseToggles whether or not the plugin will run create_domain/delete_domain as part of sls deploy/remove so that multiple commands are not required.autoDomainWaitFor120How long to wait for create_domain to finish before starting deployment if domain does not exist immediately.route53ParamsA set of options to customize Route 53 record creation. If left empty, A and AAAA records with simple routing will be created. If createRoute53Record is false, anything passed here will be ignored.route53Params:  routingPolicysimpleDefines the Route 53 routing policy, accepts simple, latency or weighted.route53Params:  weight200Sets the weight for weighted routing. Ignored for simple and latency routing.route53Params:  setIdentifierA unique identifier for records in a set of Route 53 records with the same domain name. Only relevant for latency and weighted routing. Defaults to the regional endpoint if not provided.route53Params:  healthCheckIdAn optional id for a Route 53 health check. If it is failing, Route 53 will stop routing to it. Only relevant for latency and weighted routing. If it is not provided, no health check will be associated with the record.preserveExternalPathMappingsfalseWhen autoDomain is set to true, and a deployment is removed, setting this to true checks for additional API Gateway base path mappings before automatically deleting the domain, and avoids doing so if they exist.
Running
To create the custom domain:
serverless create_domain
To deploy with the custom domain:
serverless deploy
To remove the created custom domain:
serverless delete_domain
How it works
Creating the custom domain takes advantage of Amazon's Certificate Manager to assign a certificate to the given domain name. Based on already created certificate names, the plugin will search for the certificate that resembles the custom domain's name the most and assign the ARN to that domain name. The plugin then creates the proper A Alias and AAAA Alias records for the domain through Route 53. Once the domain name is set it takes up to 40 minutes before it is initialized. After the certificate is initialized, sls deploy will create the base path mapping and assign the lambda to the custom domain name through CloudFront. All resources are created independent of CloudFormation. However, deploying will also output the domain name and distribution domain name to the CloudFormation stack outputs under the keys DomainName and DistributionDomainName, respectively.
Behavior Change in Version 3
In version 3, we decided to create/update/delete all resources through the API. Previously, only the basepath mapping was managed through CloudFormation. We moved away from creating anything through the stack for two reasons.


It seemed cleaner to have all resources be created in the same fashion, rather than just having one created elsewhere. Since multiple CloudFormation stacks can't create the same custom domain, we decided to have everything be done through the API.


We ran into issues such as #57 where the CloudFormation wasn't always being applied.


However, we still add the domain name and distribution domain name to the CloudFormation outputs, preserving the functionality requested in #43 implemented in #47.
Running Tests
To run unit tests:
npm test
To run integration tests, set an environment variable TEST_DOMAIN to the domain you will be testing for (i.e. example.com if creating a domain for api.example.com).
And ROUTE53_PROFILE for creating route53 record in one AWS account and deploy in another. Then,
export TEST_DOMAIN=example.comexport ROUTE53_PROFILE=defaultexport TLS_TRUSTSTORE_URI=s3://bucket-name/key-nameexport TLS_TRUSTSTORE_VERSION=defaultnpm run buildnpm run integration-test
All tests should pass. All unit tests should pass before merging. Integration tests will take an extremely long time, as DNS records have to propogate for the resources created - therefore, integration tests will not be run on every commit.
If there is an error update the node_modules inside the serverless-domain-manager folder:
npm install
Writing Integration Tests
Unit tests are found in test/unit-tests. Integration tests are found in test/integration-tests. Each folder in tests/integration-tests contains the serverless-domain-manager configuration being tested. To create a new integration test, create a new folder for the handler.js and serverless.yml with the same naming convention and update deploy.test.ts or create a separate one with the test.ts ending.
Changing API Types
AWS API Gateway has three different API types: REST, HTTP, and WebSocket. Special steps need to be taken when migrating from one api type to another. A common migration will be from a REST API to an HTTP API given the potential cost savings. Below are the steps required to change from REST to HTTP. A similar process can be applied for other API type migrations.
REST to HTTP

Confirm the Domain name is a Regional domain name. Edge domains are not supported by AWS for HTTP APIs. See this guide for migrating an edge-optimized custom domain name to regional.
Wait for all DNS changes to take effect/propagate and ensure all traffic is being routed to the regional domain name before proceeding.
Make sure you have setup new or modified existing routes to use httpApi event in your serverless.yml file.
Make the following changes to the customDomain properties in the serverless.yml confg:
endpointType: REGIONALapiType: httpallowPathMatching: true # Only for one deploy

Run sls deploy
Remove the allowPathMatching option, it should only be used once when migrating a base path from one API type to another.

NOTE: Always test this process in a lower level staging or development environment before performing it in production.
Known Issues

(5/23/2017) CloudFormation does not support changing the base path from empty to something or vice a versa. You must run sls remove to remove the base path mapping.
(1/17/2018) The create_domain command provided by this plugin does not currently update an existing Custom Domain's configuration. Instead, it only supports updating the Route 53 record pointing to the Custom Domain. For example, one must delete and recreate a Custom Domain to migrate it from regional to edge or vice versa, or to modify the certificate.
(8/22/2018) Creating a custom domain creates a CloudFront Distribution behind the scenes for fronting your API Gateway. This CloudFront Distribution is managed by AWS and cannot be viewed/managed by you. This is not a bug, but a quirk of how the Custom Domain feature works in API Gateway.
(2/12/2019) Users who upgraded from 2.x.x to version 3.0.4 (now unpublished) and then reverted back to 2.x.x will be unable to deploy because of a bug that will be fixed in 3.1.0. The workaround is to delete the basepath mapping manually, which will let them successfully revert back to 2.x.x.
(1/20/2022) Using route53Profile option requires having hosted zone for the domain in this profile and ACM certificate in the main profile (where functions are deployed).
(2/13/2024) ACM certificate must exist in the us-east-1 for the EDGE endpoint type. https://docs.aws.amazon.com/apigateway/latest/developerguide/how-to-edge-optimized-custom-domain-name.html

Responsible Disclosure
If you have any security issue to report, contact project maintainers privately.
You can reach us at github@amplify.com
Contributing
We welcome pull requests! For your pull request to be accepted smoothly, we suggest that you:

For any sizable change, first open a GitHub issue to discuss your idea.
Create a pull request.  Explain why you want to make the change and what it’s for.
We’ll try to answer any PR’s promptly.\n\n\n\n💨 serverless-esbuild
Serverless Framework plugin for zero-config JavaScript and TypeScript code bundling using promising fast & furious esbuild bundler and minifier





Features

Zero-config: Works out of the box without the need to install any additional plugins
Works with Typescript and Javascript projects
Supports sls package, sls deploy, sls deploy function
Integrates with Serverless Invoke Local & serverless-offline

Table of Contents

Install
Configuration

Examples
Options

Default Esbuild Options
Packager Options
Watch Options




Supported Runtimes
Advanced Configuration

Including Extra Files
External Dependencies
Esbuild Plugins


Usage

Automatic Compilation
Serverless Offline

Serverless Dynamodb Local


Invoke Local


External Tools
Contributors

Install
# install `serverless-esbuild` and `esbuild`yarn add --dev serverless-esbuild esbuild# ornpm install -D serverless-esbuild esbuild# orpnpm install -D serverless-esbuild esbuild
Add the following plugin to your serverless.yml:
plugins:  - serverless-esbuild
Configuration
By default, no configuration is required, but you can override the default behavior via the custom.esbuild section in the serverless.yml file.
custom:  esbuild:    bundle: true    minify: false
Examples
See example folder for some example configurations.
Options









































































































OptionDescriptionDefaultEsbuild OptionsThis plugin can take almost any Esbuild Javascript Build Option.Default Esbuild OptionsconcurrencyThe number of concurrent bundle operations to run at once. eg. 8. NOTE: This can be memory intensive and could produce slower builds.InfinityzipConcurrencyThe number of concurrent zip operations to run at once. eg. 8. NOTE: This can be memory intensive and could produce slower builds.InfinityexcludeAn array of dependencies to exclude from the Lambda. This is passed to the esbuild external option. Set to * to disable packaging node_modules['aws-sdk']installExtraArgsOptional arguments passed to npm or yarn for external dependency resolution. eg. ['--legacy-peer-deps'] for npm v7+ to use legacy peerDependency resolution behavior[]keepOutputDirectoryKeeps the .esbuild output folder. Useful for debugging.falsenativeZipUses the system's zip executable to create archives. NOTE: This will produce non-deterministic archives which causes a Serverless deployment update on every deploy.falseoutputBuildFolderThe output folder for Esbuild builds within the work folder. You will also need to manually override the watch ignore config if used.'.build'outputWorkFolderThe output folder for this plugin where all the bundle preparation is done. You will also need to manually override the watch ignore config if used.'.esbuild'outputFileExtensionThe file extension used for the bundled output file. This will override the esbuild outExtension option'.js'packagePathPath to the package.json file for external dependency resolution.'./package.json'packagerPackager to use for external dependency resolution. Values: npm, yarn, pnpm'npm'packagerOptionsExtra options for packagers for external dependency resolution.Packager OptionswatchWatch options for serverless-offline.Watch OptionsskipBuildAvoid rebuilding lambda artifacts in favor of reusing previous build artifacts.falseskipRebuildA boolean defining whether rebuild is avoided. Generally rebuild produces faster builds but in some context scenarios with many lambdas or low memory computer (like Github Actions) it can cause memory leaks.falseskipBuildExcludeFnsAn array of lambda names that will always be rebuilt if skipBuild is set to true and bundling individually. This is helpful for dynamically generated functions like serverless-plugin-warmup.[]stripEntryResolveExtensionsA boolean that determines if entrypoints using custom file extensions provided in the resolveExtensions ESbuild setting should be stripped of their custom extension upon packing the final bundle for that file. Example: myLambda.custom.ts would result in myLambda.js instead of myLambda.custom.js.disposeContextAn option to disable the disposal of the context.(Functions can override the global disposeContext configuration by specifying their own disposeContext option in their individual configurations.)true
Default Esbuild Options
The following esbuild options are automatically set.








































OptionDefaultNotesbundletrueEsbuild requires this for use with externalentryPointsN/ACannot be overriddenoutDirN/ACannot be overriddenplatform'node'Set format to esm to enable ESM supporttarget'node16'We dynamically set this. See Supported RuntimeswatchN/ACannot be overridden
Packager Options

























OptionDescriptionDefaultscriptsA string or array of scripts to be executed, currently only supports 'scripts' for npm, pnpm and yarnundefinednoInstall[Yarn only] A boolean that deactivates the install stepfalseignoreLockfile[Yarn only] A boolean to bypass lockfile validation, typically paired with external dependencies because we generate a new package.json with only the externalized dependencies.false
Watch Options

























OptionDescriptionDefaultpatternAn anymatch-compatible definition for the watcher to respond to./**/*.(js|ts) (watches all .js and .ts files)ignoreAn anymatch-compatible definition for the watcher to ignore['.esbuild', 'dist', 'node_modules', '.build']chokidarAny Chokidar option{ ignoreInitial: true }
Function Options















OptionDescriptionDefaultskipEsbuildSet this property to true on a function definition to skip esbuildundefined
Supported Runtimes
This plugin will automatically set the esbuild target for the following supported Serverless runtimes:
AWS





























RuntimeTargetnodejs20.xnode20nodejs18.xnode18nodejs16.xnode16nodejs14.xnode14nodejs12.xnode12
Google
This plugin is compatible with the serverless-google-cloudfunctions plugin, and will set the runtimes accordingly.





























RuntimeTargetnodejs20node20nodejs18node18nodejs16node16nodejs14node14nodejs12node12
Azure
This plugin is compatible with the serverless-azure-functions plugin, and will set the runtimes accordingly.

























RuntimeTargetnodejs18node18nodejs16node16nodejs14node14nodejs12node12
Please Note When using this package in conjunction with the serverless-azure-functions plugin, the following additional configuration is required to ensure function apps are built correctly:
package:	patterns: ["host.json", "**/function.json"],
Non-Node functions
If you wish to use this plugin alongside non Node functions like Python or functions with images, this plugin will automatically ignore any function which does not contain a handler or use a supported Node.js runtime.
Note: If you are using Python functions with Serverless Offline you will need to change the outputWorkFolder and outputBuildFolder to folder names without fullstops.
Advanced Configuration
Config file
Esbuild configuration can be defined by a config file.
custom:  esbuild:    config: './esbuild.config.js'
// esbuild.config.jsmodule.exports = (serverless) => ({  external: ['lodash'],  plugins: [],});
Including Extra Files
Serverless Package Configuration will behave in the same way as native packaging. You can use patterns, include and exclude to include extra files into your bundles.
External Dependencies
Packages that are marked as external and exist in the package.json's dependencies will be installed and included with your build under node_modules. You can customize this with a number of options.
custom:  esbuild:    external:      - lodash    packager: yarn    packagePath: absolute/path/to/package.json    packagerOptions:      scripts:        - echo 'Hello World!'        - rm -rf node_modules    installExtraArgs:      - '--legacy-peer-deps'
To easily mark all the dependencies in package.json as external, you can utilize esbuild-node-externals plugin.
To mark one or more individual packages as external, use the following configuration:
custom:  esbuild:    external:      - 'my-package-name'      - 'another-package-name'
Esbuild Plugins
Note: The Esbuild plugins API is still experimental
You can configure esbuild plugins by passing a plugins' configuration file:
custom:  esbuild:    plugins: plugins.js
The plugins' configuration file must be a javascript file exporting an array of plugins (see examples/individually/plugins.js for a dummy plugin example):
let myPlugin = {  name: 'my-plugin',  setup(build) {    // plugin implementation  },};// default export should be an array of pluginsmodule.exports = [myPlugin];
or a function that accepts serverless instance and returns an array of plugins (see issue #168 for an example):
module.exports = (serverless) => {  const myPlugin = {    name: 'my-plugin',    setup(build) {      // plugin implementation with `serverless` instance access      console.log('sls custom options', serverless.service.custom);    },  };  // an array of plugins must be returned  return [myPlugin];};
Usage
Automatic compilation
As long as the plugin is properly installed, all regular Serverless operations sls package, sls deploy, sls deploy function, sls invoke local, sls offline will automatically compile using serverless-esbuild.
Serverless Offline
The plugin integrates very well with serverless-offline to
simulate AWS Lambda and AWS API Gateway locally.
Add the plugins to your serverless.yml file and make sure that serverless-esbuild
precedes serverless-offline as the order is important:
plugins: ...  - serverless-esbuild  ...  - serverless-offline  ...
Run serverless offline or serverless offline start to start the Lambda/API simulation.
In comparison to serverless offline, the start command will fire an init and a end lifecycle hook which is needed for serverless-offline and e.g. serverless-dynamodb-local to switch off resources (see below)
Automatic compilation is available while using the plugin with serverless-offline.
custom:  esbuild:    watch:      pattern: ['src/**/*.ts'] # match only typescript files in src directory      ignore: ['temp/**/*']
Note: When overriding the ignore pattern, remember to ignore .build directory to avoid endless compilation.
Serverless Dynamodb Local
Configure your service the same as mentioned above, but additionally add the serverless-dynamodb-local
plugin as follows:
plugins:  - serverless-esbuild  - serverless-dynamodb-local  - serverless-offline
Run serverless offline start.
Invoke Local
This plugin supports the Serverless Invoke Local functionality and will automatically compile the selected function.
External Tools

serverless-analyze-bundle-plugin: a plugin that allow users to analyze the bundle of a lambda

Contributors




  
    
      Victor Korzunin💬 💻 📖 💡 🤔 🚇 🚧 🔌 📆 👀 ⚠️ 🔧
      Loup Topalian💬 💻 📖 🚇 🚧 🔌
      Sam Chung💬 💻 📖 💡 🚇 🚧 🔌 👀 🔧
      Vamsi Dharmavarapu💻 📖 💡 🚇 🚧
      Eric💻 🤔 🚧 🚇 👀
      Chris💻 🤔
      Martín Acosta💻
    
    
      Tony Tyrrell💻
      Matt Jennings💻
      Misha Bruml💻
      François Farge💻
      Sam Hulick📖
      Troy Ready💻
      subash adhikari💻
    
    
      Dan Ionescu💻
      gurushida💻
      nickygb💻
      Jiri Spac💻
      gavynriebau📖
      Adrien Cacciaguerra📖
      lulzneko💻
    
    
      AOKI Yuuto💻
      Thomas Aribart🤔
      Kory Hutchison💻 🤔
      Chris Hutchinson💻
      Fredrik Möllerstrand💻
      Sander Kooger💻
      Adam Swift💻
    
    
      Florian Mayer💻
      Zach Levi💻
    
  



Inspired by serverless-plugin-typescript and serverless-webpack\n\nPluginsServerless Esbuild💨 serverless-esbuild
Serverless Framework plugin for zero-config JavaScript and TypeScript code bundling using promising fast & furious esbuild bundler and minifier





Features

Zero-config: Works out of the box without the need to install any additional plugins
Works with Typescript and Javascript projects
Supports sls package, sls deploy, sls deploy function
Integrates with Serverless Invoke Local & serverless-offline

Table of Contents

Install
Configuration

Examples
Options

Default Esbuild Options
Packager Options
Watch Options




Supported Runtimes
Advanced Configuration

Including Extra Files
External Dependencies
Esbuild Plugins


Usage

Automatic Compilation
Serverless Offline

Serverless Dynamodb Local


Invoke Local


External Tools
Contributors

Install
# install `serverless-esbuild` and `esbuild`yarn add --dev serverless-esbuild esbuild# ornpm install -D serverless-esbuild esbuild# orpnpm install -D serverless-esbuild esbuild
Add the following plugin to your serverless.yml:
plugins:  - serverless-esbuild
Configuration
By default, no configuration is required, but you can override the default behavior via the custom.esbuild section in the serverless.yml file.
custom:  esbuild:    bundle: true    minify: false
Examples
See example folder for some example configurations.
Options









































































































OptionDescriptionDefaultEsbuild OptionsThis plugin can take almost any Esbuild Javascript Build Option.Default Esbuild OptionsconcurrencyThe number of concurrent bundle operations to run at once. eg. 8. NOTE: This can be memory intensive and could produce slower builds.InfinityzipConcurrencyThe number of concurrent zip operations to run at once. eg. 8. NOTE: This can be memory intensive and could produce slower builds.InfinityexcludeAn array of dependencies to exclude from the Lambda. This is passed to the esbuild external option. Set to * to disable packaging node_modules['aws-sdk']installExtraArgsOptional arguments passed to npm or yarn for external dependency resolution. eg. ['--legacy-peer-deps'] for npm v7+ to use legacy peerDependency resolution behavior[]keepOutputDirectoryKeeps the .esbuild output folder. Useful for debugging.falsenativeZipUses the system's zip executable to create archives. NOTE: This will produce non-deterministic archives which causes a Serverless deployment update on every deploy.falseoutputBuildFolderThe output folder for Esbuild builds within the work folder. You will also need to manually override the watch ignore config if used.'.build'outputWorkFolderThe output folder for this plugin where all the bundle preparation is done. You will also need to manually override the watch ignore config if used.'.esbuild'outputFileExtensionThe file extension used for the bundled output file. This will override the esbuild outExtension option'.js'packagePathPath to the package.json file for external dependency resolution.'./package.json'packagerPackager to use for external dependency resolution. Values: npm, yarn, pnpm'npm'packagerOptionsExtra options for packagers for external dependency resolution.Packager OptionswatchWatch options for serverless-offline.Watch OptionsskipBuildAvoid rebuilding lambda artifacts in favor of reusing previous build artifacts.falseskipRebuildA boolean defining whether rebuild is avoided. Generally rebuild produces faster builds but in some context scenarios with many lambdas or low memory computer (like Github Actions) it can cause memory leaks.falseskipBuildExcludeFnsAn array of lambda names that will always be rebuilt if skipBuild is set to true and bundling individually. This is helpful for dynamically generated functions like serverless-plugin-warmup.[]stripEntryResolveExtensionsA boolean that determines if entrypoints using custom file extensions provided in the resolveExtensions ESbuild setting should be stripped of their custom extension upon packing the final bundle for that file. Example: myLambda.custom.ts would result in myLambda.js instead of myLambda.custom.js.disposeContextAn option to disable the disposal of the context.(Functions can override the global disposeContext configuration by specifying their own disposeContext option in their individual configurations.)true
Default Esbuild Options
The following esbuild options are automatically set.








































OptionDefaultNotesbundletrueEsbuild requires this for use with externalentryPointsN/ACannot be overriddenoutDirN/ACannot be overriddenplatform'node'Set format to esm to enable ESM supporttarget'node16'We dynamically set this. See Supported RuntimeswatchN/ACannot be overridden
Packager Options

























OptionDescriptionDefaultscriptsA string or array of scripts to be executed, currently only supports 'scripts' for npm, pnpm and yarnundefinednoInstall[Yarn only] A boolean that deactivates the install stepfalseignoreLockfile[Yarn only] A boolean to bypass lockfile validation, typically paired with external dependencies because we generate a new package.json with only the externalized dependencies.false
Watch Options

























OptionDescriptionDefaultpatternAn anymatch-compatible definition for the watcher to respond to./**/*.(js|ts) (watches all .js and .ts files)ignoreAn anymatch-compatible definition for the watcher to ignore['.esbuild', 'dist', 'node_modules', '.build']chokidarAny Chokidar option{ ignoreInitial: true }
Function Options















OptionDescriptionDefaultskipEsbuildSet this property to true on a function definition to skip esbuildundefined
Supported Runtimes
This plugin will automatically set the esbuild target for the following supported Serverless runtimes:
AWS





























RuntimeTargetnodejs20.xnode20nodejs18.xnode18nodejs16.xnode16nodejs14.xnode14nodejs12.xnode12
Google
This plugin is compatible with the serverless-google-cloudfunctions plugin, and will set the runtimes accordingly.





























RuntimeTargetnodejs20node20nodejs18node18nodejs16node16nodejs14node14nodejs12node12
Azure
This plugin is compatible with the serverless-azure-functions plugin, and will set the runtimes accordingly.

























RuntimeTargetnodejs18node18nodejs16node16nodejs14node14nodejs12node12
Please Note When using this package in conjunction with the serverless-azure-functions plugin, the following additional configuration is required to ensure function apps are built correctly:
package:	patterns: ["host.json", "**/function.json"],
Non-Node functions
If you wish to use this plugin alongside non Node functions like Python or functions with images, this plugin will automatically ignore any function which does not contain a handler or use a supported Node.js runtime.
Note: If you are using Python functions with Serverless Offline you will need to change the outputWorkFolder and outputBuildFolder to folder names without fullstops.
Advanced Configuration
Config file
Esbuild configuration can be defined by a config file.
custom:  esbuild:    config: './esbuild.config.js'
// esbuild.config.jsmodule.exports = (serverless) => ({  external: ['lodash'],  plugins: [],});
Including Extra Files
Serverless Package Configuration will behave in the same way as native packaging. You can use patterns, include and exclude to include extra files into your bundles.
External Dependencies
Packages that are marked as external and exist in the package.json's dependencies will be installed and included with your build under node_modules. You can customize this with a number of options.
custom:  esbuild:    external:      - lodash    packager: yarn    packagePath: absolute/path/to/package.json    packagerOptions:      scripts:        - echo 'Hello World!'        - rm -rf node_modules    installExtraArgs:      - '--legacy-peer-deps'
To easily mark all the dependencies in package.json as external, you can utilize esbuild-node-externals plugin.
To mark one or more individual packages as external, use the following configuration:
custom:  esbuild:    external:      - 'my-package-name'      - 'another-package-name'
Esbuild Plugins
Note: The Esbuild plugins API is still experimental
You can configure esbuild plugins by passing a plugins' configuration file:
custom:  esbuild:    plugins: plugins.js
The plugins' configuration file must be a javascript file exporting an array of plugins (see examples/individually/plugins.js for a dummy plugin example):
let myPlugin = {  name: 'my-plugin',  setup(build) {    // plugin implementation  },};// default export should be an array of pluginsmodule.exports = [myPlugin];
or a function that accepts serverless instance and returns an array of plugins (see issue #168 for an example):
module.exports = (serverless) => {  const myPlugin = {    name: 'my-plugin',    setup(build) {      // plugin implementation with `serverless` instance access      console.log('sls custom options', serverless.service.custom);    },  };  // an array of plugins must be returned  return [myPlugin];};
Usage
Automatic compilation
As long as the plugin is properly installed, all regular Serverless operations sls package, sls deploy, sls deploy function, sls invoke local, sls offline will automatically compile using serverless-esbuild.
Serverless Offline
The plugin integrates very well with serverless-offline to
simulate AWS Lambda and AWS API Gateway locally.
Add the plugins to your serverless.yml file and make sure that serverless-esbuild
precedes serverless-offline as the order is important:
plugins: ...  - serverless-esbuild  ...  - serverless-offline  ...
Run serverless offline or serverless offline start to start the Lambda/API simulation.
In comparison to serverless offline, the start command will fire an init and a end lifecycle hook which is needed for serverless-offline and e.g. serverless-dynamodb-local to switch off resources (see below)
Automatic compilation is available while using the plugin with serverless-offline.
custom:  esbuild:    watch:      pattern: ['src/**/*.ts'] # match only typescript files in src directory      ignore: ['temp/**/*']
Note: When overriding the ignore pattern, remember to ignore .build directory to avoid endless compilation.
Serverless Dynamodb Local
Configure your service the same as mentioned above, but additionally add the serverless-dynamodb-local
plugin as follows:
plugins:  - serverless-esbuild  - serverless-dynamodb-local  - serverless-offline
Run serverless offline start.
Invoke Local
This plugin supports the Serverless Invoke Local functionality and will automatically compile the selected function.
External Tools

serverless-analyze-bundle-plugin: a plugin that allow users to analyze the bundle of a lambda

Contributors




  
    
      Victor Korzunin💬 💻 📖 💡 🤔 🚇 🚧 🔌 📆 👀 ⚠️ 🔧
      Loup Topalian💬 💻 📖 🚇 🚧 🔌
      Sam Chung💬 💻 📖 💡 🚇 🚧 🔌 👀 🔧
      Vamsi Dharmavarapu💻 📖 💡 🚇 🚧
      Eric💻 🤔 🚧 🚇 👀
      Chris💻 🤔
      Martín Acosta💻
    
    
      Tony Tyrrell💻
      Matt Jennings💻
      Misha Bruml💻
      François Farge💻
      Sam Hulick📖
      Troy Ready💻
      subash adhikari💻
    
    
      Dan Ionescu💻
      gurushida💻
      nickygb💻
      Jiri Spac💻
      gavynriebau📖
      Adrien Cacciaguerra📖
      lulzneko💻
    
    
      AOKI Yuuto💻
      Thomas Aribart🤔
      Kory Hutchison💻 🤔
      Chris Hutchinson💻
      Fredrik Möllerstrand💻
      Sander Kooger💻
      Adam Swift💻
    
    
      Florian Mayer💻
      Zach Levi💻
    
  



Inspired by serverless-plugin-typescript and serverless-webpack\n\n\n\nserverless-http
Description
This module allows you to 'wrap' your API for serverless use. No HTTP server, no ports or sockets. Just your code in the same execution pipeline you are already familiar with.
Sponsors
Thank you to Upstash for reaching out to sponsor this project!

  
  
  
  
Upstash: Serverless Database for Redis
  
    Serverless Redis with global replication and durable storage
    Price scales to zero with per request pricing
    Built-in REST API designed for serverless and edge functions
  
Start for free in 30 seconds!

Support
Supported Frameworks
(* Experimental)

Node (http.createServer)
Connect
Express
Koa
Restana
Sails *
Hapi *
Fastify *
Restify *
Polka *
Loopback *

Supported Providers

AWS
Genezio
Azure (Experimental, untested, probably outdated)

Deploy a Hello Word on Genezio
:rocket: You can deploy your own hello world example using the Express framework to Genezio with one click:

Examples
Please check the examples folder!
Usage example using the Koa framework
const serverless = require('serverless-http');const Koa = require('koa'); // or any supported frameworkconst app = new Koa();app.use(/* register your middleware as normal */);// this is it!module.exports.handler = serverless(app);// or as a promiseconst handler = serverless(app);module.exports.handler = async (event, context) => {  // you can do other things here  const result = await handler(event, context);  // and here  return result;};
Usage example using the Express framework with Azure
const serverless = require('serverless-http');const express = require('express');const app = express();app.use(/* register your middleware as normal */);const handler = serverless(app, { provider: 'azure' });module.exports.funcName = async (context, req) => {  context.res = await handler(context, req);}
Other examples
json-server-less-λ - using serverless-http with json-server and serverless framework in AWS
Limitations
Your code is running in a serverless environment. You cannot rely on your server being 'up' in the sense that you can/should not use in-memory sessions, web sockets, etc. You are also subject to provider specific restrictions on request/response size, duration, etc.

Think of this as a familiar way of expressing your app logic, not trying to make serverless do something it cannot.

Contributing
Pull requests are welcome! Especially test scenarios for different situations and configurations.
Further Reading
Here are some more detailed examples and advanced configuration options as well as provider-specific documentation\n\nPluginsServerless HTTPserverless-http
Description
This module allows you to 'wrap' your API for serverless use. No HTTP server, no ports or sockets. Just your code in the same execution pipeline you are already familiar with.
Sponsors
Thank you to Upstash for reaching out to sponsor this project!

  
  
  
  
Upstash: Serverless Database for Redis
  
    Serverless Redis with global replication and durable storage
    Price scales to zero with per request pricing
    Built-in REST API designed for serverless and edge functions
  
Start for free in 30 seconds!

Support
Supported Frameworks
(* Experimental)

Node (http.createServer)
Connect
Express
Koa
Restana
Sails *
Hapi *
Fastify *
Restify *
Polka *
Loopback *

Supported Providers

AWS
Genezio
Azure (Experimental, untested, probably outdated)

Deploy a Hello Word on Genezio
:rocket: You can deploy your own hello world example using the Express framework to Genezio with one click:

Examples
Please check the examples folder!
Usage example using the Koa framework
const serverless = require('serverless-http');const Koa = require('koa'); // or any supported frameworkconst app = new Koa();app.use(/* register your middleware as normal */);// this is it!module.exports.handler = serverless(app);// or as a promiseconst handler = serverless(app);module.exports.handler = async (event, context) => {  // you can do other things here  const result = await handler(event, context);  // and here  return result;};
Usage example using the Express framework with Azure
const serverless = require('serverless-http');const express = require('express');const app = express();app.use(/* register your middleware as normal */);const handler = serverless(app, { provider: 'azure' });module.exports.funcName = async (context, req) => {  context.res = await handler(context, req);}
Other examples
json-server-less-λ - using serverless-http with json-server and serverless framework in AWS
Limitations
Your code is running in a serverless environment. You cannot rely on your server being 'up' in the sense that you can/should not use in-memory sessions, web sockets, etc. You are also subject to provider specific restrictions on request/response size, duration, etc.

Think of this as a familiar way of expressing your app logic, not trying to make serverless do something it cannot.

Contributing
Pull requests are welcome! Especially test scenarios for different situations and configurations.
Further Reading
Here are some more detailed examples and advanced configuration options as well as provider-specific documentation\n\n\n\nserverless-dotenv-plugin



Preload function environment variables into Serverless. Use this plugin if you have variables stored in a .env file that you want loaded into your functions.
This used to also preload environment variables into your serverless.yml config, but no longer does with serverless>=2.26.0.
See this discussion thread or the FAQ below for details on the impact of how environment variables are loaded with serverless>=2.26.0 and serverless>=3.0.0.**
Do you need this plugin?
Serverless Framework can now natively resolve ${env:xxx} variables from .env files by setting useDotenv: true in the configuration:
useDotenv: trueprovider:  environment:    FOO: ${env:FOO}
For more complex situations, you will need to wire up dotenv yourself.
This plugin is only useful if you want to automatically import all variables from .env into functions:
plugins:  - serverless-dotenv-pluginprovider:  environment:    # With the plugin enabled, all variables in .env are automatically imported
Install and Setup
First, install the plugin:
> npm i -D serverless-dotenv-plugin
Next, add the plugin to your serverless config file:
service: myServiceplugins:  - serverless-dotenv-plugin...
Now, just like you would using dotenv in any other JS application, create your .env file in the root of your app:
DYNAMODB_TABLE=myTableAWS_REGION=us-west-1AUTH0_CLIENT_ID=abc12345AUTH0_CLIENT_SECRET=12345xyz
When deploying, all the variables listed in .env will automatically be available in the deployed functions.
Automatic ENV File Resolution
By default, the plugin looks for the file: .env. In most use cases this is all that is needed. However, there are times where you want different env files based on environment. For instance:
.env.development.env.production
When you deploy with NODE_ENV set: NODE_ENV=production sls deploy the plugin will look for files named .env, .env.production, .env.production.local. If for some reason you can't set NODE_ENV, you could always just pass it in as an option: sls deploy --env production or sls deploy --stage production. If NODE_ENV, --env or --stage is not set, it will default to development.
DEPRECATION WARNING: as of serverless>=3.0.0, --env will not be supported due to changes to the Serverless Framework.
See FAQ for details.
The precedence between the options is the following:
NODE_ENV > --env > --stage
The env resolution pattern follows the one used by Rail's dotenv and create-react-app





























Valid .env file namesDescription.envDefault file, always included.env.localIncluded in all environments except test.env.developmentIf NODE_ENV or --env or --stage is not set, will try to load .env.development..env.{ENV}If NODE_ENV or --env or --stage is set, will try to load .env.{env}..env.{ENV}.localEvery env set up in .env.{ENV}.local will override other envs

Note: .env, .env.development, and .env.production files should be included in your repository as they define defaults. .env*.local should be added to .gitignore, as those files are intended to be ignored. .env.local is where secrets can be stored.

Lambda Environment Variables
Again, remember that when you deploy your service, the plugin will inject these environment vars into every lambda functions you have and will therefore allow you to reference them as process.env.AUTH0_CLIENT_ID (Nodejs example). If this behaviour is not desireable, set include to [].
Plugin options
All options are optional.
custom:  dotenv:    # default: project root    path: path/to/my/dotenvfiles    # if set, ignores `path` option, and only uses the dotenv file at this location    # basePath: path/to/my/.env    # if set, uses provided dotenv parser function instead of built-in function    dotenvParser: dotenv.config.js    # default: adds all env variables found in your dotenv file(s)    # this option must be set to `[]` if `provider.environment` is not a literal string    include:      - DDB_TABLE      - S3_BUCKET    # default: does not exclude any env variables found in your dotenv file(s)    # does nothing if `include` is set    exclude:      - AWS_ACCESS_KEY_ID      - AWS_SECRET_ACCESS_KEY      - AWS_SESSION_TOKEN      - NODE_ENV              # Can not be declared for Google Cloud Functions    # defaults to `true`    logging: false    # default: plugin does not cause an error if any file or env variable is missing    required:      # default: []      env:        - API_KEY      # default: false      file: true    # default: true    variableExpansion: false


path (string)

The plugin will look for your .env file in the same folder where you run the command using the file resolution rules as described above, but these rules can be overridden by setting the path option.
This will disable automatic env file resolution.



basePath (string)

The problem with setting the path option is that you lose environment resolution on the file names.
If you don't need environment resolution, the path option is just fine.



dotenvParser (string)

Path to a custom dotenv parser, relative to the project root (same level as serverless.yml).
Parameters passed into the function: { dotenv, paths }.

dotenv: dotenv library provided for you or you can bring your own
paths: all the dotenv files discovered by the plugin, ordered by precedence (see Automatic ENV File Resolution above for details)


This function must return a single object, where each key/value pair represents the env var name and value.
By default, this uses the built-in parser, which calls dotenv followed by dotenv-expand for each file.



include (list or '*') (default: '*')

All env vars found in your file will be injected into your lambda functions.
If you do not want all of them to be injected into your lambda functions, you can specify the ones you want with the include option.
If set to '*', all env vars in all dotenv files will be injected.
If set to an empty list ([]), no env vars will be injected.
This option must be set to [] if provider.environment is not a literal string (see FAQ for details).



exclude (list)

If you do not want all of them to be injected into your lambda functions, you can specify the ones you do not want with the exclude option.
Note, this is only available if the include option has not been set.



logging: true|false

Supresses all logging done by this plugin if no errors are encountered.



required

env: (list)

A set of env var that must be set either in the Serverless environment or via a dotenv file.
Throws an error if a required env var is not found.
By default, no env vars are required.


file: true|false (default false)

By default, this plugin will exit gracefully and allow Serverless to continue even if it couldn't find a .env file to use.
Set this to true to cause Serverless to halt if it could not find a .env file to use.





v4BreakingChanges: true|false (default false)

Set this to true to introduce v3.x.x => v4.x.x breaking changes now



variableExpansion: true|false (default true)

By default, variables can reference other variables

E.g. INNER_ENV=innerenv, OUTER_ENV=hi-$INNER_ENV, would resolve to INNER_ENV=innerenv, OUTER_ENV=hi-innerenv


Setting this to false will disable this feature

E.g. INNER_ENV=innerenv, OUTER_ENV=hi-$INNER_ENV, would resolve to INNER_ENV=innerenv, OUTER_ENV=hi-$INNER_ENV





Example dotenvParser file:
// You can bring your own or use the one provided by the pluginconst dotenv = require('dotenv')const dotenvExpand = require('dotenv-expand')module.exports = function({ dotenv, paths }) {  const envVarsArray = [...paths]    .reverse()    .map(path => {      const parsed = dotenv.config({ path })      return dotenvExpand(parsed).parsed    })  return envVarsArray.reduce((acc, curr) => ({ ...acc, ...curr }), {})}
Examples
You can find example usage in the examples folder.
Changelog
The changelog is available in the CHANGELOG.md file in the package or on GitHub.
FAQ
This plugin loads the dotenv environment variables inside the plugin constructor. Aside from legacy reasons, this also means all your dotenv environment variables are available to the other plugins being loaded.
However, Serverless variables are not resolved in the constructor:

Variable references in the serverless instance are not resolved before a Plugin's constructor is called, so if you need these, make sure to wait to access those from your hooks.
~https://www.serverless.com/framework/docs/providers/aws/guide/plugins/#plugins/

This is important for several FAQ items below.
How has changes to the Serverless Framework affected when environment variables are loaded?
serverless>=2.26.0
serverless/serverless#8987 changed the order of when plugins are initialized in relationship to variable resolution as part of a larger initiative outlined in serverless/serverless#8364. Because of this, any env var references inside JavaScript files will now get evaluated too early in the process.
serverless>=3.0.0
env variables will get resolved before this plugin is initialized. This means env variables inside serverless.yml can no longer rely on this plugin to load them from dotenv files. See serverless/serverless#8364 for more details on the changes made to the Serverless Framework variables engine.
The Serverless Framework has basic dotenv support built-in. For support with more complicated workflows with dotenv, see serverless-dotenv-example for details.
You can continue to use this plugin to automatically load environment variables into all your functions using dotenv.
How has changes to the Serverless Framework affected configuration options?
See deprecation code UNSUPPORTED_CLI_OPTIONS for more details.
This was introduced in serverless/serverless#9171.
serverless>=2.32.0
Using the --env CLI option will now result in the following warning:
Detected unrecognized CLI options: "--env".Starting with the next major, Serverless Framework will report them with a thrown errorMore Info: https://www.serverless.com/framework/docs/deprecations/#UNSUPPORTED_CLI_OPTIONS
serverless>=3.0.0
Using the --env CLI option will now result in the following error:
Error:Detected unrecognized CLI options: "--env".
Why do env vars already defined by the system take higher precedence?
The Serverless Framework has basic dotenv support built-in. If you are loading variables from .env at the project root, it is possible the Serverless Framework preloads that env var before this plugin does.
As well, because of the variables engine changed in serverless>=2.26.0 (see above), env variables can also be resolved before this plugin runs, which means Serverless could take the values already defined in the system before the plugin loads env vars via dotenv.
Why doesn't the basePath or path options support Serverless variables?
Because Serverless variables have not been interpolated when this plugin runs, basePath and path will always be treated like literal strings (e.g. ${opt:stage} would be presented to the plugin, not the passed in via --stage). The suggested pattern is to store all your dotenv files in one folder, and rely on NODE_ENV, --env, or --stage to resolve to the right file.
There are no plans to support anything other than literal strings at this time, although you are free to discuss this in #52.
Why doesn't this plugin work when provider.environment references another file?
Upgrade to serverless>=2.26.0. The new variables engine introduced in the Serverless Framework in v2.26.0 now resolves file variables first before loading initializing any plugins.
Before v2.26.0, Serverless variables do not get interpolated before this plugin gets initialized, causing provider.environment to be presented to this plugin uninterpolated (e.g. ${file(./serverless-env.yml):environment}). Because of this, the plugin tries to append items to a string instead of a list.
To work around this, you can set the include option to [] to avoid adding any environment variables to provider.environment. However, this means you will have to wire up the environment variables yourself by referencing every single one you need. E.g.
provider:  environment:    - DDB_TABLE: ${env:DDB_TABLE}
More details are available at #38.
Contributing
Because of the highly dependent nature of this plugin (i.e. thousands of developers depend on this to deploy their apps to production) I cannot introduce changes that are backwards incompatible. Any feature requests must first consider this as a blocker. If submitting a PR ensure that the change is developer opt-in only meaning it must guarantee that it will not affect existing workflows, it's only available with an opt-in setting. I appreciate your patience on this. Thanks.\n\nPluginsServerless Dotenv Pluginserverless-dotenv-plugin



Preload function environment variables into Serverless. Use this plugin if you have variables stored in a .env file that you want loaded into your functions.
This used to also preload environment variables into your serverless.yml config, but no longer does with serverless>=2.26.0.
See this discussion thread or the FAQ below for details on the impact of how environment variables are loaded with serverless>=2.26.0 and serverless>=3.0.0.**
Do you need this plugin?
Serverless Framework can now natively resolve ${env:xxx} variables from .env files by setting useDotenv: true in the configuration:
useDotenv: trueprovider:  environment:    FOO: ${env:FOO}
For more complex situations, you will need to wire up dotenv yourself.
This plugin is only useful if you want to automatically import all variables from .env into functions:
plugins:  - serverless-dotenv-pluginprovider:  environment:    # With the plugin enabled, all variables in .env are automatically imported
Install and Setup
First, install the plugin:
> npm i -D serverless-dotenv-plugin
Next, add the plugin to your serverless config file:
service: myServiceplugins:  - serverless-dotenv-plugin...
Now, just like you would using dotenv in any other JS application, create your .env file in the root of your app:
DYNAMODB_TABLE=myTableAWS_REGION=us-west-1AUTH0_CLIENT_ID=abc12345AUTH0_CLIENT_SECRET=12345xyz
When deploying, all the variables listed in .env will automatically be available in the deployed functions.
Automatic ENV File Resolution
By default, the plugin looks for the file: .env. In most use cases this is all that is needed. However, there are times where you want different env files based on environment. For instance:
.env.development.env.production
When you deploy with NODE_ENV set: NODE_ENV=production sls deploy the plugin will look for files named .env, .env.production, .env.production.local. If for some reason you can't set NODE_ENV, you could always just pass it in as an option: sls deploy --env production or sls deploy --stage production. If NODE_ENV, --env or --stage is not set, it will default to development.
DEPRECATION WARNING: as of serverless>=3.0.0, --env will not be supported due to changes to the Serverless Framework.
See FAQ for details.
The precedence between the options is the following:
NODE_ENV > --env > --stage
The env resolution pattern follows the one used by Rail's dotenv and create-react-app





























Valid .env file namesDescription.envDefault file, always included.env.localIncluded in all environments except test.env.developmentIf NODE_ENV or --env or --stage is not set, will try to load .env.development..env.{ENV}If NODE_ENV or --env or --stage is set, will try to load .env.{env}..env.{ENV}.localEvery env set up in .env.{ENV}.local will override other envs

Note: .env, .env.development, and .env.production files should be included in your repository as they define defaults. .env*.local should be added to .gitignore, as those files are intended to be ignored. .env.local is where secrets can be stored.

Lambda Environment Variables
Again, remember that when you deploy your service, the plugin will inject these environment vars into every lambda functions you have and will therefore allow you to reference them as process.env.AUTH0_CLIENT_ID (Nodejs example). If this behaviour is not desireable, set include to [].
Plugin options
All options are optional.
custom:  dotenv:    # default: project root    path: path/to/my/dotenvfiles    # if set, ignores `path` option, and only uses the dotenv file at this location    # basePath: path/to/my/.env    # if set, uses provided dotenv parser function instead of built-in function    dotenvParser: dotenv.config.js    # default: adds all env variables found in your dotenv file(s)    # this option must be set to `[]` if `provider.environment` is not a literal string    include:      - DDB_TABLE      - S3_BUCKET    # default: does not exclude any env variables found in your dotenv file(s)    # does nothing if `include` is set    exclude:      - AWS_ACCESS_KEY_ID      - AWS_SECRET_ACCESS_KEY      - AWS_SESSION_TOKEN      - NODE_ENV              # Can not be declared for Google Cloud Functions    # defaults to `true`    logging: false    # default: plugin does not cause an error if any file or env variable is missing    required:      # default: []      env:        - API_KEY      # default: false      file: true    # default: true    variableExpansion: false


path (string)

The plugin will look for your .env file in the same folder where you run the command using the file resolution rules as described above, but these rules can be overridden by setting the path option.
This will disable automatic env file resolution.



basePath (string)

The problem with setting the path option is that you lose environment resolution on the file names.
If you don't need environment resolution, the path option is just fine.



dotenvParser (string)

Path to a custom dotenv parser, relative to the project root (same level as serverless.yml).
Parameters passed into the function: { dotenv, paths }.

dotenv: dotenv library provided for you or you can bring your own
paths: all the dotenv files discovered by the plugin, ordered by precedence (see Automatic ENV File Resolution above for details)


This function must return a single object, where each key/value pair represents the env var name and value.
By default, this uses the built-in parser, which calls dotenv followed by dotenv-expand for each file.



include (list or '*') (default: '*')

All env vars found in your file will be injected into your lambda functions.
If you do not want all of them to be injected into your lambda functions, you can specify the ones you want with the include option.
If set to '*', all env vars in all dotenv files will be injected.
If set to an empty list ([]), no env vars will be injected.
This option must be set to [] if provider.environment is not a literal string (see FAQ for details).



exclude (list)

If you do not want all of them to be injected into your lambda functions, you can specify the ones you do not want with the exclude option.
Note, this is only available if the include option has not been set.



logging: true|false

Supresses all logging done by this plugin if no errors are encountered.



required

env: (list)

A set of env var that must be set either in the Serverless environment or via a dotenv file.
Throws an error if a required env var is not found.
By default, no env vars are required.


file: true|false (default false)

By default, this plugin will exit gracefully and allow Serverless to continue even if it couldn't find a .env file to use.
Set this to true to cause Serverless to halt if it could not find a .env file to use.





v4BreakingChanges: true|false (default false)

Set this to true to introduce v3.x.x => v4.x.x breaking changes now



variableExpansion: true|false (default true)

By default, variables can reference other variables

E.g. INNER_ENV=innerenv, OUTER_ENV=hi-$INNER_ENV, would resolve to INNER_ENV=innerenv, OUTER_ENV=hi-innerenv


Setting this to false will disable this feature

E.g. INNER_ENV=innerenv, OUTER_ENV=hi-$INNER_ENV, would resolve to INNER_ENV=innerenv, OUTER_ENV=hi-$INNER_ENV





Example dotenvParser file:
// You can bring your own or use the one provided by the pluginconst dotenv = require('dotenv')const dotenvExpand = require('dotenv-expand')module.exports = function({ dotenv, paths }) {  const envVarsArray = [...paths]    .reverse()    .map(path => {      const parsed = dotenv.config({ path })      return dotenvExpand(parsed).parsed    })  return envVarsArray.reduce((acc, curr) => ({ ...acc, ...curr }), {})}
Examples
You can find example usage in the examples folder.
Changelog
The changelog is available in the CHANGELOG.md file in the package or on GitHub.
FAQ
This plugin loads the dotenv environment variables inside the plugin constructor. Aside from legacy reasons, this also means all your dotenv environment variables are available to the other plugins being loaded.
However, Serverless variables are not resolved in the constructor:

Variable references in the serverless instance are not resolved before a Plugin's constructor is called, so if you need these, make sure to wait to access those from your hooks.
~https://www.serverless.com/framework/docs/providers/aws/guide/plugins/#plugins/

This is important for several FAQ items below.
How has changes to the Serverless Framework affected when environment variables are loaded?
serverless>=2.26.0
serverless/serverless#8987 changed the order of when plugins are initialized in relationship to variable resolution as part of a larger initiative outlined in serverless/serverless#8364. Because of this, any env var references inside JavaScript files will now get evaluated too early in the process.
serverless>=3.0.0
env variables will get resolved before this plugin is initialized. This means env variables inside serverless.yml can no longer rely on this plugin to load them from dotenv files. See serverless/serverless#8364 for more details on the changes made to the Serverless Framework variables engine.
The Serverless Framework has basic dotenv support built-in. For support with more complicated workflows with dotenv, see serverless-dotenv-example for details.
You can continue to use this plugin to automatically load environment variables into all your functions using dotenv.
How has changes to the Serverless Framework affected configuration options?
See deprecation code UNSUPPORTED_CLI_OPTIONS for more details.
This was introduced in serverless/serverless#9171.
serverless>=2.32.0
Using the --env CLI option will now result in the following warning:
Detected unrecognized CLI options: "--env".Starting with the next major, Serverless Framework will report them with a thrown errorMore Info: https://www.serverless.com/framework/docs/deprecations/#UNSUPPORTED_CLI_OPTIONS
serverless>=3.0.0
Using the --env CLI option will now result in the following error:
Error:Detected unrecognized CLI options: "--env".
Why do env vars already defined by the system take higher precedence?
The Serverless Framework has basic dotenv support built-in. If you are loading variables from .env at the project root, it is possible the Serverless Framework preloads that env var before this plugin does.
As well, because of the variables engine changed in serverless>=2.26.0 (see above), env variables can also be resolved before this plugin runs, which means Serverless could take the values already defined in the system before the plugin loads env vars via dotenv.
Why doesn't the basePath or path options support Serverless variables?
Because Serverless variables have not been interpolated when this plugin runs, basePath and path will always be treated like literal strings (e.g. ${opt:stage} would be presented to the plugin, not the passed in via --stage). The suggested pattern is to store all your dotenv files in one folder, and rely on NODE_ENV, --env, or --stage to resolve to the right file.
There are no plans to support anything other than literal strings at this time, although you are free to discuss this in #52.
Why doesn't this plugin work when provider.environment references another file?
Upgrade to serverless>=2.26.0. The new variables engine introduced in the Serverless Framework in v2.26.0 now resolves file variables first before loading initializing any plugins.
Before v2.26.0, Serverless variables do not get interpolated before this plugin gets initialized, causing provider.environment to be presented to this plugin uninterpolated (e.g. ${file(./serverless-env.yml):environment}). Because of this, the plugin tries to append items to a string instead of a list.
To work around this, you can set the include option to [] to avoid adding any environment variables to provider.environment. However, this means you will have to wire up the environment variables yourself by referencing every single one you need. E.g.
provider:  environment:    - DDB_TABLE: ${env:DDB_TABLE}
More details are available at #38.
Contributing
Because of the highly dependent nature of this plugin (i.e. thousands of developers depend on this to deploy their apps to production) I cannot introduce changes that are backwards incompatible. Any feature requests must first consider this as a blocker. If submitting a PR ensure that the change is developer opt-in only meaning it must guarantee that it will not affect existing workflows, it's only available with an opt-in setting. I appreciate your patience on this. Thanks.\n\n\n\nServerless Step Functions
     
This is the Serverless Framework plugin for AWS Step Functions.
Requirement
Serverless Framework v2.32.0 or later is required.
TOC

Install
Setup

Adding a custom name for a state machine
Adding a custom logical id for a stateMachine
Depending on another logical id
Adding retain property for a state machine
CloudWatch Alarms
CloudWatch Notifications
Blue-Green deployments
Pre-deployment validation
Express Workflow
CloudWatch Logs
X-Ray


Current Gotcha
Events

API Gateway

Simple HTTP endpoint
Custom Step Functions Action
HTTP Endpoint with custom IAM Role
Share API Gateway and API Resources
Enabling CORS
HTTP Endpoints with AWS_IAM Authorizers
HTTP Endpoints with Custom Authorizers
Shared Authorizer
LAMBDA_PROXY request template
Customizing request body mapping templates
Customizing response headers and templates
Send request to an API
Setting API keys for your Rest API
Request Schema Validators


Schedule

Enabling / Disabling
Specify Name and Description
Scheduled Events IAM Role
Specify InputTransformer
Use EventBridge Scheduler instead of EventBridge rules


CloudWatch Event

Simple event definition
Enabling / Disabling
Specify Input or Inputpath or InputTransformer
Specifying a Description
Specifying a Name
Specifying a RoleArn
Specifying a custom CloudWatch EventBus
Specifying a custom EventBridge EventBus
Specifying a DeadLetterQueue




Tags
Commands

deploy
invoke


IAM Role
Tips

How to specify the stateMachine ARN to environment variables
How to split up state machines into files


Sample statemachines setting in serverless.yml

Wait State
Retry Failure
Parallel
Catch Failure
Choice
Map



Install
Run npm install in your Serverless project.
$ npm install --save-dev serverless-step-functions
Add the plugin to your serverless.yml file
plugins:  - serverless-step-functions
Setup
Specify your state machine definition using Amazon States Language in a definition statement in serverless.yml. You can use CloudFormation intrinsic functions such as Ref and Fn::GetAtt to reference Lambda functions, SNS topics, SQS queues and DynamoDB tables declared in the same serverless.yml. Since Ref returns different things (ARN, ID, resource name, etc.) depending on the type of CloudFormation resource, please refer to this page to see whether you need to use Ref or Fn::GetAtt.
Alternatively, you can also provide the raw ARN, or SQS queue URL, or DynamoDB table name as a string. If you need to construct the ARN by hand, then we recommend to use the serverless-pseudo-parameters plugin together to make your life easier.
In addition, if you want to reference a DynamoDB table managed by an external CloudFormation Stack, as long as that table name is exported as an output from that stack, it can be referenced by importing it using Fn::ImportValue. See the ddbtablestepfunc Step Function definition below for an example.
functions:  hello:    handler: handler.hellostepFunctions:  stateMachines:    hellostepfunc1:      events:        - http:            path: gofunction            method: GET        - schedule:            rate: rate(10 minutes)            enabled: true            input:              key1: value1              key2: value2              stageParams:                stage: dev      name: myStateMachine      definition:        Comment: "A Hello World example of the Amazon States Language using an AWS Lambda Function"        StartAt: HelloWorld1        States:          HelloWorld1:            Type: Task            Resource:              Fn::GetAtt: [hello, Arn]            End: true      dependsOn: CustomIamRole      tags:        Team: Atlantis      alarms:        topics:          ok: arn:aws:sns:us-east-1:1234567890:NotifyMe          alarm: arn:aws:sns:us-east-1:1234567890:NotifyMe          insufficientData: arn:aws:sns:us-east-1:1234567890:NotifyMe        metrics:          - executionsTimedOut          - executionsFailed          - executionsAborted          - metric: executionThrottled            treatMissingData: breaching # overrides below default          - executionsSucceeded        treatMissingData: ignore # optional    hellostepfunc2:      definition:        StartAt: HelloWorld2        States:          HelloWorld2:            Type: Task            Resource:              Fn::GetAtt: [hello, Arn]            End: true    ddbtablestepfunc:      definition:        Comment: Demonstrates how to reference a DynamoDB Table Name exported from an external CloudFormation Stack        StartAt: ImportDDBTableName        States:          ImportDDBTableName:            Type: Task            Resource: "arn:aws:states:::dynamodb:updateItem"            Parameters:              TableName:                Fn::ImportValue: MyExternalStack:ToDoTable:Name # imports a table name from an external stack              Key:                id:                  S.$: "$.todoId"              UpdateExpression: "SET #status = :updatedStatus"              ExpressionAttributeNames:                "#status": status              ExpressionAttributeValues:                ":updatedStatus":                  S: DONE            End: true      dependsOn:        - DynamoDBTable        - KinesisStream        - CustomIamRole      tags:        Team: Atlantis  activities:    - myTask    - yourTask  validate: true # enable pre-deployment definition validation (disabled by default)plugins:  - serverless-step-functions  - serverless-pseudo-parameters
In the example above, notice that we used Fn::GetAtt: [hello, Arn] to get the ARN for the hello function defined earlier. This means you don't have to know how the Serverless framework converts these local names to CloudFormation logical IDs (e.g. hello-world becomes HelloDashworldLambdaFunction).
However, if you prefer to work with logical IDs, you can. You can also express the above Fn::GetAtt function as Fn::GetAtt: [HelloLambdaFunction, Arn]. If you're unfamiliar with the convention the Serverless framework uses, then the easiest thing to do is to first run sls package then look in the .serverless folder for the generated CloudFormation template. Here you can find the logical resource names for the functions you want to reference.
Adding a custom name for a stateMachine
In case you need to interpolate a specific stage or service layer variable as the
stateMachines name you can add a name property to your yaml.
service: messagerfunctions:  sendMessage:    handler: handler.sendMessagestepFunctions:  stateMachines:    sendMessageFunc:      name: sendMessageFunc-${self:custom.service}-${opt:stage}      definition:        <your definition>plugins:  - serverless-step-functions
Adding a custom logical id for a stateMachine
You can use a custom logical id that is only unique within the stack as opposed to the name that needs to be unique globally. This can make referencing the state machine easier/simpler because you don't have to duplicate the interpolation logic everywhere you reference the state machine.
service: messagerfunctions:  sendMessage:    handler: handler.sendMessagestepFunctions:  stateMachines:    sendMessageFunc:      id: SendMessageStateMachine      name: sendMessageFunc-${self:custom.service}-${opt:stage}      definition:        <your definition>plugins:  - serverless-step-functions
You can then Ref: SendMessageStateMachine in various parts of CloudFormation or serverless.yml
Depending on another logical id
If your state machine depends on another resource defined in your serverless.yml then you can add a dependsOn field to the state machine definition. This would add the DependsOnclause to the generated CloudFormation template.
This dependsOn field can be either a string, or an array of strings.
stepFunctions:  stateMachines:    myStateMachine:      dependsOn: myDB    myOtherStateMachine:      dependsOn:        - myOtherDB        - myStream
Adding retain property for a stateMachine
There are some practical cases when you would like to prevent state machine from deletion on stack delete or update. This can be achieved by adding retain property to the state machine section.
stepFunctions:  stateMachines:    myStateMachine:      retain: true
Configuring in such way adds "DeletionPolicy" : "Retain" to the state machine within CloudFormation template.
CloudWatch Alarms
It's common practice to want to monitor the health of your state machines and be alerted when something goes wrong. You can either:

do this using the serverless-plugin-aws-alerts, which lets you configure custom CloudWatch Alarms against the various metrics that Step Functions publishes.
or, you can use the built-in alarms configuration from this plugin, which gives you an opinionated set of default alarms (see below)

stepFunctions:  stateMachines:    myStateMachine:      alarms:        topics:          ok: arn:aws:sns:us-east-1:1234567890:NotifyMe          alarm: arn:aws:sns:us-east-1:1234567890:NotifyMe          insufficientData: arn:aws:sns:us-east-1:1234567890:NotifyMe        metrics:          - executionsTimedOut          - executionsFailed          - executionsAborted          - executionThrottled          - executionsSucceeded        treatMissingData: missing
Both topics and metrics are required properties. There are 4 supported metrics, each map to the CloudWatch Metrics that Step Functions publishes for your executions.
You can configure how the CloudWatch Alarms should treat missing data:

missing (AWS default): The alarm does not consider missing data points when evaluating whether to change state.
ignore: The current alarm state is maintained.
breaching: Missing data points are treated as breaching the threshold.
notBreaching: Missing data points are treated as being within the threshold.

For more information, please refer to the official documentation.
The generated CloudWatch alarms would have the following configurations:
namespace: 'AWS/States'metric: <ExecutionsTimedOut | ExecutionsFailed | ExecutionsAborted | ExecutionThrottled>threshold: 1period: 60evaluationPeriods: 1ComparisonOperator: GreaterThanOrEqualToThresholdStatistic: SumtreatMissingData: <missing (default) | ignore | breaching | notBreaching>Dimensions:  - Name: StateMachineArn    Value: <ArnOfTheStateMachine>
You can also override the default treatMissingData setting for a particular alarm by specifying an override:
alarms:  topics:    ok: arn:aws:sns:us-east-1:1234567890:NotifyMe    alarm: arn:aws:sns:us-east-1:1234567890:NotifyMe    insufficientData: arn:aws:sns:us-east-1:1234567890:NotifyMe  metrics:    - executionsTimedOut    - executionsFailed    - executionsAborted    - metric: executionThrottled      treatMissingData: breaching # override    - executionsSucceeded  treatMissingData: ignore # default
Custom CloudWatch Alarm names
By default, the CloudFormation assigns names to the alarms based on the CloudFormation stack and the resource logical Id, and in some cases and these names could be confusing.
To use custom names to the alarms add nameTemplate property in the alarms object.
example:
service: myserviceplugins:  - serverless-step-functionsstepFunctions:  stateMachines:    main-workflow:      name: main      alarms:        nameTemplate: $[stateMachineName]-$[cloudWatchMetricName]-alarm        topics:          alarm: !Ref AwsAlertsGenericAlarmTopicAlarm        metrics:          - executionsFailed          - executionsAborted          - executionsTimedOut          - executionThrottled        treatMissingData: ignore      definition: ${file(./step-functions/main.asl.yaml)}
Supported variables to the nameTemplate property:

stateMachineName
metricName
cloudWatchMetricName

Per-Metric Alarm Name
To overwrite the alarm name for a specific metric, add the alarmName property in the metric object.
service: myserviceplugins:  - serverless-step-functionsstepFunctions:  stateMachines:    main-workflow:      name: main      alarms:        nameTemplate: $[stateMachineName]-$[cloudWatchMetricName]-alarm        topics:          alarm: !Ref AwsAlertsGenericAlarmTopicAlarm        metrics:          - metric: executionsFailed            alarmName: mycustom-name-${self:stage.region}-Failed-alarm          - executionsAborted          - executionsTimedOut          - executionThrottled        treatMissingData: ignore      definition: ${file(./step-functions/main.asl.yaml)}
CloudWatch Notifications
You can monitor the execution state of your state machines via CloudWatch Events. It allows you to be alerted when the status of your state machine changes to ABORTED, FAILED, RUNNING, SUCCEEDED or TIMED_OUT.
You can configure CloudWatch Events to send notification to a number of targets. Currently this plugin supports sns, sqs, kinesis, firehose, lambda and stepFunctions.
To configure status change notifications to your state machine, you can add a notifications like below:
stepFunctions:  stateMachines:    hellostepfunc1:      name: test      definition:        ...      notifications:        ABORTED:          - sns: SNS_TOPIC_ARN          - sqs: SQS_TOPIC_ARN          - sqs: # for FIFO queues, which requires you to configure the message group ID              arn: SQS_TOPIC_ARN              messageGroupId: 12345          - lambda: LAMBDA_FUNCTION_ARN          - kinesis: KINESIS_STREAM_ARN          - kinesis:               arn: KINESIS_STREAM_ARN               partitionKeyPath: $.id # used to choose the parition key from payload          - firehose: FIREHOSE_STREAM_ARN          - stepFunctions: STATE_MACHINE_ARN        FAILED:          ... # same as above        ... # other status
As you can see from the above example, you can configure different notification targets for each type of status change. If you want to configure the same targets for multiple status changes, then consider using YML anchors to keep your YML succinct.
CloudFormation intrinsic functions such as Ref and Fn::GetAtt are supported.
When setting up a notification target against a FIFO SQS queue, the queue must enable the content-based deduplication option and you must configure the messageGroupId.
Blue green deployment
To implement a blue-green deployment with Step Functions you need to reference the exact versions of the functions.
To do this, you can specify useExactVersion: true in the state machine.
stepFunctions:  stateMachines:    hellostepfunc1:      useExactVersion: true      definition:        ...
Pre-deployment validation
By default, your state machine definition will be validated during deployment by StepFunctions. This can be cumbersome when developing because you have to upload your service for every typo in your definition. In order to go faster, you can enable pre-deployment validation using asl-validator which should detect most of the issues (like a missing state property).
stepFunctions:  validate: true
Disable Output Cloudformation Outputs section
Disables the generation of outputs in the CloudFormation Outputs section. If you define many state machines in serverless.yml you may reach the CloudFormation limit of 60 outputs. If you define noOutput: true then this plugin will not generate outputs automatically.
stepFunctions:  noOutput: true
Express Workflow
At re 2019, AWS introduced Express Workflows as a cheaper, more scalable alternative (but with a cut-down set of features). See this page for differences between standard and express workflows.
To declare an express workflow, specify type as EXPRESS and you can specify the logging configuration:
stepFunctions:  stateMachines:    hellostepfunc1:      type: EXPRESS      loggingConfig:        level: ERROR        includeExecutionData: true        destinations:          - Fn::GetAtt: [MyLogGroup, Arn]
CloudWatch Logs
You can enable CloudWatch Logs for standard Step Functions, the syntax is
exactly like with Express Workflows.
stepFunctions:  stateMachines:    hellostepfunc1:      loggingConfig:        level: ERROR        includeExecutionData: true        destinations:          - Fn::GetAtt: [MyLogGroup, Arn]
X-Ray
You can enable X-Ray for your state machine, specify tracingConfig as shown below.
stepFunctions:  stateMachines:    hellostepfunc1:      tracingConfig:        enabled: true
Current Gotcha
Please keep this gotcha in mind if you want to reference the name from the resources section. To generate Logical ID for CloudFormation, the plugin transforms the specified name in serverless.yml based on the following scheme.

Transform a leading character into uppercase
Transform - into Dash
Transform _ into Underscore

If you want to use variables system in name statement, you can't put the variables as a prefix like this:${self:service}-${opt:stage}-myStateMachine since the variables are transformed within Output section, as a result, the reference will be broken.
The correct sample is here.
stepFunctions:  stateMachines:    myStateMachine:      name: myStateMachine-${self:service}-${opt:stage}...resources:  Outputs:    myStateMachine:      Value:        Ref: MyStateMachineDash${self:service}Dash${opt:stage}
Events
API Gateway
To create HTTP endpoints as Event sources for your StepFunctions statemachine
Simple HTTP Endpoint
This setup specifies that the hello state machine should be run when someone accesses the API gateway at hello via a GET request.
Here's an example:
stepFunctions:  stateMachines:    hello:      events:        - http:            path: hello            method: GET      definition:
Here You can define an POST endpoint for the path posts/create.
stepFunctions:  stateMachines:    hello:      events:        - http:            path: posts/create            method: POST      definition:
Custom Step Functions Action
Step Functions have custom actions like DescribeExecution or StopExecution to fetch and control them. You can use custom actions like this:
stepFunctions:  stateMachines:    start:      events:        - http:            path: action/start            method: POST      definition:        ...    status:      events:        - http:            path: action/status            method: POST            action: DescribeExecution      definition:        ...    stop:      events:        - http:            path: action/stop            method: POST            action: StopExecution      definition:        ...
Request template is not used when action is set because there're a bunch of actions. However if you want to use request template you can use Customizing request body mapping templates.
HTTP Endpoint with custom IAM Role
The plugin would generate an IAM Role for you by default. However, if you wish to use an IAM role that you have provisioned separately, then you can override the IAM Role like this:
stepFunctions:  stateMachines:    hello:      events:        - http:            path: posts/create            method: POST            iamRole: arn:aws:iam::<accountId>:role/<roleName>      definition:
Share API Gateway and API Resources
You can share the same API Gateway between multiple projects by referencing its REST API ID and Root Resource ID in serverless.yml as follows:
service: service-nameprovider:  name: aws  apiGateway:    # REST API resource ID. Default is generated by the framework    restApiId: xxxxxxxxxx    # Root resource, represent as / path    restApiRootResourceId: xxxxxxxxxxfunctions:  ...
If your application has many nested paths, you might also want to break them out into smaller services.
However, Cloudformation will throw an error if we try to generate an existing path resource. To avoid that, we reference the resource ID:
service: service-aprovider:  apiGateway:    restApiId: xxxxxxxxxx    restApiRootResourceId: xxxxxxxxxx    # List of existing resources that were created in the REST API. This is required or the stack will be conflicted    restApiResources:      /users: xxxxxxxxxxfunctions:  ...
Now we can define endpoints using existing API Gateway ressources
stepFunctions:  stateMachines:    hello:      events:        - http:            path: users/create            method: POST
Enabling CORS
To set CORS configurations for your HTTP endpoints, simply modify your event configurations as follows:
stepFunctions:  stateMachines:    hello:      events:        - http:            path: posts/create            method: POST            cors: true      definition:
Setting cors to true assumes a default configuration which is equivalent to:
stepFunctions:  stateMachines:    hello:      events:        - http:            path: posts/create            method: POST            cors:              origin: '*'              headers:                - Content-Type                - X-Amz-Date                - Authorization                - X-Api-Key                - X-Amz-Security-Token                - X-Amz-User-Agent              allowCredentials: false      definition:
Configuring the cors property sets Access-Control-Allow-Origin, Access-Control-Allow-Headers, Access-Control-Allow-Methods,Access-Control-Allow-Credentials headers in the CORS preflight response.
To enable the Access-Control-Max-Age preflight response header, set the maxAge property in the cors object:
stepFunctions:  stateMachines:    SfnApiGateway:      events:        - http:            path: /playground/start            method: post            cors:              origin: '*'              maxAge: 86400
HTTP Endpoints with AWS_IAM Authorizers
If you want to require that the caller submit the IAM user's access keys in order to be authenticated to invoke your Lambda Function, set the authorizer to AWS_IAM as shown in the following example:
stepFunctions:  stateMachines:    hello:      events:        - http:            path: posts/create            method: POST            authorizer: aws_iam      definition:
HTTP Endpoints with Custom Authorizers
Custom Authorizers allow you to run an AWS Lambda Function before your targeted AWS Lambda Function. This is useful for Microservice Architectures or when you simply want to do some Authorization before running your business logic.
You can enable Custom Authorizers for your HTTP endpoint by setting the Authorizer in your http event to another function in the same service, as shown in the following example:
stepFunctions:  stateMachines:    hello:      - http:          path: posts/create          method: post          authorizer: authorizerFunc      definition:
If the Authorizer function does not exist in your service but exists in AWS, you can provide the ARN of the Lambda function instead of the function name, as shown in the following example:
stepFunctions:  stateMachines:    hello:      - http:          path: posts/create          method: post          authorizer: xxx:xxx:Lambda-Name      definition:
Shared Authorizer
Auto-created Authorizer is convenient for conventional setup. However, when you need to define your custom Authorizer, or use COGNITO_USER_POOLS authorizer with shared API Gateway, it is painful because of AWS limitation. Sharing Authorizer is a better way to do.
stepFunctions:  stateMachines:    createUser:      ...      events:        - http:            path: /users            ...            authorizer:              # Provide both type and authorizerId              type: COGNITO_USER_POOLS # TOKEN, CUSTOM or COGNITO_USER_POOLS, same as AWS Cloudformation documentation              authorizerId:                Ref: ApiGatewayAuthorizer  # or hard-code Authorizer ID              # [Optional] you can also specify the OAuth scopes for Cognito              scopes:                - scope1                ...
LAMBDA_PROXY request template
The plugin generates default body mapping templates for application/json and application/x-www-form-urlencoded content types. The default template would pass the request body as input to the state machine. If you need access to other contextual information about the HTTP request such as headers, path parameters, etc. then you can also use the lambda_proxy request template like this:
stepFunctions:  stateMachines:    hello:      events:        - http:            path: posts/create            method: POST            request:              template: lambda_proxy
This would generate the normal LAMBDA_PROXY template used for API Gateway integration with Lambda functions.
Customizing request body mapping templates
If you'd like to add content types or customize the default templates, you can do so by including your custom API Gateway request mapping template in serverless.yml like so:
stepFunctions:  stateMachines:    hello:      events:        - http:            path: posts/create            method: POST            request:              template:                application/json: |
                  #set( $body = $util.escapeJavaScript($input.json('$')) )
                  #set( $name = $util.escapeJavaScript($input.json('$.data.attributes.order_id')) )
                  {
                    "input": "$body",
                    "name": "$name",
                    "stateMachineArn":"arn:aws:states:#{AWS::Region}:#{AWS::AccountId}:stateMachine:processOrderFlow-${opt:stage}"
                  }
      name: processOrderFlow-${opt:stage}      definition:
Customizing response headers and templates
If you'd like to add custom headers in the HTTP response, or customize the default response template (which just returns the response from Step Function's StartExecution API), then you can do so by including your custom headers and API Gateway response mapping template in serverless.yml like so:
stepFunctions:  stateMachines:    hello:      events:        - http:            path: posts/create            method: POST            response:              headers:                Content-Type: "'application/json'"                X-Application-Id: "'my-app'"              template:                application/json: |
                  {
                    "status": 200,
                    "info": "OK"
                  }
      definition:
Send request to an API
You can input an value as json in request body, the value is passed as the input value of your statemachine
$ curl -XPOST https://xxxxxxxxx.execute-api.us-east-1.amazonaws.com/dev/posts/create -d '{"foo":"bar"}'
Setting API keys for your Rest API
You can specify a list of API keys to be used by your service Rest API by adding an apiKeys array property to the apiGateway subsection of the provider object in serverless.yml. You'll also need to explicitly specify which endpoints are private and require one of the api keys to be included in the request by adding a private boolean property to the http event object you want to set as private. API Keys are created globally, so if you want to deploy your service to different stages make sure your API key contains a stage variable as defined below. When using API keys, you can optionally define usage plan quota and throttle, using usagePlan object.
Here's an example configuration for setting API keys for your service Rest API:
service: my-serviceprovider:  name: aws  apiGateway:    apiKeys:        - myFirstKey        - ${opt:stage}-myFirstKey        - ${env:MY_API_KEY} # you can hide it in a serverless variable  usagePlan:    quota:      limit: 5000      offset: 2      period: MONTH    throttle:      burstLimit: 200      rateLimit: 100functions:  hello:    handler: handler.hello    stepFunctions:      stateMachines:        statemachine1:          name: ${self:service}-${opt:stage}-statemachine1          events:            - http:                path: /hello                method: post                private: true          definition:            Comment: "A Hello World example of the Amazon States Language using an AWS Lambda Function"            StartAt: HelloWorld1            States:              HelloWorld1:                Type: Task                Resource:                  Fn::GetAtt: [hello, Arn]                End: true    plugins:      - serverless-step-functions      - serverless-pseudo-parameters
Please note that those are the API keys names, not the actual values. Once you deploy your service, the value of those API keys will be auto generated by AWS and printed on the screen for you to use. The values can be concealed from the output with the --conceal deploy option.
Clients connecting to this Rest API will then need to set any of these API keys values in the x-api-key header of their request. This is only necessary for functions where the private property is set to true.
Request Schema Validators
To use request schema validation with API gateway, add the JSON Schema for your content type. Since JSON Schema is represented in JSON, it's easier to include it from a file.
stepFunctions:  stateMachines:    create:      events:        - http:            path: posts/create            method: post            request:              schemas:                application/json: ${file(create_request.json)}
In addition, you can also customize created model with name and description properties.
stepFunctions:  stateMachines:    create:      events:        - http:            path: posts/create            method: post            request:              schemas:                application/json:                  schema: ${file(create_request.json)}                  name: PostCreateModel                  description: 'Validation model for Creating Posts'
To reuse the same model across different events, you can define global models on provider level. In order to define global model you need to add its configuration to provider.apiGateway.request.schemas. After defining a global model, you can use it in the event by referencing it by the key. Provider models are created for application/json content type.
provider:    ...    apiGateway:      request:        schemas:          post-create-model:            name: PostCreateModel            schema: ${file(api_schema/post_add_schema.json)}            description: "A Model validation for adding posts" stepFunctions:  stateMachines:    create:      events:        - http:            path: posts/create            method: post            request:              schemas:                application/json: post-create-model
A sample schema contained in create_request.json might look something like this:
{  "definitions": {},  "$schema": "http://json-schema.org/draft-04/schema#",  "type": "object",  "title": "The Root Schema",  "required": ["username"],  "properties": {    "username": {      "type": "string",      "title": "The Foo Schema",      "default": "",      "pattern": "^[a-zA-Z0-9]+$"    }  }}
NOTE: schema validators are only applied to content types you specify. Other content types are not blocked. Currently, API Gateway supports JSON Schema draft-04.
Schedule
The following config will attach a schedule event and causes the stateMachine crawl to be called every 2 hours. The configuration allows you to attach multiple schedules to the same stateMachine. You can either use the rate or cron syntax. Take a look at the AWS schedule syntax documentation for more details.
stepFunctions:  stateMachines:    crawl:      events:        - schedule: rate(2 hours)        - schedule: cron(0 12 * * ? *)      definition:
Enabling / Disabling
Note: schedule events are enabled by default.
This will create and attach a schedule event for the aggregate stateMachine which is disabled. If enabled it will call
the aggregate stateMachine every 10 minutes.
stepFunctions:  stateMachines:    aggregate:      events:        - schedule:            rate: rate(10 minutes)            enabled: false            input:              key1: value1              key2: value2              stageParams:                stage: dev        - schedule:            rate: cron(0 12 * * ? *)            enabled: false            inputPath: '$.stageVariables'
Specify Name and Description
Name and Description can be specified for a schedule event. These are not required properties.
events:  - schedule:      name: your-scheduled-rate-event-name      description: 'your scheduled rate event description'      rate: rate(2 hours)
Scheduled Events IAM Role
By default, the plugin will create a new IAM role that allows AWS Events to start your state machine. Note that this role is different than the role assumed by the state machine. You can specify your own role instead (it must allow events.amazonaws.com to assume it, and it must be able to run states:StartExecution on your state machine):
events:  - schedule:      rate: rate(2 hours)      role: arn:aws:iam::xxxxxxxx:role/yourRole
Specify InputTransformer
You can specify input values ​​to the Lambda function.
stepFunctions:  stateMachines:    stateMachineScheduled:      events:        - schedule:             rate: cron(30 12 ? * 1-5 *)            inputTransformer:              inputPathsMap:                 time: '$.time'                stage: '$.stageVariables'              inputTemplate: '{"time": <time>, "stage" : <stage> }'      definition:        ...
Use EventBridge Scheduler instead of EventBridge rules
AWS has account-wide limits on the number of AWS::Event::Rule triggers per bus (300 events), and all Lambda schedules go into a single bus with no way to override it. This can lead to a situation where large projects hit the limit with no ability to schedule more events.
However, AWS::Scheduler::Schedule has much higher limits (1,000,000 events), and is configured identically. method can be set in order to migrate to this trigger type seamlessly. It also allows you to specify a timezone to run your event based on local time.
stepFunctions:  stateMachines:    stateMachineScheduled:      events:        - schedule:            method: scheduler            rate: cron(30 12 ? * 1-5 *)            enabled: true            timezone: America/New_York      definition:        ...
CloudWatch Event / EventBridge
Simple event definition
This will enable your Statemachine to be called by an EC2 event rule.
Please check the page of Event Types for CloudWatch Events.
stepFunctions:  stateMachines:    first:      events:        - cloudwatchEvent:            event:              source:                - "aws.ec2"              detail-type:                - "EC2 Instance State-change Notification"              detail:                state:                  - pending      definition:        ...
You can alternatively use EventBridge:
stepFunctions:  stateMachines:    first:      events:        - eventBridge:            event:              source:                - "aws.ec2"              detail-type:                - "EC2 Instance State-change Notification"              detail:                state:                  - pending      definition:        ...
All the configurations in this section applies to both cloudwatchEvent and eventBridge.
Enabling / Disabling
Note: cloudwatchEvent and eventBridge events are enabled by default.
This will create and attach a disabled cloudwatchEvent event for the myCloudWatch statemachine.
stepFunctions:  stateMachines:    cloudwatchEvent:      events:        - cloudwatchEvent:            event:              source:                - "aws.ec2"              detail-type:                - "EC2 Instance State-change Notification"              detail:                state:                  - pending            enabled: false      definition:        ...
Specify Input or Inputpath or InputTransformer
You can specify input values ​​to the Lambda function.
stepFunctions:  stateMachines:    cloudwatchEvent:      events:        - cloudwatchEvent:            event:              source:                - "aws.ec2"              detail-type:                - "EC2 Instance State-change Notification"              detail:                state:                  - pending            input:              key1: value1              key2: value2              stageParams:                stage: dev        - cloudwatchEvent:            event:              source:                - "aws.ec2"              detail-type:                - "EC2 Instance State-change Notification"              detail:                state:                  - pending            inputPath: '$.stageVariables'        - cloudwatchEvent:            event:              source:                - "aws.ec2"              detail-type:                - "EC2 Instance State-change Notification"              detail:                state:                  - pending            inputTransformer:              inputPathsMap:                stage: '$.stageVariables'              inputTemplate: '{ "stage": <stage> }'      definition:        ...
Specifying a Description
You can also specify a CloudWatch Event description.
stepFunctions:  stateMachines:    cloudwatchEvent:      events:        - cloudwatchEvent:            description: 'CloudWatch Event triggered on EC2 Instance pending state'            event:              source:                - "aws.ec2"              detail-type:                - "EC2 Instance State-change Notification"              detail:                state:                  - pending      definition:        ...
Specifying a Name
You can also specify a CloudWatch Event name. Keep in mind that the name must begin with a letter; contain only ASCII letters, digits, and hyphens; and not end with a hyphen or contain two consecutive hyphens. More infomation here.
stepFunctions:  stateMachines:    cloudwatchEvent:      events:        - cloudwatchEvent:            name: 'my-cloudwatch-event-name'            event:              source:                - "aws.ec2"              detail-type:                - "EC2 Instance State-change Notification"              detail:                state:                  - pending      definition:        ...
Specifying a RoleArn
You can also specify a CloudWatch Event RoleArn.
The Amazon Resource Name (ARN) of the role that is used for target invocation.
Required: No
stepFunctions:  stateMachines:    cloudwatchEvent:      events:        - cloudwatchEvent:            name: 'my-cloudwatch-event-name'            iamRole: 'arn:aws:iam::012345678910:role/Events-InvokeStepFunctions-Role'            event:              source:                - "aws.ec2"              detail-type:                - "EC2 Instance State-change Notification"              detail:                state:                  - pending      definition:        ...
Specifying a custom CloudWatch EventBus
You can choose which CloudWatch Event bus:
stepFunctions:  stateMachines:    exampleCloudwatchEventStartsMachine:      events:        - cloudwatchEvent:            eventBusName: 'my-custom-event-bus'            event:              source:                - "my.custom.source"              detail-type:                - "My Event Type"              detail:                state:                  - pending      definition:        ...
Specifying a custom EventBridge EventBus
You can choose which EventBridge Event bus:
stepFunctions:  stateMachines:    exampleEventBridgeEventStartsMachine:      events:        - eventBridge:            eventBusName: 'my-custom-event-bus'            event:              source:                - "my.custom.source"              detail-type:                - "My Event Type"              detail:                state:                  - pending      definition:        ...
Specifying a DeadLetterQueue
You can configure a target queue to send dead-letter queue events to:
stepFunctions:  stateMachines:    exampleEventBridgeEventStartsMachine:      events:        - eventBridge:            eventBusName: 'my-custom-event-bus'            event:              source:                - "my.custom.source"              detail-type:                - "My Event Type"              detail:                state:                  - pending            deadLetterConfig: 'arn:aws:sqs:us-east-1:012345678910:my-dlq' # SQS Arn      definition:        ...
Important point
Don't forget to Grant permissions to the dead-letter queue, to do that you may need to have the ARN of the generated EventBridge Rule.
In order to get the ARN you can use intrinsic functions against the logicalId, this plugin generates logicalIds following this format:
`${StateMachineName}EventsRuleCloudWatchEvent${index}`
Given this example 👇
stepFunctions:  stateMachines:    hellostepfunc1: # <---- StateMachineName      events:        - eventBridge:            eventBusName: 'my-custom-event-bus'            event:              source:                - "my.custom.source"        - eventBridge:            eventBusName: 'my-custom-event-bus'            event:              source:                - "my.custom.source"            deadLetterConfig: 'arn:aws:sqs:us-east-1:012345678910:my-dlq'      name: myStateMachine      definition:        Comment: "A Hello World example of the Amazon States Language using an AWS Lambda Function"        StartAt: HelloWorld1        States:          HelloWorld1:            Type: Task            Resource:              Fn::GetAtt: [hello, Arn]            End: true
Then
# to get the Arn of the 1st EventBridge rule!GetAtt Hellostepfunc1EventsRuleCloudWatchEvent1.Arn# to get the Arn of the 2nd EventBridge rule!GetAtt Hellostepfunc1EventsRuleCloudWatchEvent2.Arn
Tags
You can specify tags on each state machine. Additionally any global tags (specified under provider section in your serverless.yml) would be merged in as well.
If you don't want for global tags to be merged into your state machine, you can include the inheritGlobalTags property for your state machine.
provider:  tags:    app: myApp    department: engineeringstepFunctions:  stateMachines:    hellostepfunc1:      name: myStateMachine      inheritGlobalTags: false      tags:        score: 42      definition: something
As a result, hellostepfunc1 will only have the tag of score: 42, and not the tags at the provider level
Commands
deploy
Run sls deploy, the defined Stepfunctions are deployed.
invoke
$ sls invoke stepf --name <stepfunctionname> --data '{"foo":"bar"}'
options

--name or -n The name of the step function in your service that you want to invoke. Required.
--stage or -s The stage in your service you want to invoke your step function.
--region or -r The region in your stage that you want to invoke your step function.
--data or -d String data to be passed as an event to your step function.
--path or -p The path to a json file with input data to be passed to the invoked step function.

IAM Role
The IAM roles required to run Statemachine are automatically generated for each state machine in the serverless.yml, with the IAM role name of StatesExecutionPolicy-<environment>. These roles are tailored to the services that the state machine integrates with, for example with Lambda the InvokeFunction is applied. You can also specify a custom ARN directly to the step functions lambda.
Here's an example:
stepFunctions:  stateMachines:    hello:      role: arn:aws:iam::xxxxxxxx:role/yourRole      definition:
It is also possible to use the CloudFormation intrinsic functions to reference resources from elsewhere. This allows for an IAM role to be created, and applied to the state machines all within the serverless file.
The below example shows the policy needed if your step function needs the ability to send a message to an sqs queue. To apply the role either the RoleName can be used as a reference in the state machine, or the role ARN can be used like in the example above. It is important to note that if you want to store your state machine role at a certain path, this must be specified on the Path property on the new role.
stepFunctions:  stateMachines:    hello:      role:        Fn::GetAtt: ["StateMachineRole", "Arn"]      definition:        ...resources:  Resources:    StateMachineRole:      Type: AWS::IAM::Role      Properties:        RoleName: RoleName        Path: /path_of_state_machine_roles/        AssumeRolePolicyDocument:          Statement:          - Effect: Allow            Principal:              Service:                - states.amazonaws.com            Action:              - sts:AssumeRole        Policies:          - PolicyName: statePolicy            PolicyDocument:              Version: "2012-10-17"              Statement:                - Effect: Allow                  Action:                    - lambda:InvokeFunction                  Resource:                    - arn:aws:lambda:lambdaName                - Effect: Allow                  Action:                    - sqs:SendMessage                  Resource:                    - arn:aws:sqs::xxxxxxxx:queueName
The short form of the intrinsic functions (i.e. !Sub, !Ref) is not supported at the moment.
Tips
How to specify the stateMachine ARN to environment variables
Here is serverless.yml sample to specify the stateMachine ARN to environment variables.
This makes it possible to trigger your statemachine through Lambda events
functions:  hello:    handler: handler.hello    environment:      statemachine_arn: ${self:resources.Outputs.MyStateMachine.Value}stepFunctions:  stateMachines:    hellostepfunc:      name: myStateMachine      definition:        <your definition>resources:  Outputs:    MyStateMachine:      Description: The ARN of the example state machine      Value:        Ref: MyStateMachineplugins:  - serverless-step-functions
How to split up state machines into files
When you have a large serverless project with lots of state machines
your serverless.yml file can grow to a point where it is unmaintainable.
You can split step functions into external files and import them
into your serverless.yml file.
There are two ways you can do this:
Single external file
You can define the entire stateMachines block in a separate file
and import it in its entirety.
includes/state-machines.yml:
stateMachines:  hellostepfunc1:    name: myStateMachine1    definition:      <your definition>  hellostepfunc2:    name: myStateMachine2    definition:      <your definition>
serverless.yml:
stepFunctions:  ${file(includes/state-machines.yml)}plugins:  - serverless-step-functions
Separate Files
You can split up the stateMachines block into separate files.
includes/state-machine-1.yml:
name: myStateMachine1definition:  <your definition>
includes/state-machine-2.yml:
name: myStateMachine2definition:  <your definition>
serverless.yml:
stepFunctions:  stateMachines:    hellostepfunc1:      ${file(includes/state-machine-1.yml)}    hellostepfunc2:      ${file(includes/state-machine-2.yml)}plugins:  - serverless-step-functions
Sample statemachines setting in serverless.yml
Wait State
functions:  hello:    handler: handler.hellostepFunctions:  stateMachines:    yourWateMachine:      definition:        Comment: "An example of the Amazon States Language using wait states"        StartAt: FirstState        States:          FirstState:            Type: Task            Resource:              Fn::GetAtt: [hello, Arn]            Next: wait_using_seconds          wait_using_seconds:            Type: Wait            Seconds: 10            Next: wait_using_timestamp          wait_using_timestamp:            Type: Wait            Timestamp: '2015-09-04T01:59:00Z'            Next: wait_using_timestamp_path          wait_using_timestamp_path:            Type: Wait            TimestampPath: "$.expirydate"            Next: wait_using_seconds_path          wait_using_seconds_path:            Type: Wait            SecondsPath: "$.expiryseconds"            Next: FinalState          FinalState:            Type: Task            Resource:              Fn::GetAtt: [hello, Arn]            End: trueplugins:  - serverless-step-functions  - serverless-pseudo-parameters
Retry Failure
functions:  hello:    handler: handler.hellostepFunctions:  stateMachines:    yourRetryMachine:      definition:        Comment: "A Retry example of the Amazon States Language using an AWS Lambda Function"        StartAt: HelloWorld        States:          HelloWorld:            Type: Task            Resource:              Fn::GetAtt: [hello, Arn]            Retry:            - ErrorEquals:              - HandledError              IntervalSeconds: 1              MaxAttempts: 2              BackoffRate: 2            - ErrorEquals:              - States.TaskFailed              IntervalSeconds: 30              MaxAttempts: 2              BackoffRate: 2            - ErrorEquals:              - States.ALL              IntervalSeconds: 5              MaxAttempts: 5              BackoffRate: 2            End: trueplugins:  - serverless-step-functions  - serverless-pseudo-parameters
Parallel
functions:  hello:    handler: handler.hellostepFunctions:  stateMachines:    yourParallelMachine:      definition:        Comment: "An example of the Amazon States Language using a parallel state to execute two branches at the same time."        StartAt: Parallel        States:          Parallel:            Type: Parallel            Next: Final State            Branches:            - StartAt: Wait 20s              States:                Wait 20s:                  Type: Wait                  Seconds: 20                  End: true            - StartAt: Pass              States:                Pass:                  Type: Pass                  Next: Wait 10s                Wait 10s:                  Type: Wait                  Seconds: 10                  End: true          Final State:            Type: Pass            End: trueplugins:  - serverless-step-functions  - serverless-pseudo-parameters
Catch Failure
functions:  hello:    handler: handler.hellostepFunctions:  stateMachines:    yourCatchMachine:      definition:        Comment: "A Catch example of the Amazon States Language using an AWS Lambda Function"        StartAt: HelloWorld        States:          HelloWorld:            Type: Task            Resource:              Fn::GetAtt: [hello, Arn]            Catch:            - ErrorEquals: ["HandledError"]              Next: CustomErrorFallback            - ErrorEquals: ["States.TaskFailed"]              Next: ReservedTypeFallback            - ErrorEquals: ["States.ALL"]              Next: CatchAllFallback            End: true          CustomErrorFallback:            Type: Pass            Result: "This is a fallback from a custom lambda function exception"            End: true          ReservedTypeFallback:            Type: Pass            Result: "This is a fallback from a reserved error code"            End: true          CatchAllFallback:            Type: Pass            Result: "This is a fallback from a reserved error code"            End: trueplugins:  - serverless-step-functions  - serverless-pseudo-parameters
Choice
functions:  hello1:    handler: handler.hello1  hello2:    handler: handler.hello2  hello3:    handler: handler.hello3  hello4:    handler: handler.hello4stepFunctions:  stateMachines:    yourChoiceMachine:      definition:        Comment: "An example of the Amazon States Language using a choice state."        StartAt: FirstState        States:          FirstState:            Type: Task            Resource:              Fn::GetAtt: [hello, Arn]            Next: ChoiceState          ChoiceState:            Type: Choice            Choices:            - Variable: "$.foo"              NumericEquals: 1              Next: FirstMatchState            - Variable: "$.foo"              NumericEquals: 2              Next: SecondMatchState            Default: DefaultState          FirstMatchState:            Type: Task            Resource:              Fn::GetAtt: [hello2, Arn]            Next: NextState          SecondMatchState:            Type: Task            Resource:              Fn::GetAtt: [hello3, Arn]            Next: NextState          DefaultState:            Type: Fail            Cause: "No Matches!"          NextState:            Type: Task            Resource:              Fn::GetAtt: [hello4, Arn]            End: trueplugins:  - serverless-step-functions  - serverless-pseudo-parameters
Map
functions:  entry:    handler: handler.entry  mapTask:    handler: handler.mapTaskstepFunctions:  stateMachines:    yourMapMachine:      definition:        Comment: "A Map example of the Amazon States Language using an AWS Lambda Function"        StartAt: FirstState        States:          FirstState:            Type: Task            Resource:              Fn::GetAtt: [entry, Arn]            Next: mapped_task          mapped_task:            Type: Map            Iterator:              StartAt: FirstMapTask              States:                FirstMapTask:                  Type: Task                  Resource:                    Fn::GetAtt: [mapTask, Arn]                  End: true            End: trueplugins:  - serverless-step-functions\n\nPluginsServerless Step FunctionsServerless Step Functions
     
This is the Serverless Framework plugin for AWS Step Functions.
Requirement
Serverless Framework v2.32.0 or later is required.
TOC

Install
Setup

Adding a custom name for a state machine
Adding a custom logical id for a stateMachine
Depending on another logical id
Adding retain property for a state machine
CloudWatch Alarms
CloudWatch Notifications
Blue-Green deployments
Pre-deployment validation
Express Workflow
CloudWatch Logs
X-Ray


Current Gotcha
Events

API Gateway

Simple HTTP endpoint
Custom Step Functions Action
HTTP Endpoint with custom IAM Role
Share API Gateway and API Resources
Enabling CORS
HTTP Endpoints with AWS_IAM Authorizers
HTTP Endpoints with Custom Authorizers
Shared Authorizer
LAMBDA_PROXY request template
Customizing request body mapping templates
Customizing response headers and templates
Send request to an API
Setting API keys for your Rest API
Request Schema Validators


Schedule

Enabling / Disabling
Specify Name and Description
Scheduled Events IAM Role
Specify InputTransformer
Use EventBridge Scheduler instead of EventBridge rules


CloudWatch Event

Simple event definition
Enabling / Disabling
Specify Input or Inputpath or InputTransformer
Specifying a Description
Specifying a Name
Specifying a RoleArn
Specifying a custom CloudWatch EventBus
Specifying a custom EventBridge EventBus
Specifying a DeadLetterQueue




Tags
Commands

deploy
invoke


IAM Role
Tips

How to specify the stateMachine ARN to environment variables
How to split up state machines into files


Sample statemachines setting in serverless.yml

Wait State
Retry Failure
Parallel
Catch Failure
Choice
Map



Install
Run npm install in your Serverless project.
$ npm install --save-dev serverless-step-functions
Add the plugin to your serverless.yml file
plugins:  - serverless-step-functions
Setup
Specify your state machine definition using Amazon States Language in a definition statement in serverless.yml. You can use CloudFormation intrinsic functions such as Ref and Fn::GetAtt to reference Lambda functions, SNS topics, SQS queues and DynamoDB tables declared in the same serverless.yml. Since Ref returns different things (ARN, ID, resource name, etc.) depending on the type of CloudFormation resource, please refer to this page to see whether you need to use Ref or Fn::GetAtt.
Alternatively, you can also provide the raw ARN, or SQS queue URL, or DynamoDB table name as a string. If you need to construct the ARN by hand, then we recommend to use the serverless-pseudo-parameters plugin together to make your life easier.
In addition, if you want to reference a DynamoDB table managed by an external CloudFormation Stack, as long as that table name is exported as an output from that stack, it can be referenced by importing it using Fn::ImportValue. See the ddbtablestepfunc Step Function definition below for an example.
functions:  hello:    handler: handler.hellostepFunctions:  stateMachines:    hellostepfunc1:      events:        - http:            path: gofunction            method: GET        - schedule:            rate: rate(10 minutes)            enabled: true            input:              key1: value1              key2: value2              stageParams:                stage: dev      name: myStateMachine      definition:        Comment: "A Hello World example of the Amazon States Language using an AWS Lambda Function"        StartAt: HelloWorld1        States:          HelloWorld1:            Type: Task            Resource:              Fn::GetAtt: [hello, Arn]            End: true      dependsOn: CustomIamRole      tags:        Team: Atlantis      alarms:        topics:          ok: arn:aws:sns:us-east-1:1234567890:NotifyMe          alarm: arn:aws:sns:us-east-1:1234567890:NotifyMe          insufficientData: arn:aws:sns:us-east-1:1234567890:NotifyMe        metrics:          - executionsTimedOut          - executionsFailed          - executionsAborted          - metric: executionThrottled            treatMissingData: breaching # overrides below default          - executionsSucceeded        treatMissingData: ignore # optional    hellostepfunc2:      definition:        StartAt: HelloWorld2        States:          HelloWorld2:            Type: Task            Resource:              Fn::GetAtt: [hello, Arn]            End: true    ddbtablestepfunc:      definition:        Comment: Demonstrates how to reference a DynamoDB Table Name exported from an external CloudFormation Stack        StartAt: ImportDDBTableName        States:          ImportDDBTableName:            Type: Task            Resource: "arn:aws:states:::dynamodb:updateItem"            Parameters:              TableName:                Fn::ImportValue: MyExternalStack:ToDoTable:Name # imports a table name from an external stack              Key:                id:                  S.$: "$.todoId"              UpdateExpression: "SET #status = :updatedStatus"              ExpressionAttributeNames:                "#status": status              ExpressionAttributeValues:                ":updatedStatus":                  S: DONE            End: true      dependsOn:        - DynamoDBTable        - KinesisStream        - CustomIamRole      tags:        Team: Atlantis  activities:    - myTask    - yourTask  validate: true # enable pre-deployment definition validation (disabled by default)plugins:  - serverless-step-functions  - serverless-pseudo-parameters
In the example above, notice that we used Fn::GetAtt: [hello, Arn] to get the ARN for the hello function defined earlier. This means you don't have to know how the Serverless framework converts these local names to CloudFormation logical IDs (e.g. hello-world becomes HelloDashworldLambdaFunction).
However, if you prefer to work with logical IDs, you can. You can also express the above Fn::GetAtt function as Fn::GetAtt: [HelloLambdaFunction, Arn]. If you're unfamiliar with the convention the Serverless framework uses, then the easiest thing to do is to first run sls package then look in the .serverless folder for the generated CloudFormation template. Here you can find the logical resource names for the functions you want to reference.
Adding a custom name for a stateMachine
In case you need to interpolate a specific stage or service layer variable as the
stateMachines name you can add a name property to your yaml.
service: messagerfunctions:  sendMessage:    handler: handler.sendMessagestepFunctions:  stateMachines:    sendMessageFunc:      name: sendMessageFunc-${self:custom.service}-${opt:stage}      definition:        <your definition>plugins:  - serverless-step-functions
Adding a custom logical id for a stateMachine
You can use a custom logical id that is only unique within the stack as opposed to the name that needs to be unique globally. This can make referencing the state machine easier/simpler because you don't have to duplicate the interpolation logic everywhere you reference the state machine.
service: messagerfunctions:  sendMessage:    handler: handler.sendMessagestepFunctions:  stateMachines:    sendMessageFunc:      id: SendMessageStateMachine      name: sendMessageFunc-${self:custom.service}-${opt:stage}      definition:        <your definition>plugins:  - serverless-step-functions
You can then Ref: SendMessageStateMachine in various parts of CloudFormation or serverless.yml
Depending on another logical id
If your state machine depends on another resource defined in your serverless.yml then you can add a dependsOn field to the state machine definition. This would add the DependsOnclause to the generated CloudFormation template.
This dependsOn field can be either a string, or an array of strings.
stepFunctions:  stateMachines:    myStateMachine:      dependsOn: myDB    myOtherStateMachine:      dependsOn:        - myOtherDB        - myStream
Adding retain property for a stateMachine
There are some practical cases when you would like to prevent state machine from deletion on stack delete or update. This can be achieved by adding retain property to the state machine section.
stepFunctions:  stateMachines:    myStateMachine:      retain: true
Configuring in such way adds "DeletionPolicy" : "Retain" to the state machine within CloudFormation template.
CloudWatch Alarms
It's common practice to want to monitor the health of your state machines and be alerted when something goes wrong. You can either:

do this using the serverless-plugin-aws-alerts, which lets you configure custom CloudWatch Alarms against the various metrics that Step Functions publishes.
or, you can use the built-in alarms configuration from this plugin, which gives you an opinionated set of default alarms (see below)

stepFunctions:  stateMachines:    myStateMachine:      alarms:        topics:          ok: arn:aws:sns:us-east-1:1234567890:NotifyMe          alarm: arn:aws:sns:us-east-1:1234567890:NotifyMe          insufficientData: arn:aws:sns:us-east-1:1234567890:NotifyMe        metrics:          - executionsTimedOut          - executionsFailed          - executionsAborted          - executionThrottled          - executionsSucceeded        treatMissingData: missing
Both topics and metrics are required properties. There are 4 supported metrics, each map to the CloudWatch Metrics that Step Functions publishes for your executions.
You can configure how the CloudWatch Alarms should treat missing data:

missing (AWS default): The alarm does not consider missing data points when evaluating whether to change state.
ignore: The current alarm state is maintained.
breaching: Missing data points are treated as breaching the threshold.
notBreaching: Missing data points are treated as being within the threshold.

For more information, please refer to the official documentation.
The generated CloudWatch alarms would have the following configurations:
namespace: 'AWS/States'metric: <ExecutionsTimedOut | ExecutionsFailed | ExecutionsAborted | ExecutionThrottled>threshold: 1period: 60evaluationPeriods: 1ComparisonOperator: GreaterThanOrEqualToThresholdStatistic: SumtreatMissingData: <missing (default) | ignore | breaching | notBreaching>Dimensions:  - Name: StateMachineArn    Value: <ArnOfTheStateMachine>
You can also override the default treatMissingData setting for a particular alarm by specifying an override:
alarms:  topics:    ok: arn:aws:sns:us-east-1:1234567890:NotifyMe    alarm: arn:aws:sns:us-east-1:1234567890:NotifyMe    insufficientData: arn:aws:sns:us-east-1:1234567890:NotifyMe  metrics:    - executionsTimedOut    - executionsFailed    - executionsAborted    - metric: executionThrottled      treatMissingData: breaching # override    - executionsSucceeded  treatMissingData: ignore # default
Custom CloudWatch Alarm names
By default, the CloudFormation assigns names to the alarms based on the CloudFormation stack and the resource logical Id, and in some cases and these names could be confusing.
To use custom names to the alarms add nameTemplate property in the alarms object.
example:
service: myserviceplugins:  - serverless-step-functionsstepFunctions:  stateMachines:    main-workflow:      name: main      alarms:        nameTemplate: $[stateMachineName]-$[cloudWatchMetricName]-alarm        topics:          alarm: !Ref AwsAlertsGenericAlarmTopicAlarm        metrics:          - executionsFailed          - executionsAborted          - executionsTimedOut          - executionThrottled        treatMissingData: ignore      definition: ${file(./step-functions/main.asl.yaml)}
Supported variables to the nameTemplate property:

stateMachineName
metricName
cloudWatchMetricName

Per-Metric Alarm Name
To overwrite the alarm name for a specific metric, add the alarmName property in the metric object.
service: myserviceplugins:  - serverless-step-functionsstepFunctions:  stateMachines:    main-workflow:      name: main      alarms:        nameTemplate: $[stateMachineName]-$[cloudWatchMetricName]-alarm        topics:          alarm: !Ref AwsAlertsGenericAlarmTopicAlarm        metrics:          - metric: executionsFailed            alarmName: mycustom-name-${self:stage.region}-Failed-alarm          - executionsAborted          - executionsTimedOut          - executionThrottled        treatMissingData: ignore      definition: ${file(./step-functions/main.asl.yaml)}
CloudWatch Notifications
You can monitor the execution state of your state machines via CloudWatch Events. It allows you to be alerted when the status of your state machine changes to ABORTED, FAILED, RUNNING, SUCCEEDED or TIMED_OUT.
You can configure CloudWatch Events to send notification to a number of targets. Currently this plugin supports sns, sqs, kinesis, firehose, lambda and stepFunctions.
To configure status change notifications to your state machine, you can add a notifications like below:
stepFunctions:  stateMachines:    hellostepfunc1:      name: test      definition:        ...      notifications:        ABORTED:          - sns: SNS_TOPIC_ARN          - sqs: SQS_TOPIC_ARN          - sqs: # for FIFO queues, which requires you to configure the message group ID              arn: SQS_TOPIC_ARN              messageGroupId: 12345          - lambda: LAMBDA_FUNCTION_ARN          - kinesis: KINESIS_STREAM_ARN          - kinesis:               arn: KINESIS_STREAM_ARN               partitionKeyPath: $.id # used to choose the parition key from payload          - firehose: FIREHOSE_STREAM_ARN          - stepFunctions: STATE_MACHINE_ARN        FAILED:          ... # same as above        ... # other status
As you can see from the above example, you can configure different notification targets for each type of status change. If you want to configure the same targets for multiple status changes, then consider using YML anchors to keep your YML succinct.
CloudFormation intrinsic functions such as Ref and Fn::GetAtt are supported.
When setting up a notification target against a FIFO SQS queue, the queue must enable the content-based deduplication option and you must configure the messageGroupId.
Blue green deployment
To implement a blue-green deployment with Step Functions you need to reference the exact versions of the functions.
To do this, you can specify useExactVersion: true in the state machine.
stepFunctions:  stateMachines:    hellostepfunc1:      useExactVersion: true      definition:        ...
Pre-deployment validation
By default, your state machine definition will be validated during deployment by StepFunctions. This can be cumbersome when developing because you have to upload your service for every typo in your definition. In order to go faster, you can enable pre-deployment validation using asl-validator which should detect most of the issues (like a missing state property).
stepFunctions:  validate: true
Disable Output Cloudformation Outputs section
Disables the generation of outputs in the CloudFormation Outputs section. If you define many state machines in serverless.yml you may reach the CloudFormation limit of 60 outputs. If you define noOutput: true then this plugin will not generate outputs automatically.
stepFunctions:  noOutput: true
Express Workflow
At re 2019, AWS introduced Express Workflows as a cheaper, more scalable alternative (but with a cut-down set of features). See this page for differences between standard and express workflows.
To declare an express workflow, specify type as EXPRESS and you can specify the logging configuration:
stepFunctions:  stateMachines:    hellostepfunc1:      type: EXPRESS      loggingConfig:        level: ERROR        includeExecutionData: true        destinations:          - Fn::GetAtt: [MyLogGroup, Arn]
CloudWatch Logs
You can enable CloudWatch Logs for standard Step Functions, the syntax is
exactly like with Express Workflows.
stepFunctions:  stateMachines:    hellostepfunc1:      loggingConfig:        level: ERROR        includeExecutionData: true        destinations:          - Fn::GetAtt: [MyLogGroup, Arn]
X-Ray
You can enable X-Ray for your state machine, specify tracingConfig as shown below.
stepFunctions:  stateMachines:    hellostepfunc1:      tracingConfig:        enabled: true
Current Gotcha
Please keep this gotcha in mind if you want to reference the name from the resources section. To generate Logical ID for CloudFormation, the plugin transforms the specified name in serverless.yml based on the following scheme.

Transform a leading character into uppercase
Transform - into Dash
Transform _ into Underscore

If you want to use variables system in name statement, you can't put the variables as a prefix like this:${self:service}-${opt:stage}-myStateMachine since the variables are transformed within Output section, as a result, the reference will be broken.
The correct sample is here.
stepFunctions:  stateMachines:    myStateMachine:      name: myStateMachine-${self:service}-${opt:stage}...resources:  Outputs:    myStateMachine:      Value:        Ref: MyStateMachineDash${self:service}Dash${opt:stage}
Events
API Gateway
To create HTTP endpoints as Event sources for your StepFunctions statemachine
Simple HTTP Endpoint
This setup specifies that the hello state machine should be run when someone accesses the API gateway at hello via a GET request.
Here's an example:
stepFunctions:  stateMachines:    hello:      events:        - http:            path: hello            method: GET      definition:
Here You can define an POST endpoint for the path posts/create.
stepFunctions:  stateMachines:    hello:      events:        - http:            path: posts/create            method: POST      definition:
Custom Step Functions Action
Step Functions have custom actions like DescribeExecution or StopExecution to fetch and control them. You can use custom actions like this:
stepFunctions:  stateMachines:    start:      events:        - http:            path: action/start            method: POST      definition:        ...    status:      events:        - http:            path: action/status            method: POST            action: DescribeExecution      definition:        ...    stop:      events:        - http:            path: action/stop            method: POST            action: StopExecution      definition:        ...
Request template is not used when action is set because there're a bunch of actions. However if you want to use request template you can use Customizing request body mapping templates.
HTTP Endpoint with custom IAM Role
The plugin would generate an IAM Role for you by default. However, if you wish to use an IAM role that you have provisioned separately, then you can override the IAM Role like this:
stepFunctions:  stateMachines:    hello:      events:        - http:            path: posts/create            method: POST            iamRole: arn:aws:iam::<accountId>:role/<roleName>      definition:
Share API Gateway and API Resources
You can share the same API Gateway between multiple projects by referencing its REST API ID and Root Resource ID in serverless.yml as follows:
service: service-nameprovider:  name: aws  apiGateway:    # REST API resource ID. Default is generated by the framework    restApiId: xxxxxxxxxx    # Root resource, represent as / path    restApiRootResourceId: xxxxxxxxxxfunctions:  ...
If your application has many nested paths, you might also want to break them out into smaller services.
However, Cloudformation will throw an error if we try to generate an existing path resource. To avoid that, we reference the resource ID:
service: service-aprovider:  apiGateway:    restApiId: xxxxxxxxxx    restApiRootResourceId: xxxxxxxxxx    # List of existing resources that were created in the REST API. This is required or the stack will be conflicted    restApiResources:      /users: xxxxxxxxxxfunctions:  ...
Now we can define endpoints using existing API Gateway ressources
stepFunctions:  stateMachines:    hello:      events:        - http:            path: users/create            method: POST
Enabling CORS
To set CORS configurations for your HTTP endpoints, simply modify your event configurations as follows:
stepFunctions:  stateMachines:    hello:      events:        - http:            path: posts/create            method: POST            cors: true      definition:
Setting cors to true assumes a default configuration which is equivalent to:
stepFunctions:  stateMachines:    hello:      events:        - http:            path: posts/create            method: POST            cors:              origin: '*'              headers:                - Content-Type                - X-Amz-Date                - Authorization                - X-Api-Key                - X-Amz-Security-Token                - X-Amz-User-Agent              allowCredentials: false      definition:
Configuring the cors property sets Access-Control-Allow-Origin, Access-Control-Allow-Headers, Access-Control-Allow-Methods,Access-Control-Allow-Credentials headers in the CORS preflight response.
To enable the Access-Control-Max-Age preflight response header, set the maxAge property in the cors object:
stepFunctions:  stateMachines:    SfnApiGateway:      events:        - http:            path: /playground/start            method: post            cors:              origin: '*'              maxAge: 86400
HTTP Endpoints with AWS_IAM Authorizers
If you want to require that the caller submit the IAM user's access keys in order to be authenticated to invoke your Lambda Function, set the authorizer to AWS_IAM as shown in the following example:
stepFunctions:  stateMachines:    hello:      events:        - http:            path: posts/create            method: POST            authorizer: aws_iam      definition:
HTTP Endpoints with Custom Authorizers
Custom Authorizers allow you to run an AWS Lambda Function before your targeted AWS Lambda Function. This is useful for Microservice Architectures or when you simply want to do some Authorization before running your business logic.
You can enable Custom Authorizers for your HTTP endpoint by setting the Authorizer in your http event to another function in the same service, as shown in the following example:
stepFunctions:  stateMachines:    hello:      - http:          path: posts/create          method: post          authorizer: authorizerFunc      definition:
If the Authorizer function does not exist in your service but exists in AWS, you can provide the ARN of the Lambda function instead of the function name, as shown in the following example:
stepFunctions:  stateMachines:    hello:      - http:          path: posts/create          method: post          authorizer: xxx:xxx:Lambda-Name      definition:
Shared Authorizer
Auto-created Authorizer is convenient for conventional setup. However, when you need to define your custom Authorizer, or use COGNITO_USER_POOLS authorizer with shared API Gateway, it is painful because of AWS limitation. Sharing Authorizer is a better way to do.
stepFunctions:  stateMachines:    createUser:      ...      events:        - http:            path: /users            ...            authorizer:              # Provide both type and authorizerId              type: COGNITO_USER_POOLS # TOKEN, CUSTOM or COGNITO_USER_POOLS, same as AWS Cloudformation documentation              authorizerId:                Ref: ApiGatewayAuthorizer  # or hard-code Authorizer ID              # [Optional] you can also specify the OAuth scopes for Cognito              scopes:                - scope1                ...
LAMBDA_PROXY request template
The plugin generates default body mapping templates for application/json and application/x-www-form-urlencoded content types. The default template would pass the request body as input to the state machine. If you need access to other contextual information about the HTTP request such as headers, path parameters, etc. then you can also use the lambda_proxy request template like this:
stepFunctions:  stateMachines:    hello:      events:        - http:            path: posts/create            method: POST            request:              template: lambda_proxy
This would generate the normal LAMBDA_PROXY template used for API Gateway integration with Lambda functions.
Customizing request body mapping templates
If you'd like to add content types or customize the default templates, you can do so by including your custom API Gateway request mapping template in serverless.yml like so:
stepFunctions:  stateMachines:    hello:      events:        - http:            path: posts/create            method: POST            request:              template:                application/json: |
                  #set( $body = $util.escapeJavaScript($input.json('$')) )
                  #set( $name = $util.escapeJavaScript($input.json('$.data.attributes.order_id')) )
                  {
                    "input": "$body",
                    "name": "$name",
                    "stateMachineArn":"arn:aws:states:#{AWS::Region}:#{AWS::AccountId}:stateMachine:processOrderFlow-${opt:stage}"
                  }
      name: processOrderFlow-${opt:stage}      definition:
Customizing response headers and templates
If you'd like to add custom headers in the HTTP response, or customize the default response template (which just returns the response from Step Function's StartExecution API), then you can do so by including your custom headers and API Gateway response mapping template in serverless.yml like so:
stepFunctions:  stateMachines:    hello:      events:        - http:            path: posts/create            method: POST            response:              headers:                Content-Type: "'application/json'"                X-Application-Id: "'my-app'"              template:                application/json: |
                  {
                    "status": 200,
                    "info": "OK"
                  }
      definition:
Send request to an API
You can input an value as json in request body, the value is passed as the input value of your statemachine
$ curl -XPOST https://xxxxxxxxx.execute-api.us-east-1.amazonaws.com/dev/posts/create -d '{"foo":"bar"}'
Setting API keys for your Rest API
You can specify a list of API keys to be used by your service Rest API by adding an apiKeys array property to the apiGateway subsection of the provider object in serverless.yml. You'll also need to explicitly specify which endpoints are private and require one of the api keys to be included in the request by adding a private boolean property to the http event object you want to set as private. API Keys are created globally, so if you want to deploy your service to different stages make sure your API key contains a stage variable as defined below. When using API keys, you can optionally define usage plan quota and throttle, using usagePlan object.
Here's an example configuration for setting API keys for your service Rest API:
service: my-serviceprovider:  name: aws  apiGateway:    apiKeys:        - myFirstKey        - ${opt:stage}-myFirstKey        - ${env:MY_API_KEY} # you can hide it in a serverless variable  usagePlan:    quota:      limit: 5000      offset: 2      period: MONTH    throttle:      burstLimit: 200      rateLimit: 100functions:  hello:    handler: handler.hello    stepFunctions:      stateMachines:        statemachine1:          name: ${self:service}-${opt:stage}-statemachine1          events:            - http:                path: /hello                method: post                private: true          definition:            Comment: "A Hello World example of the Amazon States Language using an AWS Lambda Function"            StartAt: HelloWorld1            States:              HelloWorld1:                Type: Task                Resource:                  Fn::GetAtt: [hello, Arn]                End: true    plugins:      - serverless-step-functions      - serverless-pseudo-parameters
Please note that those are the API keys names, not the actual values. Once you deploy your service, the value of those API keys will be auto generated by AWS and printed on the screen for you to use. The values can be concealed from the output with the --conceal deploy option.
Clients connecting to this Rest API will then need to set any of these API keys values in the x-api-key header of their request. This is only necessary for functions where the private property is set to true.
Request Schema Validators
To use request schema validation with API gateway, add the JSON Schema for your content type. Since JSON Schema is represented in JSON, it's easier to include it from a file.
stepFunctions:  stateMachines:    create:      events:        - http:            path: posts/create            method: post            request:              schemas:                application/json: ${file(create_request.json)}
In addition, you can also customize created model with name and description properties.
stepFunctions:  stateMachines:    create:      events:        - http:            path: posts/create            method: post            request:              schemas:                application/json:                  schema: ${file(create_request.json)}                  name: PostCreateModel                  description: 'Validation model for Creating Posts'
To reuse the same model across different events, you can define global models on provider level. In order to define global model you need to add its configuration to provider.apiGateway.request.schemas. After defining a global model, you can use it in the event by referencing it by the key. Provider models are created for application/json content type.
provider:    ...    apiGateway:      request:        schemas:          post-create-model:            name: PostCreateModel            schema: ${file(api_schema/post_add_schema.json)}            description: "A Model validation for adding posts" stepFunctions:  stateMachines:    create:      events:        - http:            path: posts/create            method: post            request:              schemas:                application/json: post-create-model
A sample schema contained in create_request.json might look something like this:
{  "definitions": {},  "$schema": "http://json-schema.org/draft-04/schema#",  "type": "object",  "title": "The Root Schema",  "required": ["username"],  "properties": {    "username": {      "type": "string",      "title": "The Foo Schema",      "default": "",      "pattern": "^[a-zA-Z0-9]+$"    }  }}
NOTE: schema validators are only applied to content types you specify. Other content types are not blocked. Currently, API Gateway supports JSON Schema draft-04.
Schedule
The following config will attach a schedule event and causes the stateMachine crawl to be called every 2 hours. The configuration allows you to attach multiple schedules to the same stateMachine. You can either use the rate or cron syntax. Take a look at the AWS schedule syntax documentation for more details.
stepFunctions:  stateMachines:    crawl:      events:        - schedule: rate(2 hours)        - schedule: cron(0 12 * * ? *)      definition:
Enabling / Disabling
Note: schedule events are enabled by default.
This will create and attach a schedule event for the aggregate stateMachine which is disabled. If enabled it will call
the aggregate stateMachine every 10 minutes.
stepFunctions:  stateMachines:    aggregate:      events:        - schedule:            rate: rate(10 minutes)            enabled: false            input:              key1: value1              key2: value2              stageParams:                stage: dev        - schedule:            rate: cron(0 12 * * ? *)            enabled: false            inputPath: '$.stageVariables'
Specify Name and Description
Name and Description can be specified for a schedule event. These are not required properties.
events:  - schedule:      name: your-scheduled-rate-event-name      description: 'your scheduled rate event description'      rate: rate(2 hours)
Scheduled Events IAM Role
By default, the plugin will create a new IAM role that allows AWS Events to start your state machine. Note that this role is different than the role assumed by the state machine. You can specify your own role instead (it must allow events.amazonaws.com to assume it, and it must be able to run states:StartExecution on your state machine):
events:  - schedule:      rate: rate(2 hours)      role: arn:aws:iam::xxxxxxxx:role/yourRole
Specify InputTransformer
You can specify input values ​​to the Lambda function.
stepFunctions:  stateMachines:    stateMachineScheduled:      events:        - schedule:             rate: cron(30 12 ? * 1-5 *)            inputTransformer:              inputPathsMap:                 time: '$.time'                stage: '$.stageVariables'              inputTemplate: '{"time": <time>, "stage" : <stage> }'      definition:        ...
Use EventBridge Scheduler instead of EventBridge rules
AWS has account-wide limits on the number of AWS::Event::Rule triggers per bus (300 events), and all Lambda schedules go into a single bus with no way to override it. This can lead to a situation where large projects hit the limit with no ability to schedule more events.
However, AWS::Scheduler::Schedule has much higher limits (1,000,000 events), and is configured identically. method can be set in order to migrate to this trigger type seamlessly. It also allows you to specify a timezone to run your event based on local time.
stepFunctions:  stateMachines:    stateMachineScheduled:      events:        - schedule:            method: scheduler            rate: cron(30 12 ? * 1-5 *)            enabled: true            timezone: America/New_York      definition:        ...
CloudWatch Event / EventBridge
Simple event definition
This will enable your Statemachine to be called by an EC2 event rule.
Please check the page of Event Types for CloudWatch Events.
stepFunctions:  stateMachines:    first:      events:        - cloudwatchEvent:            event:              source:                - "aws.ec2"              detail-type:                - "EC2 Instance State-change Notification"              detail:                state:                  - pending      definition:        ...
You can alternatively use EventBridge:
stepFunctions:  stateMachines:    first:      events:        - eventBridge:            event:              source:                - "aws.ec2"              detail-type:                - "EC2 Instance State-change Notification"              detail:                state:                  - pending      definition:        ...
All the configurations in this section applies to both cloudwatchEvent and eventBridge.
Enabling / Disabling
Note: cloudwatchEvent and eventBridge events are enabled by default.
This will create and attach a disabled cloudwatchEvent event for the myCloudWatch statemachine.
stepFunctions:  stateMachines:    cloudwatchEvent:      events:        - cloudwatchEvent:            event:              source:                - "aws.ec2"              detail-type:                - "EC2 Instance State-change Notification"              detail:                state:                  - pending            enabled: false      definition:        ...
Specify Input or Inputpath or InputTransformer
You can specify input values ​​to the Lambda function.
stepFunctions:  stateMachines:    cloudwatchEvent:      events:        - cloudwatchEvent:            event:              source:                - "aws.ec2"              detail-type:                - "EC2 Instance State-change Notification"              detail:                state:                  - pending            input:              key1: value1              key2: value2              stageParams:                stage: dev        - cloudwatchEvent:            event:              source:                - "aws.ec2"              detail-type:                - "EC2 Instance State-change Notification"              detail:                state:                  - pending            inputPath: '$.stageVariables'        - cloudwatchEvent:            event:              source:                - "aws.ec2"              detail-type:                - "EC2 Instance State-change Notification"              detail:                state:                  - pending            inputTransformer:              inputPathsMap:                stage: '$.stageVariables'              inputTemplate: '{ "stage": <stage> }'      definition:        ...
Specifying a Description
You can also specify a CloudWatch Event description.
stepFunctions:  stateMachines:    cloudwatchEvent:      events:        - cloudwatchEvent:            description: 'CloudWatch Event triggered on EC2 Instance pending state'            event:              source:                - "aws.ec2"              detail-type:                - "EC2 Instance State-change Notification"              detail:                state:                  - pending      definition:        ...
Specifying a Name
You can also specify a CloudWatch Event name. Keep in mind that the name must begin with a letter; contain only ASCII letters, digits, and hyphens; and not end with a hyphen or contain two consecutive hyphens. More infomation here.
stepFunctions:  stateMachines:    cloudwatchEvent:      events:        - cloudwatchEvent:            name: 'my-cloudwatch-event-name'            event:              source:                - "aws.ec2"              detail-type:                - "EC2 Instance State-change Notification"              detail:                state:                  - pending      definition:        ...
Specifying a RoleArn
You can also specify a CloudWatch Event RoleArn.
The Amazon Resource Name (ARN) of the role that is used for target invocation.
Required: No
stepFunctions:  stateMachines:    cloudwatchEvent:      events:        - cloudwatchEvent:            name: 'my-cloudwatch-event-name'            iamRole: 'arn:aws:iam::012345678910:role/Events-InvokeStepFunctions-Role'            event:              source:                - "aws.ec2"              detail-type:                - "EC2 Instance State-change Notification"              detail:                state:                  - pending      definition:        ...
Specifying a custom CloudWatch EventBus
You can choose which CloudWatch Event bus:
stepFunctions:  stateMachines:    exampleCloudwatchEventStartsMachine:      events:        - cloudwatchEvent:            eventBusName: 'my-custom-event-bus'            event:              source:                - "my.custom.source"              detail-type:                - "My Event Type"              detail:                state:                  - pending      definition:        ...
Specifying a custom EventBridge EventBus
You can choose which EventBridge Event bus:
stepFunctions:  stateMachines:    exampleEventBridgeEventStartsMachine:      events:        - eventBridge:            eventBusName: 'my-custom-event-bus'            event:              source:                - "my.custom.source"              detail-type:                - "My Event Type"              detail:                state:                  - pending      definition:        ...
Specifying a DeadLetterQueue
You can configure a target queue to send dead-letter queue events to:
stepFunctions:  stateMachines:    exampleEventBridgeEventStartsMachine:      events:        - eventBridge:            eventBusName: 'my-custom-event-bus'            event:              source:                - "my.custom.source"              detail-type:                - "My Event Type"              detail:                state:                  - pending            deadLetterConfig: 'arn:aws:sqs:us-east-1:012345678910:my-dlq' # SQS Arn      definition:        ...
Important point
Don't forget to Grant permissions to the dead-letter queue, to do that you may need to have the ARN of the generated EventBridge Rule.
In order to get the ARN you can use intrinsic functions against the logicalId, this plugin generates logicalIds following this format:
`${StateMachineName}EventsRuleCloudWatchEvent${index}`
Given this example 👇
stepFunctions:  stateMachines:    hellostepfunc1: # <---- StateMachineName      events:        - eventBridge:            eventBusName: 'my-custom-event-bus'            event:              source:                - "my.custom.source"        - eventBridge:            eventBusName: 'my-custom-event-bus'            event:              source:                - "my.custom.source"            deadLetterConfig: 'arn:aws:sqs:us-east-1:012345678910:my-dlq'      name: myStateMachine      definition:        Comment: "A Hello World example of the Amazon States Language using an AWS Lambda Function"        StartAt: HelloWorld1        States:          HelloWorld1:            Type: Task            Resource:              Fn::GetAtt: [hello, Arn]            End: true
Then
# to get the Arn of the 1st EventBridge rule!GetAtt Hellostepfunc1EventsRuleCloudWatchEvent1.Arn# to get the Arn of the 2nd EventBridge rule!GetAtt Hellostepfunc1EventsRuleCloudWatchEvent2.Arn
Tags
You can specify tags on each state machine. Additionally any global tags (specified under provider section in your serverless.yml) would be merged in as well.
If you don't want for global tags to be merged into your state machine, you can include the inheritGlobalTags property for your state machine.
provider:  tags:    app: myApp    department: engineeringstepFunctions:  stateMachines:    hellostepfunc1:      name: myStateMachine      inheritGlobalTags: false      tags:        score: 42      definition: something
As a result, hellostepfunc1 will only have the tag of score: 42, and not the tags at the provider level
Commands
deploy
Run sls deploy, the defined Stepfunctions are deployed.
invoke
$ sls invoke stepf --name <stepfunctionname> --data '{"foo":"bar"}'
options

--name or -n The name of the step function in your service that you want to invoke. Required.
--stage or -s The stage in your service you want to invoke your step function.
--region or -r The region in your stage that you want to invoke your step function.
--data or -d String data to be passed as an event to your step function.
--path or -p The path to a json file with input data to be passed to the invoked step function.

IAM Role
The IAM roles required to run Statemachine are automatically generated for each state machine in the serverless.yml, with the IAM role name of StatesExecutionPolicy-<environment>. These roles are tailored to the services that the state machine integrates with, for example with Lambda the InvokeFunction is applied. You can also specify a custom ARN directly to the step functions lambda.
Here's an example:
stepFunctions:  stateMachines:    hello:      role: arn:aws:iam::xxxxxxxx:role/yourRole      definition:
It is also possible to use the CloudFormation intrinsic functions to reference resources from elsewhere. This allows for an IAM role to be created, and applied to the state machines all within the serverless file.
The below example shows the policy needed if your step function needs the ability to send a message to an sqs queue. To apply the role either the RoleName can be used as a reference in the state machine, or the role ARN can be used like in the example above. It is important to note that if you want to store your state machine role at a certain path, this must be specified on the Path property on the new role.
stepFunctions:  stateMachines:    hello:      role:        Fn::GetAtt: ["StateMachineRole", "Arn"]      definition:        ...resources:  Resources:    StateMachineRole:      Type: AWS::IAM::Role      Properties:        RoleName: RoleName        Path: /path_of_state_machine_roles/        AssumeRolePolicyDocument:          Statement:          - Effect: Allow            Principal:              Service:                - states.amazonaws.com            Action:              - sts:AssumeRole        Policies:          - PolicyName: statePolicy            PolicyDocument:              Version: "2012-10-17"              Statement:                - Effect: Allow                  Action:                    - lambda:InvokeFunction                  Resource:                    - arn:aws:lambda:lambdaName                - Effect: Allow                  Action:                    - sqs:SendMessage                  Resource:                    - arn:aws:sqs::xxxxxxxx:queueName
The short form of the intrinsic functions (i.e. !Sub, !Ref) is not supported at the moment.
Tips
How to specify the stateMachine ARN to environment variables
Here is serverless.yml sample to specify the stateMachine ARN to environment variables.
This makes it possible to trigger your statemachine through Lambda events
functions:  hello:    handler: handler.hello    environment:      statemachine_arn: ${self:resources.Outputs.MyStateMachine.Value}stepFunctions:  stateMachines:    hellostepfunc:      name: myStateMachine      definition:        <your definition>resources:  Outputs:    MyStateMachine:      Description: The ARN of the example state machine      Value:        Ref: MyStateMachineplugins:  - serverless-step-functions
How to split up state machines into files
When you have a large serverless project with lots of state machines
your serverless.yml file can grow to a point where it is unmaintainable.
You can split step functions into external files and import them
into your serverless.yml file.
There are two ways you can do this:
Single external file
You can define the entire stateMachines block in a separate file
and import it in its entirety.
includes/state-machines.yml:
stateMachines:  hellostepfunc1:    name: myStateMachine1    definition:      <your definition>  hellostepfunc2:    name: myStateMachine2    definition:      <your definition>
serverless.yml:
stepFunctions:  ${file(includes/state-machines.yml)}plugins:  - serverless-step-functions
Separate Files
You can split up the stateMachines block into separate files.
includes/state-machine-1.yml:
name: myStateMachine1definition:  <your definition>
includes/state-machine-2.yml:
name: myStateMachine2definition:  <your definition>
serverless.yml:
stepFunctions:  stateMachines:    hellostepfunc1:      ${file(includes/state-machine-1.yml)}    hellostepfunc2:      ${file(includes/state-machine-2.yml)}plugins:  - serverless-step-functions
Sample statemachines setting in serverless.yml
Wait State
functions:  hello:    handler: handler.hellostepFunctions:  stateMachines:    yourWateMachine:      definition:        Comment: "An example of the Amazon States Language using wait states"        StartAt: FirstState        States:          FirstState:            Type: Task            Resource:              Fn::GetAtt: [hello, Arn]            Next: wait_using_seconds          wait_using_seconds:            Type: Wait            Seconds: 10            Next: wait_using_timestamp          wait_using_timestamp:            Type: Wait            Timestamp: '2015-09-04T01:59:00Z'            Next: wait_using_timestamp_path          wait_using_timestamp_path:            Type: Wait            TimestampPath: "$.expirydate"            Next: wait_using_seconds_path          wait_using_seconds_path:            Type: Wait            SecondsPath: "$.expiryseconds"            Next: FinalState          FinalState:            Type: Task            Resource:              Fn::GetAtt: [hello, Arn]            End: trueplugins:  - serverless-step-functions  - serverless-pseudo-parameters
Retry Failure
functions:  hello:    handler: handler.hellostepFunctions:  stateMachines:    yourRetryMachine:      definition:        Comment: "A Retry example of the Amazon States Language using an AWS Lambda Function"        StartAt: HelloWorld        States:          HelloWorld:            Type: Task            Resource:              Fn::GetAtt: [hello, Arn]            Retry:            - ErrorEquals:              - HandledError              IntervalSeconds: 1              MaxAttempts: 2              BackoffRate: 2            - ErrorEquals:              - States.TaskFailed              IntervalSeconds: 30              MaxAttempts: 2              BackoffRate: 2            - ErrorEquals:              - States.ALL              IntervalSeconds: 5              MaxAttempts: 5              BackoffRate: 2            End: trueplugins:  - serverless-step-functions  - serverless-pseudo-parameters
Parallel
functions:  hello:    handler: handler.hellostepFunctions:  stateMachines:    yourParallelMachine:      definition:        Comment: "An example of the Amazon States Language using a parallel state to execute two branches at the same time."        StartAt: Parallel        States:          Parallel:            Type: Parallel            Next: Final State            Branches:            - StartAt: Wait 20s              States:                Wait 20s:                  Type: Wait                  Seconds: 20                  End: true            - StartAt: Pass              States:                Pass:                  Type: Pass                  Next: Wait 10s                Wait 10s:                  Type: Wait                  Seconds: 10                  End: true          Final State:            Type: Pass            End: trueplugins:  - serverless-step-functions  - serverless-pseudo-parameters
Catch Failure
functions:  hello:    handler: handler.hellostepFunctions:  stateMachines:    yourCatchMachine:      definition:        Comment: "A Catch example of the Amazon States Language using an AWS Lambda Function"        StartAt: HelloWorld        States:          HelloWorld:            Type: Task            Resource:              Fn::GetAtt: [hello, Arn]            Catch:            - ErrorEquals: ["HandledError"]              Next: CustomErrorFallback            - ErrorEquals: ["States.TaskFailed"]              Next: ReservedTypeFallback            - ErrorEquals: ["States.ALL"]              Next: CatchAllFallback            End: true          CustomErrorFallback:            Type: Pass            Result: "This is a fallback from a custom lambda function exception"            End: true          ReservedTypeFallback:            Type: Pass            Result: "This is a fallback from a reserved error code"            End: true          CatchAllFallback:            Type: Pass            Result: "This is a fallback from a reserved error code"            End: trueplugins:  - serverless-step-functions  - serverless-pseudo-parameters
Choice
functions:  hello1:    handler: handler.hello1  hello2:    handler: handler.hello2  hello3:    handler: handler.hello3  hello4:    handler: handler.hello4stepFunctions:  stateMachines:    yourChoiceMachine:      definition:        Comment: "An example of the Amazon States Language using a choice state."        StartAt: FirstState        States:          FirstState:            Type: Task            Resource:              Fn::GetAtt: [hello, Arn]            Next: ChoiceState          ChoiceState:            Type: Choice            Choices:            - Variable: "$.foo"              NumericEquals: 1              Next: FirstMatchState            - Variable: "$.foo"              NumericEquals: 2              Next: SecondMatchState            Default: DefaultState          FirstMatchState:            Type: Task            Resource:              Fn::GetAtt: [hello2, Arn]            Next: NextState          SecondMatchState:            Type: Task            Resource:              Fn::GetAtt: [hello3, Arn]            Next: NextState          DefaultState:            Type: Fail            Cause: "No Matches!"          NextState:            Type: Task            Resource:              Fn::GetAtt: [hello4, Arn]            End: trueplugins:  - serverless-step-functions  - serverless-pseudo-parameters
Map
functions:  entry:    handler: handler.entry  mapTask:    handler: handler.mapTaskstepFunctions:  stateMachines:    yourMapMachine:      definition:        Comment: "A Map example of the Amazon States Language using an AWS Lambda Function"        StartAt: FirstState        States:          FirstState:            Type: Task            Resource:              Fn::GetAtt: [entry, Arn]            Next: mapped_task          mapped_task:            Type: Map            Iterator:              StartAt: FirstMapTask              States:                FirstMapTask:                  Type: Task                  Resource:                    Fn::GetAtt: [mapTask, Arn]                  End: true            End: trueplugins:  - serverless-step-functions\n\n\n\nDatadog recommends the Serverless Framework Plugin for developers using the Serverless Framework to deploy their serverless applications.
The plugin automatically enables instrumentation for applications to collect metrics, traces, and logs by:

Installing the Datadog Lambda library to your Lambda functions as a Lambda layer.
Installing the Datadog Lambda Extension to your Lambda functions as a Lambda layer (addExtension) or subscribing the Datadog Forwarder to your Lambda functions' log groups (forwarderArn).
Making the required configuration changes, such as adding environment variables or additional tracing layers, to your Lambda functions.

Getting started
To quickly get started, follow the installation instructions for Python, Node.js, Ruby, Java, Go, or .NET and view your function's enhanced metrics, traces, and logs in Datadog.
After installation is complete, configure the advanced options to suit your monitoring needs.
Upgrade
Each version of the plugin is published with a specific set of versions of the Datadog Lambda layers. To pick up new features and bug fixes provided by the latest versions of Datadog Lambda layers, upgrade the serverless framework plugin. Test the new version before applying it on your production applications.
Configuration parameters
To further configure your plugin, use the following custom parameters in your serverless.yml:









































































































































































ParameterDescriptionsiteSet which Datadog site to send data to, such as datadoghq.com (default), datadoghq.eu, us3.datadoghq.com, us5.datadoghq.com, ap1.datadoghq.com, or ddog-gov.com. This parameter is required when collecting telemetry using the Datadog Lambda Extension.apiKeyDatadog API key. This parameter is required when collecting telemetry using the Datadog Lambda Extension. Alternatively, you can also set the DATADOG_API_KEY environment variable in your deployment environment.appKeyDatadog app key. Only needed when the monitors field is defined. Alternatively, you can also set the DATADOG_APP_KEY environment variable in your deployment environment.apiKeySecretArnAn alternative to using the apiKey field. The ARN of the secret that is storing the Datadog API key in AWS Secrets Manager. Remember to add the secretsmanager:GetSecretValue permission to the Lambda execution role.apiKMSKeyAn alternative to using the apiKey field. Datadog API key encrypted using KMS. Remember to add the kms:Decrypt permission to the Lambda execution role.envWhen set along with addExtension, a DD_ENV environment variable is added to all Lambda functions with the provided value. Otherwise, an env tag is added to all Lambda functions with the provided value. Defaults to the stage value of the serverless deployment.serviceWhen set along with addExtension, a DD_SERVICE environment variable is added to all Lambda functions with the provided value. Otherwise, a service tag is added to all Lambda functions with the provided value. Defaults to the service value of the serverless project.versionWhen set along with addExtension, a DD_VERSION environment variable is added to all Lambda functions with the provided value. When set along with forwarderArn, a version tag is added to all Lambda functions with the provided value.tagsA comma separated list of key:value pairs as a single string. When set along with extensionLayerVersion, a DD_TAGS environment variable is added to all Lambda functions with the provided value. When set along with forwarderArn, the plugin parses the string and sets each key:value pair as a tag on all Lambda functions.enableXrayTracingSet true to enable X-Ray tracing on the Lambda functions and API Gateway integrations. Defaults to false.enableDDTracingEnable Datadog tracing on the Lambda function. Defaults to true.enableASMEnable Datadog Application Security Management (ASM) on the Lambda function. Requires the Datadog extension to be present (using addExtension or manually added) and enableDDTracing. Defaults to false.enableDDLogsEnable Datadog log collection using the Lambda Extension. Defaults to true. Note: This setting has no effect on logs sent by the Datadog Forwarder.monitorsWhen defined, the Datadog plugin configures monitors for the deployed function. Requires setting DATADOG_API_KEY and DATADOG_APP_KEY in your environment. To learn how to define monitors, see To Enable and Configure a Recommended Serverless Monitor.captureLambdaPayloadCaptures incoming and outgoing AWS Lambda payloads in the Datadog APM spans for Lambda invocations. Defaults to false.enableSourceCodeIntegrationEnable Datadog Source Code Integration for the function. Defaults to true.uploadGitMetadataEnable Git metadata uploading for the function, as a part of source code integration. Set this to false if you have the Datadog Github Integration installed, as it renders Git metadata uploading unnecessary. Defaults to true.subscribeToAccessLogsEnable automatic subscription of the Datadog Forwarder to API Gateway access log groups. Requires setting forwarderArn. Defaults to true.subscribeToExecutionLogsEnable automatic subscription of the Datadog Forwarder to HTTP API  and Websocket log groups. Requires setting forwarderArn. Defaults to true.forwarderArnThe ARN of the Datadog Forwarder to be subscribed to the Lambda or API Gateway log groups.addLayersWhether to install the Datadog Lambda library as a layer. Defaults to true. Set to false when you plan to package the Datadog Lambda library to your function's deployment package on your own so that you can install a specific version of the Datadog Lambda library (Python or Node.js).addExtensionWhether to install the Datadog Lambda Extension as a layer. Defaults to true. When enabled, it's required to set the apiKey and site.excludeWhen set, this plugin ignores all specified functions. Use this parameter if you have any functions that should not include Datadog functionality. Defaults to [].enabledWhen set to false, the Datadog plugin stays inactive. Defaults to true. You can control this option using an environment variable. For example, use enabled: ${strToBool(${env:DD_PLUGIN_ENABLED, true})} to activate/deactivate the plugin during deployment. Alternatively, you can also use the value passed in through --stage to control this option—see example.customHandlerWhen set, the specified handler is set as the handler for all the functions.failOnErrorWhen set, this plugin throws an error if any custom Datadog monitors fail to create or update. This occurs after deploy, but will cause the result of serverless deploy to return a nonzero exit code (to fail user CI). Defaults to false.logLevelThe log level, set to DEBUG for extended logging.skipCloudformationOutputsSet to true if you want to skip adding Datadog Cloudformation Outputs for your stack. This is useful if you are running into the 200 output limit which can cause the stack creation to fail.enableColdStartTracingSet to false to disable Cold Start Tracing. Used in NodeJS and Python. Defaults to true.coldStartTraceMinDurationSets the minimum duration (in milliseconds) for a module load event to be traced via Cold Start Tracing. Number. Defaults to 3.coldStartTraceSkipLibsoptionally skip creating Cold Start Spans for a comma-separated list of libraries. Useful to limit depth or skip known libraries. Default depends on runtime.subdomainSet an optional subdomain to use for app URLs which are printed to output. Defaults to app.enableProfilingEnable the Datadog Continuous Profiler with true. Supported in Beta for NodeJS and Python. Defaults to false.encodeAuthorizerContextWhen set to true for Lambda authorizers, the tracing context will be encoded into the response for propagation. Supported for NodeJS and Python. Defaults to true.decodeAuthorizerContextWhen set to true for Lambdas that are authorized via Lambda authorizers, it will parse and use the encoded tracing context (if found). Supported for NodeJS and Python. Defaults to true.apmFlushDeadlineUsed to determine when to submit spans before a timeout occurs, in milliseconds. When the remaining time in an AWS Lambda invocation is less than the value set, the tracer attempts to submit the current active spans and all finished spans. Supported for NodeJS and Python. Defaults to 100 milliseconds.enableStepFunctionsTracingEnable automatic subscription of the Datadog Forwarder to Step Function log groups and Step Functions tracing. If no Step Function log groups are configured, then they are automatically created. Requires setting forwarderArn. Defaults to false.propagateUpstreamTraceWhen set to true, downstream Stepfunction invocation traces merge with upstream Stepfunction invocations. Defaults to false.redirectHandlersOptionally disable handler redirection if set to false. This should only be set to false when APM is fully disabled. Defaults to true.To use any of these parameters, add a custom > datadog section to your serverless.yml similar to this example:
custom:  datadog:    apiKeySecretArn: "{Datadog_API_Key_Secret_ARN}"    enableXrayTracing: false    enableDDTracing: true    enableDDLogs: true    subscribeToAccessLogs: true    forwarderArn: arn:aws:lambda:us-east-1:000000000000:function:datadog-forwarder    exclude:      - dd-excluded-function
Webpack
If you are using a bundler, such as webpack, see Serverless Tracing and Webpack.
TypeScript
You may encounter the error of missing type definitions. To resolve the error, add datadog-lambda-js and dd-trace to the devDependencies list of your project's package.json.
If you are using serverless-typescript, make sure that serverless-datadog is above the serverless-typescript entry in your serverless.yml. The plugin will automatically detect .ts files.
plugins:  - serverless-plugin-datadog  - serverless-typescript
Disable Plugin for Particular Environment
If you'd like to turn off the plugin based on the environment (passed via --stage), you can use something similar to the example below.
provider:  stage: ${self:opt.stage, 'dev'}custom:  staged: ${self:custom.stageVars.${self:provider.stage}, {}}  stageVars:    dev:      dd_enabled: false  datadog:    enabled: ${self:custom.staged.dd_enabled, true}
Serverless Monitors
There are seven recommended monitors with default values pre-configured.





















































MonitorMetricsThresholdServerless Monitor IDHigh Error Rateaws.lambda.errors/aws.lambda.invocations>= 10%high_error_rateTimeoutaws.lambda.duration.max/aws.lambda.timeout>= 1timeoutOut of Memoryaws.lambda.enhanced.out_of_memory> 0out_of_memoryHigh Iterator Ageaws.lambda.iterator_age.maximum>= 24 hrshigh_iterator_ageHigh Cold Start Rateaws.lambda.enhanced.invocations(cold_start:true)/aws.lambda.enhanced.invocations>= 20%high_cold_start_rateHigh Throttlesaws.lambda.throttles/aws.lambda.invocations>= 20%high_throttlesIncreased Costaws.lambda.enhanced.estimated_cost↑20%increased_cost
To Enable and Configure a Recommended Serverless Monitor
To create a recommended monitor, you must use its respective serverless monitor ID. Note that you must also set the DATADOG_API_KEY and DATADOG_APP_KEY in your environment.
If you’d like to further configure the parameters for a recommended monitor, you can directly define the parameter values below the serverless monitor ID. Parameters not specified under a recommended monitor will use the default recommended value. The query parameter for recommended monitors cannot be directly modified and will default to using the query valued as defined above; however, you may change the threshold value in query by re-defining it within the options parameter. To delete a monitor, remove the monitor from the serverless.yml template. For further documentation on how to define monitor parameters, see the Datadog Monitors API.
Monitor creation occurs after the function is deployed. In the event that a monitor is unsuccessfully created, the function will still be successfully deployed.
To create a recommended monitor with the default values
Define the appropriate serverless monitor ID without specifying any parameter values
custom:  datadog:    addLayers: true    monitors:      - high_error_rate:
To configure a recommended monitor
custom:  datadog:    addLayers: true    monitors:      - high_error_rate:          name: "High Error Rate with Modified Warning Threshold"          message: "More than 10% of the function’s invocations were errors in the selected time range. Notify @data.dog@datadoghq.com @slack-serverless-monitors"          tags: ["modified_error_rate", "serverless", "error_rate"]          require_full_window: true          priority: 2          options:            include_tags: true            notify_audit: true            thresholds:              warning: 0.05              critical: 0.1
To delete a monitor
Removing the serverless monitor ID and its parameters will delete the monitor.
To Enable and Configure a Custom Monitor
To define a custom monitor, you must define a unique serverless monitor ID string in addition to passing in the API key and Application key, DATADOG_API_KEY and DATADOG_APP_KEY, in your environment. The query parameter is required but every other parameter is optional. Define a unique serverless monitor ID string and specify the necessary parameters below. For further documentation on monitor parameters, see the Datadog Monitors API.
custom:  datadog:    addLayers: true    monitors:      - custom_monitor_id:          name: "Custom Monitor"          query: "max(next_1w):forecast(avg:system.load.1{*}, 'linear', 1, interval='60m', history='1w', model='default') >= 3"          message: "Custom message for custom monitor. Notify @data.dog@datadoghq.com @slack-serverless-monitors"          tags: ["custom_monitor", "serverless"]          priority: 3          options:            enable_logs_sample: true            require_full_window: true            include_tags: false            notify_audit: true            notify_no_data: false            thresholds:              warning: 2              critical: 3
Breaking Changes
v5.0.0

When used in conjunction with the Datadog Extension, this plugin sets service and env tags through environment variables instead of Lambda resource tags.
The enableTags parameter was replaced by the new service, env parameters.

v4.0.0

The Datadog Lambda Extension is now the default mechanism for transmitting telemetry to Datadog.

Working with serverless-plugin-warmup
This library is compatible at best effort with serverless-plugin-warmup. If you want to exclude the warmer function from Datadog, use the exclude feature of this library.
To properly package your application, this plugin must be listed after serverless-plugin-warmup in your serverless.yml file:
plugins:  - serverless-plugin-warmup  - serverless-plugin-datadog
Opening Issues
If you encounter a bug with this package, let us know by filing an issue! Before opening a new issue, please search the existing issues to avoid duplicates.
When opening an issue, include your Serverless Framework version, Python/Node.js version, and stack trace if available. Also, please include the steps to reproduce when appropriate.
You can also open an issue for a feature request.
Contributing
If you find an issue with this package and have a fix, open a pull request following the procedures.
Community
For product feedback and questions, join the #serverless channel in the Datadog community on Slack.
License
Unless explicitly stated otherwise, all files in this repository are licensed under the Apache License Version 2.0.
This product includes software developed at Datadog (https://www.datadoghq.com/). Copyright 2021 Datadog, Inc.\n\nPluginsServerless Plugin Datadog




Datadog recommends the Serverless Framework Plugin for developers using the Serverless Framework to deploy their serverless applications.
The plugin automatically enables instrumentation for applications to collect metrics, traces, and logs by:

Installing the Datadog Lambda library to your Lambda functions as a Lambda layer.
Installing the Datadog Lambda Extension to your Lambda functions as a Lambda layer (addExtension) or subscribing the Datadog Forwarder to your Lambda functions' log groups (forwarderArn).
Making the required configuration changes, such as adding environment variables or additional tracing layers, to your Lambda functions.

Getting started
To quickly get started, follow the installation instructions for Python, Node.js, Ruby, Java, Go, or .NET and view your function's enhanced metrics, traces, and logs in Datadog.
After installation is complete, configure the advanced options to suit your monitoring needs.
Upgrade
Each version of the plugin is published with a specific set of versions of the Datadog Lambda layers. To pick up new features and bug fixes provided by the latest versions of Datadog Lambda layers, upgrade the serverless framework plugin. Test the new version before applying it on your production applications.
Configuration parameters
To further configure your plugin, use the following custom parameters in your serverless.yml:









































































































































































ParameterDescriptionsiteSet which Datadog site to send data to, such as datadoghq.com (default), datadoghq.eu, us3.datadoghq.com, us5.datadoghq.com, ap1.datadoghq.com, or ddog-gov.com. This parameter is required when collecting telemetry using the Datadog Lambda Extension.apiKeyDatadog API key. This parameter is required when collecting telemetry using the Datadog Lambda Extension. Alternatively, you can also set the DATADOG_API_KEY environment variable in your deployment environment.appKeyDatadog app key. Only needed when the monitors field is defined. Alternatively, you can also set the DATADOG_APP_KEY environment variable in your deployment environment.apiKeySecretArnAn alternative to using the apiKey field. The ARN of the secret that is storing the Datadog API key in AWS Secrets Manager. Remember to add the secretsmanager:GetSecretValue permission to the Lambda execution role.apiKMSKeyAn alternative to using the apiKey field. Datadog API key encrypted using KMS. Remember to add the kms:Decrypt permission to the Lambda execution role.envWhen set along with addExtension, a DD_ENV environment variable is added to all Lambda functions with the provided value. Otherwise, an env tag is added to all Lambda functions with the provided value. Defaults to the stage value of the serverless deployment.serviceWhen set along with addExtension, a DD_SERVICE environment variable is added to all Lambda functions with the provided value. Otherwise, a service tag is added to all Lambda functions with the provided value. Defaults to the service value of the serverless project.versionWhen set along with addExtension, a DD_VERSION environment variable is added to all Lambda functions with the provided value. When set along with forwarderArn, a version tag is added to all Lambda functions with the provided value.tagsA comma separated list of key:value pairs as a single string. When set along with extensionLayerVersion, a DD_TAGS environment variable is added to all Lambda functions with the provided value. When set along with forwarderArn, the plugin parses the string and sets each key:value pair as a tag on all Lambda functions.enableXrayTracingSet true to enable X-Ray tracing on the Lambda functions and API Gateway integrations. Defaults to false.enableDDTracingEnable Datadog tracing on the Lambda function. Defaults to true.enableASMEnable Datadog Application Security Management (ASM) on the Lambda function. Requires the Datadog extension to be present (using addExtension or manually added) and enableDDTracing. Defaults to false.enableDDLogsEnable Datadog log collection using the Lambda Extension. Defaults to true. Note: This setting has no effect on logs sent by the Datadog Forwarder.monitorsWhen defined, the Datadog plugin configures monitors for the deployed function. Requires setting DATADOG_API_KEY and DATADOG_APP_KEY in your environment. To learn how to define monitors, see To Enable and Configure a Recommended Serverless Monitor.captureLambdaPayloadCaptures incoming and outgoing AWS Lambda payloads in the Datadog APM spans for Lambda invocations. Defaults to false.enableSourceCodeIntegrationEnable Datadog Source Code Integration for the function. Defaults to true.uploadGitMetadataEnable Git metadata uploading for the function, as a part of source code integration. Set this to false if you have the Datadog Github Integration installed, as it renders Git metadata uploading unnecessary. Defaults to true.subscribeToAccessLogsEnable automatic subscription of the Datadog Forwarder to API Gateway access log groups. Requires setting forwarderArn. Defaults to true.subscribeToExecutionLogsEnable automatic subscription of the Datadog Forwarder to HTTP API  and Websocket log groups. Requires setting forwarderArn. Defaults to true.forwarderArnThe ARN of the Datadog Forwarder to be subscribed to the Lambda or API Gateway log groups.addLayersWhether to install the Datadog Lambda library as a layer. Defaults to true. Set to false when you plan to package the Datadog Lambda library to your function's deployment package on your own so that you can install a specific version of the Datadog Lambda library (Python or Node.js).addExtensionWhether to install the Datadog Lambda Extension as a layer. Defaults to true. When enabled, it's required to set the apiKey and site.excludeWhen set, this plugin ignores all specified functions. Use this parameter if you have any functions that should not include Datadog functionality. Defaults to [].enabledWhen set to false, the Datadog plugin stays inactive. Defaults to true. You can control this option using an environment variable. For example, use enabled: ${strToBool(${env:DD_PLUGIN_ENABLED, true})} to activate/deactivate the plugin during deployment. Alternatively, you can also use the value passed in through --stage to control this option—see example.customHandlerWhen set, the specified handler is set as the handler for all the functions.failOnErrorWhen set, this plugin throws an error if any custom Datadog monitors fail to create or update. This occurs after deploy, but will cause the result of serverless deploy to return a nonzero exit code (to fail user CI). Defaults to false.logLevelThe log level, set to DEBUG for extended logging.skipCloudformationOutputsSet to true if you want to skip adding Datadog Cloudformation Outputs for your stack. This is useful if you are running into the 200 output limit which can cause the stack creation to fail.enableColdStartTracingSet to false to disable Cold Start Tracing. Used in NodeJS and Python. Defaults to true.coldStartTraceMinDurationSets the minimum duration (in milliseconds) for a module load event to be traced via Cold Start Tracing. Number. Defaults to 3.coldStartTraceSkipLibsoptionally skip creating Cold Start Spans for a comma-separated list of libraries. Useful to limit depth or skip known libraries. Default depends on runtime.subdomainSet an optional subdomain to use for app URLs which are printed to output. Defaults to app.enableProfilingEnable the Datadog Continuous Profiler with true. Supported in Beta for NodeJS and Python. Defaults to false.encodeAuthorizerContextWhen set to true for Lambda authorizers, the tracing context will be encoded into the response for propagation. Supported for NodeJS and Python. Defaults to true.decodeAuthorizerContextWhen set to true for Lambdas that are authorized via Lambda authorizers, it will parse and use the encoded tracing context (if found). Supported for NodeJS and Python. Defaults to true.apmFlushDeadlineUsed to determine when to submit spans before a timeout occurs, in milliseconds. When the remaining time in an AWS Lambda invocation is less than the value set, the tracer attempts to submit the current active spans and all finished spans. Supported for NodeJS and Python. Defaults to 100 milliseconds.enableStepFunctionsTracingEnable automatic subscription of the Datadog Forwarder to Step Function log groups and Step Functions tracing. If no Step Function log groups are configured, then they are automatically created. Requires setting forwarderArn. Defaults to false.propagateUpstreamTraceWhen set to true, downstream Stepfunction invocation traces merge with upstream Stepfunction invocations. Defaults to false.redirectHandlersOptionally disable handler redirection if set to false. This should only be set to false when APM is fully disabled. Defaults to true.To use any of these parameters, add a custom > datadog section to your serverless.yml similar to this example:
custom:  datadog:    apiKeySecretArn: "{Datadog_API_Key_Secret_ARN}"    enableXrayTracing: false    enableDDTracing: true    enableDDLogs: true    subscribeToAccessLogs: true    forwarderArn: arn:aws:lambda:us-east-1:000000000000:function:datadog-forwarder    exclude:      - dd-excluded-function
Webpack
If you are using a bundler, such as webpack, see Serverless Tracing and Webpack.
TypeScript
You may encounter the error of missing type definitions. To resolve the error, add datadog-lambda-js and dd-trace to the devDependencies list of your project's package.json.
If you are using serverless-typescript, make sure that serverless-datadog is above the serverless-typescript entry in your serverless.yml. The plugin will automatically detect .ts files.
plugins:  - serverless-plugin-datadog  - serverless-typescript
Disable Plugin for Particular Environment
If you'd like to turn off the plugin based on the environment (passed via --stage), you can use something similar to the example below.
provider:  stage: ${self:opt.stage, 'dev'}custom:  staged: ${self:custom.stageVars.${self:provider.stage}, {}}  stageVars:    dev:      dd_enabled: false  datadog:    enabled: ${self:custom.staged.dd_enabled, true}
Serverless Monitors
There are seven recommended monitors with default values pre-configured.





















































MonitorMetricsThresholdServerless Monitor IDHigh Error Rateaws.lambda.errors/aws.lambda.invocations>= 10%high_error_rateTimeoutaws.lambda.duration.max/aws.lambda.timeout>= 1timeoutOut of Memoryaws.lambda.enhanced.out_of_memory> 0out_of_memoryHigh Iterator Ageaws.lambda.iterator_age.maximum>= 24 hrshigh_iterator_ageHigh Cold Start Rateaws.lambda.enhanced.invocations(cold_start:true)/aws.lambda.enhanced.invocations>= 20%high_cold_start_rateHigh Throttlesaws.lambda.throttles/aws.lambda.invocations>= 20%high_throttlesIncreased Costaws.lambda.enhanced.estimated_cost↑20%increased_cost
To Enable and Configure a Recommended Serverless Monitor
To create a recommended monitor, you must use its respective serverless monitor ID. Note that you must also set the DATADOG_API_KEY and DATADOG_APP_KEY in your environment.
If you’d like to further configure the parameters for a recommended monitor, you can directly define the parameter values below the serverless monitor ID. Parameters not specified under a recommended monitor will use the default recommended value. The query parameter for recommended monitors cannot be directly modified and will default to using the query valued as defined above; however, you may change the threshold value in query by re-defining it within the options parameter. To delete a monitor, remove the monitor from the serverless.yml template. For further documentation on how to define monitor parameters, see the Datadog Monitors API.
Monitor creation occurs after the function is deployed. In the event that a monitor is unsuccessfully created, the function will still be successfully deployed.
To create a recommended monitor with the default values
Define the appropriate serverless monitor ID without specifying any parameter values
custom:  datadog:    addLayers: true    monitors:      - high_error_rate:
To configure a recommended monitor
custom:  datadog:    addLayers: true    monitors:      - high_error_rate:          name: "High Error Rate with Modified Warning Threshold"          message: "More than 10% of the function’s invocations were errors in the selected time range. Notify @data.dog@datadoghq.com @slack-serverless-monitors"          tags: ["modified_error_rate", "serverless", "error_rate"]          require_full_window: true          priority: 2          options:            include_tags: true            notify_audit: true            thresholds:              warning: 0.05              critical: 0.1
To delete a monitor
Removing the serverless monitor ID and its parameters will delete the monitor.
To Enable and Configure a Custom Monitor
To define a custom monitor, you must define a unique serverless monitor ID string in addition to passing in the API key and Application key, DATADOG_API_KEY and DATADOG_APP_KEY, in your environment. The query parameter is required but every other parameter is optional. Define a unique serverless monitor ID string and specify the necessary parameters below. For further documentation on monitor parameters, see the Datadog Monitors API.
custom:  datadog:    addLayers: true    monitors:      - custom_monitor_id:          name: "Custom Monitor"          query: "max(next_1w):forecast(avg:system.load.1{*}, 'linear', 1, interval='60m', history='1w', model='default') >= 3"          message: "Custom message for custom monitor. Notify @data.dog@datadoghq.com @slack-serverless-monitors"          tags: ["custom_monitor", "serverless"]          priority: 3          options:            enable_logs_sample: true            require_full_window: true            include_tags: false            notify_audit: true            notify_no_data: false            thresholds:              warning: 2              critical: 3
Breaking Changes
v5.0.0

When used in conjunction with the Datadog Extension, this plugin sets service and env tags through environment variables instead of Lambda resource tags.
The enableTags parameter was replaced by the new service, env parameters.

v4.0.0

The Datadog Lambda Extension is now the default mechanism for transmitting telemetry to Datadog.

Working with serverless-plugin-warmup
This library is compatible at best effort with serverless-plugin-warmup. If you want to exclude the warmer function from Datadog, use the exclude feature of this library.
To properly package your application, this plugin must be listed after serverless-plugin-warmup in your serverless.yml file:
plugins:  - serverless-plugin-warmup  - serverless-plugin-datadog
Opening Issues
If you encounter a bug with this package, let us know by filing an issue! Before opening a new issue, please search the existing issues to avoid duplicates.
When opening an issue, include your Serverless Framework version, Python/Node.js version, and stack trace if available. Also, please include the steps to reproduce when appropriate.
You can also open an issue for a feature request.
Contributing
If you find an issue with this package and have a fix, open a pull request following the procedures.
Community
For product feedback and questions, join the #serverless channel in the Datadog community on Slack.
License
Unless explicitly stated otherwise, all files in this repository are licensed under the Apache License Version 2.0.
This product includes software developed at Datadog (https://www.datadoghq.com/). Copyright 2021 Datadog, Inc.\n\n\n\nserverless-plugin-typescript
  
Originally developed by Prisma Labs, now maintained in scope of Serverless, Inc
Serverless plugin for zero-config Typescript support
Features

Zero-config: Works out of the box without the need to install any other compiler or plugins
Supports ES2015 syntax + features (export, import, async, await, Promise, ...)
Supports sls package, sls deploy and sls deploy function
Supports sls invoke local + --watch mode
Integrates nicely with serverless-offline

Install
yarn add --dev serverless-plugin-typescript typescript# ornpm install -D serverless-plugin-typescript typescript
Add the following plugin to your serverless.yml:
plugins:  - serverless-plugin-typescript
Configure
See example folder for a minimal example.
tsconfig.json
The default tsconfig.json file used by the plugin looks like this:
{  "compilerOptions": {    "preserveConstEnums": true,    "strictNullChecks": true,    "sourceMap": true,    "allowJs": true,    "target": "es5",    "outDir": ".build",    "moduleResolution": "node",    "lib": ["es2015"],    "rootDir": "./"  }}

Note 1: The outDir and rootDir options cannot be overwritten.


Note 2: Don't confuse the tsconfig.json in this repository with the one mentioned above.

Including extra files
All files from package/include will be included in the final build file. See Exclude/Include
Non-standard tsconfig.json locations
Override what tsconfig.json to use with the following snippet in your severless.yaml
custom:  serverlessPluginTypescript:    tsConfigFileLocation: './tsconfig.build.json'
Usage
Google Cloud Functions
When using with Google Cloud Functions via the serverless-google-cloudfunctions
plugin, you simply have to provide a main field in your package.json:
{  // ...  "main": "handler.js",  // ..}
And this plugin will automatically compile your typescript correctly. Note
that the field must refer to the compiled file name, namely, ending with a .js
extension.
If a main field was not found, then this plugin will use index.js. Before
compilation begins, it will check to see that the file indicated exists with a
.ts extension before actually trying to compile it.
Automatic compilation
The normal Serverless deploy procedure will automatically compile with Typescript:

Create the Serverless project with serverless create -t aws-nodejs
Install Serverless Typescript as above
Deploy with serverless deploy

Usage with serverless-offline
The plugin integrates very well with serverless-offline to
simulate AWS Lambda and AWS API Gateway locally.
Add the plugins to your serverless.yml file and make sure that serverless-plugin-typescript
precedes serverless-offline as the order is important:
  plugins:    ...    - serverless-plugin-typescript    ...    - serverless-offline    ...
Run serverless offline or serverless offline start to start the Lambda/API simulation.
In comparison to serverless offline, the start command will fire an init and a end lifecycle hook which is needed for serverless-offline and e.g. serverless-dynamodb-local to switch off resources (see below)
serverless-dynamodb-local
Configure your service the same as mentioned above, but additionally add the serverless-dynamodb-local
plugin as follows:
  plugins:    - serverless-plugin-typescript    - serverless-dynamodb-local    - serverless-offline
Run serverless offline start.
Other useful options
You can reduce the clutter generated by serverless-offline with --dontPrintOutput and
disable timeouts with --noTimeout.
Run a function locally
To run your compiled functions locally you can:
$ serverless invoke local --function <function-name>
Options are:

--function or -f (required) is the name of the function to run
--watch - recompile and run a function locally on source changes
--path or -p (optional) path to JSON or YAML file holding input data
--data or -d (optional) input data

Enabling source-maps
You can easily enable support for source-maps (making stacktraces easier to read) by installing and using the following plugin:
yarn add --dev source-map-support
// inside of your functionimport 'source-map-support/register'
If you are using webpack (most likely). Add devtool: 'source-map' to webpack.config.js:
module.exports = {  .... snip ....  devtool: 'source-map',  .... snip ....}\n\nPluginsServerless Plugin Typescriptserverless-plugin-typescript
  
Originally developed by Prisma Labs, now maintained in scope of Serverless, Inc
Serverless plugin for zero-config Typescript support
Features

Zero-config: Works out of the box without the need to install any other compiler or plugins
Supports ES2015 syntax + features (export, import, async, await, Promise, ...)
Supports sls package, sls deploy and sls deploy function
Supports sls invoke local + --watch mode
Integrates nicely with serverless-offline

Install
yarn add --dev serverless-plugin-typescript typescript# ornpm install -D serverless-plugin-typescript typescript
Add the following plugin to your serverless.yml:
plugins:  - serverless-plugin-typescript
Configure
See example folder for a minimal example.
tsconfig.json
The default tsconfig.json file used by the plugin looks like this:
{  "compilerOptions": {    "preserveConstEnums": true,    "strictNullChecks": true,    "sourceMap": true,    "allowJs": true,    "target": "es5",    "outDir": ".build",    "moduleResolution": "node",    "lib": ["es2015"],    "rootDir": "./"  }}

Note 1: The outDir and rootDir options cannot be overwritten.


Note 2: Don't confuse the tsconfig.json in this repository with the one mentioned above.

Including extra files
All files from package/include will be included in the final build file. See Exclude/Include
Non-standard tsconfig.json locations
Override what tsconfig.json to use with the following snippet in your severless.yaml
custom:  serverlessPluginTypescript:    tsConfigFileLocation: './tsconfig.build.json'
Usage
Google Cloud Functions
When using with Google Cloud Functions via the serverless-google-cloudfunctions
plugin, you simply have to provide a main field in your package.json:
{  // ...  "main": "handler.js",  // ..}
And this plugin will automatically compile your typescript correctly. Note
that the field must refer to the compiled file name, namely, ending with a .js
extension.
If a main field was not found, then this plugin will use index.js. Before
compilation begins, it will check to see that the file indicated exists with a
.ts extension before actually trying to compile it.
Automatic compilation
The normal Serverless deploy procedure will automatically compile with Typescript:

Create the Serverless project with serverless create -t aws-nodejs
Install Serverless Typescript as above
Deploy with serverless deploy

Usage with serverless-offline
The plugin integrates very well with serverless-offline to
simulate AWS Lambda and AWS API Gateway locally.
Add the plugins to your serverless.yml file and make sure that serverless-plugin-typescript
precedes serverless-offline as the order is important:
  plugins:    ...    - serverless-plugin-typescript    ...    - serverless-offline    ...
Run serverless offline or serverless offline start to start the Lambda/API simulation.
In comparison to serverless offline, the start command will fire an init and a end lifecycle hook which is needed for serverless-offline and e.g. serverless-dynamodb-local to switch off resources (see below)
serverless-dynamodb-local
Configure your service the same as mentioned above, but additionally add the serverless-dynamodb-local
plugin as follows:
  plugins:    - serverless-plugin-typescript    - serverless-dynamodb-local    - serverless-offline
Run serverless offline start.
Other useful options
You can reduce the clutter generated by serverless-offline with --dontPrintOutput and
disable timeouts with --noTimeout.
Run a function locally
To run your compiled functions locally you can:
$ serverless invoke local --function <function-name>
Options are:

--function or -f (required) is the name of the function to run
--watch - recompile and run a function locally on source changes
--path or -p (optional) path to JSON or YAML file holding input data
--data or -d (optional) input data

Enabling source-maps
You can easily enable support for source-maps (making stacktraces easier to read) by installing and using the following plugin:
yarn add --dev source-map-support
// inside of your functionimport 'source-map-support/register'
If you are using webpack (most likely). Add devtool: 'source-map' to webpack.config.js:
module.exports = {  .... snip ....  devtool: 'source-map',  .... snip ....}\n\n\n\nServerless IAM Roles Per Function Plugin






A Serverless plugin to easily define IAM roles per function via the use of iamRoleStatements at the function definition block.
Installation
npm install --save-dev serverless-iam-roles-per-function
Or if you want to try out the next upcoming version:
npm install --save-dev serverless-iam-roles-per-function@next
Add the plugin to serverless.yml:
plugins:  - serverless-iam-roles-per-function
Note: Node 6.10 or higher runtime required.
Usage
Define iamRoleStatements definitions at the function level:
functions:  func1:    handler: handler.get    iamRoleStatementsName: my-custom-role-name #optional custom role name setting instead of the default generated one    iamRoleStatements:      - Effect: "Allow"                Action:          - dynamodb:GetItem                Resource: "arn:aws:dynamodb:${self:provider.region}:*:table/mytable"    ...  func2:    handler: handler.put        iamRoleStatements:      - Effect: "Allow"                Action:          - dynamodb:PutItem                Resource: "arn:aws:dynamodb:${self:provider.region}:*:table/mytable"    ...
The plugin will create a dedicated role for each function that has an iamRoleStatements definition. It will include the permissions for create and write to CloudWatch logs, stream events and if VPC is defined: AWSLambdaVPCAccessExecutionRole will be included (as is done when using iamRoleStatements at the provider level).
if iamRoleStatements are not defined at the function level default behavior is maintained and the function will receive the global IAM role. It is possible to define an empty iamRoleStatements for a function and then the function will receive a dedicated role with only the permissions needed for CloudWatch and (if needed) stream events and VPC. Example of defining a function with empty iamRoleStatements and configured VPC. The function will receive a custom role with CloudWatch logs permissions and the policy AWSLambdaVPCAccessExecutionRole:
functions:  func1:    handler: handler.get        iamRoleStatements: []    vpc:      securityGroupIds:        - sg-xxxxxx      subnetIds:        - subnet-xxxx        - subnet-xxxxx
By default, function level iamRoleStatements override the provider level definition. It is also possible to inherit the provider level definition by specifying the option iamRoleStatementsInherit: true:
serverless >= v2.24.0
provider:  name: aws  iam:    role:      statements:        - Effect: "Allow"          Action:            - xray:PutTelemetryRecords            - xray:PutTraceSegments          Resource: "*"  ...functions:  func1:    handler: handler.get    iamRoleStatementsInherit: true    iamRoleStatements:      - Effect: "Allow"                Action:          - dynamodb:GetItem                Resource: "arn:aws:dynamodb:${self:provider.region}:*:table/mytable"
serverless < v2.24.0
provider:  name: aws  iamRoleStatements:    - Effect: "Allow"      Action:        - xray:PutTelemetryRecords        - xray:PutTraceSegments      Resource: "*"  ...functions:  func1:    handler: handler.get    iamRoleStatementsInherit: true    iamRoleStatements:      - Effect: "Allow"                Action:          - dynamodb:GetItem                Resource: "arn:aws:dynamodb:${self:provider.region}:*:table/mytable"
The generated role for func1 will contain both the statements defined at the provider level and the ones defined at the function level.
If you wish to change the default behavior to inherit instead of override it is possible to specify the following custom configuration:
custom:  serverless-iam-roles-per-function:    defaultInherit: true
Role Names
The plugin uses a naming convention for function roles which is similar to the naming convention used by the Serverless Framework. Function roles are named with the following convention:
<service-name>-<stage>-<function-name>-<region>-lambdaRole
AWS has a 64 character limit on role names. If the default naming exceeds 64 chars the plugin will remove the suffix: -lambdaRole to shorten the name. If it still exceeds 64 chars an error will be thrown containing a message of the form:
auto generated role name for function: ${functionName} is too long (over 64 chars).Try setting a custom role name using the property: iamRoleStatementsName.
In this case you should set the role name using the property iamRoleStatementsName. For example:
functions:  func1:    handler: handler.get    iamRoleStatementsName: my-custom-role-name     iamRoleStatements:      - Effect: "Allow"                Action:          - dynamodb:GetItem                Resource: "arn:aws:dynamodb:${self:provider.region}:*:table/mytable"    ...
PermissionsBoundary
Define iamPermissionsBoundary definitions at the function level:
functions:  func1:    handler: handler.get    iamPermissionsBoundary: !Sub arn:aws:iam::xxxxx:policy/your_permissions_boundary_policy    iamRoleStatementsName: my-custom-role-name     iamRoleStatements:      - Effect: "Allow"                Action:          - sqs:*                Resource: "*"    ...
You can set permissionsBoundary for all roles with iamGlobalPermissionsBoundary in custom:
custom:  serverless-iam-roles-per-function:    iamGlobalPermissionsBoundary: !Sub arn:aws:iam::xxxx:policy/permissions-boundary-policy
For more information, see Permissions Boundaries.
Contributing
Contributions are welcome and appreciated.

Before opening a PR it is best to first open an issue. Describe in the issue what you want you plan to implement/fix. Based on the feedback in the issue, you should be able to plan how to implement your PR.
Once ready, open a PR to contribute your code.
To help updating the CHANGELOG.md file, we use standard-version. Make sure to use conventional commit messages as specified at: https://www.conventionalcommits.org/en/v1.0.0/.
Update the release notes at CHANGELOG.md and bump the version by running:
npm run release 

Examine the CHANGELOG.md and update if still required.
Don't forget to commit the files modified by npm run release (we have the auto-commit option disabled by default).
Once the PR is approved and merged into master, travis-ci will automatically tag the version you created and deploy to npmjs under the next tag. You will see your version deployed at: https://www.npmjs.com/package/serverless-iam-roles-per-function?activeTab=versions.
Test your deployed version by installing with the next tag. For example:
npm install --save-dev serverless-iam-roles-per-function@next


Publishing a Production Release (Maintainers)
Once a contributed PR (or multiple PRs) have been merged into master, there is need to publish a production release, after we are sure that the release is stable. Maintainers with commit access to the repository can publish a release by merging into the release branch. Steps to follow:


Verify that the current deployed pre-release version under the next tag in npmjs is working properly. Usually, it is best to allow the next version to gain traction a week or two before releasing. Also, if the version solves a specific reported issue, ask the community on the issue to test out the next version.


Make sure the version being used in master hasn't been released. This can happen if a PR was merged without bumping the version by running npm run release. If the version needs to be advanced, open a PR to advance the version as specified here.


Open a PR to merge into the release branch. Use as a base the release branch and compare the tag version to release. For example:



Once approved by another maintainer, merge the PR.


Make sure to check after the Travis CI build completes that the release has been published to the latest tag on nmpjs.


More Info
Introduction post:
Serverless Framework: Defining Per-Function IAM Roles
Note: Serverless Framework provides support for defining custom IAM roles on a per function level through the use of the role property and creating CloudFormation resources, as documented here. This plugin doesn't support defining both the role property and iamRoleStatements at the function level.\n\nPluginsServerless IAM Roles Per FunctionServerless IAM Roles Per Function Plugin






A Serverless plugin to easily define IAM roles per function via the use of iamRoleStatements at the function definition block.
Installation
npm install --save-dev serverless-iam-roles-per-function
Or if you want to try out the next upcoming version:
npm install --save-dev serverless-iam-roles-per-function@next
Add the plugin to serverless.yml:
plugins:  - serverless-iam-roles-per-function
Note: Node 6.10 or higher runtime required.
Usage
Define iamRoleStatements definitions at the function level:
functions:  func1:    handler: handler.get    iamRoleStatementsName: my-custom-role-name #optional custom role name setting instead of the default generated one    iamRoleStatements:      - Effect: "Allow"                Action:          - dynamodb:GetItem                Resource: "arn:aws:dynamodb:${self:provider.region}:*:table/mytable"    ...  func2:    handler: handler.put        iamRoleStatements:      - Effect: "Allow"                Action:          - dynamodb:PutItem                Resource: "arn:aws:dynamodb:${self:provider.region}:*:table/mytable"    ...
The plugin will create a dedicated role for each function that has an iamRoleStatements definition. It will include the permissions for create and write to CloudWatch logs, stream events and if VPC is defined: AWSLambdaVPCAccessExecutionRole will be included (as is done when using iamRoleStatements at the provider level).
if iamRoleStatements are not defined at the function level default behavior is maintained and the function will receive the global IAM role. It is possible to define an empty iamRoleStatements for a function and then the function will receive a dedicated role with only the permissions needed for CloudWatch and (if needed) stream events and VPC. Example of defining a function with empty iamRoleStatements and configured VPC. The function will receive a custom role with CloudWatch logs permissions and the policy AWSLambdaVPCAccessExecutionRole:
functions:  func1:    handler: handler.get        iamRoleStatements: []    vpc:      securityGroupIds:        - sg-xxxxxx      subnetIds:        - subnet-xxxx        - subnet-xxxxx
By default, function level iamRoleStatements override the provider level definition. It is also possible to inherit the provider level definition by specifying the option iamRoleStatementsInherit: true:
serverless >= v2.24.0
provider:  name: aws  iam:    role:      statements:        - Effect: "Allow"          Action:            - xray:PutTelemetryRecords            - xray:PutTraceSegments          Resource: "*"  ...functions:  func1:    handler: handler.get    iamRoleStatementsInherit: true    iamRoleStatements:      - Effect: "Allow"                Action:          - dynamodb:GetItem                Resource: "arn:aws:dynamodb:${self:provider.region}:*:table/mytable"
serverless < v2.24.0
provider:  name: aws  iamRoleStatements:    - Effect: "Allow"      Action:        - xray:PutTelemetryRecords        - xray:PutTraceSegments      Resource: "*"  ...functions:  func1:    handler: handler.get    iamRoleStatementsInherit: true    iamRoleStatements:      - Effect: "Allow"                Action:          - dynamodb:GetItem                Resource: "arn:aws:dynamodb:${self:provider.region}:*:table/mytable"
The generated role for func1 will contain both the statements defined at the provider level and the ones defined at the function level.
If you wish to change the default behavior to inherit instead of override it is possible to specify the following custom configuration:
custom:  serverless-iam-roles-per-function:    defaultInherit: true
Role Names
The plugin uses a naming convention for function roles which is similar to the naming convention used by the Serverless Framework. Function roles are named with the following convention:
<service-name>-<stage>-<function-name>-<region>-lambdaRole
AWS has a 64 character limit on role names. If the default naming exceeds 64 chars the plugin will remove the suffix: -lambdaRole to shorten the name. If it still exceeds 64 chars an error will be thrown containing a message of the form:
auto generated role name for function: ${functionName} is too long (over 64 chars).Try setting a custom role name using the property: iamRoleStatementsName.
In this case you should set the role name using the property iamRoleStatementsName. For example:
functions:  func1:    handler: handler.get    iamRoleStatementsName: my-custom-role-name     iamRoleStatements:      - Effect: "Allow"                Action:          - dynamodb:GetItem                Resource: "arn:aws:dynamodb:${self:provider.region}:*:table/mytable"    ...
PermissionsBoundary
Define iamPermissionsBoundary definitions at the function level:
functions:  func1:    handler: handler.get    iamPermissionsBoundary: !Sub arn:aws:iam::xxxxx:policy/your_permissions_boundary_policy    iamRoleStatementsName: my-custom-role-name     iamRoleStatements:      - Effect: "Allow"                Action:          - sqs:*                Resource: "*"    ...
You can set permissionsBoundary for all roles with iamGlobalPermissionsBoundary in custom:
custom:  serverless-iam-roles-per-function:    iamGlobalPermissionsBoundary: !Sub arn:aws:iam::xxxx:policy/permissions-boundary-policy
For more information, see Permissions Boundaries.
Contributing
Contributions are welcome and appreciated.

Before opening a PR it is best to first open an issue. Describe in the issue what you want you plan to implement/fix. Based on the feedback in the issue, you should be able to plan how to implement your PR.
Once ready, open a PR to contribute your code.
To help updating the CHANGELOG.md file, we use standard-version. Make sure to use conventional commit messages as specified at: https://www.conventionalcommits.org/en/v1.0.0/.
Update the release notes at CHANGELOG.md and bump the version by running:
npm run release 

Examine the CHANGELOG.md and update if still required.
Don't forget to commit the files modified by npm run release (we have the auto-commit option disabled by default).
Once the PR is approved and merged into master, travis-ci will automatically tag the version you created and deploy to npmjs under the next tag. You will see your version deployed at: https://www.npmjs.com/package/serverless-iam-roles-per-function?activeTab=versions.
Test your deployed version by installing with the next tag. For example:
npm install --save-dev serverless-iam-roles-per-function@next


Publishing a Production Release (Maintainers)
Once a contributed PR (or multiple PRs) have been merged into master, there is need to publish a production release, after we are sure that the release is stable. Maintainers with commit access to the repository can publish a release by merging into the release branch. Steps to follow:


Verify that the current deployed pre-release version under the next tag in npmjs is working properly. Usually, it is best to allow the next version to gain traction a week or two before releasing. Also, if the version solves a specific reported issue, ask the community on the issue to test out the next version.


Make sure the version being used in master hasn't been released. This can happen if a PR was merged without bumping the version by running npm run release. If the version needs to be advanced, open a PR to advance the version as specified here.


Open a PR to merge into the release branch. Use as a base the release branch and compare the tag version to release. For example:



Once approved by another maintainer, merge the PR.


Make sure to check after the Travis CI build completes that the release has been published to the latest tag on nmpjs.


More Info
Introduction post:
Serverless Framework: Defining Per-Function IAM Roles
Note: Serverless Framework provides support for defining custom IAM roles on a per function level through the use of the role property and creating CloudFormation resources, as documented here. This plugin doesn't support defining both the role property and iamRoleStatements at the function level.\n\n\n\nServerless Python Requirements




A Serverless Framework plugin to automatically bundle dependencies from requirements.txt and make them available in your PYTHONPATH.

Originally developed by Capital One, now maintained in scope of Serverless, Inc
Capital One considers itself the bank a technology company would build. It's delivering best-in-class innovation so that its millions of customers can manage their finances with ease. Capital One is all-in on the cloud and is a leader in the adoption of open source, RESTful APIs, microservices and containers. We build our own products and release them with a speed and agility that allows us to get new customer experiences to market quickly. Our engineers use artificial intelligence and machine learning to transform real-time data, software and algorithms into the future of finance, reimagined.

Install
sls plugin install -n serverless-python-requirements
This will automatically add the plugin to your project's package.json and the plugins section of its
serverless.yml. That's all that's needed for basic use! The plugin will now bundle your python
dependencies specified in your requirements.txt or Pipfile when you run sls deploy.
For a more in depth introduction on how to use this plugin, check out
this post on the Serverless Blog
If you're on a mac, check out these notes about using python installed by brew.
Cross compiling
Compiling non-pure-Python modules or fetching their manylinux wheels is
supported on non-linux OSs via the use of Docker and official AWS build images.
To enable docker usage, add the following to your serverless.yml:
custom:  pythonRequirements:    dockerizePip: true
The dockerizePip option supports a special case in addition to booleans of 'non-linux' which makes
it dockerize only on non-linux environments.
To utilize your own Docker container instead of the default, add the following to your serverless.yml:
custom:  pythonRequirements:    dockerImage: <image name>:tag
This must be the full image name and tag to use, including the runtime specific tag if applicable.
Alternatively, you can define your Docker image in your own Dockerfile and add the following to your serverless.yml:
custom:  pythonRequirements:    dockerFile: ./path/to/Dockerfile
With Dockerfile the path to the Dockerfile that must be in the current folder (or a subfolder).
Please note the dockerImage and the dockerFile are mutually exclusive.
To install requirements from private git repositories, add the following to your serverless.yml:
custom:  pythonRequirements:    dockerizePip: true    dockerSsh: true
The dockerSsh option will mount your $HOME/.ssh/id_rsa and $HOME/.ssh/known_hosts as a
volume in the docker container.
In case you want to use a different key, you can specify the path (absolute) to it through dockerPrivateKey option:
custom:  pythonRequirements:    dockerizePip: true    dockerSsh: true    dockerPrivateKey: /home/.ssh/id_ed25519
If your SSH key is password protected, you can use ssh-agent
because $SSH_AUTH_SOCK is also mounted & the env var is set.
It is important that the host of your private repositories has already been added in your
$HOME/.ssh/known_hosts file, as the install process will fail otherwise due to host authenticity
failure.
You can also pass environment variables to docker by specifying them in dockerEnv
option:
custom:  pythonRequirements:    dockerEnv:      - https_proxy
:checkered_flag: Windows notes
:sparkles::cake::sparkles: Pipenv support
Requires pipenv in version 2022-04-08 or higher.
If you include a Pipfile and have pipenv installed, this will use pipenv to generate requirements instead of a requirements.txt. It is fully compatible with all options such as zip and
dockerizePip. If you don't want this plugin to generate it for you, set the following option:
custom:  pythonRequirements:    usePipenv: false
:sparkles::pencil::sparkles: Poetry support
If you include a pyproject.toml and have poetry installed instead of a requirements.txt this will use
poetry export --without-hashes -f requirements.txt -o requirements.txt --with-credentials to generate them. It is fully compatible with all options such as zip and
dockerizePip. If you don't want this plugin to generate it for you, set the following option:
custom:  pythonRequirements:    usePoetry: false
Be aware that if no poetry.lock file is present, a new one will be generated on the fly. To help having predictable builds,
you can set the requirePoetryLockFile flag to true to throw an error when poetry.lock is missing.
custom:  pythonRequirements:    requirePoetryLockFile: false
If your Poetry configuration includes custom dependency groups, they will not be installed automatically. To include them in the deployment package, use the poetryWithGroups, poetryWithoutGroups and poetryOnlyGroups options which wrap poetry export's --with, --without and --only parameters.
custom:  pythonRequirements:    poetryWithGroups:      - internal_dependencies      - lambda_dependencies
Poetry with git dependencies
Poetry by default generates the exported requirements.txt file with -e and that breaks pip with -t parameter
(used to install all requirements in a specific folder). In order to fix that we remove all -e from the generated file but,
for that to work you need to add the git dependencies in a specific way.
Instead of:
[tool.poetry.dependencies]bottle = {git = "git@github.com/bottlepy/bottle.git", tag = "0.12.16"}
Use:
[tool.poetry.dependencies]bottle = {git = "https://git@github.com/bottlepy/bottle.git", tag = "0.12.16"}
Or, if you have an SSH key configured:
[tool.poetry.dependencies]bottle = {git = "ssh://git@github.com/bottlepy/bottle.git", tag = "0.12.16"}
Dealing with Lambda's size limitations
To help deal with potentially large dependencies (for example: numpy, scipy
and scikit-learn) there is support for compressing the libraries. This does
require a minor change to your code to decompress them. To enable this add the
following to your serverless.yml:
custom:  pythonRequirements:    zip: true
and add this to your handler module before any code that imports your deps:
try:  import unzip_requirementsexcept ImportError:  pass
Slim Package
Works on non 'win32' environments: Docker, WSL are included
To remove the tests, information and caches from the installed packages,
enable the slim option. This will: strip the .so files, remove __pycache__
and dist-info directories as well as .pyc and .pyo files.
custom:  pythonRequirements:    slim: true
Custom Removal Patterns
To specify additional directories to remove from the installed packages,
define a list of patterns in the serverless config using the slimPatterns
option and glob syntax. These patterns will be added to the default ones (**/*.py[c|o], **/__pycache__*, **/*.dist-info*).
Note, the glob syntax matches against whole paths, so to match a file in any
directory, start your pattern with **/.
custom:  pythonRequirements:    slim: true    slimPatterns:      - '**/*.egg-info*'
To overwrite the default patterns set the option slimPatternsAppendDefaults to false (true by default).
custom:  pythonRequirements:    slim: true    slimPatternsAppendDefaults: false    slimPatterns:      - '**/*.egg-info*'
This will remove all folders within the installed requirements that match
the names in slimPatterns
Option not to strip binaries
In some cases, stripping binaries leads to problems like "ELF load command address/offset not properly aligned", even when done in the Docker environment. You can still slim down the package without *.so files with:
custom:  pythonRequirements:    slim: true    strip: false
Lambda Layer
Another method for dealing with large dependencies is to put them into a
Lambda Layer.
Simply add the layer option to the configuration.
custom:  pythonRequirements:    layer: true
The requirements will be zipped up and a layer will be created automatically.
Now just add the reference to the functions that will use the layer.
functions:  hello:    handler: handler.hello    layers:      - Ref: PythonRequirementsLambdaLayer
If the layer requires additional or custom configuration, add them onto the layer option.
custom:  pythonRequirements:    layer:      name: ${self:provider.stage}-layerName      description: Python requirements lambda layer      compatibleRuntimes:        - python3.7      licenseInfo: GPLv3      allowedAccounts:        - '*'
Omitting Packages
You can omit a package from deployment with the noDeploy option. Note that
dependencies of omitted packages must explicitly be omitted too.
This example makes it instead omit pytest:
custom:  pythonRequirements:    noDeploy:      - pytest
Extra Config Options
Caching
You can enable two kinds of caching with this plugin which are currently both ENABLED by default.
First, a download cache that will cache downloads that pip needs to compile the packages.
And second, a what we call "static caching" which caches output of pip after compiling everything for your requirements file.
Since generally requirements.txt files rarely change, you will often see large amounts of speed improvements when enabling the static cache feature.
These caches will be shared between all your projects if no custom cacheLocation is specified (see below).
Please note: This has replaced the previously recommended usage of "--cache-dir" in the pipCmdExtraArgs
custom:  pythonRequirements:    useDownloadCache: true    useStaticCache: true
Other caching options
There are two additional options related to caching.
You can specify where in your system that this plugin caches with the cacheLocation option.
By default it will figure out automatically where based on your username and your OS to store the cache via the appdirectory module.
Additionally, you can specify how many max static caches to store with staticCacheMaxVersions, as a simple attempt to limit disk space usage for caching.
This is DISABLED (set to 0) by default.
Example:
custom:  pythonRequirements:    useStaticCache: true    useDownloadCache: true    cacheLocation: '/home/user/.my_cache_goes_here'    staticCacheMaxVersions: 10
Extra pip arguments
You can specify extra arguments supported by pip to be passed to pip like this:
custom:  pythonRequirements:    pipCmdExtraArgs:      - --compile
Extra Docker arguments
You can specify extra arguments to be passed to docker build during the build step, and docker run during the dockerized pip install step:
custom:  pythonRequirements:    dockerizePip: true    dockerBuildCmdExtraArgs: ['--build-arg', 'MY_GREAT_ARG=123']    dockerRunCmdExtraArgs: ['-v', '${env:PWD}:/my-app']
Customize requirements file name
Some pip workflows involve using requirements files not named
requirements.txt.
To support these, this plugin has the following option:
custom:  pythonRequirements:    fileName: requirements-prod.txt
Per-function requirements
Note: this feature does not work with Pipenv/Poetry, it requires requirements.txt
files for your Python modules.
If you have different python functions, with different sets of requirements, you can avoid
including all the unecessary dependencies of your functions by using the following structure:
├── serverless.yml├── function1│      ├── requirements.txt│      └── index.py└── function2       ├── requirements.txt       └── index.py
With the content of your serverless.yml containing:
package:  individually: truefunctions:  func1:    handler: index.handler    module: function1  func2:    handler: index.handler    module: function2
The result is 2 zip archives, with only the requirements for function1 in the first one, and only
the requirements for function2 in the second one.
Quick notes on the config file:

The module field must be used to tell the plugin where to find the requirements.txt file for
each function.
The handler field must not be prefixed by the folder name (already known through module) as
the root of the zip artifact is already the path to your function.

Customize Python executable
Sometimes your Python executable isn't available on your $PATH as python2.7
or python3.6 (for example, windows or using pyenv).
To support this, this plugin has the following option:
custom:  pythonRequirements:    pythonBin: /opt/python3.6/bin/python
Vendor library directory
For certain libraries, default packaging produces too large an installation,
even when zipping. In those cases it may be necessary to tailor make a version
of the module. In that case you can store them in a directory and use the
vendor option, and the plugin will copy them along with all the other
dependencies to install:
custom:  pythonRequirements:    vendor: ./vendored-librariesfunctions:  hello:    handler: hello.handler    vendor: ./hello-vendor # The option is also available at the function level
Manual invocation
The .requirements and requirements.zip (if using zip support) files are left
behind to speed things up on subsequent deploys. To clean them up, run:
sls requirements clean
You can also create them (and unzip_requirements if
using zip support) manually with:
sls requirements install
The pip download/static cache is outside the serverless folder, and should be manually cleaned when i.e. changing python versions:
sls requirements cleanCache
Invalidate requirements caches on package
If you are using your own Python library, you have to cleanup
.requirements on any update. You can use the following option to cleanup
.requirements everytime you package.
custom:  pythonRequirements:    invalidateCaches: true
:apple::beer::snake: Mac Brew installed Python notes
Brew wilfully breaks the --target option with no seeming intention to fix it
which causes issues since this uses that option. There are a few easy workarounds for this:

Install Python from python.org and specify it with the
pythonBin option.

OR

Create a virtualenv and activate it while using serverless.

OR

Install Docker and use the dockerizePip option.

Also, brew seems to cause issues with pipenv,
so make sure you install pipenv using pip.
:checkered_flag: Windows dockerizePip notes
For usage of dockerizePip on Windows do Step 1 only if running serverless on windows, or do both Step 1 & 2 if running serverless inside WSL.

Enabling shared volume in Windows Docker Taskbar settings
Installing the Docker client on Windows Subsystem for Linux (Ubuntu)

Native Code Dependencies During Build
Some Python packages require extra OS dependencies to build successfully. To deal with this, replace the default image with a Dockerfile like:
FROM public.ecr.aws/sam/build-python3.9# Install your dependenciesRUN yum -y install mysql-devel
Then update your serverless.yml:
custom:  pythonRequirements:    dockerFile: Dockerfile
Native Code Dependencies During Runtime
Some Python packages require extra OS libraries (*.so files) at runtime. You need to manually include these files in the root directory of your Serverless package. The simplest way to do this is to use the dockerExtraFiles option.
For instance, the mysqlclient package requires libmysqlclient.so.1020. If you use the Dockerfile from the previous section, add an item to the dockerExtraFiles option in your serverless.yml:
custom:  pythonRequirements:    dockerExtraFiles:      - /usr/lib64/mysql57/libmysqlclient.so.1020
Then verify the library gets included in your package:
sls packagezipinfo .serverless/xxx.zip
If you can't see the library, you might need to adjust your package include/exclude configuration in serverless.yml.
Optimising packaging time
If you wish to exclude most of the files in your project, and only include the source files of your lambdas and their dependencies you may well use an approach like this:
package:  individually: false  include:    - './src/lambda_one/**'    - './src/lambda_two/**'  exclude:    - '**'
This will be very slow. Serverless adds a default "&ast;&ast;" include. If you are using the cacheLocation parameter to this plugin, this will result in all of the cached files' names being loaded and then subsequently discarded because of the exclude pattern. To avoid this happening you can add a negated include pattern, as is observed in https://github.com/serverless/serverless/pull/5825.
Use this approach instead:
package:  individually: false  include:    - '!./**'    - './src/lambda_one/**'    - './src/lambda_two/**'  exclude:    - '**'
Custom Provider Support
Scaleway
This plugin is compatible with the Scaleway Serverless Framework Plugin to package dependencies for Python functions deployed on Scaleway. To use it, add the following to your serverless.yml:
provider:  name: scaleway  runtime: python311plugins:  - serverless-python-requirements  - serverless-scaleway-functions
To handle native dependencies, it's recommended to use the Docker builder with the image provided by Scaleway:
custom:  pythonRequirements:    # Can use any Python version supported by Scaleway    dockerImage: rg.fr-par.scw.cloud/scwfunctionsruntimes-public/python-dep:3.11
Contributors

@dschep - Original developer
@azurelogic - logging & documentation fixes
@abetomo - style & linting
@angstwad - deploy --function support
@mather - the cache invalidation option
@rmax - the extra pip args option
@bsamuel-ui - Python 3 support, current maintainer
@suxor42 - fixing permission issues with Docker on Linux
@mbeltran213 - fixing docker linux -u option bug
@Tethik - adding usePipenv option
@miketheman - fixing bug with includes when using zip option, update eslint,
@wattdave - fixing bug when using deploymentBucket
@heri16 - fixing Docker support in Windows
@ryansb - package individually support
@cgrimal - Private SSH Repo access in Docker, dockerFile option
to build a custom docker image, real per-function requirements, and the vendor option
@kichik - Imposed windows & noDeploy support,
switched to adding files straight to zip instead of creating symlinks, and
improved pip cache support when using docker.
@dee-me-tree-or-love - the slim package option
@alexjurkiewicz - docs about docker workflows
@andrewfarley - Implemented download caching and static caching
@bweigel - adding the slimPatternsAppendDefaults option & fixing per-function packaging when some functions don't have requirements & Porting tests from bats to js!
Poetry support

@squaresurf
@drice
@ofercaspi
@tpansino


@david-mk-lawrence - added Lambda Layer support
@bryantbriggs - Fixing CI/CD
@jacksgt - Fixing pip issues
@lephuongbg - Fixing single function deployment
@rileypriddle - Introducing schema validation for module property
@martinezpl - Fixing test issues, adding dockerPrivateKey option\n\nPluginsServerless Python RequirementsServerless Python Requirements




A Serverless Framework plugin to automatically bundle dependencies from requirements.txt and make them available in your PYTHONPATH.

Originally developed by Capital One, now maintained in scope of Serverless, Inc
Capital One considers itself the bank a technology company would build. It's delivering best-in-class innovation so that its millions of customers can manage their finances with ease. Capital One is all-in on the cloud and is a leader in the adoption of open source, RESTful APIs, microservices and containers. We build our own products and release them with a speed and agility that allows us to get new customer experiences to market quickly. Our engineers use artificial intelligence and machine learning to transform real-time data, software and algorithms into the future of finance, reimagined.

Install
sls plugin install -n serverless-python-requirements
This will automatically add the plugin to your project's package.json and the plugins section of its
serverless.yml. That's all that's needed for basic use! The plugin will now bundle your python
dependencies specified in your requirements.txt or Pipfile when you run sls deploy.
For a more in depth introduction on how to use this plugin, check out
this post on the Serverless Blog
If you're on a mac, check out these notes about using python installed by brew.
Cross compiling
Compiling non-pure-Python modules or fetching their manylinux wheels is
supported on non-linux OSs via the use of Docker and official AWS build images.
To enable docker usage, add the following to your serverless.yml:
custom:  pythonRequirements:    dockerizePip: true
The dockerizePip option supports a special case in addition to booleans of 'non-linux' which makes
it dockerize only on non-linux environments.
To utilize your own Docker container instead of the default, add the following to your serverless.yml:
custom:  pythonRequirements:    dockerImage: <image name>:tag
This must be the full image name and tag to use, including the runtime specific tag if applicable.
Alternatively, you can define your Docker image in your own Dockerfile and add the following to your serverless.yml:
custom:  pythonRequirements:    dockerFile: ./path/to/Dockerfile
With Dockerfile the path to the Dockerfile that must be in the current folder (or a subfolder).
Please note the dockerImage and the dockerFile are mutually exclusive.
To install requirements from private git repositories, add the following to your serverless.yml:
custom:  pythonRequirements:    dockerizePip: true    dockerSsh: true
The dockerSsh option will mount your $HOME/.ssh/id_rsa and $HOME/.ssh/known_hosts as a
volume in the docker container.
In case you want to use a different key, you can specify the path (absolute) to it through dockerPrivateKey option:
custom:  pythonRequirements:    dockerizePip: true    dockerSsh: true    dockerPrivateKey: /home/.ssh/id_ed25519
If your SSH key is password protected, you can use ssh-agent
because $SSH_AUTH_SOCK is also mounted & the env var is set.
It is important that the host of your private repositories has already been added in your
$HOME/.ssh/known_hosts file, as the install process will fail otherwise due to host authenticity
failure.
You can also pass environment variables to docker by specifying them in dockerEnv
option:
custom:  pythonRequirements:    dockerEnv:      - https_proxy
:checkered_flag: Windows notes
:sparkles::cake::sparkles: Pipenv support
Requires pipenv in version 2022-04-08 or higher.
If you include a Pipfile and have pipenv installed, this will use pipenv to generate requirements instead of a requirements.txt. It is fully compatible with all options such as zip and
dockerizePip. If you don't want this plugin to generate it for you, set the following option:
custom:  pythonRequirements:    usePipenv: false
:sparkles::pencil::sparkles: Poetry support
If you include a pyproject.toml and have poetry installed instead of a requirements.txt this will use
poetry export --without-hashes -f requirements.txt -o requirements.txt --with-credentials to generate them. It is fully compatible with all options such as zip and
dockerizePip. If you don't want this plugin to generate it for you, set the following option:
custom:  pythonRequirements:    usePoetry: false
Be aware that if no poetry.lock file is present, a new one will be generated on the fly. To help having predictable builds,
you can set the requirePoetryLockFile flag to true to throw an error when poetry.lock is missing.
custom:  pythonRequirements:    requirePoetryLockFile: false
If your Poetry configuration includes custom dependency groups, they will not be installed automatically. To include them in the deployment package, use the poetryWithGroups, poetryWithoutGroups and poetryOnlyGroups options which wrap poetry export's --with, --without and --only parameters.
custom:  pythonRequirements:    poetryWithGroups:      - internal_dependencies      - lambda_dependencies
Poetry with git dependencies
Poetry by default generates the exported requirements.txt file with -e and that breaks pip with -t parameter
(used to install all requirements in a specific folder). In order to fix that we remove all -e from the generated file but,
for that to work you need to add the git dependencies in a specific way.
Instead of:
[tool.poetry.dependencies]bottle = {git = "git@github.com/bottlepy/bottle.git", tag = "0.12.16"}
Use:
[tool.poetry.dependencies]bottle = {git = "https://git@github.com/bottlepy/bottle.git", tag = "0.12.16"}
Or, if you have an SSH key configured:
[tool.poetry.dependencies]bottle = {git = "ssh://git@github.com/bottlepy/bottle.git", tag = "0.12.16"}
Dealing with Lambda's size limitations
To help deal with potentially large dependencies (for example: numpy, scipy
and scikit-learn) there is support for compressing the libraries. This does
require a minor change to your code to decompress them. To enable this add the
following to your serverless.yml:
custom:  pythonRequirements:    zip: true
and add this to your handler module before any code that imports your deps:
try:  import unzip_requirementsexcept ImportError:  pass
Slim Package
Works on non 'win32' environments: Docker, WSL are included
To remove the tests, information and caches from the installed packages,
enable the slim option. This will: strip the .so files, remove __pycache__
and dist-info directories as well as .pyc and .pyo files.
custom:  pythonRequirements:    slim: true
Custom Removal Patterns
To specify additional directories to remove from the installed packages,
define a list of patterns in the serverless config using the slimPatterns
option and glob syntax. These patterns will be added to the default ones (**/*.py[c|o], **/__pycache__*, **/*.dist-info*).
Note, the glob syntax matches against whole paths, so to match a file in any
directory, start your pattern with **/.
custom:  pythonRequirements:    slim: true    slimPatterns:      - '**/*.egg-info*'
To overwrite the default patterns set the option slimPatternsAppendDefaults to false (true by default).
custom:  pythonRequirements:    slim: true    slimPatternsAppendDefaults: false    slimPatterns:      - '**/*.egg-info*'
This will remove all folders within the installed requirements that match
the names in slimPatterns
Option not to strip binaries
In some cases, stripping binaries leads to problems like "ELF load command address/offset not properly aligned", even when done in the Docker environment. You can still slim down the package without *.so files with:
custom:  pythonRequirements:    slim: true    strip: false
Lambda Layer
Another method for dealing with large dependencies is to put them into a
Lambda Layer.
Simply add the layer option to the configuration.
custom:  pythonRequirements:    layer: true
The requirements will be zipped up and a layer will be created automatically.
Now just add the reference to the functions that will use the layer.
functions:  hello:    handler: handler.hello    layers:      - Ref: PythonRequirementsLambdaLayer
If the layer requires additional or custom configuration, add them onto the layer option.
custom:  pythonRequirements:    layer:      name: ${self:provider.stage}-layerName      description: Python requirements lambda layer      compatibleRuntimes:        - python3.7      licenseInfo: GPLv3      allowedAccounts:        - '*'
Omitting Packages
You can omit a package from deployment with the noDeploy option. Note that
dependencies of omitted packages must explicitly be omitted too.
This example makes it instead omit pytest:
custom:  pythonRequirements:    noDeploy:      - pytest
Extra Config Options
Caching
You can enable two kinds of caching with this plugin which are currently both ENABLED by default.
First, a download cache that will cache downloads that pip needs to compile the packages.
And second, a what we call "static caching" which caches output of pip after compiling everything for your requirements file.
Since generally requirements.txt files rarely change, you will often see large amounts of speed improvements when enabling the static cache feature.
These caches will be shared between all your projects if no custom cacheLocation is specified (see below).
Please note: This has replaced the previously recommended usage of "--cache-dir" in the pipCmdExtraArgs
custom:  pythonRequirements:    useDownloadCache: true    useStaticCache: true
Other caching options
There are two additional options related to caching.
You can specify where in your system that this plugin caches with the cacheLocation option.
By default it will figure out automatically where based on your username and your OS to store the cache via the appdirectory module.
Additionally, you can specify how many max static caches to store with staticCacheMaxVersions, as a simple attempt to limit disk space usage for caching.
This is DISABLED (set to 0) by default.
Example:
custom:  pythonRequirements:    useStaticCache: true    useDownloadCache: true    cacheLocation: '/home/user/.my_cache_goes_here'    staticCacheMaxVersions: 10
Extra pip arguments
You can specify extra arguments supported by pip to be passed to pip like this:
custom:  pythonRequirements:    pipCmdExtraArgs:      - --compile
Extra Docker arguments
You can specify extra arguments to be passed to docker build during the build step, and docker run during the dockerized pip install step:
custom:  pythonRequirements:    dockerizePip: true    dockerBuildCmdExtraArgs: ['--build-arg', 'MY_GREAT_ARG=123']    dockerRunCmdExtraArgs: ['-v', '${env:PWD}:/my-app']
Customize requirements file name
Some pip workflows involve using requirements files not named
requirements.txt.
To support these, this plugin has the following option:
custom:  pythonRequirements:    fileName: requirements-prod.txt
Per-function requirements
Note: this feature does not work with Pipenv/Poetry, it requires requirements.txt
files for your Python modules.
If you have different python functions, with different sets of requirements, you can avoid
including all the unecessary dependencies of your functions by using the following structure:
├── serverless.yml├── function1│      ├── requirements.txt│      └── index.py└── function2       ├── requirements.txt       └── index.py
With the content of your serverless.yml containing:
package:  individually: truefunctions:  func1:    handler: index.handler    module: function1  func2:    handler: index.handler    module: function2
The result is 2 zip archives, with only the requirements for function1 in the first one, and only
the requirements for function2 in the second one.
Quick notes on the config file:

The module field must be used to tell the plugin where to find the requirements.txt file for
each function.
The handler field must not be prefixed by the folder name (already known through module) as
the root of the zip artifact is already the path to your function.

Customize Python executable
Sometimes your Python executable isn't available on your $PATH as python2.7
or python3.6 (for example, windows or using pyenv).
To support this, this plugin has the following option:
custom:  pythonRequirements:    pythonBin: /opt/python3.6/bin/python
Vendor library directory
For certain libraries, default packaging produces too large an installation,
even when zipping. In those cases it may be necessary to tailor make a version
of the module. In that case you can store them in a directory and use the
vendor option, and the plugin will copy them along with all the other
dependencies to install:
custom:  pythonRequirements:    vendor: ./vendored-librariesfunctions:  hello:    handler: hello.handler    vendor: ./hello-vendor # The option is also available at the function level
Manual invocation
The .requirements and requirements.zip (if using zip support) files are left
behind to speed things up on subsequent deploys. To clean them up, run:
sls requirements clean
You can also create them (and unzip_requirements if
using zip support) manually with:
sls requirements install
The pip download/static cache is outside the serverless folder, and should be manually cleaned when i.e. changing python versions:
sls requirements cleanCache
Invalidate requirements caches on package
If you are using your own Python library, you have to cleanup
.requirements on any update. You can use the following option to cleanup
.requirements everytime you package.
custom:  pythonRequirements:    invalidateCaches: true
:apple::beer::snake: Mac Brew installed Python notes
Brew wilfully breaks the --target option with no seeming intention to fix it
which causes issues since this uses that option. There are a few easy workarounds for this:

Install Python from python.org and specify it with the
pythonBin option.

OR

Create a virtualenv and activate it while using serverless.

OR

Install Docker and use the dockerizePip option.

Also, brew seems to cause issues with pipenv,
so make sure you install pipenv using pip.
:checkered_flag: Windows dockerizePip notes
For usage of dockerizePip on Windows do Step 1 only if running serverless on windows, or do both Step 1 & 2 if running serverless inside WSL.

Enabling shared volume in Windows Docker Taskbar settings
Installing the Docker client on Windows Subsystem for Linux (Ubuntu)

Native Code Dependencies During Build
Some Python packages require extra OS dependencies to build successfully. To deal with this, replace the default image with a Dockerfile like:
FROM public.ecr.aws/sam/build-python3.9# Install your dependenciesRUN yum -y install mysql-devel
Then update your serverless.yml:
custom:  pythonRequirements:    dockerFile: Dockerfile
Native Code Dependencies During Runtime
Some Python packages require extra OS libraries (*.so files) at runtime. You need to manually include these files in the root directory of your Serverless package. The simplest way to do this is to use the dockerExtraFiles option.
For instance, the mysqlclient package requires libmysqlclient.so.1020. If you use the Dockerfile from the previous section, add an item to the dockerExtraFiles option in your serverless.yml:
custom:  pythonRequirements:    dockerExtraFiles:      - /usr/lib64/mysql57/libmysqlclient.so.1020
Then verify the library gets included in your package:
sls packagezipinfo .serverless/xxx.zip
If you can't see the library, you might need to adjust your package include/exclude configuration in serverless.yml.
Optimising packaging time
If you wish to exclude most of the files in your project, and only include the source files of your lambdas and their dependencies you may well use an approach like this:
package:  individually: false  include:    - './src/lambda_one/**'    - './src/lambda_two/**'  exclude:    - '**'
This will be very slow. Serverless adds a default "&ast;&ast;" include. If you are using the cacheLocation parameter to this plugin, this will result in all of the cached files' names being loaded and then subsequently discarded because of the exclude pattern. To avoid this happening you can add a negated include pattern, as is observed in https://github.com/serverless/serverless/pull/5825.
Use this approach instead:
package:  individually: false  include:    - '!./**'    - './src/lambda_one/**'    - './src/lambda_two/**'  exclude:    - '**'
Custom Provider Support
Scaleway
This plugin is compatible with the Scaleway Serverless Framework Plugin to package dependencies for Python functions deployed on Scaleway. To use it, add the following to your serverless.yml:
provider:  name: scaleway  runtime: python311plugins:  - serverless-python-requirements  - serverless-scaleway-functions
To handle native dependencies, it's recommended to use the Docker builder with the image provided by Scaleway:
custom:  pythonRequirements:    # Can use any Python version supported by Scaleway    dockerImage: rg.fr-par.scw.cloud/scwfunctionsruntimes-public/python-dep:3.11
Contributors

@dschep - Original developer
@azurelogic - logging & documentation fixes
@abetomo - style & linting
@angstwad - deploy --function support
@mather - the cache invalidation option
@rmax - the extra pip args option
@bsamuel-ui - Python 3 support, current maintainer
@suxor42 - fixing permission issues with Docker on Linux
@mbeltran213 - fixing docker linux -u option bug
@Tethik - adding usePipenv option
@miketheman - fixing bug with includes when using zip option, update eslint,
@wattdave - fixing bug when using deploymentBucket
@heri16 - fixing Docker support in Windows
@ryansb - package individually support
@cgrimal - Private SSH Repo access in Docker, dockerFile option
to build a custom docker image, real per-function requirements, and the vendor option
@kichik - Imposed windows & noDeploy support,
switched to adding files straight to zip instead of creating symlinks, and
improved pip cache support when using docker.
@dee-me-tree-or-love - the slim package option
@alexjurkiewicz - docs about docker workflows
@andrewfarley - Implemented download caching and static caching
@bweigel - adding the slimPatternsAppendDefaults option & fixing per-function packaging when some functions don't have requirements & Porting tests from bats to js!
Poetry support

@squaresurf
@drice
@ofercaspi
@tpansino


@david-mk-lawrence - added Lambda Layer support
@bryantbriggs - Fixing CI/CD
@jacksgt - Fixing pip issues
@lephuongbg - Fixing single function deployment
@rileypriddle - Introducing schema validation for module property
@martinezpl - Fixing test issues, adding dockerPrivateKey option\n\n\n\nProducts Documentation PricingCompany Toggle themeSearch⌘ KLoginSign UpToggle navigation menu\nProducts Documentation PricingCompany Toggle themeSearch⌘ KLoginSign UpToggle navigation menu\nProducts Documentation PricingCompany Toggle themeSearch⌘ KLoginSign UpToggle navigation menu\nProducts Documentation PricingCompany\nToggle themeSearch⌘ KLoginSign Up\nToggle navigation menu\nMenuToggle navigation menuServerless PluginsAuthorServerless99xAa2kbAbemediaAccentureACloudGuruActivescottAdieuadieuAditmalik-synechronAgutoliAheissenbergerAjmathAlex-murashkinAlex20465Alhazmy13AlikianAliyunAmazon-archivesAmplify-educationAnantabAndrewcuriosoAntonBazhalApancuttAr90nAraboldAregierAwslabsBarstoolSportsBealeartsBespoken-cookbookBirdcatcherBramhovenBrefphpBubblydooButterwireBwinantCapitaloneCaptainsiddCfchouChechuChris-feistCipri-pCivicteamClaygregoryCloudflareCloudSnorkelCoalesceSoftwareCodecentricCodeRecipe-devCommandeerCommercetoolsConcon121CoorpAcademyDanepowellDaniel-cottoneDataDogDavidgfDavidWellsDeep-securityDeliveryheroDheraultDianaIonitaDieProduktMacherDigitalmaasDitttoDoapp-ryanpDomdomeggDong-dohaiDougmoscropDrexlerDroplrDuanefieldsDvlaE-e-eEconomysizegeekEddmannEliasjcjuniorEliuXEmmkongEnigmatic-SmileEnykeevEpsagonEvgenykireevEvolv-aiFdaciukFernando-mcFivepapertigersFloydspaceFormidableLabsFourTheoremFruffinFunctionaloneFunkybobGaaraZhuGertjvrGetliftGFGGfragosoGilmarsquinelatoGmetzkerGo-dimaGoldwasserexchangeGozupHenhalHieuunguyeenHonarpourHorike37HubSpotWebTeamHypoportIcarus-sullivanIlayanambi86IliasbhalImran99InokappaInqnuamIopipeIs2eiIsudzumiJacob-meachamJaredCEJaumardJeremydalyJimdoJitsecurityJlopezJmaleonardJoshuaflanaganJuancarestreJuanjoDiazJubel-hanJweyrichK1LoWKandstenKangcifongKatallaxieKevinrambaudKevinsewellKrysKrukKumologicaHQLeftclickbenLeoPlatformLithinLoanmarketLocalstackLogandkLumigo-ioMaciejtrederMadSkills-ioManelferreiraManoManoTechManwaringMarcy-teruiMartinlindenbergMatt-filionMechanicalRockMedikooMeemawMiguel-a-calles-mbaMikepatrickMikesouzaMikestaubMitipiMj1618Mutual-of-enumclawMvilaNavarasuNeiman-marcusNervous-systemsNeverendingqsNfourNickaNikaeraNlangNordcloudNordstromNya1OnlicarOptimator999Paul-PSDigitalPaulSambolinPianomansamPidz-developmentPiercusPretty-fun-therapyPuresecRafPeRajingtonRawphpRhythminmeRobzskRogerBarretoRogersgtRondineliRrahul963RubentrancosoRurriRyanmurakamiSantiagocardenasSapessiSashkopavlenkoSbstjnSC5ScalewaySddSean9keenanSeek-ossSergioramosServerless-appsyncServerless-heavenServerless-nextjsServerless-operationsSid88inSilvermineSinofsevenSmoketurnerSoftpropsStackStormStarschemaStyleTributeITSuorSvdgraafTalbotpTeddy-gustiauxTemandoTencentyunTgfischerTho-actrecipeThomasmichaelwallaceThoreinsteinThreadheapTradleTrek10incTsibelmanTsubUbaniabalogunUnbillUsefulioUswitchVacasaossVkkis93VortarianWangshaWeixu365WhardierWilliamsandonzYndlingsfarYonomiZaruZephraxServerless Offlineby dheraultEmulate AWS λ and API Gateway locally when developing your Serverle...39.7m5.2kServerless Prune Pluginby claygregoryDeletes old versions of functions from AWS, preserving recent and a...22.3m355Serverless Webpackby serverless-heavenServerless plugin to bundle your lambdas with Webpack19.3m1.7kServerless Domain Managerby amplify-educationServerless plugin for managing custom domains with API Gateways.15.9m936Serverless Esbuildby floydspaceServerless plugin to bundle JavaScript and TypeScript lambdas with ...15.5m445Serverless HTTPby dougmoscropUse your existing middleware framework (e.g. Express, Koa) in AWS L...11.9m1.7kServerless Dotenv Pluginby neverendingqsPreload environment variables from `.env` into serverless.10.1m346Serverless Step Functionsby serverless-operationsAWS Step Functions plugin for Serverless Framework9.5m1.0kServerless Plugin Datadogby DataDogMonitoring, tracing, and real-time metrics for your Lambda functions9.2m94Serverless Plugin Typescriptby serverlessServerless plugin for zero-config Typescript support.9.0m784Serverless IAM Roles Per Functionby functionaloneServerless Plugin for easily defining IAM roles per function via th...8.6m411Serverless Python Requirementsby serverlessServerless plugin to bundle Python packages8.0m1.1kPrevious12345More pages29Next\nMenuToggle navigation menuServerless PluginsAuthorServerless99xAa2kbAbemediaAccentureACloudGuruActivescottAdieuadieuAditmalik-synechronAgutoliAheissenbergerAjmathAlex-murashkinAlex20465Alhazmy13AlikianAliyunAmazon-archivesAmplify-educationAnantabAndrewcuriosoAntonBazhalApancuttAr90nAraboldAregierAwslabsBarstoolSportsBealeartsBespoken-cookbookBirdcatcherBramhovenBrefphpBubblydooButterwireBwinantCapitaloneCaptainsiddCfchouChechuChris-feistCipri-pCivicteamClaygregoryCloudflareCloudSnorkelCoalesceSoftwareCodecentricCodeRecipe-devCommandeerCommercetoolsConcon121CoorpAcademyDanepowellDaniel-cottoneDataDogDavidgfDavidWellsDeep-securityDeliveryheroDheraultDianaIonitaDieProduktMacherDigitalmaasDitttoDoapp-ryanpDomdomeggDong-dohaiDougmoscropDrexlerDroplrDuanefieldsDvlaE-e-eEconomysizegeekEddmannEliasjcjuniorEliuXEmmkongEnigmatic-SmileEnykeevEpsagonEvgenykireevEvolv-aiFdaciukFernando-mcFivepapertigersFloydspaceFormidableLabsFourTheoremFruffinFunctionaloneFunkybobGaaraZhuGertjvrGetliftGFGGfragosoGilmarsquinelatoGmetzkerGo-dimaGoldwasserexchangeGozupHenhalHieuunguyeenHonarpourHorike37HubSpotWebTeamHypoportIcarus-sullivanIlayanambi86IliasbhalImran99InokappaInqnuamIopipeIs2eiIsudzumiJacob-meachamJaredCEJaumardJeremydalyJimdoJitsecurityJlopezJmaleonardJoshuaflanaganJuancarestreJuanjoDiazJubel-hanJweyrichK1LoWKandstenKangcifongKatallaxieKevinrambaudKevinsewellKrysKrukKumologicaHQLeftclickbenLeoPlatformLithinLoanmarketLocalstackLogandkLumigo-ioMaciejtrederMadSkills-ioManelferreiraManoManoTechManwaringMarcy-teruiMartinlindenbergMatt-filionMechanicalRockMedikooMeemawMiguel-a-calles-mbaMikepatrickMikesouzaMikestaubMitipiMj1618Mutual-of-enumclawMvilaNavarasuNeiman-marcusNervous-systemsNeverendingqsNfourNickaNikaeraNlangNordcloudNordstromNya1OnlicarOptimator999Paul-PSDigitalPaulSambolinPianomansamPidz-developmentPiercusPretty-fun-therapyPuresecRafPeRajingtonRawphpRhythminmeRobzskRogerBarretoRogersgtRondineliRrahul963RubentrancosoRurriRyanmurakamiSantiagocardenasSapessiSashkopavlenkoSbstjnSC5ScalewaySddSean9keenanSeek-ossSergioramosServerless-appsyncServerless-heavenServerless-nextjsServerless-operationsSid88inSilvermineSinofsevenSmoketurnerSoftpropsStackStormStarschemaStyleTributeITSuorSvdgraafTalbotpTeddy-gustiauxTemandoTencentyunTgfischerTho-actrecipeThomasmichaelwallaceThoreinsteinThreadheapTradleTrek10incTsibelmanTsubUbaniabalogunUnbillUsefulioUswitchVacasaossVkkis93VortarianWangshaWeixu365WhardierWilliamsandonzYndlingsfarYonomiZaruZephraxServerless Offlineby dheraultEmulate AWS λ and API Gateway locally when developing your Serverle...39.7m5.2kServerless Prune Pluginby claygregoryDeletes old versions of functions from AWS, preserving recent and a...22.3m355Serverless Webpackby serverless-heavenServerless plugin to bundle your lambdas with Webpack19.3m1.7kServerless Domain Managerby amplify-educationServerless plugin for managing custom domains with API Gateways.15.9m936Serverless Esbuildby floydspaceServerless plugin to bundle JavaScript and TypeScript lambdas with ...15.5m445Serverless HTTPby dougmoscropUse your existing middleware framework (e.g. Express, Koa) in AWS L...11.9m1.7kServerless Dotenv Pluginby neverendingqsPreload environment variables from `.env` into serverless.10.1m346Serverless Step Functionsby serverless-operationsAWS Step Functions plugin for Serverless Framework9.5m1.0kServerless Plugin Datadogby DataDogMonitoring, tracing, and real-time metrics for your Lambda functions9.2m94Serverless Plugin Typescriptby serverlessServerless plugin for zero-config Typescript support.9.0m784Serverless IAM Roles Per Functionby functionaloneServerless Plugin for easily defining IAM roles per function via th...8.6m411Serverless Python Requirementsby serverlessServerless plugin to bundle Python packages8.0m1.1kPrevious12345More pages29Next\nMenuToggle navigation menu\nToggle navigation menu\nServerless PluginsAuthorServerless99xAa2kbAbemediaAccentureACloudGuruActivescottAdieuadieuAditmalik-synechronAgutoliAheissenbergerAjmathAlex-murashkinAlex20465Alhazmy13AlikianAliyunAmazon-archivesAmplify-educationAnantabAndrewcuriosoAntonBazhalApancuttAr90nAraboldAregierAwslabsBarstoolSportsBealeartsBespoken-cookbookBirdcatcherBramhovenBrefphpBubblydooButterwireBwinantCapitaloneCaptainsiddCfchouChechuChris-feistCipri-pCivicteamClaygregoryCloudflareCloudSnorkelCoalesceSoftwareCodecentricCodeRecipe-devCommandeerCommercetoolsConcon121CoorpAcademyDanepowellDaniel-cottoneDataDogDavidgfDavidWellsDeep-securityDeliveryheroDheraultDianaIonitaDieProduktMacherDigitalmaasDitttoDoapp-ryanpDomdomeggDong-dohaiDougmoscropDrexlerDroplrDuanefieldsDvlaE-e-eEconomysizegeekEddmannEliasjcjuniorEliuXEmmkongEnigmatic-SmileEnykeevEpsagonEvgenykireevEvolv-aiFdaciukFernando-mcFivepapertigersFloydspaceFormidableLabsFourTheoremFruffinFunctionaloneFunkybobGaaraZhuGertjvrGetliftGFGGfragosoGilmarsquinelatoGmetzkerGo-dimaGoldwasserexchangeGozupHenhalHieuunguyeenHonarpourHorike37HubSpotWebTeamHypoportIcarus-sullivanIlayanambi86IliasbhalImran99InokappaInqnuamIopipeIs2eiIsudzumiJacob-meachamJaredCEJaumardJeremydalyJimdoJitsecurityJlopezJmaleonardJoshuaflanaganJuancarestreJuanjoDiazJubel-hanJweyrichK1LoWKandstenKangcifongKatallaxieKevinrambaudKevinsewellKrysKrukKumologicaHQLeftclickbenLeoPlatformLithinLoanmarketLocalstackLogandkLumigo-ioMaciejtrederMadSkills-ioManelferreiraManoManoTechManwaringMarcy-teruiMartinlindenbergMatt-filionMechanicalRockMedikooMeemawMiguel-a-calles-mbaMikepatrickMikesouzaMikestaubMitipiMj1618Mutual-of-enumclawMvilaNavarasuNeiman-marcusNervous-systemsNeverendingqsNfourNickaNikaeraNlangNordcloudNordstromNya1OnlicarOptimator999Paul-PSDigitalPaulSambolinPianomansamPidz-developmentPiercusPretty-fun-therapyPuresecRafPeRajingtonRawphpRhythminmeRobzskRogerBarretoRogersgtRondineliRrahul963RubentrancosoRurriRyanmurakamiSantiagocardenasSapessiSashkopavlenkoSbstjnSC5ScalewaySddSean9keenanSeek-ossSergioramosServerless-appsyncServerless-heavenServerless-nextjsServerless-operationsSid88inSilvermineSinofsevenSmoketurnerSoftpropsStackStormStarschemaStyleTributeITSuorSvdgraafTalbotpTeddy-gustiauxTemandoTencentyunTgfischerTho-actrecipeThomasmichaelwallaceThoreinsteinThreadheapTradleTrek10incTsibelmanTsubUbaniabalogunUnbillUsefulioUswitchVacasaossVkkis93VortarianWangshaWeixu365WhardierWilliamsandonzYndlingsfarYonomiZaruZephrax\nServerless PluginsAuthorServerless99xAa2kbAbemediaAccentureACloudGuruActivescottAdieuadieuAditmalik-synechronAgutoliAheissenbergerAjmathAlex-murashkinAlex20465Alhazmy13AlikianAliyunAmazon-archivesAmplify-educationAnantabAndrewcuriosoAntonBazhalApancuttAr90nAraboldAregierAwslabsBarstoolSportsBealeartsBespoken-cookbookBirdcatcherBramhovenBrefphpBubblydooButterwireBwinantCapitaloneCaptainsiddCfchouChechuChris-feistCipri-pCivicteamClaygregoryCloudflareCloudSnorkelCoalesceSoftwareCodecentricCodeRecipe-devCommandeerCommercetoolsConcon121CoorpAcademyDanepowellDaniel-cottoneDataDogDavidgfDavidWellsDeep-securityDeliveryheroDheraultDianaIonitaDieProduktMacherDigitalmaasDitttoDoapp-ryanpDomdomeggDong-dohaiDougmoscropDrexlerDroplrDuanefieldsDvlaE-e-eEconomysizegeekEddmannEliasjcjuniorEliuXEmmkongEnigmatic-SmileEnykeevEpsagonEvgenykireevEvolv-aiFdaciukFernando-mcFivepapertigersFloydspaceFormidableLabsFourTheoremFruffinFunctionaloneFunkybobGaaraZhuGertjvrGetliftGFGGfragosoGilmarsquinelatoGmetzkerGo-dimaGoldwasserexchangeGozupHenhalHieuunguyeenHonarpourHorike37HubSpotWebTeamHypoportIcarus-sullivanIlayanambi86IliasbhalImran99InokappaInqnuamIopipeIs2eiIsudzumiJacob-meachamJaredCEJaumardJeremydalyJimdoJitsecurityJlopezJmaleonardJoshuaflanaganJuancarestreJuanjoDiazJubel-hanJweyrichK1LoWKandstenKangcifongKatallaxieKevinrambaudKevinsewellKrysKrukKumologicaHQLeftclickbenLeoPlatformLithinLoanmarketLocalstackLogandkLumigo-ioMaciejtrederMadSkills-ioManelferreiraManoManoTechManwaringMarcy-teruiMartinlindenbergMatt-filionMechanicalRockMedikooMeemawMiguel-a-calles-mbaMikepatrickMikesouzaMikestaubMitipiMj1618Mutual-of-enumclawMvilaNavarasuNeiman-marcusNervous-systemsNeverendingqsNfourNickaNikaeraNlangNordcloudNordstromNya1OnlicarOptimator999Paul-PSDigitalPaulSambolinPianomansamPidz-developmentPiercusPretty-fun-therapyPuresecRafPeRajingtonRawphpRhythminmeRobzskRogerBarretoRogersgtRondineliRrahul963RubentrancosoRurriRyanmurakamiSantiagocardenasSapessiSashkopavlenkoSbstjnSC5ScalewaySddSean9keenanSeek-ossSergioramosServerless-appsyncServerless-heavenServerless-nextjsServerless-operationsSid88inSilvermineSinofsevenSmoketurnerSoftpropsStackStormStarschemaStyleTributeITSuorSvdgraafTalbotpTeddy-gustiauxTemandoTencentyunTgfischerTho-actrecipeThomasmichaelwallaceThoreinsteinThreadheapTradleTrek10incTsibelmanTsubUbaniabalogunUnbillUsefulioUswitchVacasaossVkkis93VortarianWangshaWeixu365WhardierWilliamsandonzYndlingsfarYonomiZaruZephrax\nServerless PluginsAuthorServerless99xAa2kbAbemediaAccentureACloudGuruActivescottAdieuadieuAditmalik-synechronAgutoliAheissenbergerAjmathAlex-murashkinAlex20465Alhazmy13AlikianAliyunAmazon-archivesAmplify-educationAnantabAndrewcuriosoAntonBazhalApancuttAr90nAraboldAregierAwslabsBarstoolSportsBealeartsBespoken-cookbookBirdcatcherBramhovenBrefphpBubblydooButterwireBwinantCapitaloneCaptainsiddCfchouChechuChris-feistCipri-pCivicteamClaygregoryCloudflareCloudSnorkelCoalesceSoftwareCodecentricCodeRecipe-devCommandeerCommercetoolsConcon121CoorpAcademyDanepowellDaniel-cottoneDataDogDavidgfDavidWellsDeep-securityDeliveryheroDheraultDianaIonitaDieProduktMacherDigitalmaasDitttoDoapp-ryanpDomdomeggDong-dohaiDougmoscropDrexlerDroplrDuanefieldsDvlaE-e-eEconomysizegeekEddmannEliasjcjuniorEliuXEmmkongEnigmatic-SmileEnykeevEpsagonEvgenykireevEvolv-aiFdaciukFernando-mcFivepapertigersFloydspaceFormidableLabsFourTheoremFruffinFunctionaloneFunkybobGaaraZhuGertjvrGetliftGFGGfragosoGilmarsquinelatoGmetzkerGo-dimaGoldwasserexchangeGozupHenhalHieuunguyeenHonarpourHorike37HubSpotWebTeamHypoportIcarus-sullivanIlayanambi86IliasbhalImran99InokappaInqnuamIopipeIs2eiIsudzumiJacob-meachamJaredCEJaumardJeremydalyJimdoJitsecurityJlopezJmaleonardJoshuaflanaganJuancarestreJuanjoDiazJubel-hanJweyrichK1LoWKandstenKangcifongKatallaxieKevinrambaudKevinsewellKrysKrukKumologicaHQLeftclickbenLeoPlatformLithinLoanmarketLocalstackLogandkLumigo-ioMaciejtrederMadSkills-ioManelferreiraManoManoTechManwaringMarcy-teruiMartinlindenbergMatt-filionMechanicalRockMedikooMeemawMiguel-a-calles-mbaMikepatrickMikesouzaMikestaubMitipiMj1618Mutual-of-enumclawMvilaNavarasuNeiman-marcusNervous-systemsNeverendingqsNfourNickaNikaeraNlangNordcloudNordstromNya1OnlicarOptimator999Paul-PSDigitalPaulSambolinPianomansamPidz-developmentPiercusPretty-fun-therapyPuresecRafPeRajingtonRawphpRhythminmeRobzskRogerBarretoRogersgtRondineliRrahul963RubentrancosoRurriRyanmurakamiSantiagocardenasSapessiSashkopavlenkoSbstjnSC5ScalewaySddSean9keenanSeek-ossSergioramosServerless-appsyncServerless-heavenServerless-nextjsServerless-operationsSid88inSilvermineSinofsevenSmoketurnerSoftpropsStackStormStarschemaStyleTributeITSuorSvdgraafTalbotpTeddy-gustiauxTemandoTencentyunTgfischerTho-actrecipeThomasmichaelwallaceThoreinsteinThreadheapTradleTrek10incTsibelmanTsubUbaniabalogunUnbillUsefulioUswitchVacasaossVkkis93VortarianWangshaWeixu365WhardierWilliamsandonzYndlingsfarYonomiZaruZephrax\nAuthorServerless99xAa2kbAbemediaAccentureACloudGuruActivescottAdieuadieuAditmalik-synechronAgutoliAheissenbergerAjmathAlex-murashkinAlex20465Alhazmy13AlikianAliyunAmazon-archivesAmplify-educationAnantabAndrewcuriosoAntonBazhalApancuttAr90nAraboldAregierAwslabsBarstoolSportsBealeartsBespoken-cookbookBirdcatcherBramhovenBrefphpBubblydooButterwireBwinantCapitaloneCaptainsiddCfchouChechuChris-feistCipri-pCivicteamClaygregoryCloudflareCloudSnorkelCoalesceSoftwareCodecentricCodeRecipe-devCommandeerCommercetoolsConcon121CoorpAcademyDanepowellDaniel-cottoneDataDogDavidgfDavidWellsDeep-securityDeliveryheroDheraultDianaIonitaDieProduktMacherDigitalmaasDitttoDoapp-ryanpDomdomeggDong-dohaiDougmoscropDrexlerDroplrDuanefieldsDvlaE-e-eEconomysizegeekEddmannEliasjcjuniorEliuXEmmkongEnigmatic-SmileEnykeevEpsagonEvgenykireevEvolv-aiFdaciukFernando-mcFivepapertigersFloydspaceFormidableLabsFourTheoremFruffinFunctionaloneFunkybobGaaraZhuGertjvrGetliftGFGGfragosoGilmarsquinelatoGmetzkerGo-dimaGoldwasserexchangeGozupHenhalHieuunguyeenHonarpourHorike37HubSpotWebTeamHypoportIcarus-sullivanIlayanambi86IliasbhalImran99InokappaInqnuamIopipeIs2eiIsudzumiJacob-meachamJaredCEJaumardJeremydalyJimdoJitsecurityJlopezJmaleonardJoshuaflanaganJuancarestreJuanjoDiazJubel-hanJweyrichK1LoWKandstenKangcifongKatallaxieKevinrambaudKevinsewellKrysKrukKumologicaHQLeftclickbenLeoPlatformLithinLoanmarketLocalstackLogandkLumigo-ioMaciejtrederMadSkills-ioManelferreiraManoManoTechManwaringMarcy-teruiMartinlindenbergMatt-filionMechanicalRockMedikooMeemawMiguel-a-calles-mbaMikepatrickMikesouzaMikestaubMitipiMj1618Mutual-of-enumclawMvilaNavarasuNeiman-marcusNervous-systemsNeverendingqsNfourNickaNikaeraNlangNordcloudNordstromNya1OnlicarOptimator999Paul-PSDigitalPaulSambolinPianomansamPidz-developmentPiercusPretty-fun-therapyPuresecRafPeRajingtonRawphpRhythminmeRobzskRogerBarretoRogersgtRondineliRrahul963RubentrancosoRurriRyanmurakamiSantiagocardenasSapessiSashkopavlenkoSbstjnSC5ScalewaySddSean9keenanSeek-ossSergioramosServerless-appsyncServerless-heavenServerless-nextjsServerless-operationsSid88inSilvermineSinofsevenSmoketurnerSoftpropsStackStormStarschemaStyleTributeITSuorSvdgraafTalbotpTeddy-gustiauxTemandoTencentyunTgfischerTho-actrecipeThomasmichaelwallaceThoreinsteinThreadheapTradleTrek10incTsibelmanTsubUbaniabalogunUnbillUsefulioUswitchVacasaossVkkis93VortarianWangshaWeixu365WhardierWilliamsandonzYndlingsfarYonomiZaruZephrax\nServerless99xAa2kbAbemediaAccentureACloudGuruActivescottAdieuadieuAditmalik-synechronAgutoliAheissenbergerAjmathAlex-murashkinAlex20465Alhazmy13AlikianAliyunAmazon-archivesAmplify-educationAnantabAndrewcuriosoAntonBazhalApancuttAr90nAraboldAregierAwslabsBarstoolSportsBealeartsBespoken-cookbookBirdcatcherBramhovenBrefphpBubblydooButterwireBwinantCapitaloneCaptainsiddCfchouChechuChris-feistCipri-pCivicteamClaygregoryCloudflareCloudSnorkelCoalesceSoftwareCodecentricCodeRecipe-devCommandeerCommercetoolsConcon121CoorpAcademyDanepowellDaniel-cottoneDataDogDavidgfDavidWellsDeep-securityDeliveryheroDheraultDianaIonitaDieProduktMacherDigitalmaasDitttoDoapp-ryanpDomdomeggDong-dohaiDougmoscropDrexlerDroplrDuanefieldsDvlaE-e-eEconomysizegeekEddmannEliasjcjuniorEliuXEmmkongEnigmatic-SmileEnykeevEpsagonEvgenykireevEvolv-aiFdaciukFernando-mcFivepapertigersFloydspaceFormidableLabsFourTheoremFruffinFunctionaloneFunkybobGaaraZhuGertjvrGetliftGFGGfragosoGilmarsquinelatoGmetzkerGo-dimaGoldwasserexchangeGozupHenhalHieuunguyeenHonarpourHorike37HubSpotWebTeamHypoportIcarus-sullivanIlayanambi86IliasbhalImran99InokappaInqnuamIopipeIs2eiIsudzumiJacob-meachamJaredCEJaumardJeremydalyJimdoJitsecurityJlopezJmaleonardJoshuaflanaganJuancarestreJuanjoDiazJubel-hanJweyrichK1LoWKandstenKangcifongKatallaxieKevinrambaudKevinsewellKrysKrukKumologicaHQLeftclickbenLeoPlatformLithinLoanmarketLocalstackLogandkLumigo-ioMaciejtrederMadSkills-ioManelferreiraManoManoTechManwaringMarcy-teruiMartinlindenbergMatt-filionMechanicalRockMedikooMeemawMiguel-a-calles-mbaMikepatrickMikesouzaMikestaubMitipiMj1618Mutual-of-enumclawMvilaNavarasuNeiman-marcusNervous-systemsNeverendingqsNfourNickaNikaeraNlangNordcloudNordstromNya1OnlicarOptimator999Paul-PSDigitalPaulSambolinPianomansamPidz-developmentPiercusPretty-fun-therapyPuresecRafPeRajingtonRawphpRhythminmeRobzskRogerBarretoRogersgtRondineliRrahul963RubentrancosoRurriRyanmurakamiSantiagocardenasSapessiSashkopavlenkoSbstjnSC5ScalewaySddSean9keenanSeek-ossSergioramosServerless-appsyncServerless-heavenServerless-nextjsServerless-operationsSid88inSilvermineSinofsevenSmoketurnerSoftpropsStackStormStarschemaStyleTributeITSuorSvdgraafTalbotpTeddy-gustiauxTemandoTencentyunTgfischerTho-actrecipeThomasmichaelwallaceThoreinsteinThreadheapTradleTrek10incTsibelmanTsubUbaniabalogunUnbillUsefulioUswitchVacasaossVkkis93VortarianWangshaWeixu365WhardierWilliamsandonzYndlingsfarYonomiZaruZephrax\nServerless-operations\nServerless-operations\nServerless Offlineby dheraultEmulate AWS λ and API Gateway locally when developing your Serverle...39.7m5.2kServerless Prune Pluginby claygregoryDeletes old versions of functions from AWS, preserving recent and a...22.3m355Serverless Webpackby serverless-heavenServerless plugin to bundle your lambdas with Webpack19.3m1.7kServerless Domain Managerby amplify-educationServerless plugin for managing custom domains with API Gateways.15.9m936Serverless Esbuildby floydspaceServerless plugin to bundle JavaScript and TypeScript lambdas with ...15.5m445Serverless HTTPby dougmoscropUse your existing middleware framework (e.g. Express, Koa) in AWS L...11.9m1.7kServerless Dotenv Pluginby neverendingqsPreload environment variables from `.env` into serverless.10.1m346Serverless Step Functionsby serverless-operationsAWS Step Functions plugin for Serverless Framework9.5m1.0kServerless Plugin Datadogby DataDogMonitoring, tracing, and real-time metrics for your Lambda functions9.2m94Serverless Plugin Typescriptby serverlessServerless plugin for zero-config Typescript support.9.0m784Serverless IAM Roles Per Functionby functionaloneServerless Plugin for easily defining IAM roles per function via th...8.6m411Serverless Python Requirementsby serverlessServerless plugin to bundle Python packages8.0m1.1kPrevious12345More pages29Next\nServerless Offlineby dheraultEmulate AWS λ and API Gateway locally when developing your Serverle...39.7m5.2kServerless Prune Pluginby claygregoryDeletes old versions of functions from AWS, preserving recent and a...22.3m355Serverless Webpackby serverless-heavenServerless plugin to bundle your lambdas with Webpack19.3m1.7kServerless Domain Managerby amplify-educationServerless plugin for managing custom domains with API Gateways.15.9m936Serverless Esbuildby floydspaceServerless plugin to bundle JavaScript and TypeScript lambdas with ...15.5m445Serverless HTTPby dougmoscropUse your existing middleware framework (e.g. Express, Koa) in AWS L...11.9m1.7kServerless Dotenv Pluginby neverendingqsPreload environment variables from `.env` into serverless.10.1m346Serverless Step Functionsby serverless-operationsAWS Step Functions plugin for Serverless Framework9.5m1.0kServerless Plugin Datadogby DataDogMonitoring, tracing, and real-time metrics for your Lambda functions9.2m94Serverless Plugin Typescriptby serverlessServerless plugin for zero-config Typescript support.9.0m784Serverless IAM Roles Per Functionby functionaloneServerless Plugin for easily defining IAM roles per function via th...8.6m411Serverless Python Requirementsby serverlessServerless plugin to bundle Python packages8.0m1.1k\nServerless Offlineby dheraultEmulate AWS λ and API Gateway locally when developing your Serverle...39.7m5.2k\nServerless Offlineby dherault\nServerless Offlineby dherault\nEmulate AWS λ and API Gateway locally when developing your Serverle...\nServerless Prune Pluginby claygregoryDeletes old versions of functions from AWS, preserving recent and a...22.3m355\nServerless Prune Pluginby claygregory\nServerless Prune Pluginby claygregory\nServerless Prune Plugin\nDeletes old versions of functions from AWS, preserving recent and a...\nServerless Webpackby serverless-heavenServerless plugin to bundle your lambdas with Webpack19.3m1.7k\nServerless Webpackby serverless-heaven\nServerless Webpackby serverless-heaven\nServerless plugin to bundle your lambdas with Webpack\nServerless Domain Managerby amplify-educationServerless plugin for managing custom domains with API Gateways.15.9m936\nServerless Domain Managerby amplify-education\nServerless Domain Managerby amplify-education\nServerless Domain Manager\nServerless plugin for managing custom domains with API Gateways.\nServerless Esbuildby floydspaceServerless plugin to bundle JavaScript and TypeScript lambdas with ...15.5m445\nServerless Esbuildby floydspace\nServerless Esbuildby floydspace\nServerless plugin to bundle JavaScript and TypeScript lambdas with ...\nServerless HTTPby dougmoscropUse your existing middleware framework (e.g. Express, Koa) in AWS L...11.9m1.7k\nServerless HTTPby dougmoscrop\nServerless HTTPby dougmoscrop\nUse your existing middleware framework (e.g. Express, Koa) in AWS L...\nServerless Dotenv Pluginby neverendingqsPreload environment variables from `.env` into serverless.10.1m346\nServerless Dotenv Pluginby neverendingqs\nServerless Dotenv Pluginby neverendingqs\nServerless Dotenv Plugin\nPreload environment variables from `.env` into serverless.\nServerless Step Functionsby serverless-operationsAWS Step Functions plugin for Serverless Framework9.5m1.0k\nServerless Step Functionsby serverless-operations\nServerless Step Functionsby serverless-operations\nServerless Step Functions\nby serverless-operations\nAWS Step Functions plugin for Serverless Framework\nServerless Plugin Datadogby DataDogMonitoring, tracing, and real-time metrics for your Lambda functions9.2m94\nServerless Plugin Datadogby DataDog\nServerless Plugin Datadogby DataDog\nServerless Plugin Datadog\nMonitoring, tracing, and real-time metrics for your Lambda functions\nServerless Plugin Typescriptby serverlessServerless plugin for zero-config Typescript support.9.0m784\nServerless Plugin Typescriptby serverless\nServerless Plugin Typescriptby serverless\nServerless Plugin Typescript\nServerless plugin for zero-config Typescript support.\nServerless IAM Roles Per Functionby functionaloneServerless Plugin for easily defining IAM roles per function via th...8.6m411\nServerless IAM Roles Per Functionby functionalone\nServerless IAM Roles Per Functionby functionalone\nServerless IAM Roles Per Function\nServerless Plugin for easily defining IAM roles per function via th...\nServerless Python Requirementsby serverlessServerless plugin to bundle Python packages8.0m1.1k\nServerless Python Requirementsby serverless\nServerless Python Requirementsby serverless\nServerless Python Requirements\nServerless plugin to bundle Python packages\n© 2025 Serverless, Inc. All rights reserved.Terms of ServicePrivacy Policy\n© 2025 Serverless, Inc. All rights reserved.\nTerms of ServicePrivacy Policy\n\n\n\n\n\n\n\n\nHow to Troubleshoot Serverless API’sGareth McCumskeyJanuary 24, 2020Resolve Serverless Errors the Easy Way- with TagsVerne LindnerNovember 21, 2019Take the legwork out of API Gateway troubleshootingVerne LindnerNovember 20, 2019Managing secrets, API keys and more with ServerlessAlex DeBrieNovember 7, 2017Using AWS CloudTrail to enhance your serverless application securityOry SegalOctober 11, 2018Things to consider before building a serverless data warehouseAshan FernandoAugust 29, 2018The new Serverless Platform Beta: everything teams need to operationalize serverless developmentAusten CollinsJuly 30, 2018Google Cloud Functions goes GA: what it means for ServerlessNick GottliebJuly 25, 2018Unit testing for Node.js Serverless projects with JestEslam HefnawyJuly 17, 2018\n\n\n\n\n\n7 Reasons Why Serverless Encourages Useful Engineering PracticesAnna GellerJune 2, 2022Why Many Engineers Don't Understand ServerlessAnna GellerApril 19, 2022Prototype faster than ever before with Serverless CloudEmrah SamdanFebruary 25, 2022Unleashing the power of serverless for solo developersEmrah SamdanJanuary 25, 2022Webinar October 05, 2021: Enabling Serverless Teams with CEO Austen CollinsAusten CollinsSeptember 28, 2021The true cost of a new employee: compensation calculator for startupsCasey ShultzNovember 14, 2018Keeping the culture in remote cultureThom CroweSeptember 17, 2018The Serveless design ethos: creating brand identity from a green fieldAndre PiresSeptember 3, 2018How to win followers & thought-leader people in 10 weeks Andrea PasswaterAugust 30, 2018\n\n\n\n\n\nJoot & Serverless: Machine Learning for Image Optimization on the Serverless FrameworkRichard GrantMay 4, 2022Serverless: The Ideal Choice For Startups? (CloudForecast Case Study)Francois LagierAugust 7, 2019How BuildCenter and Serverless Guru Streamlined Their Serverless Development CycleNick GottliebJuly 9, 2019AO.com: the path to Serverless FirstNick GottliebApril 24, 2019How Shamrock transacts billions of dollars with Serverless Framework EnterpriseAndrea PasswaterFebruary 26, 2019SQQUID: a 100% serverless startupRon PeledDecember 17, 2018A Serverless Twitter bot helps house Camp Fire victimsEric WyneDecember 5, 2018From chef to Serverless developer in 4 yearsKieran McCarthyJanuary 9, 2018How Droplr Scales to Millions With The Serverless FrameworkAntoni OrfinOctober 26, 2017\n\n\n\n\n\nMay 17th Community Call - Webinar RecapRichard GrantJune 22, 2022Deploying PyTorch Model as a Serverless ServiceAnand MenonMay 19, 2022A Guide to Serverless ArchitectureGareth McCumskeyMay 17, 2022Structuring a Serverless Application & Purple Technology Richard GrantMay 12, 2022Week of Java: Part 5 - Testing Your CodeJuan Sebastián Urrego EscobarMay 13, 2022Week of Java: Part 4 - A Multi-layer Core for Your FunctionJuan Sebastián Urrego EscobarMay 12, 2022Week of Java: Part 3 - Designing and Implementing a Multi-Tier Lambda AppJuan Sebastián Urrego EscobarMay 11, 2022Week of Java: Part 2 - Setting Up Your Local Development EnvironmentJuan Sebastián Urrego EscobarMay 10, 2022Week of Java: Part 1 - Setting Up the ProjectJuan Sebastián Urrego EscobarMay 9, 2022\n\n\n\n\n\nIntroducing the Serverless MCPServerless TeamApril 17, 2025Introducing Serverless Container FrameworkServerless TeamFebruary 4, 2025Introducing The AWS AI StackServerless TeamSeptember 11, 2024Slash AWS Lambda Observability Costs with Serverless Framework’s Axiom IntegrationServerless TeamAugust 26, 2024Serverless Framework Now Supports AWS SAM & CloudformationServerless TeamAugust 26, 2024Serverless Framework V4 Generally AvailableServerless TeamJune 13, 2024Serverless Framework V4: A New ModelServerless TeamOctober 26, 2023Serverless Cloud spins off as AmptAusten CollinsNovember 15, 2022Introducing Serverless Console V2Austen CollinsNovember 10, 2022\n\n\n\n\n\nIntroducing the Serverless MCPServerless TeamApr 17, 2025Introducing Serverless Container FrameworkServerless TeamFeb 4, 2025Introducing The AWS AI StackServerless TeamSep 11, 2024\n\n\n\n\n\nIntroducing the Serverless MCPServerless TeamApr 17, 2025Introducing Serverless Container FrameworkServerless TeamFeb 4, 2025Introducing The AWS AI StackServerless TeamSep 11, 2024\n\n\n\n\n\nIntroducing the Serverless MCPServerless TeamApr 17, 2025Introducing Serverless Container FrameworkServerless TeamFeb 4, 2025Introducing The AWS AI StackServerless TeamSep 11, 2024\n\n\n\n\n\nIntroducing the Serverless MCPServerless TeamApr 17, 2025Introducing Serverless Container FrameworkServerless TeamFeb 4, 2025Introducing The AWS AI StackServerless TeamSep 11, 2024\n\n\n\n\n\nIntroducing the Serverless MCPServerless TeamApr 17, 2025Introducing Serverless Container FrameworkServerless TeamFeb 4, 2025Introducing The AWS AI StackServerless TeamSep 11, 2024\n\n\n\n\n\n\n\n\n\nIntroducing the Serverless MCPServerless TeamApr 17, 2025Introducing Serverless Container FrameworkServerless TeamFeb 4, 2025Introducing The AWS AI StackServerless TeamSep 11, 2024\n\n\n\n\n\nHow to send transactional emails with Sendinblue and Serverless CloudEmrah SamdanJuly 26, 2022May 17th Community Call - Webinar RecapRichard GrantJune 22, 20227 Reasons Why Serverless Encourages Useful Engineering PracticesAnna GellerJune 2, 2022Webinar: Getting Started With Serverless FrameworkRichard GrantMay 25, 2022Deploying PyTorch Model as a Serverless ServiceAnand MenonMay 19, 2022How to Use Upstash with Serverless CloudEslam HefnawyMay 18, 2022A Guide to Serverless ArchitectureGareth McCumskeyMay 17, 2022Week of Java: Part 5 - Testing Your CodeJuan Sebastián Urrego EscobarMay 13, 2022Structuring a Serverless Application & Purple Technology Richard GrantMay 12, 2022\n\n\n\n\n\nIntroducing the Serverless MCPServerless TeamApr 17, 2025Introducing Serverless Container FrameworkServerless TeamFeb 4, 2025Introducing The AWS AI StackServerless TeamSep 11, 2024\n\n\n\n\n\nIntroducing the Serverless MCPServerless TeamApr 17, 2025Introducing Serverless Container FrameworkServerless TeamFeb 4, 2025Introducing The AWS AI StackServerless TeamSep 11, 2024\n\n\n\n\n\nIntroducing the Serverless MCPServerless TeamApr 17, 2025Introducing Serverless Container FrameworkServerless TeamFeb 4, 2025Introducing The AWS AI StackServerless TeamSep 11, 2024\n\n\n\n\n\nIntroducing the Serverless MCPServerless TeamApr 17, 2025Introducing Serverless Container FrameworkServerless TeamFeb 4, 2025Introducing The AWS AI StackServerless TeamSep 11, 2024\n\n\n\n\n\nIntroducing the Serverless MCPServerless TeamApr 17, 2025Introducing Serverless Container FrameworkServerless TeamFeb 4, 2025Introducing The AWS AI StackServerless TeamSep 11, 2024\n\n\n\n\n\nIntroducing the Serverless MCPServerless TeamApr 17, 2025Introducing Serverless Container FrameworkServerless TeamFeb 4, 2025Introducing The AWS AI StackServerless TeamSep 11, 2024\n\n\n\n\n\nIntroducing the Serverless MCPServerless TeamApr 17, 2025Introducing Serverless Container FrameworkServerless TeamFeb 4, 2025Introducing The AWS AI StackServerless TeamSep 11, 2024\n\n\n\n\n\nIntroducing the Serverless MCPServerless TeamApr 17, 2025Introducing Serverless Container FrameworkServerless TeamFeb 4, 2025Introducing The AWS AI StackServerless TeamSep 11, 2024\n\n\n\n\n\nIntroducing the Serverless MCPServerless TeamApr 17, 2025Introducing Serverless Container FrameworkServerless TeamFeb 4, 2025Introducing The AWS AI StackServerless TeamSep 11, 2024\n\n\n\n\n\nIntroducing the Serverless MCPServerless TeamApr 17, 2025Introducing Serverless Container FrameworkServerless TeamFeb 4, 2025Introducing The AWS AI StackServerless TeamSep 11, 2024\n\n\n\n\n\nIntroducing the Serverless MCPServerless TeamApr 17, 2025Introducing Serverless Container FrameworkServerless TeamFeb 4, 2025Introducing The AWS AI StackServerless TeamSep 11, 2024\n\n\n\n\n\nIntroducing the Serverless MCPServerless TeamApr 17, 2025Introducing Serverless Container FrameworkServerless TeamFeb 4, 2025Introducing The AWS AI StackServerless TeamSep 11, 2024\n\n\n\n\n\nIntroducing the Serverless MCPServerless TeamApr 17, 2025Introducing Serverless Container FrameworkServerless TeamFeb 4, 2025Introducing The AWS AI StackServerless TeamSep 11, 2024\n\n\n\n\n\nIntroducing the Serverless MCPServerless TeamApr 17, 2025Introducing Serverless Container FrameworkServerless TeamFeb 4, 2025Introducing The AWS AI StackServerless TeamSep 11, 2024\n\n\n\n\n\nIntroducing the Serverless MCPServerless TeamApr 17, 2025Introducing Serverless Container FrameworkServerless TeamFeb 4, 2025Introducing The AWS AI StackServerless TeamSep 11, 2024\n\n\n\n\n\nIntroducing the Serverless MCPServerless TeamApr 17, 2025Introducing Serverless Container FrameworkServerless TeamFeb 4, 2025Introducing The AWS AI StackServerless TeamSep 11, 2024\n\n\n\n\n\nIntroducing the Serverless MCPServerless TeamApril 17, 2025Introducing Serverless Container FrameworkServerless TeamFebruary 4, 2025Introducing The AWS AI StackServerless TeamSeptember 11, 2024Slash AWS Lambda Observability Costs with Serverless Framework’s Axiom IntegrationServerless TeamAugust 26, 2024Serverless Framework Now Supports AWS SAM & CloudformationServerless TeamAugust 26, 2024Serverless Framework V4 Generally AvailableServerless TeamJune 13, 2024Serverless Framework V4: A New ModelServerless TeamOctober 26, 2023Serverless Cloud spins off as AmptAusten CollinsNovember 15, 2022Introducing Serverless Console V2Austen CollinsNovember 10, 2022\n\n\n\nServerless Framework Node HTTP API on AWS
This template demonstrates how to make a simple HTTP API with Node.js running on AWS Lambda and API Gateway using the Serverless Framework.
This template does not include any kind of persistence (database). For more advanced examples, check out the serverless/examples repository which includes Typescript, Mongo, DynamoDB and other examples.
Usage
Deployment
In order to deploy the example, you need to run the following command:
serverless deploy
After running deploy, you should see output similar to:
Deploying "serverless-http-api" to stage "dev" (us-east-1)✔ Service deployed to stack serverless-http-api-dev (91s)endpoint: GET - https://xxxxxxxxxx.execute-api.us-east-1.amazonaws.com/functions:  hello: serverless-http-api-dev-hello (1.6 kB)
Note: In current form, after deployment, your API is public and can be invoked by anyone. For production deployments, you might want to configure an authorizer. For details on how to do that, refer to HTTP API (API Gateway V2) event docs.
Invocation
After successful deployment, you can call the created application via HTTP:
curl https://xxxxxxx.execute-api.us-east-1.amazonaws.com/
Which should result in response similar to:
{ "message": "Go Serverless v4! Your function executed successfully!" }
Local development
The easiest way to develop and test your function is to use the dev command:
serverless dev
This will start a local emulator of AWS Lambda and tunnel your requests to and from AWS Lambda, allowing you to interact with your function as if it were running in the cloud.
Now you can invoke the function as before, but this time the function will be executed locally. Now you can develop your function locally, invoke it, and see the results immediately without having to re-deploy.
When you are done developing, don't forget to run serverless deploy to deploy the function to the cloud.\n\nExamplesAWS Simple HTTP Endpoint example in NodeJSServerless Framework Node HTTP API on AWS
This template demonstrates how to make a simple HTTP API with Node.js running on AWS Lambda and API Gateway using the Serverless Framework.
This template does not include any kind of persistence (database). For more advanced examples, check out the serverless/examples repository which includes Typescript, Mongo, DynamoDB and other examples.
Usage
Deployment
In order to deploy the example, you need to run the following command:
serverless deploy
After running deploy, you should see output similar to:
Deploying "serverless-http-api" to stage "dev" (us-east-1)✔ Service deployed to stack serverless-http-api-dev (91s)endpoint: GET - https://xxxxxxxxxx.execute-api.us-east-1.amazonaws.com/functions:  hello: serverless-http-api-dev-hello (1.6 kB)
Note: In current form, after deployment, your API is public and can be invoked by anyone. For production deployments, you might want to configure an authorizer. For details on how to do that, refer to HTTP API (API Gateway V2) event docs.
Invocation
After successful deployment, you can call the created application via HTTP:
curl https://xxxxxxx.execute-api.us-east-1.amazonaws.com/
Which should result in response similar to:
{ "message": "Go Serverless v4! Your function executed successfully!" }
Local development
The easiest way to develop and test your function is to use the dev command:
serverless dev
This will start a local emulator of AWS Lambda and tunnel your requests to and from AWS Lambda, allowing you to interact with your function as if it were running in the cloud.
Now you can invoke the function as before, but this time the function will be executed locally. Now you can develop your function locally, invoke it, and see the results immediately without having to re-deploy.
When you are done developing, don't forget to run serverless deploy to deploy the function to the cloud.\n\n\n\nServerless Framework Node Express API on AWS
This template demonstrates how to develop and deploy a simple Node Express API service running on AWS Lambda using the Serverless Framework.
This template configures a single function, api, which is responsible for handling all incoming requests using the httpApi event. To learn more about httpApi event configuration options, please refer to httpApi event docs. As the event is configured in a way to accept all incoming requests, the Express.js framework is responsible for routing and handling requests internally. This implementation uses the serverless-http package to transform the incoming event request payloads to payloads compatible with Express.js. To learn more about serverless-http, please refer to the serverless-http README.
Usage
Deployment
Install dependencies with:
npm install
and then deploy with:
serverless deploy
After running deploy, you should see output similar to:
Deploying "aws-node-express-api" to stage "dev" (us-east-1)✔ Service deployed to stack aws-node-express-api-dev (96s)endpoint: ANY - https://xxxxxxxxxx.execute-api.us-east-1.amazonaws.comfunctions:  api: aws-node-express-api-dev-api (2.3 kB)
Note: In current form, after deployment, your API is public and can be invoked by anyone. For production deployments, you might want to configure an authorizer. For details on how to do that, refer to httpApi event docs.
Invocation
After successful deployment, you can call the created application via HTTP:
curl https://xxxxxxx.execute-api.us-east-1.amazonaws.com/
Which should result in the following response:
{ "message": "Hello from root!" }
Local development
The easiest way to develop and test your function is to use the dev command:
serverless dev
This will start a local emulator of AWS Lambda and tunnel your requests to and from AWS Lambda, allowing you to interact with your function as if it were running in the cloud.
Now you can invoke the function as before, but this time the function will be executed locally. Now you can develop your function locally, invoke it, and see the results immediately without having to re-deploy.
When you are done developing, don't forget to run serverless deploy to deploy the function to the cloud.\n\nExamplesNode Express API on AWSServerless Framework Node Express API on AWS
This template demonstrates how to develop and deploy a simple Node Express API service running on AWS Lambda using the Serverless Framework.
This template configures a single function, api, which is responsible for handling all incoming requests using the httpApi event. To learn more about httpApi event configuration options, please refer to httpApi event docs. As the event is configured in a way to accept all incoming requests, the Express.js framework is responsible for routing and handling requests internally. This implementation uses the serverless-http package to transform the incoming event request payloads to payloads compatible with Express.js. To learn more about serverless-http, please refer to the serverless-http README.
Usage
Deployment
Install dependencies with:
npm install
and then deploy with:
serverless deploy
After running deploy, you should see output similar to:
Deploying "aws-node-express-api" to stage "dev" (us-east-1)✔ Service deployed to stack aws-node-express-api-dev (96s)endpoint: ANY - https://xxxxxxxxxx.execute-api.us-east-1.amazonaws.comfunctions:  api: aws-node-express-api-dev-api (2.3 kB)
Note: In current form, after deployment, your API is public and can be invoked by anyone. For production deployments, you might want to configure an authorizer. For details on how to do that, refer to httpApi event docs.
Invocation
After successful deployment, you can call the created application via HTTP:
curl https://xxxxxxx.execute-api.us-east-1.amazonaws.com/
Which should result in the following response:
{ "message": "Hello from root!" }
Local development
The easiest way to develop and test your function is to use the dev command:
serverless dev
This will start a local emulator of AWS Lambda and tunnel your requests to and from AWS Lambda, allowing you to interact with your function as if it were running in the cloud.
Now you can invoke the function as before, but this time the function will be executed locally. Now you can develop your function locally, invoke it, and see the results immediately without having to re-deploy.
When you are done developing, don't forget to run serverless deploy to deploy the function to the cloud.\n\n\n\nServerless Framework Node Express API on AWS
This template demonstrates how to develop and deploy a simple Node Express API service, backed by DynamoDB table, running on AWS Lambda using the Serverless Framework.
This template configures a single function, api, which is responsible for handling all incoming requests using the httpApi event. To learn more about httpApi event configuration options, please refer to httpApi event docs. As the event is configured in a way to accept all incoming requests, the Express.js framework is responsible for routing and handling requests internally. This implementation uses the serverless-http package to transform the incoming event request payloads to payloads compatible with Express.js. To learn more about serverless-http, please refer to the serverless-http README.
Additionally, it also handles provisioning of a DynamoDB database that is used for storing data about users. The Express.js application exposes two endpoints, POST /users and GET /user/:userId, which create and retrieve a user record.
Usage
Deployment
Install dependencies with:
npm install
and then deploy with:
serverless deploy
After running deploy, you should see output similar to:
Deploying "aws-node-express-dynamodb-api" to stage "dev" (us-east-1)✔ Service deployed to stack aws-node-express-dynamodb-api-dev (109s)endpoint: ANY - https://xxxxxxxxxx.execute-api.us-east-1.amazonaws.comfunctions:  api: aws-node-express-dynamodb-api-dev-api (3.8 MB)
Note: In current form, after deployment, your API is public and can be invoked by anyone. For production deployments, you might want to configure an authorizer. For details on how to do that, refer to httpApi event docs. Additionally, in current configuration, the DynamoDB table will be removed when running serverless remove. To retain the DynamoDB table even after removal of the stack, add DeletionPolicy: Retain to its resource definition.
Invocation
After successful deployment, you can create a new user by calling the corresponding endpoint:
curl --request POST 'https://xxxxxx.execute-api.us-east-1.amazonaws.com/users' --header 'Content-Type: application/json' --data-raw '{"name": "John", "userId": "someUserId"}'
Which should result in the following response:
{ "userId": "someUserId", "name": "John" }
You can later retrieve the user by userId by calling the following endpoint:
curl https://xxxxxxx.execute-api.us-east-1.amazonaws.com/users/someUserId
Which should result in the following response:
{ "userId": "someUserId", "name": "John" }
Local development
The easiest way to develop and test your function is to use the dev command:
serverless dev
This will start a local emulator of AWS Lambda and tunnel your requests to and from AWS Lambda, allowing you to interact with your function as if it were running in the cloud.
Now you can invoke the function as before, but this time the function will be executed locally. Now you can develop your function locally, invoke it, and see the results immediately without having to re-deploy.
When you are done developing, don't forget to run serverless deploy to deploy the function to the cloud.\n\nExamplesNode Express API service backed by DynamoDB on AWSServerless Framework Node Express API on AWS
This template demonstrates how to develop and deploy a simple Node Express API service, backed by DynamoDB table, running on AWS Lambda using the Serverless Framework.
This template configures a single function, api, which is responsible for handling all incoming requests using the httpApi event. To learn more about httpApi event configuration options, please refer to httpApi event docs. As the event is configured in a way to accept all incoming requests, the Express.js framework is responsible for routing and handling requests internally. This implementation uses the serverless-http package to transform the incoming event request payloads to payloads compatible with Express.js. To learn more about serverless-http, please refer to the serverless-http README.
Additionally, it also handles provisioning of a DynamoDB database that is used for storing data about users. The Express.js application exposes two endpoints, POST /users and GET /user/:userId, which create and retrieve a user record.
Usage
Deployment
Install dependencies with:
npm install
and then deploy with:
serverless deploy
After running deploy, you should see output similar to:
Deploying "aws-node-express-dynamodb-api" to stage "dev" (us-east-1)✔ Service deployed to stack aws-node-express-dynamodb-api-dev (109s)endpoint: ANY - https://xxxxxxxxxx.execute-api.us-east-1.amazonaws.comfunctions:  api: aws-node-express-dynamodb-api-dev-api (3.8 MB)
Note: In current form, after deployment, your API is public and can be invoked by anyone. For production deployments, you might want to configure an authorizer. For details on how to do that, refer to httpApi event docs. Additionally, in current configuration, the DynamoDB table will be removed when running serverless remove. To retain the DynamoDB table even after removal of the stack, add DeletionPolicy: Retain to its resource definition.
Invocation
After successful deployment, you can create a new user by calling the corresponding endpoint:
curl --request POST 'https://xxxxxx.execute-api.us-east-1.amazonaws.com/users' --header 'Content-Type: application/json' --data-raw '{"name": "John", "userId": "someUserId"}'
Which should result in the following response:
{ "userId": "someUserId", "name": "John" }
You can later retrieve the user by userId by calling the following endpoint:
curl https://xxxxxxx.execute-api.us-east-1.amazonaws.com/users/someUserId
Which should result in the following response:
{ "userId": "someUserId", "name": "John" }
Local development
The easiest way to develop and test your function is to use the dev command:
serverless dev
This will start a local emulator of AWS Lambda and tunnel your requests to and from AWS Lambda, allowing you to interact with your function as if it were running in the cloud.
Now you can invoke the function as before, but this time the function will be executed locally. Now you can develop your function locally, invoke it, and see the results immediately without having to re-deploy.
When you are done developing, don't forget to run serverless deploy to deploy the function to the cloud.\n\n\n\nServerless Framework Node Scheduled Cron on AWS
This template demonstrates how to develop and deploy a simple cron-like service running on AWS Lambda using the Serverless Framework.
This examples defines a single function, rateHandler which is triggered by an event of schedule type at a rate of 1 per minute. For detailed information about schedule event, please refer to corresponding section of Serverless docs.
Usage
Deployment
In order to deploy the example, you need to run the following command:
serverless deploy
After running deploy, you should see output similar to:
Deploying "aws-node-scheduled-cron" to stage "dev" (us-east-1)✔ Service deployed to stack aws-node-scheduled-cron-dev (151s)functions:  rateHandler: aws-node-scheduled-cron-dev-rateHandler (2.3 kB)
There is no additional step required. Your defined schedules becomes active right away after deployment.
Local development
The easiest way to develop and test your function is to use the dev command:
serverless dev
This will start a local emulator of AWS Lambda and tunnel your requests to and from AWS Lambda, allowing you to interact with your function as if it were running in the cloud.
Now you can invoke the function as before, but this time the function will be executed locally. Now you can develop your function locally, invoke it, and see the results immediately without having to re-deploy.
When you are done developing, don't forget to run serverless deploy to deploy the function to the cloud.\n\nExamplesAWS Node Scheduled Cron example in NodeJSServerless Framework Node Scheduled Cron on AWS
This template demonstrates how to develop and deploy a simple cron-like service running on AWS Lambda using the Serverless Framework.
This examples defines a single function, rateHandler which is triggered by an event of schedule type at a rate of 1 per minute. For detailed information about schedule event, please refer to corresponding section of Serverless docs.
Usage
Deployment
In order to deploy the example, you need to run the following command:
serverless deploy
After running deploy, you should see output similar to:
Deploying "aws-node-scheduled-cron" to stage "dev" (us-east-1)✔ Service deployed to stack aws-node-scheduled-cron-dev (151s)functions:  rateHandler: aws-node-scheduled-cron-dev-rateHandler (2.3 kB)
There is no additional step required. Your defined schedules becomes active right away after deployment.
Local development
The easiest way to develop and test your function is to use the dev command:
serverless dev
This will start a local emulator of AWS Lambda and tunnel your requests to and from AWS Lambda, allowing you to interact with your function as if it were running in the cloud.
Now you can invoke the function as before, but this time the function will be executed locally. Now you can develop your function locally, invoke it, and see the results immediately without having to re-deploy.
When you are done developing, don't forget to run serverless deploy to deploy the function to the cloud.\n\n\n\nServerless Framework AWS NodeJS Example
This template demonstrates how to deploy a simple NodeJS function running on AWS Lambda using the Serverless Framework. The deployed function does not include any event definitions or any kind of persistence (database). For more advanced configurations check out the examples repo which include use cases like API endpoints, workers triggered by SQS, persistence with DynamoDB, and scheduled tasks. For details about configuration of specific events, please refer to our documentation.
Usage
Deployment
In order to deploy the example, you need to run the following command:
serverless deploy
After running deploy, you should see output similar to:
Deploying "aws-node" to stage "dev" (us-east-1)✔ Service deployed to stack aws-node-dev (90s)functions:  hello: aws-node-dev-hello (1.5 kB)
Invocation
After successful deployment, you can invoke the deployed function by using the following command:
serverless invoke --function hello
Which should result in response similar to the following:
{  "statusCode": 200,  "body": "{\"message\":\"Go Serverless v4.0! Your function executed successfully!\"}"}
Local development
The easiest way to develop and test your function is to use the Serverless Framework's dev command:
serverless dev
This will start a local emulator of AWS Lambda and tunnel your requests to and from AWS Lambda, allowing you to interact with your function as if it were running in the cloud.
Now you can invoke the function as before, but this time the function will be executed locally. Now you can develop your function locally, invoke it, and see the results immediately without having to re-deploy.
When you are done developing, don't forget to run serverless deploy to deploy the function to the cloud.\n\nExamplesAWS NodeJS ExampleServerless Framework AWS NodeJS Example
This template demonstrates how to deploy a simple NodeJS function running on AWS Lambda using the Serverless Framework. The deployed function does not include any event definitions or any kind of persistence (database). For more advanced configurations check out the examples repo which include use cases like API endpoints, workers triggered by SQS, persistence with DynamoDB, and scheduled tasks. For details about configuration of specific events, please refer to our documentation.
Usage
Deployment
In order to deploy the example, you need to run the following command:
serverless deploy
After running deploy, you should see output similar to:
Deploying "aws-node" to stage "dev" (us-east-1)✔ Service deployed to stack aws-node-dev (90s)functions:  hello: aws-node-dev-hello (1.5 kB)
Invocation
After successful deployment, you can invoke the deployed function by using the following command:
serverless invoke --function hello
Which should result in response similar to the following:
{  "statusCode": 200,  "body": "{\"message\":\"Go Serverless v4.0! Your function executed successfully!\"}"}
Local development
The easiest way to develop and test your function is to use the Serverless Framework's dev command:
serverless dev
This will start a local emulator of AWS Lambda and tunnel your requests to and from AWS Lambda, allowing you to interact with your function as if it were running in the cloud.
Now you can invoke the function as before, but this time the function will be executed locally. Now you can develop your function locally, invoke it, and see the results immediately without having to re-deploy.
When you are done developing, don't forget to run serverless deploy to deploy the function to the cloud.\n\n\n\nServerless Framework Python HTTP API on AWS
This template demonstrates how to make a simple HTTP API with Python running on AWS Lambda and API Gateway using the Serverless Framework.
This template does not include any kind of persistence (database). For more advanced examples, check out the serverless/examples repository which includes DynamoDB, Mongo, Fauna and other examples.
Usage
Deployment
serverless deploy
After deploying, you should see output similar to:
Deploying "aws-python-http-api" to stage "dev" (us-east-1)✔ Service deployed to stack aws-python-http-api-dev (85s)endpoint: GET - https://6ewcye3q4d.execute-api.us-east-1.amazonaws.com/functions:  hello: aws-python-http-api-dev-hello (2.3 kB)
Note: In current form, after deployment, your API is public and can be invoked by anyone. For production deployments, you might want to configure an authorizer. For details on how to do that, refer to http event docs.
Invocation
After successful deployment, you can call the created application via HTTP:
curl https://xxxxxxx.execute-api.us-east-1.amazonaws.com/
Which should result in response similar to the following (removed input content for brevity):
{  "message": "Go Serverless v4.0! Your function executed successfully!"}
Local development
You can invoke your function locally by using the following command:
serverless invoke local --function hello
Which should result in response similar to the following:
{  "statusCode": 200,  "body": "{\n  \"message\": \"Go Serverless v4.0! Your function executed successfully!\"}"}
Alternatively, it is also possible to emulate API Gateway and Lambda locally by using serverless-offline plugin. In order to do that, execute the following command:
serverless plugin install -n serverless-offline
It will add the serverless-offline plugin to devDependencies in package.json file as well as will add it to plugins in serverless.yml.
After installation, you can start local emulation with:
serverless offline
To learn more about the capabilities of serverless-offline, please refer to its GitHub repository.
Bundling dependencies
In case you would like to include 3rd party dependencies, you will need to use a plugin called serverless-python-requirements. You can set it up by running the following command:
serverless plugin install -n serverless-python-requirements
Running the above will automatically add serverless-python-requirements to plugins section in your serverless.yml file and add it as a devDependency to package.json file. The package.json file will be automatically created if it doesn't exist beforehand. Now you will be able to add your dependencies to requirements.txt file (Pipfile and pyproject.toml is also supported but requires additional configuration) and they will be automatically injected to Lambda package during build process. For more details about the plugin's configuration, please refer to official documentation.\n\nExamplesAWS Simple HTTP Endpoint example in PythonServerless Framework Python HTTP API on AWS
This template demonstrates how to make a simple HTTP API with Python running on AWS Lambda and API Gateway using the Serverless Framework.
This template does not include any kind of persistence (database). For more advanced examples, check out the serverless/examples repository which includes DynamoDB, Mongo, Fauna and other examples.
Usage
Deployment
serverless deploy
After deploying, you should see output similar to:
Deploying "aws-python-http-api" to stage "dev" (us-east-1)✔ Service deployed to stack aws-python-http-api-dev (85s)endpoint: GET - https://6ewcye3q4d.execute-api.us-east-1.amazonaws.com/functions:  hello: aws-python-http-api-dev-hello (2.3 kB)
Note: In current form, after deployment, your API is public and can be invoked by anyone. For production deployments, you might want to configure an authorizer. For details on how to do that, refer to http event docs.
Invocation
After successful deployment, you can call the created application via HTTP:
curl https://xxxxxxx.execute-api.us-east-1.amazonaws.com/
Which should result in response similar to the following (removed input content for brevity):
{  "message": "Go Serverless v4.0! Your function executed successfully!"}
Local development
You can invoke your function locally by using the following command:
serverless invoke local --function hello
Which should result in response similar to the following:
{  "statusCode": 200,  "body": "{\n  \"message\": \"Go Serverless v4.0! Your function executed successfully!\"}"}
Alternatively, it is also possible to emulate API Gateway and Lambda locally by using serverless-offline plugin. In order to do that, execute the following command:
serverless plugin install -n serverless-offline
It will add the serverless-offline plugin to devDependencies in package.json file as well as will add it to plugins in serverless.yml.
After installation, you can start local emulation with:
serverless offline
To learn more about the capabilities of serverless-offline, please refer to its GitHub repository.
Bundling dependencies
In case you would like to include 3rd party dependencies, you will need to use a plugin called serverless-python-requirements. You can set it up by running the following command:
serverless plugin install -n serverless-python-requirements
Running the above will automatically add serverless-python-requirements to plugins section in your serverless.yml file and add it as a devDependency to package.json file. The package.json file will be automatically created if it doesn't exist beforehand. Now you will be able to add your dependencies to requirements.txt file (Pipfile and pyproject.toml is also supported but requires additional configuration) and they will be automatically injected to Lambda package during build process. For more details about the plugin's configuration, please refer to official documentation.\n\n\n\nServerless Framework Python Flask API on AWS
This template demonstrates how to develop and deploy a simple Python Flask API service running on AWS Lambda using the Serverless Framework.
This template configures a single function, api, which is responsible for handling all incoming requests thanks to configured http events. To learn more about http event configuration options, please refer to http event docs. As the events are configured in a way to accept all incoming requests, Flask framework is responsible for routing and handling requests internall y. The implementation takes advantage of serverless-wsgi, which allows you to wrap WSGI applications such as Flask apps. To learn more about serverless-wsgi, please refer to corresponding GitHub repository. Additionally, the template relies on serverless-python-requirements plugin for packaging dependencies from requirements.txt file. For more details about serverless-python-requirements configuration, please refer to corresponding GitHub repository.
Usage
Deployment
This example is made to work with the Serverless Framework dashboard, which includes advanced features such as CI/CD, monitoring, metrics, etc.
In order to deploy with dashboard, you need to first login with:
serverless login
install dependencies with:
npm install
and
pip install -r requirements.txt
and then perform deployment with:
serverless deploy
After running deploy, you should see output similar to:
Deploying "aws-python-flask-api" to stage "dev" (us-east-1)Using Python specified in "runtime": python3.12Packaging Python WSGI handler...✔ Service deployed to stack aws-python-flask-api-dev (104s)endpoints:  ANY - https://xxxxxxxxxe.execute-api.us-east-1.amazonaws.com/dev/  ANY - https://xxxxxxxxxx.execute-api.us-east-1.amazonaws.com/dev/{proxy+}functions:  api: aws-python-flask-api-dev-api (41 MB)
Note: In current form, after deployment, your API is public and can be invoked by anyone. For production deployments, you might want to configure an authorizer. For details on how to do that, refer to http event docs.
Invocation
After successful deployment, you can call the created application via HTTP:
curl https://xxxxxxx.execute-api.us-east-1.amazonaws.com/dev/
Which should result in the following response:
{ "message": "Hello from root!" }
Calling the /hello path with:
curl https://xxxxxxx.execute-api.us-east-1.amazonaws.com/dev/hello
Should result in the following response:
{ "message": "Hello from path!" }
Local development
Thanks to capabilities of serverless-wsgi, it is also possible to run your application locally, however, in order to do that, you will need to first install werkzeug dependency, as well as all other dependencies listed in requirements.txt. It is recommended to use a dedicated virtual environment for that purpose. You can install all needed dependencies with the following commands:
pip install werkzeugpip install -r requirements.txt
At this point, you can run your application locally with the following command:
serverless wsgi serve
For additional local development capabilities of serverless-wsgi plugin, please refer to corresponding GitHub repository.\n\nExamplesPython Flask API on AWSServerless Framework Python Flask API on AWS
This template demonstrates how to develop and deploy a simple Python Flask API service running on AWS Lambda using the Serverless Framework.
This template configures a single function, api, which is responsible for handling all incoming requests thanks to configured http events. To learn more about http event configuration options, please refer to http event docs. As the events are configured in a way to accept all incoming requests, Flask framework is responsible for routing and handling requests internall y. The implementation takes advantage of serverless-wsgi, which allows you to wrap WSGI applications such as Flask apps. To learn more about serverless-wsgi, please refer to corresponding GitHub repository. Additionally, the template relies on serverless-python-requirements plugin for packaging dependencies from requirements.txt file. For more details about serverless-python-requirements configuration, please refer to corresponding GitHub repository.
Usage
Deployment
This example is made to work with the Serverless Framework dashboard, which includes advanced features such as CI/CD, monitoring, metrics, etc.
In order to deploy with dashboard, you need to first login with:
serverless login
install dependencies with:
npm install
and
pip install -r requirements.txt
and then perform deployment with:
serverless deploy
After running deploy, you should see output similar to:
Deploying "aws-python-flask-api" to stage "dev" (us-east-1)Using Python specified in "runtime": python3.12Packaging Python WSGI handler...✔ Service deployed to stack aws-python-flask-api-dev (104s)endpoints:  ANY - https://xxxxxxxxxe.execute-api.us-east-1.amazonaws.com/dev/  ANY - https://xxxxxxxxxx.execute-api.us-east-1.amazonaws.com/dev/{proxy+}functions:  api: aws-python-flask-api-dev-api (41 MB)
Note: In current form, after deployment, your API is public and can be invoked by anyone. For production deployments, you might want to configure an authorizer. For details on how to do that, refer to http event docs.
Invocation
After successful deployment, you can call the created application via HTTP:
curl https://xxxxxxx.execute-api.us-east-1.amazonaws.com/dev/
Which should result in the following response:
{ "message": "Hello from root!" }
Calling the /hello path with:
curl https://xxxxxxx.execute-api.us-east-1.amazonaws.com/dev/hello
Should result in the following response:
{ "message": "Hello from path!" }
Local development
Thanks to capabilities of serverless-wsgi, it is also possible to run your application locally, however, in order to do that, you will need to first install werkzeug dependency, as well as all other dependencies listed in requirements.txt. It is recommended to use a dedicated virtual environment for that purpose. You can install all needed dependencies with the following commands:
pip install werkzeugpip install -r requirements.txt
At this point, you can run your application locally with the following command:
serverless wsgi serve
For additional local development capabilities of serverless-wsgi plugin, please refer to corresponding GitHub repository.\n\n\n\nServerless Framework Python Flask API service backed by DynamoDB on AWS
This template demonstrates how to develop and deploy a simple Python Flask API service, backed by DynamoDB, running on AWS Lambda using the Serverless Framework.
This template configures a single function, api, which is responsible for handling all incoming requests thanks to configured http events. To learn more about http event configuration options, please refer to http event docs. As the events are configured in a way to accept all incoming requests, Flask framework is responsible for routing and handling requests internally. The implementation takes advantage of serverless-wsgi, which allows you to wrap WSGI applications such as Flask apps. To learn more about serverless-wsgi, please refer to corresponding GitHub repository. The template also relies on serverless-python-requirements plugin for packaging dependencies from requirements.txt file. For more details about serverless-python-requirements configuration, please refer to corresponding GitHub repository.
Additionally, the template also handles provisioning of a DynamoDB database that is used for storing data about users. The Flask application exposes two endpoints, POST /users and GET /user/{userId}, which allow to create and retrieve users.
Usage
Prerequisites
In order to package your dependencies locally with serverless-python-requirements, you need to have Python3.8 installed locally. You can create and activate a dedicated virtual environment with the following command:
python3.8 -m venv ./venvsource ./venv/bin/activate
Alternatively, you can also use dockerizePip configuration from serverless-python-requirements. For details on that, please refer to corresponding GitHub repository.
Deployment
install dependencies with:
npm install
and then perform deployment with:
serverless deploy
After running deploy, you should see output similar to:
Deploying "aws-python-flask-dynamodb-api" to stage "dev" (us-east-1)Using Python specified in "runtime": python3.12Packaging Python WSGI handler...✔ Service deployed to stack aws-python-flask-dynamodb-api-dev (123s)endpoints:  ANY - https://xxxxxxxxxx.execute-api.us-east-1.amazonaws.com/dev/  ANY - https://xxxxxxxxxx.execute-api.us-east-1.amazonaws.com/dev/{proxy+}functions:  api: aws-python-flask-dynamodb-api-dev-api (41 MB)
Note: In current form, after deployment, your API is public and can be invoked by anyone. For production deployments, you might want to configure an authorizer. For details on how to do that, refer to http event docs.
Invocation
After successful deployment, you can create a new user by calling the corresponding endpoint:
curl --request POST 'https://xxxxxx.execute-api.us-east-1.amazonaws.com/dev/users' --header 'Content-Type: application/json' --data-raw '{"name": "John", "userId": "someUserId"}'
Which should result in the following response:
{ "userId": "someUserId", "name": "John" }
You can later retrieve the user by userId by calling the following endpoint:
curl https://xxxxxxx.execute-api.us-east-1.amazonaws.com/dev/users/someUserId
Which should result in the following response:
{ "userId": "someUserId", "name": "John" }
Local development
Thanks to capabilities of serverless-wsgi, it is also possible to run your application locally, however, in order to do that, you will need to first install werkzeug, boto3 dependencies, as well as all other dependencies listed in requirements.txt. It is recommended to use a dedicated virtual environment for that purpose. You can install all needed dependencies with the following commands:
pip install werkzeug boto3pip install -r requirements.txt
Additionally, you will need to emulate DynamoDB locally, which can be done by using serverless-dynamodb-local plugin. In order to do that, execute the following commands:
serverless plugin install -n serverless-dynamodb-localserverless dynamodb install
It will add the plugin to devDependencies in package.json file as well as to plugins section in serverless.yml. Additionally, it will also install DynamoDB locally.
You should also add the following config to custom section in serverless.yml:
custom:  (...)  dynamodb:    start:      migrate: true    stages:      - dev
Additionally, we need to reconfigure DynamoDB Client to connect to our local instance of DynamoDB. We can take advantage of IS_OFFLINE environment variable set by serverless-wsgi plugin and replace:
dynamodb_client = boto3.client('dynamodb')
with
dynamodb_client = boto3.client('dynamodb')if os.environ.get('IS_OFFLINE'):    dynamodb_client = boto3.client('dynamodb', region_name='localhost', endpoint_url='http://localhost:8000')
Now you can start DynamoDB local with the following command:
serverless dynamodb start
At this point, you can run your application locally with the following command:
serverless wsgi serve
For additional local development capabilities of serverless-wsgi and serverless-dynamodb-local plugins, please refer to corresponding GitHub repositories:

https://github.com/logandk/serverless-wsgi
https://github.com/99x/serverless-dynamodb-local\n\nExamplesPython Flask API backed by DynamoDB on AWSServerless Framework Python Flask API service backed by DynamoDB on AWS
This template demonstrates how to develop and deploy a simple Python Flask API service, backed by DynamoDB, running on AWS Lambda using the Serverless Framework.
This template configures a single function, api, which is responsible for handling all incoming requests thanks to configured http events. To learn more about http event configuration options, please refer to http event docs. As the events are configured in a way to accept all incoming requests, Flask framework is responsible for routing and handling requests internally. The implementation takes advantage of serverless-wsgi, which allows you to wrap WSGI applications such as Flask apps. To learn more about serverless-wsgi, please refer to corresponding GitHub repository. The template also relies on serverless-python-requirements plugin for packaging dependencies from requirements.txt file. For more details about serverless-python-requirements configuration, please refer to corresponding GitHub repository.
Additionally, the template also handles provisioning of a DynamoDB database that is used for storing data about users. The Flask application exposes two endpoints, POST /users and GET /user/{userId}, which allow to create and retrieve users.
Usage
Prerequisites
In order to package your dependencies locally with serverless-python-requirements, you need to have Python3.8 installed locally. You can create and activate a dedicated virtual environment with the following command:
python3.8 -m venv ./venvsource ./venv/bin/activate
Alternatively, you can also use dockerizePip configuration from serverless-python-requirements. For details on that, please refer to corresponding GitHub repository.
Deployment
install dependencies with:
npm install
and then perform deployment with:
serverless deploy
After running deploy, you should see output similar to:
Deploying "aws-python-flask-dynamodb-api" to stage "dev" (us-east-1)Using Python specified in "runtime": python3.12Packaging Python WSGI handler...✔ Service deployed to stack aws-python-flask-dynamodb-api-dev (123s)endpoints:  ANY - https://xxxxxxxxxx.execute-api.us-east-1.amazonaws.com/dev/  ANY - https://xxxxxxxxxx.execute-api.us-east-1.amazonaws.com/dev/{proxy+}functions:  api: aws-python-flask-dynamodb-api-dev-api (41 MB)
Note: In current form, after deployment, your API is public and can be invoked by anyone. For production deployments, you might want to configure an authorizer. For details on how to do that, refer to http event docs.
Invocation
After successful deployment, you can create a new user by calling the corresponding endpoint:
curl --request POST 'https://xxxxxx.execute-api.us-east-1.amazonaws.com/dev/users' --header 'Content-Type: application/json' --data-raw '{"name": "John", "userId": "someUserId"}'
Which should result in the following response:
{ "userId": "someUserId", "name": "John" }
You can later retrieve the user by userId by calling the following endpoint:
curl https://xxxxxxx.execute-api.us-east-1.amazonaws.com/dev/users/someUserId
Which should result in the following response:
{ "userId": "someUserId", "name": "John" }
Local development
Thanks to capabilities of serverless-wsgi, it is also possible to run your application locally, however, in order to do that, you will need to first install werkzeug, boto3 dependencies, as well as all other dependencies listed in requirements.txt. It is recommended to use a dedicated virtual environment for that purpose. You can install all needed dependencies with the following commands:
pip install werkzeug boto3pip install -r requirements.txt
Additionally, you will need to emulate DynamoDB locally, which can be done by using serverless-dynamodb-local plugin. In order to do that, execute the following commands:
serverless plugin install -n serverless-dynamodb-localserverless dynamodb install
It will add the plugin to devDependencies in package.json file as well as to plugins section in serverless.yml. Additionally, it will also install DynamoDB locally.
You should also add the following config to custom section in serverless.yml:
custom:  (...)  dynamodb:    start:      migrate: true    stages:      - dev
Additionally, we need to reconfigure DynamoDB Client to connect to our local instance of DynamoDB. We can take advantage of IS_OFFLINE environment variable set by serverless-wsgi plugin and replace:
dynamodb_client = boto3.client('dynamodb')
with
dynamodb_client = boto3.client('dynamodb')if os.environ.get('IS_OFFLINE'):    dynamodb_client = boto3.client('dynamodb', region_name='localhost', endpoint_url='http://localhost:8000')
Now you can start DynamoDB local with the following command:
serverless dynamodb start
At this point, you can run your application locally with the following command:
serverless wsgi serve
For additional local development capabilities of serverless-wsgi and serverless-dynamodb-local plugins, please refer to corresponding GitHub repositories:

https://github.com/logandk/serverless-wsgi
https://github.com/99x/serverless-dynamodb-local\n\n\n\nServerless Framework Python Scheduled Cron on AWS
This template demonstrates how to develop and deploy a simple cron-like service running on AWS Lambda using the Serverless Framework.
Detailed information about cron expressions in available in official AWS docs.
Usage
Deployment
This example is made to work with the Serverless Framework dashboard, which includes advanced features such as CI/CD, monitoring, metrics, etc.
In order to deploy with dashboard, you need to first login with:
serverless login
and then perform deployment with:
serverless deploy
After running deploy, you should see output similar to:
Deploying "aws-python-scheduled-cron" to stage "dev" (us-east-1)✔ Service deployed to stack aws-python-scheduled-cron-dev (146s)functions:  rateHandler: aws-python-scheduled-cron-dev-rateHandler (2.2 kB)
There is no additional step required. Your defined schedules becomes active right away after deployment.
Local invocation
In order to test out your functions locally, you can invoke them with the following command:
serverless invoke local --function rateHandler
After invocation, you should see output similar to:
INFO:handler:Your cron function ran at 15:02:43.203145
Bundling dependencies
In case you would like to include 3rd party dependencies, you will need to use a plugin called serverless-python-requirements. You can set it up by running the following command:
serverless plugin install -n serverless-python-requirements
Running the above will automatically add serverless-python-requirements to plugins section in your serverless.yml file and add it as a devDependency to package.json file. The package.json file will be automatically created if it doesn't exist beforehand. Now you will be able to add your dependencies to requirements.txt file (Pipfile and pyproject.toml is also supported but requires additional configuration) and they will be automatically injected to Lambda package during build process. For more details about the plugin's configuration, please refer to official documentation.\n\nExamplesAWS Python Scheduled Cron example in PythonServerless Framework Python Scheduled Cron on AWS
This template demonstrates how to develop and deploy a simple cron-like service running on AWS Lambda using the Serverless Framework.
Detailed information about cron expressions in available in official AWS docs.
Usage
Deployment
This example is made to work with the Serverless Framework dashboard, which includes advanced features such as CI/CD, monitoring, metrics, etc.
In order to deploy with dashboard, you need to first login with:
serverless login
and then perform deployment with:
serverless deploy
After running deploy, you should see output similar to:
Deploying "aws-python-scheduled-cron" to stage "dev" (us-east-1)✔ Service deployed to stack aws-python-scheduled-cron-dev (146s)functions:  rateHandler: aws-python-scheduled-cron-dev-rateHandler (2.2 kB)
There is no additional step required. Your defined schedules becomes active right away after deployment.
Local invocation
In order to test out your functions locally, you can invoke them with the following command:
serverless invoke local --function rateHandler
After invocation, you should see output similar to:
INFO:handler:Your cron function ran at 15:02:43.203145
Bundling dependencies
In case you would like to include 3rd party dependencies, you will need to use a plugin called serverless-python-requirements. You can set it up by running the following command:
serverless plugin install -n serverless-python-requirements
Running the above will automatically add serverless-python-requirements to plugins section in your serverless.yml file and add it as a devDependency to package.json file. The package.json file will be automatically created if it doesn't exist beforehand. Now you will be able to add your dependencies to requirements.txt file (Pipfile and pyproject.toml is also supported but requires additional configuration) and they will be automatically injected to Lambda package during build process. For more details about the plugin's configuration, please refer to official documentation.\n\n\n\nServerless Framework AWS Python Example
This template demonstrates how to deploy a Python function running on AWS Lambda using the Serverless Framework. The deployed function does not include any event definitions as well as any kind of persistence (database). For more advanced configurations check out the examples repo which includes integrations with SQS, DynamoDB or examples of functions that are triggered in cron-like manner. For details about configuration of specific events, please refer to our documentation.
Usage
Deployment
In order to deploy the example, you need to run the following command:
serverless deploy
After running deploy, you should see output similar to:
Deploying "aws-python" to stage "dev" (us-east-1)✔ Service deployed to stack aws-python-dev (90s)functions:  hello: aws-python-dev-hello (1.9 kB)
Invocation
After successful deployment, you can invoke the deployed function by using the following command:
serverless invoke --function hello
Which should result in response similar to the following:
{  "statusCode": 200,  "body": "{\"message\": \"Go Serverless v4.0! Your function executed successfully!\"}"}
Local development
You can invoke your function locally by using the following command:
serverless invoke local --function hello
Which should result in response similar to the following:
{  "statusCode": 200,  "body": "{\"message\": \"Go Serverless v4.0! Your function executed successfully!\"}"}
Bundling dependencies
In case you would like to include third-party dependencies, you will need to use a plugin called serverless-python-requirements. You can set it up by running the following command:
serverless plugin install -n serverless-python-requirements
Running the above will automatically add serverless-python-requirements to plugins section in your serverless.yml file and add it as a devDependency to package.json file. The package.json file will be automatically created if it doesn't exist beforehand. Now you will be able to add your dependencies to requirements.txt file (Pipfile and pyproject.toml is also supported but requires additional configuration) and they will be automatically injected to Lambda package during build process. For more details about the plugin's configuration, please refer to official documentation.\n\nExamplesAWS Python ExampleServerless Framework AWS Python Example
This template demonstrates how to deploy a Python function running on AWS Lambda using the Serverless Framework. The deployed function does not include any event definitions as well as any kind of persistence (database). For more advanced configurations check out the examples repo which includes integrations with SQS, DynamoDB or examples of functions that are triggered in cron-like manner. For details about configuration of specific events, please refer to our documentation.
Usage
Deployment
In order to deploy the example, you need to run the following command:
serverless deploy
After running deploy, you should see output similar to:
Deploying "aws-python" to stage "dev" (us-east-1)✔ Service deployed to stack aws-python-dev (90s)functions:  hello: aws-python-dev-hello (1.9 kB)
Invocation
After successful deployment, you can invoke the deployed function by using the following command:
serverless invoke --function hello
Which should result in response similar to the following:
{  "statusCode": 200,  "body": "{\"message\": \"Go Serverless v4.0! Your function executed successfully!\"}"}
Local development
You can invoke your function locally by using the following command:
serverless invoke local --function hello
Which should result in response similar to the following:
{  "statusCode": 200,  "body": "{\"message\": \"Go Serverless v4.0! Your function executed successfully!\"}"}
Bundling dependencies
In case you would like to include third-party dependencies, you will need to use a plugin called serverless-python-requirements. You can set it up by running the following command:
serverless plugin install -n serverless-python-requirements
Running the above will automatically add serverless-python-requirements to plugins section in your serverless.yml file and add it as a devDependency to package.json file. The package.json file will be automatically created if it doesn't exist beforehand. Now you will be able to add your dependencies to requirements.txt file (Pipfile and pyproject.toml is also supported but requires additional configuration) and they will be automatically injected to Lambda package during build process. For more details about the plugin's configuration, please refer to official documentation.\n\n\n\nServerless Framework Node with Typescript REST API on AWS
This template demonstrates how to make a simple REST API with Node.js and Typescript running on AWS Lambda and API Gateway using the Serverless Framework v1.
This template does not include any kind of persistence (database). For a more advanced example check out the aws-node-rest-api-typescript example which has must RESTful resources and persistence using MongoDB.
Setup
Run this command to initialize a new project in a new working directory.
sls init aws-node-rest-api-typescript
Usage
Deploy
This example is made to work with the Serverless Framework dashboard which includes advanced features like CI/CD, monitoring, metrics, etc.
$ serverless login$ serverless deploy
To deploy without the dashboard you will need to remove org and app fields from the serverless.yml, and you won’t have to run sls login before deploying.
Invoke the function locally.
serverless invoke local --function hello
Invoke the function
curl https://xxxxxxxxx.execute-api.us-east-1.amazonaws.com/dev/\n\nExamplesAWS Simple HTTP Endpoint example in NodeJS with TypescriptServerless Framework Node with Typescript REST API on AWS
This template demonstrates how to make a simple REST API with Node.js and Typescript running on AWS Lambda and API Gateway using the Serverless Framework v1.
This template does not include any kind of persistence (database). For a more advanced example check out the aws-node-rest-api-typescript example which has must RESTful resources and persistence using MongoDB.
Setup
Run this command to initialize a new project in a new working directory.
sls init aws-node-rest-api-typescript
Usage
Deploy
This example is made to work with the Serverless Framework dashboard which includes advanced features like CI/CD, monitoring, metrics, etc.
$ serverless login$ serverless deploy
To deploy without the dashboard you will need to remove org and app fields from the serverless.yml, and you won’t have to run sls login before deploying.
Invoke the function locally.
serverless invoke local --function hello
Invoke the function
curl https://xxxxxxxxx.execute-api.us-east-1.amazonaws.com/dev/\n\n\n\nServerless Framework Node REST API on AWS
This template demonstrates how to make a simple REST API with Node.js running on AWS Lambda and API Gateway using the traditional Serverless Framework.
This template does not include any kind of persistence (database). For a more advanced examples check out the examples repo which includes Typescript, Mongo, DynamoDB and other examples.
Usage
Deployment
This example is made to work with the Serverless Framework dashboard which includes advanced features like CI/CD, monitoring, metrics, etc.
$ serverless login$ serverless deploy
To deploy without the dashboard you will need to remove org and app fields from the serverless.yml, and you won’t have to run sls login before deploying.
After running deploy, you should see output similar to:
Serverless: Packaging service...Serverless: Excluding development dependencies...Serverless: Creating Stack...Serverless: Checking Stack create progress...........Serverless: Stack create finished...Serverless: Uploading CloudFormation file to S3...Serverless: Uploading artifacts...Serverless: Uploading service aws-node-rest-api.zip file to S3 (711.23 KB)...Serverless: Validating template...Serverless: Updating Stack...Serverless: Checking Stack update progress....................................Serverless: Stack update finished...Service Informationservice: aws-node-rest-apistage: devregion: us-east-1stack: aws-node-rest-api-devresources: 12api keys:  Noneendpoints:  ANY - https://xxxxxxx.execute-api.us-east-1.amazonaws.com/dev/functions:  api: aws-node-rest-api-dev-hellolayers:  None
Note: In current form, after deployment, your API is public and can be invoked by anyone. For production deployments, you might want to configure an authorizer. For details on how to do that, refer to http event docs.
Invocation
After successful deployment, you can call the created application via HTTP:
curl https://xxxxxxx.execute-api.us-east-1.amazonaws.com/dev/
Which should result in response similar to the following (removed input content for brevity):
{  "message": "Go Serverless v2.0! Your function executed successfully!",  "input": {    ...  }}
Local development
You can invoke your function locally by using the following command:
serverless invoke local --function hello
Which should result in response similar to the following:
{  "statusCode": 200,  "body": "{\n  \"message\": \"Go Serverless v2.0! Your function executed successfully!\",\n  \"input\": \"\"\n}"}
Alternatively, it is also possible to emulate API Gateway and Lambda locally by using serverless-offline plugin. In order to do that, execute the following command:
serverless plugin install -n serverless-offline
It will add the serverless-offline plugin to devDependencies in package.json file as well as will add it to plugins in serverless.yml.
After installation, you can start local emulation with:
serverless offline
To learn more about the capabilities of serverless-offline, please refer to its GitHub repository.\n\nExamplesAWS Simple HTTP Endpoint example in NodeJSServerless Framework Node REST API on AWS
This template demonstrates how to make a simple REST API with Node.js running on AWS Lambda and API Gateway using the traditional Serverless Framework.
This template does not include any kind of persistence (database). For a more advanced examples check out the examples repo which includes Typescript, Mongo, DynamoDB and other examples.
Usage
Deployment
This example is made to work with the Serverless Framework dashboard which includes advanced features like CI/CD, monitoring, metrics, etc.
$ serverless login$ serverless deploy
To deploy without the dashboard you will need to remove org and app fields from the serverless.yml, and you won’t have to run sls login before deploying.
After running deploy, you should see output similar to:
Serverless: Packaging service...Serverless: Excluding development dependencies...Serverless: Creating Stack...Serverless: Checking Stack create progress...........Serverless: Stack create finished...Serverless: Uploading CloudFormation file to S3...Serverless: Uploading artifacts...Serverless: Uploading service aws-node-rest-api.zip file to S3 (711.23 KB)...Serverless: Validating template...Serverless: Updating Stack...Serverless: Checking Stack update progress....................................Serverless: Stack update finished...Service Informationservice: aws-node-rest-apistage: devregion: us-east-1stack: aws-node-rest-api-devresources: 12api keys:  Noneendpoints:  ANY - https://xxxxxxx.execute-api.us-east-1.amazonaws.com/dev/functions:  api: aws-node-rest-api-dev-hellolayers:  None
Note: In current form, after deployment, your API is public and can be invoked by anyone. For production deployments, you might want to configure an authorizer. For details on how to do that, refer to http event docs.
Invocation
After successful deployment, you can call the created application via HTTP:
curl https://xxxxxxx.execute-api.us-east-1.amazonaws.com/dev/
Which should result in response similar to the following (removed input content for brevity):
{  "message": "Go Serverless v2.0! Your function executed successfully!",  "input": {    ...  }}
Local development
You can invoke your function locally by using the following command:
serverless invoke local --function hello
Which should result in response similar to the following:
{  "statusCode": 200,  "body": "{\n  \"message\": \"Go Serverless v2.0! Your function executed successfully!\",\n  \"input\": \"\"\n}"}
Alternatively, it is also possible to emulate API Gateway and Lambda locally by using serverless-offline plugin. In order to do that, execute the following command:
serverless plugin install -n serverless-offline
It will add the serverless-offline plugin to devDependencies in package.json file as well as will add it to plugins in serverless.yml.
After installation, you can start local emulation with:
serverless offline
To learn more about the capabilities of serverless-offline, please refer to its GitHub repository.\n\n\n\nProducts Documentation PricingCompany Toggle themeSearch⌘ KLoginSign UpToggle navigation menu\nProducts Documentation PricingCompany Toggle themeSearch⌘ KLoginSign UpToggle navigation menu\nProducts Documentation PricingCompany Toggle themeSearch⌘ KLoginSign UpToggle navigation menu\nProducts Documentation PricingCompany\nToggle themeSearch⌘ KLoginSign Up\nToggle navigation menu\nMenuToggle navigation menuServerless ExamplesLanguageNodeGoJavaPythonRubyRustPhpSwiftCsharpAuthor0x4D31Abbasdgr8Adam BergmanAdnanrahicAdrian MoraretAletheiaAlex CasalboniAlexcasalboniAllan ChuaAndreas HeissenbergerAndrei MaksimovAndreivmaksimovAndresAndrewFarleyAnna SpyszAnomaly InnovationsAusten CollinsAyoubEdBen FitzgeraldBennybauerBill KidwellBill WangBjörn BilgerBoazdejongBrianAndersen78Bruce EdgeBryan KillianBsdkurtBvincent1CalvintychanCaulagiCeilforsChan9390Chief WizardChristoph GysinConveyalCpleeCraftshipCraig SweatonDaisuke-awajiDaniel AniszkiewiczDaniel OlsonDarren HollandDidilDrocco007DschepDuong TranDylan MyersDzimineEetu TuomalaEliecer Hernandez GarbeyEmilien EscalleErez RokahEslam λ HefnawyFaultlineFlorian FußFrancisco OrtizFrançois FargeGarden AidGarrett SweeneyGismo RanasGodfrey HobbsHoseungJangIgorbakmanIttusIvanderbu2James ThomasJan LiesendahlJay DeshmukhJisuParkJoeseph RodriguesJohncmunsonJonatas BaldinJonee Ryan TyJordan HornblowJoseph YiJoshuaTothKai HendryKalin ChernevKalinchernevKenyippKimcoderKurshit KukrejaLakshmantgldLuciano Pellacani FrancaLukas AndersenLynnalooMarcus LumMário LuizMark SteeleMarkhobsonMarzeelabsMatt HernandezMatt WelkeMay JunMbsambangiMbudmMiguel FrazaoMsfidelisMugglmenzelNiJiaNikosNileshprasad137NoetixNsupyqOpen-botP0n2Patrick MichelbergerPeter ChuPharindokoPhilipp MuensPicsoungPmuensPramono WinataRafalWilinskiRandy FindleyRentropRhlsthrmRob AbbottRpidannyRupak GangulySbstjnSC5Scott BrennerSCPRSebastian BorzaSeojeeeSeonghyun OhServerless, inc.ServerlessbuchShahzeb K.SilvermulletSlashbitSlaytrSrbryStefan JudisSvdgraafTakahashimTakahiro HorikeTheburningmonkThomastoyeTimothy HopperTylorShinUnlyWalgarchWolfgang TeuberPlatformAWSAzureGCPKubelessOpenwhiskTwilioAWS Simple HTTP Endpoint Example In Node JSby Serverless, inc.This template demonstrates how to make a simple HTTP API with Node....Node Express API On AWSby Serverless, inc.This template demonstrates how to develop and deploy a simple Node ...Node Express API Service Backed By Dynamo DB On...by Serverless, inc.This template demonstrates how to develop and deploy a simple Node ...AWS Node Scheduled Cron Example In Node JSby Rob AbbottThis is an example of creating a function that runs as a cron job u...AWS Node JS Exampleby Serverless, inc.This template demonstrates how to deploy a simple NodeJS function r...AWS Simple HTTP Endpoint Example In Pythonby Serverless, inc.This template demonstrates how to make a simple HTTP API with Pytho...Python Flask API On AWSby Serverless, inc.This template demonstrates how to develop and deploy a simple Pytho...Python Flask API Backed By Dynamo DB On AWSby Serverless, inc.This template demonstrates how to develop and deploy a simple Pytho...AWS Python Scheduled Cron Example In Pythonby Rupak GangulyThis is an example of creating a function that runs as a cron job u...AWS Python Exampleby Serverless, inc.This template demonstrates how to deploy a Python function running ...AWS Simple HTTP Endpoint Example In Node JS Wit...by Serverless, inc.This template demonstrates how to make a simple REST API with Node....AWS Simple HTTP Endpoint Example In Node JSby Serverless, inc.This template demonstrates how to make a simple REST API with Node....Previous12345More pages19Next\nMenuToggle navigation menuServerless ExamplesLanguageNodeGoJavaPythonRubyRustPhpSwiftCsharpAuthor0x4D31Abbasdgr8Adam BergmanAdnanrahicAdrian MoraretAletheiaAlex CasalboniAlexcasalboniAllan ChuaAndreas HeissenbergerAndrei MaksimovAndreivmaksimovAndresAndrewFarleyAnna SpyszAnomaly InnovationsAusten CollinsAyoubEdBen FitzgeraldBennybauerBill KidwellBill WangBjörn BilgerBoazdejongBrianAndersen78Bruce EdgeBryan KillianBsdkurtBvincent1CalvintychanCaulagiCeilforsChan9390Chief WizardChristoph GysinConveyalCpleeCraftshipCraig SweatonDaisuke-awajiDaniel AniszkiewiczDaniel OlsonDarren HollandDidilDrocco007DschepDuong TranDylan MyersDzimineEetu TuomalaEliecer Hernandez GarbeyEmilien EscalleErez RokahEslam λ HefnawyFaultlineFlorian FußFrancisco OrtizFrançois FargeGarden AidGarrett SweeneyGismo RanasGodfrey HobbsHoseungJangIgorbakmanIttusIvanderbu2James ThomasJan LiesendahlJay DeshmukhJisuParkJoeseph RodriguesJohncmunsonJonatas BaldinJonee Ryan TyJordan HornblowJoseph YiJoshuaTothKai HendryKalin ChernevKalinchernevKenyippKimcoderKurshit KukrejaLakshmantgldLuciano Pellacani FrancaLukas AndersenLynnalooMarcus LumMário LuizMark SteeleMarkhobsonMarzeelabsMatt HernandezMatt WelkeMay JunMbsambangiMbudmMiguel FrazaoMsfidelisMugglmenzelNiJiaNikosNileshprasad137NoetixNsupyqOpen-botP0n2Patrick MichelbergerPeter ChuPharindokoPhilipp MuensPicsoungPmuensPramono WinataRafalWilinskiRandy FindleyRentropRhlsthrmRob AbbottRpidannyRupak GangulySbstjnSC5Scott BrennerSCPRSebastian BorzaSeojeeeSeonghyun OhServerless, inc.ServerlessbuchShahzeb K.SilvermulletSlashbitSlaytrSrbryStefan JudisSvdgraafTakahashimTakahiro HorikeTheburningmonkThomastoyeTimothy HopperTylorShinUnlyWalgarchWolfgang TeuberPlatformAWSAzureGCPKubelessOpenwhiskTwilioAWS Simple HTTP Endpoint Example In Node JSby Serverless, inc.This template demonstrates how to make a simple HTTP API with Node....Node Express API On AWSby Serverless, inc.This template demonstrates how to develop and deploy a simple Node ...Node Express API Service Backed By Dynamo DB On...by Serverless, inc.This template demonstrates how to develop and deploy a simple Node ...AWS Node Scheduled Cron Example In Node JSby Rob AbbottThis is an example of creating a function that runs as a cron job u...AWS Node JS Exampleby Serverless, inc.This template demonstrates how to deploy a simple NodeJS function r...AWS Simple HTTP Endpoint Example In Pythonby Serverless, inc.This template demonstrates how to make a simple HTTP API with Pytho...Python Flask API On AWSby Serverless, inc.This template demonstrates how to develop and deploy a simple Pytho...Python Flask API Backed By Dynamo DB On AWSby Serverless, inc.This template demonstrates how to develop and deploy a simple Pytho...AWS Python Scheduled Cron Example In Pythonby Rupak GangulyThis is an example of creating a function that runs as a cron job u...AWS Python Exampleby Serverless, inc.This template demonstrates how to deploy a Python function running ...AWS Simple HTTP Endpoint Example In Node JS Wit...by Serverless, inc.This template demonstrates how to make a simple REST API with Node....AWS Simple HTTP Endpoint Example In Node JSby Serverless, inc.This template demonstrates how to make a simple REST API with Node....Previous12345More pages19Next\nMenuToggle navigation menu\nToggle navigation menu\nServerless ExamplesLanguageNodeGoJavaPythonRubyRustPhpSwiftCsharpAuthor0x4D31Abbasdgr8Adam BergmanAdnanrahicAdrian MoraretAletheiaAlex CasalboniAlexcasalboniAllan ChuaAndreas HeissenbergerAndrei MaksimovAndreivmaksimovAndresAndrewFarleyAnna SpyszAnomaly InnovationsAusten CollinsAyoubEdBen FitzgeraldBennybauerBill KidwellBill WangBjörn BilgerBoazdejongBrianAndersen78Bruce EdgeBryan KillianBsdkurtBvincent1CalvintychanCaulagiCeilforsChan9390Chief WizardChristoph GysinConveyalCpleeCraftshipCraig SweatonDaisuke-awajiDaniel AniszkiewiczDaniel OlsonDarren HollandDidilDrocco007DschepDuong TranDylan MyersDzimineEetu TuomalaEliecer Hernandez GarbeyEmilien EscalleErez RokahEslam λ HefnawyFaultlineFlorian FußFrancisco OrtizFrançois FargeGarden AidGarrett SweeneyGismo RanasGodfrey HobbsHoseungJangIgorbakmanIttusIvanderbu2James ThomasJan LiesendahlJay DeshmukhJisuParkJoeseph RodriguesJohncmunsonJonatas BaldinJonee Ryan TyJordan HornblowJoseph YiJoshuaTothKai HendryKalin ChernevKalinchernevKenyippKimcoderKurshit KukrejaLakshmantgldLuciano Pellacani FrancaLukas AndersenLynnalooMarcus LumMário LuizMark SteeleMarkhobsonMarzeelabsMatt HernandezMatt WelkeMay JunMbsambangiMbudmMiguel FrazaoMsfidelisMugglmenzelNiJiaNikosNileshprasad137NoetixNsupyqOpen-botP0n2Patrick MichelbergerPeter ChuPharindokoPhilipp MuensPicsoungPmuensPramono WinataRafalWilinskiRandy FindleyRentropRhlsthrmRob AbbottRpidannyRupak GangulySbstjnSC5Scott BrennerSCPRSebastian BorzaSeojeeeSeonghyun OhServerless, inc.ServerlessbuchShahzeb K.SilvermulletSlashbitSlaytrSrbryStefan JudisSvdgraafTakahashimTakahiro HorikeTheburningmonkThomastoyeTimothy HopperTylorShinUnlyWalgarchWolfgang TeuberPlatformAWSAzureGCPKubelessOpenwhiskTwilio\nServerless ExamplesLanguageNodeGoJavaPythonRubyRustPhpSwiftCsharpAuthor0x4D31Abbasdgr8Adam BergmanAdnanrahicAdrian MoraretAletheiaAlex CasalboniAlexcasalboniAllan ChuaAndreas HeissenbergerAndrei MaksimovAndreivmaksimovAndresAndrewFarleyAnna SpyszAnomaly InnovationsAusten CollinsAyoubEdBen FitzgeraldBennybauerBill KidwellBill WangBjörn BilgerBoazdejongBrianAndersen78Bruce EdgeBryan KillianBsdkurtBvincent1CalvintychanCaulagiCeilforsChan9390Chief WizardChristoph GysinConveyalCpleeCraftshipCraig SweatonDaisuke-awajiDaniel AniszkiewiczDaniel OlsonDarren HollandDidilDrocco007DschepDuong TranDylan MyersDzimineEetu TuomalaEliecer Hernandez GarbeyEmilien EscalleErez RokahEslam λ HefnawyFaultlineFlorian FußFrancisco OrtizFrançois FargeGarden AidGarrett SweeneyGismo RanasGodfrey HobbsHoseungJangIgorbakmanIttusIvanderbu2James ThomasJan LiesendahlJay DeshmukhJisuParkJoeseph RodriguesJohncmunsonJonatas BaldinJonee Ryan TyJordan HornblowJoseph YiJoshuaTothKai HendryKalin ChernevKalinchernevKenyippKimcoderKurshit KukrejaLakshmantgldLuciano Pellacani FrancaLukas AndersenLynnalooMarcus LumMário LuizMark SteeleMarkhobsonMarzeelabsMatt HernandezMatt WelkeMay JunMbsambangiMbudmMiguel FrazaoMsfidelisMugglmenzelNiJiaNikosNileshprasad137NoetixNsupyqOpen-botP0n2Patrick MichelbergerPeter ChuPharindokoPhilipp MuensPicsoungPmuensPramono WinataRafalWilinskiRandy FindleyRentropRhlsthrmRob AbbottRpidannyRupak GangulySbstjnSC5Scott BrennerSCPRSebastian BorzaSeojeeeSeonghyun OhServerless, inc.ServerlessbuchShahzeb K.SilvermulletSlashbitSlaytrSrbryStefan JudisSvdgraafTakahashimTakahiro HorikeTheburningmonkThomastoyeTimothy HopperTylorShinUnlyWalgarchWolfgang TeuberPlatformAWSAzureGCPKubelessOpenwhiskTwilio\nServerless ExamplesLanguageNodeGoJavaPythonRubyRustPhpSwiftCsharpAuthor0x4D31Abbasdgr8Adam BergmanAdnanrahicAdrian MoraretAletheiaAlex CasalboniAlexcasalboniAllan ChuaAndreas HeissenbergerAndrei MaksimovAndreivmaksimovAndresAndrewFarleyAnna SpyszAnomaly InnovationsAusten CollinsAyoubEdBen FitzgeraldBennybauerBill KidwellBill WangBjörn BilgerBoazdejongBrianAndersen78Bruce EdgeBryan KillianBsdkurtBvincent1CalvintychanCaulagiCeilforsChan9390Chief WizardChristoph GysinConveyalCpleeCraftshipCraig SweatonDaisuke-awajiDaniel AniszkiewiczDaniel OlsonDarren HollandDidilDrocco007DschepDuong TranDylan MyersDzimineEetu TuomalaEliecer Hernandez GarbeyEmilien EscalleErez RokahEslam λ HefnawyFaultlineFlorian FußFrancisco OrtizFrançois FargeGarden AidGarrett SweeneyGismo RanasGodfrey HobbsHoseungJangIgorbakmanIttusIvanderbu2James ThomasJan LiesendahlJay DeshmukhJisuParkJoeseph RodriguesJohncmunsonJonatas BaldinJonee Ryan TyJordan HornblowJoseph YiJoshuaTothKai HendryKalin ChernevKalinchernevKenyippKimcoderKurshit KukrejaLakshmantgldLuciano Pellacani FrancaLukas AndersenLynnalooMarcus LumMário LuizMark SteeleMarkhobsonMarzeelabsMatt HernandezMatt WelkeMay JunMbsambangiMbudmMiguel FrazaoMsfidelisMugglmenzelNiJiaNikosNileshprasad137NoetixNsupyqOpen-botP0n2Patrick MichelbergerPeter ChuPharindokoPhilipp MuensPicsoungPmuensPramono WinataRafalWilinskiRandy FindleyRentropRhlsthrmRob AbbottRpidannyRupak GangulySbstjnSC5Scott BrennerSCPRSebastian BorzaSeojeeeSeonghyun OhServerless, inc.ServerlessbuchShahzeb K.SilvermulletSlashbitSlaytrSrbryStefan JudisSvdgraafTakahashimTakahiro HorikeTheburningmonkThomastoyeTimothy HopperTylorShinUnlyWalgarchWolfgang TeuberPlatformAWSAzureGCPKubelessOpenwhiskTwilio\nLanguageNodeGoJavaPythonRubyRustPhpSwiftCsharp\nNodeGoJavaPythonRubyRustPhpSwiftCsharp\nAuthor0x4D31Abbasdgr8Adam BergmanAdnanrahicAdrian MoraretAletheiaAlex CasalboniAlexcasalboniAllan ChuaAndreas HeissenbergerAndrei MaksimovAndreivmaksimovAndresAndrewFarleyAnna SpyszAnomaly InnovationsAusten CollinsAyoubEdBen FitzgeraldBennybauerBill KidwellBill WangBjörn BilgerBoazdejongBrianAndersen78Bruce EdgeBryan KillianBsdkurtBvincent1CalvintychanCaulagiCeilforsChan9390Chief WizardChristoph GysinConveyalCpleeCraftshipCraig SweatonDaisuke-awajiDaniel AniszkiewiczDaniel OlsonDarren HollandDidilDrocco007DschepDuong TranDylan MyersDzimineEetu TuomalaEliecer Hernandez GarbeyEmilien EscalleErez RokahEslam λ HefnawyFaultlineFlorian FußFrancisco OrtizFrançois FargeGarden AidGarrett SweeneyGismo RanasGodfrey HobbsHoseungJangIgorbakmanIttusIvanderbu2James ThomasJan LiesendahlJay DeshmukhJisuParkJoeseph RodriguesJohncmunsonJonatas BaldinJonee Ryan TyJordan HornblowJoseph YiJoshuaTothKai HendryKalin ChernevKalinchernevKenyippKimcoderKurshit KukrejaLakshmantgldLuciano Pellacani FrancaLukas AndersenLynnalooMarcus LumMário LuizMark SteeleMarkhobsonMarzeelabsMatt HernandezMatt WelkeMay JunMbsambangiMbudmMiguel FrazaoMsfidelisMugglmenzelNiJiaNikosNileshprasad137NoetixNsupyqOpen-botP0n2Patrick MichelbergerPeter ChuPharindokoPhilipp MuensPicsoungPmuensPramono WinataRafalWilinskiRandy FindleyRentropRhlsthrmRob AbbottRpidannyRupak GangulySbstjnSC5Scott BrennerSCPRSebastian BorzaSeojeeeSeonghyun OhServerless, inc.ServerlessbuchShahzeb K.SilvermulletSlashbitSlaytrSrbryStefan JudisSvdgraafTakahashimTakahiro HorikeTheburningmonkThomastoyeTimothy HopperTylorShinUnlyWalgarchWolfgang Teuber\n0x4D31Abbasdgr8Adam BergmanAdnanrahicAdrian MoraretAletheiaAlex CasalboniAlexcasalboniAllan ChuaAndreas HeissenbergerAndrei MaksimovAndreivmaksimovAndresAndrewFarleyAnna SpyszAnomaly InnovationsAusten CollinsAyoubEdBen FitzgeraldBennybauerBill KidwellBill WangBjörn BilgerBoazdejongBrianAndersen78Bruce EdgeBryan KillianBsdkurtBvincent1CalvintychanCaulagiCeilforsChan9390Chief WizardChristoph GysinConveyalCpleeCraftshipCraig SweatonDaisuke-awajiDaniel AniszkiewiczDaniel OlsonDarren HollandDidilDrocco007DschepDuong TranDylan MyersDzimineEetu TuomalaEliecer Hernandez GarbeyEmilien EscalleErez RokahEslam λ HefnawyFaultlineFlorian FußFrancisco OrtizFrançois FargeGarden AidGarrett SweeneyGismo RanasGodfrey HobbsHoseungJangIgorbakmanIttusIvanderbu2James ThomasJan LiesendahlJay DeshmukhJisuParkJoeseph RodriguesJohncmunsonJonatas BaldinJonee Ryan TyJordan HornblowJoseph YiJoshuaTothKai HendryKalin ChernevKalinchernevKenyippKimcoderKurshit KukrejaLakshmantgldLuciano Pellacani FrancaLukas AndersenLynnalooMarcus LumMário LuizMark SteeleMarkhobsonMarzeelabsMatt HernandezMatt WelkeMay JunMbsambangiMbudmMiguel FrazaoMsfidelisMugglmenzelNiJiaNikosNileshprasad137NoetixNsupyqOpen-botP0n2Patrick MichelbergerPeter ChuPharindokoPhilipp MuensPicsoungPmuensPramono WinataRafalWilinskiRandy FindleyRentropRhlsthrmRob AbbottRpidannyRupak GangulySbstjnSC5Scott BrennerSCPRSebastian BorzaSeojeeeSeonghyun OhServerless, inc.ServerlessbuchShahzeb K.SilvermulletSlashbitSlaytrSrbryStefan JudisSvdgraafTakahashimTakahiro HorikeTheburningmonkThomastoyeTimothy HopperTylorShinUnlyWalgarchWolfgang Teuber\nAndreas Heissenberger\nAndreas Heissenberger\nEliecer Hernandez Garbey\nEliecer Hernandez Garbey\nLuciano Pellacani Franca\nLuciano Pellacani Franca\nPlatformAWSAzureGCPKubelessOpenwhiskTwilio\nAWSAzureGCPKubelessOpenwhiskTwilio\nAWS Simple HTTP Endpoint Example In Node JSby Serverless, inc.This template demonstrates how to make a simple HTTP API with Node....Node Express API On AWSby Serverless, inc.This template demonstrates how to develop and deploy a simple Node ...Node Express API Service Backed By Dynamo DB On...by Serverless, inc.This template demonstrates how to develop and deploy a simple Node ...AWS Node Scheduled Cron Example In Node JSby Rob AbbottThis is an example of creating a function that runs as a cron job u...AWS Node JS Exampleby Serverless, inc.This template demonstrates how to deploy a simple NodeJS function r...AWS Simple HTTP Endpoint Example In Pythonby Serverless, inc.This template demonstrates how to make a simple HTTP API with Pytho...Python Flask API On AWSby Serverless, inc.This template demonstrates how to develop and deploy a simple Pytho...Python Flask API Backed By Dynamo DB On AWSby Serverless, inc.This template demonstrates how to develop and deploy a simple Pytho...AWS Python Scheduled Cron Example In Pythonby Rupak GangulyThis is an example of creating a function that runs as a cron job u...AWS Python Exampleby Serverless, inc.This template demonstrates how to deploy a Python function running ...AWS Simple HTTP Endpoint Example In Node JS Wit...by Serverless, inc.This template demonstrates how to make a simple REST API with Node....AWS Simple HTTP Endpoint Example In Node JSby Serverless, inc.This template demonstrates how to make a simple REST API with Node....Previous12345More pages19Next\nAWS Simple HTTP Endpoint Example In Node JSby Serverless, inc.This template demonstrates how to make a simple HTTP API with Node....Node Express API On AWSby Serverless, inc.This template demonstrates how to develop and deploy a simple Node ...Node Express API Service Backed By Dynamo DB On...by Serverless, inc.This template demonstrates how to develop and deploy a simple Node ...AWS Node Scheduled Cron Example In Node JSby Rob AbbottThis is an example of creating a function that runs as a cron job u...AWS Node JS Exampleby Serverless, inc.This template demonstrates how to deploy a simple NodeJS function r...AWS Simple HTTP Endpoint Example In Pythonby Serverless, inc.This template demonstrates how to make a simple HTTP API with Pytho...Python Flask API On AWSby Serverless, inc.This template demonstrates how to develop and deploy a simple Pytho...Python Flask API Backed By Dynamo DB On AWSby Serverless, inc.This template demonstrates how to develop and deploy a simple Pytho...AWS Python Scheduled Cron Example In Pythonby Rupak GangulyThis is an example of creating a function that runs as a cron job u...AWS Python Exampleby Serverless, inc.This template demonstrates how to deploy a Python function running ...AWS Simple HTTP Endpoint Example In Node JS Wit...by Serverless, inc.This template demonstrates how to make a simple REST API with Node....AWS Simple HTTP Endpoint Example In Node JSby Serverless, inc.This template demonstrates how to make a simple REST API with Node....\nAWS Simple HTTP Endpoint Example In Node JSby Serverless, inc.This template demonstrates how to make a simple HTTP API with Node....\nAWS Simple HTTP Endpoint Example In Node JSby Serverless, inc.\nAWS Simple HTTP Endpoint Example In Node JSby Serverless, inc.\nAWS Simple HTTP Endpoint Example In Node JS\nThis template demonstrates how to make a simple HTTP API with Node....\nNode Express API On AWSby Serverless, inc.This template demonstrates how to develop and deploy a simple Node ...\nNode Express API On AWSby Serverless, inc.\nNode Express API On AWSby Serverless, inc.\nNode Express API On AWS\nThis template demonstrates how to develop and deploy a simple Node ...\nNode Express API Service Backed By Dynamo DB On...by Serverless, inc.This template demonstrates how to develop and deploy a simple Node ...\nNode Express API Service Backed By Dynamo DB On...by Serverless, inc.\nNode Express API Service Backed By Dynamo DB On...by Serverless, inc.\nNode Express API Service Backed By Dynamo DB On...\nThis template demonstrates how to develop and deploy a simple Node ...\nAWS Node Scheduled Cron Example In Node JSby Rob AbbottThis is an example of creating a function that runs as a cron job u...\nAWS Node Scheduled Cron Example In Node JSby Rob Abbott\nAWS Node Scheduled Cron Example In Node JSby Rob Abbott\nAWS Node Scheduled Cron Example In Node JS\nThis is an example of creating a function that runs as a cron job u...\nAWS Node JS Exampleby Serverless, inc.This template demonstrates how to deploy a simple NodeJS function r...\nAWS Node JS Exampleby Serverless, inc.\nAWS Node JS Exampleby Serverless, inc.\nThis template demonstrates how to deploy a simple NodeJS function r...\nAWS Simple HTTP Endpoint Example In Pythonby Serverless, inc.This template demonstrates how to make a simple HTTP API with Pytho...\nAWS Simple HTTP Endpoint Example In Pythonby Serverless, inc.\nAWS Simple HTTP Endpoint Example In Pythonby Serverless, inc.\nAWS Simple HTTP Endpoint Example In Python\nThis template demonstrates how to make a simple HTTP API with Pytho...\nPython Flask API On AWSby Serverless, inc.This template demonstrates how to develop and deploy a simple Pytho...\nPython Flask API On AWSby Serverless, inc.\nPython Flask API On AWSby Serverless, inc.\nPython Flask API On AWS\nThis template demonstrates how to develop and deploy a simple Pytho...\nPython Flask API Backed By Dynamo DB On AWSby Serverless, inc.This template demonstrates how to develop and deploy a simple Pytho...\nPython Flask API Backed By Dynamo DB On AWSby Serverless, inc.\nPython Flask API Backed By Dynamo DB On AWSby Serverless, inc.\nPython Flask API Backed By Dynamo DB On AWS\nThis template demonstrates how to develop and deploy a simple Pytho...\nAWS Python Scheduled Cron Example In Pythonby Rupak GangulyThis is an example of creating a function that runs as a cron job u...\nAWS Python Scheduled Cron Example In Pythonby Rupak Ganguly\nAWS Python Scheduled Cron Example In Pythonby Rupak Ganguly\nAWS Python Scheduled Cron Example In Python\nThis is an example of creating a function that runs as a cron job u...\nAWS Python Exampleby Serverless, inc.This template demonstrates how to deploy a Python function running ...\nAWS Python Exampleby Serverless, inc.\nAWS Python Exampleby Serverless, inc.\nThis template demonstrates how to deploy a Python function running ...\nAWS Simple HTTP Endpoint Example In Node JS Wit...by Serverless, inc.This template demonstrates how to make a simple REST API with Node....\nAWS Simple HTTP Endpoint Example In Node JS Wit...by Serverless, inc.\nAWS Simple HTTP Endpoint Example In Node JS Wit...by Serverless, inc.\nAWS Simple HTTP Endpoint Example In Node JS Wit...\nThis template demonstrates how to make a simple REST API with Node....\nAWS Simple HTTP Endpoint Example In Node JSby Serverless, inc.This template demonstrates how to make a simple REST API with Node....\nAWS Simple HTTP Endpoint Example In Node JSby Serverless, inc.\nAWS Simple HTTP Endpoint Example In Node JSby Serverless, inc.\nAWS Simple HTTP Endpoint Example In Node JS\nThis template demonstrates how to make a simple REST API with Node....\n© 2025 Serverless, Inc. All rights reserved.Terms of ServicePrivacy Policy\n© 2025 Serverless, Inc. All rights reserved.\nTerms of ServicePrivacy Policy\n\n\n\n\nTraditionally, if you wanted to deploy an app to the web in some way, it usually involves finding a hosting provider like AWS where you can configure a server, maybe multiple servers or even clusters of servers to provide you everything you need for your application. You develop an application and deploy it to the servers you setup. More servers will be needed to host your database platform. Perhaps you even need additional servers for features such as message queues or event buses. Lets call this a “serverful” architectureWhile it is perfectly possible to get all of this up and running, it does create some significant problems, which we will take a look at, but Serverless as an architectural pattern aims to replace all this need for servers with the exclusive use of fully managed services such as you find in the cloud.For example, instead of setting up a web server and all the associated load balancing, auto scaling, updating and management required, you use a service such as API Gateway that can receive HTTP requests. Instead of setting up an application server to execute business logic on top of these requests, you use a service such as AWS Lambda.But why bother? Isn't the serverful way good enough? Lets take a look at the advantages that Serverless development gives youHandling loadOne of the issues around traditional serverful architectures is that it is a little difficult to handle sudden spikes in load efficiently. Usually you need to rely on being able to predict these spikes. For example, if you know the marketing team sends a newsletter out to a lot of people in the morning, you can spin up enough servers to (hopefully) manage the expected load. But what about unexpected load? The last thing you want is to get a sudden flood of traffic because of a news article or social media influencer and not be able to take advantage of potential revenue because everything just falls over under the load.The only reliable way to make accommodation for that in a serverful environment, is to set your minimum capacity high enough to hopefully handle the load until the automated systems can spin up additional infrastructure. However, this means that even at 2am, when load is at lowest, you have a costly amount of infrastructure deployed “just in case”, billing you by the hour.On the flip side, fully managed services such as API Gateway, DynamoDB and AWS Lambda, bill on usage only. Have no traffic at 2am? You get billed nothing. Yet these services are, by default, able to handle large spikes of traffic at once with no delay in ramping up capacity and essentially scale down to zero instantly too. At no additional cost or effort from you.Much lower management overheadPeople may tell you “oh just spin up a virtual machine in the cloud” in order to serve your application over the web. That sounds easy enough when you know what you are doing. But there’s the rub. While anyone can Google around and create cloud infrastructure with virtual machines and containers, setting them up correctly in a secure way requires the right knowledge and skills. And once setup, it doesn’t end there. Servers need to be maintained; operating system updates, application software updates, configuration updates to conform to newer best practices, efficiency improvements, security improvements. And your application needs may change over time, so your infrastructure will need to be adjusted, added to and expanded as you grow and as your application changes.dwBut this has some downsides:You need to have qualified personnel available to manage this infrastructure.Your developers will need to wait for changes to be made to infrastructure before deploying newer features.Skilled dev ops professionals are in short supply and expensiveStill run the risk of mismanagement or something critical being overlooked. While this isn’t entirely removed by Serverless architectures, it is significantly reduced.Because Serverless architectures do not rely on managing your own infrastructure, these problems just do not exist. Does your dev team need to deploy new features that use specialised AWS services? They can go ahead and do so with no need to wait for it all to be setup and configured.Increased development agilityServerless development combines the use of fully managed infrastructure from your cloud provider with some code to glue the interactions with these services together. This means that, instead of your engineering team having to wait around for the dev ops team to provision the right VM's and containerto use, they can just deploy their solutions as soon as they are ready. And because there is no need to concern yourself with load balancing, patches, upgrades and other maintenance tasks, you can just focus on moving forward and meeting and even exceeding your competitors.Lower costWe alluded to it before. Serverless architectures only bill for usage. The problem with any serverful architecture is that you need to have something up and running 24/7 that bills you per minute just in case, even if you aren’t serving any users at all. On top of that, since the need to manage infrastructure is reduced or entirely eliminated, there are also the reduced costs around needing to have the right team to manage things. Total Cost of Ownership is not just the bill from the cloud provider but also the people needed to run things!ConclusionIn general, Serverless architectures solve a lot of the issues related to building applications for the web and can provide the means to build solutions that are less time consuming to release, cost less, are scalable and require less maintenance over time.\n\n\n\n\n\nAre you interested in learning more about how Amazon S3 works with your Serverless applications? Curious about the benefits and the drawbacks of using Amazon S3 compared to all your other options? Then look no further—this article is for you.In this guide we go over what Amazon S3 is, discuss why it’s an important part of the Serverless ecosystem, and cover both the positive and negative aspects of using S3, to help you determine if it’s the right fit for your task at hand.You can also scroll to the end of this article for a list of resources and examples, should you want to learn even more about Amazon S3 and use it with the Serverless Framework.What is Amazon S3?‍Amazon S3 is a cloud storage service offered by Amazon Web Services (AWS). S3’s primary purpose is to store all kinds of files in the cloud, from media files to static web pages, and to make them available via simple requests, either from inside your application or directly out to your customers.How does Amazon S3 work?‍Amazon S3 is a managed service, which means all you have to do is upload and download the files you need. AWS takes care of storing your files, ensuring their availability, and delivering the files when you or your customers request them.You can upload a file to S3 by signing in to the AWS Console and accessing the S3 user interface, or by programmatically issuing a request to the S3 API, directly via HTTP or using one of the AWS SDKs.The S3 service is subdivided into individual storage “buckets”; each bucket can contain many “prefixes” (which work much like folders on your local disk), and the prefixes in turn contain your uploaded files. You can control access to the files at the bucket level as well as at the individual file level, and you can set up automated rules for managing the lifecycle of the files for entire buckets or specific prefixes within them.Once a file is uploaded to S3, it can be referenced using an S3 path that, as you might imagine, includes the bucket name and the path to the file within the bucket. If you’ve configured the bucket to be publicly accessible, the files in the bucket can be accessed directly using their S3 URL.What makes Amazon S3 an essential part of the Serverless ecosystem?‍Serverless applications generally use cloud storage services like Amazon S3 to store application data that doesn’t fit into a database. S3 therefore forms the functional basis for all Serverless solutions that handle large files like user-generated data, images, or video content.It’s also common to use cloud storage to host the static portions of Serverless systems: HTML pages, images used on Serverless websites, CSS files, and compiled JavaScript code. This reduces load times for Serverless websites, lowers operating costs, and keeps maintenance of Serverless applications to a minimum.How does Amazon S3 integrate with other AWS services?‍Amazon S3 provides notifications when a file is created or changed, and these notifications flow into other AWS services. One service that can act on these notifications is Amazon Lambda; this represents the most valuable integration for Serverless developers. Serverless functions can be made to trigger when files in S3 change, enabling all kinds of S3-based business logic. S3 notifications can also flow into Amazon SQS and SNS.Although technically part of S3 itself, Amazon S3 Glacier is a storage service in its own right, designed for long-term file storage at lower cost. S3 enjoys direct integration with Glacier and allows moving files between the two storage solutions based on a set of S3’s own rules.Several AWS services are able to read and write data directly from and to S3; for example, Amazon RDS can write and read database backups to and from S3. And AWS Athena is a data warehousing solution entirely based on data stored in S3.S3 also integrates with AWS IAM in order to manage access to specific files and buckets. One of the useful features of the integration is generating short-lived credentials for a specific S3 object. This proves particularly helpful in situations such as when you need to control access to files in S3 using your own user authentication.S3 also integrates with AWS CloudWatch and CloudTrail for monitoring and logging purposes.How does S3 work with the Serverless Framework?‍In the Serverless Framework, S3 is most often used as a source for events in Serverless functions. For example, a Serverless function can be triggered when an object in an S3 bucket is created or modified, with rules available to filter for the specific requests you want to call the functions.When using an S3 bucket as storage for customer-facing files, you can use the Serverless Framework to maintain the configuration of your S3 bucket in code. See the Custom S3 bucket configuration section of the Serverless Framework docs for examples on how to use this functionality.As we mentioned above, many Serverless applications also use S3 via the AWS SDK for JavaScript in order to store user data that doesn’t fit into a database, including media files and system state.Benefits of using Amazon S3‍Here are the main ways Amazon S3 can be helpful when developing Serverless applications.Scalability One of the core benefits of S3 is that it’s scalable and, at the same time, fully managed. You don’t need to worry about how the files are allocated. You can just focus on uploading, accessing, and managing the lifecycle of the files you care about, and S3 takes care of the actual storage mechanism. A single AWS account can have hundreds of S3 buckets, and each bucket can contain many terabytes or petabytes of files, while still providing low-latency access to every file.Ease of setup Amazon S3 requires very little setup in order to get started. You simply create a bucket, choose whether you want it to be publicly accessible or not, and you can start uploading files right away.Convenient integrations with other AWS services Amazon S3 has a number of integrations with other AWS services that make it easy to build out complex workflows with very little custom code. This includes the integrations we already discussed: AWS Lambda, Amazon RDS, Amazon Athena, and other services.Disadvantages‍Before you choose to use Amazon S3 in production, consider these drawbacks and some ways you might design around them.High cost at scale when not managed correctly The S3 pricing model is pay-per-use. While this works great for small amounts of files, the total cost scales progressively as you use S3 in production and accumulate files in various buckets. Over time, the cost of storage and network transfer out of S3 to the end users can rise precipitously.To work around this issue, you might consider putting lifecycle rules for your buckets in place early on, so that you only end up storing the data you care about—everything else is removed automatically.Complicated storage-class model S3 provides a number of storage classes for you to choose from, and while having multiple options for different use cases is useful, it can be hard to understand which storage class is the right fit for every task.Some storage classes also include a minimum storage duration. This means you could pay more if you decide to delete or move the files before a certain minimum amount of time, which creates both billing and logical complications when building Serverless systems.One workaround would be to use only a single storage class that you understand well, but this could end up limiting the value you get from S3. As we see it, your best bet is to spend some time deciding which storage classes are a good solution for your specific problems, and then try experimenting with some of them to observe their intricacies.Unlimited scalability creates challenges, too While unlimited storage is helpful when you have a rapidly growing system, it can also result in too few questions asked about what data developers are choosing to store and why. As a result, teams may make poor architectural decisions around storing data, not to mention that the cost of the S3 storage can quickly spiral out of control.To avoid issues with this aspect of S3, we recommend performing architectural reviews on any system that might end up storing large amounts of data in S3 and, of course, periodically checking on your S3 spending.Minimal default visibility into a bucket’s contents If you’re like most companies and are using S3 to store many sorts of application-essential files, at some point you’ll start to wonder, "What exactly are we storing here?" This question might come up when you realize you’re paying a lot for S3 each month, without knowing for sure what data you still need and what you should be discarding.While S3 provides the tools to understand what files are stored in a bucket, these tools rely on file tags you must supply yourself when the files are created or modified. To understand what you’re storing, you’ll generally have to set up a tagging structure that makes sense for your business.To avoid visibility issues in your file structure, we recommend creating a tagging convention early on and enforcing it across all your applications that write to S3.What is Amazon S3 good for?‍Here’s a short list of tasks for which Amazon S3 is generally a good fit.Storing static content and serving it directly to the end users Since S3 objects can be accessed directly via a URL, S3 is very good at serving large data objects directly to your users, with no need to proxy them through your applications. This includes images, static web pages, web assets like CSS files, and video content.Storing internal data: configuration, system state, intermediate states of business processes In Serverless systems where the applications themselves don’t preserve state, S3 can help you store state effectively (along with database services like RDS). This might be the output of various Lambda functions for cases where the output is mostly large files), intermediate states between different business processes, or a location that "bridges" your AWS systems and non-AWS systems.Storing logs and audit trails CloudTrail and CloudWatch can work with S3 as the output destination for the metrics generated by your infrastructure. You can store audit logs and audit trails in S3 and access and process them later. Note: S3 might not be a good fit for short-lived operational logs due to their very high volume of generated data.Amazon S3 regions‍Amazon S3 is available in the following AWS regions:US East (Ohio) — us-east-2US East (N. Virginia) — us-east-1US West (N. California) — us-west-1US West (Oregon) — us-west-2Asia Pacific (Hong Kong) — ap-east-1 Asia Pacific (Mumbai) — ap-south-1Asia Pacific (Osaka-Local) — ap-northeast-3Asia Pacific (Seoul) — ap-northeast-2Asia Pacific (Singapore) — ap-southeast-1Asia Pacific (Sydney) — ap-southeast-2Asia Pacific (Tokyo) — ap-northeast-1Canada (Central) — ca-central-1China (Beijing) — cn-north-1China (Ningxia) — cn-northwest-1EU (Frankfurt) — eu-central-1EU (Ireland) — eu-west-1EU (London) — eu-west-2EU (Paris) — eu-west-3EU (Stockholm) — eu-north-1South America (São Paulo) — sa-east-1Middle East (Bahrain) — me-south-1AWS GovCloud (US-East) — us-gov-east-1AWS GovCloud (US-West) — us-gov-west-1Keep in mind that the pricing of Amazon S3 can differ between regions, so some regions may be significantly more expensive to use than others. We cover this in more detail in the Pricing section below.Amazon S3 limits‍The key value propositions of S3 are essentially limitless scalability of storage and consistent performance at scale. As such, S3 doesn’t have any built-in or configurable limits on things like the number of files in a bucket, the number of prefixes in a bucket, or the total size of all files within the same bucket. The service does have a few limits, however, that can affect how you use S3:Once created, a bucket can’t be moved to a different region. Usually this is not a problem: if you need to move the files into a different region, you can create a new bucket and copy the files over. However, in doing so you’ll incur charges for the copy operations as well as data transfer charges between the regions.While S3 is built for high performance at scale, your buckets’ access patterns can negatively affect the performance of individual file operations if not structured correctly. Learn more about the recommended structure of an S3 bucket when optimizing for a high number of parallel operations in the Optimizing S3 Performance guide from the AWS documentation.If you are encrypting the files in your S3 buckets using AWS KMS, the encryption limits for AWS KMS apply. AWS KMS could become a bottleneck for your S3 storage or retrieval operations if you end up exceeding the AWS KMS limits.Amazon S3 pricing‍As part of the AWS free tier, in the first 12 months after you’ve created your AWS account you get 5GB of free storage, 20,000 free GET requests, and 2,000 PUT, COPY, POST or LIST requests per month. The free tier also includes 15GB of Data Transfer Out.Beyond the free tier, the pricing for S3 is as follows:‍


	HTML Table Generator 
	


	
		
			
				Aspect
				Pricing
				Comment
			
		
		
			
				 S3 Standard
				$0.023/GB
				Goes down to $0.021/GB with higher volumes of data stored.
			
			
				 S3 infrequent access
				$0.0125/GB
				Half standard price.
			
			
				 S3 one zone - infrequent access
				 $0.01/GB
				 This storage class is best used for data that can be recreated, due to reduced redundancy. However, it still offers fast access to the files stored.
			
			
				 PUT, COPY, POST, LIST requests
				 $0.005/1,000 requests
				 
			
			
				 GET, SELECT, and all other requests
				 $0.0004/1,000 requests
				 
			
		
	

The Amazon S3 Glacier product is technically a part of the S3 offering but has a different price structure:‍


	HTML Table Generator 
	


	
		
			
				Aspect
				Pricing
				Comment
			
		
		
			
				 S3 Glacier storage
				 $0.004/GB
				 Data retrieval for Glacier is priced separately.
			
			
				 S3 Glacier expedited retrieval
				 $0.03/GB
				 Typically 1-5 mins/request.
			
			
				 S3 Glacier standard retrieval
				 $0.01/GB
				 Typically 3-5 hours/request.
			
			
				 S3 Glacier bulk retrieval
				 $0.0025/GB
				 Optimized for large numbers of files or large volumes of data. Typically 5-12 hours/request.
			
			
				 S3 Glacier expedited retrieval requests - Expedited
				 $10/1,000 requests
				 This is charged in addition to the data volume.
			
			
				 S3 Glacier expedited retrieval requests
				 $0.05/1,000 requests
				 This is charged in addition to the data volume.
			
			
				 S3 Glacier bulk retrieval requests
				 $0.025/1,000 requests
				 This is charged in addition to the data volume.
			
			
				 S3 Glacier upload requests
				 $0.05/1,000 requests
				 The data transfer for the uploads is charged at the data transfer rates (see below).
			
		
	

‍In addition to charges based on quantity of files, requests, and data volume, with S3 you also pay for data transfer outbound from AWS. All incoming data transfers are free, but transfers between AWS services count as both data out and data in. The pricing is as follows:‍


	HTML Table Generator 
	


	
		
			
				Aspect
				Pricing
				Comment
			
		
		
			
				 Data transfer out
				 $0.09/GB
				Goes down to $0.05/GB at high volumes. This applies to data transfers outbound from AWS infrastructure into public networks.
			
			
				 Data transfer out: public internet
				 $0.09/GB
				Goes down to $0.05/GB at high volumes. This applies to data transfers outbound from AWS infrastructure into public networks.
			
			
				 Data transfer out: CloudFront
				 Free
				 Amazon CloudFront pricing applies in addition.
			
			
				 Data transfer out: other AWS services
				 Between $0.01/GB and $0.02/GB
				 The $0.01/GB rate applies for the transfers within the same region, and also between us-east-1 and us-east-2 regions. Otherwise, the $0.02/GB rate applies.
			
		
	

‍Pricing in different AWS regions The pricing of S3 can differ depending on the region(s) you use it in. The GovCloud regions, for example, can be almost twice as expensive as us-east-1. The California region is a bit more expensive compared to other US-based public regions (excluding GovCloud). Check the details of the pricing for each region on the S3 Pricing page by using the region drop-down menu.Sample pricing scenario Let’s imagine a hypothetical S3 bucket where your users upload 100,000 objects every day. Each object is on average 500KB in size. On average, each object is accessed just once after it’s been uploaded. You keep the objects for 60 days, and then delete them using an automated S3 lifecycle policy.In this case, after 60 days you will be paying the following amounts:Storage: 60 days’ worth of objects 100,000 objects/day 500KB/object * $0.023/GB/month = $65.80/monthPOST requests for file uploads: 100,000 objects/day 30 days $0.005/1,000 requests = $15.00/monthGET requests for file downloads: 100,000 objects/day 30 days $0.0004/1,000 requests = $1.2/monthData Transfer Out: 100,000 objects 30 days 500KB/object * $0.09/GB = $128.75/monthSo the total for this scenario would be $210.85/month, or $210.51/month if the AWS free tier still applied to your account.Amazon S3 alternatives‍While Amazon S3 is usually a good choice for storing static content and media files as well as access logs and metrics, it’s not necessarily the right solution for other use cases. Both Amazon and other cloud and infrastructure providers offer multiple types of file storage which might be better fits, depending on the task you have at hand.Amazon EBS Amazon EBS is the "virtual disk" that gets attached to your EC2 instances. S3 is a good storage medium for long-lived files, but it’s not a file system for a machine running in the cloud. When running Amazon EC2 machines, using Amazon EBS (or on-host storage) makes the most sense. The EC2 + EBS combination can also work quite well if you are using EC2 machines as caching solutions or other high-throughput storage for small files.Amazon CloudFront Amazon CloudFront is a CDN solution that can easily be "plugged in" to S3. CloudFront is generally used alongside S3 rather than replacing it wholesale. The main task CloudFront accomplishes is shortening the latency in accessing your static files (that may originate in an S3 bucket) in comparison to S3. CloudFront achieves this by placing your files closer to end users in locations around the world. CloudFront can be a better choice for storing files when access latency is critical, such as static website pages or frequently accessed media files.AWS Glacier S3 Glacier is an extension of S3 but also represents an alternative to using S3 for long-term file storage. It’s cheaper than S3, but it doesn’t offer immediate access to the files. While S3 focuses on millisecond-grade response times for all the files you store in all your buckets, retrieval of files from Glacier can take anywhere from a few minutes to a few hours and requires an asynchronous mechanism to notify you of the completed file retrievals. Compared to S3, Glacier is a more cost-effective option for long-term storage of files you don’t need very often.Backblaze B2 Backblaze B2 is a low-cost cloud storage provider. Their storage is priced competitively at $0.005/GB, one-quarter of S3's cost. Also, their network traffic will run you only $0.01/GB, which comes to (at most) one-fifth of S3’s network transfer cost. If you’re not already using AWS, and your primary need in the cloud is cloud storage, B2 can be an option to consider. However, if in fact you’re already using AWS for the rest of your infrastructure, using B2 means giving up the potential benefits of integrating your storage with other parts of your systems that run in AWS. For existing AWS users migrating to Backblaze, B2 is worth considering if you have a very high volume of data going in and out every month.Other major cloud providers’ storage offerings Google Cloud and Microsoft Azure also offer cloud storage solutions: Google Cloud Storage and Azure Blob Storage, respectively. These are priced at roughly the same level as S3 and generally match it in available functionality. From a cost and efficiency perspective, it makes sense to use the storage offering of your current cloud provider. If you are using multiple cloud providers, it’s worth comparing the features of each of their offerings and seeing which one fits your use case the best.On-premise SAN system Using cloud file storage is generally the fastest and the most cost-effective option if your infrastructure is running in the cloud. However, if your infrastructure is mostly in a physical datacenter, building out your own storage area network (SAN) is an option. Many vendors like EMC and NetApp offer various SAN solutions at different cost and performance levels.When to use Amazon S3 vs EC2?‍S3 is a storage service, while EC2 is primarily a compute service. In general, it’s best practice to use S3 (or S3 with CloudFront) to store files that are accessible to the users of your application; storing files on EC2 machines is best to satisfy the needs of your internal applications.You may also need to use EC2 in certain edge cases: for example, when you have complex file processing logic that isn’t compatible with how S3 works. In most cases, however, you can architect your application to take advantage of cloud storage and thereby reap the benefits of using S3.Amazon S3 FAQ‍Can S3 be used as a relational database? Technically yes, but it’s not very common to use it like this. S3 offers functionality known as S3 Select, which provides an SQL-like query interface for certain kinds of data stored in S3, and it works if your bucket contains CSV or JSON files. In truth it isn’t really a relational database—it’s just a more convenient way for you to retrieve subsets of data from S3 when you’re storing CSV or JSON in your buckets.If you’re looking for a true managed relational database solution, consider using Amazon RDS.What is Amazon S3 Transfer Acceleration? S3 Transfer Acceleration is a way for you to upload files into your S3 buckets faster. The Transfer Acceleration tool will upload your files first to the closest CloudFront location and will then send it to S3 from there. This costs extra on top of the data transfer charges, between $0.04/GB and $0.08/GB.Can S3 objects be encrypted? Yes. S3 supports per-object encryption options with per-bucket defaults. The objects are encrypted at rest and get decrypted when they are accessed. For your encryption you can use either S3-managed keys or your own keys, generated and managed using AWS KMS.Can I use S3 for backups? Yes. S3 is a solid option for backing up the contents of your databases and other data. S3 has native integration with Amazon RDS to allow backing up your databases continuously to S3 and restoring them from S3 as well.If you are backing up large volumes of data, consider setting up lifecycle rules on the backups and/or using Amazon S3 Glacier to reduce cost in the long run.Is S3 a CDN? No. With S3, the files are usually stored in a single location or at most a few locations and aren’t optimized for fast download speeds around the world. If you are looking for a CDN, consider using Amazon CloudFront.Can I use S3 for video content? Yes. You can store video files in S3 and either stream them directly or distribute them first to Amazon CloudFront, where your users would then stream the videos.Using S3 with Serverless Framework‍If you’d like to learn more about using Amazon S3 with the Serverless Framework, here are a few of our most helpful blog posts and examples that involve S3:Uploading objects to S3 using one-time, pre-signed URLsDeploy a REST API using Serverless, Django and Python — uses SQLite stored in S3Dynamic image resizing with Amazon S3, and Serverless FrameworkRubyPythonNode.jsExample - Single Page App with Cloudfront and Serverless FrameworkLogging to S3 buckets with Serverless and CloudTrailUsing AWS Rekognition with Amazon S3 and Serverless FrameworkServerless notification systemOther resources that can be useful for you to learn more about using S3 and Serverless Framework:Serverless Framework S3 event documentationServerless Framework AWS provider documentationAWS S3 documentation\n\n\n\n\n\nAre you considering using a content delivery network (CDN) solution like Amazon CloudFront with your Serverless applications or websites? Looking to learn more about the pros and cons of CloudFront and understand its alternatives? Well, you’re in the right place — this guide addresses exactly those considerations.In this guide, we’ll cover what Amazon CloudFront is, discuss why it’s an important part of the Serverless ecosystem, and walk you through the advantages and disadvantages of using CloudFront in your Serverless applications.The goal of this article is to help you decide whether CloudFront is the right tool to use for your specific situation. You can also skip to the end of this article for a list of resources and examples, should you want to learn even more about Amazon CloudFront and use it with the Serverless Framework.What is Amazon CloudFront?‍Amazon CloudFront is a content delivery network (CDN) provided by Amazon Web Services. By using a CDN, companies can accelerate delivery of files to users over the Internet while also reducing the load on their own infrastructure. CloudFront is AWS’s own CDN solution that integrates with other AWS products, so it’s convenient for companies already running on AWS.How does CloudFront work?‍CloudFront acts as a distributed cache for your files, with cache locations around the world. It fetches your files from their source location (“origin” in CloudFront terms) and places the copies of the files in different edge locations across the Americas, Europe, Asia, Africa, and Oceania. In so doing, CloudFront speeds up access to your files for your end users.Why is this worth doing? Imagine, for example, that your data origin is located in Brazil and one of your customers in Japan would like to access this data. Without CloudFront (or a similar solution) this customer would need to send a request to the other side of the world, transferring the files from a very distant location. This would result in a request that’s slow to arrive to the destination as well as a slow file download. Having your customers wait longer to get data often makes for a poor customer experience.With CloudFront, however, the files are periodically fetched by CloudFront system from the location in Brazil and placed onto a set of servers around the world, including one in Japan. When a user in Japan goes to download the files, the request will now be served by a nearby server with lower latency, a higher download speed, and a better customer experience.(Note: a distributed cache model is just one approach to building a CDN; we discuss other approaches in the CloudFront alternatives section in this article.)Why is CloudFront an essential part of the Serverless ecosystem?‍Under the Serverless model, many websites and applications rely on static files to do most of the work, with only parts of the content customized using Serverless APIs. The static portions include HTML web pages, CSS files, Javascript code, and media such as images and video files.Fast website load times are a requirement, regardless of where your user base is located. You can see this reflected in Google’s hinting that faster-loading websites appear higher in their search results.CloudFront allows Serverless applications to provide a fast and low-latency experience to end users by making sure that the static parts of their application load fast, irrespective of where its users are. CloudFront achieves this while also allowing developers to pay only for what they use and to scale their systems on demand. That’s what makes CloudFront an essential part of the Serverless ecosystem.How does CloudFront integrate with other AWS services?‍To speak of CloudFront being integrated with another AWS service chiefly refers to CloudFront’s ability to use that service as a data source for distribution. These integrations include:Amazon S3. It’s possible (and in fact very common) to use an Amazon S3 bucket as a source from which CloudFront will request files before placing them in its edge locations. This works both with standard S3 buckets and with buckets configured as website endpoints. When CloudFront is configured, the S3 bucket can continue to be used with no changes.Amazon EC2. CloudFront supports using an Amazon EC2 server or an Elastic Load Balancing endpoint as an origin for files in a CloudFront distribution. CloudFront’s support for custom HTTP/HTTPS origins is what enables this integration, meaning that it’s also possible to use a non-EC2 server as a file origin.AWS Lambda@Edge. Working essentially just like AWS Lambda, Lambda@Edge functions run at CloudFront edge locations. This means the code of Lambda@Edge functions runs closer to where your users are located, and as a result you can provide a faster, smoother experience to your website visitors or application users. The functions on Lambda@Edge can “intercept” the requests and the responses between CloudFront and the origin of the data, as well as between CloudFront and the end user.AWS Elemental MediaStore and MediaPackage. CloudFront supports AWS MediaStore and MediaPackage as origins for existing or live video content, which is then distributed to the end users using CloudFront endpoints.Amazon CloudWatch. Every CloudFront distribution emits Amazon CloudFront metrics for metrics such as total number of requests, error rates, and Lambda@Edge throttles and execution errors. These metrics are available with no additional configuration and don’t count against CloudWatch limits, making it a good starting point for monitoring your CloudFront usage.How does CloudFront work with the Serverless Framework?‍You can use Serverless Framework Resources to create and configure CloudFront distributions.In addition, the Serverless Framework allows you to create, deploy and manage Lambda@Edge functions that are based on events originating in CloudFront. See the Serverless Framework CloudFront event documentation for examples and more details.Benefits of using CloudFront‍Using CloudFront provides Serverless developers with a number of benefits, discussed below.Scalability CloudFront distributions scale automatically with the number of requests your files are getting and require no configuration changes to respond to increased load, making CloudFront a great choice for serving the static content of a website or a fast-growing application.Ease of setup Setting up a CloudFront distribution is quite easy when using S3 or even a custom HTTP/HTTPS endpoint as a file origin. Once set up, CloudFront requires no maintenance to continue working. Low maintenance means extra time for more productive tasks like building out the business logic of your application.Flexible configuration You can customize your CloudFront distributions to have different caching policies based on the kinds of files you’re serving. So, for example, if you have different kinds of content being served from the same domain and you want to apply different file expiration rules in the CloudFront cache to different sections of your website or application, you can do so on a very granular level.Disadvantages of using CloudFront‍Using CloudFront also comes with a few drawbacks that you need to be aware of before you decide to use it in production.High cost at scale CloudFront pricing is pay-per-use. This means you pay very little if the traffic to your Serverless site or application is low. However, as the traffic grows, the cost of using CloudFront can increase very rapidly.You can avoid surprises with CloudFront bills by establishing a process to regularly review your CloudFront usage and give your accounting teams a heads up if any significant increases in CloudFront traffic (and thus cost) are expected as you develop your application.We also recommend only using CloudFront for files where delivery time and speed is truly important, for example, the assets for your main website’s marketing pages. It’s likely that most of the files you distribute to your users can be shared directly from S3 or another file storage solution without much impact to the customer experience. Customer invoices, user-generated video content, and short-lived assets probably don’t need to be part of your CloudFront distributions.Lack of visibility into the underlying CloudFront structure When using a managed service, ease of use and configuration frequently trades off for the control you would normally have over the underlying infrastructure. CloudFront is a proprietary solution, and while Amazon provides a guide on optimizing CloudFront caching performance, you don’t get a lot of visibility into how exactly caching is performing in every region and for every request type. This can sometimes result in slower performance compared to a similar self-hosted solution that you can tweak for your exact use case.That being said, there are very few use cases that would truly warrant building your own CDN solution for performance reasons. For most teams, using a managed service like CloudFront will work just fine.CloudFront Locations‍CloudFront currently offers around 200 edge locations—which consist of content caches and supporting infrastructure—on five continents. You’ll find the highest density of edge locations in the United States, Western Europe, and East Asia.In addition, CloudFront offers 11 regional edge caches in AWS regions around the world, which act as caches for the caches; instead of having all 200 edge locations get the original files from your servers, the regional edge caches retain the most frequently accessed files and serve them to the edge location when it requests the updated version of a file.A full list of CloudFront locations, including edge locations and edge caches, is available on the CloudFront website’s features page.Amazon CloudFront Limits‍CloudFront core service limits are flexible: the default limits on total network throughput per distribution and number of requests per second can be increased by contacting AWS Support.When using a Lambda@Edge function with origin requests and responses, that is, when a function is executed coupled with a request to the origin, the limits are similar to the standard AWS Lambda limits.The only exception is the function timeout—by default 30 seconds for Lambda@Edge rather than 15 minutes—but this timeout can be increased on request. However, note that Lambda@Edge functions that run on viewer requests and responses will execute at a very high frequency—potentially every time a user requests a file from any edge location.The Lambda@Edge limits in this case are lower in order to preserve fast response times:Only up to 128MB function memory (instead of AWS Lambda’s usual 1GB limit).Five-second function timeout (instead of 15 minutes).40KB maximum response size (instead of 1MB).1MB maximum size of the compressed function code (instead of 50MB).In most cases, these limits won’t be an issue: Lambda@Edge is specifically designed for short, fast operations that run near to your users. For use cases requiring more compute power or longer function runtime, we recommend using garden-variety AWS Lambda rather than Lambda@Edge.Amazon CloudFront Pricing‍With the AWS free tier, during the 12 months after your account was created, AWS provides 50GB of free outbound data transfer and 2 million free HTTP/HTTPS requests to your CloudFront distributions per month. The free tier also includes 1,000 free invalidation requests per month. This is generally enough to experiment with using CloudFront but insufficient for production use.Beyond the free tier, CloudFront pricing runs as follows:‍



	


	
		
			
				Aspect
				Cost
				Comment
			
		
		
			
				 Data transfer out—end users
				 $0.09/GB
				 This is data transfer outbound to the public Internet (your end users). The pricing per additional GB goes down gradually as your usage increases. The $0.09/GB cost applies for the first 10TB of traffic, between 10TB and 50TB the cost is $0.085/GB, between 50TB and 150TB it’s $0.07/GB, and above 150TB it’s $0.05/GB.
			
			
				Data transfer out—origin servers 
				 Between free and $0.09/GB
				 Exact pricing here depends on the location of the origin servers. When CloudFront makes PUT or POST requests to fetch the data from your servers, the rate shown here is applied. With servers outside AWS, rates will be closer to the regular outbound data transfer rate, $0.09/GB. For files originating in Amazon S3 or EC2, this traffic is free.
			
			
				 HTTP/HTTPS requests
				 Between $0.0075 and $0.0220/10K requests
				 Exact pricing depends on the region you’re using and whether you’re accessing the files using HTTP or HTTPS.
			
			
				 Invalidation requests
				 $0.005/request
				 An invalidation request forces the early removal of a file or path from a CloudFront distribution before the configured time-to-live interval has expired.
			
		
	

‍For many use cases, Cloudfront’s outbound data transfer to end users is what’s going to cost the most. In some edge locations around the world, for example in South America and Australia, data transfer pricing can be significantly higher than in US regions. To help you control the costs, CloudFront offers three different price classes that can be set for each CloudFront distribution:‍



	


	
		
			
				Price class
				Regions included
			
		
		
			
				100
				Includes only standard-priced regions in the US, Canada, and Europe.
			
			
				200
				Includes all regions in class 100, plus South Africa, the Middle East, Japan, India, Singapore, South Korea, Taiwan, Hong Kong, and the Philippines.
			
			
				All
				Includes all regions in class 200, **plus South America and Australia.
			
		
	

‍CloudFront includes a free SSL certificate option if you use a CloudFront domain (i.e. <distribution-name>.cloudfront.net) or your own domain for your distribution. When using your own domain, the free option uses SNI Custom SSL technology which works properly with all modern browsers. However, SNI doesn’t work with some legacy browsers. If you’re looking to support SSL on a CloudFront custom domain for a large number of legacy users, AWS can provide a dedicated IP address for all your HTTPS CloudFront traffic, which will cost you an additional $600/month.Use of Lambda@Edge is priced as follows:



	


	
		
			
				Aspect
				Pricing
			
		
		
			
				Requests
				$0.60/1M requests
			
			
				Function run time
				$0.00005001/GB-second
			
		
	

Note: the function run time is measured as a combination of wall-clock time and the amount of memory configured for the function.Sample pricing scenario Let’s assume that you have 10,000 users for your application or website every day. On average, each user downloads from your CloudFront distributions 100 files per day over HTTPS, including static HTML and media files, and these 100 files constitute an average 20MB in total.To simplify the calculation, we’re going to assume that your files originate in S3, making the transfer to CloudFront free. We’ll also assume you don’t typically issue invalidation requests and will let the files expire automatically.To further simplify, we’ll assume that all your users are equally split between the US, Canada and Western Europe.In this situation, your monthly data transfer charges would be:30 days 10,000 users 20MB/day * $0.085/GB = $498.05/monthThe charges for requests would be:30 days 10,000 users 100 files/day ($0.01/10,000 requests 67% of users in the US and Canada + $0.012/10,000 requests * 33% of users in Europe) = $31.68/monthThe total amount you’d pay in this scenario would be $529.73/month.Amazon CloudFront Alternatives‍CloudFront is the only CDN service offered by AWS, but there are other services from Amazon and from other providers that you could use to achieve the same goal—giving your users fast access to your static files at scale.Amazon S3 Amazon S3 is a cloud file-storage solution from Amazon, and while it’s not a CDN like CloudFront, it can work well for the purpose of distributing files to your end users. With both CloudFront and S3 alike, the core of the cost is the data transfer from file storage to your end users. S3 can be cheaper, since you’ll only pay for data transfer from your region of origin, while with CloudFront you’ll be paying for data transfer in all regions where your users access the files. This can of course include regions where data transfer is very expensive, for example, South America or Australia.But using S3 will also likely be slower for your end users, unless they all happen to be located near the region where your S3 bucket is hosted.In short, using S3 directly (without CloudFront) can be a good option for cases where a small amount of extra latency is acceptable for your users.Google Cloud CDN Google Cloud CDN offers very similar functionality to that of CloudFront. The key difference is the pricing structure: Google Cloud CDN exposes more detail about the cache structure and charges for cache lookups, cache fill data transfer, and cache egress data transfer. The total cost of using Google Cloud CDN should be in the same range as CloudFront, as most of the cost still lies in the data transfer charges, and data transfer is priced similarly for both services. The extra visibility you get into the details of how Google Cloud CDN works through their pricing model can allow you to reduce the CDN’s cost and optimize its performance.CloudFlare CDN CloudFlare is a company that provides CDN and related solutions. The technical implementation of their CDN solution is different from that of CloudFront and Google Cloud CDN: CloudFlare is built as a reverse proxy. CloudFlare’s customers point the name servers for their domain(s) to CloudFlare, whose CDN service then becomes the primary endpoint for all HTTP or HTTPS requests each domain receives. CloudFlare retrieves any files it’s missing from the customer’s backend server.This method differs from CloudFront’s, in which you configure an explicit set of files to be available in a CloudFront distribution and let the CloudFront infrastructure periodically fetch the up-to-date versions of the content for you.CloudFlare CDN has a different pricing structure: rather than paying for the traffic out to the public internet, you pay a flat monthly fee plus a usage fee based on the number of DNS requests made to your site.When using CloudFlare, you have access to fewer configuration options than in CloudFront. But in more conventional use cases, such as caching a website, using CloudFlare can result in a site that’s equally fast while paying smaller CDN bills.When should I use Amazon CloudFront vs S3?‍We generally recommend using CloudFront only in cases where faster download speeds and lower latency for your files will result in a significant improvement in customer experience. This includes cases like hosting the homepage of your marketing website on CloudFront instead of S3.For all cases where latency and download speed are less crucial, we recommend using S3 directly to reduce the total operating cost of your system.Amazon CloudFront FAQ‍Is it possible to serve private content through CloudFront? Yes. CloudFront supports generating signed URLs for your content. You can generate these URLs for all private file downloads within your system. This requires integration with the CloudFront API and configuring the appropriate access policies. You would also need to make sure that the origin of your files (for example, S3 or your HTTP/HTTPS server) prevents direct file access, bypassing CloudFront.Does CloudFront offer access logging? Yes, it is possible to generate a log message every time a file is accessed worldwide. The log files can be written to Amazon S3.Is it possible to create redirect rules with CloudFront? CloudFront doesn’t support the explicit configuration of redirect rules. However, it will cache any response that the origin generates, including redirects. For example, if you are using your S3 bucket as a website endpoint. and if you have a redirect rule from an HTTP URL to an HTTPS URL in your bucket settings, this redirect will be cached by CloudFront. Accessing the HTTP URL on CloudFront will redirect the user to the HTTPS URL without hitting S3 directly.If you are using your own HTTP/HTTPS server as the file origin, you can configure appropriate redirect rules on the server and let CloudFront cache these rules.Using CloudFront with the Serverless Framework‍Check out the following resources for examples of using the Serverless Framework with Amazon CloudFront:Single page web app with Serverless Framework and CloudFrontGenerating S3 signed URLs using Lambda@Edge and Serverless FrameworkSetting up a custom domain name for AWS Lambda and Amazon API Gateway using CloudFront and Serverless FrameworkUsing the Serverless Next.js component with CloudFront and Lambda@EdgeOther resourcesUsing Lambda@Edge with the Serverless Framework - CloudFront event documentationServerless Framework - AWS provider documentationCloudFront documentation - AWSAWS Lambda - The Ultimate GuideAmazon S3 - The Ultimate Guide\n\n\n\n\n\nAre you considering using Amazon Simple Notification Service (SNS) in production? Looking to learn about the service’s pros and cons and how it compares to other solutions? Curious what the total day-to-day cost of using SNS might be?If you answered yes to any of those questions, this article is for you. In addition to the topics mentioned above, we’ll provide helpful information such as what Amazon SNS actually is and how it works, why SNS is important for the Serverless ecosystem, and what the alternatives are to using SNS in your applications.Scroll to the bottom of the article to find a few examples of using SNS with Serverless Framework and pointers to some documents to help you get started with SNS.What is Amazon SNS?Amazon SNS is a managed publish/subscribe (also known as “pub/sub”) service from Amazon Web Services. The fundamental idea of a publish/subscribe system is to allow communication between systems that are not directly connected by having one side publish messages to a shared location, called a "topic" in SNS, and having the other side subscribe to the messages from this location.SNS provides an HTTP API over which messages can be published to an SNS topic. Among the subscriber types SNS supports are AWS Lambda functions, SQS queues, HTTP(S) endpoints using webhooks, email, and SMS.SNS is most useful for sending notifications of various events that happen in your AWS-hosted applications and for distributing information between different services in a microservice-oriented infrastructure.The main difference between Amazon SNS and Amazon SQS is that SNS implements a "push" architecture—all subscribers receive the messages that are published to a topic, while SQS implements a "pull" architecture, in which clients pull messages from a shared queue.How does SNS work?‍Every SNS topic has a set of subscriptions. Once a message is published to a topic, SNS handles distributing the message to all its subscribers. The subscribers can be AWS Lambda functions and SQS queues, mobile push notifications (including iOS, macOS, Android, and Windows devices), HTTP(S) endpoints, email addresses and mobile phone numbers capable of receiving SMS messages.To publish a message to an SNS topic, a message producer must use the SNS HTTP API. Once the message is published, all subscribers receive a copy of the message over the channel through which they established their subscription.Each subscriber can receive messages from multiple topics and apply filters to topics in order to receive only the most relevant messages. If a message can’t be delivered to a subscriber right away, SNS will retry its delivery a number of times with varying intervals between attempts. SNS runs in multiple availability zones in AWS, guaranteeing that all messages are sent and received correctly even if one of AWS’ datacenters is experiencing downtime.Why is SNS an essential part of the Serverless ecosystem?‍The pub/sub model that SNS implements is useful for creating system and application alerts, sending email, SMS and push notifications, and for fanning information out from one system to multiple other systems, all using a fully managed service that requires no maintenance.This functionality is essential in Serverless applications for both user-facing and internal notifications and automations, and therefore for building scalable and reliable Serverless systems.How does SNS integrate with other AWS services?‍Both AWS Lambda functions and Amazon SQS queues can subscribe directly to SNS topics with no need for any additional code.Associating a Lambda function with an SNS topic causes the function to run for each message published to the topic.If an SQS queue subscribes to an SNS topic, the contents of each SNS message is added to the SQS queue. This is useful for sending messages from one source into multiple queues: for example, if you’d like to send a notification about a shipped order both to your fulfilment queue and your analytics queue.Other integrations for SNS include Amazon X-Ray and Amazon CloudWatch, both of which are useful for obtaining insights into your SNS usage and debugging potential issues.How does SNS work with the Serverless Framework?‍SNS works with Serverless in three ways. First, you can configure an SNS event in your Serverless function. This uses the integration between AWS Lambda and SNS and runs your Serverless function for each message (or group of messages) that is sent to the SNS topic.Second, you can use the Resources construct to manage the details of your SNS topics as well as the permissions of all users and applications accessing SNS in code.Finally, the Serverless Framework Notifications provides a native SNS integration that sends SNS notifications for all alerts generated within your Serverless applications.Benefits of using SNS‍These are the main benefits of using SNS in Serverless applications.Scalability. SNS topics scale up to any number of publishers, subscribers and messages without your needing to do any infrastructure work. This is helpful for growing applications where the teams would rather not have to provision additional infrastructure as their usage of pub/sub model increases over time.Ease of setup. SNS is a fully managed service; setting it up requires zero infrastructure work. Initial ramp-up is also easy as SNS provides an HTTP API that conforms to API standards. With plenty of subscriber types supported out of the box, topic subscribers are unlikely to require any further setup either. SNS’s ease of setup means you will have a faster path to a proof-of-concept application or to a fully implemented solution.Multiple notification formats supported. SNS supports AWS Lambda and AWS SQS notifications as well as mobile push notifications, HTTP(S) endpoints, email addresses, and SMS messages. These formats cover many common use cases, so you won’t have to write custom code to implement a subscriber for your SNS topic.Integration with AWS Lambda. The native integration with AWS Lambda allows you to run a Lambda function every time a message is published to an SNS topic. This allows for many useful workflows that process data from SNS messages, such as reacting to notifications from other systems or preparing the data for storage in S3 or Redshift.Drawbacks of using SNS‍Using SNS does have the following limitations that you should be aware of before choosing to use SNS in production:High cost at scale. When using SNS, you pay for exactly what you use. This can be both positive and negative. The upside is that there are no monthly charges—if you use SNS for just one day of the month, you pay only for that one day. On the downside, however, with a high number of topics, subscribers, and messages the costs of SNS can eventually rise quite high, and operating your own infrastructure for SNS-like load may be more cost-effective in such cases.Not much control over performance. SNS is a fully managed service; as a result, you don’t get to look under the hood. This can be a problem if SNS is a part of your customer-facing response path or if you have certain SLAs to meet. While for many use cases SNS performance is plenty good enough, at a certain stage you will likely be able to get better and more predictable performance from a pub/sub system that you manage yourself and tweak to your needs compared to what SNS can offer at scale.What is SNS used for?‍Here are a few of the common SNS use cases for Serverless applications.Sending events to mobile clients via p**ush notifications** Mobile push notifications can be useful for sending secure, time-sensitive updates to your users. Push notifications usually rely on a service that maintains a connection between each mobile device subscribed to the notifications and sends any incoming app notifications to the end users. While Amazon doesn’t run a service that actually sends the app notifications for you, it does allow you to plug into SNS the following push notification services:Amazon Device Messaging (ADM) for Amazon devicesApple Push Notification Service (APNs) for both iOS/iPadOS/tvOS/watchOS and macOS devicesBaidu Cloud Push (Baidu): multi-platformFirebase Cloud Messaging (FCM): Android, iOS, web, and desktopMicrosoft Push Notification Service for Windows Phone (MPNS)Windows Push Notification Services (WNS): Universal Windows Platform applicationsIf you are using any of these services, you can assign them in SNS as a subscriber to a topic.Sending events between system elements that don’t require exactly-once processing While Amazon SQS, a related AWS service, is a good fit for distributing work in units that need to be performed exactly once, SNS is a better option for distributing the information across systems where exactly-once delivery isn’t as important.One-to-many notifications In using different queueing systems, you might find that you need to send a message into multiple read-once queues. For example, if you run an e-commerce store, you might have each order trigger notifications to both the order tracking system and the analytics system by using Amazon SNS. Imagine also that, for each of those downstream systems, you want to ensure that the work isn’t performed multiple times—for example, that the same order isn’t counted twice on two separate analytics servers.A common solution for such cases is to use SNS with two SQS queues as subscribers. SQS guarantees that each message is only processed once, and SNS allows you to send the same message to multiple clients. This type of solution results in data being propagated to all relevant systems, while also ensuring that the work in each downstream system is only performed once.Sending transactional email or SMS notifications Many companies need to keep their customers up to date on what’s happening with their accounts, orders, posts, and so on. A notification sent when an action is completed in the company’s system is frequently called a "transaction message". SNS is a good choice for sending this kind of message with its email, push, and SMS capabilities.When to use SNS vs. SQS?‍While SNS and SQS are related, they serve different purposes.SQS is a queuing system. The tasks it excels at are maintaining a queue of messages and ensuring that each message is successfully pulled from the queue exactly once. As a result, SQS requires polling for items—"pulling" data, where it’s the responsibility of the client to request the data it is ready to process.On the other end, SNS is a publish/subscribe system. The task for which it was designed is to send all the messages it receives to each of its many subscribers. SNS follows the "push" principle, where it’s system’s responsibility to make sure all subscribers are notified of the new message. No polling on the part of subscribers is required.In some cases you might want to use only one of these services, sometimes using SQS together with SNS can be a good option, as in the one-to-many use case.Amazon SNS limits‍SNS has a few limits that you should be aware of when designing a system that uses SNS in production.The delivery rate for email messages has an upper limit of 10 messages per second. If you’d like to send more emails than that, consider using a dedicated email service for that task—for example, Amazon SES in combination with a Lambda function.Both subscribe and unsubscribe transactions are limited to 100 transactions per second (per AWS account).The Publish API, the core API for publishing SNS messages, will be throttled at the following levels:30,000 calls/second in the us-east-1 region9,000 calls/second in the us-west-1 and eu-west-1 regions1,500 calls/second in the ap-southeast-1, ap-southeast-2, ap-northeast-1, eu-central-1, us-west-1 regions300 calls/second in other AWS regionsAPIs for creating/deleting topics, confirming subscriptions, and getting subscription attributes (among others) are limited to:3,000 calls/second in the us-east-1 region900 calls/second in the us-west-1 and eu-west-1 regions150 calls/second in the ap-southeast-1, ap-southeast-2, ap-northeast-1, eu-central-1, us-west-1 regions30 calls/second in other AWS regionsSee the AWS documentation on SNS service limits for more details.Amazon SNS pricing‍As part of the AWS free tier, SNS usage up to one million requests, 100 SMS messages, 1,000 emails, and 100,000 HTTP(S) calls is free for all AWS accounts. This applies even if your AWS account was created more than 12 months ago (some AWS services only offer a free tier for the first 12 months of a new account, but this is not the case for SNS).Beyond the free tier you are charged for the following aspects of using the service:‍


	


	
		
			
				Aspect
				Pricing
				Comment
			
		
		
			
				 Publish action
				 $0.50/1 million requests
				 Each 64KB of request payload count as one request. So a “publish” action with a 256KB payload will be charged as four requests.
			
			
				 Mobile push notifications
				 $0.50/1 million requests
				 
			
			
				 SMS messages sent
				 Pricing depends on the country
				 $0.00645/message in the US, up to $0.15407/message in Germany. See details in SNS SMS pricing.
			
			
				 Email notifications
				 $2.00 per 100,000
				 
			
			
				 HTTP(S) notifications
				 $0.60 per million
				 
			
			
				 Data transfer: public internet
				 $0.09/GB
				 Data transfer is tracked monthly. The cost goes down to $0.085 per each additional GB after 10TB of data transfer in a given month, $0.07/additional GB after 50TB, and $0.05/additional GB after 150TB/month.
			
			
				 SQS and Lambda calls
				 Free
				 These are charged at SQS and Lambda rates. See SQS and Lambda pricing for details.
			
		
	

‍Sample pricing scenario Imagine that you are running a production system with 100,000 daily active users. Each user results in 500 SNS messages sent using the Publish API per day, 5 push notifications, 3 emails and 1 HTTP notification on average. Let’s assume that each outgoing notification of each type is 8KB in size.For this use case your daily SNS charges will be approximately:Publish API: 100,000 users (500 messages/day / 4 messages/API call) $0.50/1 million requests = 12,5M requests $0.50/1M requests = $6.25/day Mobile push notifications: 100,000 users 5 push notification/user $0.50/1M notifications = 500,000 notifications $0.50/1M notifications = $0.25/day Emails: 100,000 users 3 emails/user $2.00/100,000 emails = 300,000 emails $2.00/100,000 emails = $6/day HTTPS notifications: 100,000 users 1 notification/user $0.60/1M notifications = $0.06/day Data transfer: (500,000 push notifications + 300,000 email notifications + 100,000 HTTPS notifications) 8KB/notification $0.09/GB = 7.2GB $0.09/GB = $0.65/dayThe total per day would be $13.21, and the monthly total would be $396.30.Amazon SNS alternatives‍In this section we cover alternatives to using SNS. These are services or software products that are better suited to a particular task than SNS or that have another advantage.Amazon Kinesis Data Streams Amazon Kinesis Data Streams is a managed AWS service that’s designed for high-volume near-real-time data intake. Kinesis Data Streams can be a good choice if you produce large amounts of data that must be processed in batches in near real-time. For example, you could use Kinesis Data Streams to collect all the events happening in your systems for analytics purposes and process them with Lambda functions.While Kinesis Data Streams can scale to hundreds of data sources and gigabytes of data processed per second, compared to SNS it is usually harder to use for simpler tasks like sending messages between different parts of your systems. Kinesis Data Streams requires using special libraries for both consumers and producers of streams, as opposed to the simple HTTP API in SNS and its many out-of-the-box supported subscriber types. Kinesis Data Streams also requires that you consider different aspects of performance by configuring the number of shards in each Kinesis stream.Amazon MQ Amazon MQ is a managed queue service from AWS which is based on Apache ActiveMQ. Amazon MQ’s design is closer to Amazon SQS than to SNS; it’s a good fit for applications that already use ActiveMQ and want to move to the cloud without changing any queue-related code.If you don’t use ActiveMQ, however, SQS and SNS would generally be a better fit as they both have simpler APIs which make them easier to work with, not to mention that they are more cost-effective with their pay-per-use pricing models, and they integrate better with other AWS services like AWS Lambda.Apache Kafka Apache Kafka is an open source stream processing system. Its main purpose, similar to AWS Kinesis, is to process large amounts of data in near-real time. It has the same advantages and disadvantages as Kinesis Data Streams when compared to SNS: on the one hand, it can process a very large number of messages; on the other, it requires much more configuration and maintenance and is harder to use for producers and consumers than SNS.Twilio Twilio is a communication API company that offers a simple API to send emails and SMS messages. While it doesn’t integrate with SNS or other AWS services, Twilio can be a good alternative if what you’re looking for is primarily transactional email and SMS notifications.Pusher Pusher is a managed real-time notifications service. It focuses on push notifications and WebSockets-based data streaming. The main focus of Pusher’s product is real-time in-app updates, for example, on the front end of your applications. Pusher offers convenient client-side libraries that make it easy to implement real-time features without writing backend code. While it’s possible to use SNS for the same purpose, SNS doesn’t offer WebSockets support and isn’t optimized to be used on the client side. So if you are looking to create real-time updates in the frontend of your application, Pusher might be a better choice.PubNub PubNub is a managed real-time pub/sub service. In addition to basic pub/sub functionality, PubNub offers features like channel groups (in which a subscriber can receive the updates to a group of channels) along with user online status tracking and archival storage and retrieval of past pub/sub updates.PubNub doesn’t support email or SMS notifications out of the box, and it also lacks integration with AWS services. It does, however, support mobile push notifications to multiple platforms.Many of PubNub’s differentiating features involve compliance, archiving, and tracking of past streams. If you are building an application that calls for the pub/sub model and also carries significant compliance requirements (for example, in the medical industry), PubNub might be a better choice than SNS.Amazon Pinpoint Amazon Pinpoint is a customer engagement solution from AWS. It can send email, SMS, push notifications, and voice messages. This service works well with other AWS services like S3 and AWS Lambda through its integration with AWS Kinesis.The purpose of this service is to simplify management of user engagement campaigns that employ email, SMS, and push notifications. Pinpoint provides a number of features for managing such campaigns. SNS, in contrast, is a more generic messaging service. If you are looking for a way to send user engagement-related messages, Pinpoint might be a better choice than SNS.Amazon SNS FAQ‍Can SNS trigger Amazon Lambda functions? Yes. Lambda functions can subscribe to SNS topics, and the Lambda function will be triggered when there are new messages in the SNS topic.Can SNS send emails? Yes, SNS supports email, SMS, push notifications, and passing messages to Amazon SQS. However, the throughput of email notifications sent through SNS is limited to 10 emails per second across your entire AWS account. If you’re looking to send higher frequency email notifications through SNS, consider using SNS with an AWS Lambda function, which in turn uses the email-specific AWS SES service to send emails at scale.Is Amazon SNS free? No, but it offers a free tier for the first one million processed messages. This free tier should be enough for you to experiment with the service. See the Pricing section for more details.Is Apache Kafka the same as SNS? No. These two solutions serve different use cases. SNS is used for communication between two systems or between an application and its end users. SNS focuses on short (a few KB) self-contained messages and operates at the granularity of one or a few messages (rather than streams of data) when it comes to sending messages to clients. It works with multiple channels like email and push notifications. SNS requires no setup and very little ongoing maintenance, but its throughput at scale is limited and can’t be tweaked or optimized.Kafka is a product that’s best used for streaming and processing large volumes of data. You have to use Kafka streaming libraries on both the sending and receiving ends, and of course you’ll need to manage your own Kafka cluster and scale it according to usage. In a Kafka stream, you can’t mark a specific message as read or received without also marking all the previous messages in the stream as read.SNS is generally a better choice if what you’re looking for is a low-maintenance, easy-to-use pub/sub system. If you have a use case that focuses on streaming data at very high volumes, then Kafka is likely a better fit.Using SNS with Serverless Framework‍If you’d like to learn more about using Amazon SNS with the Serverless framework, check out the following guides:Building a Serverless notifications system on AWSSimple data processing pipeline with Serverless, SNS and Node.jsYou can find more details about SNS in the following documentation pages:Amazon SNS events: Serverless documentationAmazon SNS developer guide: AWS documentation\n\n\n\n