Node.js
        
      
      
About this documentation
Usage and example



Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Modules: TypeScript
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
Readline
REPL
Report
Single executable applications
SQLite
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker

    

    
      
        
          Node.js v24.0.1 documentation
          
            
            
          
        
        
          
            Node.js v24.0.1
            
    
      
        
        Table of contents
      

      
VM (executing JavaScript)

Class: vm.Script

new vm.Script(code[, options])
script.cachedDataRejected
script.createCachedData()
script.runInContext(contextifiedObject[, options])
script.runInNewContext([contextObject[, options]])
script.runInThisContext([options])
script.sourceMapURL


Class: vm.Module

module.dependencySpecifiers
module.error
module.evaluate([options])
module.identifier
module.link(linker)
module.namespace
module.status


Class: vm.SourceTextModule

new vm.SourceTextModule(code[, options])
sourceTextModule.createCachedData()


Class: vm.SyntheticModule

new vm.SyntheticModule(exportNames, evaluateCallback[, options])
syntheticModule.setExport(name, value)


vm.compileFunction(code[, params[, options]])
vm.constants

vm.constants.USE_MAIN_CONTEXT_DEFAULT_LOADER


vm.createContext([contextObject[, options]])
vm.isContext(object)
vm.measureMemory([options])
vm.runInContext(code, contextifiedObject[, options])
vm.runInNewContext(code[, contextObject[, options]])
vm.runInThisContext(code[, options])
Example: Running an HTTP server within a VM
What does it mean to "contextify" an object?

vm.constants.DONT_CONTEXTIFY


Timeout interactions with asynchronous tasks and Promises
Support of dynamic import() in compilation APIs

When the importModuleDynamically option is not specified or undefined
When importModuleDynamically is vm.constants.USE_MAIN_CONTEXT_DEFAULT_LOADER
When importModuleDynamically is a function





    
  
            
    
      
        
        Index
      

      
About this documentation
Usage and example

      
        Index
      
    
  


Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Modules: TypeScript
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
Readline
REPL
Report
Single executable applications
SQLite
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker

    
  
            
    
      
        
        Other versions
      
      24.x
23.x
22.x LTS
21.x
20.x LTS
19.x
18.x
17.x
16.x
15.x
14.x
13.x
12.x
11.x
10.x
9.x
8.x
7.x
6.x
5.x
4.x
0.12.x
0.10.x
    
  
            
              
                
                Options
              
        
              
                
                  
                    View on single page
                  
                  
                    View as JSON
                  
                  Edit on GitHub    
                
              
            
          
        
        
      

      Table of contents
VM (executing JavaScript)

Class: vm.Script

new vm.Script(code[, options])
script.cachedDataRejected
script.createCachedData()
script.runInContext(contextifiedObject[, options])
script.runInNewContext([contextObject[, options]])
script.runInThisContext([options])
script.sourceMapURL


Class: vm.Module

module.dependencySpecifiers
module.error
module.evaluate([options])
module.identifier
module.link(linker)
module.namespace
module.status


Class: vm.SourceTextModule

new vm.SourceTextModule(code[, options])
sourceTextModule.createCachedData()


Class: vm.SyntheticModule

new vm.SyntheticModule(exportNames, evaluateCallback[, options])
syntheticModule.setExport(name, value)


vm.compileFunction(code[, params[, options]])
vm.constants

vm.constants.USE_MAIN_CONTEXT_DEFAULT_LOADER


vm.createContext([contextObject[, options]])
vm.isContext(object)
vm.measureMemory([options])
vm.runInContext(code, contextifiedObject[, options])
vm.runInNewContext(code[, contextObject[, options]])
vm.runInThisContext(code[, options])
Example: Running an HTTP server within a VM
What does it mean to "contextify" an object?

vm.constants.DONT_CONTEXTIFY


Timeout interactions with asynchronous tasks and Promises
Support of dynamic import() in compilation APIs

When the importModuleDynamically option is not specified or undefined
When importModuleDynamically is vm.constants.USE_MAIN_CONTEXT_DEFAULT_LOADER
When importModuleDynamically is a function






      
        VM (executing JavaScript)#

Stability: 2 - Stable

Source Code: lib/vm.js
The node:vm module enables compiling and running code within V8 Virtual
Machine contexts.
The node:vm module is not a security
mechanism. Do not use it to run untrusted code.
JavaScript code can be compiled and run immediately or
compiled, saved, and run later.
A common use case is to run the code in a different V8 Context. This means
invoked code has a different global object than the invoking code.
One can provide the context by contextifying an
object. The invoked code treats any property in the context like a
global variable. Any changes to global variables caused by the invoked
code are reflected in the context object.
const vm = require('node:vm');

const x = 1;

const context = { x: 2 };
vm.createContext(context); // Contextify the object.

const code = 'x += 40; var y = 17;';
// `x` and `y` are global variables in the context.
// Initially, x has the value 2 because that is the value of context.x.
vm.runInContext(code, context);

console.log(context.x); // 42
console.log(context.y); // 17

console.log(x); // 1; y is not defined. copy
Class: vm.Script#

Added in: v0.3.1

Instances of the vm.Script class contain precompiled scripts that can be
executed in specific contexts.

new vm.Script(code[, options])#

History

VersionChanges
v21.7.0, v20.12.0
Added support for vm.constants.USE_MAIN_CONTEXT_DEFAULT_LOADER.
v17.0.0, v16.12.0
Added support for import attributes to the importModuleDynamically parameter.
v10.6.0
The produceCachedData is deprecated in favour of script.createCachedData().
v5.7.0
The cachedData and produceCachedData options are supported now.
v0.3.1
Added in: v0.3.1




code <string> The JavaScript code to compile.
options <Object> | <string>

filename <string> Specifies the filename used in stack traces produced
by this script. Default: 'evalmachine.<anonymous>'.
lineOffset <number> Specifies the line number offset that is displayed
in stack traces produced by this script. Default: 0.
columnOffset <number> Specifies the first-line column number offset that
is displayed in stack traces produced by this script. Default: 0.
cachedData <Buffer> | <TypedArray> | <DataView> Provides an optional Buffer or
TypedArray, or DataView with V8's code cache data for the supplied
source. When supplied, the cachedDataRejected value will be set to
either true or false depending on acceptance of the data by V8.
produceCachedData <boolean> When true and no cachedData is present, V8
will attempt to produce code cache data for code. Upon success, a
Buffer with V8's code cache data will be produced and stored in the
cachedData property of the returned vm.Script instance.
The cachedDataProduced value will be set to either true or false
depending on whether code cache data is produced successfully.
This option is deprecated in favor of script.createCachedData().
Default: false.
importModuleDynamically
<Function> | <vm.constants.USE_MAIN_CONTEXT_DEFAULT_LOADER>
Used to specify how the modules should be loaded during the evaluation
of this script when import() is called. This option is part of the
experimental modules API. We do not recommend using it in a production
environment. For detailed information, see
Support of dynamic import() in compilation APIs.



If options is a string, then it specifies the filename.
Creating a new vm.Script object compiles code but does not run it. The
compiled vm.Script can be run later multiple times. The code is not bound to
any global object; rather, it is bound before each run, just for that run.

script.cachedDataRejected#

Added in: v5.7.0


<boolean> | <undefined>

When cachedData is supplied to create the vm.Script, this value will be set
to either true or false depending on acceptance of the data by V8.
Otherwise the value is undefined.

script.createCachedData()#

Added in: v10.6.0


Returns: <Buffer>

Creates a code cache that can be used with the Script constructor's
cachedData option. Returns a Buffer. This method may be called at any
time and any number of times.
The code cache of the Script doesn't contain any JavaScript observable
states. The code cache is safe to be saved along side the script source and
used to construct new Script instances multiple times.
Functions in the Script source can be marked as lazily compiled and they are
not compiled at construction of the Script. These functions are going to be
compiled when they are invoked the first time. The code cache serializes the
metadata that V8 currently knows about the Script that it can use to speed up
future compilations.
const script = new vm.Script(`
function add(a, b) {
  return a + b;
}

const x = add(1, 2);
`);

const cacheWithoutAdd = script.createCachedData();
// In `cacheWithoutAdd` the function `add()` is marked for full compilation
// upon invocation.

script.runInThisContext();

const cacheWithAdd = script.createCachedData();
// `cacheWithAdd` contains fully compiled function `add()`. copy

script.runInContext(contextifiedObject[, options])#

History

VersionChanges
v6.3.0
The breakOnSigint option is supported now.
v0.3.1
Added in: v0.3.1




contextifiedObject <Object> A contextified object as returned by the
vm.createContext() method.
options <Object>

displayErrors <boolean> When true, if an Error occurs
while compiling the code, the line of code causing the error is attached
to the stack trace. Default: true.
timeout <integer> Specifies the number of milliseconds to execute code
before terminating execution. If execution is terminated, an Error
will be thrown. This value must be a strictly positive integer.
breakOnSigint <boolean> If true, receiving SIGINT
(Ctrl+C) will terminate execution and throw an
Error. Existing handlers for the event that have been attached via
process.on('SIGINT') are disabled during script execution, but continue to
work after that. Default: false.


Returns: <any> the result of the very last statement executed in the script.

Runs the compiled code contained by the vm.Script object within the given
contextifiedObject and returns the result. Running code does not have access
to local scope.
The following example compiles code that increments a global variable, sets
the value of another global variable, then execute the code multiple times.
The globals are contained in the context object.
const vm = require('node:vm');

const context = {
  animal: 'cat',
  count: 2,
};

const script = new vm.Script('count += 1; name = "kitty";');

vm.createContext(context);
for (let i = 0; i < 10; ++i) {
  script.runInContext(context);
}

console.log(context);
// Prints: { animal: 'cat', count: 12, name: 'kitty' } copy
Using the timeout or breakOnSigint options will result in new event loops
and corresponding threads being started, which have a non-zero performance
overhead.

script.runInNewContext([contextObject[, options]])#

History

VersionChanges
v22.8.0, v20.18.0
The contextObject argument now accepts vm.constants.DONT_CONTEXTIFY.
v14.6.0
The microtaskMode option is supported now.
v10.0.0
The contextCodeGeneration option is supported now.
v6.3.0
The breakOnSigint option is supported now.
v0.3.1
Added in: v0.3.1




contextObject <Object> | <vm.constants.DONT_CONTEXTIFY> | <undefined>
Either vm.constants.DONT_CONTEXTIFY or an object that will be contextified.
If undefined, an empty contextified object will be created for backwards compatibility.
options <Object>

displayErrors <boolean> When true, if an Error occurs
while compiling the code, the line of code causing the error is attached
to the stack trace. Default: true.
timeout <integer> Specifies the number of milliseconds to execute code
before terminating execution. If execution is terminated, an Error
will be thrown. This value must be a strictly positive integer.
breakOnSigint <boolean> If true, receiving SIGINT
(Ctrl+C) will terminate execution and throw an
Error. Existing handlers for the event that have been attached via
process.on('SIGINT') are disabled during script execution, but continue to
work after that. Default: false.
contextName <string> Human-readable name of the newly created context.
Default: 'VM Context i', where i is an ascending numerical index of
the created context.
contextOrigin <string> Origin corresponding to the newly
created context for display purposes. The origin should be formatted like a
URL, but with only the scheme, host, and port (if necessary), like the
value of the url.origin property of a URL object. Most notably,
this string should omit the trailing slash, as that denotes a path.
Default: ''.
contextCodeGeneration <Object>

strings <boolean> If set to false any calls to eval or function
constructors (Function, GeneratorFunction, etc) will throw an
EvalError. Default: true.
wasm <boolean> If set to false any attempt to compile a WebAssembly
module will throw a WebAssembly.CompileError. Default: true.


microtaskMode <string> If set to afterEvaluate, microtasks (tasks
scheduled through Promises and async functions) will be run immediately
after the script has run. They are included in the timeout and
breakOnSigint scopes in that case.


Returns: <any> the result of the very last statement executed in the script.

This method is a shortcut to script.runInContext(vm.createContext(options), options).
It does several things at once:

Creates a new context.
If contextObject is an object, contextifies it with the new context.
If  contextObject is undefined, creates a new object and contextifies it.
If contextObject is vm.constants.DONT_CONTEXTIFY, don't contextify anything.
Runs the compiled code contained by the vm.Script object within the created context. The code
does not have access to the scope in which this method is called.
Returns the result.

The following example compiles code that sets a global variable, then executes
the code multiple times in different contexts. The globals are set on and
contained within each individual context.
const vm = require('node:vm');

const script = new vm.Script('globalVar = "set"');

const contexts = [{}, {}, {}];
contexts.forEach((context) => {
  script.runInNewContext(context);
});

console.log(contexts);
// Prints: [{ globalVar: 'set' }, { globalVar: 'set' }, { globalVar: 'set' }]

// This would throw if the context is created from a contextified object.
// vm.constants.DONT_CONTEXTIFY allows creating contexts with ordinary
// global objects that can be frozen.
const freezeScript = new vm.Script('Object.freeze(globalThis); globalThis;');
const frozenContext = freezeScript.runInNewContext(vm.constants.DONT_CONTEXTIFY); copy

script.runInThisContext([options])#

History

VersionChanges
v6.3.0
The breakOnSigint option is supported now.
v0.3.1
Added in: v0.3.1




options <Object>

displayErrors <boolean> When true, if an Error occurs
while compiling the code, the line of code causing the error is attached
to the stack trace. Default: true.
timeout <integer> Specifies the number of milliseconds to execute code
before terminating execution. If execution is terminated, an Error
will be thrown. This value must be a strictly positive integer.
breakOnSigint <boolean> If true, receiving SIGINT
(Ctrl+C) will terminate execution and throw an
Error. Existing handlers for the event that have been attached via
process.on('SIGINT') are disabled during script execution, but continue to
work after that. Default: false.


Returns: <any> the result of the very last statement executed in the script.

Runs the compiled code contained by the vm.Script within the context of the
current global object. Running code does not have access to local scope, but
does have access to the current global object.
The following example compiles code that increments a global variable then
executes that code multiple times:
const vm = require('node:vm');

global.globalVar = 0;

const script = new vm.Script('globalVar += 1', { filename: 'myfile.vm' });

for (let i = 0; i < 1000; ++i) {
  script.runInThisContext();
}

console.log(globalVar);

// 1000 copy

script.sourceMapURL#

Added in: v19.1.0, v18.13.0


<string> | <undefined>

When the script is compiled from a source that contains a source map magic
comment, this property will be set to the URL of the source map.

import vm from 'node:vm';

const script = new vm.Script(`
function myFunc() {}
//# sourceMappingURL=sourcemap.json
`);

console.log(script.sourceMapURL);
// Prints: sourcemap.jsonconst vm = require('node:vm');

const script = new vm.Script(`
function myFunc() {}
//# sourceMappingURL=sourcemap.json
`);

console.log(script.sourceMapURL);
// Prints: sourcemap.jsoncopy

Class: vm.Module#

Added in: v13.0.0, v12.16.0

Stability: 1 - Experimental
This feature is only available with the --experimental-vm-modules command
flag enabled.
The vm.Module class provides a low-level interface for using
ECMAScript modules in VM contexts. It is the counterpart of the vm.Script
class that closely mirrors Module Records as defined in the ECMAScript
specification.
Unlike vm.Script however, every vm.Module object is bound to a context from
its creation. Operations on vm.Module objects are intrinsically asynchronous,
in contrast with the synchronous nature of vm.Script objects. The use of
'async' functions can help with manipulating vm.Module objects.
Using a vm.Module object requires three distinct steps: creation/parsing,
linking, and evaluation. These three steps are illustrated in the following
example.
This implementation lies at a lower level than the ECMAScript Module
loader. There is also no way to interact with the Loader yet, though
support is planned.

import vm from 'node:vm';

const contextifiedObject = vm.createContext({
  secret: 42,
  print: console.log,
});

// Step 1
//
// Create a Module by constructing a new `vm.SourceTextModule` object. This
// parses the provided source text, throwing a `SyntaxError` if anything goes
// wrong. By default, a Module is created in the top context. But here, we
// specify `contextifiedObject` as the context this Module belongs to.
//
// Here, we attempt to obtain the default export from the module "foo", and
// put it into local binding "secret".

const bar = new vm.SourceTextModule(`
  import s from 'foo';
  s;
  print(s);
`, { context: contextifiedObject });

// Step 2
//
// "Link" the imported dependencies of this Module to it.
//
// The provided linking callback (the "linker") accepts two arguments: the
// parent module (`bar` in this case) and the string that is the specifier of
// the imported module. The callback is expected to return a Module that
// corresponds to the provided specifier, with certain requirements documented
// in `module.link()`.
//
// If linking has not started for the returned Module, the same linker
// callback will be called on the returned Module.
//
// Even top-level Modules without dependencies must be explicitly linked. The
// callback provided would never be called, however.
//
// The link() method returns a Promise that will be resolved when all the
// Promises returned by the linker resolve.
//
// Note: This is a contrived example in that the linker function creates a new
// "foo" module every time it is called. In a full-fledged module system, a
// cache would probably be used to avoid duplicated modules.

async function linker(specifier, referencingModule) {
  if (specifier === 'foo') {
    return new vm.SourceTextModule(`
      // The "secret" variable refers to the global variable we added to
      // "contextifiedObject" when creating the context.
      export default secret;
    `, { context: referencingModule.context });

    // Using `contextifiedObject` instead of `referencingModule.context`
    // here would work as well.
  }
  throw new Error(`Unable to resolve dependency: ${specifier}`);
}
await bar.link(linker);

// Step 3
//
// Evaluate the Module. The evaluate() method returns a promise which will
// resolve after the module has finished evaluating.

// Prints 42.
await bar.evaluate();const vm = require('node:vm');

const contextifiedObject = vm.createContext({
  secret: 42,
  print: console.log,
});

(async () => {
  // Step 1
  //
  // Create a Module by constructing a new `vm.SourceTextModule` object. This
  // parses the provided source text, throwing a `SyntaxError` if anything goes
  // wrong. By default, a Module is created in the top context. But here, we
  // specify `contextifiedObject` as the context this Module belongs to.
  //
  // Here, we attempt to obtain the default export from the module "foo", and
  // put it into local binding "secret".

  const bar = new vm.SourceTextModule(`
    import s from 'foo';
    s;
    print(s);
  `, { context: contextifiedObject });

  // Step 2
  //
  // "Link" the imported dependencies of this Module to it.
  //
  // The provided linking callback (the "linker") accepts two arguments: the
  // parent module (`bar` in this case) and the string that is the specifier of
  // the imported module. The callback is expected to return a Module that
  // corresponds to the provided specifier, with certain requirements documented
  // in `module.link()`.
  //
  // If linking has not started for the returned Module, the same linker
  // callback will be called on the returned Module.
  //
  // Even top-level Modules without dependencies must be explicitly linked. The
  // callback provided would never be called, however.
  //
  // The link() method returns a Promise that will be resolved when all the
  // Promises returned by the linker resolve.
  //
  // Note: This is a contrived example in that the linker function creates a new
  // "foo" module every time it is called. In a full-fledged module system, a
  // cache would probably be used to avoid duplicated modules.

  async function linker(specifier, referencingModule) {
    if (specifier === 'foo') {
      return new vm.SourceTextModule(`
        // The "secret" variable refers to the global variable we added to
        // "contextifiedObject" when creating the context.
        export default secret;
      `, { context: referencingModule.context });

      // Using `contextifiedObject` instead of `referencingModule.context`
      // here would work as well.
    }
    throw new Error(`Unable to resolve dependency: ${specifier}`);
  }
  await bar.link(linker);

  // Step 3
  //
  // Evaluate the Module. The evaluate() method returns a promise which will
  // resolve after the module has finished evaluating.

  // Prints 42.
  await bar.evaluate();
})();copy

module.dependencySpecifiers#

<string[]>

The specifiers of all dependencies of this module. The returned array is frozen
to disallow any changes to it.
Corresponds to the [[RequestedModules]] field of Cyclic Module Records in
the ECMAScript specification.

module.error#

<any>

If the module.status is 'errored', this property contains the exception
thrown by the module during evaluation. If the status is anything else,
accessing this property will result in a thrown exception.
The value undefined cannot be used for cases where there is not a thrown
exception due to possible ambiguity with throw undefined;.
Corresponds to the [[EvaluationError]] field of Cyclic Module Records
in the ECMAScript specification.

module.evaluate([options])#

options <Object>

timeout <integer> Specifies the number of milliseconds to evaluate
before terminating execution. If execution is interrupted, an Error
will be thrown. This value must be a strictly positive integer.
breakOnSigint <boolean> If true, receiving SIGINT
(Ctrl+C) will terminate execution and throw an
Error. Existing handlers for the event that have been attached via
process.on('SIGINT') are disabled during script execution, but continue to
work after that. Default: false.


Returns: <Promise> Fulfills with undefined upon success.

Evaluate the module.
This must be called after the module has been linked; otherwise it will reject.
It could be called also when the module has already been evaluated, in which
case it will either do nothing if the initial evaluation ended in success
(module.status is 'evaluated') or it will re-throw the exception that the
initial evaluation resulted in (module.status is 'errored').
This method cannot be called while the module is being evaluated
(module.status is 'evaluating').
Corresponds to the Evaluate() concrete method field of Cyclic Module
Records in the ECMAScript specification.

module.identifier#

<string>

The identifier of the current module, as set in the constructor.

module.link(linker)#

History

VersionChanges
v21.1.0, v20.10.0, v18.19.0
The option extra.assert is renamed to extra.attributes. The former name is still provided for backward compatibility.




linker <Function>


specifier <string> The specifier of the requested module:
import foo from 'foo';
//              ^^^^^ the module specifier copy


referencingModule <vm.Module> The Module object link() is called on.


extra <Object>

attributes <Object> The data from the attribute:
import foo from 'foo' with { name: 'value' };
//                         ^^^^^^^^^^^^^^^^^ the attribute copy
Per ECMA-262, hosts are expected to trigger an error if an
unsupported attribute is present.
assert <Object> Alias for extra.attributes.



Returns: <vm.Module> | <Promise>



Returns: <Promise>

Link module dependencies. This method must be called before evaluation, and
can only be called once per module.
The function is expected to return a Module object or a Promise that
eventually resolves to a Module object. The returned Module must satisfy the
following two invariants:

It must belong to the same context as the parent Module.
Its status must not be 'errored'.

If the returned Module's status is 'unlinked', this method will be
recursively called on the returned Module with the same provided linker
function.
link() returns a Promise that will either get resolved when all linking
instances resolve to a valid Module, or rejected if the linker function either
throws an exception or returns an invalid Module.
The linker function roughly corresponds to the implementation-defined
HostResolveImportedModule abstract operation in the ECMAScript
specification, with a few key differences:

The linker function is allowed to be asynchronous while
HostResolveImportedModule is synchronous.

The actual HostResolveImportedModule implementation used during module
linking is one that returns the modules linked during linking. Since at
that point all modules would have been fully linked already, the
HostResolveImportedModule implementation is fully synchronous per
specification.
Corresponds to the Link() concrete method field of Cyclic Module
Records in the ECMAScript specification.

module.namespace#

<Object>

The namespace object of the module. This is only available after linking
(module.link()) has completed.
Corresponds to the GetModuleNamespace abstract operation in the ECMAScript
specification.

module.status#

<string>

The current status of the module. Will be one of:


'unlinked': module.link() has not yet been called.


'linking': module.link() has been called, but not all Promises returned
by the linker function have been resolved yet.


'linked': The module has been linked successfully, and all of its
dependencies are linked, but module.evaluate() has not yet been called.


'evaluating': The module is being evaluated through a module.evaluate() on
itself or a parent module.


'evaluated': The module has been successfully evaluated.


'errored': The module has been evaluated, but an exception was thrown.


Other than 'errored', this status string corresponds to the specification's
Cyclic Module Record's [[Status]] field. 'errored' corresponds to
'evaluated' in the specification, but with [[EvaluationError]] set to a
value that is not undefined.

Class: vm.SourceTextModule#

Added in: v9.6.0

Stability: 1 - Experimental
This feature is only available with the --experimental-vm-modules command
flag enabled.

Extends: <vm.Module>

The vm.SourceTextModule class provides the Source Text Module Record as
defined in the ECMAScript specification.

new vm.SourceTextModule(code[, options])#

History

VersionChanges
v17.0.0, v16.12.0
Added support for import attributes to the importModuleDynamically parameter.




code <string> JavaScript Module code to parse
options

identifier <string> String used in stack traces.
Default: 'vm:module(i)' where i is a context-specific ascending
index.
cachedData <Buffer> | <TypedArray> | <DataView> Provides an optional Buffer or
TypedArray, or DataView with V8's code cache data for the supplied
source. The code must be the same as the module from which this
cachedData was created.
context <Object> The contextified object as returned by the
vm.createContext() method, to compile and evaluate this Module in.
If no context is specified, the module is evaluated in the current
execution context.
lineOffset <integer> Specifies the line number offset that is displayed
in stack traces produced by this Module. Default: 0.
columnOffset <integer> Specifies the first-line column number offset that
is displayed in stack traces produced by this Module. Default: 0.
initializeImportMeta <Function> Called during evaluation of this Module
to initialize the import.meta.

meta <import.meta>
module <vm.SourceTextModule>


importModuleDynamically <Function> Used to specify the
how the modules should be loaded during the evaluation of this module
when import() is called. This option is part of the experimental
modules API. We do not recommend using it in a production environment.
For detailed information, see
Support of dynamic import() in compilation APIs.



Creates a new SourceTextModule instance.
Properties assigned to the import.meta object that are objects may
allow the module to access information outside the specified context. Use
vm.runInContext() to create objects in a specific context.

import vm from 'node:vm';

const contextifiedObject = vm.createContext({ secret: 42 });

const module = new vm.SourceTextModule(
  'Object.getPrototypeOf(import.meta.prop).secret = secret;',
  {
    initializeImportMeta(meta) {
      // Note: this object is created in the top context. As such,
      // Object.getPrototypeOf(import.meta.prop) points to the
      // Object.prototype in the top context rather than that in
      // the contextified object.
      meta.prop = {};
    },
  });
// Since module has no dependencies, the linker function will never be called.
await module.link(() => {});
await module.evaluate();

// Now, Object.prototype.secret will be equal to 42.
//
// To fix this problem, replace
//     meta.prop = {};
// above with
//     meta.prop = vm.runInContext('{}', contextifiedObject);const vm = require('node:vm');
const contextifiedObject = vm.createContext({ secret: 42 });
(async () => {
  const module = new vm.SourceTextModule(
    'Object.getPrototypeOf(import.meta.prop).secret = secret;',
    {
      initializeImportMeta(meta) {
        // Note: this object is created in the top context. As such,
        // Object.getPrototypeOf(import.meta.prop) points to the
        // Object.prototype in the top context rather than that in
        // the contextified object.
        meta.prop = {};
      },
    });
  // Since module has no dependencies, the linker function will never be called.
  await module.link(() => {});
  await module.evaluate();
  // Now, Object.prototype.secret will be equal to 42.
  //
  // To fix this problem, replace
  //     meta.prop = {};
  // above with
  //     meta.prop = vm.runInContext('{}', contextifiedObject);
})();copy

sourceTextModule.createCachedData()#

Added in: v13.7.0, v12.17.0


Returns: <Buffer>

Creates a code cache that can be used with the SourceTextModule constructor's
cachedData option. Returns a Buffer. This method may be called any number
of times before the module has been evaluated.
The code cache of the SourceTextModule doesn't contain any JavaScript
observable states. The code cache is safe to be saved along side the script
source and used to construct new SourceTextModule instances multiple times.
Functions in the SourceTextModule source can be marked as lazily compiled
and they are not compiled at construction of the SourceTextModule. These
functions are going to be compiled when they are invoked the first time. The
code cache serializes the metadata that V8 currently knows about the
SourceTextModule that it can use to speed up future compilations.
// Create an initial module
const module = new vm.SourceTextModule('const a = 1;');

// Create cached data from this module
const cachedData = module.createCachedData();

// Create a new module using the cached data. The code must be the same.
const module2 = new vm.SourceTextModule('const a = 1;', { cachedData }); copy

Class: vm.SyntheticModule#

Added in: v13.0.0, v12.16.0

Stability: 1 - Experimental
This feature is only available with the --experimental-vm-modules command
flag enabled.

Extends: <vm.Module>

The vm.SyntheticModule class provides the Synthetic Module Record as
defined in the WebIDL specification. The purpose of synthetic modules is to
provide a generic interface for exposing non-JavaScript sources to ECMAScript
module graphs.
const vm = require('node:vm');

const source = '{ "a": 1 }';
const module = new vm.SyntheticModule(['default'], function() {
  const obj = JSON.parse(source);
  this.setExport('default', obj);
});

// Use `module` in linking... copy

new vm.SyntheticModule(exportNames, evaluateCallback[, options])#

Added in: v13.0.0, v12.16.0


exportNames <string[]> Array of names that will be exported from the
module.
evaluateCallback <Function> Called when the module is evaluated.
options

identifier <string> String used in stack traces.
Default: 'vm:module(i)' where i is a context-specific ascending
index.
context <Object> The contextified object as returned by the
vm.createContext() method, to compile and evaluate this Module in.



Creates a new SyntheticModule instance.
Objects assigned to the exports of this instance may allow importers of
the module to access information outside the specified context. Use
vm.runInContext() to create objects in a specific context.

syntheticModule.setExport(name, value)#

Added in: v13.0.0, v12.16.0


name <string> Name of the export to set.
value <any> The value to set the export to.

This method is used after the module is linked to set the values of exports. If
it is called before the module is linked, an ERR_VM_MODULE_STATUS error
will be thrown.

import vm from 'node:vm';

const m = new vm.SyntheticModule(['x'], () => {
  m.setExport('x', 1);
});

await m.link(() => {});
await m.evaluate();

assert.strictEqual(m.namespace.x, 1);const vm = require('node:vm');
(async () => {
  const m = new vm.SyntheticModule(['x'], () => {
    m.setExport('x', 1);
  });
  await m.link(() => {});
  await m.evaluate();
  assert.strictEqual(m.namespace.x, 1);
})();copy

vm.compileFunction(code[, params[, options]])#

History

VersionChanges
v21.7.0, v20.12.0
Added support for vm.constants.USE_MAIN_CONTEXT_DEFAULT_LOADER.
v19.6.0, v18.15.0
The return value now includes cachedDataRejected with the same semantics as the vm.Script version if the cachedData option was passed.
v17.0.0, v16.12.0
Added support for import attributes to the importModuleDynamically parameter.
v15.9.0
Added importModuleDynamically option again.
v14.3.0
Removal of importModuleDynamically due to compatibility issues.
v14.1.0, v13.14.0
The importModuleDynamically option is now supported.
v10.10.0
Added in: v10.10.0




code <string> The body of the function to compile.
params <string[]> An array of strings containing all parameters for the
function.
options <Object>

filename <string> Specifies the filename used in stack traces produced
by this script. Default: ''.
lineOffset <number> Specifies the line number offset that is displayed
in stack traces produced by this script. Default: 0.
columnOffset <number> Specifies the first-line column number offset that
is displayed in stack traces produced by this script. Default: 0.
cachedData <Buffer> | <TypedArray> | <DataView> Provides an optional Buffer or
TypedArray, or DataView with V8's code cache data for the supplied
source. This must be produced by a prior call to vm.compileFunction()
with the same code and params.
produceCachedData <boolean> Specifies whether to produce new cache data.
Default: false.
parsingContext <Object> The contextified object in which the said
function should be compiled in.
contextExtensions <Object[]> An array containing a collection of context
extensions (objects wrapping the current scope) to be applied while
compiling. Default: [].
importModuleDynamically
<Function> | <vm.constants.USE_MAIN_CONTEXT_DEFAULT_LOADER>
Used to specify the how the modules should be loaded during the evaluation of
this function when import() is called. This option is part of the
experimental modules API. We do not recommend using it in a production
environment. For detailed information, see
Support of dynamic import() in compilation APIs.


Returns: <Function>

Compiles the given code into the provided context (if no context is
supplied, the current context is used), and returns it wrapped inside a
function with the given params.
vm.constants#

Added in: v21.7.0, v20.12.0


<Object>

Returns an object containing commonly used constants for VM operations.

vm.constants.USE_MAIN_CONTEXT_DEFAULT_LOADER#

Added in: v21.7.0, v20.12.0

Stability: 1.1 - Active development
A constant that can be used as the importModuleDynamically option to
vm.Script and vm.compileFunction() so that Node.js uses the default
ESM loader from the main context to load the requested module.
For detailed information, see
Support of dynamic import() in compilation APIs.

vm.createContext([contextObject[, options]])#

History

VersionChanges
v22.8.0, v20.18.0
The contextObject argument now accepts vm.constants.DONT_CONTEXTIFY.
v21.7.0, v20.12.0
Added support for vm.constants.USE_MAIN_CONTEXT_DEFAULT_LOADER.
v21.2.0, v20.11.0
The importModuleDynamically option is supported now.
v14.6.0
The microtaskMode option is supported now.
v10.0.0
The first argument can no longer be a function.
v10.0.0
The codeGeneration option is supported now.
v0.3.1
Added in: v0.3.1




contextObject <Object> | <vm.constants.DONT_CONTEXTIFY> | <undefined>
Either vm.constants.DONT_CONTEXTIFY or an object that will be contextified.
If undefined, an empty contextified object will be created for backwards compatibility.
options <Object>

name <string> Human-readable name of the newly created context.
Default: 'VM Context i', where i is an ascending numerical index of
the created context.
origin <string> Origin corresponding to the newly created
context for display purposes. The origin should be formatted like a URL,
but with only the scheme, host, and port (if necessary), like the value of
the url.origin property of a URL object. Most notably, this
string should omit the trailing slash, as that denotes a path.
Default: ''.
codeGeneration <Object>

strings <boolean> If set to false any calls to eval or function
constructors (Function, GeneratorFunction, etc) will throw an
EvalError. Default: true.
wasm <boolean> If set to false any attempt to compile a WebAssembly
module will throw a WebAssembly.CompileError. Default: true.


microtaskMode <string> If set to afterEvaluate, microtasks (tasks
scheduled through Promises and async functions) will be run immediately
after a script has run through script.runInContext().
They are included in the timeout and breakOnSigint scopes in that case.
importModuleDynamically
<Function> | <vm.constants.USE_MAIN_CONTEXT_DEFAULT_LOADER>
Used to specify the how the modules should be loaded when import() is
called in this context without a referrer script or module. This option is
part of the experimental modules API. We do not recommend using it in a
production environment. For detailed information, see
Support of dynamic import() in compilation APIs.


Returns: <Object> contextified object.

If the given contextObject is an object, the vm.createContext() method will prepare that
object and return a reference to it so that it can be used in
calls to vm.runInContext() or script.runInContext(). Inside such
scripts, the global object will be wrapped by the contextObject, retaining all of its
existing properties but also having the built-in objects and functions any
standard global object has. Outside of scripts run by the vm module, global
variables will remain unchanged.
const vm = require('node:vm');

global.globalVar = 3;

const context = { globalVar: 1 };
vm.createContext(context);

vm.runInContext('globalVar *= 2;', context);

console.log(context);
// Prints: { globalVar: 2 }

console.log(global.globalVar);
// Prints: 3 copy
If contextObject is omitted (or passed explicitly as undefined), a new,
empty contextified object will be returned.
When the global object in the newly created context is contextified, it has some quirks
compared to ordinary global objects. For example, it cannot be frozen. To create a context
without the contextifying quirks, pass vm.constants.DONT_CONTEXTIFY as the contextObject
argument. See the documentation of vm.constants.DONT_CONTEXTIFY for details.
The vm.createContext() method is primarily useful for creating a single
context that can be used to run multiple scripts. For instance, if emulating a
web browser, the method can be used to create a single context representing a
window's global object, then run all <script> tags together within that
context.
The provided name and origin of the context are made visible through the
Inspector API.
vm.isContext(object)#

Added in: v0.11.7


object <Object>
Returns: <boolean>

Returns true if the given object object has been contextified using
vm.createContext(), or if it's the global object of a context created
using vm.constants.DONT_CONTEXTIFY.
vm.measureMemory([options])#

Added in: v13.10.0

Stability: 1 - Experimental
Measure the memory known to V8 and used by all contexts known to the
current V8 isolate, or the main context.

options <Object> Optional.

mode <string> Either 'summary' or 'detailed'. In summary mode,
only the memory measured for the main context will be returned. In
detailed mode, the memory measured for all contexts known to the
current V8 isolate will be returned.
Default: 'summary'
execution <string> Either 'default' or 'eager'. With default
execution, the promise will not resolve until after the next scheduled
garbage collection starts, which may take a while (or never if the program
exits before the next GC). With eager execution, the GC will be started
right away to measure the memory.
Default: 'default'


Returns: <Promise> If the memory is successfully measured, the promise will
resolve with an object containing information about the memory usage.
Otherwise it will be rejected with an ERR_CONTEXT_NOT_INITIALIZED error.

The format of the object that the returned Promise may resolve with is
specific to the V8 engine and may change from one version of V8 to the next.
The returned result is different from the statistics returned by
v8.getHeapSpaceStatistics() in that vm.measureMemory() measure the
memory reachable by each V8 specific contexts in the current instance of
the V8 engine, while the result of v8.getHeapSpaceStatistics() measure
the memory occupied by each heap space in the current V8 instance.
const vm = require('node:vm');
// Measure the memory used by the main context.
vm.measureMemory({ mode: 'summary' })
  // This is the same as vm.measureMemory()
  .then((result) => {
    // The current format is:
    // {
    //   total: {
    //      jsMemoryEstimate: 2418479, jsMemoryRange: [ 2418479, 2745799 ]
    //    }
    // }
    console.log(result);
  });

const context = vm.createContext({ a: 1 });
vm.measureMemory({ mode: 'detailed', execution: 'eager' })
  .then((result) => {
    // Reference the context here so that it won't be GC'ed
    // until the measurement is complete.
    console.log(context.a);
    // {
    //   total: {
    //     jsMemoryEstimate: 2574732,
    //     jsMemoryRange: [ 2574732, 2904372 ]
    //   },
    //   current: {
    //     jsMemoryEstimate: 2438996,
    //     jsMemoryRange: [ 2438996, 2768636 ]
    //   },
    //   other: [
    //     {
    //       jsMemoryEstimate: 135736,
    //       jsMemoryRange: [ 135736, 465376 ]
    //     }
    //   ]
    // }
    console.log(result);
  }); copy
vm.runInContext(code, contextifiedObject[, options])#

History

VersionChanges
v21.7.0, v20.12.0
Added support for vm.constants.USE_MAIN_CONTEXT_DEFAULT_LOADER.
v17.0.0, v16.12.0
Added support for import attributes to the importModuleDynamically parameter.
v6.3.0
The breakOnSigint option is supported now.
v0.3.1
Added in: v0.3.1




code <string> The JavaScript code to compile and run.
contextifiedObject <Object> The contextified object that will be used
as the global when the code is compiled and run.
options <Object> | <string>

filename <string> Specifies the filename used in stack traces produced
by this script. Default: 'evalmachine.<anonymous>'.
lineOffset <number> Specifies the line number offset that is displayed
in stack traces produced by this script. Default: 0.
columnOffset <number> Specifies the first-line column number offset that
is displayed in stack traces produced by this script. Default: 0.
displayErrors <boolean> When true, if an Error occurs
while compiling the code, the line of code causing the error is attached
to the stack trace. Default: true.
timeout <integer> Specifies the number of milliseconds to execute code
before terminating execution. If execution is terminated, an Error
will be thrown. This value must be a strictly positive integer.
breakOnSigint <boolean> If true, receiving SIGINT
(Ctrl+C) will terminate execution and throw an
Error. Existing handlers for the event that have been attached via
process.on('SIGINT') are disabled during script execution, but continue to
work after that. Default: false.
cachedData <Buffer> | <TypedArray> | <DataView> Provides an optional Buffer or
TypedArray, or DataView with V8's code cache data for the supplied
source.
importModuleDynamically
<Function> | <vm.constants.USE_MAIN_CONTEXT_DEFAULT_LOADER>
Used to specify the how the modules should be loaded during the evaluation
of this script when import() is called. This option is part of the
experimental modules API. We do not recommend using it in a production
environment. For detailed information, see
Support of dynamic import() in compilation APIs.



The vm.runInContext() method compiles code, runs it within the context of
the contextifiedObject, then returns the result. Running code does not have
access to the local scope. The contextifiedObject object must have been
previously contextified using the vm.createContext() method.
If options is a string, then it specifies the filename.
The following example compiles and executes different scripts using a single
contextified object:
const vm = require('node:vm');

const contextObject = { globalVar: 1 };
vm.createContext(contextObject);

for (let i = 0; i < 10; ++i) {
  vm.runInContext('globalVar *= 2;', contextObject);
}
console.log(contextObject);
// Prints: { globalVar: 1024 } copy
vm.runInNewContext(code[, contextObject[, options]])#

History

VersionChanges
v22.8.0, v20.18.0
The contextObject argument now accepts vm.constants.DONT_CONTEXTIFY.
v21.7.0, v20.12.0
Added support for vm.constants.USE_MAIN_CONTEXT_DEFAULT_LOADER.
v17.0.0, v16.12.0
Added support for import attributes to the importModuleDynamically parameter.
v14.6.0
The microtaskMode option is supported now.
v10.0.0
The contextCodeGeneration option is supported now.
v6.3.0
The breakOnSigint option is supported now.
v0.3.1
Added in: v0.3.1




code <string> The JavaScript code to compile and run.
contextObject <Object> | <vm.constants.DONT_CONTEXTIFY> | <undefined>
Either vm.constants.DONT_CONTEXTIFY or an object that will be contextified.
If undefined, an empty contextified object will be created for backwards compatibility.
options <Object> | <string>

filename <string> Specifies the filename used in stack traces produced
by this script. Default: 'evalmachine.<anonymous>'.
lineOffset <number> Specifies the line number offset that is displayed
in stack traces produced by this script. Default: 0.
columnOffset <number> Specifies the first-line column number offset that
is displayed in stack traces produced by this script. Default: 0.
displayErrors <boolean> When true, if an Error occurs
while compiling the code, the line of code causing the error is attached
to the stack trace. Default: true.
timeout <integer> Specifies the number of milliseconds to execute code
before terminating execution. If execution is terminated, an Error
will be thrown. This value must be a strictly positive integer.
breakOnSigint <boolean> If true, receiving SIGINT
(Ctrl+C) will terminate execution and throw an
Error. Existing handlers for the event that have been attached via
process.on('SIGINT') are disabled during script execution, but continue to
work after that. Default: false.
contextName <string> Human-readable name of the newly created context.
Default: 'VM Context i', where i is an ascending numerical index of
the created context.
contextOrigin <string> Origin corresponding to the newly
created context for display purposes. The origin should be formatted like a
URL, but with only the scheme, host, and port (if necessary), like the
value of the url.origin property of a URL object. Most notably,
this string should omit the trailing slash, as that denotes a path.
Default: ''.
contextCodeGeneration <Object>

strings <boolean> If set to false any calls to eval or function
constructors (Function, GeneratorFunction, etc) will throw an
EvalError. Default: true.
wasm <boolean> If set to false any attempt to compile a WebAssembly
module will throw a WebAssembly.CompileError. Default: true.


cachedData <Buffer> | <TypedArray> | <DataView> Provides an optional Buffer or
TypedArray, or DataView with V8's code cache data for the supplied
source.
importModuleDynamically
<Function> | <vm.constants.USE_MAIN_CONTEXT_DEFAULT_LOADER>
Used to specify the how the modules should be loaded during the evaluation
of this script when import() is called. This option is part of the
experimental modules API. We do not recommend using it in a production
environment. For detailed information, see
Support of dynamic import() in compilation APIs.
microtaskMode <string> If set to afterEvaluate, microtasks (tasks
scheduled through Promises and async functions) will be run immediately
after the script has run. They are included in the timeout and
breakOnSigint scopes in that case.


Returns: <any> the result of the very last statement executed in the script.

This method is a shortcut to
(new vm.Script(code, options)).runInContext(vm.createContext(options), options).
If options is a string, then it specifies the filename.
It does several things at once:

Creates a new context.
If contextObject is an object, contextifies it with the new context.
If  contextObject is undefined, creates a new object and contextifies it.
If contextObject is vm.constants.DONT_CONTEXTIFY, don't contextify anything.
Compiles the code as avm.Script
Runs the compield code within the created context. The code does not have access to the scope in
which this method is called.
Returns the result.

The following example compiles and executes code that increments a global
variable and sets a new one. These globals are contained in the contextObject.
const vm = require('node:vm');

const contextObject = {
  animal: 'cat',
  count: 2,
};

vm.runInNewContext('count += 1; name = "kitty"', contextObject);
console.log(contextObject);
// Prints: { animal: 'cat', count: 3, name: 'kitty' }

// This would throw if the context is created from a contextified object.
// vm.constants.DONT_CONTEXTIFY allows creating contexts with ordinary global objects that
// can be frozen.
const frozenContext = vm.runInNewContext('Object.freeze(globalThis); globalThis;', vm.constants.DONT_CONTEXTIFY); copy
vm.runInThisContext(code[, options])#

History

VersionChanges
v21.7.0, v20.12.0
Added support for vm.constants.USE_MAIN_CONTEXT_DEFAULT_LOADER.
v17.0.0, v16.12.0
Added support for import attributes to the importModuleDynamically parameter.
v6.3.0
The breakOnSigint option is supported now.
v0.3.1
Added in: v0.3.1




code <string> The JavaScript code to compile and run.
options <Object> | <string>

filename <string> Specifies the filename used in stack traces produced
by this script. Default: 'evalmachine.<anonymous>'.
lineOffset <number> Specifies the line number offset that is displayed
in stack traces produced by this script. Default: 0.
columnOffset <number> Specifies the first-line column number offset that
is displayed in stack traces produced by this script. Default: 0.
displayErrors <boolean> When true, if an Error occurs
while compiling the code, the line of code causing the error is attached
to the stack trace. Default: true.
timeout <integer> Specifies the number of milliseconds to execute code
before terminating execution. If execution is terminated, an Error
will be thrown. This value must be a strictly positive integer.
breakOnSigint <boolean> If true, receiving SIGINT
(Ctrl+C) will terminate execution and throw an
Error. Existing handlers for the event that have been attached via
process.on('SIGINT') are disabled during script execution, but continue to
work after that. Default: false.
cachedData <Buffer> | <TypedArray> | <DataView> Provides an optional Buffer or
TypedArray, or DataView with V8's code cache data for the supplied
source.
importModuleDynamically
<Function> | <vm.constants.USE_MAIN_CONTEXT_DEFAULT_LOADER>
Used to specify the how the modules should be loaded during the evaluation
of this script when import() is called. This option is part of the
experimental modules API. We do not recommend using it in a production
environment. For detailed information, see
Support of dynamic import() in compilation APIs.


Returns: <any> the result of the very last statement executed in the script.

vm.runInThisContext() compiles code, runs it within the context of the
current global and returns the result. Running code does not have access to
local scope, but does have access to the current global object.
If options is a string, then it specifies the filename.
The following example illustrates using both vm.runInThisContext() and
the JavaScript eval() function to run the same code:

const vm = require('node:vm');
let localVar = 'initial value';

const vmResult = vm.runInThisContext('localVar = "vm";');
console.log(`vmResult: '${vmResult}', localVar: '${localVar}'`);
// Prints: vmResult: 'vm', localVar: 'initial value'

const evalResult = eval('localVar = "eval";');
console.log(`evalResult: '${evalResult}', localVar: '${localVar}'`);
// Prints: evalResult: 'eval', localVar: 'eval' copy
Because vm.runInThisContext() does not have access to the local scope,
localVar is unchanged. In contrast, eval() does have access to the
local scope, so the value localVar is changed. In this way
vm.runInThisContext() is much like an indirect eval() call, e.g.
(0,eval)('code').
Example: Running an HTTP server within a VM#
When using either script.runInThisContext() or
vm.runInThisContext(), the code is executed within the current V8 global
context. The code passed to this VM context will have its own isolated scope.
In order to run a simple web server using the node:http module the code passed
to the context must either call require('node:http') on its own, or have a
reference to the node:http module passed to it. For instance:
'use strict';
const vm = require('node:vm');

const code = `
((require) => {
  const http = require('node:http');

  http.createServer((request, response) => {
    response.writeHead(200, { 'Content-Type': 'text/plain' });
    response.end('Hello World\\n');
  }).listen(8124);

  console.log('Server running at http://127.0.0.1:8124/');
})`;

vm.runInThisContext(code)(require); copy
The require() in the above case shares the state with the context it is
passed from. This may introduce risks when untrusted code is executed, e.g.
altering objects in the context in unwanted ways.
What does it mean to "contextify" an object?#
All JavaScript executed within Node.js runs within the scope of a "context".
According to the V8 Embedder's Guide:

In V8, a context is an execution environment that allows separate, unrelated,
JavaScript applications to run in a single instance of V8. You must explicitly
specify the context in which you want any JavaScript code to be run.

When the method vm.createContext() is called with an object, the contextObject argument
will be used to wrap the global object of a new instance of a V8 Context
(if contextObject is undefined, a new object will be created from the current context
before its contextified). This V8 Context provides the code run using the node:vm
module's methods with an isolated global environment within which it can operate.
The process of creating the V8 Context and associating it with the contextObject
in the outer context is what this document refers to as "contextifying" the object.
The contextifying would introduce some quirks to the globalThis value in the context.
For example, it cannot be frozen, and it is not reference equal to the contextObject
in the outer context.
const vm = require('node:vm');

// An undefined `contextObject` option makes the global object contextified.
const context = vm.createContext();
console.log(vm.runInContext('globalThis', context) === context);  // false
// A contextified global object cannot be frozen.
try {
  vm.runInContext('Object.freeze(globalThis);', context);
} catch (e) {
  console.log(e); // TypeError: Cannot freeze
}
console.log(vm.runInContext('globalThis.foo = 1; foo;', context));  // 1 copy
To create a context with an ordinary global object and get access to a global proxy in
the outer context with fewer quirks, specify vm.constants.DONT_CONTEXTIFY as the
contextObject argument.

vm.constants.DONT_CONTEXTIFY#
This constant, when used as the contextObject argument in vm APIs, instructs Node.js to create
a context without wrapping its global object with another object in a Node.js-specific manner.
As a result, the globalThis value inside the new context would behave more closely to an ordinary
one.
const vm = require('node:vm');

// Use vm.constants.DONT_CONTEXTIFY to freeze the global object.
const context = vm.createContext(vm.constants.DONT_CONTEXTIFY);
vm.runInContext('Object.freeze(globalThis);', context);
try {
  vm.runInContext('bar = 1; bar;', context);
} catch (e) {
  console.log(e); // Uncaught ReferenceError: bar is not defined
} copy
When vm.constants.DONT_CONTEXTIFY is used as the contextObject argument to vm.createContext(),
the returned object is a proxy-like object to the global object in the newly created context with
fewer Node.js-specific quirks. It is reference equal to the globalThis value in the new context,
can be modified from outside the context, and can be used to access built-ins in the new context directly.
const vm = require('node:vm');

const context = vm.createContext(vm.constants.DONT_CONTEXTIFY);

// Returned object is reference equal to globalThis in the new context.
console.log(vm.runInContext('globalThis', context) === context);  // true

// Can be used to access globals in the new context directly.
console.log(context.Array);  // [Function: Array]
vm.runInContext('foo = 1;', context);
console.log(context.foo);  // 1
context.bar = 1;
console.log(vm.runInContext('bar;', context));  // 1

// Can be frozen and it affects the inner context.
Object.freeze(context);
try {
  vm.runInContext('baz = 1; baz;', context);
} catch (e) {
  console.log(e); // Uncaught ReferenceError: baz is not defined
} copy

Timeout interactions with asynchronous tasks and Promises#
Promises and async functions can schedule tasks run by the JavaScript
engine asynchronously. By default, these tasks are run after all JavaScript
functions on the current stack are done executing.
This allows escaping the functionality of the timeout and
breakOnSigint options.
For example, the following code executed by vm.runInNewContext() with a
timeout of 5 milliseconds schedules an infinite loop to run after a promise
resolves. The scheduled loop is never interrupted by the timeout:
const vm = require('node:vm');

function loop() {
  console.log('entering loop');
  while (1) console.log(Date.now());
}

vm.runInNewContext(
  'Promise.resolve().then(() => loop());',
  { loop, console },
  { timeout: 5 },
);
// This is printed *before* 'entering loop' (!)
console.log('done executing'); copy
This can be addressed by passing microtaskMode: 'afterEvaluate' to the code
that creates the Context:
const vm = require('node:vm');

function loop() {
  while (1) console.log(Date.now());
}

vm.runInNewContext(
  'Promise.resolve().then(() => loop());',
  { loop, console },
  { timeout: 5, microtaskMode: 'afterEvaluate' },
); copy
In this case, the microtask scheduled through promise.then() will be run
before returning from vm.runInNewContext(), and will be interrupted
by the timeout functionality. This applies only to code running in a
vm.Context, so e.g. vm.runInThisContext() does not take this option.
Promise callbacks are entered into the microtask queue of the context in which
they were created. For example, if () => loop() is replaced with just loop
in the above example, then loop will be pushed into the global microtask
queue, because it is a function from the outer (main) context, and thus will
also be able to escape the timeout.
If asynchronous scheduling functions such as process.nextTick(),
queueMicrotask(), setTimeout(), setImmediate(), etc. are made available
inside a vm.Context, functions passed to them will be added to global queues,
which are shared by all contexts. Therefore, callbacks passed to those functions
are not controllable through the timeout either.
Support of dynamic import() in compilation APIs#
The following APIs support an importModuleDynamically option to enable dynamic
import() in code compiled by the vm module.

new vm.Script
vm.compileFunction()
new vm.SourceTextModule
vm.runInThisContext()
vm.runInContext()
vm.runInNewContext()
vm.createContext()

This option is still part of the experimental modules API. We do not recommend
using it in a production environment.

When the importModuleDynamically option is not specified or undefined#
If this option is not specified, or if it's undefined, code containing
import() can still be compiled by the vm APIs, but when the compiled code is
executed and it actually calls import(), the result will reject with
ERR_VM_DYNAMIC_IMPORT_CALLBACK_MISSING.

When importModuleDynamically is vm.constants.USE_MAIN_CONTEXT_DEFAULT_LOADER#
This option is currently not supported for vm.SourceTextModule.
With this option, when an import() is initiated in the compiled code, Node.js
would use the default ESM loader from the main context to load the requested
module and return it to the code being executed.
This gives access to Node.js built-in modules such as fs or http
to the code being compiled. If the code is executed in a different context,
be aware that the objects created by modules loaded from the main context
are still from the main context and not instanceof built-in classes in the
new context.

const { Script, constants } = require('node:vm');
const script = new Script(
  'import("node:fs").then(({readFile}) => readFile instanceof Function)',
  { importModuleDynamically: constants.USE_MAIN_CONTEXT_DEFAULT_LOADER });

// false: URL loaded from the main context is not an instance of the Function
// class in the new context.
script.runInNewContext().then(console.log);import { Script, constants } from 'node:vm';

const script = new Script(
  'import("node:fs").then(({readFile}) => readFile instanceof Function)',
  { importModuleDynamically: constants.USE_MAIN_CONTEXT_DEFAULT_LOADER });

// false: URL loaded from the main context is not an instance of the Function
// class in the new context.
script.runInNewContext().then(console.log);copy
This option also allows the script or function to load user modules:

import { Script, constants } from 'node:vm';
import { resolve } from 'node:path';
import { writeFileSync } from 'node:fs';

// Write test.js and test.txt to the directory where the current script
// being run is located.
writeFileSync(resolve(import.meta.dirname, 'test.mjs'),
              'export const filename = "./test.json";');
writeFileSync(resolve(import.meta.dirname, 'test.json'),
              '{"hello": "world"}');

// Compile a script that loads test.mjs and then test.json
// as if the script is placed in the same directory.
const script = new Script(
  `(async function() {
    const { filename } = await import('./test.mjs');
    return import(filename, { with: { type: 'json' } })
  })();`,
  {
    filename: resolve(import.meta.dirname, 'test-with-default.js'),
    importModuleDynamically: constants.USE_MAIN_CONTEXT_DEFAULT_LOADER,
  });

// { default: { hello: 'world' } }
script.runInThisContext().then(console.log);const { Script, constants } = require('node:vm');
const { resolve } = require('node:path');
const { writeFileSync } = require('node:fs');

// Write test.js and test.txt to the directory where the current script
// being run is located.
writeFileSync(resolve(__dirname, 'test.mjs'),
              'export const filename = "./test.json";');
writeFileSync(resolve(__dirname, 'test.json'),
              '{"hello": "world"}');

// Compile a script that loads test.mjs and then test.json
// as if the script is placed in the same directory.
const script = new Script(
  `(async function() {
    const { filename } = await import('./test.mjs');
    return import(filename, { with: { type: 'json' } })
  })();`,
  {
    filename: resolve(__dirname, 'test-with-default.js'),
    importModuleDynamically: constants.USE_MAIN_CONTEXT_DEFAULT_LOADER,
  });

// { default: { hello: 'world' } }
script.runInThisContext().then(console.log);copy
There are a few caveats with loading user modules using the default loader
from the main context:

The module being resolved would be relative to the filename option passed
to vm.Script or vm.compileFunction(). The resolution can work with a
filename that's either an absolute path or a URL string.  If filename is
a string that's neither an absolute path or a URL, or if it's undefined,
the resolution will be relative to the current working directory
of the process. In the case of vm.createContext(), the resolution is always
relative to the current working directory since this option is only used when
there isn't a referrer script or module.
For any given filename that resolves to a specific path, once the process
manages to load a particular module from that path, the result may be cached,
and subsequent load of the same module from the same path would return the
same thing. If the filename is a URL string, the cache would not be hit
if it has different search parameters. For filenames that are not URL
strings, there is currently no way to bypass the caching behavior.


When importModuleDynamically is a function#
When importModuleDynamically is a function, it will be invoked when import()
is called in the compiled code for users to customize how the requested module
should be compiled and evaluated. Currently, the Node.js instance must be
launched with the --experimental-vm-modules flag for this option to work. If
the flag isn't set, this callback will be ignored. If the code evaluated
actually calls to import(), the result will reject with
ERR_VM_DYNAMIC_IMPORT_CALLBACK_MISSING_FLAG.
The callback importModuleDynamically(specifier, referrer, importAttributes)
has the following signature:

specifier <string> specifier passed to import()
referrer <vm.Script> | <Function> | <vm.SourceTextModule> | <Object>
The referrer is the compiled vm.Script for new vm.Script,
vm.runInThisContext, vm.runInContext and vm.runInNewContext. It's the
compiled Function for vm.compileFunction, the compiled
vm.SourceTextModule for new vm.SourceTextModule, and the context Object
for vm.createContext().
importAttributes <Object> The "with" value passed to the
optionsExpression optional parameter, or an empty object if no value was
provided.
phase <string> The phase of the dynamic import ("source" or "evaluation").
Returns: <Module Namespace Object> | <vm.Module> Returning a vm.Module is
recommended in order to take advantage of error tracking, and to avoid issues
with namespaces that contain then function exports.


// This script must be run with --experimental-vm-modules.
import { Script, SyntheticModule } from 'node:vm';

const script = new Script('import("foo.json", { with: { type: "json" } })', {
  async importModuleDynamically(specifier, referrer, importAttributes) {
    console.log(specifier);  // 'foo.json'
    console.log(referrer);   // The compiled script
    console.log(importAttributes);  // { type: 'json' }
    const m = new SyntheticModule(['bar'], () => { });
    await m.link(() => { });
    m.setExport('bar', { hello: 'world' });
    return m;
  },
});
const result = await script.runInThisContext();
console.log(result);  //  { bar: { hello: 'world' } }// This script must be run with --experimental-vm-modules.
const { Script, SyntheticModule } = require('node:vm');

(async function main() {
  const script = new Script('import("foo.json", { with: { type: "json" } })', {
    async importModuleDynamically(specifier, referrer, importAttributes) {
      console.log(specifier);  // 'foo.json'
      console.log(referrer);   // The compiled script
      console.log(importAttributes);  // { type: 'json' }
      const m = new SyntheticModule(['bar'], () => { });
      await m.link(() => { });
      m.setExport('bar', { hello: 'world' });
      return m;
    },
  });
  const result = await script.runInThisContext();
  console.log(result);  //  { bar: { hello: 'world' } }
})();copy\n\n\n\nNode.js
        
      
      
About this documentation
Usage and example



Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Modules: TypeScript
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
Readline
REPL
Report
Single executable applications
SQLite
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker

    

    
      
        
          Node.js v24.0.1 documentation
          
            
            
          
        
        
          
            Node.js v24.0.1
            
    
      
        
        Table of contents
      

      
VM (executing JavaScript)

Class: vm.Script

new vm.Script(code[, options])
script.cachedDataRejected
script.createCachedData()
script.runInContext(contextifiedObject[, options])
script.runInNewContext([contextObject[, options]])
script.runInThisContext([options])
script.sourceMapURL


Class: vm.Module

module.dependencySpecifiers
module.error
module.evaluate([options])
module.identifier
module.link(linker)
module.namespace
module.status


Class: vm.SourceTextModule

new vm.SourceTextModule(code[, options])
sourceTextModule.createCachedData()


Class: vm.SyntheticModule

new vm.SyntheticModule(exportNames, evaluateCallback[, options])
syntheticModule.setExport(name, value)


vm.compileFunction(code[, params[, options]])
vm.constants

vm.constants.USE_MAIN_CONTEXT_DEFAULT_LOADER


vm.createContext([contextObject[, options]])
vm.isContext(object)
vm.measureMemory([options])
vm.runInContext(code, contextifiedObject[, options])
vm.runInNewContext(code[, contextObject[, options]])
vm.runInThisContext(code[, options])
Example: Running an HTTP server within a VM
What does it mean to "contextify" an object?

vm.constants.DONT_CONTEXTIFY


Timeout interactions with asynchronous tasks and Promises
Support of dynamic import() in compilation APIs

When the importModuleDynamically option is not specified or undefined
When importModuleDynamically is vm.constants.USE_MAIN_CONTEXT_DEFAULT_LOADER
When importModuleDynamically is a function





    
  
            
    
      
        
        Index
      

      
About this documentation
Usage and example

      
        Index
      
    
  


Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Modules: TypeScript
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
Readline
REPL
Report
Single executable applications
SQLite
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker

    
  
            
    
      
        
        Other versions
      
      24.x
23.x
22.x LTS
21.x
20.x LTS
19.x
18.x
17.x
16.x
15.x
14.x
13.x
12.x
11.x
10.x
9.x
8.x
7.x
6.x
5.x
4.x
0.12.x
0.10.x
    
  
            
              
                
                Options
              
        
              
                
                  
                    View on single page
                  
                  
                    View as JSON
                  
                  Edit on GitHub    
                
              
            
          
        
        
      

      Table of contents
VM (executing JavaScript)

Class: vm.Script

new vm.Script(code[, options])
script.cachedDataRejected
script.createCachedData()
script.runInContext(contextifiedObject[, options])
script.runInNewContext([contextObject[, options]])
script.runInThisContext([options])
script.sourceMapURL


Class: vm.Module

module.dependencySpecifiers
module.error
module.evaluate([options])
module.identifier
module.link(linker)
module.namespace
module.status


Class: vm.SourceTextModule

new vm.SourceTextModule(code[, options])
sourceTextModule.createCachedData()


Class: vm.SyntheticModule

new vm.SyntheticModule(exportNames, evaluateCallback[, options])
syntheticModule.setExport(name, value)


vm.compileFunction(code[, params[, options]])
vm.constants

vm.constants.USE_MAIN_CONTEXT_DEFAULT_LOADER


vm.createContext([contextObject[, options]])
vm.isContext(object)
vm.measureMemory([options])
vm.runInContext(code, contextifiedObject[, options])
vm.runInNewContext(code[, contextObject[, options]])
vm.runInThisContext(code[, options])
Example: Running an HTTP server within a VM
What does it mean to "contextify" an object?

vm.constants.DONT_CONTEXTIFY


Timeout interactions with asynchronous tasks and Promises
Support of dynamic import() in compilation APIs

When the importModuleDynamically option is not specified or undefined
When importModuleDynamically is vm.constants.USE_MAIN_CONTEXT_DEFAULT_LOADER
When importModuleDynamically is a function






      
        VM (executing JavaScript)#

Stability: 2 - Stable

Source Code: lib/vm.js
The node:vm module enables compiling and running code within V8 Virtual
Machine contexts.
The node:vm module is not a security
mechanism. Do not use it to run untrusted code.
JavaScript code can be compiled and run immediately or
compiled, saved, and run later.
A common use case is to run the code in a different V8 Context. This means
invoked code has a different global object than the invoking code.
One can provide the context by contextifying an
object. The invoked code treats any property in the context like a
global variable. Any changes to global variables caused by the invoked
code are reflected in the context object.
const vm = require('node:vm');

const x = 1;

const context = { x: 2 };
vm.createContext(context); // Contextify the object.

const code = 'x += 40; var y = 17;';
// `x` and `y` are global variables in the context.
// Initially, x has the value 2 because that is the value of context.x.
vm.runInContext(code, context);

console.log(context.x); // 42
console.log(context.y); // 17

console.log(x); // 1; y is not defined. copy
Class: vm.Script#

Added in: v0.3.1

Instances of the vm.Script class contain precompiled scripts that can be
executed in specific contexts.

new vm.Script(code[, options])#

History

VersionChanges
v21.7.0, v20.12.0
Added support for vm.constants.USE_MAIN_CONTEXT_DEFAULT_LOADER.
v17.0.0, v16.12.0
Added support for import attributes to the importModuleDynamically parameter.
v10.6.0
The produceCachedData is deprecated in favour of script.createCachedData().
v5.7.0
The cachedData and produceCachedData options are supported now.
v0.3.1
Added in: v0.3.1




code <string> The JavaScript code to compile.
options <Object> | <string>

filename <string> Specifies the filename used in stack traces produced
by this script. Default: 'evalmachine.<anonymous>'.
lineOffset <number> Specifies the line number offset that is displayed
in stack traces produced by this script. Default: 0.
columnOffset <number> Specifies the first-line column number offset that
is displayed in stack traces produced by this script. Default: 0.
cachedData <Buffer> | <TypedArray> | <DataView> Provides an optional Buffer or
TypedArray, or DataView with V8's code cache data for the supplied
source. When supplied, the cachedDataRejected value will be set to
either true or false depending on acceptance of the data by V8.
produceCachedData <boolean> When true and no cachedData is present, V8
will attempt to produce code cache data for code. Upon success, a
Buffer with V8's code cache data will be produced and stored in the
cachedData property of the returned vm.Script instance.
The cachedDataProduced value will be set to either true or false
depending on whether code cache data is produced successfully.
This option is deprecated in favor of script.createCachedData().
Default: false.
importModuleDynamically
<Function> | <vm.constants.USE_MAIN_CONTEXT_DEFAULT_LOADER>
Used to specify how the modules should be loaded during the evaluation
of this script when import() is called. This option is part of the
experimental modules API. We do not recommend using it in a production
environment. For detailed information, see
Support of dynamic import() in compilation APIs.



If options is a string, then it specifies the filename.
Creating a new vm.Script object compiles code but does not run it. The
compiled vm.Script can be run later multiple times. The code is not bound to
any global object; rather, it is bound before each run, just for that run.

script.cachedDataRejected#

Added in: v5.7.0


<boolean> | <undefined>

When cachedData is supplied to create the vm.Script, this value will be set
to either true or false depending on acceptance of the data by V8.
Otherwise the value is undefined.

script.createCachedData()#

Added in: v10.6.0


Returns: <Buffer>

Creates a code cache that can be used with the Script constructor's
cachedData option. Returns a Buffer. This method may be called at any
time and any number of times.
The code cache of the Script doesn't contain any JavaScript observable
states. The code cache is safe to be saved along side the script source and
used to construct new Script instances multiple times.
Functions in the Script source can be marked as lazily compiled and they are
not compiled at construction of the Script. These functions are going to be
compiled when they are invoked the first time. The code cache serializes the
metadata that V8 currently knows about the Script that it can use to speed up
future compilations.
const script = new vm.Script(`
function add(a, b) {
  return a + b;
}

const x = add(1, 2);
`);

const cacheWithoutAdd = script.createCachedData();
// In `cacheWithoutAdd` the function `add()` is marked for full compilation
// upon invocation.

script.runInThisContext();

const cacheWithAdd = script.createCachedData();
// `cacheWithAdd` contains fully compiled function `add()`. copy

script.runInContext(contextifiedObject[, options])#

History

VersionChanges
v6.3.0
The breakOnSigint option is supported now.
v0.3.1
Added in: v0.3.1




contextifiedObject <Object> A contextified object as returned by the
vm.createContext() method.
options <Object>

displayErrors <boolean> When true, if an Error occurs
while compiling the code, the line of code causing the error is attached
to the stack trace. Default: true.
timeout <integer> Specifies the number of milliseconds to execute code
before terminating execution. If execution is terminated, an Error
will be thrown. This value must be a strictly positive integer.
breakOnSigint <boolean> If true, receiving SIGINT
(Ctrl+C) will terminate execution and throw an
Error. Existing handlers for the event that have been attached via
process.on('SIGINT') are disabled during script execution, but continue to
work after that. Default: false.


Returns: <any> the result of the very last statement executed in the script.

Runs the compiled code contained by the vm.Script object within the given
contextifiedObject and returns the result. Running code does not have access
to local scope.
The following example compiles code that increments a global variable, sets
the value of another global variable, then execute the code multiple times.
The globals are contained in the context object.
const vm = require('node:vm');

const context = {
  animal: 'cat',
  count: 2,
};

const script = new vm.Script('count += 1; name = "kitty";');

vm.createContext(context);
for (let i = 0; i < 10; ++i) {
  script.runInContext(context);
}

console.log(context);
// Prints: { animal: 'cat', count: 12, name: 'kitty' } copy
Using the timeout or breakOnSigint options will result in new event loops
and corresponding threads being started, which have a non-zero performance
overhead.

script.runInNewContext([contextObject[, options]])#

History

VersionChanges
v22.8.0, v20.18.0
The contextObject argument now accepts vm.constants.DONT_CONTEXTIFY.
v14.6.0
The microtaskMode option is supported now.
v10.0.0
The contextCodeGeneration option is supported now.
v6.3.0
The breakOnSigint option is supported now.
v0.3.1
Added in: v0.3.1




contextObject <Object> | <vm.constants.DONT_CONTEXTIFY> | <undefined>
Either vm.constants.DONT_CONTEXTIFY or an object that will be contextified.
If undefined, an empty contextified object will be created for backwards compatibility.
options <Object>

displayErrors <boolean> When true, if an Error occurs
while compiling the code, the line of code causing the error is attached
to the stack trace. Default: true.
timeout <integer> Specifies the number of milliseconds to execute code
before terminating execution. If execution is terminated, an Error
will be thrown. This value must be a strictly positive integer.
breakOnSigint <boolean> If true, receiving SIGINT
(Ctrl+C) will terminate execution and throw an
Error. Existing handlers for the event that have been attached via
process.on('SIGINT') are disabled during script execution, but continue to
work after that. Default: false.
contextName <string> Human-readable name of the newly created context.
Default: 'VM Context i', where i is an ascending numerical index of
the created context.
contextOrigin <string> Origin corresponding to the newly
created context for display purposes. The origin should be formatted like a
URL, but with only the scheme, host, and port (if necessary), like the
value of the url.origin property of a URL object. Most notably,
this string should omit the trailing slash, as that denotes a path.
Default: ''.
contextCodeGeneration <Object>

strings <boolean> If set to false any calls to eval or function
constructors (Function, GeneratorFunction, etc) will throw an
EvalError. Default: true.
wasm <boolean> If set to false any attempt to compile a WebAssembly
module will throw a WebAssembly.CompileError. Default: true.


microtaskMode <string> If set to afterEvaluate, microtasks (tasks
scheduled through Promises and async functions) will be run immediately
after the script has run. They are included in the timeout and
breakOnSigint scopes in that case.


Returns: <any> the result of the very last statement executed in the script.

This method is a shortcut to script.runInContext(vm.createContext(options), options).
It does several things at once:

Creates a new context.
If contextObject is an object, contextifies it with the new context.
If  contextObject is undefined, creates a new object and contextifies it.
If contextObject is vm.constants.DONT_CONTEXTIFY, don't contextify anything.
Runs the compiled code contained by the vm.Script object within the created context. The code
does not have access to the scope in which this method is called.
Returns the result.

The following example compiles code that sets a global variable, then executes
the code multiple times in different contexts. The globals are set on and
contained within each individual context.
const vm = require('node:vm');

const script = new vm.Script('globalVar = "set"');

const contexts = [{}, {}, {}];
contexts.forEach((context) => {
  script.runInNewContext(context);
});

console.log(contexts);
// Prints: [{ globalVar: 'set' }, { globalVar: 'set' }, { globalVar: 'set' }]

// This would throw if the context is created from a contextified object.
// vm.constants.DONT_CONTEXTIFY allows creating contexts with ordinary
// global objects that can be frozen.
const freezeScript = new vm.Script('Object.freeze(globalThis); globalThis;');
const frozenContext = freezeScript.runInNewContext(vm.constants.DONT_CONTEXTIFY); copy

script.runInThisContext([options])#

History

VersionChanges
v6.3.0
The breakOnSigint option is supported now.
v0.3.1
Added in: v0.3.1




options <Object>

displayErrors <boolean> When true, if an Error occurs
while compiling the code, the line of code causing the error is attached
to the stack trace. Default: true.
timeout <integer> Specifies the number of milliseconds to execute code
before terminating execution. If execution is terminated, an Error
will be thrown. This value must be a strictly positive integer.
breakOnSigint <boolean> If true, receiving SIGINT
(Ctrl+C) will terminate execution and throw an
Error. Existing handlers for the event that have been attached via
process.on('SIGINT') are disabled during script execution, but continue to
work after that. Default: false.


Returns: <any> the result of the very last statement executed in the script.

Runs the compiled code contained by the vm.Script within the context of the
current global object. Running code does not have access to local scope, but
does have access to the current global object.
The following example compiles code that increments a global variable then
executes that code multiple times:
const vm = require('node:vm');

global.globalVar = 0;

const script = new vm.Script('globalVar += 1', { filename: 'myfile.vm' });

for (let i = 0; i < 1000; ++i) {
  script.runInThisContext();
}

console.log(globalVar);

// 1000 copy

script.sourceMapURL#

Added in: v19.1.0, v18.13.0


<string> | <undefined>

When the script is compiled from a source that contains a source map magic
comment, this property will be set to the URL of the source map.

import vm from 'node:vm';

const script = new vm.Script(`
function myFunc() {}
//# sourceMappingURL=sourcemap.json
`);

console.log(script.sourceMapURL);
// Prints: sourcemap.jsonconst vm = require('node:vm');

const script = new vm.Script(`
function myFunc() {}
//# sourceMappingURL=sourcemap.json
`);

console.log(script.sourceMapURL);
// Prints: sourcemap.jsoncopy

Class: vm.Module#

Added in: v13.0.0, v12.16.0

Stability: 1 - Experimental
This feature is only available with the --experimental-vm-modules command
flag enabled.
The vm.Module class provides a low-level interface for using
ECMAScript modules in VM contexts. It is the counterpart of the vm.Script
class that closely mirrors Module Records as defined in the ECMAScript
specification.
Unlike vm.Script however, every vm.Module object is bound to a context from
its creation. Operations on vm.Module objects are intrinsically asynchronous,
in contrast with the synchronous nature of vm.Script objects. The use of
'async' functions can help with manipulating vm.Module objects.
Using a vm.Module object requires three distinct steps: creation/parsing,
linking, and evaluation. These three steps are illustrated in the following
example.
This implementation lies at a lower level than the ECMAScript Module
loader. There is also no way to interact with the Loader yet, though
support is planned.

import vm from 'node:vm';

const contextifiedObject = vm.createContext({
  secret: 42,
  print: console.log,
});

// Step 1
//
// Create a Module by constructing a new `vm.SourceTextModule` object. This
// parses the provided source text, throwing a `SyntaxError` if anything goes
// wrong. By default, a Module is created in the top context. But here, we
// specify `contextifiedObject` as the context this Module belongs to.
//
// Here, we attempt to obtain the default export from the module "foo", and
// put it into local binding "secret".

const bar = new vm.SourceTextModule(`
  import s from 'foo';
  s;
  print(s);
`, { context: contextifiedObject });

// Step 2
//
// "Link" the imported dependencies of this Module to it.
//
// The provided linking callback (the "linker") accepts two arguments: the
// parent module (`bar` in this case) and the string that is the specifier of
// the imported module. The callback is expected to return a Module that
// corresponds to the provided specifier, with certain requirements documented
// in `module.link()`.
//
// If linking has not started for the returned Module, the same linker
// callback will be called on the returned Module.
//
// Even top-level Modules without dependencies must be explicitly linked. The
// callback provided would never be called, however.
//
// The link() method returns a Promise that will be resolved when all the
// Promises returned by the linker resolve.
//
// Note: This is a contrived example in that the linker function creates a new
// "foo" module every time it is called. In a full-fledged module system, a
// cache would probably be used to avoid duplicated modules.

async function linker(specifier, referencingModule) {
  if (specifier === 'foo') {
    return new vm.SourceTextModule(`
      // The "secret" variable refers to the global variable we added to
      // "contextifiedObject" when creating the context.
      export default secret;
    `, { context: referencingModule.context });

    // Using `contextifiedObject` instead of `referencingModule.context`
    // here would work as well.
  }
  throw new Error(`Unable to resolve dependency: ${specifier}`);
}
await bar.link(linker);

// Step 3
//
// Evaluate the Module. The evaluate() method returns a promise which will
// resolve after the module has finished evaluating.

// Prints 42.
await bar.evaluate();const vm = require('node:vm');

const contextifiedObject = vm.createContext({
  secret: 42,
  print: console.log,
});

(async () => {
  // Step 1
  //
  // Create a Module by constructing a new `vm.SourceTextModule` object. This
  // parses the provided source text, throwing a `SyntaxError` if anything goes
  // wrong. By default, a Module is created in the top context. But here, we
  // specify `contextifiedObject` as the context this Module belongs to.
  //
  // Here, we attempt to obtain the default export from the module "foo", and
  // put it into local binding "secret".

  const bar = new vm.SourceTextModule(`
    import s from 'foo';
    s;
    print(s);
  `, { context: contextifiedObject });

  // Step 2
  //
  // "Link" the imported dependencies of this Module to it.
  //
  // The provided linking callback (the "linker") accepts two arguments: the
  // parent module (`bar` in this case) and the string that is the specifier of
  // the imported module. The callback is expected to return a Module that
  // corresponds to the provided specifier, with certain requirements documented
  // in `module.link()`.
  //
  // If linking has not started for the returned Module, the same linker
  // callback will be called on the returned Module.
  //
  // Even top-level Modules without dependencies must be explicitly linked. The
  // callback provided would never be called, however.
  //
  // The link() method returns a Promise that will be resolved when all the
  // Promises returned by the linker resolve.
  //
  // Note: This is a contrived example in that the linker function creates a new
  // "foo" module every time it is called. In a full-fledged module system, a
  // cache would probably be used to avoid duplicated modules.

  async function linker(specifier, referencingModule) {
    if (specifier === 'foo') {
      return new vm.SourceTextModule(`
        // The "secret" variable refers to the global variable we added to
        // "contextifiedObject" when creating the context.
        export default secret;
      `, { context: referencingModule.context });

      // Using `contextifiedObject` instead of `referencingModule.context`
      // here would work as well.
    }
    throw new Error(`Unable to resolve dependency: ${specifier}`);
  }
  await bar.link(linker);

  // Step 3
  //
  // Evaluate the Module. The evaluate() method returns a promise which will
  // resolve after the module has finished evaluating.

  // Prints 42.
  await bar.evaluate();
})();copy

module.dependencySpecifiers#

<string[]>

The specifiers of all dependencies of this module. The returned array is frozen
to disallow any changes to it.
Corresponds to the [[RequestedModules]] field of Cyclic Module Records in
the ECMAScript specification.

module.error#

<any>

If the module.status is 'errored', this property contains the exception
thrown by the module during evaluation. If the status is anything else,
accessing this property will result in a thrown exception.
The value undefined cannot be used for cases where there is not a thrown
exception due to possible ambiguity with throw undefined;.
Corresponds to the [[EvaluationError]] field of Cyclic Module Records
in the ECMAScript specification.

module.evaluate([options])#

options <Object>

timeout <integer> Specifies the number of milliseconds to evaluate
before terminating execution. If execution is interrupted, an Error
will be thrown. This value must be a strictly positive integer.
breakOnSigint <boolean> If true, receiving SIGINT
(Ctrl+C) will terminate execution and throw an
Error. Existing handlers for the event that have been attached via
process.on('SIGINT') are disabled during script execution, but continue to
work after that. Default: false.


Returns: <Promise> Fulfills with undefined upon success.

Evaluate the module.
This must be called after the module has been linked; otherwise it will reject.
It could be called also when the module has already been evaluated, in which
case it will either do nothing if the initial evaluation ended in success
(module.status is 'evaluated') or it will re-throw the exception that the
initial evaluation resulted in (module.status is 'errored').
This method cannot be called while the module is being evaluated
(module.status is 'evaluating').
Corresponds to the Evaluate() concrete method field of Cyclic Module
Records in the ECMAScript specification.

module.identifier#

<string>

The identifier of the current module, as set in the constructor.

module.link(linker)#

History

VersionChanges
v21.1.0, v20.10.0, v18.19.0
The option extra.assert is renamed to extra.attributes. The former name is still provided for backward compatibility.




linker <Function>


specifier <string> The specifier of the requested module:
import foo from 'foo';
//              ^^^^^ the module specifier copy


referencingModule <vm.Module> The Module object link() is called on.


extra <Object>

attributes <Object> The data from the attribute:
import foo from 'foo' with { name: 'value' };
//                         ^^^^^^^^^^^^^^^^^ the attribute copy
Per ECMA-262, hosts are expected to trigger an error if an
unsupported attribute is present.
assert <Object> Alias for extra.attributes.



Returns: <vm.Module> | <Promise>



Returns: <Promise>

Link module dependencies. This method must be called before evaluation, and
can only be called once per module.
The function is expected to return a Module object or a Promise that
eventually resolves to a Module object. The returned Module must satisfy the
following two invariants:

It must belong to the same context as the parent Module.
Its status must not be 'errored'.

If the returned Module's status is 'unlinked', this method will be
recursively called on the returned Module with the same provided linker
function.
link() returns a Promise that will either get resolved when all linking
instances resolve to a valid Module, or rejected if the linker function either
throws an exception or returns an invalid Module.
The linker function roughly corresponds to the implementation-defined
HostResolveImportedModule abstract operation in the ECMAScript
specification, with a few key differences:

The linker function is allowed to be asynchronous while
HostResolveImportedModule is synchronous.

The actual HostResolveImportedModule implementation used during module
linking is one that returns the modules linked during linking. Since at
that point all modules would have been fully linked already, the
HostResolveImportedModule implementation is fully synchronous per
specification.
Corresponds to the Link() concrete method field of Cyclic Module
Records in the ECMAScript specification.

module.namespace#

<Object>

The namespace object of the module. This is only available after linking
(module.link()) has completed.
Corresponds to the GetModuleNamespace abstract operation in the ECMAScript
specification.

module.status#

<string>

The current status of the module. Will be one of:


'unlinked': module.link() has not yet been called.


'linking': module.link() has been called, but not all Promises returned
by the linker function have been resolved yet.


'linked': The module has been linked successfully, and all of its
dependencies are linked, but module.evaluate() has not yet been called.


'evaluating': The module is being evaluated through a module.evaluate() on
itself or a parent module.


'evaluated': The module has been successfully evaluated.


'errored': The module has been evaluated, but an exception was thrown.


Other than 'errored', this status string corresponds to the specification's
Cyclic Module Record's [[Status]] field. 'errored' corresponds to
'evaluated' in the specification, but with [[EvaluationError]] set to a
value that is not undefined.

Class: vm.SourceTextModule#

Added in: v9.6.0

Stability: 1 - Experimental
This feature is only available with the --experimental-vm-modules command
flag enabled.

Extends: <vm.Module>

The vm.SourceTextModule class provides the Source Text Module Record as
defined in the ECMAScript specification.

new vm.SourceTextModule(code[, options])#

History

VersionChanges
v17.0.0, v16.12.0
Added support for import attributes to the importModuleDynamically parameter.




code <string> JavaScript Module code to parse
options

identifier <string> String used in stack traces.
Default: 'vm:module(i)' where i is a context-specific ascending
index.
cachedData <Buffer> | <TypedArray> | <DataView> Provides an optional Buffer or
TypedArray, or DataView with V8's code cache data for the supplied
source. The code must be the same as the module from which this
cachedData was created.
context <Object> The contextified object as returned by the
vm.createContext() method, to compile and evaluate this Module in.
If no context is specified, the module is evaluated in the current
execution context.
lineOffset <integer> Specifies the line number offset that is displayed
in stack traces produced by this Module. Default: 0.
columnOffset <integer> Specifies the first-line column number offset that
is displayed in stack traces produced by this Module. Default: 0.
initializeImportMeta <Function> Called during evaluation of this Module
to initialize the import.meta.

meta <import.meta>
module <vm.SourceTextModule>


importModuleDynamically <Function> Used to specify the
how the modules should be loaded during the evaluation of this module
when import() is called. This option is part of the experimental
modules API. We do not recommend using it in a production environment.
For detailed information, see
Support of dynamic import() in compilation APIs.



Creates a new SourceTextModule instance.
Properties assigned to the import.meta object that are objects may
allow the module to access information outside the specified context. Use
vm.runInContext() to create objects in a specific context.

import vm from 'node:vm';

const contextifiedObject = vm.createContext({ secret: 42 });

const module = new vm.SourceTextModule(
  'Object.getPrototypeOf(import.meta.prop).secret = secret;',
  {
    initializeImportMeta(meta) {
      // Note: this object is created in the top context. As such,
      // Object.getPrototypeOf(import.meta.prop) points to the
      // Object.prototype in the top context rather than that in
      // the contextified object.
      meta.prop = {};
    },
  });
// Since module has no dependencies, the linker function will never be called.
await module.link(() => {});
await module.evaluate();

// Now, Object.prototype.secret will be equal to 42.
//
// To fix this problem, replace
//     meta.prop = {};
// above with
//     meta.prop = vm.runInContext('{}', contextifiedObject);const vm = require('node:vm');
const contextifiedObject = vm.createContext({ secret: 42 });
(async () => {
  const module = new vm.SourceTextModule(
    'Object.getPrototypeOf(import.meta.prop).secret = secret;',
    {
      initializeImportMeta(meta) {
        // Note: this object is created in the top context. As such,
        // Object.getPrototypeOf(import.meta.prop) points to the
        // Object.prototype in the top context rather than that in
        // the contextified object.
        meta.prop = {};
      },
    });
  // Since module has no dependencies, the linker function will never be called.
  await module.link(() => {});
  await module.evaluate();
  // Now, Object.prototype.secret will be equal to 42.
  //
  // To fix this problem, replace
  //     meta.prop = {};
  // above with
  //     meta.prop = vm.runInContext('{}', contextifiedObject);
})();copy

sourceTextModule.createCachedData()#

Added in: v13.7.0, v12.17.0


Returns: <Buffer>

Creates a code cache that can be used with the SourceTextModule constructor's
cachedData option. Returns a Buffer. This method may be called any number
of times before the module has been evaluated.
The code cache of the SourceTextModule doesn't contain any JavaScript
observable states. The code cache is safe to be saved along side the script
source and used to construct new SourceTextModule instances multiple times.
Functions in the SourceTextModule source can be marked as lazily compiled
and they are not compiled at construction of the SourceTextModule. These
functions are going to be compiled when they are invoked the first time. The
code cache serializes the metadata that V8 currently knows about the
SourceTextModule that it can use to speed up future compilations.
// Create an initial module
const module = new vm.SourceTextModule('const a = 1;');

// Create cached data from this module
const cachedData = module.createCachedData();

// Create a new module using the cached data. The code must be the same.
const module2 = new vm.SourceTextModule('const a = 1;', { cachedData }); copy

Class: vm.SyntheticModule#

Added in: v13.0.0, v12.16.0

Stability: 1 - Experimental
This feature is only available with the --experimental-vm-modules command
flag enabled.

Extends: <vm.Module>

The vm.SyntheticModule class provides the Synthetic Module Record as
defined in the WebIDL specification. The purpose of synthetic modules is to
provide a generic interface for exposing non-JavaScript sources to ECMAScript
module graphs.
const vm = require('node:vm');

const source = '{ "a": 1 }';
const module = new vm.SyntheticModule(['default'], function() {
  const obj = JSON.parse(source);
  this.setExport('default', obj);
});

// Use `module` in linking... copy

new vm.SyntheticModule(exportNames, evaluateCallback[, options])#

Added in: v13.0.0, v12.16.0


exportNames <string[]> Array of names that will be exported from the
module.
evaluateCallback <Function> Called when the module is evaluated.
options

identifier <string> String used in stack traces.
Default: 'vm:module(i)' where i is a context-specific ascending
index.
context <Object> The contextified object as returned by the
vm.createContext() method, to compile and evaluate this Module in.



Creates a new SyntheticModule instance.
Objects assigned to the exports of this instance may allow importers of
the module to access information outside the specified context. Use
vm.runInContext() to create objects in a specific context.

syntheticModule.setExport(name, value)#

Added in: v13.0.0, v12.16.0


name <string> Name of the export to set.
value <any> The value to set the export to.

This method is used after the module is linked to set the values of exports. If
it is called before the module is linked, an ERR_VM_MODULE_STATUS error
will be thrown.

import vm from 'node:vm';

const m = new vm.SyntheticModule(['x'], () => {
  m.setExport('x', 1);
});

await m.link(() => {});
await m.evaluate();

assert.strictEqual(m.namespace.x, 1);const vm = require('node:vm');
(async () => {
  const m = new vm.SyntheticModule(['x'], () => {
    m.setExport('x', 1);
  });
  await m.link(() => {});
  await m.evaluate();
  assert.strictEqual(m.namespace.x, 1);
})();copy

vm.compileFunction(code[, params[, options]])#

History

VersionChanges
v21.7.0, v20.12.0
Added support for vm.constants.USE_MAIN_CONTEXT_DEFAULT_LOADER.
v19.6.0, v18.15.0
The return value now includes cachedDataRejected with the same semantics as the vm.Script version if the cachedData option was passed.
v17.0.0, v16.12.0
Added support for import attributes to the importModuleDynamically parameter.
v15.9.0
Added importModuleDynamically option again.
v14.3.0
Removal of importModuleDynamically due to compatibility issues.
v14.1.0, v13.14.0
The importModuleDynamically option is now supported.
v10.10.0
Added in: v10.10.0




code <string> The body of the function to compile.
params <string[]> An array of strings containing all parameters for the
function.
options <Object>

filename <string> Specifies the filename used in stack traces produced
by this script. Default: ''.
lineOffset <number> Specifies the line number offset that is displayed
in stack traces produced by this script. Default: 0.
columnOffset <number> Specifies the first-line column number offset that
is displayed in stack traces produced by this script. Default: 0.
cachedData <Buffer> | <TypedArray> | <DataView> Provides an optional Buffer or
TypedArray, or DataView with V8's code cache data for the supplied
source. This must be produced by a prior call to vm.compileFunction()
with the same code and params.
produceCachedData <boolean> Specifies whether to produce new cache data.
Default: false.
parsingContext <Object> The contextified object in which the said
function should be compiled in.
contextExtensions <Object[]> An array containing a collection of context
extensions (objects wrapping the current scope) to be applied while
compiling. Default: [].
importModuleDynamically
<Function> | <vm.constants.USE_MAIN_CONTEXT_DEFAULT_LOADER>
Used to specify the how the modules should be loaded during the evaluation of
this function when import() is called. This option is part of the
experimental modules API. We do not recommend using it in a production
environment. For detailed information, see
Support of dynamic import() in compilation APIs.


Returns: <Function>

Compiles the given code into the provided context (if no context is
supplied, the current context is used), and returns it wrapped inside a
function with the given params.
vm.constants#

Added in: v21.7.0, v20.12.0


<Object>

Returns an object containing commonly used constants for VM operations.

vm.constants.USE_MAIN_CONTEXT_DEFAULT_LOADER#

Added in: v21.7.0, v20.12.0

Stability: 1.1 - Active development
A constant that can be used as the importModuleDynamically option to
vm.Script and vm.compileFunction() so that Node.js uses the default
ESM loader from the main context to load the requested module.
For detailed information, see
Support of dynamic import() in compilation APIs.

vm.createContext([contextObject[, options]])#

History

VersionChanges
v22.8.0, v20.18.0
The contextObject argument now accepts vm.constants.DONT_CONTEXTIFY.
v21.7.0, v20.12.0
Added support for vm.constants.USE_MAIN_CONTEXT_DEFAULT_LOADER.
v21.2.0, v20.11.0
The importModuleDynamically option is supported now.
v14.6.0
The microtaskMode option is supported now.
v10.0.0
The first argument can no longer be a function.
v10.0.0
The codeGeneration option is supported now.
v0.3.1
Added in: v0.3.1




contextObject <Object> | <vm.constants.DONT_CONTEXTIFY> | <undefined>
Either vm.constants.DONT_CONTEXTIFY or an object that will be contextified.
If undefined, an empty contextified object will be created for backwards compatibility.
options <Object>

name <string> Human-readable name of the newly created context.
Default: 'VM Context i', where i is an ascending numerical index of
the created context.
origin <string> Origin corresponding to the newly created
context for display purposes. The origin should be formatted like a URL,
but with only the scheme, host, and port (if necessary), like the value of
the url.origin property of a URL object. Most notably, this
string should omit the trailing slash, as that denotes a path.
Default: ''.
codeGeneration <Object>

strings <boolean> If set to false any calls to eval or function
constructors (Function, GeneratorFunction, etc) will throw an
EvalError. Default: true.
wasm <boolean> If set to false any attempt to compile a WebAssembly
module will throw a WebAssembly.CompileError. Default: true.


microtaskMode <string> If set to afterEvaluate, microtasks (tasks
scheduled through Promises and async functions) will be run immediately
after a script has run through script.runInContext().
They are included in the timeout and breakOnSigint scopes in that case.
importModuleDynamically
<Function> | <vm.constants.USE_MAIN_CONTEXT_DEFAULT_LOADER>
Used to specify the how the modules should be loaded when import() is
called in this context without a referrer script or module. This option is
part of the experimental modules API. We do not recommend using it in a
production environment. For detailed information, see
Support of dynamic import() in compilation APIs.


Returns: <Object> contextified object.

If the given contextObject is an object, the vm.createContext() method will prepare that
object and return a reference to it so that it can be used in
calls to vm.runInContext() or script.runInContext(). Inside such
scripts, the global object will be wrapped by the contextObject, retaining all of its
existing properties but also having the built-in objects and functions any
standard global object has. Outside of scripts run by the vm module, global
variables will remain unchanged.
const vm = require('node:vm');

global.globalVar = 3;

const context = { globalVar: 1 };
vm.createContext(context);

vm.runInContext('globalVar *= 2;', context);

console.log(context);
// Prints: { globalVar: 2 }

console.log(global.globalVar);
// Prints: 3 copy
If contextObject is omitted (or passed explicitly as undefined), a new,
empty contextified object will be returned.
When the global object in the newly created context is contextified, it has some quirks
compared to ordinary global objects. For example, it cannot be frozen. To create a context
without the contextifying quirks, pass vm.constants.DONT_CONTEXTIFY as the contextObject
argument. See the documentation of vm.constants.DONT_CONTEXTIFY for details.
The vm.createContext() method is primarily useful for creating a single
context that can be used to run multiple scripts. For instance, if emulating a
web browser, the method can be used to create a single context representing a
window's global object, then run all <script> tags together within that
context.
The provided name and origin of the context are made visible through the
Inspector API.
vm.isContext(object)#

Added in: v0.11.7


object <Object>
Returns: <boolean>

Returns true if the given object object has been contextified using
vm.createContext(), or if it's the global object of a context created
using vm.constants.DONT_CONTEXTIFY.
vm.measureMemory([options])#

Added in: v13.10.0

Stability: 1 - Experimental
Measure the memory known to V8 and used by all contexts known to the
current V8 isolate, or the main context.

options <Object> Optional.

mode <string> Either 'summary' or 'detailed'. In summary mode,
only the memory measured for the main context will be returned. In
detailed mode, the memory measured for all contexts known to the
current V8 isolate will be returned.
Default: 'summary'
execution <string> Either 'default' or 'eager'. With default
execution, the promise will not resolve until after the next scheduled
garbage collection starts, which may take a while (or never if the program
exits before the next GC). With eager execution, the GC will be started
right away to measure the memory.
Default: 'default'


Returns: <Promise> If the memory is successfully measured, the promise will
resolve with an object containing information about the memory usage.
Otherwise it will be rejected with an ERR_CONTEXT_NOT_INITIALIZED error.

The format of the object that the returned Promise may resolve with is
specific to the V8 engine and may change from one version of V8 to the next.
The returned result is different from the statistics returned by
v8.getHeapSpaceStatistics() in that vm.measureMemory() measure the
memory reachable by each V8 specific contexts in the current instance of
the V8 engine, while the result of v8.getHeapSpaceStatistics() measure
the memory occupied by each heap space in the current V8 instance.
const vm = require('node:vm');
// Measure the memory used by the main context.
vm.measureMemory({ mode: 'summary' })
  // This is the same as vm.measureMemory()
  .then((result) => {
    // The current format is:
    // {
    //   total: {
    //      jsMemoryEstimate: 2418479, jsMemoryRange: [ 2418479, 2745799 ]
    //    }
    // }
    console.log(result);
  });

const context = vm.createContext({ a: 1 });
vm.measureMemory({ mode: 'detailed', execution: 'eager' })
  .then((result) => {
    // Reference the context here so that it won't be GC'ed
    // until the measurement is complete.
    console.log(context.a);
    // {
    //   total: {
    //     jsMemoryEstimate: 2574732,
    //     jsMemoryRange: [ 2574732, 2904372 ]
    //   },
    //   current: {
    //     jsMemoryEstimate: 2438996,
    //     jsMemoryRange: [ 2438996, 2768636 ]
    //   },
    //   other: [
    //     {
    //       jsMemoryEstimate: 135736,
    //       jsMemoryRange: [ 135736, 465376 ]
    //     }
    //   ]
    // }
    console.log(result);
  }); copy
vm.runInContext(code, contextifiedObject[, options])#

History

VersionChanges
v21.7.0, v20.12.0
Added support for vm.constants.USE_MAIN_CONTEXT_DEFAULT_LOADER.
v17.0.0, v16.12.0
Added support for import attributes to the importModuleDynamically parameter.
v6.3.0
The breakOnSigint option is supported now.
v0.3.1
Added in: v0.3.1




code <string> The JavaScript code to compile and run.
contextifiedObject <Object> The contextified object that will be used
as the global when the code is compiled and run.
options <Object> | <string>

filename <string> Specifies the filename used in stack traces produced
by this script. Default: 'evalmachine.<anonymous>'.
lineOffset <number> Specifies the line number offset that is displayed
in stack traces produced by this script. Default: 0.
columnOffset <number> Specifies the first-line column number offset that
is displayed in stack traces produced by this script. Default: 0.
displayErrors <boolean> When true, if an Error occurs
while compiling the code, the line of code causing the error is attached
to the stack trace. Default: true.
timeout <integer> Specifies the number of milliseconds to execute code
before terminating execution. If execution is terminated, an Error
will be thrown. This value must be a strictly positive integer.
breakOnSigint <boolean> If true, receiving SIGINT
(Ctrl+C) will terminate execution and throw an
Error. Existing handlers for the event that have been attached via
process.on('SIGINT') are disabled during script execution, but continue to
work after that. Default: false.
cachedData <Buffer> | <TypedArray> | <DataView> Provides an optional Buffer or
TypedArray, or DataView with V8's code cache data for the supplied
source.
importModuleDynamically
<Function> | <vm.constants.USE_MAIN_CONTEXT_DEFAULT_LOADER>
Used to specify the how the modules should be loaded during the evaluation
of this script when import() is called. This option is part of the
experimental modules API. We do not recommend using it in a production
environment. For detailed information, see
Support of dynamic import() in compilation APIs.



The vm.runInContext() method compiles code, runs it within the context of
the contextifiedObject, then returns the result. Running code does not have
access to the local scope. The contextifiedObject object must have been
previously contextified using the vm.createContext() method.
If options is a string, then it specifies the filename.
The following example compiles and executes different scripts using a single
contextified object:
const vm = require('node:vm');

const contextObject = { globalVar: 1 };
vm.createContext(contextObject);

for (let i = 0; i < 10; ++i) {
  vm.runInContext('globalVar *= 2;', contextObject);
}
console.log(contextObject);
// Prints: { globalVar: 1024 } copy
vm.runInNewContext(code[, contextObject[, options]])#

History

VersionChanges
v22.8.0, v20.18.0
The contextObject argument now accepts vm.constants.DONT_CONTEXTIFY.
v21.7.0, v20.12.0
Added support for vm.constants.USE_MAIN_CONTEXT_DEFAULT_LOADER.
v17.0.0, v16.12.0
Added support for import attributes to the importModuleDynamically parameter.
v14.6.0
The microtaskMode option is supported now.
v10.0.0
The contextCodeGeneration option is supported now.
v6.3.0
The breakOnSigint option is supported now.
v0.3.1
Added in: v0.3.1




code <string> The JavaScript code to compile and run.
contextObject <Object> | <vm.constants.DONT_CONTEXTIFY> | <undefined>
Either vm.constants.DONT_CONTEXTIFY or an object that will be contextified.
If undefined, an empty contextified object will be created for backwards compatibility.
options <Object> | <string>

filename <string> Specifies the filename used in stack traces produced
by this script. Default: 'evalmachine.<anonymous>'.
lineOffset <number> Specifies the line number offset that is displayed
in stack traces produced by this script. Default: 0.
columnOffset <number> Specifies the first-line column number offset that
is displayed in stack traces produced by this script. Default: 0.
displayErrors <boolean> When true, if an Error occurs
while compiling the code, the line of code causing the error is attached
to the stack trace. Default: true.
timeout <integer> Specifies the number of milliseconds to execute code
before terminating execution. If execution is terminated, an Error
will be thrown. This value must be a strictly positive integer.
breakOnSigint <boolean> If true, receiving SIGINT
(Ctrl+C) will terminate execution and throw an
Error. Existing handlers for the event that have been attached via
process.on('SIGINT') are disabled during script execution, but continue to
work after that. Default: false.
contextName <string> Human-readable name of the newly created context.
Default: 'VM Context i', where i is an ascending numerical index of
the created context.
contextOrigin <string> Origin corresponding to the newly
created context for display purposes. The origin should be formatted like a
URL, but with only the scheme, host, and port (if necessary), like the
value of the url.origin property of a URL object. Most notably,
this string should omit the trailing slash, as that denotes a path.
Default: ''.
contextCodeGeneration <Object>

strings <boolean> If set to false any calls to eval or function
constructors (Function, GeneratorFunction, etc) will throw an
EvalError. Default: true.
wasm <boolean> If set to false any attempt to compile a WebAssembly
module will throw a WebAssembly.CompileError. Default: true.


cachedData <Buffer> | <TypedArray> | <DataView> Provides an optional Buffer or
TypedArray, or DataView with V8's code cache data for the supplied
source.
importModuleDynamically
<Function> | <vm.constants.USE_MAIN_CONTEXT_DEFAULT_LOADER>
Used to specify the how the modules should be loaded during the evaluation
of this script when import() is called. This option is part of the
experimental modules API. We do not recommend using it in a production
environment. For detailed information, see
Support of dynamic import() in compilation APIs.
microtaskMode <string> If set to afterEvaluate, microtasks (tasks
scheduled through Promises and async functions) will be run immediately
after the script has run. They are included in the timeout and
breakOnSigint scopes in that case.


Returns: <any> the result of the very last statement executed in the script.

This method is a shortcut to
(new vm.Script(code, options)).runInContext(vm.createContext(options), options).
If options is a string, then it specifies the filename.
It does several things at once:

Creates a new context.
If contextObject is an object, contextifies it with the new context.
If  contextObject is undefined, creates a new object and contextifies it.
If contextObject is vm.constants.DONT_CONTEXTIFY, don't contextify anything.
Compiles the code as avm.Script
Runs the compield code within the created context. The code does not have access to the scope in
which this method is called.
Returns the result.

The following example compiles and executes code that increments a global
variable and sets a new one. These globals are contained in the contextObject.
const vm = require('node:vm');

const contextObject = {
  animal: 'cat',
  count: 2,
};

vm.runInNewContext('count += 1; name = "kitty"', contextObject);
console.log(contextObject);
// Prints: { animal: 'cat', count: 3, name: 'kitty' }

// This would throw if the context is created from a contextified object.
// vm.constants.DONT_CONTEXTIFY allows creating contexts with ordinary global objects that
// can be frozen.
const frozenContext = vm.runInNewContext('Object.freeze(globalThis); globalThis;', vm.constants.DONT_CONTEXTIFY); copy
vm.runInThisContext(code[, options])#

History

VersionChanges
v21.7.0, v20.12.0
Added support for vm.constants.USE_MAIN_CONTEXT_DEFAULT_LOADER.
v17.0.0, v16.12.0
Added support for import attributes to the importModuleDynamically parameter.
v6.3.0
The breakOnSigint option is supported now.
v0.3.1
Added in: v0.3.1




code <string> The JavaScript code to compile and run.
options <Object> | <string>

filename <string> Specifies the filename used in stack traces produced
by this script. Default: 'evalmachine.<anonymous>'.
lineOffset <number> Specifies the line number offset that is displayed
in stack traces produced by this script. Default: 0.
columnOffset <number> Specifies the first-line column number offset that
is displayed in stack traces produced by this script. Default: 0.
displayErrors <boolean> When true, if an Error occurs
while compiling the code, the line of code causing the error is attached
to the stack trace. Default: true.
timeout <integer> Specifies the number of milliseconds to execute code
before terminating execution. If execution is terminated, an Error
will be thrown. This value must be a strictly positive integer.
breakOnSigint <boolean> If true, receiving SIGINT
(Ctrl+C) will terminate execution and throw an
Error. Existing handlers for the event that have been attached via
process.on('SIGINT') are disabled during script execution, but continue to
work after that. Default: false.
cachedData <Buffer> | <TypedArray> | <DataView> Provides an optional Buffer or
TypedArray, or DataView with V8's code cache data for the supplied
source.
importModuleDynamically
<Function> | <vm.constants.USE_MAIN_CONTEXT_DEFAULT_LOADER>
Used to specify the how the modules should be loaded during the evaluation
of this script when import() is called. This option is part of the
experimental modules API. We do not recommend using it in a production
environment. For detailed information, see
Support of dynamic import() in compilation APIs.


Returns: <any> the result of the very last statement executed in the script.

vm.runInThisContext() compiles code, runs it within the context of the
current global and returns the result. Running code does not have access to
local scope, but does have access to the current global object.
If options is a string, then it specifies the filename.
The following example illustrates using both vm.runInThisContext() and
the JavaScript eval() function to run the same code:

const vm = require('node:vm');
let localVar = 'initial value';

const vmResult = vm.runInThisContext('localVar = "vm";');
console.log(`vmResult: '${vmResult}', localVar: '${localVar}'`);
// Prints: vmResult: 'vm', localVar: 'initial value'

const evalResult = eval('localVar = "eval";');
console.log(`evalResult: '${evalResult}', localVar: '${localVar}'`);
// Prints: evalResult: 'eval', localVar: 'eval' copy
Because vm.runInThisContext() does not have access to the local scope,
localVar is unchanged. In contrast, eval() does have access to the
local scope, so the value localVar is changed. In this way
vm.runInThisContext() is much like an indirect eval() call, e.g.
(0,eval)('code').
Example: Running an HTTP server within a VM#
When using either script.runInThisContext() or
vm.runInThisContext(), the code is executed within the current V8 global
context. The code passed to this VM context will have its own isolated scope.
In order to run a simple web server using the node:http module the code passed
to the context must either call require('node:http') on its own, or have a
reference to the node:http module passed to it. For instance:
'use strict';
const vm = require('node:vm');

const code = `
((require) => {
  const http = require('node:http');

  http.createServer((request, response) => {
    response.writeHead(200, { 'Content-Type': 'text/plain' });
    response.end('Hello World\\n');
  }).listen(8124);

  console.log('Server running at http://127.0.0.1:8124/');
})`;

vm.runInThisContext(code)(require); copy
The require() in the above case shares the state with the context it is
passed from. This may introduce risks when untrusted code is executed, e.g.
altering objects in the context in unwanted ways.
What does it mean to "contextify" an object?#
All JavaScript executed within Node.js runs within the scope of a "context".
According to the V8 Embedder's Guide:

In V8, a context is an execution environment that allows separate, unrelated,
JavaScript applications to run in a single instance of V8. You must explicitly
specify the context in which you want any JavaScript code to be run.

When the method vm.createContext() is called with an object, the contextObject argument
will be used to wrap the global object of a new instance of a V8 Context
(if contextObject is undefined, a new object will be created from the current context
before its contextified). This V8 Context provides the code run using the node:vm
module's methods with an isolated global environment within which it can operate.
The process of creating the V8 Context and associating it with the contextObject
in the outer context is what this document refers to as "contextifying" the object.
The contextifying would introduce some quirks to the globalThis value in the context.
For example, it cannot be frozen, and it is not reference equal to the contextObject
in the outer context.
const vm = require('node:vm');

// An undefined `contextObject` option makes the global object contextified.
const context = vm.createContext();
console.log(vm.runInContext('globalThis', context) === context);  // false
// A contextified global object cannot be frozen.
try {
  vm.runInContext('Object.freeze(globalThis);', context);
} catch (e) {
  console.log(e); // TypeError: Cannot freeze
}
console.log(vm.runInContext('globalThis.foo = 1; foo;', context));  // 1 copy
To create a context with an ordinary global object and get access to a global proxy in
the outer context with fewer quirks, specify vm.constants.DONT_CONTEXTIFY as the
contextObject argument.

vm.constants.DONT_CONTEXTIFY#
This constant, when used as the contextObject argument in vm APIs, instructs Node.js to create
a context without wrapping its global object with another object in a Node.js-specific manner.
As a result, the globalThis value inside the new context would behave more closely to an ordinary
one.
const vm = require('node:vm');

// Use vm.constants.DONT_CONTEXTIFY to freeze the global object.
const context = vm.createContext(vm.constants.DONT_CONTEXTIFY);
vm.runInContext('Object.freeze(globalThis);', context);
try {
  vm.runInContext('bar = 1; bar;', context);
} catch (e) {
  console.log(e); // Uncaught ReferenceError: bar is not defined
} copy
When vm.constants.DONT_CONTEXTIFY is used as the contextObject argument to vm.createContext(),
the returned object is a proxy-like object to the global object in the newly created context with
fewer Node.js-specific quirks. It is reference equal to the globalThis value in the new context,
can be modified from outside the context, and can be used to access built-ins in the new context directly.
const vm = require('node:vm');

const context = vm.createContext(vm.constants.DONT_CONTEXTIFY);

// Returned object is reference equal to globalThis in the new context.
console.log(vm.runInContext('globalThis', context) === context);  // true

// Can be used to access globals in the new context directly.
console.log(context.Array);  // [Function: Array]
vm.runInContext('foo = 1;', context);
console.log(context.foo);  // 1
context.bar = 1;
console.log(vm.runInContext('bar;', context));  // 1

// Can be frozen and it affects the inner context.
Object.freeze(context);
try {
  vm.runInContext('baz = 1; baz;', context);
} catch (e) {
  console.log(e); // Uncaught ReferenceError: baz is not defined
} copy

Timeout interactions with asynchronous tasks and Promises#
Promises and async functions can schedule tasks run by the JavaScript
engine asynchronously. By default, these tasks are run after all JavaScript
functions on the current stack are done executing.
This allows escaping the functionality of the timeout and
breakOnSigint options.
For example, the following code executed by vm.runInNewContext() with a
timeout of 5 milliseconds schedules an infinite loop to run after a promise
resolves. The scheduled loop is never interrupted by the timeout:
const vm = require('node:vm');

function loop() {
  console.log('entering loop');
  while (1) console.log(Date.now());
}

vm.runInNewContext(
  'Promise.resolve().then(() => loop());',
  { loop, console },
  { timeout: 5 },
);
// This is printed *before* 'entering loop' (!)
console.log('done executing'); copy
This can be addressed by passing microtaskMode: 'afterEvaluate' to the code
that creates the Context:
const vm = require('node:vm');

function loop() {
  while (1) console.log(Date.now());
}

vm.runInNewContext(
  'Promise.resolve().then(() => loop());',
  { loop, console },
  { timeout: 5, microtaskMode: 'afterEvaluate' },
); copy
In this case, the microtask scheduled through promise.then() will be run
before returning from vm.runInNewContext(), and will be interrupted
by the timeout functionality. This applies only to code running in a
vm.Context, so e.g. vm.runInThisContext() does not take this option.
Promise callbacks are entered into the microtask queue of the context in which
they were created. For example, if () => loop() is replaced with just loop
in the above example, then loop will be pushed into the global microtask
queue, because it is a function from the outer (main) context, and thus will
also be able to escape the timeout.
If asynchronous scheduling functions such as process.nextTick(),
queueMicrotask(), setTimeout(), setImmediate(), etc. are made available
inside a vm.Context, functions passed to them will be added to global queues,
which are shared by all contexts. Therefore, callbacks passed to those functions
are not controllable through the timeout either.
Support of dynamic import() in compilation APIs#
The following APIs support an importModuleDynamically option to enable dynamic
import() in code compiled by the vm module.

new vm.Script
vm.compileFunction()
new vm.SourceTextModule
vm.runInThisContext()
vm.runInContext()
vm.runInNewContext()
vm.createContext()

This option is still part of the experimental modules API. We do not recommend
using it in a production environment.

When the importModuleDynamically option is not specified or undefined#
If this option is not specified, or if it's undefined, code containing
import() can still be compiled by the vm APIs, but when the compiled code is
executed and it actually calls import(), the result will reject with
ERR_VM_DYNAMIC_IMPORT_CALLBACK_MISSING.

When importModuleDynamically is vm.constants.USE_MAIN_CONTEXT_DEFAULT_LOADER#
This option is currently not supported for vm.SourceTextModule.
With this option, when an import() is initiated in the compiled code, Node.js
would use the default ESM loader from the main context to load the requested
module and return it to the code being executed.
This gives access to Node.js built-in modules such as fs or http
to the code being compiled. If the code is executed in a different context,
be aware that the objects created by modules loaded from the main context
are still from the main context and not instanceof built-in classes in the
new context.

const { Script, constants } = require('node:vm');
const script = new Script(
  'import("node:fs").then(({readFile}) => readFile instanceof Function)',
  { importModuleDynamically: constants.USE_MAIN_CONTEXT_DEFAULT_LOADER });

// false: URL loaded from the main context is not an instance of the Function
// class in the new context.
script.runInNewContext().then(console.log);import { Script, constants } from 'node:vm';

const script = new Script(
  'import("node:fs").then(({readFile}) => readFile instanceof Function)',
  { importModuleDynamically: constants.USE_MAIN_CONTEXT_DEFAULT_LOADER });

// false: URL loaded from the main context is not an instance of the Function
// class in the new context.
script.runInNewContext().then(console.log);copy
This option also allows the script or function to load user modules:

import { Script, constants } from 'node:vm';
import { resolve } from 'node:path';
import { writeFileSync } from 'node:fs';

// Write test.js and test.txt to the directory where the current script
// being run is located.
writeFileSync(resolve(import.meta.dirname, 'test.mjs'),
              'export const filename = "./test.json";');
writeFileSync(resolve(import.meta.dirname, 'test.json'),
              '{"hello": "world"}');

// Compile a script that loads test.mjs and then test.json
// as if the script is placed in the same directory.
const script = new Script(
  `(async function() {
    const { filename } = await import('./test.mjs');
    return import(filename, { with: { type: 'json' } })
  })();`,
  {
    filename: resolve(import.meta.dirname, 'test-with-default.js'),
    importModuleDynamically: constants.USE_MAIN_CONTEXT_DEFAULT_LOADER,
  });

// { default: { hello: 'world' } }
script.runInThisContext().then(console.log);const { Script, constants } = require('node:vm');
const { resolve } = require('node:path');
const { writeFileSync } = require('node:fs');

// Write test.js and test.txt to the directory where the current script
// being run is located.
writeFileSync(resolve(__dirname, 'test.mjs'),
              'export const filename = "./test.json";');
writeFileSync(resolve(__dirname, 'test.json'),
              '{"hello": "world"}');

// Compile a script that loads test.mjs and then test.json
// as if the script is placed in the same directory.
const script = new Script(
  `(async function() {
    const { filename } = await import('./test.mjs');
    return import(filename, { with: { type: 'json' } })
  })();`,
  {
    filename: resolve(__dirname, 'test-with-default.js'),
    importModuleDynamically: constants.USE_MAIN_CONTEXT_DEFAULT_LOADER,
  });

// { default: { hello: 'world' } }
script.runInThisContext().then(console.log);copy
There are a few caveats with loading user modules using the default loader
from the main context:

The module being resolved would be relative to the filename option passed
to vm.Script or vm.compileFunction(). The resolution can work with a
filename that's either an absolute path or a URL string.  If filename is
a string that's neither an absolute path or a URL, or if it's undefined,
the resolution will be relative to the current working directory
of the process. In the case of vm.createContext(), the resolution is always
relative to the current working directory since this option is only used when
there isn't a referrer script or module.
For any given filename that resolves to a specific path, once the process
manages to load a particular module from that path, the result may be cached,
and subsequent load of the same module from the same path would return the
same thing. If the filename is a URL string, the cache would not be hit
if it has different search parameters. For filenames that are not URL
strings, there is currently no way to bypass the caching behavior.


When importModuleDynamically is a function#
When importModuleDynamically is a function, it will be invoked when import()
is called in the compiled code for users to customize how the requested module
should be compiled and evaluated. Currently, the Node.js instance must be
launched with the --experimental-vm-modules flag for this option to work. If
the flag isn't set, this callback will be ignored. If the code evaluated
actually calls to import(), the result will reject with
ERR_VM_DYNAMIC_IMPORT_CALLBACK_MISSING_FLAG.
The callback importModuleDynamically(specifier, referrer, importAttributes)
has the following signature:

specifier <string> specifier passed to import()
referrer <vm.Script> | <Function> | <vm.SourceTextModule> | <Object>
The referrer is the compiled vm.Script for new vm.Script,
vm.runInThisContext, vm.runInContext and vm.runInNewContext. It's the
compiled Function for vm.compileFunction, the compiled
vm.SourceTextModule for new vm.SourceTextModule, and the context Object
for vm.createContext().
importAttributes <Object> The "with" value passed to the
optionsExpression optional parameter, or an empty object if no value was
provided.
phase <string> The phase of the dynamic import ("source" or "evaluation").
Returns: <Module Namespace Object> | <vm.Module> Returning a vm.Module is
recommended in order to take advantage of error tracking, and to avoid issues
with namespaces that contain then function exports.


// This script must be run with --experimental-vm-modules.
import { Script, SyntheticModule } from 'node:vm';

const script = new Script('import("foo.json", { with: { type: "json" } })', {
  async importModuleDynamically(specifier, referrer, importAttributes) {
    console.log(specifier);  // 'foo.json'
    console.log(referrer);   // The compiled script
    console.log(importAttributes);  // { type: 'json' }
    const m = new SyntheticModule(['bar'], () => { });
    await m.link(() => { });
    m.setExport('bar', { hello: 'world' });
    return m;
  },
});
const result = await script.runInThisContext();
console.log(result);  //  { bar: { hello: 'world' } }// This script must be run with --experimental-vm-modules.
const { Script, SyntheticModule } = require('node:vm');

(async function main() {
  const script = new Script('import("foo.json", { with: { type: "json" } })', {
    async importModuleDynamically(specifier, referrer, importAttributes) {
      console.log(specifier);  // 'foo.json'
      console.log(referrer);   // The compiled script
      console.log(importAttributes);  // { type: 'json' }
      const m = new SyntheticModule(['bar'], () => { });
      await m.link(() => { });
      m.setExport('bar', { hello: 'world' });
      return m;
    },
  });
  const result = await script.runInThisContext();
  console.log(result);  //  { bar: { hello: 'world' } }
})();copy\n\n\n\nNext-10 SurveyWe need your feedback to help us shape Node.jsRun JavaScript EverywhereNode.js® is a free, open-source, cross-platform JavaScript runtime environment
that lets developers create servers, web apps, command line tools and scripts.Download Node.js (LTS)Download Node.js (LTS)Downloads Node.js v22.15.01 with long-term support. Node.js can also be installed via version managers.Want new features sooner? Get Node.js v24.0.11 instead.
Create an HTTP ServerWrite TestsRead and Hash a FileStreams PipelineWork with Threads// server.mjs
import { createServer } from 'node:http';

const server = createServer((req, res) => {
  res.writeHead(200, { 'Content-Type': 'text/plain' });
  res.end('Hello World!\n');
});

// starts a simple http server locally on port 3000
server.listen(3000, '127.0.0.1', () => {
  console.log('Listening on 127.0.0.1:3000');
});

// run with `node server.mjs`
JavaScriptCopy to clipboardLearn more what Node.js is able to offer with our Learning materials.\n\n\n\nNode.js
        
      
      
About this documentation
Usage and example



Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Modules: TypeScript
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
Readline
REPL
Report
Single executable applications
SQLite
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker

    

    
      
        
          Node.js v24.0.1 documentation
          
            
            
          
        
        
          
            Node.js v24.0.1
            
    
      
        
        Table of contents
      

      
About this documentation

Contributing
Stability index
Stability overview
JSON output
System calls and man pages



    
  
            
    
      
        
        Index
      

      
About this documentation
Usage and example

      
        Index
      
    
  


Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Modules: TypeScript
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
Readline
REPL
Report
Single executable applications
SQLite
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker

    
  
            
    
      
        
        Other versions
      
      24.x
23.x
22.x LTS
21.x
20.x LTS
19.x
18.x
17.x
16.x
15.x
14.x
13.x
12.x
11.x
10.x
9.x
8.x
7.x
6.x
5.x
4.x
0.12.x
0.10.x
    
  
            
              
                
                Options
              
        
              
                
                  
                    View on single page
                  
                  
                    View as JSON
                  
                  Edit on GitHub    
                
              
            
          
        
        
      

      Table of contents
About this documentation

Contributing
Stability index
Stability overview
JSON output
System calls and man pages




      
        About this documentation#


Welcome to the official API reference documentation for Node.js!
Node.js is a JavaScript runtime built on the V8 JavaScript engine.
Contributing#
Report errors in this documentation in the issue tracker. See
the contributing guide for directions on how to submit pull requests.
Stability index#

Throughout the documentation are indications of a section's stability. Some APIs
are so proven and so relied upon that they are unlikely to ever change at all.
Others are brand new and experimental, or known to be hazardous.
The stability indexes are as follows:
Stability: 0 - Deprecated. The feature may emit warnings. Backward
compatibility is not guaranteed.

Stability: 1 - Experimental. The feature is not subject to
semantic versioning rules. Non-backward compatible changes or removal may
occur in any future release. Use of the feature is not recommended in
production environments.Experimental features are subdivided into stages:
1.0 - Early development. Experimental features at this stage are unfinished
and subject to substantial change.
1.1 - Active development. Experimental features at this stage are nearing
minimum viability.
1.2 - Release candidate. Experimental features at this stage are hopefully
ready to become stable. No further breaking changes are anticipated but may
still occur in response to user feedback. We encourage user testing and
feedback so that we can know that this feature is ready to be marked as
stable.
Experimental features leave the experimental status typically either by
graduating to stable, or are removed without a deprecation cycle.

Stability: 2 - Stable. Compatibility with the npm ecosystem is a high
priority.

Stability: 3 - Legacy. Although this feature is unlikely to be removed and is
still covered by semantic versioning guarantees, it is no longer actively
maintained, and other alternatives are available.
Features are marked as legacy rather than being deprecated if their use does no
harm, and they are widely relied upon within the npm ecosystem. Bugs found in
legacy features are unlikely to be fixed.
Use caution when making use of Experimental features, particularly when
authoring libraries. Users may not be aware that experimental features are being
used. Bugs or behavior changes may surprise users when Experimental API
modifications occur. To avoid surprises, use of an Experimental feature may need
a command-line flag. Experimental features may also emit a warning.
Stability overview#
APIStabilityAssert(2) StableAsync hooks(1) ExperimentalAsynchronous context tracking(2) StableBuffer(2) StableChild process(2) StableCluster(2) StableConsole(2) StableCrypto(2) StableDiagnostics Channel(2) StableDNS(2) StableDomain(0) DeprecatedFile system(2) StableHTTP(2) StableHTTP/2(2) StableHTTPS(2) StableInspector(2) StableModules: node:module API(1) .2 - Release candidate (asynchronous version) Stability: 1.1 - Active development (synchronous version)Modules: CommonJS modules(2) StableModules: TypeScript(1) .2 - Release candidateOS(2) StablePath(2) StablePerformance measurement APIs(2) StablePunycode(0) DeprecatedQuery string(2) StableReadline(2) StableREPL(2) StableSingle executable applications(1) .1 - Active developmentSQLite(1) .1 - Active development.Stream(2) StableString decoder(2) StableTest runner(2) StableTimers(2) StableTLS (SSL)(2) StableTrace events(1) ExperimentalTTY(2) StableUDP/datagram sockets(2) StableURL(2) StableUtil(2) StableVM (executing JavaScript)(2) StableWeb Crypto API(2) StableWeb Streams API(2) StableWebAssembly System Interface (WASI)(1) ExperimentalWorker threads(2) StableZlib(2) Stable
JSON output#

Added in: v0.6.12

Every .html document has a corresponding .json document. This is for IDEs
and other utilities that consume the documentation.
System calls and man pages#
Node.js functions which wrap a system call will document that. The docs link
to the corresponding man pages which describe how the system call works.
Most Unix system calls have Windows analogues. Still, behavior differences may
be unavoidable.\n\n\n\nNode.js
        
      
      
About this documentation
Usage and example



Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Modules: TypeScript
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
Readline
REPL
Report
Single executable applications
SQLite
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker

    

    
      
        
          Node.js v24.0.1 documentation
          
            
            
          
        
        
          
            Node.js v24.0.1
            
    
      
        
        Table of contents
      

      
Usage and example

Usage
Example



    
  
            
    
      
        
        Index
      

      
About this documentation
Usage and example

      
        Index
      
    
  


Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Modules: TypeScript
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
Readline
REPL
Report
Single executable applications
SQLite
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker

    
  
            
    
      
        
        Other versions
      
      24.x
23.x
22.x LTS
21.x
20.x LTS
19.x
18.x
17.x
16.x
15.x
14.x
13.x
12.x
11.x
10.x
9.x
8.x
7.x
6.x
5.x
4.x
0.12.x
0.10.x
    
  
            
              
                
                Options
              
        
              
                
                  
                    View on single page
                  
                  
                    View as JSON
                  
                  Edit on GitHub    
                
              
            
          
        
        
      

      Table of contents
Usage and example

Usage
Example




      
        Usage and example#
Usage#


node [options] [V8 options] [script.js | -e "script" | - ] [arguments]
Please see the Command-line options document for more information.
Example#
An example of a web server written with Node.js which responds with
'Hello, World!':
Commands in this document start with $ or > to replicate how they would
appear in a user's terminal. Do not include the $ and > characters. They are
there to show the start of each command.
Lines that don't start with $ or > character show the output of the previous
command.
First, make sure to have downloaded and installed Node.js. See
Installing Node.js via package manager for further install information.
Now, create an empty project folder called projects, then navigate into it.
Linux and Mac:
mkdir ~/projects
cd ~/projects copy
Windows CMD:
mkdir %USERPROFILE%\projects
cd %USERPROFILE%\projects copy
Windows PowerShell:
mkdir $env:USERPROFILE\projects
cd $env:USERPROFILE\projects copy
Next, create a new source file in the projects
folder and call it hello-world.js.
Open hello-world.js in any preferred text editor and
paste in the following content:
const http = require('node:http');

const hostname = '127.0.0.1';
const port = 3000;

const server = http.createServer((req, res) => {
  res.statusCode = 200;
  res.setHeader('Content-Type', 'text/plain');
  res.end('Hello, World!\n');
});

server.listen(port, hostname, () => {
  console.log(`Server running at http://${hostname}:${port}/`);
}); copy
Save the file. Then, in the terminal window, to run the hello-world.js file,
enter:
node hello-world.js copy
Output like this should appear in the terminal:
Server running at http://127.0.0.1:3000/ copy
Now, open any preferred web browser and visit http://127.0.0.1:3000.
If the browser displays the string Hello, World!, that indicates
the server is working.\n\n\n\nNode.js
        
      
      
About this documentation
Usage and example



Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Modules: TypeScript
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
Readline
REPL
Report
Single executable applications
SQLite
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker

    

    
      
        
          Node.js v24.0.1 documentation
          
            
            
          
        
        
          
            Node.js v24.0.1
            
    
      
        
        Table of contents
      

      
Assert

Strict assertion mode
Legacy assertion mode
Class: assert.AssertionError

new assert.AssertionError(options)


Class: assert.CallTracker

new assert.CallTracker()
tracker.calls([fn][, exact])
tracker.getCalls(fn)
tracker.report()
tracker.reset([fn])
tracker.verify()


assert(value[, message])
assert.deepEqual(actual, expected[, message])

Comparison details


assert.deepStrictEqual(actual, expected[, message])

Comparison details


assert.doesNotMatch(string, regexp[, message])
assert.doesNotReject(asyncFn[, error][, message])
assert.doesNotThrow(fn[, error][, message])
assert.equal(actual, expected[, message])
assert.fail([message])
assert.fail(actual, expected[, message[, operator[, stackStartFn]]])
assert.ifError(value)
assert.match(string, regexp[, message])
assert.notDeepEqual(actual, expected[, message])
assert.notDeepStrictEqual(actual, expected[, message])
assert.notEqual(actual, expected[, message])
assert.notStrictEqual(actual, expected[, message])
assert.ok(value[, message])
assert.rejects(asyncFn[, error][, message])
assert.strictEqual(actual, expected[, message])
assert.throws(fn[, error][, message])
assert.partialDeepStrictEqual(actual, expected[, message])

Comparison details





    
  
            
    
      
        
        Index
      

      
About this documentation
Usage and example

      
        Index
      
    
  


Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Modules: TypeScript
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
Readline
REPL
Report
Single executable applications
SQLite
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker

    
  
            
    
      
        
        Other versions
      
      24.x
23.x
22.x LTS
21.x
20.x LTS
19.x
18.x
17.x
16.x
15.x
14.x
13.x
12.x
11.x
10.x
9.x
8.x
7.x
6.x
5.x
4.x
0.12.x
0.10.x
    
  
            
              
                
                Options
              
        
              
                
                  
                    View on single page
                  
                  
                    View as JSON
                  
                  Edit on GitHub    
                
              
            
          
        
        
      

      Table of contents
Assert

Strict assertion mode
Legacy assertion mode
Class: assert.AssertionError

new assert.AssertionError(options)


Class: assert.CallTracker

new assert.CallTracker()
tracker.calls([fn][, exact])
tracker.getCalls(fn)
tracker.report()
tracker.reset([fn])
tracker.verify()


assert(value[, message])
assert.deepEqual(actual, expected[, message])

Comparison details


assert.deepStrictEqual(actual, expected[, message])

Comparison details


assert.doesNotMatch(string, regexp[, message])
assert.doesNotReject(asyncFn[, error][, message])
assert.doesNotThrow(fn[, error][, message])
assert.equal(actual, expected[, message])
assert.fail([message])
assert.fail(actual, expected[, message[, operator[, stackStartFn]]])
assert.ifError(value)
assert.match(string, regexp[, message])
assert.notDeepEqual(actual, expected[, message])
assert.notDeepStrictEqual(actual, expected[, message])
assert.notEqual(actual, expected[, message])
assert.notStrictEqual(actual, expected[, message])
assert.ok(value[, message])
assert.rejects(asyncFn[, error][, message])
assert.strictEqual(actual, expected[, message])
assert.throws(fn[, error][, message])
assert.partialDeepStrictEqual(actual, expected[, message])

Comparison details






      
        Assert#

Stability: 2 - Stable
Source Code: lib/assert.js
The node:assert module provides a set of assertion functions for verifying
invariants.
Strict assertion mode#

History

VersionChanges
v15.0.0
Exposed as require('node:assert/strict').
v13.9.0, v12.16.2
Changed "strict mode" to "strict assertion mode" and "legacy mode" to "legacy assertion mode" to avoid confusion with the more usual meaning of "strict mode".
v9.9.0
Added error diffs to the strict assertion mode.
v9.9.0
Added strict assertion mode to the assert module.
v9.9.0
Added in: v9.9.0



In strict assertion mode, non-strict methods behave like their corresponding
strict methods. For example, assert.deepEqual() will behave like
assert.deepStrictEqual().
In strict assertion mode, error messages for objects display a diff. In legacy
assertion mode, error messages for objects display the objects, often truncated.
To use strict assertion mode:

import { strict as assert } from 'node:assert';const assert = require('node:assert').strict;copy

import assert from 'node:assert/strict';const assert = require('node:assert/strict');copy
Example error diff:

import { strict as assert } from 'node:assert';

assert.deepEqual([[[1, 2, 3]], 4, 5], [[[1, 2, '3']], 4, 5]);
// AssertionError: Expected inputs to be strictly deep-equal:
// + actual - expected ... Lines skipped
//
//   [
//     [
// ...
//       2,
// +     3
// -     '3'
//     ],
// ...
//     5
//   ]const assert = require('node:assert/strict');

assert.deepEqual([[[1, 2, 3]], 4, 5], [[[1, 2, '3']], 4, 5]);
// AssertionError: Expected inputs to be strictly deep-equal:
// + actual - expected ... Lines skipped
//
//   [
//     [
// ...
//       2,
// +     3
// -     '3'
//     ],
// ...
//     5
//   ]copy
To deactivate the colors, use the NO_COLOR or NODE_DISABLE_COLORS
environment variables. This will also deactivate the colors in the REPL. For
more on color support in terminal environments, read the tty
getColorDepth() documentation.
Legacy assertion mode#
Legacy assertion mode uses the == operator in:

assert.deepEqual()
assert.equal()
assert.notDeepEqual()
assert.notEqual()

To use legacy assertion mode:

import assert from 'node:assert';const assert = require('node:assert');copy
Legacy assertion mode may have surprising results, especially when using
assert.deepEqual():
// WARNING: This does not throw an AssertionError in legacy assertion mode!
assert.deepEqual(/a/gi, new Date()); copy
Class: assert.AssertionError[src]#

Extends: <errors.Error>

Indicates the failure of an assertion. All errors thrown by the node:assert
module will be instances of the AssertionError class.

new assert.AssertionError(options)#

Added in: v0.1.21


options <Object>

message <string> If provided, the error message is set to this value.
actual <any> The actual property on the error instance.
expected <any> The expected property on the error instance.
operator <string> The operator property on the error instance.
stackStartFn <Function> If provided, the generated stack trace omits
frames before this function.



A subclass of <Error> that indicates the failure of an assertion.
All instances contain the built-in Error properties (message and name)
and:

actual <any> Set to the actual argument for methods such as
assert.strictEqual().
expected <any> Set to the expected value for methods such as
assert.strictEqual().
generatedMessage <boolean> Indicates if the message was auto-generated
(true) or not.
code <string> Value is always ERR_ASSERTION to show that the error is an
assertion error.
operator <string> Set to the passed in operator value.


import assert from 'node:assert';

// Generate an AssertionError to compare the error message later:
const { message } = new assert.AssertionError({
  actual: 1,
  expected: 2,
  operator: 'strictEqual',
});

// Verify error output:
try {
  assert.strictEqual(1, 2);
} catch (err) {
  assert(err instanceof assert.AssertionError);
  assert.strictEqual(err.message, message);
  assert.strictEqual(err.name, 'AssertionError');
  assert.strictEqual(err.actual, 1);
  assert.strictEqual(err.expected, 2);
  assert.strictEqual(err.code, 'ERR_ASSERTION');
  assert.strictEqual(err.operator, 'strictEqual');
  assert.strictEqual(err.generatedMessage, true);
}const assert = require('node:assert');

// Generate an AssertionError to compare the error message later:
const { message } = new assert.AssertionError({
  actual: 1,
  expected: 2,
  operator: 'strictEqual',
});

// Verify error output:
try {
  assert.strictEqual(1, 2);
} catch (err) {
  assert(err instanceof assert.AssertionError);
  assert.strictEqual(err.message, message);
  assert.strictEqual(err.name, 'AssertionError');
  assert.strictEqual(err.actual, 1);
  assert.strictEqual(err.expected, 2);
  assert.strictEqual(err.code, 'ERR_ASSERTION');
  assert.strictEqual(err.operator, 'strictEqual');
  assert.strictEqual(err.generatedMessage, true);
}copy

Class: assert.CallTracker#

History

VersionChanges
v20.1.0
the assert.CallTracker class has been deprecated and will be removed in a future version.
v14.2.0, v12.19.0
Added in: v14.2.0, v12.19.0



Stability: 0 - Deprecated
This feature is deprecated and will be removed in a future version.
Please consider using alternatives such as the
mock helper function.

new assert.CallTracker()#

Added in: v14.2.0, v12.19.0

Creates a new CallTracker object which can be used to track if functions
were called a specific number of times. The tracker.verify() must be called
for the verification to take place. The usual pattern would be to call it in a
process.on('exit') handler.

import assert from 'node:assert';
import process from 'node:process';

const tracker = new assert.CallTracker();

function func() {}

// callsfunc() must be called exactly 1 time before tracker.verify().
const callsfunc = tracker.calls(func, 1);

callsfunc();

// Calls tracker.verify() and verifies if all tracker.calls() functions have
// been called exact times.
process.on('exit', () => {
  tracker.verify();
});const assert = require('node:assert');
const process = require('node:process');

const tracker = new assert.CallTracker();

function func() {}

// callsfunc() must be called exactly 1 time before tracker.verify().
const callsfunc = tracker.calls(func, 1);

callsfunc();

// Calls tracker.verify() and verifies if all tracker.calls() functions have
// been called exact times.
process.on('exit', () => {
  tracker.verify();
});copy

tracker.calls([fn][, exact])#

Added in: v14.2.0, v12.19.0


fn <Function> Default: A no-op function.
exact <number> Default: 1.
Returns: <Function> A function that wraps fn.

The wrapper function is expected to be called exactly exact times. If the
function has not been called exactly exact times when
tracker.verify() is called, then tracker.verify() will throw an
error.

import assert from 'node:assert';

// Creates call tracker.
const tracker = new assert.CallTracker();

function func() {}

// Returns a function that wraps func() that must be called exact times
// before tracker.verify().
const callsfunc = tracker.calls(func);const assert = require('node:assert');

// Creates call tracker.
const tracker = new assert.CallTracker();

function func() {}

// Returns a function that wraps func() that must be called exact times
// before tracker.verify().
const callsfunc = tracker.calls(func);copy

tracker.getCalls(fn)#

Added in: v18.8.0, v16.18.0



fn <Function>


Returns: <Array> An array with all the calls to a tracked function.


Object <Object>

thisArg <Object>
arguments <Array> the arguments passed to the tracked function




import assert from 'node:assert';

const tracker = new assert.CallTracker();

function func() {}
const callsfunc = tracker.calls(func);
callsfunc(1, 2, 3);

assert.deepStrictEqual(tracker.getCalls(callsfunc),
                       [{ thisArg: undefined, arguments: [1, 2, 3] }]);const assert = require('node:assert');

// Creates call tracker.
const tracker = new assert.CallTracker();

function func() {}
const callsfunc = tracker.calls(func);
callsfunc(1, 2, 3);

assert.deepStrictEqual(tracker.getCalls(callsfunc),
                       [{ thisArg: undefined, arguments: [1, 2, 3] }]);copy

tracker.report()#

Added in: v14.2.0, v12.19.0


Returns: <Array> An array of objects containing information about the wrapper
functions returned by tracker.calls().
Object <Object>

message <string>
actual <number> The actual number of times the function was called.
expected <number> The number of times the function was expected to be
called.
operator <string> The name of the function that is wrapped.
stack <Object> A stack trace of the function.



The arrays contains information about the expected and actual number of calls of
the functions that have not been called the expected number of times.

import assert from 'node:assert';

// Creates call tracker.
const tracker = new assert.CallTracker();

function func() {}

// Returns a function that wraps func() that must be called exact times
// before tracker.verify().
const callsfunc = tracker.calls(func, 2);

// Returns an array containing information on callsfunc()
console.log(tracker.report());
// [
//  {
//    message: 'Expected the func function to be executed 2 time(s) but was
//    executed 0 time(s).',
//    actual: 0,
//    expected: 2,
//    operator: 'func',
//    stack: stack trace
//  }
// ]const assert = require('node:assert');

// Creates call tracker.
const tracker = new assert.CallTracker();

function func() {}

// Returns a function that wraps func() that must be called exact times
// before tracker.verify().
const callsfunc = tracker.calls(func, 2);

// Returns an array containing information on callsfunc()
console.log(tracker.report());
// [
//  {
//    message: 'Expected the func function to be executed 2 time(s) but was
//    executed 0 time(s).',
//    actual: 0,
//    expected: 2,
//    operator: 'func',
//    stack: stack trace
//  }
// ]copy

tracker.reset([fn])#

Added in: v18.8.0, v16.18.0


fn <Function> a tracked function to reset.

Reset calls of the call tracker.
If a tracked function is passed as an argument, the calls will be reset for it.
If no arguments are passed, all tracked functions will be reset.

import assert from 'node:assert';

const tracker = new assert.CallTracker();

function func() {}
const callsfunc = tracker.calls(func);

callsfunc();
// Tracker was called once
assert.strictEqual(tracker.getCalls(callsfunc).length, 1);

tracker.reset(callsfunc);
assert.strictEqual(tracker.getCalls(callsfunc).length, 0);const assert = require('node:assert');

const tracker = new assert.CallTracker();

function func() {}
const callsfunc = tracker.calls(func);

callsfunc();
// Tracker was called once
assert.strictEqual(tracker.getCalls(callsfunc).length, 1);

tracker.reset(callsfunc);
assert.strictEqual(tracker.getCalls(callsfunc).length, 0);copy

tracker.verify()#

Added in: v14.2.0, v12.19.0

Iterates through the list of functions passed to
tracker.calls() and will throw an error for functions that
have not been called the expected number of times.

import assert from 'node:assert';

// Creates call tracker.
const tracker = new assert.CallTracker();

function func() {}

// Returns a function that wraps func() that must be called exact times
// before tracker.verify().
const callsfunc = tracker.calls(func, 2);

callsfunc();

// Will throw an error since callsfunc() was only called once.
tracker.verify();const assert = require('node:assert');

// Creates call tracker.
const tracker = new assert.CallTracker();

function func() {}

// Returns a function that wraps func() that must be called exact times
// before tracker.verify().
const callsfunc = tracker.calls(func, 2);

callsfunc();

// Will throw an error since callsfunc() was only called once.
tracker.verify();copy

assert(value[, message])#

Added in: v0.5.9


value <any> The input that is checked for being truthy.
message <string> | <Error>

An alias of assert.ok().
assert.deepEqual(actual, expected[, message])#

History

VersionChanges
v24.0.0
Recursion now stops when either side encounters a circular reference.
v22.2.0, v20.15.0
Error cause and errors properties are now compared as well.
v18.0.0
Regular expressions lastIndex property is now compared as well.
v16.0.0, v14.18.0
In Legacy assertion mode, changed status from Deprecated to Legacy.
v14.0.0
NaN is now treated as being identical if both sides are NaN.
v12.0.0
The type tags are now properly compared and there are a couple minor comparison adjustments to make the check less surprising.
v9.0.0
The Error names and messages are now properly compared.
v8.0.0
The Set and Map content is also compared.
v6.4.0, v4.7.1
Typed array slices are handled correctly now.
v6.1.0, v4.5.0
Objects with circular references can be used as inputs now.
v5.10.1, v4.4.3
Handle non-Uint8Array typed arrays correctly.
v0.1.21
Added in: v0.1.21




actual <any>
expected <any>
message <string> | <Error>

Strict assertion mode
An alias of assert.deepStrictEqual().
Legacy assertion mode
Stability: 3 - Legacy: Use assert.deepStrictEqual() instead.
Tests for deep equality between the actual and expected parameters. Consider
using assert.deepStrictEqual() instead. assert.deepEqual() can have
surprising results.
Deep equality means that the enumerable "own" properties of child objects
are also recursively evaluated by the following rules.

Comparison details#

Primitive values are compared with the == operator,
with the exception of <NaN>. It is treated as being identical in case
both sides are <NaN>.
Type tags of objects should be the same.
Only enumerable "own" properties are considered.
<Error> names, messages, causes, and errors are always compared,
even if these are not enumerable properties.
Object wrappers are compared both as objects and unwrapped values.
Object properties are compared unordered.
<Map> keys and <Set> items are compared unordered.
Recursion stops when both sides differ or either side encounters a circular
reference.
Implementation does not test the [[Prototype]] of
objects.
<Symbol> properties are not compared.
<WeakMap> and <WeakSet> comparison does not rely on their values
but only on their instances.
<RegExp> lastIndex, flags, and source are always compared, even if these
are not enumerable properties.

The following example does not throw an AssertionError because the
primitives are compared using the == operator.

import assert from 'node:assert';
// WARNING: This does not throw an AssertionError!

assert.deepEqual('+00000000', false);const assert = require('node:assert');
// WARNING: This does not throw an AssertionError!

assert.deepEqual('+00000000', false);copy
"Deep" equality means that the enumerable "own" properties of child objects
are evaluated also:

import assert from 'node:assert';

const obj1 = {
  a: {
    b: 1,
  },
};
const obj2 = {
  a: {
    b: 2,
  },
};
const obj3 = {
  a: {
    b: 1,
  },
};
const obj4 = { __proto__: obj1 };

assert.deepEqual(obj1, obj1);
// OK

// Values of b are different:
assert.deepEqual(obj1, obj2);
// AssertionError: { a: { b: 1 } } deepEqual { a: { b: 2 } }

assert.deepEqual(obj1, obj3);
// OK

// Prototypes are ignored:
assert.deepEqual(obj1, obj4);
// AssertionError: { a: { b: 1 } } deepEqual {}const assert = require('node:assert');

const obj1 = {
  a: {
    b: 1,
  },
};
const obj2 = {
  a: {
    b: 2,
  },
};
const obj3 = {
  a: {
    b: 1,
  },
};
const obj4 = { __proto__: obj1 };

assert.deepEqual(obj1, obj1);
// OK

// Values of b are different:
assert.deepEqual(obj1, obj2);
// AssertionError: { a: { b: 1 } } deepEqual { a: { b: 2 } }

assert.deepEqual(obj1, obj3);
// OK

// Prototypes are ignored:
assert.deepEqual(obj1, obj4);
// AssertionError: { a: { b: 1 } } deepEqual {}copy
If the values are not equal, an AssertionError is thrown with a message
property set equal to the value of the message parameter. If the message
parameter is undefined, a default error message is assigned. If the message
parameter is an instance of <Error> then it will be thrown instead of the
AssertionError.

assert.deepStrictEqual(actual, expected[, message])#

History

VersionChanges
v24.0.0
Recursion now stops when either side encounters a circular reference.
v22.2.0, v20.15.0
Error cause and errors properties are now compared as well.
v18.0.0
Regular expressions lastIndex property is now compared as well.
v9.0.0
Enumerable symbol properties are now compared.
v9.0.0
The NaN is now compared using the SameValueZero comparison.
v8.5.0
The Error names and messages are now properly compared.
v8.0.0
The Set and Map content is also compared.
v6.1.0
Objects with circular references can be used as inputs now.
v6.4.0, v4.7.1
Typed array slices are handled correctly now.
v5.10.1, v4.4.3
Handle non-Uint8Array typed arrays correctly.
v1.2.0
Added in: v1.2.0




actual <any>
expected <any>
message <string> | <Error>

Tests for deep equality between the actual and expected parameters.
"Deep" equality means that the enumerable "own" properties of child objects
are recursively evaluated also by the following rules.

Comparison details#

Primitive values are compared using Object.is().
Type tags of objects should be the same.
[[Prototype]] of objects are compared using
the === operator.
Only enumerable "own" properties are considered.
<Error> names, messages, causes, and errors are always compared,
even if these are not enumerable properties.
errors is also compared.
Enumerable own <Symbol> properties are compared as well.
Object wrappers are compared both as objects and unwrapped values.
Object properties are compared unordered.
<Map> keys and <Set> items are compared unordered.
Recursion stops when both sides differ or either side encounters a circular
reference.
<WeakMap> and <WeakSet> instances are not compared structurally.
They are only equal if they reference the same object. Any comparison between
different WeakMap or WeakSet instances will result in inequality,
even if they contain the same entries.
<RegExp> lastIndex, flags, and source are always compared, even if these
are not enumerable properties.


import assert from 'node:assert/strict';

// This fails because 1 !== '1'.
assert.deepStrictEqual({ a: 1 }, { a: '1' });
// AssertionError: Expected inputs to be strictly deep-equal:
// + actual - expected
//
//   {
// +   a: 1
// -   a: '1'
//   }

// The following objects don't have own properties
const date = new Date();
const object = {};
const fakeDate = {};
Object.setPrototypeOf(fakeDate, Date.prototype);

// Different [[Prototype]]:
assert.deepStrictEqual(object, fakeDate);
// AssertionError: Expected inputs to be strictly deep-equal:
// + actual - expected
//
// + {}
// - Date {}

// Different type tags:
assert.deepStrictEqual(date, fakeDate);
// AssertionError: Expected inputs to be strictly deep-equal:
// + actual - expected
//
// + 2018-04-26T00:49:08.604Z
// - Date {}

assert.deepStrictEqual(NaN, NaN);
// OK because Object.is(NaN, NaN) is true.

// Different unwrapped numbers:
assert.deepStrictEqual(new Number(1), new Number(2));
// AssertionError: Expected inputs to be strictly deep-equal:
// + actual - expected
//
// + [Number: 1]
// - [Number: 2]

assert.deepStrictEqual(new String('foo'), Object('foo'));
// OK because the object and the string are identical when unwrapped.

assert.deepStrictEqual(-0, -0);
// OK

// Different zeros:
assert.deepStrictEqual(0, -0);
// AssertionError: Expected inputs to be strictly deep-equal:
// + actual - expected
//
// + 0
// - -0

const symbol1 = Symbol();
const symbol2 = Symbol();
assert.deepStrictEqual({ [symbol1]: 1 }, { [symbol1]: 1 });
// OK, because it is the same symbol on both objects.

assert.deepStrictEqual({ [symbol1]: 1 }, { [symbol2]: 1 });
// AssertionError [ERR_ASSERTION]: Inputs identical but not reference equal:
//
// {
//   Symbol(): 1
// }

const weakMap1 = new WeakMap();
const weakMap2 = new WeakMap();
const obj = {};

weakMap1.set(obj, 'value');
weakMap2.set(obj, 'value');

// Comparing different instances fails, even with same contents
assert.deepStrictEqual(weakMap1, weakMap2);
// AssertionError: Values have same structure but are not reference-equal:
//
// WeakMap {
//   <items unknown>
// }

// Comparing the same instance to itself succeeds
assert.deepStrictEqual(weakMap1, weakMap1);
// OK

const weakSet1 = new WeakSet();
const weakSet2 = new WeakSet();
weakSet1.add(obj);
weakSet2.add(obj);

// Comparing different instances fails, even with same contents
assert.deepStrictEqual(weakSet1, weakSet2);
// AssertionError: Values have same structure but are not reference-equal:
// + actual - expected
//
// WeakSet {
//   <items unknown>
// }

// Comparing the same instance to itself succeeds
assert.deepStrictEqual(weakSet1, weakSet1);
// OKconst assert = require('node:assert/strict');

// This fails because 1 !== '1'.
assert.deepStrictEqual({ a: 1 }, { a: '1' });
// AssertionError: Expected inputs to be strictly deep-equal:
// + actual - expected
//
//   {
// +   a: 1
// -   a: '1'
//   }

// The following objects don't have own properties
const date = new Date();
const object = {};
const fakeDate = {};
Object.setPrototypeOf(fakeDate, Date.prototype);

// Different [[Prototype]]:
assert.deepStrictEqual(object, fakeDate);
// AssertionError: Expected inputs to be strictly deep-equal:
// + actual - expected
//
// + {}
// - Date {}

// Different type tags:
assert.deepStrictEqual(date, fakeDate);
// AssertionError: Expected inputs to be strictly deep-equal:
// + actual - expected
//
// + 2018-04-26T00:49:08.604Z
// - Date {}

assert.deepStrictEqual(NaN, NaN);
// OK because Object.is(NaN, NaN) is true.

// Different unwrapped numbers:
assert.deepStrictEqual(new Number(1), new Number(2));
// AssertionError: Expected inputs to be strictly deep-equal:
// + actual - expected
//
// + [Number: 1]
// - [Number: 2]

assert.deepStrictEqual(new String('foo'), Object('foo'));
// OK because the object and the string are identical when unwrapped.

assert.deepStrictEqual(-0, -0);
// OK

// Different zeros:
assert.deepStrictEqual(0, -0);
// AssertionError: Expected inputs to be strictly deep-equal:
// + actual - expected
//
// + 0
// - -0

const symbol1 = Symbol();
const symbol2 = Symbol();
assert.deepStrictEqual({ [symbol1]: 1 }, { [symbol1]: 1 });
// OK, because it is the same symbol on both objects.

assert.deepStrictEqual({ [symbol1]: 1 }, { [symbol2]: 1 });
// AssertionError [ERR_ASSERTION]: Inputs identical but not reference equal:
//
// {
//   Symbol(): 1
// }

const weakMap1 = new WeakMap();
const weakMap2 = new WeakMap();
const obj = {};

weakMap1.set(obj, 'value');
weakMap2.set(obj, 'value');

// Comparing different instances fails, even with same contents
assert.deepStrictEqual(weakMap1, weakMap2);
// AssertionError: Values have same structure but are not reference-equal:
//
// WeakMap {
//   <items unknown>
// }

// Comparing the same instance to itself succeeds
assert.deepStrictEqual(weakMap1, weakMap1);
// OK

const weakSet1 = new WeakSet();
const weakSet2 = new WeakSet();
weakSet1.add(obj);
weakSet2.add(obj);

// Comparing different instances fails, even with same contents
assert.deepStrictEqual(weakSet1, weakSet2);
// AssertionError: Values have same structure but are not reference-equal:
// + actual - expected
//
// WeakSet {
//   <items unknown>
// }

// Comparing the same instance to itself succeeds
assert.deepStrictEqual(weakSet1, weakSet1);
// OKcopy
If the values are not equal, an AssertionError is thrown with a message
property set equal to the value of the message parameter. If the message
parameter is undefined, a default error message is assigned. If the message
parameter is an instance of <Error> then it will be thrown instead of the
AssertionError.

assert.doesNotMatch(string, regexp[, message])#

History

VersionChanges
v16.0.0
This API is no longer experimental.
v13.6.0, v12.16.0
Added in: v13.6.0, v12.16.0




string <string>
regexp <RegExp>
message <string> | <Error>

Expects the string input not to match the regular expression.

import assert from 'node:assert/strict';

assert.doesNotMatch('I will fail', /fail/);
// AssertionError [ERR_ASSERTION]: The input was expected to not match the ...

assert.doesNotMatch(123, /pass/);
// AssertionError [ERR_ASSERTION]: The "string" argument must be of type string.

assert.doesNotMatch('I will pass', /different/);
// OKconst assert = require('node:assert/strict');

assert.doesNotMatch('I will fail', /fail/);
// AssertionError [ERR_ASSERTION]: The input was expected to not match the ...

assert.doesNotMatch(123, /pass/);
// AssertionError [ERR_ASSERTION]: The "string" argument must be of type string.

assert.doesNotMatch('I will pass', /different/);
// OKcopy
If the values do match, or if the string argument is of another type than
string, an AssertionError is thrown with a message property set equal
to the value of the message parameter. If the message parameter is
undefined, a default error message is assigned. If the message parameter is an
instance of <Error> then it will be thrown instead of the
AssertionError.
assert.doesNotReject(asyncFn[, error][, message])#

Added in: v10.0.0


asyncFn <Function> | <Promise>
error <RegExp> | <Function>
message <string>
Returns: <Promise>

Awaits the asyncFn promise or, if asyncFn is a function, immediately
calls the function and awaits the returned promise to complete. It will then
check that the promise is not rejected.
If asyncFn is a function and it throws an error synchronously,
assert.doesNotReject() will return a rejected Promise with that error. If
the function does not return a promise, assert.doesNotReject() will return a
rejected Promise with an ERR_INVALID_RETURN_VALUE error. In both cases
the error handler is skipped.
Using assert.doesNotReject() is actually not useful because there is little
benefit in catching a rejection and then rejecting it again. Instead, consider
adding a comment next to the specific code path that should not reject and keep
error messages as expressive as possible.
If specified, error can be a Class, <RegExp> or a validation
function. See assert.throws() for more details.
Besides the async nature to await the completion behaves identically to
assert.doesNotThrow().

import assert from 'node:assert/strict';

await assert.doesNotReject(
  async () => {
    throw new TypeError('Wrong value');
  },
  SyntaxError,
);const assert = require('node:assert/strict');

(async () => {
  await assert.doesNotReject(
    async () => {
      throw new TypeError('Wrong value');
    },
    SyntaxError,
  );
})();copy

import assert from 'node:assert/strict';

assert.doesNotReject(Promise.reject(new TypeError('Wrong value')))
  .then(() => {
    // ...
  });const assert = require('node:assert/strict');

assert.doesNotReject(Promise.reject(new TypeError('Wrong value')))
  .then(() => {
    // ...
  });copy
assert.doesNotThrow(fn[, error][, message])#

History

VersionChanges
v5.11.0, v4.4.5
The message parameter is respected now.
v4.2.0
The error parameter can now be an arrow function.
v0.1.21
Added in: v0.1.21




fn <Function>
error <RegExp> | <Function>
message <string>

Asserts that the function fn does not throw an error.
Using assert.doesNotThrow() is actually not useful because there
is no benefit in catching an error and then rethrowing it. Instead, consider
adding a comment next to the specific code path that should not throw and keep
error messages as expressive as possible.
When assert.doesNotThrow() is called, it will immediately call the fn
function.
If an error is thrown and it is the same type as that specified by the error
parameter, then an AssertionError is thrown. If the error is of a
different type, or if the error parameter is undefined, the error is
propagated back to the caller.
If specified, error can be a Class, <RegExp>, or a validation
function. See assert.throws() for more details.
The following, for instance, will throw the <TypeError> because there is no
matching error type in the assertion:

import assert from 'node:assert/strict';

assert.doesNotThrow(
  () => {
    throw new TypeError('Wrong value');
  },
  SyntaxError,
);const assert = require('node:assert/strict');

assert.doesNotThrow(
  () => {
    throw new TypeError('Wrong value');
  },
  SyntaxError,
);copy
However, the following will result in an AssertionError with the message
'Got unwanted exception...':

import assert from 'node:assert/strict';

assert.doesNotThrow(
  () => {
    throw new TypeError('Wrong value');
  },
  TypeError,
);const assert = require('node:assert/strict');

assert.doesNotThrow(
  () => {
    throw new TypeError('Wrong value');
  },
  TypeError,
);copy
If an AssertionError is thrown and a value is provided for the message
parameter, the value of message will be appended to the AssertionError
message:

import assert from 'node:assert/strict';

assert.doesNotThrow(
  () => {
    throw new TypeError('Wrong value');
  },
  /Wrong value/,
  'Whoops',
);
// Throws: AssertionError: Got unwanted exception: Whoopsconst assert = require('node:assert/strict');

assert.doesNotThrow(
  () => {
    throw new TypeError('Wrong value');
  },
  /Wrong value/,
  'Whoops',
);
// Throws: AssertionError: Got unwanted exception: Whoopscopy
assert.equal(actual, expected[, message])#

History

VersionChanges
v16.0.0, v14.18.0
In Legacy assertion mode, changed status from Deprecated to Legacy.
v14.0.0
NaN is now treated as being identical if both sides are NaN.
v0.1.21
Added in: v0.1.21




actual <any>
expected <any>
message <string> | <Error>

Strict assertion mode
An alias of assert.strictEqual().
Legacy assertion mode
Stability: 3 - Legacy: Use assert.strictEqual() instead.
Tests shallow, coercive equality between the actual and expected parameters
using the == operator. NaN is specially handled
and treated as being identical if both sides are NaN.

import assert from 'node:assert';

assert.equal(1, 1);
// OK, 1 == 1
assert.equal(1, '1');
// OK, 1 == '1'
assert.equal(NaN, NaN);
// OK

assert.equal(1, 2);
// AssertionError: 1 == 2
assert.equal({ a: { b: 1 } }, { a: { b: 1 } });
// AssertionError: { a: { b: 1 } } == { a: { b: 1 } }const assert = require('node:assert');

assert.equal(1, 1);
// OK, 1 == 1
assert.equal(1, '1');
// OK, 1 == '1'
assert.equal(NaN, NaN);
// OK

assert.equal(1, 2);
// AssertionError: 1 == 2
assert.equal({ a: { b: 1 } }, { a: { b: 1 } });
// AssertionError: { a: { b: 1 } } == { a: { b: 1 } }copy
If the values are not equal, an AssertionError is thrown with a message
property set equal to the value of the message parameter. If the message
parameter is undefined, a default error message is assigned. If the message
parameter is an instance of <Error> then it will be thrown instead of the
AssertionError.
assert.fail([message])#

Added in: v0.1.21


message <string> | <Error> Default: 'Failed'

Throws an AssertionError with the provided error message or a default
error message. If the message parameter is an instance of <Error> then
it will be thrown instead of the AssertionError.

import assert from 'node:assert/strict';

assert.fail();
// AssertionError [ERR_ASSERTION]: Failed

assert.fail('boom');
// AssertionError [ERR_ASSERTION]: boom

assert.fail(new TypeError('need array'));
// TypeError: need arrayconst assert = require('node:assert/strict');

assert.fail();
// AssertionError [ERR_ASSERTION]: Failed

assert.fail('boom');
// AssertionError [ERR_ASSERTION]: boom

assert.fail(new TypeError('need array'));
// TypeError: need arraycopy
Using assert.fail() with more than two arguments is possible but deprecated.
See below for further details.
assert.fail(actual, expected[, message[, operator[, stackStartFn]]])#

History

VersionChanges
v10.0.0
Calling assert.fail() with more than one argument is deprecated and emits a warning.
v0.1.21
Added in: v0.1.21



Stability: 0 - Deprecated: Use assert.fail([message]) or other assert
functions instead.

actual <any>
expected <any>
message <string> | <Error>
operator <string> Default: '!='
stackStartFn <Function> Default: assert.fail

If message is falsy, the error message is set as the values of actual and
expected separated by the provided operator. If just the two actual and
expected arguments are provided, operator will default to '!='. If
message is provided as third argument it will be used as the error message and
the other arguments will be stored as properties on the thrown object. If
stackStartFn is provided, all stack frames above that function will be
removed from stacktrace (see Error.captureStackTrace). If no arguments are
given, the default message Failed will be used.

import assert from 'node:assert/strict';

assert.fail('a', 'b');
// AssertionError [ERR_ASSERTION]: 'a' != 'b'

assert.fail(1, 2, undefined, '>');
// AssertionError [ERR_ASSERTION]: 1 > 2

assert.fail(1, 2, 'fail');
// AssertionError [ERR_ASSERTION]: fail

assert.fail(1, 2, 'whoops', '>');
// AssertionError [ERR_ASSERTION]: whoops

assert.fail(1, 2, new TypeError('need array'));
// TypeError: need arrayconst assert = require('node:assert/strict');

assert.fail('a', 'b');
// AssertionError [ERR_ASSERTION]: 'a' != 'b'

assert.fail(1, 2, undefined, '>');
// AssertionError [ERR_ASSERTION]: 1 > 2

assert.fail(1, 2, 'fail');
// AssertionError [ERR_ASSERTION]: fail

assert.fail(1, 2, 'whoops', '>');
// AssertionError [ERR_ASSERTION]: whoops

assert.fail(1, 2, new TypeError('need array'));
// TypeError: need arraycopy
In the last three cases actual, expected, and operator have no
influence on the error message.
Example use of stackStartFn for truncating the exception's stacktrace:

import assert from 'node:assert/strict';

function suppressFrame() {
  assert.fail('a', 'b', undefined, '!==', suppressFrame);
}
suppressFrame();
// AssertionError [ERR_ASSERTION]: 'a' !== 'b'
//     at repl:1:1
//     at ContextifyScript.Script.runInThisContext (vm.js:44:33)
//     ...const assert = require('node:assert/strict');

function suppressFrame() {
  assert.fail('a', 'b', undefined, '!==', suppressFrame);
}
suppressFrame();
// AssertionError [ERR_ASSERTION]: 'a' !== 'b'
//     at repl:1:1
//     at ContextifyScript.Script.runInThisContext (vm.js:44:33)
//     ...copy
assert.ifError(value)#

History

VersionChanges
v10.0.0
Instead of throwing the original error it is now wrapped into an [AssertionError][] that contains the full stack trace.
v10.0.0
Value may now only be undefined or null. Before all falsy values were handled the same as null and did not throw.
v0.1.97
Added in: v0.1.97




value <any>

Throws value if value is not undefined or null. This is useful when
testing the error argument in callbacks. The stack trace contains all frames
from the error passed to ifError() including the potential new frames for
ifError() itself.

import assert from 'node:assert/strict';

assert.ifError(null);
// OK
assert.ifError(0);
// AssertionError [ERR_ASSERTION]: ifError got unwanted exception: 0
assert.ifError('error');
// AssertionError [ERR_ASSERTION]: ifError got unwanted exception: 'error'
assert.ifError(new Error());
// AssertionError [ERR_ASSERTION]: ifError got unwanted exception: Error

// Create some random error frames.
let err;
(function errorFrame() {
  err = new Error('test error');
})();

(function ifErrorFrame() {
  assert.ifError(err);
})();
// AssertionError [ERR_ASSERTION]: ifError got unwanted exception: test error
//     at ifErrorFrame
//     at errorFrameconst assert = require('node:assert/strict');

assert.ifError(null);
// OK
assert.ifError(0);
// AssertionError [ERR_ASSERTION]: ifError got unwanted exception: 0
assert.ifError('error');
// AssertionError [ERR_ASSERTION]: ifError got unwanted exception: 'error'
assert.ifError(new Error());
// AssertionError [ERR_ASSERTION]: ifError got unwanted exception: Error

// Create some random error frames.
let err;
(function errorFrame() {
  err = new Error('test error');
})();

(function ifErrorFrame() {
  assert.ifError(err);
})();
// AssertionError [ERR_ASSERTION]: ifError got unwanted exception: test error
//     at ifErrorFrame
//     at errorFramecopy
assert.match(string, regexp[, message])#

History

VersionChanges
v16.0.0
This API is no longer experimental.
v13.6.0, v12.16.0
Added in: v13.6.0, v12.16.0




string <string>
regexp <RegExp>
message <string> | <Error>

Expects the string input to match the regular expression.

import assert from 'node:assert/strict';

assert.match('I will fail', /pass/);
// AssertionError [ERR_ASSERTION]: The input did not match the regular ...

assert.match(123, /pass/);
// AssertionError [ERR_ASSERTION]: The "string" argument must be of type string.

assert.match('I will pass', /pass/);
// OKconst assert = require('node:assert/strict');

assert.match('I will fail', /pass/);
// AssertionError [ERR_ASSERTION]: The input did not match the regular ...

assert.match(123, /pass/);
// AssertionError [ERR_ASSERTION]: The "string" argument must be of type string.

assert.match('I will pass', /pass/);
// OKcopy
If the values do not match, or if the string argument is of another type than
string, an AssertionError is thrown with a message property set equal
to the value of the message parameter. If the message parameter is
undefined, a default error message is assigned. If the message parameter is an
instance of <Error> then it will be thrown instead of the
AssertionError.
assert.notDeepEqual(actual, expected[, message])#

History

VersionChanges
v16.0.0, v14.18.0
In Legacy assertion mode, changed status from Deprecated to Legacy.
v14.0.0
NaN is now treated as being identical if both sides are NaN.
v9.0.0
The Error names and messages are now properly compared.
v8.0.0
The Set and Map content is also compared.
v6.4.0, v4.7.1
Typed array slices are handled correctly now.
v6.1.0, v4.5.0
Objects with circular references can be used as inputs now.
v5.10.1, v4.4.3
Handle non-Uint8Array typed arrays correctly.
v0.1.21
Added in: v0.1.21




actual <any>
expected <any>
message <string> | <Error>

Strict assertion mode
An alias of assert.notDeepStrictEqual().
Legacy assertion mode
Stability: 3 - Legacy: Use assert.notDeepStrictEqual() instead.
Tests for any deep inequality. Opposite of assert.deepEqual().

import assert from 'node:assert';

const obj1 = {
  a: {
    b: 1,
  },
};
const obj2 = {
  a: {
    b: 2,
  },
};
const obj3 = {
  a: {
    b: 1,
  },
};
const obj4 = { __proto__: obj1 };

assert.notDeepEqual(obj1, obj1);
// AssertionError: { a: { b: 1 } } notDeepEqual { a: { b: 1 } }

assert.notDeepEqual(obj1, obj2);
// OK

assert.notDeepEqual(obj1, obj3);
// AssertionError: { a: { b: 1 } } notDeepEqual { a: { b: 1 } }

assert.notDeepEqual(obj1, obj4);
// OKconst assert = require('node:assert');

const obj1 = {
  a: {
    b: 1,
  },
};
const obj2 = {
  a: {
    b: 2,
  },
};
const obj3 = {
  a: {
    b: 1,
  },
};
const obj4 = { __proto__: obj1 };

assert.notDeepEqual(obj1, obj1);
// AssertionError: { a: { b: 1 } } notDeepEqual { a: { b: 1 } }

assert.notDeepEqual(obj1, obj2);
// OK

assert.notDeepEqual(obj1, obj3);
// AssertionError: { a: { b: 1 } } notDeepEqual { a: { b: 1 } }

assert.notDeepEqual(obj1, obj4);
// OKcopy
If the values are deeply equal, an AssertionError is thrown with a
message property set equal to the value of the message parameter. If the
message parameter is undefined, a default error message is assigned. If the
message parameter is an instance of <Error> then it will be thrown
instead of the AssertionError.
assert.notDeepStrictEqual(actual, expected[, message])#

History

VersionChanges
v9.0.0
The -0 and +0 are not considered equal anymore.
v9.0.0
The NaN is now compared using the SameValueZero comparison.
v9.0.0
The Error names and messages are now properly compared.
v8.0.0
The Set and Map content is also compared.
v6.1.0
Objects with circular references can be used as inputs now.
v6.4.0, v4.7.1
Typed array slices are handled correctly now.
v5.10.1, v4.4.3
Handle non-Uint8Array typed arrays correctly.
v1.2.0
Added in: v1.2.0




actual <any>
expected <any>
message <string> | <Error>

Tests for deep strict inequality. Opposite of assert.deepStrictEqual().

import assert from 'node:assert/strict';

assert.notDeepStrictEqual({ a: 1 }, { a: '1' });
// OKconst assert = require('node:assert/strict');

assert.notDeepStrictEqual({ a: 1 }, { a: '1' });
// OKcopy
If the values are deeply and strictly equal, an AssertionError is thrown
with a message property set equal to the value of the message parameter. If
the message parameter is undefined, a default error message is assigned. If
the message parameter is an instance of <Error> then it will be thrown
instead of the AssertionError.
assert.notEqual(actual, expected[, message])#

History

VersionChanges
v16.0.0, v14.18.0
In Legacy assertion mode, changed status from Deprecated to Legacy.
v14.0.0
NaN is now treated as being identical if both sides are NaN.
v0.1.21
Added in: v0.1.21




actual <any>
expected <any>
message <string> | <Error>

Strict assertion mode
An alias of assert.notStrictEqual().
Legacy assertion mode
Stability: 3 - Legacy: Use assert.notStrictEqual() instead.
Tests shallow, coercive inequality with the != operator. NaN is
specially handled and treated as being identical if both sides are NaN.

import assert from 'node:assert';

assert.notEqual(1, 2);
// OK

assert.notEqual(1, 1);
// AssertionError: 1 != 1

assert.notEqual(1, '1');
// AssertionError: 1 != '1'const assert = require('node:assert');

assert.notEqual(1, 2);
// OK

assert.notEqual(1, 1);
// AssertionError: 1 != 1

assert.notEqual(1, '1');
// AssertionError: 1 != '1'copy
If the values are equal, an AssertionError is thrown with a message
property set equal to the value of the message parameter. If the message
parameter is undefined, a default error message is assigned. If the message
parameter is an instance of <Error> then it will be thrown instead of the
AssertionError.
assert.notStrictEqual(actual, expected[, message])#

History

VersionChanges
v10.0.0
Used comparison changed from Strict Equality to Object.is().
v0.1.21
Added in: v0.1.21




actual <any>
expected <any>
message <string> | <Error>

Tests strict inequality between the actual and expected parameters as
determined by Object.is().

import assert from 'node:assert/strict';

assert.notStrictEqual(1, 2);
// OK

assert.notStrictEqual(1, 1);
// AssertionError [ERR_ASSERTION]: Expected "actual" to be strictly unequal to:
//
// 1

assert.notStrictEqual(1, '1');
// OKconst assert = require('node:assert/strict');

assert.notStrictEqual(1, 2);
// OK

assert.notStrictEqual(1, 1);
// AssertionError [ERR_ASSERTION]: Expected "actual" to be strictly unequal to:
//
// 1

assert.notStrictEqual(1, '1');
// OKcopy
If the values are strictly equal, an AssertionError is thrown with a
message property set equal to the value of the message parameter. If the
message parameter is undefined, a default error message is assigned. If the
message parameter is an instance of <Error> then it will be thrown
instead of the AssertionError.
assert.ok(value[, message])#

History

VersionChanges
v10.0.0
The assert.ok() (no arguments) will now use a predefined error message.
v0.1.21
Added in: v0.1.21




value <any>
message <string> | <Error>

Tests if value is truthy. It is equivalent to
assert.equal(!!value, true, message).
If value is not truthy, an AssertionError is thrown with a message
property set equal to the value of the message parameter. If the message
parameter is undefined, a default error message is assigned. If the message
parameter is an instance of <Error> then it will be thrown instead of the
AssertionError.
If no arguments are passed in at all message will be set to the string:
'No value argument passed to `assert.ok()`'.
Be aware that in the repl the error message will be different to the one
thrown in a file! See below for further details.

import assert from 'node:assert/strict';

assert.ok(true);
// OK
assert.ok(1);
// OK

assert.ok();
// AssertionError: No value argument passed to `assert.ok()`

assert.ok(false, 'it\'s false');
// AssertionError: it's false

// In the repl:
assert.ok(typeof 123 === 'string');
// AssertionError: false == true

// In a file (e.g. test.js):
assert.ok(typeof 123 === 'string');
// AssertionError: The expression evaluated to a falsy value:
//
//   assert.ok(typeof 123 === 'string')

assert.ok(false);
// AssertionError: The expression evaluated to a falsy value:
//
//   assert.ok(false)

assert.ok(0);
// AssertionError: The expression evaluated to a falsy value:
//
//   assert.ok(0)const assert = require('node:assert/strict');

assert.ok(true);
// OK
assert.ok(1);
// OK

assert.ok();
// AssertionError: No value argument passed to `assert.ok()`

assert.ok(false, 'it\'s false');
// AssertionError: it's false

// In the repl:
assert.ok(typeof 123 === 'string');
// AssertionError: false == true

// In a file (e.g. test.js):
assert.ok(typeof 123 === 'string');
// AssertionError: The expression evaluated to a falsy value:
//
//   assert.ok(typeof 123 === 'string')

assert.ok(false);
// AssertionError: The expression evaluated to a falsy value:
//
//   assert.ok(false)

assert.ok(0);
// AssertionError: The expression evaluated to a falsy value:
//
//   assert.ok(0)copy

import assert from 'node:assert/strict';

// Using `assert()` works the same:
assert(0);
// AssertionError: The expression evaluated to a falsy value:
//
//   assert(0)const assert = require('node:assert');

// Using `assert()` works the same:
assert(0);
// AssertionError: The expression evaluated to a falsy value:
//
//   assert(0)copy
assert.rejects(asyncFn[, error][, message])#

Added in: v10.0.0


asyncFn <Function> | <Promise>
error <RegExp> | <Function> | <Object> | <Error>
message <string>
Returns: <Promise>

Awaits the asyncFn promise or, if asyncFn is a function, immediately
calls the function and awaits the returned promise to complete. It will then
check that the promise is rejected.
If asyncFn is a function and it throws an error synchronously,
assert.rejects() will return a rejected Promise with that error. If the
function does not return a promise, assert.rejects() will return a rejected
Promise with an ERR_INVALID_RETURN_VALUE error. In both cases the error
handler is skipped.
Besides the async nature to await the completion behaves identically to
assert.throws().
If specified, error can be a Class, <RegExp>, a validation function,
an object where each property will be tested for, or an instance of error where
each property will be tested for including the non-enumerable message and
name properties.
If specified, message will be the message provided by the AssertionError
if the asyncFn fails to reject.

import assert from 'node:assert/strict';

await assert.rejects(
  async () => {
    throw new TypeError('Wrong value');
  },
  {
    name: 'TypeError',
    message: 'Wrong value',
  },
);const assert = require('node:assert/strict');

(async () => {
  await assert.rejects(
    async () => {
      throw new TypeError('Wrong value');
    },
    {
      name: 'TypeError',
      message: 'Wrong value',
    },
  );
})();copy

import assert from 'node:assert/strict';

await assert.rejects(
  async () => {
    throw new TypeError('Wrong value');
  },
  (err) => {
    assert.strictEqual(err.name, 'TypeError');
    assert.strictEqual(err.message, 'Wrong value');
    return true;
  },
);const assert = require('node:assert/strict');

(async () => {
  await assert.rejects(
    async () => {
      throw new TypeError('Wrong value');
    },
    (err) => {
      assert.strictEqual(err.name, 'TypeError');
      assert.strictEqual(err.message, 'Wrong value');
      return true;
    },
  );
})();copy

import assert from 'node:assert/strict';

assert.rejects(
  Promise.reject(new Error('Wrong value')),
  Error,
).then(() => {
  // ...
});const assert = require('node:assert/strict');

assert.rejects(
  Promise.reject(new Error('Wrong value')),
  Error,
).then(() => {
  // ...
});copy
error cannot be a string. If a string is provided as the second
argument, then error is assumed to be omitted and the string will be used for
message instead. This can lead to easy-to-miss mistakes. Please read the
example in assert.throws() carefully if using a string as the second
argument gets considered.
assert.strictEqual(actual, expected[, message])#

History

VersionChanges
v10.0.0
Used comparison changed from Strict Equality to Object.is().
v0.1.21
Added in: v0.1.21




actual <any>
expected <any>
message <string> | <Error>

Tests strict equality between the actual and expected parameters as
determined by Object.is().

import assert from 'node:assert/strict';

assert.strictEqual(1, 2);
// AssertionError [ERR_ASSERTION]: Expected inputs to be strictly equal:
//
// 1 !== 2

assert.strictEqual(1, 1);
// OK

assert.strictEqual('Hello foobar', 'Hello World!');
// AssertionError [ERR_ASSERTION]: Expected inputs to be strictly equal:
// + actual - expected
//
// + 'Hello foobar'
// - 'Hello World!'
//          ^

const apples = 1;
const oranges = 2;
assert.strictEqual(apples, oranges, `apples ${apples} !== oranges ${oranges}`);
// AssertionError [ERR_ASSERTION]: apples 1 !== oranges 2

assert.strictEqual(1, '1', new TypeError('Inputs are not identical'));
// TypeError: Inputs are not identicalconst assert = require('node:assert/strict');

assert.strictEqual(1, 2);
// AssertionError [ERR_ASSERTION]: Expected inputs to be strictly equal:
//
// 1 !== 2

assert.strictEqual(1, 1);
// OK

assert.strictEqual('Hello foobar', 'Hello World!');
// AssertionError [ERR_ASSERTION]: Expected inputs to be strictly equal:
// + actual - expected
//
// + 'Hello foobar'
// - 'Hello World!'
//          ^

const apples = 1;
const oranges = 2;
assert.strictEqual(apples, oranges, `apples ${apples} !== oranges ${oranges}`);
// AssertionError [ERR_ASSERTION]: apples 1 !== oranges 2

assert.strictEqual(1, '1', new TypeError('Inputs are not identical'));
// TypeError: Inputs are not identicalcopy
If the values are not strictly equal, an AssertionError is thrown with a
message property set equal to the value of the message parameter. If the
message parameter is undefined, a default error message is assigned. If the
message parameter is an instance of <Error> then it will be thrown
instead of the AssertionError.
assert.throws(fn[, error][, message])#

History

VersionChanges
v10.2.0
The error parameter can be an object containing regular expressions now.
v9.9.0
The error parameter can now be an object as well.
v4.2.0
The error parameter can now be an arrow function.
v0.1.21
Added in: v0.1.21




fn <Function>
error <RegExp> | <Function> | <Object> | <Error>
message <string>

Expects the function fn to throw an error.
If specified, error can be a Class, <RegExp>, a validation function,
a validation object where each property will be tested for strict deep equality,
or an instance of error where each property will be tested for strict deep
equality including the non-enumerable message and name properties. When
using an object, it is also possible to use a regular expression, when
validating against a string property. See below for examples.
If specified, message will be appended to the message provided by the
AssertionError if the fn call fails to throw or in case the error validation
fails.
Custom validation object/error instance:

import assert from 'node:assert/strict';

const err = new TypeError('Wrong value');
err.code = 404;
err.foo = 'bar';
err.info = {
  nested: true,
  baz: 'text',
};
err.reg = /abc/i;

assert.throws(
  () => {
    throw err;
  },
  {
    name: 'TypeError',
    message: 'Wrong value',
    info: {
      nested: true,
      baz: 'text',
    },
    // Only properties on the validation object will be tested for.
    // Using nested objects requires all properties to be present. Otherwise
    // the validation is going to fail.
  },
);

// Using regular expressions to validate error properties:
assert.throws(
  () => {
    throw err;
  },
  {
    // The `name` and `message` properties are strings and using regular
    // expressions on those will match against the string. If they fail, an
    // error is thrown.
    name: /^TypeError$/,
    message: /Wrong/,
    foo: 'bar',
    info: {
      nested: true,
      // It is not possible to use regular expressions for nested properties!
      baz: 'text',
    },
    // The `reg` property contains a regular expression and only if the
    // validation object contains an identical regular expression, it is going
    // to pass.
    reg: /abc/i,
  },
);

// Fails due to the different `message` and `name` properties:
assert.throws(
  () => {
    const otherErr = new Error('Not found');
    // Copy all enumerable properties from `err` to `otherErr`.
    for (const [key, value] of Object.entries(err)) {
      otherErr[key] = value;
    }
    throw otherErr;
  },
  // The error's `message` and `name` properties will also be checked when using
  // an error as validation object.
  err,
);const assert = require('node:assert/strict');

const err = new TypeError('Wrong value');
err.code = 404;
err.foo = 'bar';
err.info = {
  nested: true,
  baz: 'text',
};
err.reg = /abc/i;

assert.throws(
  () => {
    throw err;
  },
  {
    name: 'TypeError',
    message: 'Wrong value',
    info: {
      nested: true,
      baz: 'text',
    },
    // Only properties on the validation object will be tested for.
    // Using nested objects requires all properties to be present. Otherwise
    // the validation is going to fail.
  },
);

// Using regular expressions to validate error properties:
assert.throws(
  () => {
    throw err;
  },
  {
    // The `name` and `message` properties are strings and using regular
    // expressions on those will match against the string. If they fail, an
    // error is thrown.
    name: /^TypeError$/,
    message: /Wrong/,
    foo: 'bar',
    info: {
      nested: true,
      // It is not possible to use regular expressions for nested properties!
      baz: 'text',
    },
    // The `reg` property contains a regular expression and only if the
    // validation object contains an identical regular expression, it is going
    // to pass.
    reg: /abc/i,
  },
);

// Fails due to the different `message` and `name` properties:
assert.throws(
  () => {
    const otherErr = new Error('Not found');
    // Copy all enumerable properties from `err` to `otherErr`.
    for (const [key, value] of Object.entries(err)) {
      otherErr[key] = value;
    }
    throw otherErr;
  },
  // The error's `message` and `name` properties will also be checked when using
  // an error as validation object.
  err,
);copy
Validate instanceof using constructor:

import assert from 'node:assert/strict';

assert.throws(
  () => {
    throw new Error('Wrong value');
  },
  Error,
);const assert = require('node:assert/strict');

assert.throws(
  () => {
    throw new Error('Wrong value');
  },
  Error,
);copy
Validate error message using <RegExp>:
Using a regular expression runs .toString on the error object, and will
therefore also include the error name.

import assert from 'node:assert/strict';

assert.throws(
  () => {
    throw new Error('Wrong value');
  },
  /^Error: Wrong value$/,
);const assert = require('node:assert/strict');

assert.throws(
  () => {
    throw new Error('Wrong value');
  },
  /^Error: Wrong value$/,
);copy
Custom error validation:
The function must return true to indicate all internal validations passed.
It will otherwise fail with an AssertionError.

import assert from 'node:assert/strict';

assert.throws(
  () => {
    throw new Error('Wrong value');
  },
  (err) => {
    assert(err instanceof Error);
    assert(/value/.test(err));
    // Avoid returning anything from validation functions besides `true`.
    // Otherwise, it's not clear what part of the validation failed. Instead,
    // throw an error about the specific validation that failed (as done in this
    // example) and add as much helpful debugging information to that error as
    // possible.
    return true;
  },
  'unexpected error',
);const assert = require('node:assert/strict');

assert.throws(
  () => {
    throw new Error('Wrong value');
  },
  (err) => {
    assert(err instanceof Error);
    assert(/value/.test(err));
    // Avoid returning anything from validation functions besides `true`.
    // Otherwise, it's not clear what part of the validation failed. Instead,
    // throw an error about the specific validation that failed (as done in this
    // example) and add as much helpful debugging information to that error as
    // possible.
    return true;
  },
  'unexpected error',
);copy
error cannot be a string. If a string is provided as the second
argument, then error is assumed to be omitted and the string will be used for
message instead. This can lead to easy-to-miss mistakes. Using the same
message as the thrown error message is going to result in an
ERR_AMBIGUOUS_ARGUMENT error. Please read the example below carefully if using
a string as the second argument gets considered:

import assert from 'node:assert/strict';

function throwingFirst() {
  throw new Error('First');
}

function throwingSecond() {
  throw new Error('Second');
}

function notThrowing() {}

// The second argument is a string and the input function threw an Error.
// The first case will not throw as it does not match for the error message
// thrown by the input function!
assert.throws(throwingFirst, 'Second');
// In the next example the message has no benefit over the message from the
// error and since it is not clear if the user intended to actually match
// against the error message, Node.js throws an `ERR_AMBIGUOUS_ARGUMENT` error.
assert.throws(throwingSecond, 'Second');
// TypeError [ERR_AMBIGUOUS_ARGUMENT]

// The string is only used (as message) in case the function does not throw:
assert.throws(notThrowing, 'Second');
// AssertionError [ERR_ASSERTION]: Missing expected exception: Second

// If it was intended to match for the error message do this instead:
// It does not throw because the error messages match.
assert.throws(throwingSecond, /Second$/);

// If the error message does not match, an AssertionError is thrown.
assert.throws(throwingFirst, /Second$/);
// AssertionError [ERR_ASSERTION]const assert = require('node:assert/strict');

function throwingFirst() {
  throw new Error('First');
}

function throwingSecond() {
  throw new Error('Second');
}

function notThrowing() {}

// The second argument is a string and the input function threw an Error.
// The first case will not throw as it does not match for the error message
// thrown by the input function!
assert.throws(throwingFirst, 'Second');
// In the next example the message has no benefit over the message from the
// error and since it is not clear if the user intended to actually match
// against the error message, Node.js throws an `ERR_AMBIGUOUS_ARGUMENT` error.
assert.throws(throwingSecond, 'Second');
// TypeError [ERR_AMBIGUOUS_ARGUMENT]

// The string is only used (as message) in case the function does not throw:
assert.throws(notThrowing, 'Second');
// AssertionError [ERR_ASSERTION]: Missing expected exception: Second

// If it was intended to match for the error message do this instead:
// It does not throw because the error messages match.
assert.throws(throwingSecond, /Second$/);

// If the error message does not match, an AssertionError is thrown.
assert.throws(throwingFirst, /Second$/);
// AssertionError [ERR_ASSERTION]copy
Due to the confusing error-prone notation, avoid a string as the second
argument.
assert.partialDeepStrictEqual(actual, expected[, message])#

History

VersionChanges
v24.0.0
partialDeepStrictEqual is now Stable. Previously, it had been Experimental.
v23.4.0, v22.13.0
Added in: v23.4.0, v22.13.0




actual <any>
expected <any>
message <string> | <Error>

Tests for partial deep equality between the actual and expected parameters.
"Deep" equality means that the enumerable "own" properties of child objects
are recursively evaluated also by the following rules. "Partial" equality means
that only properties that exist on the expected parameter are going to be
compared.
This method always passes the same test cases as assert.deepStrictEqual(),
behaving as a super set of it.

Comparison details#

Primitive values are compared using Object.is().
Type tags of objects should be the same.
[[Prototype]] of objects are not compared.
Only enumerable "own" properties are considered.
<Error> names, messages, causes, and errors are always compared,
even if these are not enumerable properties.
errors is also compared.
Enumerable own <Symbol> properties are compared as well.
Object wrappers are compared both as objects and unwrapped values.
Object properties are compared unordered.
<Map> keys and <Set> items are compared unordered.
Recursion stops when both sides differ or both sides encounter a circular
reference.
<WeakMap> and <WeakSet> instances are not compared structurally.
They are only equal if they reference the same object. Any comparison between
different WeakMap or WeakSet instances will result in inequality,
even if they contain the same entries.
<RegExp> lastIndex, flags, and source are always compared, even if these
are not enumerable properties.
Holes in sparse arrays are ignored.


import assert from 'node:assert';

assert.partialDeepStrictEqual(
  { a: { b: { c: 1 } } },
  { a: { b: { c: 1 } } },
);
// OK

assert.partialDeepStrictEqual(
  { a: 1, b: 2, c: 3 },
  { b: 2 },
);
// OK

assert.partialDeepStrictEqual(
  [1, 2, 3, 4, 5, 6, 7, 8, 9],
  [4, 5, 8],
);
// OK

assert.partialDeepStrictEqual(
  new Set([{ a: 1 }, { b: 1 }]),
  new Set([{ a: 1 }]),
);
// OK

assert.partialDeepStrictEqual(
  new Map([['key1', 'value1'], ['key2', 'value2']]),
  new Map([['key2', 'value2']]),
);
// OK

assert.partialDeepStrictEqual(123n, 123n);
// OK

assert.partialDeepStrictEqual(
  [1, 2, 3, 4, 5, 6, 7, 8, 9],
  [5, 4, 8],
);
// AssertionError

assert.partialDeepStrictEqual(
  { a: 1 },
  { a: 1, b: 2 },
);
// AssertionError

assert.partialDeepStrictEqual(
  { a: { b: 2 } },
  { a: { b: '2' } },
);
// AssertionErrorconst assert = require('node:assert');

assert.partialDeepStrictEqual(
  { a: { b: { c: 1 } } },
  { a: { b: { c: 1 } } },
);
// OK

assert.partialDeepStrictEqual(
  { a: 1, b: 2, c: 3 },
  { b: 2 },
);
// OK

assert.partialDeepStrictEqual(
  [1, 2, 3, 4, 5, 6, 7, 8, 9],
  [4, 5, 8],
);
// OK

assert.partialDeepStrictEqual(
  new Set([{ a: 1 }, { b: 1 }]),
  new Set([{ a: 1 }]),
);
// OK

assert.partialDeepStrictEqual(
  new Map([['key1', 'value1'], ['key2', 'value2']]),
  new Map([['key2', 'value2']]),
);
// OK

assert.partialDeepStrictEqual(123n, 123n);
// OK

assert.partialDeepStrictEqual(
  [1, 2, 3, 4, 5, 6, 7, 8, 9],
  [5, 4, 8],
);
// AssertionError

assert.partialDeepStrictEqual(
  { a: 1 },
  { a: 1, b: 2 },
);
// AssertionError

assert.partialDeepStrictEqual(
  { a: { b: 2 } },
  { a: { b: '2' } },
);
// AssertionErrorcopy\n\n\n\nNode.js
        
      
      
About this documentation
Usage and example



Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Modules: TypeScript
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
Readline
REPL
Report
Single executable applications
SQLite
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker

    

    
      
        
          Node.js v24.0.1 documentation
          
            
            
          
        
        
          
            Node.js v24.0.1
            
    
      
        
        Table of contents
      

      
Asynchronous context tracking

Introduction
Class: AsyncLocalStorage

new AsyncLocalStorage([options])
Static method: AsyncLocalStorage.bind(fn)
Static method: AsyncLocalStorage.snapshot()
asyncLocalStorage.disable()
asyncLocalStorage.getStore()
asyncLocalStorage.enterWith(store)
asyncLocalStorage.name
asyncLocalStorage.run(store, callback[, ...args])
asyncLocalStorage.exit(callback[, ...args])
Usage with async/await
Troubleshooting: Context loss


Class: AsyncResource

new AsyncResource(type[, options])
Static method: AsyncResource.bind(fn[, type[, thisArg]])
asyncResource.bind(fn[, thisArg])
asyncResource.runInAsyncScope(fn[, thisArg, ...args])
asyncResource.emitDestroy()
asyncResource.asyncId()
asyncResource.triggerAsyncId()
Using AsyncResource for a Worker thread pool
Integrating AsyncResource with EventEmitter





    
  
            
    
      
        
        Index
      

      
About this documentation
Usage and example

      
        Index
      
    
  


Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Modules: TypeScript
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
Readline
REPL
Report
Single executable applications
SQLite
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker

    
  
            
    
      
        
        Other versions
      
      24.x
23.x
22.x LTS
21.x
20.x LTS
19.x
18.x
17.x
16.x
    
  
            
              
                
                Options
              
        
              
                
                  
                    View on single page
                  
                  
                    View as JSON
                  
                  Edit on GitHub    
                
              
            
          
        
        
      

      Table of contents
Asynchronous context tracking

Introduction
Class: AsyncLocalStorage

new AsyncLocalStorage([options])
Static method: AsyncLocalStorage.bind(fn)
Static method: AsyncLocalStorage.snapshot()
asyncLocalStorage.disable()
asyncLocalStorage.getStore()
asyncLocalStorage.enterWith(store)
asyncLocalStorage.name
asyncLocalStorage.run(store, callback[, ...args])
asyncLocalStorage.exit(callback[, ...args])
Usage with async/await
Troubleshooting: Context loss


Class: AsyncResource

new AsyncResource(type[, options])
Static method: AsyncResource.bind(fn[, type[, thisArg]])
asyncResource.bind(fn[, thisArg])
asyncResource.runInAsyncScope(fn[, thisArg, ...args])
asyncResource.emitDestroy()
asyncResource.asyncId()
asyncResource.triggerAsyncId()
Using AsyncResource for a Worker thread pool
Integrating AsyncResource with EventEmitter






      
        Asynchronous context tracking#

Stability: 2 - Stable
Source Code: lib/async_hooks.js
Introduction#
These classes are used to associate state and propagate it throughout
callbacks and promise chains.
They allow storing data throughout the lifetime of a web request
or any other asynchronous duration. It is similar to thread-local storage
in other languages.
The AsyncLocalStorage and AsyncResource classes are part of the
node:async_hooks module:

import { AsyncLocalStorage, AsyncResource } from 'node:async_hooks';const { AsyncLocalStorage, AsyncResource } = require('node:async_hooks');copy
Class: AsyncLocalStorage#

History

VersionChanges
v16.4.0
AsyncLocalStorage is now Stable. Previously, it had been Experimental.
v13.10.0, v12.17.0
Added in: v13.10.0, v12.17.0



This class creates stores that stay coherent through asynchronous operations.
While you can create your own implementation on top of the node:async_hooks
module, AsyncLocalStorage should be preferred as it is a performant and memory
safe implementation that involves significant optimizations that are non-obvious
to implement.
The following example uses AsyncLocalStorage to build a simple logger
that assigns IDs to incoming HTTP requests and includes them in messages
logged within each request.

import http from 'node:http';
import { AsyncLocalStorage } from 'node:async_hooks';

const asyncLocalStorage = new AsyncLocalStorage();

function logWithId(msg) {
  const id = asyncLocalStorage.getStore();
  console.log(`${id !== undefined ? id : '-'}:`, msg);
}

let idSeq = 0;
http.createServer((req, res) => {
  asyncLocalStorage.run(idSeq++, () => {
    logWithId('start');
    // Imagine any chain of async operations here
    setImmediate(() => {
      logWithId('finish');
      res.end();
    });
  });
}).listen(8080);

http.get('http://localhost:8080');
http.get('http://localhost:8080');
// Prints:
//   0: start
//   0: finish
//   1: start
//   1: finishconst http = require('node:http');
const { AsyncLocalStorage } = require('node:async_hooks');

const asyncLocalStorage = new AsyncLocalStorage();

function logWithId(msg) {
  const id = asyncLocalStorage.getStore();
  console.log(`${id !== undefined ? id : '-'}:`, msg);
}

let idSeq = 0;
http.createServer((req, res) => {
  asyncLocalStorage.run(idSeq++, () => {
    logWithId('start');
    // Imagine any chain of async operations here
    setImmediate(() => {
      logWithId('finish');
      res.end();
    });
  });
}).listen(8080);

http.get('http://localhost:8080');
http.get('http://localhost:8080');
// Prints:
//   0: start
//   0: finish
//   1: start
//   1: finishcopy
Each instance of AsyncLocalStorage maintains an independent storage context.
Multiple instances can safely exist simultaneously without risk of interfering
with each other's data.

new AsyncLocalStorage([options])#

History

VersionChanges
v24.0.0
Add defaultValue and name options.
v19.7.0, v18.16.0
Removed experimental onPropagate option.
v19.2.0, v18.13.0
Add option onPropagate.
v13.10.0, v12.17.0
Added in: v13.10.0, v12.17.0




options <Object>

defaultValue <any> The default value to be used when no store is provided.
name <string> A name for the AsyncLocalStorage value.



Creates a new instance of AsyncLocalStorage. Store is only provided within a
run() call or after an enterWith() call.

Static method: AsyncLocalStorage.bind(fn)#

History

VersionChanges
v23.11.0, v22.15.0
Marking the API stable.
v19.8.0, v18.16.0
Added in: v19.8.0, v18.16.0




fn <Function> The function to bind to the current execution context.
Returns: <Function> A new function that calls fn within the captured
execution context.

Binds the given function to the current execution context.

Static method: AsyncLocalStorage.snapshot()#

History

VersionChanges
v23.11.0, v22.15.0
Marking the API stable.
v19.8.0, v18.16.0
Added in: v19.8.0, v18.16.0




Returns: <Function> A new function with the signature
(fn: (...args) : R, ...args) : R.

Captures the current execution context and returns a function that accepts a
function as an argument. Whenever the returned function is called, it
calls the function passed to it within the captured context.
const asyncLocalStorage = new AsyncLocalStorage();
const runInAsyncScope = asyncLocalStorage.run(123, () => AsyncLocalStorage.snapshot());
const result = asyncLocalStorage.run(321, () => runInAsyncScope(() => asyncLocalStorage.getStore()));
console.log(result);  // returns 123 copy
AsyncLocalStorage.snapshot() can replace the use of AsyncResource for simple
async context tracking purposes, for example:
class Foo {
  #runInAsyncScope = AsyncLocalStorage.snapshot();

  get() { return this.#runInAsyncScope(() => asyncLocalStorage.getStore()); }
}

const foo = asyncLocalStorage.run(123, () => new Foo());
console.log(asyncLocalStorage.run(321, () => foo.get())); // returns 123 copy

asyncLocalStorage.disable()#

Added in: v13.10.0, v12.17.0

Stability: 1 - Experimental
Disables the instance of AsyncLocalStorage. All subsequent calls
to asyncLocalStorage.getStore() will return undefined until
asyncLocalStorage.run() or asyncLocalStorage.enterWith() is called again.
When calling asyncLocalStorage.disable(), all current contexts linked to the
instance will be exited.
Calling asyncLocalStorage.disable() is required before the
asyncLocalStorage can be garbage collected. This does not apply to stores
provided by the asyncLocalStorage, as those objects are garbage collected
along with the corresponding async resources.
Use this method when the asyncLocalStorage is not in use anymore
in the current process.

asyncLocalStorage.getStore()#

Added in: v13.10.0, v12.17.0


Returns: <any>

Returns the current store.
If called outside of an asynchronous context initialized by
calling asyncLocalStorage.run() or asyncLocalStorage.enterWith(), it
returns undefined.

asyncLocalStorage.enterWith(store)#

Added in: v13.11.0, v12.17.0

Stability: 1 - Experimental

store <any>

Transitions into the context for the remainder of the current
synchronous execution and then persists the store through any following
asynchronous calls.
Example:
const store = { id: 1 };
// Replaces previous store with the given store object
asyncLocalStorage.enterWith(store);
asyncLocalStorage.getStore(); // Returns the store object
someAsyncOperation(() => {
  asyncLocalStorage.getStore(); // Returns the same object
}); copy
This transition will continue for the entire synchronous execution.
This means that if, for example, the context is entered within an event
handler subsequent event handlers will also run within that context unless
specifically bound to another context with an AsyncResource. That is why
run() should be preferred over enterWith() unless there are strong reasons
to use the latter method.
const store = { id: 1 };

emitter.on('my-event', () => {
  asyncLocalStorage.enterWith(store);
});
emitter.on('my-event', () => {
  asyncLocalStorage.getStore(); // Returns the same object
});

asyncLocalStorage.getStore(); // Returns undefined
emitter.emit('my-event');
asyncLocalStorage.getStore(); // Returns the same object copy

asyncLocalStorage.name#

Added in: v24.0.0


<string>

The name of the AsyncLocalStorage instance if provided.

asyncLocalStorage.run(store, callback[, ...args])#

Added in: v13.10.0, v12.17.0


store <any>
callback <Function>
...args <any>

Runs a function synchronously within a context and returns its
return value. The store is not accessible outside of the callback function.
The store is accessible to any asynchronous operations created within the
callback.
The optional args are passed to the callback function.
If the callback function throws an error, the error is thrown by run() too.
The stacktrace is not impacted by this call and the context is exited.
Example:
const store = { id: 2 };
try {
  asyncLocalStorage.run(store, () => {
    asyncLocalStorage.getStore(); // Returns the store object
    setTimeout(() => {
      asyncLocalStorage.getStore(); // Returns the store object
    }, 200);
    throw new Error();
  });
} catch (e) {
  asyncLocalStorage.getStore(); // Returns undefined
  // The error will be caught here
} copy

asyncLocalStorage.exit(callback[, ...args])#

Added in: v13.10.0, v12.17.0

Stability: 1 - Experimental

callback <Function>
...args <any>

Runs a function synchronously outside of a context and returns its
return value. The store is not accessible within the callback function or
the asynchronous operations created within the callback. Any getStore()
call done within the callback function will always return undefined.
The optional args are passed to the callback function.
If the callback function throws an error, the error is thrown by exit() too.
The stacktrace is not impacted by this call and the context is re-entered.
Example:
// Within a call to run
try {
  asyncLocalStorage.getStore(); // Returns the store object or value
  asyncLocalStorage.exit(() => {
    asyncLocalStorage.getStore(); // Returns undefined
    throw new Error();
  });
} catch (e) {
  asyncLocalStorage.getStore(); // Returns the same object or value
  // The error will be caught here
} copy

Usage with async/await#
If, within an async function, only one await call is to run within a context,
the following pattern should be used:
async function fn() {
  await asyncLocalStorage.run(new Map(), () => {
    asyncLocalStorage.getStore().set('key', value);
    return foo(); // The return value of foo will be awaited
  });
} copy
In this example, the store is only available in the callback function and the
functions called by foo. Outside of run, calling getStore will return
undefined.

Troubleshooting: Context loss#
In most cases, AsyncLocalStorage works without issues. In rare situations, the
current store is lost in one of the asynchronous operations.
If your code is callback-based, it is enough to promisify it with
util.promisify() so it starts working with native promises.
If you need to use a callback-based API or your code assumes
a custom thenable implementation, use the AsyncResource class
to associate the asynchronous operation with the correct execution context.
Find the function call responsible for the context loss by logging the content
of asyncLocalStorage.getStore() after the calls you suspect are responsible
for the loss. When the code logs undefined, the last callback called is
probably responsible for the context loss.

Class: AsyncResource#

History

VersionChanges
v16.4.0
AsyncResource is now Stable. Previously, it had been Experimental.



The class AsyncResource is designed to be extended by the embedder's async
resources. Using this, users can easily trigger the lifetime events of their
own resources.
The init hook will trigger when an AsyncResource is instantiated.
The following is an overview of the AsyncResource API.

import { AsyncResource, executionAsyncId } from 'node:async_hooks';

// AsyncResource() is meant to be extended. Instantiating a
// new AsyncResource() also triggers init. If triggerAsyncId is omitted then
// async_hook.executionAsyncId() is used.
const asyncResource = new AsyncResource(
  type, { triggerAsyncId: executionAsyncId(), requireManualDestroy: false },
);

// Run a function in the execution context of the resource. This will
// * establish the context of the resource
// * trigger the AsyncHooks before callbacks
// * call the provided function `fn` with the supplied arguments
// * trigger the AsyncHooks after callbacks
// * restore the original execution context
asyncResource.runInAsyncScope(fn, thisArg, ...args);

// Call AsyncHooks destroy callbacks.
asyncResource.emitDestroy();

// Return the unique ID assigned to the AsyncResource instance.
asyncResource.asyncId();

// Return the trigger ID for the AsyncResource instance.
asyncResource.triggerAsyncId();const { AsyncResource, executionAsyncId } = require('node:async_hooks');

// AsyncResource() is meant to be extended. Instantiating a
// new AsyncResource() also triggers init. If triggerAsyncId is omitted then
// async_hook.executionAsyncId() is used.
const asyncResource = new AsyncResource(
  type, { triggerAsyncId: executionAsyncId(), requireManualDestroy: false },
);

// Run a function in the execution context of the resource. This will
// * establish the context of the resource
// * trigger the AsyncHooks before callbacks
// * call the provided function `fn` with the supplied arguments
// * trigger the AsyncHooks after callbacks
// * restore the original execution context
asyncResource.runInAsyncScope(fn, thisArg, ...args);

// Call AsyncHooks destroy callbacks.
asyncResource.emitDestroy();

// Return the unique ID assigned to the AsyncResource instance.
asyncResource.asyncId();

// Return the trigger ID for the AsyncResource instance.
asyncResource.triggerAsyncId();copy

new AsyncResource(type[, options])#

type <string> The type of async event.
options <Object>

triggerAsyncId <number> The ID of the execution context that created this
async event. Default: executionAsyncId().
requireManualDestroy <boolean> If set to true, disables emitDestroy
when the object is garbage collected. This usually does not need to be set
(even if emitDestroy is called manually), unless the resource's asyncId
is retrieved and the sensitive API's emitDestroy is called with it.
When set to false, the emitDestroy call on garbage collection
will only take place if there is at least one active destroy hook.
Default: false.



Example usage:
class DBQuery extends AsyncResource {
  constructor(db) {
    super('DBQuery');
    this.db = db;
  }

  getInfo(query, callback) {
    this.db.get(query, (err, data) => {
      this.runInAsyncScope(callback, null, err, data);
    });
  }

  close() {
    this.db = null;
    this.emitDestroy();
  }
} copy

Static method: AsyncResource.bind(fn[, type[, thisArg]])#

History

VersionChanges
v20.0.0
The asyncResource property added to the bound function has been deprecated and will be removed in a future version.
v17.8.0, v16.15.0
Changed the default when thisArg is undefined to use this from the caller.
v16.0.0
Added optional thisArg.
v14.8.0, v12.19.0
Added in: v14.8.0, v12.19.0




fn <Function> The function to bind to the current execution context.
type <string> An optional name to associate with the underlying
AsyncResource.
thisArg <any>

Binds the given function to the current execution context.

asyncResource.bind(fn[, thisArg])#

History

VersionChanges
v20.0.0
The asyncResource property added to the bound function has been deprecated and will be removed in a future version.
v17.8.0, v16.15.0
Changed the default when thisArg is undefined to use this from the caller.
v16.0.0
Added optional thisArg.
v14.8.0, v12.19.0
Added in: v14.8.0, v12.19.0




fn <Function> The function to bind to the current AsyncResource.
thisArg <any>

Binds the given function to execute to this AsyncResource's scope.

asyncResource.runInAsyncScope(fn[, thisArg, ...args])#

Added in: v9.6.0


fn <Function> The function to call in the execution context of this async
resource.
thisArg <any> The receiver to be used for the function call.
...args <any> Optional arguments to pass to the function.

Call the provided function with the provided arguments in the execution context
of the async resource. This will establish the context, trigger the AsyncHooks
before callbacks, call the function, trigger the AsyncHooks after callbacks, and
then restore the original execution context.

asyncResource.emitDestroy()#

Returns: <AsyncResource> A reference to asyncResource.

Call all destroy hooks. This should only ever be called once. An error will
be thrown if it is called more than once. This must be manually called. If
the resource is left to be collected by the GC then the destroy hooks will
never be called.

asyncResource.asyncId()#

Returns: <number> The unique asyncId assigned to the resource.


asyncResource.triggerAsyncId()#

Returns: <number> The same triggerAsyncId that is passed to the
AsyncResource constructor.



Using AsyncResource for a Worker thread pool#
The following example shows how to use the AsyncResource class to properly
provide async tracking for a Worker pool. Other resource pools, such as
database connection pools, can follow a similar model.
Assuming that the task is adding two numbers, using a file named
task_processor.js with the following content:

import { parentPort } from 'node:worker_threads';
parentPort.on('message', (task) => {
  parentPort.postMessage(task.a + task.b);
});const { parentPort } = require('node:worker_threads');
parentPort.on('message', (task) => {
  parentPort.postMessage(task.a + task.b);
});copy
a Worker pool around it could use the following structure:

import { AsyncResource } from 'node:async_hooks';
import { EventEmitter } from 'node:events';
import { Worker } from 'node:worker_threads';

const kTaskInfo = Symbol('kTaskInfo');
const kWorkerFreedEvent = Symbol('kWorkerFreedEvent');

class WorkerPoolTaskInfo extends AsyncResource {
  constructor(callback) {
    super('WorkerPoolTaskInfo');
    this.callback = callback;
  }

  done(err, result) {
    this.runInAsyncScope(this.callback, null, err, result);
    this.emitDestroy();  // `TaskInfo`s are used only once.
  }
}

export default class WorkerPool extends EventEmitter {
  constructor(numThreads) {
    super();
    this.numThreads = numThreads;
    this.workers = [];
    this.freeWorkers = [];
    this.tasks = [];

    for (let i = 0; i < numThreads; i++)
      this.addNewWorker();

    // Any time the kWorkerFreedEvent is emitted, dispatch
    // the next task pending in the queue, if any.
    this.on(kWorkerFreedEvent, () => {
      if (this.tasks.length > 0) {
        const { task, callback } = this.tasks.shift();
        this.runTask(task, callback);
      }
    });
  }

  addNewWorker() {
    const worker = new Worker(new URL('task_processor.js', import.meta.url));
    worker.on('message', (result) => {
      // In case of success: Call the callback that was passed to `runTask`,
      // remove the `TaskInfo` associated with the Worker, and mark it as free
      // again.
      worker[kTaskInfo].done(null, result);
      worker[kTaskInfo] = null;
      this.freeWorkers.push(worker);
      this.emit(kWorkerFreedEvent);
    });
    worker.on('error', (err) => {
      // In case of an uncaught exception: Call the callback that was passed to
      // `runTask` with the error.
      if (worker[kTaskInfo])
        worker[kTaskInfo].done(err, null);
      else
        this.emit('error', err);
      // Remove the worker from the list and start a new Worker to replace the
      // current one.
      this.workers.splice(this.workers.indexOf(worker), 1);
      this.addNewWorker();
    });
    this.workers.push(worker);
    this.freeWorkers.push(worker);
    this.emit(kWorkerFreedEvent);
  }

  runTask(task, callback) {
    if (this.freeWorkers.length === 0) {
      // No free threads, wait until a worker thread becomes free.
      this.tasks.push({ task, callback });
      return;
    }

    const worker = this.freeWorkers.pop();
    worker[kTaskInfo] = new WorkerPoolTaskInfo(callback);
    worker.postMessage(task);
  }

  close() {
    for (const worker of this.workers) worker.terminate();
  }
}const { AsyncResource } = require('node:async_hooks');
const { EventEmitter } = require('node:events');
const path = require('node:path');
const { Worker } = require('node:worker_threads');

const kTaskInfo = Symbol('kTaskInfo');
const kWorkerFreedEvent = Symbol('kWorkerFreedEvent');

class WorkerPoolTaskInfo extends AsyncResource {
  constructor(callback) {
    super('WorkerPoolTaskInfo');
    this.callback = callback;
  }

  done(err, result) {
    this.runInAsyncScope(this.callback, null, err, result);
    this.emitDestroy();  // `TaskInfo`s are used only once.
  }
}

class WorkerPool extends EventEmitter {
  constructor(numThreads) {
    super();
    this.numThreads = numThreads;
    this.workers = [];
    this.freeWorkers = [];
    this.tasks = [];

    for (let i = 0; i < numThreads; i++)
      this.addNewWorker();

    // Any time the kWorkerFreedEvent is emitted, dispatch
    // the next task pending in the queue, if any.
    this.on(kWorkerFreedEvent, () => {
      if (this.tasks.length > 0) {
        const { task, callback } = this.tasks.shift();
        this.runTask(task, callback);
      }
    });
  }

  addNewWorker() {
    const worker = new Worker(path.resolve(__dirname, 'task_processor.js'));
    worker.on('message', (result) => {
      // In case of success: Call the callback that was passed to `runTask`,
      // remove the `TaskInfo` associated with the Worker, and mark it as free
      // again.
      worker[kTaskInfo].done(null, result);
      worker[kTaskInfo] = null;
      this.freeWorkers.push(worker);
      this.emit(kWorkerFreedEvent);
    });
    worker.on('error', (err) => {
      // In case of an uncaught exception: Call the callback that was passed to
      // `runTask` with the error.
      if (worker[kTaskInfo])
        worker[kTaskInfo].done(err, null);
      else
        this.emit('error', err);
      // Remove the worker from the list and start a new Worker to replace the
      // current one.
      this.workers.splice(this.workers.indexOf(worker), 1);
      this.addNewWorker();
    });
    this.workers.push(worker);
    this.freeWorkers.push(worker);
    this.emit(kWorkerFreedEvent);
  }

  runTask(task, callback) {
    if (this.freeWorkers.length === 0) {
      // No free threads, wait until a worker thread becomes free.
      this.tasks.push({ task, callback });
      return;
    }

    const worker = this.freeWorkers.pop();
    worker[kTaskInfo] = new WorkerPoolTaskInfo(callback);
    worker.postMessage(task);
  }

  close() {
    for (const worker of this.workers) worker.terminate();
  }
}

module.exports = WorkerPool;copy
Without the explicit tracking added by the WorkerPoolTaskInfo objects,
it would appear that the callbacks are associated with the individual Worker
objects. However, the creation of the Workers is not associated with the
creation of the tasks and does not provide information about when tasks
were scheduled.
This pool could be used as follows:

import WorkerPool from './worker_pool.js';
import os from 'node:os';

const pool = new WorkerPool(os.availableParallelism());

let finished = 0;
for (let i = 0; i < 10; i++) {
  pool.runTask({ a: 42, b: 100 }, (err, result) => {
    console.log(i, err, result);
    if (++finished === 10)
      pool.close();
  });
}const WorkerPool = require('./worker_pool.js');
const os = require('node:os');

const pool = new WorkerPool(os.availableParallelism());

let finished = 0;
for (let i = 0; i < 10; i++) {
  pool.runTask({ a: 42, b: 100 }, (err, result) => {
    console.log(i, err, result);
    if (++finished === 10)
      pool.close();
  });
}copy

Integrating AsyncResource with EventEmitter#
Event listeners triggered by an EventEmitter may be run in a different
execution context than the one that was active when eventEmitter.on() was
called.
The following example shows how to use the AsyncResource class to properly
associate an event listener with the correct execution context. The same
approach can be applied to a Stream or a similar event-driven class.

import { createServer } from 'node:http';
import { AsyncResource, executionAsyncId } from 'node:async_hooks';

const server = createServer((req, res) => {
  req.on('close', AsyncResource.bind(() => {
    // Execution context is bound to the current outer scope.
  }));
  req.on('close', () => {
    // Execution context is bound to the scope that caused 'close' to emit.
  });
  res.end();
}).listen(3000);const { createServer } = require('node:http');
const { AsyncResource, executionAsyncId } = require('node:async_hooks');

const server = createServer((req, res) => {
  req.on('close', AsyncResource.bind(() => {
    // Execution context is bound to the current outer scope.
  }));
  req.on('close', () => {
    // Execution context is bound to the scope that caused 'close' to emit.
  });
  res.end();
}).listen(3000);copy\n\n\n\nNode.js
        
      
      
About this documentation
Usage and example



Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Modules: TypeScript
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
Readline
REPL
Report
Single executable applications
SQLite
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker

    

    
      
        
          Node.js v24.0.1 documentation
          
            
            
          
        
        
          
            Node.js v24.0.1
            
    
      
        
        Table of contents
      

      
Async hooks

Terminology
Overview
async_hooks.createHook(callbacks)

Error handling
Printing in AsyncHook callbacks


Class: AsyncHook

asyncHook.enable()
asyncHook.disable()
Hook callbacks

init(asyncId, type, triggerAsyncId, resource)

type
triggerAsyncId
resource
Asynchronous context example


before(asyncId)
after(asyncId)
destroy(asyncId)
promiseResolve(asyncId)


async_hooks.executionAsyncResource()
async_hooks.executionAsyncId()
async_hooks.triggerAsyncId()
async_hooks.asyncWrapProviders


Promise execution tracking
JavaScript embedder API

Class: AsyncResource


Class: AsyncLocalStorage



    
  
            
    
      
        
        Index
      

      
About this documentation
Usage and example

      
        Index
      
    
  


Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Modules: TypeScript
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
Readline
REPL
Report
Single executable applications
SQLite
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker

    
  
            
    
      
        
        Other versions
      
      24.x
23.x
22.x LTS
21.x
20.x LTS
19.x
18.x
17.x
16.x
15.x
14.x
13.x
12.x
11.x
10.x
9.x
8.x
    
  
            
              
                
                Options
              
        
              
                
                  
                    View on single page
                  
                  
                    View as JSON
                  
                  Edit on GitHub    
                
              
            
          
        
        
      

      Table of contents
Async hooks

Terminology
Overview
async_hooks.createHook(callbacks)

Error handling
Printing in AsyncHook callbacks


Class: AsyncHook

asyncHook.enable()
asyncHook.disable()
Hook callbacks

init(asyncId, type, triggerAsyncId, resource)

type
triggerAsyncId
resource
Asynchronous context example


before(asyncId)
after(asyncId)
destroy(asyncId)
promiseResolve(asyncId)


async_hooks.executionAsyncResource()
async_hooks.executionAsyncId()
async_hooks.triggerAsyncId()
async_hooks.asyncWrapProviders


Promise execution tracking
JavaScript embedder API

Class: AsyncResource


Class: AsyncLocalStorage




      
        Async hooks#

Stability: 1 - Experimental. Please migrate away from this API, if you can.
We do not recommend using the createHook, AsyncHook, and
executionAsyncResource APIs as they have usability issues, safety risks,
and performance implications. Async context tracking use cases are better
served by the stable AsyncLocalStorage API. If you have a use case for
createHook, AsyncHook, or executionAsyncResource beyond the context
tracking need solved by AsyncLocalStorage or diagnostics data currently
provided by Diagnostics Channel, please open an issue at
https://github.com/nodejs/node/issues describing your use case so we can
create a more purpose-focused API.
Source Code: lib/async_hooks.js
We strongly discourage the use of the async_hooks API.
Other APIs that can cover most of its use cases include:

AsyncLocalStorage tracks async context
process.getActiveResourcesInfo() tracks active resources

The node:async_hooks module provides an API to track asynchronous resources.
It can be accessed using:

import async_hooks from 'node:async_hooks';const async_hooks = require('node:async_hooks');copy
Terminology#
An asynchronous resource represents an object with an associated callback.
This callback may be called multiple times, such as the 'connection'
event in net.createServer(), or just a single time like in fs.open().
A resource can also be closed before the callback is called. AsyncHook does
not explicitly distinguish between these different cases but will represent them
as the abstract concept that is a resource.
If Workers are used, each thread has an independent async_hooks
interface, and each thread will use a new set of async IDs.
Overview#
Following is a simple overview of the public API.

import async_hooks from 'node:async_hooks';

// Return the ID of the current execution context.
const eid = async_hooks.executionAsyncId();

// Return the ID of the handle responsible for triggering the callback of the
// current execution scope to call.
const tid = async_hooks.triggerAsyncId();

// Create a new AsyncHook instance. All of these callbacks are optional.
const asyncHook =
    async_hooks.createHook({ init, before, after, destroy, promiseResolve });

// Allow callbacks of this AsyncHook instance to call. This is not an implicit
// action after running the constructor, and must be explicitly run to begin
// executing callbacks.
asyncHook.enable();

// Disable listening for new asynchronous events.
asyncHook.disable();

//
// The following are the callbacks that can be passed to createHook().
//

// init() is called during object construction. The resource may not have
// completed construction when this callback runs. Therefore, all fields of the
// resource referenced by "asyncId" may not have been populated.
function init(asyncId, type, triggerAsyncId, resource) { }

// before() is called just before the resource's callback is called. It can be
// called 0-N times for handles (such as TCPWrap), and will be called exactly 1
// time for requests (such as FSReqCallback).
function before(asyncId) { }

// after() is called just after the resource's callback has finished.
function after(asyncId) { }

// destroy() is called when the resource is destroyed.
function destroy(asyncId) { }

// promiseResolve() is called only for promise resources, when the
// resolve() function passed to the Promise constructor is invoked
// (either directly or through other means of resolving a promise).
function promiseResolve(asyncId) { }const async_hooks = require('node:async_hooks');

// Return the ID of the current execution context.
const eid = async_hooks.executionAsyncId();

// Return the ID of the handle responsible for triggering the callback of the
// current execution scope to call.
const tid = async_hooks.triggerAsyncId();

// Create a new AsyncHook instance. All of these callbacks are optional.
const asyncHook =
    async_hooks.createHook({ init, before, after, destroy, promiseResolve });

// Allow callbacks of this AsyncHook instance to call. This is not an implicit
// action after running the constructor, and must be explicitly run to begin
// executing callbacks.
asyncHook.enable();

// Disable listening for new asynchronous events.
asyncHook.disable();

//
// The following are the callbacks that can be passed to createHook().
//

// init() is called during object construction. The resource may not have
// completed construction when this callback runs. Therefore, all fields of the
// resource referenced by "asyncId" may not have been populated.
function init(asyncId, type, triggerAsyncId, resource) { }

// before() is called just before the resource's callback is called. It can be
// called 0-N times for handles (such as TCPWrap), and will be called exactly 1
// time for requests (such as FSReqCallback).
function before(asyncId) { }

// after() is called just after the resource's callback has finished.
function after(asyncId) { }

// destroy() is called when the resource is destroyed.
function destroy(asyncId) { }

// promiseResolve() is called only for promise resources, when the
// resolve() function passed to the Promise constructor is invoked
// (either directly or through other means of resolving a promise).
function promiseResolve(asyncId) { }copy
async_hooks.createHook(callbacks)#

Added in: v8.1.0


callbacks <Object> The Hook Callbacks to register

init <Function> The init callback.
before <Function> The before callback.
after <Function> The after callback.
destroy <Function> The destroy callback.
promiseResolve <Function> The promiseResolve callback.


Returns: <AsyncHook> Instance used for disabling and enabling hooks

Registers functions to be called for different lifetime events of each async
operation.
The callbacks init()/before()/after()/destroy() are called for the
respective asynchronous event during a resource's lifetime.
All callbacks are optional. For example, if only resource cleanup needs to
be tracked, then only the destroy callback needs to be passed. The
specifics of all functions that can be passed to callbacks is in the
Hook Callbacks section.

import { createHook } from 'node:async_hooks';

const asyncHook = createHook({
  init(asyncId, type, triggerAsyncId, resource) { },
  destroy(asyncId) { },
});const async_hooks = require('node:async_hooks');

const asyncHook = async_hooks.createHook({
  init(asyncId, type, triggerAsyncId, resource) { },
  destroy(asyncId) { },
});copy
The callbacks will be inherited via the prototype chain:
class MyAsyncCallbacks {
  init(asyncId, type, triggerAsyncId, resource) { }
  destroy(asyncId) {}
}

class MyAddedCallbacks extends MyAsyncCallbacks {
  before(asyncId) { }
  after(asyncId) { }
}

const asyncHook = async_hooks.createHook(new MyAddedCallbacks()); copy
Because promises are asynchronous resources whose lifecycle is tracked
via the async hooks mechanism, the init(), before(), after(), and
destroy() callbacks must not be async functions that return promises.

Error handling#
If any AsyncHook callbacks throw, the application will print the stack trace
and exit. The exit path does follow that of an uncaught exception, but
all 'uncaughtException' listeners are removed, thus forcing the process to
exit. The 'exit' callbacks will still be called unless the application is run
with --abort-on-uncaught-exception, in which case a stack trace will be
printed and the application exits, leaving a core file.
The reason for this error handling behavior is that these callbacks are running
at potentially volatile points in an object's lifetime, for example during
class construction and destruction. Because of this, it is deemed necessary to
bring down the process quickly in order to prevent an unintentional abort in the
future. This is subject to change in the future if a comprehensive analysis is
performed to ensure an exception can follow the normal control flow without
unintentional side effects.

Printing in AsyncHook callbacks#
Because printing to the console is an asynchronous operation, console.log()
will cause AsyncHook callbacks to be called. Using console.log() or
similar asynchronous operations inside an AsyncHook callback function will
cause an infinite recursion. An easy solution to this when debugging is to use a
synchronous logging operation such as fs.writeFileSync(file, msg, flag).
This will print to the file and will not invoke AsyncHook recursively because
it is synchronous.

import { writeFileSync } from 'node:fs';
import { format } from 'node:util';

function debug(...args) {
  // Use a function like this one when debugging inside an AsyncHook callback
  writeFileSync('log.out', `${format(...args)}\n`, { flag: 'a' });
}const fs = require('node:fs');
const util = require('node:util');

function debug(...args) {
  // Use a function like this one when debugging inside an AsyncHook callback
  fs.writeFileSync('log.out', `${util.format(...args)}\n`, { flag: 'a' });
}copy
If an asynchronous operation is needed for logging, it is possible to keep
track of what caused the asynchronous operation using the information
provided by AsyncHook itself. The logging should then be skipped when
it was the logging itself that caused the AsyncHook callback to be called. By
doing this, the otherwise infinite recursion is broken.

Class: AsyncHook#
The class AsyncHook exposes an interface for tracking lifetime events
of asynchronous operations.

asyncHook.enable()#

Returns: <AsyncHook> A reference to asyncHook.

Enable the callbacks for a given AsyncHook instance. If no callbacks are
provided, enabling is a no-op.
The AsyncHook instance is disabled by default. If the AsyncHook instance
should be enabled immediately after creation, the following pattern can be used.

import { createHook } from 'node:async_hooks';

const hook = createHook(callbacks).enable();const async_hooks = require('node:async_hooks');

const hook = async_hooks.createHook(callbacks).enable();copy

asyncHook.disable()#

Returns: <AsyncHook> A reference to asyncHook.

Disable the callbacks for a given AsyncHook instance from the global pool of
AsyncHook callbacks to be executed. Once a hook has been disabled it will not
be called again until enabled.
For API consistency disable() also returns the AsyncHook instance.

Hook callbacks#
Key events in the lifetime of asynchronous events have been categorized into
four areas: instantiation, before/after the callback is called, and when the
instance is destroyed.

init(asyncId, type, triggerAsyncId, resource)#

asyncId <number> A unique ID for the async resource.
type <string> The type of the async resource.
triggerAsyncId <number> The unique ID of the async resource in whose
execution context this async resource was created.
resource <Object> Reference to the resource representing the async
operation, needs to be released during destroy.

Called when a class is constructed that has the possibility to emit an
asynchronous event. This does not mean the instance must call
before/after before destroy is called, only that the possibility
exists.
This behavior can be observed by doing something like opening a resource then
closing it before the resource can be used. The following snippet demonstrates
this.

import { createServer } from 'node:net';

createServer().listen(function() { this.close(); });
// OR
clearTimeout(setTimeout(() => {}, 10));require('node:net').createServer().listen(function() { this.close(); });
// OR
clearTimeout(setTimeout(() => {}, 10));copy
Every new resource is assigned an ID that is unique within the scope of the
current Node.js instance.

type#
The type is a string identifying the type of resource that caused
init to be called. Generally, it will correspond to the name of the
resource's constructor.
The type of resources created by Node.js itself can change in any Node.js
release. Valid values include TLSWRAP,
TCPWRAP, TCPSERVERWRAP, GETADDRINFOREQWRAP, FSREQCALLBACK,
Microtask, and Timeout. Inspect the source code of the Node.js version used
to get the full list.
Furthermore users of AsyncResource create async resources independent
of Node.js itself.
There is also the PROMISE resource type, which is used to track Promise
instances and asynchronous work scheduled by them.
Users are able to define their own type when using the public embedder API.
It is possible to have type name collisions. Embedders are encouraged to use
unique prefixes, such as the npm package name, to prevent collisions when
listening to the hooks.

triggerAsyncId#
triggerAsyncId is the asyncId of the resource that caused (or "triggered")
the new resource to initialize and that caused init to call. This is different
from async_hooks.executionAsyncId() that only shows when a resource was
created, while triggerAsyncId shows why a resource was created.
The following is a simple demonstration of triggerAsyncId:

import { createHook, executionAsyncId } from 'node:async_hooks';
import { stdout } from 'node:process';
import net from 'node:net';
import fs from 'node:fs';

createHook({
  init(asyncId, type, triggerAsyncId) {
    const eid = executionAsyncId();
    fs.writeSync(
      stdout.fd,
      `${type}(${asyncId}): trigger: ${triggerAsyncId} execution: ${eid}\n`);
  },
}).enable();

net.createServer((conn) => {}).listen(8080);const { createHook, executionAsyncId } = require('node:async_hooks');
const { stdout } = require('node:process');
const net = require('node:net');
const fs = require('node:fs');

createHook({
  init(asyncId, type, triggerAsyncId) {
    const eid = executionAsyncId();
    fs.writeSync(
      stdout.fd,
      `${type}(${asyncId}): trigger: ${triggerAsyncId} execution: ${eid}\n`);
  },
}).enable();

net.createServer((conn) => {}).listen(8080);copy
Output when hitting the server with nc localhost 8080:
TCPSERVERWRAP(5): trigger: 1 execution: 1
TCPWRAP(7): trigger: 5 execution: 0 copy
The TCPSERVERWRAP is the server which receives the connections.
The TCPWRAP is the new connection from the client. When a new
connection is made, the TCPWrap instance is immediately constructed. This
happens outside of any JavaScript stack. (An executionAsyncId() of 0 means
that it is being executed from C++ with no JavaScript stack above it.) With only
that information, it would be impossible to link resources together in
terms of what caused them to be created, so triggerAsyncId is given the task
of propagating what resource is responsible for the new resource's existence.

resource#
resource is an object that represents the actual async resource that has
been initialized. The API to access the object may be specified by the
creator of the resource. Resources created by Node.js itself are internal
and may change at any time. Therefore no API is specified for these.
In some cases the resource object is reused for performance reasons, it is
thus not safe to use it as a key in a WeakMap or add properties to it.

Asynchronous context example#
The context tracking use case is covered by the stable API AsyncLocalStorage.
This example only illustrates async hooks operation but AsyncLocalStorage
fits better to this use case.
The following is an example with additional information about the calls to
init between the before and after calls, specifically what the
callback to listen() will look like. The output formatting is slightly more
elaborate to make calling context easier to see.

import async_hooks from 'node:async_hooks';
import fs from 'node:fs';
import net from 'node:net';
import { stdout } from 'node:process';
const { fd } = stdout;

let indent = 0;
async_hooks.createHook({
  init(asyncId, type, triggerAsyncId) {
    const eid = async_hooks.executionAsyncId();
    const indentStr = ' '.repeat(indent);
    fs.writeSync(
      fd,
      `${indentStr}${type}(${asyncId}):` +
      ` trigger: ${triggerAsyncId} execution: ${eid}\n`);
  },
  before(asyncId) {
    const indentStr = ' '.repeat(indent);
    fs.writeSync(fd, `${indentStr}before:  ${asyncId}\n`);
    indent += 2;
  },
  after(asyncId) {
    indent -= 2;
    const indentStr = ' '.repeat(indent);
    fs.writeSync(fd, `${indentStr}after:  ${asyncId}\n`);
  },
  destroy(asyncId) {
    const indentStr = ' '.repeat(indent);
    fs.writeSync(fd, `${indentStr}destroy:  ${asyncId}\n`);
  },
}).enable();

net.createServer(() => {}).listen(8080, () => {
  // Let's wait 10ms before logging the server started.
  setTimeout(() => {
    console.log('>>>', async_hooks.executionAsyncId());
  }, 10);
});const async_hooks = require('node:async_hooks');
const fs = require('node:fs');
const net = require('node:net');
const { fd } = process.stdout;

let indent = 0;
async_hooks.createHook({
  init(asyncId, type, triggerAsyncId) {
    const eid = async_hooks.executionAsyncId();
    const indentStr = ' '.repeat(indent);
    fs.writeSync(
      fd,
      `${indentStr}${type}(${asyncId}):` +
      ` trigger: ${triggerAsyncId} execution: ${eid}\n`);
  },
  before(asyncId) {
    const indentStr = ' '.repeat(indent);
    fs.writeSync(fd, `${indentStr}before:  ${asyncId}\n`);
    indent += 2;
  },
  after(asyncId) {
    indent -= 2;
    const indentStr = ' '.repeat(indent);
    fs.writeSync(fd, `${indentStr}after:  ${asyncId}\n`);
  },
  destroy(asyncId) {
    const indentStr = ' '.repeat(indent);
    fs.writeSync(fd, `${indentStr}destroy:  ${asyncId}\n`);
  },
}).enable();

net.createServer(() => {}).listen(8080, () => {
  // Let's wait 10ms before logging the server started.
  setTimeout(() => {
    console.log('>>>', async_hooks.executionAsyncId());
  }, 10);
});copy
Output from only starting the server:
TCPSERVERWRAP(5): trigger: 1 execution: 1
TickObject(6): trigger: 5 execution: 1
before:  6
  Timeout(7): trigger: 6 execution: 6
after:   6
destroy: 6
before:  7
>>> 7
  TickObject(8): trigger: 7 execution: 7
after:   7
before:  8
after:   8 copy
As illustrated in the example, executionAsyncId() and execution each specify
the value of the current execution context; which is delineated by calls to
before and after.
Only using execution to graph resource allocation results in the following:
  root(1)
     ^
     |
TickObject(6)
     ^
     |
 Timeout(7) copy
The TCPSERVERWRAP is not part of this graph, even though it was the reason for
console.log() being called. This is because binding to a port without a host
name is a synchronous operation, but to maintain a completely asynchronous
API the user's callback is placed in a process.nextTick(). Which is why
TickObject is present in the output and is a 'parent' for .listen()
callback.
The graph only shows when a resource was created, not why, so to track
the why use triggerAsyncId. Which can be represented with the following
graph:
 bootstrap(1)
     |
     ˅
TCPSERVERWRAP(5)
     |
     ˅
 TickObject(6)
     |
     ˅
  Timeout(7) copy

before(asyncId)#

asyncId <number>

When an asynchronous operation is initiated (such as a TCP server receiving a
new connection) or completes (such as writing data to disk) a callback is
called to notify the user. The before callback is called just before said
callback is executed. asyncId is the unique identifier assigned to the
resource about to execute the callback.
The before callback will be called 0 to N times. The before callback
will typically be called 0 times if the asynchronous operation was cancelled
or, for example, if no connections are received by a TCP server. Persistent
asynchronous resources like a TCP server will typically call the before
callback multiple times, while other operations like fs.open() will call
it only once.

after(asyncId)#

asyncId <number>

Called immediately after the callback specified in before is completed.
If an uncaught exception occurs during execution of the callback, then after
will run after the 'uncaughtException' event is emitted or a domain's
handler runs.

destroy(asyncId)#

asyncId <number>

Called after the resource corresponding to asyncId is destroyed. It is also
called asynchronously from the embedder API emitDestroy().
Some resources depend on garbage collection for cleanup, so if a reference is
made to the resource object passed to init it is possible that destroy
will never be called, causing a memory leak in the application. If the resource
does not depend on garbage collection, then this will not be an issue.
Using the destroy hook results in additional overhead because it enables
tracking of Promise instances via the garbage collector.

promiseResolve(asyncId)#

Added in: v8.6.0


asyncId <number>

Called when the resolve function passed to the Promise constructor is
invoked (either directly or through other means of resolving a promise).
resolve() does not do any observable synchronous work.
The Promise is not necessarily fulfilled or rejected at this point if the
Promise was resolved by assuming the state of another Promise.
new Promise((resolve) => resolve(true)).then((a) => {}); copy
calls the following callbacks:
init for PROMISE with id 5, trigger id: 1
  promise resolve 5      # corresponds to resolve(true)
init for PROMISE with id 6, trigger id: 5  # the Promise returned by then()
  before 6               # the then() callback is entered
  promise resolve 6      # the then() callback resolves the promise by returning
  after 6 copy

async_hooks.executionAsyncResource()#

Added in: v13.9.0, v12.17.0


Returns: <Object> The resource representing the current execution.
Useful to store data within the resource.

Resource objects returned by executionAsyncResource() are most often internal
Node.js handle objects with undocumented APIs. Using any functions or properties
on the object is likely to crash your application and should be avoided.
Using executionAsyncResource() in the top-level execution context will
return an empty object as there is no handle or request object to use,
but having an object representing the top-level can be helpful.

import { open } from 'node:fs';
import { executionAsyncId, executionAsyncResource } from 'node:async_hooks';

console.log(executionAsyncId(), executionAsyncResource());  // 1 {}
open(new URL(import.meta.url), 'r', (err, fd) => {
  console.log(executionAsyncId(), executionAsyncResource());  // 7 FSReqWrap
});const { open } = require('node:fs');
const { executionAsyncId, executionAsyncResource } = require('node:async_hooks');

console.log(executionAsyncId(), executionAsyncResource());  // 1 {}
open(__filename, 'r', (err, fd) => {
  console.log(executionAsyncId(), executionAsyncResource());  // 7 FSReqWrap
});copy
This can be used to implement continuation local storage without the
use of a tracking Map to store the metadata:

import { createServer } from 'node:http';
import {
  executionAsyncId,
  executionAsyncResource,
  createHook,
} from 'node:async_hooks';
const sym = Symbol('state'); // Private symbol to avoid pollution

createHook({
  init(asyncId, type, triggerAsyncId, resource) {
    const cr = executionAsyncResource();
    if (cr) {
      resource[sym] = cr[sym];
    }
  },
}).enable();

const server = createServer((req, res) => {
  executionAsyncResource()[sym] = { state: req.url };
  setTimeout(function() {
    res.end(JSON.stringify(executionAsyncResource()[sym]));
  }, 100);
}).listen(3000);const { createServer } = require('node:http');
const {
  executionAsyncId,
  executionAsyncResource,
  createHook,
} = require('node:async_hooks');
const sym = Symbol('state'); // Private symbol to avoid pollution

createHook({
  init(asyncId, type, triggerAsyncId, resource) {
    const cr = executionAsyncResource();
    if (cr) {
      resource[sym] = cr[sym];
    }
  },
}).enable();

const server = createServer((req, res) => {
  executionAsyncResource()[sym] = { state: req.url };
  setTimeout(function() {
    res.end(JSON.stringify(executionAsyncResource()[sym]));
  }, 100);
}).listen(3000);copy

async_hooks.executionAsyncId()#

History

VersionChanges
v8.2.0
Renamed from currentId.
v8.1.0
Added in: v8.1.0




Returns: <number> The asyncId of the current execution context. Useful to
track when something calls.


import { executionAsyncId } from 'node:async_hooks';
import fs from 'node:fs';

console.log(executionAsyncId());  // 1 - bootstrap
const path = '.';
fs.open(path, 'r', (err, fd) => {
  console.log(executionAsyncId());  // 6 - open()
});const async_hooks = require('node:async_hooks');
const fs = require('node:fs');

console.log(async_hooks.executionAsyncId());  // 1 - bootstrap
const path = '.';
fs.open(path, 'r', (err, fd) => {
  console.log(async_hooks.executionAsyncId());  // 6 - open()
});copy
The ID returned from executionAsyncId() is related to execution timing, not
causality (which is covered by triggerAsyncId()):
const server = net.createServer((conn) => {
  // Returns the ID of the server, not of the new connection, because the
  // callback runs in the execution scope of the server's MakeCallback().
  async_hooks.executionAsyncId();

}).listen(port, () => {
  // Returns the ID of a TickObject (process.nextTick()) because all
  // callbacks passed to .listen() are wrapped in a nextTick().
  async_hooks.executionAsyncId();
}); copy
Promise contexts may not get precise executionAsyncIds by default.
See the section on promise execution tracking.

async_hooks.triggerAsyncId()#

Returns: <number> The ID of the resource responsible for calling the callback
that is currently being executed.

const server = net.createServer((conn) => {
  // The resource that caused (or triggered) this callback to be called
  // was that of the new connection. Thus the return value of triggerAsyncId()
  // is the asyncId of "conn".
  async_hooks.triggerAsyncId();

}).listen(port, () => {
  // Even though all callbacks passed to .listen() are wrapped in a nextTick()
  // the callback itself exists because the call to the server's .listen()
  // was made. So the return value would be the ID of the server.
  async_hooks.triggerAsyncId();
}); copy
Promise contexts may not get valid triggerAsyncIds by default. See
the section on promise execution tracking.

async_hooks.asyncWrapProviders#

Added in: v17.2.0, v16.14.0


Returns: A map of provider types to the corresponding numeric id.
This map contains all the event types that might be emitted by the async_hooks.init() event.

This feature suppresses the deprecated usage of process.binding('async_wrap').Providers.
See: DEP0111

Promise execution tracking#
By default, promise executions are not assigned asyncIds due to the relatively
expensive nature of the promise introspection API provided by
V8. This means that programs using promises or async/await will not get
correct execution and trigger ids for promise callback contexts by default.

import { executionAsyncId, triggerAsyncId } from 'node:async_hooks';

Promise.resolve(1729).then(() => {
  console.log(`eid ${executionAsyncId()} tid ${triggerAsyncId()}`);
});
// produces:
// eid 1 tid 0const { executionAsyncId, triggerAsyncId } = require('node:async_hooks');

Promise.resolve(1729).then(() => {
  console.log(`eid ${executionAsyncId()} tid ${triggerAsyncId()}`);
});
// produces:
// eid 1 tid 0copy
Observe that the then() callback claims to have executed in the context of the
outer scope even though there was an asynchronous hop involved. Also,
the triggerAsyncId value is 0, which means that we are missing context about
the resource that caused (triggered) the then() callback to be executed.
Installing async hooks via async_hooks.createHook enables promise execution
tracking:

import { createHook, executionAsyncId, triggerAsyncId } from 'node:async_hooks';
createHook({ init() {} }).enable(); // forces PromiseHooks to be enabled.
Promise.resolve(1729).then(() => {
  console.log(`eid ${executionAsyncId()} tid ${triggerAsyncId()}`);
});
// produces:
// eid 7 tid 6const { createHook, executionAsyncId, triggerAsyncId } = require('node:async_hooks');

createHook({ init() {} }).enable(); // forces PromiseHooks to be enabled.
Promise.resolve(1729).then(() => {
  console.log(`eid ${executionAsyncId()} tid ${triggerAsyncId()}`);
});
// produces:
// eid 7 tid 6copy
In this example, adding any actual hook function enabled the tracking of
promises. There are two promises in the example above; the promise created by
Promise.resolve() and the promise returned by the call to then(). In the
example above, the first promise got the asyncId 6 and the latter got
asyncId 7. During the execution of the then() callback, we are executing
in the context of promise with asyncId 7. This promise was triggered by
async resource 6.
Another subtlety with promises is that before and after callbacks are run
only on chained promises. That means promises not created by then()/catch()
will not have the before and after callbacks fired on them. For more details
see the details of the V8 PromiseHooks API.
JavaScript embedder API#
Library developers that handle their own asynchronous resources performing tasks
like I/O, connection pooling, or managing callback queues may use the
AsyncResource JavaScript API so that all the appropriate callbacks are called.

Class: AsyncResource#
The documentation for this class has moved AsyncResource.

Class: AsyncLocalStorage#
The documentation for this class has moved AsyncLocalStorage.\n\n\n\nNode.js
        
      
      
About this documentation
Usage and example



Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Modules: TypeScript
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
Readline
REPL
Report
Single executable applications
SQLite
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker

    

    
      
        
          Node.js v24.0.1 documentation
          
            
            
          
        
        
          
            Node.js v24.0.1
            
    
      
        
        Table of contents
      

      
Buffer

Buffers and character encodings
Buffers and TypedArrays
Buffers and iteration
Class: Blob

new buffer.Blob([sources[, options]])
blob.arrayBuffer()

blob.bytes()


blob.size
blob.slice([start[, end[, type]]])
blob.stream()
blob.text()
blob.type
Blob objects and MessageChannel


Class: Buffer

Static method: Buffer.alloc(size[, fill[, encoding]])
Static method: Buffer.allocUnsafe(size)
Static method: Buffer.allocUnsafeSlow(size)
Static method: Buffer.byteLength(string[, encoding])
Static method: Buffer.compare(buf1, buf2)
Static method: Buffer.concat(list[, totalLength])
Static method: Buffer.copyBytesFrom(view[, offset[, length]])
Static method: Buffer.from(array)
Static method: Buffer.from(arrayBuffer[, byteOffset[, length]])
Static method: Buffer.from(buffer)
Static method: Buffer.from(object[, offsetOrEncoding[, length]])
Static method: Buffer.from(string[, encoding])
Static method: Buffer.isBuffer(obj)
Static method: Buffer.isEncoding(encoding)
Class property: Buffer.poolSize
buf[index]
buf.buffer
buf.byteOffset
buf.compare(target[, targetStart[, targetEnd[, sourceStart[, sourceEnd]]]])
buf.copy(target[, targetStart[, sourceStart[, sourceEnd]]])
buf.entries()
buf.equals(otherBuffer)
buf.fill(value[, offset[, end]][, encoding])
buf.includes(value[, byteOffset][, encoding])
buf.indexOf(value[, byteOffset][, encoding])
buf.keys()
buf.lastIndexOf(value[, byteOffset][, encoding])
buf.length
buf.parent
buf.readBigInt64BE([offset])
buf.readBigInt64LE([offset])
buf.readBigUInt64BE([offset])
buf.readBigUInt64LE([offset])
buf.readDoubleBE([offset])
buf.readDoubleLE([offset])
buf.readFloatBE([offset])
buf.readFloatLE([offset])
buf.readInt8([offset])
buf.readInt16BE([offset])
buf.readInt16LE([offset])
buf.readInt32BE([offset])
buf.readInt32LE([offset])
buf.readIntBE(offset, byteLength)
buf.readIntLE(offset, byteLength)
buf.readUInt8([offset])
buf.readUInt16BE([offset])
buf.readUInt16LE([offset])
buf.readUInt32BE([offset])
buf.readUInt32LE([offset])
buf.readUIntBE(offset, byteLength)
buf.readUIntLE(offset, byteLength)
buf.subarray([start[, end]])
buf.slice([start[, end]])
buf.swap16()
buf.swap32()
buf.swap64()
buf.toJSON()
buf.toString([encoding[, start[, end]]])
buf.values()
buf.write(string[, offset[, length]][, encoding])
buf.writeBigInt64BE(value[, offset])
buf.writeBigInt64LE(value[, offset])
buf.writeBigUInt64BE(value[, offset])
buf.writeBigUInt64LE(value[, offset])
buf.writeDoubleBE(value[, offset])
buf.writeDoubleLE(value[, offset])
buf.writeFloatBE(value[, offset])
buf.writeFloatLE(value[, offset])
buf.writeInt8(value[, offset])
buf.writeInt16BE(value[, offset])
buf.writeInt16LE(value[, offset])
buf.writeInt32BE(value[, offset])
buf.writeInt32LE(value[, offset])
buf.writeIntBE(value, offset, byteLength)
buf.writeIntLE(value, offset, byteLength)
buf.writeUInt8(value[, offset])
buf.writeUInt16BE(value[, offset])
buf.writeUInt16LE(value[, offset])
buf.writeUInt32BE(value[, offset])
buf.writeUInt32LE(value[, offset])
buf.writeUIntBE(value, offset, byteLength)
buf.writeUIntLE(value, offset, byteLength)
new Buffer(array)
new Buffer(arrayBuffer[, byteOffset[, length]])
new Buffer(buffer)
new Buffer(size)
new Buffer(string[, encoding])


Class: File

new buffer.File(sources, fileName[, options])
file.name
file.lastModified


node:buffer module APIs

buffer.atob(data)
buffer.btoa(data)
buffer.isAscii(input)
buffer.isUtf8(input)
buffer.INSPECT_MAX_BYTES
buffer.kMaxLength
buffer.kStringMaxLength
buffer.resolveObjectURL(id)
buffer.transcode(source, fromEnc, toEnc)
Class: SlowBuffer

new SlowBuffer(size)


Buffer constants

buffer.constants.MAX_LENGTH
buffer.constants.MAX_STRING_LENGTH




Buffer.from(), Buffer.alloc(), and Buffer.allocUnsafe()

The --zero-fill-buffers command-line option
What makes Buffer.allocUnsafe() and Buffer.allocUnsafeSlow() "unsafe"?





    
  
            
    
      
        
        Index
      

      
About this documentation
Usage and example

      
        Index
      
    
  


Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Modules: TypeScript
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
Readline
REPL
Report
Single executable applications
SQLite
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker

    
  
            
    
      
        
        Other versions
      
      24.x
23.x
22.x LTS
21.x
20.x LTS
19.x
18.x
17.x
16.x
15.x
14.x
13.x
12.x
11.x
10.x
9.x
8.x
7.x
6.x
5.x
4.x
0.12.x
0.10.x
    
  
            
              
                
                Options
              
        
              
                
                  
                    View on single page
                  
                  
                    View as JSON
                  
                  Edit on GitHub    
                
              
            
          
        
        
      

      Table of contents
Buffer

Buffers and character encodings
Buffers and TypedArrays
Buffers and iteration
Class: Blob

new buffer.Blob([sources[, options]])
blob.arrayBuffer()

blob.bytes()


blob.size
blob.slice([start[, end[, type]]])
blob.stream()
blob.text()
blob.type
Blob objects and MessageChannel


Class: Buffer

Static method: Buffer.alloc(size[, fill[, encoding]])
Static method: Buffer.allocUnsafe(size)
Static method: Buffer.allocUnsafeSlow(size)
Static method: Buffer.byteLength(string[, encoding])
Static method: Buffer.compare(buf1, buf2)
Static method: Buffer.concat(list[, totalLength])
Static method: Buffer.copyBytesFrom(view[, offset[, length]])
Static method: Buffer.from(array)
Static method: Buffer.from(arrayBuffer[, byteOffset[, length]])
Static method: Buffer.from(buffer)
Static method: Buffer.from(object[, offsetOrEncoding[, length]])
Static method: Buffer.from(string[, encoding])
Static method: Buffer.isBuffer(obj)
Static method: Buffer.isEncoding(encoding)
Class property: Buffer.poolSize
buf[index]
buf.buffer
buf.byteOffset
buf.compare(target[, targetStart[, targetEnd[, sourceStart[, sourceEnd]]]])
buf.copy(target[, targetStart[, sourceStart[, sourceEnd]]])
buf.entries()
buf.equals(otherBuffer)
buf.fill(value[, offset[, end]][, encoding])
buf.includes(value[, byteOffset][, encoding])
buf.indexOf(value[, byteOffset][, encoding])
buf.keys()
buf.lastIndexOf(value[, byteOffset][, encoding])
buf.length
buf.parent
buf.readBigInt64BE([offset])
buf.readBigInt64LE([offset])
buf.readBigUInt64BE([offset])
buf.readBigUInt64LE([offset])
buf.readDoubleBE([offset])
buf.readDoubleLE([offset])
buf.readFloatBE([offset])
buf.readFloatLE([offset])
buf.readInt8([offset])
buf.readInt16BE([offset])
buf.readInt16LE([offset])
buf.readInt32BE([offset])
buf.readInt32LE([offset])
buf.readIntBE(offset, byteLength)
buf.readIntLE(offset, byteLength)
buf.readUInt8([offset])
buf.readUInt16BE([offset])
buf.readUInt16LE([offset])
buf.readUInt32BE([offset])
buf.readUInt32LE([offset])
buf.readUIntBE(offset, byteLength)
buf.readUIntLE(offset, byteLength)
buf.subarray([start[, end]])
buf.slice([start[, end]])
buf.swap16()
buf.swap32()
buf.swap64()
buf.toJSON()
buf.toString([encoding[, start[, end]]])
buf.values()
buf.write(string[, offset[, length]][, encoding])
buf.writeBigInt64BE(value[, offset])
buf.writeBigInt64LE(value[, offset])
buf.writeBigUInt64BE(value[, offset])
buf.writeBigUInt64LE(value[, offset])
buf.writeDoubleBE(value[, offset])
buf.writeDoubleLE(value[, offset])
buf.writeFloatBE(value[, offset])
buf.writeFloatLE(value[, offset])
buf.writeInt8(value[, offset])
buf.writeInt16BE(value[, offset])
buf.writeInt16LE(value[, offset])
buf.writeInt32BE(value[, offset])
buf.writeInt32LE(value[, offset])
buf.writeIntBE(value, offset, byteLength)
buf.writeIntLE(value, offset, byteLength)
buf.writeUInt8(value[, offset])
buf.writeUInt16BE(value[, offset])
buf.writeUInt16LE(value[, offset])
buf.writeUInt32BE(value[, offset])
buf.writeUInt32LE(value[, offset])
buf.writeUIntBE(value, offset, byteLength)
buf.writeUIntLE(value, offset, byteLength)
new Buffer(array)
new Buffer(arrayBuffer[, byteOffset[, length]])
new Buffer(buffer)
new Buffer(size)
new Buffer(string[, encoding])


Class: File

new buffer.File(sources, fileName[, options])
file.name
file.lastModified


node:buffer module APIs

buffer.atob(data)
buffer.btoa(data)
buffer.isAscii(input)
buffer.isUtf8(input)
buffer.INSPECT_MAX_BYTES
buffer.kMaxLength
buffer.kStringMaxLength
buffer.resolveObjectURL(id)
buffer.transcode(source, fromEnc, toEnc)
Class: SlowBuffer

new SlowBuffer(size)


Buffer constants

buffer.constants.MAX_LENGTH
buffer.constants.MAX_STRING_LENGTH




Buffer.from(), Buffer.alloc(), and Buffer.allocUnsafe()

The --zero-fill-buffers command-line option
What makes Buffer.allocUnsafe() and Buffer.allocUnsafeSlow() "unsafe"?






      
        Buffer#

Stability: 2 - Stable
Source Code: lib/buffer.js
Buffer objects are used to represent a fixed-length sequence of bytes. Many
Node.js APIs support Buffers.
The Buffer class is a subclass of JavaScript's <Uint8Array> class and
extends it with methods that cover additional use cases. Node.js APIs accept
plain <Uint8Array>s wherever Buffers are supported as well.
While the Buffer class is available within the global scope, it is still
recommended to explicitly reference it via an import or require statement.

import { Buffer } from 'node:buffer';

// Creates a zero-filled Buffer of length 10.
const buf1 = Buffer.alloc(10);

// Creates a Buffer of length 10,
// filled with bytes which all have the value `1`.
const buf2 = Buffer.alloc(10, 1);

// Creates an uninitialized buffer of length 10.
// This is faster than calling Buffer.alloc() but the returned
// Buffer instance might contain old data that needs to be
// overwritten using fill(), write(), or other functions that fill the Buffer's
// contents.
const buf3 = Buffer.allocUnsafe(10);

// Creates a Buffer containing the bytes [1, 2, 3].
const buf4 = Buffer.from([1, 2, 3]);

// Creates a Buffer containing the bytes [1, 1, 1, 1] – the entries
// are all truncated using `(value & 255)` to fit into the range 0–255.
const buf5 = Buffer.from([257, 257.5, -255, '1']);

// Creates a Buffer containing the UTF-8-encoded bytes for the string 'tést':
// [0x74, 0xc3, 0xa9, 0x73, 0x74] (in hexadecimal notation)
// [116, 195, 169, 115, 116] (in decimal notation)
const buf6 = Buffer.from('tést');

// Creates a Buffer containing the Latin-1 bytes [0x74, 0xe9, 0x73, 0x74].
const buf7 = Buffer.from('tést', 'latin1');const { Buffer } = require('node:buffer');

// Creates a zero-filled Buffer of length 10.
const buf1 = Buffer.alloc(10);

// Creates a Buffer of length 10,
// filled with bytes which all have the value `1`.
const buf2 = Buffer.alloc(10, 1);

// Creates an uninitialized buffer of length 10.
// This is faster than calling Buffer.alloc() but the returned
// Buffer instance might contain old data that needs to be
// overwritten using fill(), write(), or other functions that fill the Buffer's
// contents.
const buf3 = Buffer.allocUnsafe(10);

// Creates a Buffer containing the bytes [1, 2, 3].
const buf4 = Buffer.from([1, 2, 3]);

// Creates a Buffer containing the bytes [1, 1, 1, 1] – the entries
// are all truncated using `(value & 255)` to fit into the range 0–255.
const buf5 = Buffer.from([257, 257.5, -255, '1']);

// Creates a Buffer containing the UTF-8-encoded bytes for the string 'tést':
// [0x74, 0xc3, 0xa9, 0x73, 0x74] (in hexadecimal notation)
// [116, 195, 169, 115, 116] (in decimal notation)
const buf6 = Buffer.from('tést');

// Creates a Buffer containing the Latin-1 bytes [0x74, 0xe9, 0x73, 0x74].
const buf7 = Buffer.from('tést', 'latin1');copy
Buffers and character encodings#

History

VersionChanges
v15.7.0, v14.18.0
Introduced base64url encoding.
v6.4.0
Introduced latin1 as an alias for binary.
v5.0.0
Removed the deprecated raw and raws encodings.



When converting between Buffers and strings, a character encoding may be
specified. If no character encoding is specified, UTF-8 will be used as the
default.

import { Buffer } from 'node:buffer';

const buf = Buffer.from('hello world', 'utf8');

console.log(buf.toString('hex'));
// Prints: 68656c6c6f20776f726c64
console.log(buf.toString('base64'));
// Prints: aGVsbG8gd29ybGQ=

console.log(Buffer.from('fhqwhgads', 'utf8'));
// Prints: <Buffer 66 68 71 77 68 67 61 64 73>
console.log(Buffer.from('fhqwhgads', 'utf16le'));
// Prints: <Buffer 66 00 68 00 71 00 77 00 68 00 67 00 61 00 64 00 73 00>const { Buffer } = require('node:buffer');

const buf = Buffer.from('hello world', 'utf8');

console.log(buf.toString('hex'));
// Prints: 68656c6c6f20776f726c64
console.log(buf.toString('base64'));
// Prints: aGVsbG8gd29ybGQ=

console.log(Buffer.from('fhqwhgads', 'utf8'));
// Prints: <Buffer 66 68 71 77 68 67 61 64 73>
console.log(Buffer.from('fhqwhgads', 'utf16le'));
// Prints: <Buffer 66 00 68 00 71 00 77 00 68 00 67 00 61 00 64 00 73 00>copy
Node.js buffers accept all case variations of encoding strings that they
receive. For example, UTF-8 can be specified as 'utf8', 'UTF8', or 'uTf8'.
The character encodings currently supported by Node.js are the following:


'utf8' (alias: 'utf-8'): Multi-byte encoded Unicode characters. Many web
pages and other document formats use UTF-8. This is the default character
encoding. When decoding a Buffer into a string that does not exclusively
contain valid UTF-8 data, the Unicode replacement character U+FFFD � will be
used to represent those errors.


'utf16le' (alias: 'utf-16le'): Multi-byte encoded Unicode characters.
Unlike 'utf8', each character in the string will be encoded using either 2
or 4 bytes. Node.js only supports the little-endian variant of
UTF-16.


'latin1': Latin-1 stands for ISO-8859-1. This character encoding only
supports the Unicode characters from U+0000 to U+00FF. Each character is
encoded using a single byte. Characters that do not fit into that range are
truncated and will be mapped to characters in that range.


Converting a Buffer into a string using one of the above is referred to as
decoding, and converting a string into a Buffer is referred to as encoding.
Node.js also supports the following binary-to-text encodings. For
binary-to-text encodings, the naming convention is reversed: Converting a
Buffer into a string is typically referred to as encoding, and converting a
string into a Buffer as decoding.


'base64': Base64 encoding. When creating a Buffer from a string,
this encoding will also correctly accept "URL and Filename Safe Alphabet" as
specified in RFC 4648, Section 5. Whitespace characters such as spaces,
tabs, and new lines contained within the base64-encoded string are ignored.


'base64url': base64url encoding as specified in
RFC 4648, Section 5. When creating a Buffer from a string, this
encoding will also correctly accept regular base64-encoded strings. When
encoding a Buffer to a string, this encoding will omit padding.


'hex': Encode each byte as two hexadecimal characters. Data truncation
may occur when decoding strings that do not exclusively consist of an even
number of hexadecimal characters. See below for an example.


The following legacy character encodings are also supported:


'ascii': For 7-bit ASCII data only. When encoding a string into a
Buffer, this is equivalent to using 'latin1'. When decoding a Buffer
into a string, using this encoding will additionally unset the highest bit of
each byte before decoding as 'latin1'.
Generally, there should be no reason to use this encoding, as 'utf8'
(or, if the data is known to always be ASCII-only, 'latin1') will be a
better choice when encoding or decoding ASCII-only text. It is only provided
for legacy compatibility.


'binary': Alias for 'latin1'.
The name of this encoding can be very misleading, as all of the
encodings listed here convert between strings and binary data. For converting
between strings and Buffers, typically 'utf8' is the right choice.


'ucs2', 'ucs-2': Aliases of 'utf16le'. UCS-2 used to refer to a variant
of UTF-16 that did not support characters that had code points larger than
U+FFFF. In Node.js, these code points are always supported.



import { Buffer } from 'node:buffer';

Buffer.from('1ag123', 'hex');
// Prints <Buffer 1a>, data truncated when first non-hexadecimal value
// ('g') encountered.

Buffer.from('1a7', 'hex');
// Prints <Buffer 1a>, data truncated when data ends in single digit ('7').

Buffer.from('1634', 'hex');
// Prints <Buffer 16 34>, all data represented.const { Buffer } = require('node:buffer');

Buffer.from('1ag123', 'hex');
// Prints <Buffer 1a>, data truncated when first non-hexadecimal value
// ('g') encountered.

Buffer.from('1a7', 'hex');
// Prints <Buffer 1a>, data truncated when data ends in single digit ('7').

Buffer.from('1634', 'hex');
// Prints <Buffer 16 34>, all data represented.copy
Modern Web browsers follow the WHATWG Encoding Standard which aliases
both 'latin1' and 'ISO-8859-1' to 'win-1252'. This means that while doing
something like http.get(), if the returned charset is one of those listed in
the WHATWG specification it is possible that the server actually returned
'win-1252'-encoded data, and using 'latin1' encoding may incorrectly decode
the characters.
Buffers and TypedArrays#

History

VersionChanges
v3.0.0
The Buffer class now inherits from Uint8Array.



Buffer instances are also JavaScript <Uint8Array> and <TypedArray>
instances. All <TypedArray> methods are available on Buffers. There are,
however, subtle incompatibilities between the Buffer API and the
<TypedArray> API.
In particular:

While TypedArray.prototype.slice() creates a copy of part of the TypedArray,
Buffer.prototype.slice() creates a view over the existing Buffer
without copying. This behavior can be surprising, and only exists for legacy
compatibility. TypedArray.prototype.subarray() can be used to achieve
the behavior of Buffer.prototype.slice() on both Buffers
and other TypedArrays and should be preferred.
buf.toString() is incompatible with its TypedArray equivalent.
A number of methods, e.g. buf.indexOf(), support additional arguments.

There are two ways to create new <TypedArray> instances from a Buffer:

Passing a Buffer to a <TypedArray> constructor will copy the Buffer's
contents, interpreted as an array of integers, and not as a byte sequence
of the target type.


import { Buffer } from 'node:buffer';

const buf = Buffer.from([1, 2, 3, 4]);
const uint32array = new Uint32Array(buf);

console.log(uint32array);

// Prints: Uint32Array(4) [ 1, 2, 3, 4 ]const { Buffer } = require('node:buffer');

const buf = Buffer.from([1, 2, 3, 4]);
const uint32array = new Uint32Array(buf);

console.log(uint32array);

// Prints: Uint32Array(4) [ 1, 2, 3, 4 ]copy

Passing the Buffer's underlying <ArrayBuffer> will create a
<TypedArray> that shares its memory with the Buffer.


import { Buffer } from 'node:buffer';

const buf = Buffer.from('hello', 'utf16le');
const uint16array = new Uint16Array(
  buf.buffer,
  buf.byteOffset,
  buf.length / Uint16Array.BYTES_PER_ELEMENT);

console.log(uint16array);

// Prints: Uint16Array(5) [ 104, 101, 108, 108, 111 ]const { Buffer } = require('node:buffer');

const buf = Buffer.from('hello', 'utf16le');
const uint16array = new Uint16Array(
  buf.buffer,
  buf.byteOffset,
  buf.length / Uint16Array.BYTES_PER_ELEMENT);

console.log(uint16array);

// Prints: Uint16Array(5) [ 104, 101, 108, 108, 111 ]copy
It is possible to create a new Buffer that shares the same allocated
memory as a <TypedArray> instance by using the TypedArray object's
.buffer property in the same way. Buffer.from()
behaves like new Uint8Array() in this context.

import { Buffer } from 'node:buffer';

const arr = new Uint16Array(2);

arr[0] = 5000;
arr[1] = 4000;

// Copies the contents of `arr`.
const buf1 = Buffer.from(arr);

// Shares memory with `arr`.
const buf2 = Buffer.from(arr.buffer);

console.log(buf1);
// Prints: <Buffer 88 a0>
console.log(buf2);
// Prints: <Buffer 88 13 a0 0f>

arr[1] = 6000;

console.log(buf1);
// Prints: <Buffer 88 a0>
console.log(buf2);
// Prints: <Buffer 88 13 70 17>const { Buffer } = require('node:buffer');

const arr = new Uint16Array(2);

arr[0] = 5000;
arr[1] = 4000;

// Copies the contents of `arr`.
const buf1 = Buffer.from(arr);

// Shares memory with `arr`.
const buf2 = Buffer.from(arr.buffer);

console.log(buf1);
// Prints: <Buffer 88 a0>
console.log(buf2);
// Prints: <Buffer 88 13 a0 0f>

arr[1] = 6000;

console.log(buf1);
// Prints: <Buffer 88 a0>
console.log(buf2);
// Prints: <Buffer 88 13 70 17>copy
When creating a Buffer using a <TypedArray>'s .buffer, it is
possible to use only a portion of the underlying <ArrayBuffer> by passing in
byteOffset and length parameters.

import { Buffer } from 'node:buffer';

const arr = new Uint16Array(20);
const buf = Buffer.from(arr.buffer, 0, 16);

console.log(buf.length);
// Prints: 16const { Buffer } = require('node:buffer');

const arr = new Uint16Array(20);
const buf = Buffer.from(arr.buffer, 0, 16);

console.log(buf.length);
// Prints: 16copy
The Buffer.from() and TypedArray.from() have different signatures and
implementations. Specifically, the <TypedArray> variants accept a second
argument that is a mapping function that is invoked on every element of the
typed array:

TypedArray.from(source[, mapFn[, thisArg]])

The Buffer.from() method, however, does not support the use of a mapping
function:

Buffer.from(array)
Buffer.from(buffer)
Buffer.from(arrayBuffer[, byteOffset[, length]])
Buffer.from(string[, encoding])

Buffers and iteration#
Buffer instances can be iterated over using for..of syntax:

import { Buffer } from 'node:buffer';

const buf = Buffer.from([1, 2, 3]);

for (const b of buf) {
  console.log(b);
}
// Prints:
//   1
//   2
//   3const { Buffer } = require('node:buffer');

const buf = Buffer.from([1, 2, 3]);

for (const b of buf) {
  console.log(b);
}
// Prints:
//   1
//   2
//   3copy
Additionally, the buf.values(), buf.keys(), and
buf.entries() methods can be used to create iterators.
Class: Blob#

History

VersionChanges
v18.0.0, v16.17.0
No longer experimental.
v15.7.0, v14.18.0
Added in: v15.7.0, v14.18.0



A Blob encapsulates immutable, raw data that can be safely shared across
multiple worker threads.

new buffer.Blob([sources[, options]])#

History

VersionChanges
v16.7.0
Added the standard endings option to replace line-endings, and removed the non-standard encoding option.
v15.7.0, v14.18.0
Added in: v15.7.0, v14.18.0




sources <string[]> | <ArrayBuffer[]> | <TypedArray[]> | <DataView[]> | <Blob[]> An
array of string, <ArrayBuffer>, <TypedArray>, <DataView>, or <Blob> objects,
or any mix of such objects, that will be stored within the Blob.
options <Object>

endings <string> One of either 'transparent' or 'native'. When set
to 'native', line endings in string source parts will be converted to
the platform native line-ending as specified by require('node:os').EOL.
type <string> The Blob content-type. The intent is for type to convey
the MIME media type of the data, however no validation of the type format
is performed.



Creates a new Blob object containing a concatenation of the given sources.
<ArrayBuffer>, <TypedArray>, <DataView>, and <Buffer> sources are copied into
the 'Blob' and can therefore be safely modified after the 'Blob' is created.
String sources are encoded as UTF-8 byte sequences and copied into the Blob.
Unmatched surrogate pairs within each string part will be replaced by Unicode
U+FFFD replacement characters.

blob.arrayBuffer()#

Added in: v15.7.0, v14.18.0


Returns: <Promise>

Returns a promise that fulfills with an <ArrayBuffer> containing a copy of
the Blob data.

blob.bytes()#

Added in: v22.3.0, v20.16.0

The blob.bytes() method returns the byte of the Blob object as a Promise<Uint8Array>.
const blob = new Blob(['hello']);
blob.bytes().then((bytes) => {
  console.log(bytes); // Outputs: Uint8Array(5) [ 104, 101, 108, 108, 111 ]
}); copy

blob.size#

Added in: v15.7.0, v14.18.0

The total size of the Blob in bytes.

blob.slice([start[, end[, type]]])#

Added in: v15.7.0, v14.18.0


start <number> The starting index.
end <number> The ending index.
type <string> The content-type for the new Blob

Creates and returns a new Blob containing a subset of this Blob objects
data. The original Blob is not altered.

blob.stream()#

Added in: v16.7.0


Returns: <ReadableStream>

Returns a new ReadableStream that allows the content of the Blob to be read.

blob.text()#

Added in: v15.7.0, v14.18.0


Returns: <Promise>

Returns a promise that fulfills with the contents of the Blob decoded as a
UTF-8 string.

blob.type#

Added in: v15.7.0, v14.18.0


Type: <string>

The content-type of the Blob.

Blob objects and MessageChannel#
Once a <Blob> object is created, it can be sent via MessagePort to multiple
destinations without transferring or immediately copying the data. The data
contained by the Blob is copied only when the arrayBuffer() or text()
methods are called.

import { Blob } from 'node:buffer';
import { setTimeout as delay } from 'node:timers/promises';

const blob = new Blob(['hello there']);

const mc1 = new MessageChannel();
const mc2 = new MessageChannel();

mc1.port1.onmessage = async ({ data }) => {
  console.log(await data.arrayBuffer());
  mc1.port1.close();
};

mc2.port1.onmessage = async ({ data }) => {
  await delay(1000);
  console.log(await data.arrayBuffer());
  mc2.port1.close();
};

mc1.port2.postMessage(blob);
mc2.port2.postMessage(blob);

// The Blob is still usable after posting.
blob.text().then(console.log);const { Blob } = require('node:buffer');
const { setTimeout: delay } = require('node:timers/promises');

const blob = new Blob(['hello there']);

const mc1 = new MessageChannel();
const mc2 = new MessageChannel();

mc1.port1.onmessage = async ({ data }) => {
  console.log(await data.arrayBuffer());
  mc1.port1.close();
};

mc2.port1.onmessage = async ({ data }) => {
  await delay(1000);
  console.log(await data.arrayBuffer());
  mc2.port1.close();
};

mc1.port2.postMessage(blob);
mc2.port2.postMessage(blob);

// The Blob is still usable after posting.
blob.text().then(console.log);copy

Class: Buffer#
The Buffer class is a global type for dealing with binary data directly.
It can be constructed in a variety of ways.

Static method: Buffer.alloc(size[, fill[, encoding]])#

History

VersionChanges
v20.0.0
Throw ERR_INVALID_ARG_TYPE or ERR_OUT_OF_RANGE instead of ERR_INVALID_ARG_VALUE for invalid input arguments.
v15.0.0
Throw ERR_INVALID_ARG_VALUE instead of ERR_INVALID_OPT_VALUE for invalid input arguments.
v10.0.0
Attempting to fill a non-zero length buffer with a zero length buffer triggers a thrown exception.
v10.0.0
Specifying an invalid string for fill triggers a thrown exception.
v8.9.3
Specifying an invalid string for fill now results in a zero-filled buffer.
v5.10.0
Added in: v5.10.0




size <integer> The desired length of the new Buffer.
fill <string> | <Buffer> | <Uint8Array> | <integer> A value to pre-fill the new Buffer
with. Default: 0.
encoding <string> If fill is a string, this is its encoding.
Default: 'utf8'.
Returns: <Buffer>

Allocates a new Buffer of size bytes. If fill is undefined, the
Buffer will be zero-filled.

import { Buffer } from 'node:buffer';

const buf = Buffer.alloc(5);

console.log(buf);
// Prints: <Buffer 00 00 00 00 00>const { Buffer } = require('node:buffer');

const buf = Buffer.alloc(5);

console.log(buf);
// Prints: <Buffer 00 00 00 00 00>copy
If size is larger than
buffer.constants.MAX_LENGTH or smaller than 0, ERR_OUT_OF_RANGE
is thrown.
If fill is specified, the allocated Buffer will be initialized by calling
buf.fill(fill).

import { Buffer } from 'node:buffer';

const buf = Buffer.alloc(5, 'a');

console.log(buf);
// Prints: <Buffer 61 61 61 61 61>const { Buffer } = require('node:buffer');

const buf = Buffer.alloc(5, 'a');

console.log(buf);
// Prints: <Buffer 61 61 61 61 61>copy
If both fill and encoding are specified, the allocated Buffer will be
initialized by calling buf.fill(fill, encoding).

import { Buffer } from 'node:buffer';

const buf = Buffer.alloc(11, 'aGVsbG8gd29ybGQ=', 'base64');

console.log(buf);
// Prints: <Buffer 68 65 6c 6c 6f 20 77 6f 72 6c 64>const { Buffer } = require('node:buffer');

const buf = Buffer.alloc(11, 'aGVsbG8gd29ybGQ=', 'base64');

console.log(buf);
// Prints: <Buffer 68 65 6c 6c 6f 20 77 6f 72 6c 64>copy
Calling Buffer.alloc() can be measurably slower than the alternative
Buffer.allocUnsafe() but ensures that the newly created Buffer instance
contents will never contain sensitive data from previous allocations, including
data that might not have been allocated for Buffers.
A TypeError will be thrown if size is not a number.

Static method: Buffer.allocUnsafe(size)#

History

VersionChanges
v20.0.0
Throw ERR_INVALID_ARG_TYPE or ERR_OUT_OF_RANGE instead of ERR_INVALID_ARG_VALUE for invalid input arguments.
v15.0.0
Throw ERR_INVALID_ARG_VALUE instead of ERR_INVALID_OPT_VALUE for invalid input arguments.
v7.0.0
Passing a negative size will now throw an error.
v5.10.0
Added in: v5.10.0




size <integer> The desired length of the new Buffer.
Returns: <Buffer>

Allocates a new Buffer of size bytes. If size is larger than
buffer.constants.MAX_LENGTH or smaller than 0, ERR_OUT_OF_RANGE
is thrown.
The underlying memory for Buffer instances created in this way is not
initialized. The contents of the newly created Buffer are unknown and
may contain sensitive data. Use Buffer.alloc() instead to initialize
Buffer instances with zeroes.

import { Buffer } from 'node:buffer';

const buf = Buffer.allocUnsafe(10);

console.log(buf);
// Prints (contents may vary): <Buffer a0 8b 28 3f 01 00 00 00 50 32>

buf.fill(0);

console.log(buf);
// Prints: <Buffer 00 00 00 00 00 00 00 00 00 00>const { Buffer } = require('node:buffer');

const buf = Buffer.allocUnsafe(10);

console.log(buf);
// Prints (contents may vary): <Buffer a0 8b 28 3f 01 00 00 00 50 32>

buf.fill(0);

console.log(buf);
// Prints: <Buffer 00 00 00 00 00 00 00 00 00 00>copy
A TypeError will be thrown if size is not a number.
The Buffer module pre-allocates an internal Buffer instance of
size Buffer.poolSize that is used as a pool for the fast allocation of new
Buffer instances created using Buffer.allocUnsafe(), Buffer.from(array),
Buffer.from(string), and Buffer.concat() only when size is less than
Buffer.poolSize >>> 1 (floor of Buffer.poolSize divided by two).
Use of this pre-allocated internal memory pool is a key difference between
calling Buffer.alloc(size, fill) vs. Buffer.allocUnsafe(size).fill(fill).
Specifically, Buffer.alloc(size, fill) will never use the internal Buffer
pool, while Buffer.allocUnsafe(size).fill(fill) will use the internal
Buffer pool if size is less than or equal to half Buffer.poolSize. The
difference is subtle but can be important when an application requires the
additional performance that Buffer.allocUnsafe() provides.

Static method: Buffer.allocUnsafeSlow(size)#

History

VersionChanges
v20.0.0
Throw ERR_INVALID_ARG_TYPE or ERR_OUT_OF_RANGE instead of ERR_INVALID_ARG_VALUE for invalid input arguments.
v15.0.0
Throw ERR_INVALID_ARG_VALUE instead of ERR_INVALID_OPT_VALUE for invalid input arguments.
v5.12.0
Added in: v5.12.0




size <integer> The desired length of the new Buffer.
Returns: <Buffer>

Allocates a new Buffer of size bytes. If size is larger than
buffer.constants.MAX_LENGTH or smaller than 0, ERR_OUT_OF_RANGE
is thrown. A zero-length Buffer is created if size is 0.
The underlying memory for Buffer instances created in this way is not
initialized. The contents of the newly created Buffer are unknown and
may contain sensitive data. Use buf.fill(0) to initialize
such Buffer instances with zeroes.
When using Buffer.allocUnsafe() to allocate new Buffer instances,
allocations less than Buffer.poolSize >>> 1 (4KiB when default poolSize is used) are sliced
from a single pre-allocated Buffer. This allows applications to avoid the
garbage collection overhead of creating many individually allocated Buffer
instances. This approach improves both performance and memory usage by
eliminating the need to track and clean up as many individual ArrayBuffer objects.
However, in the case where a developer may need to retain a small chunk of
memory from a pool for an indeterminate amount of time, it may be appropriate
to create an un-pooled Buffer instance using Buffer.allocUnsafeSlow() and
then copying out the relevant bits.

import { Buffer } from 'node:buffer';

// Need to keep around a few small chunks of memory.
const store = [];

socket.on('readable', () => {
  let data;
  while (null !== (data = readable.read())) {
    // Allocate for retained data.
    const sb = Buffer.allocUnsafeSlow(10);

    // Copy the data into the new allocation.
    data.copy(sb, 0, 0, 10);

    store.push(sb);
  }
});const { Buffer } = require('node:buffer');

// Need to keep around a few small chunks of memory.
const store = [];

socket.on('readable', () => {
  let data;
  while (null !== (data = readable.read())) {
    // Allocate for retained data.
    const sb = Buffer.allocUnsafeSlow(10);

    // Copy the data into the new allocation.
    data.copy(sb, 0, 0, 10);

    store.push(sb);
  }
});copy
A TypeError will be thrown if size is not a number.

Static method: Buffer.byteLength(string[, encoding])#

History

VersionChanges
v7.0.0
Passing invalid input will now throw an error.
v5.10.0
The string parameter can now be any TypedArray, DataView or ArrayBuffer.
v0.1.90
Added in: v0.1.90




string <string> | <Buffer> | <TypedArray> | <DataView> | <ArrayBuffer> | <SharedArrayBuffer> A
value to calculate the length of.
encoding <string> If string is a string, this is its encoding.
Default: 'utf8'.
Returns: <integer> The number of bytes contained within string.

Returns the byte length of a string when encoded using encoding.
This is not the same as String.prototype.length, which does not account
for the encoding that is used to convert the string into bytes.
For 'base64', 'base64url', and 'hex', this function assumes valid input.
For strings that contain non-base64/hex-encoded data (e.g. whitespace), the
return value might be greater than the length of a Buffer created from the
string.

import { Buffer } from 'node:buffer';

const str = '\u00bd + \u00bc = \u00be';

console.log(`${str}: ${str.length} characters, ` +
            `${Buffer.byteLength(str, 'utf8')} bytes`);
// Prints: ½ + ¼ = ¾: 9 characters, 12 bytesconst { Buffer } = require('node:buffer');

const str = '\u00bd + \u00bc = \u00be';

console.log(`${str}: ${str.length} characters, ` +
            `${Buffer.byteLength(str, 'utf8')} bytes`);
// Prints: ½ + ¼ = ¾: 9 characters, 12 bytescopy
When string is a <Buffer> | <DataView> | <TypedArray> | <ArrayBuffer> | <SharedArrayBuffer>,
the byte length as reported by .byteLength is returned.

Static method: Buffer.compare(buf1, buf2)#

History

VersionChanges
v8.0.0
The arguments can now be Uint8Arrays.
v0.11.13
Added in: v0.11.13




buf1 <Buffer> | <Uint8Array>
buf2 <Buffer> | <Uint8Array>
Returns: <integer> Either -1, 0, or 1, depending on the result of the
comparison. See buf.compare() for details.

Compares buf1 to buf2, typically for the purpose of sorting arrays of
Buffer instances. This is equivalent to calling
buf1.compare(buf2).

import { Buffer } from 'node:buffer';

const buf1 = Buffer.from('1234');
const buf2 = Buffer.from('0123');
const arr = [buf1, buf2];

console.log(arr.sort(Buffer.compare));
// Prints: [ <Buffer 30 31 32 33>, <Buffer 31 32 33 34> ]
// (This result is equal to: [buf2, buf1].)const { Buffer } = require('node:buffer');

const buf1 = Buffer.from('1234');
const buf2 = Buffer.from('0123');
const arr = [buf1, buf2];

console.log(arr.sort(Buffer.compare));
// Prints: [ <Buffer 30 31 32 33>, <Buffer 31 32 33 34> ]
// (This result is equal to: [buf2, buf1].)copy

Static method: Buffer.concat(list[, totalLength])#

History

VersionChanges
v8.0.0
The elements of list can now be Uint8Arrays.
v0.7.11
Added in: v0.7.11




list <Buffer[]> | <Uint8Array[]> List of Buffer or <Uint8Array>
instances to concatenate.
totalLength <integer> Total length of the Buffer instances in list
when concatenated.
Returns: <Buffer>

Returns a new Buffer which is the result of concatenating all the Buffer
instances in the list together.
If the list has no items, or if the totalLength is 0, then a new zero-length
Buffer is returned.
If totalLength is not provided, it is calculated from the Buffer instances
in list by adding their lengths.
If totalLength is provided, it is coerced to an unsigned integer. If the
combined length of the Buffers in list exceeds totalLength, the result is
truncated to totalLength. If the combined length of the Buffers in list is
less than totalLength, the remaining space is filled with zeros.

import { Buffer } from 'node:buffer';

// Create a single `Buffer` from a list of three `Buffer` instances.

const buf1 = Buffer.alloc(10);
const buf2 = Buffer.alloc(14);
const buf3 = Buffer.alloc(18);
const totalLength = buf1.length + buf2.length + buf3.length;

console.log(totalLength);
// Prints: 42

const bufA = Buffer.concat([buf1, buf2, buf3], totalLength);

console.log(bufA);
// Prints: <Buffer 00 00 00 00 ...>
console.log(bufA.length);
// Prints: 42const { Buffer } = require('node:buffer');

// Create a single `Buffer` from a list of three `Buffer` instances.

const buf1 = Buffer.alloc(10);
const buf2 = Buffer.alloc(14);
const buf3 = Buffer.alloc(18);
const totalLength = buf1.length + buf2.length + buf3.length;

console.log(totalLength);
// Prints: 42

const bufA = Buffer.concat([buf1, buf2, buf3], totalLength);

console.log(bufA);
// Prints: <Buffer 00 00 00 00 ...>
console.log(bufA.length);
// Prints: 42copy
Buffer.concat() may also use the internal Buffer pool like
Buffer.allocUnsafe() does.

Static method: Buffer.copyBytesFrom(view[, offset[, length]])#

Added in: v19.8.0, v18.16.0


view <TypedArray> The <TypedArray> to copy.
offset <integer> The starting offset within view. Default: 0.
length <integer> The number of elements from view to copy.
Default: view.length - offset.
Returns: <Buffer>

Copies the underlying memory of view into a new Buffer.
const u16 = new Uint16Array([0, 0xffff]);
const buf = Buffer.copyBytesFrom(u16, 1, 1);
u16[1] = 0;
console.log(buf.length); // 2
console.log(buf[0]); // 255
console.log(buf[1]); // 255 copy

Static method: Buffer.from(array)#

Added in: v5.10.0


array <integer[]>
Returns: <Buffer>

Allocates a new Buffer using an array of bytes in the range 0 – 255.
Array entries outside that range will be truncated to fit into it.

import { Buffer } from 'node:buffer';

// Creates a new Buffer containing the UTF-8 bytes of the string 'buffer'.
const buf = Buffer.from([0x62, 0x75, 0x66, 0x66, 0x65, 0x72]);const { Buffer } = require('node:buffer');

// Creates a new Buffer containing the UTF-8 bytes of the string 'buffer'.
const buf = Buffer.from([0x62, 0x75, 0x66, 0x66, 0x65, 0x72]);copy
If array is an Array-like object (that is, one with a length property of
type number), it is treated as if it is an array, unless it is a Buffer or
a Uint8Array. This means all other TypedArray variants get treated as an
Array. To create a Buffer from the bytes backing a TypedArray, use
Buffer.copyBytesFrom().
A TypeError will be thrown if array is not an Array or another type
appropriate for Buffer.from() variants.
Buffer.from(array) and Buffer.from(string) may also use the internal
Buffer pool like Buffer.allocUnsafe() does.

Static method: Buffer.from(arrayBuffer[, byteOffset[, length]])#

Added in: v5.10.0


arrayBuffer <ArrayBuffer> | <SharedArrayBuffer> An <ArrayBuffer>,
<SharedArrayBuffer>, for example the .buffer property of a
<TypedArray>.
byteOffset <integer> Index of first byte to expose. Default: 0.
length <integer> Number of bytes to expose.
Default: arrayBuffer.byteLength - byteOffset.
Returns: <Buffer>

This creates a view of the <ArrayBuffer> without copying the underlying
memory. For example, when passed a reference to the .buffer property of a
<TypedArray> instance, the newly created Buffer will share the same
allocated memory as the <TypedArray>'s underlying ArrayBuffer.

import { Buffer } from 'node:buffer';

const arr = new Uint16Array(2);

arr[0] = 5000;
arr[1] = 4000;

// Shares memory with `arr`.
const buf = Buffer.from(arr.buffer);

console.log(buf);
// Prints: <Buffer 88 13 a0 0f>

// Changing the original Uint16Array changes the Buffer also.
arr[1] = 6000;

console.log(buf);
// Prints: <Buffer 88 13 70 17>const { Buffer } = require('node:buffer');

const arr = new Uint16Array(2);

arr[0] = 5000;
arr[1] = 4000;

// Shares memory with `arr`.
const buf = Buffer.from(arr.buffer);

console.log(buf);
// Prints: <Buffer 88 13 a0 0f>

// Changing the original Uint16Array changes the Buffer also.
arr[1] = 6000;

console.log(buf);
// Prints: <Buffer 88 13 70 17>copy
The optional byteOffset and length arguments specify a memory range within
the arrayBuffer that will be shared by the Buffer.

import { Buffer } from 'node:buffer';

const ab = new ArrayBuffer(10);
const buf = Buffer.from(ab, 0, 2);

console.log(buf.length);
// Prints: 2const { Buffer } = require('node:buffer');

const ab = new ArrayBuffer(10);
const buf = Buffer.from(ab, 0, 2);

console.log(buf.length);
// Prints: 2copy
A TypeError will be thrown if arrayBuffer is not an <ArrayBuffer> or a
<SharedArrayBuffer> or another type appropriate for Buffer.from()
variants.
It is important to remember that a backing ArrayBuffer can cover a range
of memory that extends beyond the bounds of a TypedArray view. A new
Buffer created using the buffer property of a TypedArray may extend
beyond the range of the TypedArray:

import { Buffer } from 'node:buffer';

const arrA = Uint8Array.from([0x63, 0x64, 0x65, 0x66]); // 4 elements
const arrB = new Uint8Array(arrA.buffer, 1, 2); // 2 elements
console.log(arrA.buffer === arrB.buffer); // true

const buf = Buffer.from(arrB.buffer);
console.log(buf);
// Prints: <Buffer 63 64 65 66>const { Buffer } = require('node:buffer');

const arrA = Uint8Array.from([0x63, 0x64, 0x65, 0x66]); // 4 elements
const arrB = new Uint8Array(arrA.buffer, 1, 2); // 2 elements
console.log(arrA.buffer === arrB.buffer); // true

const buf = Buffer.from(arrB.buffer);
console.log(buf);
// Prints: <Buffer 63 64 65 66>copy

Static method: Buffer.from(buffer)#

Added in: v5.10.0


buffer <Buffer> | <Uint8Array> An existing Buffer or <Uint8Array> from
which to copy data.
Returns: <Buffer>

Copies the passed buffer data onto a new Buffer instance.

import { Buffer } from 'node:buffer';

const buf1 = Buffer.from('buffer');
const buf2 = Buffer.from(buf1);

buf1[0] = 0x61;

console.log(buf1.toString());
// Prints: auffer
console.log(buf2.toString());
// Prints: bufferconst { Buffer } = require('node:buffer');

const buf1 = Buffer.from('buffer');
const buf2 = Buffer.from(buf1);

buf1[0] = 0x61;

console.log(buf1.toString());
// Prints: auffer
console.log(buf2.toString());
// Prints: buffercopy
A TypeError will be thrown if buffer is not a Buffer or another type
appropriate for Buffer.from() variants.

Static method: Buffer.from(object[, offsetOrEncoding[, length]])#

Added in: v8.2.0


object <Object> An object supporting Symbol.toPrimitive or valueOf().
offsetOrEncoding <integer> | <string> A byte-offset or encoding.
length <integer> A length.
Returns: <Buffer>

For objects whose valueOf() function returns a value not strictly equal to
object, returns Buffer.from(object.valueOf(), offsetOrEncoding, length).

import { Buffer } from 'node:buffer';

const buf = Buffer.from(new String('this is a test'));
// Prints: <Buffer 74 68 69 73 20 69 73 20 61 20 74 65 73 74>const { Buffer } = require('node:buffer');

const buf = Buffer.from(new String('this is a test'));
// Prints: <Buffer 74 68 69 73 20 69 73 20 61 20 74 65 73 74>copy
For objects that support Symbol.toPrimitive, returns
Buffer.from(object[Symbol.toPrimitive]('string'), offsetOrEncoding).

import { Buffer } from 'node:buffer';

class Foo {
  [Symbol.toPrimitive]() {
    return 'this is a test';
  }
}

const buf = Buffer.from(new Foo(), 'utf8');
// Prints: <Buffer 74 68 69 73 20 69 73 20 61 20 74 65 73 74>const { Buffer } = require('node:buffer');

class Foo {
  [Symbol.toPrimitive]() {
    return 'this is a test';
  }
}

const buf = Buffer.from(new Foo(), 'utf8');
// Prints: <Buffer 74 68 69 73 20 69 73 20 61 20 74 65 73 74>copy
A TypeError will be thrown if object does not have the mentioned methods or
is not of another type appropriate for Buffer.from() variants.

Static method: Buffer.from(string[, encoding])#

Added in: v5.10.0


string <string> A string to encode.
encoding <string> The encoding of string. Default: 'utf8'.
Returns: <Buffer>

Creates a new Buffer containing string. The encoding parameter identifies
the character encoding to be used when converting string into bytes.

import { Buffer } from 'node:buffer';

const buf1 = Buffer.from('this is a tést');
const buf2 = Buffer.from('7468697320697320612074c3a97374', 'hex');

console.log(buf1.toString());
// Prints: this is a tést
console.log(buf2.toString());
// Prints: this is a tést
console.log(buf1.toString('latin1'));
// Prints: this is a tÃ©stconst { Buffer } = require('node:buffer');

const buf1 = Buffer.from('this is a tést');
const buf2 = Buffer.from('7468697320697320612074c3a97374', 'hex');

console.log(buf1.toString());
// Prints: this is a tést
console.log(buf2.toString());
// Prints: this is a tést
console.log(buf1.toString('latin1'));
// Prints: this is a tÃ©stcopy
A TypeError will be thrown if string is not a string or another type
appropriate for Buffer.from() variants.
Buffer.from(string) may also use the internal Buffer pool like
Buffer.allocUnsafe() does.

Static method: Buffer.isBuffer(obj)#

Added in: v0.1.101


obj <Object>
Returns: <boolean>

Returns true if obj is a Buffer, false otherwise.

import { Buffer } from 'node:buffer';

Buffer.isBuffer(Buffer.alloc(10)); // true
Buffer.isBuffer(Buffer.from('foo')); // true
Buffer.isBuffer('a string'); // false
Buffer.isBuffer([]); // false
Buffer.isBuffer(new Uint8Array(1024)); // falseconst { Buffer } = require('node:buffer');

Buffer.isBuffer(Buffer.alloc(10)); // true
Buffer.isBuffer(Buffer.from('foo')); // true
Buffer.isBuffer('a string'); // false
Buffer.isBuffer([]); // false
Buffer.isBuffer(new Uint8Array(1024)); // falsecopy

Static method: Buffer.isEncoding(encoding)#

Added in: v0.9.1


encoding <string> A character encoding name to check.
Returns: <boolean>

Returns true if encoding is the name of a supported character encoding,
or false otherwise.

import { Buffer } from 'node:buffer';

console.log(Buffer.isEncoding('utf8'));
// Prints: true

console.log(Buffer.isEncoding('hex'));
// Prints: true

console.log(Buffer.isEncoding('utf/8'));
// Prints: false

console.log(Buffer.isEncoding(''));
// Prints: falseconst { Buffer } = require('node:buffer');

console.log(Buffer.isEncoding('utf8'));
// Prints: true

console.log(Buffer.isEncoding('hex'));
// Prints: true

console.log(Buffer.isEncoding('utf/8'));
// Prints: false

console.log(Buffer.isEncoding(''));
// Prints: falsecopy

Class property: Buffer.poolSize#

Added in: v0.11.3


<integer> Default: 8192

This is the size (in bytes) of pre-allocated internal Buffer instances used
for pooling. This value may be modified.

buf[index]#

index <integer>

The index operator [index] can be used to get and set the octet at position
index in buf. The values refer to individual bytes, so the legal value
range is between 0x00 and 0xFF (hex) or 0 and 255 (decimal).
This operator is inherited from Uint8Array, so its behavior on out-of-bounds
access is the same as Uint8Array. In other words, buf[index] returns
undefined when index is negative or greater or equal to buf.length, and
buf[index] = value does not modify the buffer if index is negative or
>= buf.length.

import { Buffer } from 'node:buffer';

// Copy an ASCII string into a `Buffer` one byte at a time.
// (This only works for ASCII-only strings. In general, one should use
// `Buffer.from()` to perform this conversion.)

const str = 'Node.js';
const buf = Buffer.allocUnsafe(str.length);

for (let i = 0; i < str.length; i++) {
  buf[i] = str.charCodeAt(i);
}

console.log(buf.toString('utf8'));
// Prints: Node.jsconst { Buffer } = require('node:buffer');

// Copy an ASCII string into a `Buffer` one byte at a time.
// (This only works for ASCII-only strings. In general, one should use
// `Buffer.from()` to perform this conversion.)

const str = 'Node.js';
const buf = Buffer.allocUnsafe(str.length);

for (let i = 0; i < str.length; i++) {
  buf[i] = str.charCodeAt(i);
}

console.log(buf.toString('utf8'));
// Prints: Node.jscopy

buf.buffer#

<ArrayBuffer> The underlying ArrayBuffer object based on which this Buffer
object is created.

This ArrayBuffer is not guaranteed to correspond exactly to the original
Buffer. See the notes on buf.byteOffset for details.

import { Buffer } from 'node:buffer';

const arrayBuffer = new ArrayBuffer(16);
const buffer = Buffer.from(arrayBuffer);

console.log(buffer.buffer === arrayBuffer);
// Prints: trueconst { Buffer } = require('node:buffer');

const arrayBuffer = new ArrayBuffer(16);
const buffer = Buffer.from(arrayBuffer);

console.log(buffer.buffer === arrayBuffer);
// Prints: truecopy

buf.byteOffset#

<integer> The byteOffset of the Buffer's underlying ArrayBuffer object.

When setting byteOffset in Buffer.from(ArrayBuffer, byteOffset, length),
or sometimes when allocating a Buffer smaller than Buffer.poolSize, the
buffer does not start from a zero offset on the underlying ArrayBuffer.
This can cause problems when accessing the underlying ArrayBuffer directly
using buf.buffer, as other parts of the ArrayBuffer may be unrelated
to the Buffer object itself.
A common issue when creating a TypedArray object that shares its memory with
a Buffer is that in this case one needs to specify the byteOffset correctly:

import { Buffer } from 'node:buffer';

// Create a buffer smaller than `Buffer.poolSize`.
const nodeBuffer = Buffer.from([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]);

// When casting the Node.js Buffer to an Int8Array, use the byteOffset
// to refer only to the part of `nodeBuffer.buffer` that contains the memory
// for `nodeBuffer`.
new Int8Array(nodeBuffer.buffer, nodeBuffer.byteOffset, nodeBuffer.length);const { Buffer } = require('node:buffer');

// Create a buffer smaller than `Buffer.poolSize`.
const nodeBuffer = Buffer.from([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]);

// When casting the Node.js Buffer to an Int8Array, use the byteOffset
// to refer only to the part of `nodeBuffer.buffer` that contains the memory
// for `nodeBuffer`.
new Int8Array(nodeBuffer.buffer, nodeBuffer.byteOffset, nodeBuffer.length);copy

buf.compare(target[, targetStart[, targetEnd[, sourceStart[, sourceEnd]]]])#

History

VersionChanges
v8.0.0
The target parameter can now be a Uint8Array.
v5.11.0
Additional parameters for specifying offsets are supported now.
v0.11.13
Added in: v0.11.13




target <Buffer> | <Uint8Array> A Buffer or <Uint8Array> with which to
compare buf.
targetStart <integer> The offset within target at which to begin
comparison. Default: 0.
targetEnd <integer> The offset within target at which to end comparison
(not inclusive). Default: target.length.
sourceStart <integer> The offset within buf at which to begin comparison.
Default: 0.
sourceEnd <integer> The offset within buf at which to end comparison
(not inclusive). Default: buf.length.
Returns: <integer>

Compares buf with target and returns a number indicating whether buf
comes before, after, or is the same as target in sort order.
Comparison is based on the actual sequence of bytes in each Buffer.

0 is returned if target is the same as buf
1 is returned if target should come before buf when sorted.
-1 is returned if target should come after buf when sorted.


import { Buffer } from 'node:buffer';

const buf1 = Buffer.from('ABC');
const buf2 = Buffer.from('BCD');
const buf3 = Buffer.from('ABCD');

console.log(buf1.compare(buf1));
// Prints: 0
console.log(buf1.compare(buf2));
// Prints: -1
console.log(buf1.compare(buf3));
// Prints: -1
console.log(buf2.compare(buf1));
// Prints: 1
console.log(buf2.compare(buf3));
// Prints: 1
console.log([buf1, buf2, buf3].sort(Buffer.compare));
// Prints: [ <Buffer 41 42 43>, <Buffer 41 42 43 44>, <Buffer 42 43 44> ]
// (This result is equal to: [buf1, buf3, buf2].)const { Buffer } = require('node:buffer');

const buf1 = Buffer.from('ABC');
const buf2 = Buffer.from('BCD');
const buf3 = Buffer.from('ABCD');

console.log(buf1.compare(buf1));
// Prints: 0
console.log(buf1.compare(buf2));
// Prints: -1
console.log(buf1.compare(buf3));
// Prints: -1
console.log(buf2.compare(buf1));
// Prints: 1
console.log(buf2.compare(buf3));
// Prints: 1
console.log([buf1, buf2, buf3].sort(Buffer.compare));
// Prints: [ <Buffer 41 42 43>, <Buffer 41 42 43 44>, <Buffer 42 43 44> ]
// (This result is equal to: [buf1, buf3, buf2].)copy
The optional targetStart, targetEnd, sourceStart, and sourceEnd
arguments can be used to limit the comparison to specific ranges within target
and buf respectively.

import { Buffer } from 'node:buffer';

const buf1 = Buffer.from([1, 2, 3, 4, 5, 6, 7, 8, 9]);
const buf2 = Buffer.from([5, 6, 7, 8, 9, 1, 2, 3, 4]);

console.log(buf1.compare(buf2, 5, 9, 0, 4));
// Prints: 0
console.log(buf1.compare(buf2, 0, 6, 4));
// Prints: -1
console.log(buf1.compare(buf2, 5, 6, 5));
// Prints: 1const { Buffer } = require('node:buffer');

const buf1 = Buffer.from([1, 2, 3, 4, 5, 6, 7, 8, 9]);
const buf2 = Buffer.from([5, 6, 7, 8, 9, 1, 2, 3, 4]);

console.log(buf1.compare(buf2, 5, 9, 0, 4));
// Prints: 0
console.log(buf1.compare(buf2, 0, 6, 4));
// Prints: -1
console.log(buf1.compare(buf2, 5, 6, 5));
// Prints: 1copy
ERR_OUT_OF_RANGE is thrown if targetStart < 0, sourceStart < 0,
targetEnd > target.byteLength, or sourceEnd > source.byteLength.

buf.copy(target[, targetStart[, sourceStart[, sourceEnd]]])#

Added in: v0.1.90


target <Buffer> | <Uint8Array> A Buffer or <Uint8Array> to copy into.
targetStart <integer> The offset within target at which to begin
writing. Default: 0.
sourceStart <integer> The offset within buf from which to begin copying.
Default: 0.
sourceEnd <integer> The offset within buf at which to stop copying (not
inclusive). Default: buf.length.
Returns: <integer> The number of bytes copied.

Copies data from a region of buf to a region in target, even if the target
memory region overlaps with buf.
TypedArray.prototype.set() performs the same operation, and is available
for all TypedArrays, including Node.js Buffers, although it takes
different function arguments.

import { Buffer } from 'node:buffer';

// Create two `Buffer` instances.
const buf1 = Buffer.allocUnsafe(26);
const buf2 = Buffer.allocUnsafe(26).fill('!');

for (let i = 0; i < 26; i++) {
  // 97 is the decimal ASCII value for 'a'.
  buf1[i] = i + 97;
}

// Copy `buf1` bytes 16 through 19 into `buf2` starting at byte 8 of `buf2`.
buf1.copy(buf2, 8, 16, 20);
// This is equivalent to:
// buf2.set(buf1.subarray(16, 20), 8);

console.log(buf2.toString('ascii', 0, 25));
// Prints: !!!!!!!!qrst!!!!!!!!!!!!!const { Buffer } = require('node:buffer');

// Create two `Buffer` instances.
const buf1 = Buffer.allocUnsafe(26);
const buf2 = Buffer.allocUnsafe(26).fill('!');

for (let i = 0; i < 26; i++) {
  // 97 is the decimal ASCII value for 'a'.
  buf1[i] = i + 97;
}

// Copy `buf1` bytes 16 through 19 into `buf2` starting at byte 8 of `buf2`.
buf1.copy(buf2, 8, 16, 20);
// This is equivalent to:
// buf2.set(buf1.subarray(16, 20), 8);

console.log(buf2.toString('ascii', 0, 25));
// Prints: !!!!!!!!qrst!!!!!!!!!!!!!copy

import { Buffer } from 'node:buffer';

// Create a `Buffer` and copy data from one region to an overlapping region
// within the same `Buffer`.

const buf = Buffer.allocUnsafe(26);

for (let i = 0; i < 26; i++) {
  // 97 is the decimal ASCII value for 'a'.
  buf[i] = i + 97;
}

buf.copy(buf, 0, 4, 10);

console.log(buf.toString());
// Prints: efghijghijklmnopqrstuvwxyzconst { Buffer } = require('node:buffer');

// Create a `Buffer` and copy data from one region to an overlapping region
// within the same `Buffer`.

const buf = Buffer.allocUnsafe(26);

for (let i = 0; i < 26; i++) {
  // 97 is the decimal ASCII value for 'a'.
  buf[i] = i + 97;
}

buf.copy(buf, 0, 4, 10);

console.log(buf.toString());
// Prints: efghijghijklmnopqrstuvwxyzcopy

buf.entries()#

Added in: v1.1.0


Returns: <Iterator>

Creates and returns an iterator of [index, byte] pairs from the contents
of buf.

import { Buffer } from 'node:buffer';

// Log the entire contents of a `Buffer`.

const buf = Buffer.from('buffer');

for (const pair of buf.entries()) {
  console.log(pair);
}
// Prints:
//   [0, 98]
//   [1, 117]
//   [2, 102]
//   [3, 102]
//   [4, 101]
//   [5, 114]const { Buffer } = require('node:buffer');

// Log the entire contents of a `Buffer`.

const buf = Buffer.from('buffer');

for (const pair of buf.entries()) {
  console.log(pair);
}
// Prints:
//   [0, 98]
//   [1, 117]
//   [2, 102]
//   [3, 102]
//   [4, 101]
//   [5, 114]copy

buf.equals(otherBuffer)#

History

VersionChanges
v8.0.0
The arguments can now be Uint8Arrays.
v0.11.13
Added in: v0.11.13




otherBuffer <Buffer> | <Uint8Array> A Buffer or <Uint8Array> with which to
compare buf.
Returns: <boolean>

Returns true if both buf and otherBuffer have exactly the same bytes,
false otherwise. Equivalent to
buf.compare(otherBuffer) === 0.

import { Buffer } from 'node:buffer';

const buf1 = Buffer.from('ABC');
const buf2 = Buffer.from('414243', 'hex');
const buf3 = Buffer.from('ABCD');

console.log(buf1.equals(buf2));
// Prints: true
console.log(buf1.equals(buf3));
// Prints: falseconst { Buffer } = require('node:buffer');

const buf1 = Buffer.from('ABC');
const buf2 = Buffer.from('414243', 'hex');
const buf3 = Buffer.from('ABCD');

console.log(buf1.equals(buf2));
// Prints: true
console.log(buf1.equals(buf3));
// Prints: falsecopy

buf.fill(value[, offset[, end]][, encoding])#

History

VersionChanges
v11.0.0
Throws ERR_OUT_OF_RANGE instead of ERR_INDEX_OUT_OF_RANGE.
v10.0.0
Negative end values throw an ERR_INDEX_OUT_OF_RANGE error.
v10.0.0
Attempting to fill a non-zero length buffer with a zero length buffer triggers a thrown exception.
v10.0.0
Specifying an invalid string for value triggers a thrown exception.
v5.7.0
The encoding parameter is supported now.
v0.5.0
Added in: v0.5.0




value <string> | <Buffer> | <Uint8Array> | <integer> The value with which to fill buf.
Empty value (string, Uint8Array, Buffer) is coerced to 0.
offset <integer> Number of bytes to skip before starting to fill buf.
Default: 0.
end <integer> Where to stop filling buf (not inclusive). Default:
buf.length.
encoding <string> The encoding for value if value is a string.
Default: 'utf8'.
Returns: <Buffer> A reference to buf.

Fills buf with the specified value. If the offset and end are not given,
the entire buf will be filled:

import { Buffer } from 'node:buffer';

// Fill a `Buffer` with the ASCII character 'h'.

const b = Buffer.allocUnsafe(50).fill('h');

console.log(b.toString());
// Prints: hhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh

// Fill a buffer with empty string
const c = Buffer.allocUnsafe(5).fill('');

console.log(c.fill(''));
// Prints: <Buffer 00 00 00 00 00>const { Buffer } = require('node:buffer');

// Fill a `Buffer` with the ASCII character 'h'.

const b = Buffer.allocUnsafe(50).fill('h');

console.log(b.toString());
// Prints: hhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh

// Fill a buffer with empty string
const c = Buffer.allocUnsafe(5).fill('');

console.log(c.fill(''));
// Prints: <Buffer 00 00 00 00 00>copy
value is coerced to a uint32 value if it is not a string, Buffer, or
integer. If the resulting integer is greater than 255 (decimal), buf will be
filled with value & 255.
If the final write of a fill() operation falls on a multi-byte character,
then only the bytes of that character that fit into buf are written:

import { Buffer } from 'node:buffer';

// Fill a `Buffer` with character that takes up two bytes in UTF-8.

console.log(Buffer.allocUnsafe(5).fill('\u0222'));
// Prints: <Buffer c8 a2 c8 a2 c8>const { Buffer } = require('node:buffer');

// Fill a `Buffer` with character that takes up two bytes in UTF-8.

console.log(Buffer.allocUnsafe(5).fill('\u0222'));
// Prints: <Buffer c8 a2 c8 a2 c8>copy
If value contains invalid characters, it is truncated; if no valid
fill data remains, an exception is thrown:

import { Buffer } from 'node:buffer';

const buf = Buffer.allocUnsafe(5);

console.log(buf.fill('a'));
// Prints: <Buffer 61 61 61 61 61>
console.log(buf.fill('aazz', 'hex'));
// Prints: <Buffer aa aa aa aa aa>
console.log(buf.fill('zz', 'hex'));
// Throws an exception.const { Buffer } = require('node:buffer');

const buf = Buffer.allocUnsafe(5);

console.log(buf.fill('a'));
// Prints: <Buffer 61 61 61 61 61>
console.log(buf.fill('aazz', 'hex'));
// Prints: <Buffer aa aa aa aa aa>
console.log(buf.fill('zz', 'hex'));
// Throws an exception.copy

buf.includes(value[, byteOffset][, encoding])#

Added in: v5.3.0


value <string> | <Buffer> | <Uint8Array> | <integer> What to search for.
byteOffset <integer> Where to begin searching in buf. If negative, then
offset is calculated from the end of buf. Default: 0.
encoding <string> If value is a string, this is its encoding.
Default: 'utf8'.
Returns: <boolean> true if value was found in buf, false otherwise.

Equivalent to buf.indexOf() !== -1.

import { Buffer } from 'node:buffer';

const buf = Buffer.from('this is a buffer');

console.log(buf.includes('this'));
// Prints: true
console.log(buf.includes('is'));
// Prints: true
console.log(buf.includes(Buffer.from('a buffer')));
// Prints: true
console.log(buf.includes(97));
// Prints: true (97 is the decimal ASCII value for 'a')
console.log(buf.includes(Buffer.from('a buffer example')));
// Prints: false
console.log(buf.includes(Buffer.from('a buffer example').slice(0, 8)));
// Prints: true
console.log(buf.includes('this', 4));
// Prints: falseconst { Buffer } = require('node:buffer');

const buf = Buffer.from('this is a buffer');

console.log(buf.includes('this'));
// Prints: true
console.log(buf.includes('is'));
// Prints: true
console.log(buf.includes(Buffer.from('a buffer')));
// Prints: true
console.log(buf.includes(97));
// Prints: true (97 is the decimal ASCII value for 'a')
console.log(buf.includes(Buffer.from('a buffer example')));
// Prints: false
console.log(buf.includes(Buffer.from('a buffer example').slice(0, 8)));
// Prints: true
console.log(buf.includes('this', 4));
// Prints: falsecopy

buf.indexOf(value[, byteOffset][, encoding])#

History

VersionChanges
v8.0.0
The value can now be a Uint8Array.
v5.7.0, v4.4.0
When encoding is being passed, the byteOffset parameter is no longer required.
v1.5.0
Added in: v1.5.0




value <string> | <Buffer> | <Uint8Array> | <integer> What to search for.
byteOffset <integer> Where to begin searching in buf. If negative, then
offset is calculated from the end of buf. Default: 0.
encoding <string> If value is a string, this is the encoding used to
determine the binary representation of the string that will be searched for in
buf. Default: 'utf8'.
Returns: <integer> The index of the first occurrence of value in buf, or
-1 if buf does not contain value.

If value is:

a string, value is interpreted according to the character encoding in
encoding.
a Buffer or <Uint8Array>, value will be used in its entirety.
To compare a partial Buffer, use buf.subarray.
a number, value will be interpreted as an unsigned 8-bit integer
value between 0 and 255.


import { Buffer } from 'node:buffer';

const buf = Buffer.from('this is a buffer');

console.log(buf.indexOf('this'));
// Prints: 0
console.log(buf.indexOf('is'));
// Prints: 2
console.log(buf.indexOf(Buffer.from('a buffer')));
// Prints: 8
console.log(buf.indexOf(97));
// Prints: 8 (97 is the decimal ASCII value for 'a')
console.log(buf.indexOf(Buffer.from('a buffer example')));
// Prints: -1
console.log(buf.indexOf(Buffer.from('a buffer example').slice(0, 8)));
// Prints: 8

const utf16Buffer = Buffer.from('\u039a\u0391\u03a3\u03a3\u0395', 'utf16le');

console.log(utf16Buffer.indexOf('\u03a3', 0, 'utf16le'));
// Prints: 4
console.log(utf16Buffer.indexOf('\u03a3', -4, 'utf16le'));
// Prints: 6const { Buffer } = require('node:buffer');

const buf = Buffer.from('this is a buffer');

console.log(buf.indexOf('this'));
// Prints: 0
console.log(buf.indexOf('is'));
// Prints: 2
console.log(buf.indexOf(Buffer.from('a buffer')));
// Prints: 8
console.log(buf.indexOf(97));
// Prints: 8 (97 is the decimal ASCII value for 'a')
console.log(buf.indexOf(Buffer.from('a buffer example')));
// Prints: -1
console.log(buf.indexOf(Buffer.from('a buffer example').slice(0, 8)));
// Prints: 8

const utf16Buffer = Buffer.from('\u039a\u0391\u03a3\u03a3\u0395', 'utf16le');

console.log(utf16Buffer.indexOf('\u03a3', 0, 'utf16le'));
// Prints: 4
console.log(utf16Buffer.indexOf('\u03a3', -4, 'utf16le'));
// Prints: 6copy
If value is not a string, number, or Buffer, this method will throw a
TypeError. If value is a number, it will be coerced to a valid byte value,
an integer between 0 and 255.
If byteOffset is not a number, it will be coerced to a number. If the result
of coercion is NaN or 0, then the entire buffer will be searched. This
behavior matches String.prototype.indexOf().

import { Buffer } from 'node:buffer';

const b = Buffer.from('abcdef');

// Passing a value that's a number, but not a valid byte.
// Prints: 2, equivalent to searching for 99 or 'c'.
console.log(b.indexOf(99.9));
console.log(b.indexOf(256 + 99));

// Passing a byteOffset that coerces to NaN or 0.
// Prints: 1, searching the whole buffer.
console.log(b.indexOf('b', undefined));
console.log(b.indexOf('b', {}));
console.log(b.indexOf('b', null));
console.log(b.indexOf('b', []));const { Buffer } = require('node:buffer');

const b = Buffer.from('abcdef');

// Passing a value that's a number, but not a valid byte.
// Prints: 2, equivalent to searching for 99 or 'c'.
console.log(b.indexOf(99.9));
console.log(b.indexOf(256 + 99));

// Passing a byteOffset that coerces to NaN or 0.
// Prints: 1, searching the whole buffer.
console.log(b.indexOf('b', undefined));
console.log(b.indexOf('b', {}));
console.log(b.indexOf('b', null));
console.log(b.indexOf('b', []));copy
If value is an empty string or empty Buffer and byteOffset is less
than buf.length, byteOffset will be returned. If value is empty and
byteOffset is at least buf.length, buf.length will be returned.

buf.keys()#

Added in: v1.1.0


Returns: <Iterator>

Creates and returns an iterator of buf keys (indexes).

import { Buffer } from 'node:buffer';

const buf = Buffer.from('buffer');

for (const key of buf.keys()) {
  console.log(key);
}
// Prints:
//   0
//   1
//   2
//   3
//   4
//   5const { Buffer } = require('node:buffer');

const buf = Buffer.from('buffer');

for (const key of buf.keys()) {
  console.log(key);
}
// Prints:
//   0
//   1
//   2
//   3
//   4
//   5copy

buf.lastIndexOf(value[, byteOffset][, encoding])#

History

VersionChanges
v8.0.0
The value can now be a Uint8Array.
v6.0.0
Added in: v6.0.0




value <string> | <Buffer> | <Uint8Array> | <integer> What to search for.
byteOffset <integer> Where to begin searching in buf. If negative, then
offset is calculated from the end of buf. Default:
buf.length - 1.
encoding <string> If value is a string, this is the encoding used to
determine the binary representation of the string that will be searched for in
buf. Default: 'utf8'.
Returns: <integer> The index of the last occurrence of value in buf, or
-1 if buf does not contain value.

Identical to buf.indexOf(), except the last occurrence of value is found
rather than the first occurrence.

import { Buffer } from 'node:buffer';

const buf = Buffer.from('this buffer is a buffer');

console.log(buf.lastIndexOf('this'));
// Prints: 0
console.log(buf.lastIndexOf('buffer'));
// Prints: 17
console.log(buf.lastIndexOf(Buffer.from('buffer')));
// Prints: 17
console.log(buf.lastIndexOf(97));
// Prints: 15 (97 is the decimal ASCII value for 'a')
console.log(buf.lastIndexOf(Buffer.from('yolo')));
// Prints: -1
console.log(buf.lastIndexOf('buffer', 5));
// Prints: 5
console.log(buf.lastIndexOf('buffer', 4));
// Prints: -1

const utf16Buffer = Buffer.from('\u039a\u0391\u03a3\u03a3\u0395', 'utf16le');

console.log(utf16Buffer.lastIndexOf('\u03a3', undefined, 'utf16le'));
// Prints: 6
console.log(utf16Buffer.lastIndexOf('\u03a3', -5, 'utf16le'));
// Prints: 4const { Buffer } = require('node:buffer');

const buf = Buffer.from('this buffer is a buffer');

console.log(buf.lastIndexOf('this'));
// Prints: 0
console.log(buf.lastIndexOf('buffer'));
// Prints: 17
console.log(buf.lastIndexOf(Buffer.from('buffer')));
// Prints: 17
console.log(buf.lastIndexOf(97));
// Prints: 15 (97 is the decimal ASCII value for 'a')
console.log(buf.lastIndexOf(Buffer.from('yolo')));
// Prints: -1
console.log(buf.lastIndexOf('buffer', 5));
// Prints: 5
console.log(buf.lastIndexOf('buffer', 4));
// Prints: -1

const utf16Buffer = Buffer.from('\u039a\u0391\u03a3\u03a3\u0395', 'utf16le');

console.log(utf16Buffer.lastIndexOf('\u03a3', undefined, 'utf16le'));
// Prints: 6
console.log(utf16Buffer.lastIndexOf('\u03a3', -5, 'utf16le'));
// Prints: 4copy
If value is not a string, number, or Buffer, this method will throw a
TypeError. If value is a number, it will be coerced to a valid byte value,
an integer between 0 and 255.
If byteOffset is not a number, it will be coerced to a number. Any arguments
that coerce to NaN, like {} or undefined, will search the whole buffer.
This behavior matches String.prototype.lastIndexOf().

import { Buffer } from 'node:buffer';

const b = Buffer.from('abcdef');

// Passing a value that's a number, but not a valid byte.
// Prints: 2, equivalent to searching for 99 or 'c'.
console.log(b.lastIndexOf(99.9));
console.log(b.lastIndexOf(256 + 99));

// Passing a byteOffset that coerces to NaN.
// Prints: 1, searching the whole buffer.
console.log(b.lastIndexOf('b', undefined));
console.log(b.lastIndexOf('b', {}));

// Passing a byteOffset that coerces to 0.
// Prints: -1, equivalent to passing 0.
console.log(b.lastIndexOf('b', null));
console.log(b.lastIndexOf('b', []));const { Buffer } = require('node:buffer');

const b = Buffer.from('abcdef');

// Passing a value that's a number, but not a valid byte.
// Prints: 2, equivalent to searching for 99 or 'c'.
console.log(b.lastIndexOf(99.9));
console.log(b.lastIndexOf(256 + 99));

// Passing a byteOffset that coerces to NaN.
// Prints: 1, searching the whole buffer.
console.log(b.lastIndexOf('b', undefined));
console.log(b.lastIndexOf('b', {}));

// Passing a byteOffset that coerces to 0.
// Prints: -1, equivalent to passing 0.
console.log(b.lastIndexOf('b', null));
console.log(b.lastIndexOf('b', []));copy
If value is an empty string or empty Buffer, byteOffset will be returned.

buf.length#

Added in: v0.1.90


<integer>

Returns the number of bytes in buf.

import { Buffer } from 'node:buffer';

// Create a `Buffer` and write a shorter string to it using UTF-8.

const buf = Buffer.alloc(1234);

console.log(buf.length);
// Prints: 1234

buf.write('some string', 0, 'utf8');

console.log(buf.length);
// Prints: 1234const { Buffer } = require('node:buffer');

// Create a `Buffer` and write a shorter string to it using UTF-8.

const buf = Buffer.alloc(1234);

console.log(buf.length);
// Prints: 1234

buf.write('some string', 0, 'utf8');

console.log(buf.length);
// Prints: 1234copy

buf.parent#

Deprecated since: v8.0.0

Stability: 0 - Deprecated: Use buf.buffer instead.
The buf.parent property is a deprecated alias for buf.buffer.

buf.readBigInt64BE([offset])#

Added in: v12.0.0, v10.20.0


offset <integer> Number of bytes to skip before starting to read. Must
satisfy: 0 <= offset <= buf.length - 8. Default: 0.
Returns: <bigint>

Reads a signed, big-endian 64-bit integer from buf at the specified offset.
Integers read from a Buffer are interpreted as two's complement signed
values.

buf.readBigInt64LE([offset])#

Added in: v12.0.0, v10.20.0


offset <integer> Number of bytes to skip before starting to read. Must
satisfy: 0 <= offset <= buf.length - 8. Default: 0.
Returns: <bigint>

Reads a signed, little-endian 64-bit integer from buf at the specified
offset.
Integers read from a Buffer are interpreted as two's complement signed
values.

buf.readBigUInt64BE([offset])#

History

VersionChanges
v14.10.0, v12.19.0
This function is also available as buf.readBigUint64BE().
v12.0.0, v10.20.0
Added in: v12.0.0, v10.20.0




offset <integer> Number of bytes to skip before starting to read. Must
satisfy: 0 <= offset <= buf.length - 8. Default: 0.
Returns: <bigint>

Reads an unsigned, big-endian 64-bit integer from buf at the specified
offset.
This function is also available under the readBigUint64BE alias.

import { Buffer } from 'node:buffer';

const buf = Buffer.from([0x00, 0x00, 0x00, 0x00, 0xff, 0xff, 0xff, 0xff]);

console.log(buf.readBigUInt64BE(0));
// Prints: 4294967295nconst { Buffer } = require('node:buffer');

const buf = Buffer.from([0x00, 0x00, 0x00, 0x00, 0xff, 0xff, 0xff, 0xff]);

console.log(buf.readBigUInt64BE(0));
// Prints: 4294967295ncopy

buf.readBigUInt64LE([offset])#

History

VersionChanges
v14.10.0, v12.19.0
This function is also available as buf.readBigUint64LE().
v12.0.0, v10.20.0
Added in: v12.0.0, v10.20.0




offset <integer> Number of bytes to skip before starting to read. Must
satisfy: 0 <= offset <= buf.length - 8. Default: 0.
Returns: <bigint>

Reads an unsigned, little-endian 64-bit integer from buf at the specified
offset.
This function is also available under the readBigUint64LE alias.

import { Buffer } from 'node:buffer';

const buf = Buffer.from([0x00, 0x00, 0x00, 0x00, 0xff, 0xff, 0xff, 0xff]);

console.log(buf.readBigUInt64LE(0));
// Prints: 18446744069414584320nconst { Buffer } = require('node:buffer');

const buf = Buffer.from([0x00, 0x00, 0x00, 0x00, 0xff, 0xff, 0xff, 0xff]);

console.log(buf.readBigUInt64LE(0));
// Prints: 18446744069414584320ncopy

buf.readDoubleBE([offset])#

History

VersionChanges
v10.0.0
Removed noAssert and no implicit coercion of the offset to uint32 anymore.
v0.11.15
Added in: v0.11.15




offset <integer> Number of bytes to skip before starting to read. Must
satisfy 0 <= offset <= buf.length - 8. Default: 0.
Returns: <number>

Reads a 64-bit, big-endian double from buf at the specified offset.

import { Buffer } from 'node:buffer';

const buf = Buffer.from([1, 2, 3, 4, 5, 6, 7, 8]);

console.log(buf.readDoubleBE(0));
// Prints: 8.20788039913184e-304const { Buffer } = require('node:buffer');

const buf = Buffer.from([1, 2, 3, 4, 5, 6, 7, 8]);

console.log(buf.readDoubleBE(0));
// Prints: 8.20788039913184e-304copy

buf.readDoubleLE([offset])#

History

VersionChanges
v10.0.0
Removed noAssert and no implicit coercion of the offset to uint32 anymore.
v0.11.15
Added in: v0.11.15




offset <integer> Number of bytes to skip before starting to read. Must
satisfy 0 <= offset <= buf.length - 8. Default: 0.
Returns: <number>

Reads a 64-bit, little-endian double from buf at the specified offset.

import { Buffer } from 'node:buffer';

const buf = Buffer.from([1, 2, 3, 4, 5, 6, 7, 8]);

console.log(buf.readDoubleLE(0));
// Prints: 5.447603722011605e-270
console.log(buf.readDoubleLE(1));
// Throws ERR_OUT_OF_RANGE.const { Buffer } = require('node:buffer');

const buf = Buffer.from([1, 2, 3, 4, 5, 6, 7, 8]);

console.log(buf.readDoubleLE(0));
// Prints: 5.447603722011605e-270
console.log(buf.readDoubleLE(1));
// Throws ERR_OUT_OF_RANGE.copy

buf.readFloatBE([offset])#

History

VersionChanges
v10.0.0
Removed noAssert and no implicit coercion of the offset to uint32 anymore.
v0.11.15
Added in: v0.11.15




offset <integer> Number of bytes to skip before starting to read. Must
satisfy 0 <= offset <= buf.length - 4. Default: 0.
Returns: <number>

Reads a 32-bit, big-endian float from buf at the specified offset.

import { Buffer } from 'node:buffer';

const buf = Buffer.from([1, 2, 3, 4]);

console.log(buf.readFloatBE(0));
// Prints: 2.387939260590663e-38const { Buffer } = require('node:buffer');

const buf = Buffer.from([1, 2, 3, 4]);

console.log(buf.readFloatBE(0));
// Prints: 2.387939260590663e-38copy

buf.readFloatLE([offset])#

History

VersionChanges
v10.0.0
Removed noAssert and no implicit coercion of the offset to uint32 anymore.
v0.11.15
Added in: v0.11.15




offset <integer> Number of bytes to skip before starting to read. Must
satisfy 0 <= offset <= buf.length - 4. Default: 0.
Returns: <number>

Reads a 32-bit, little-endian float from buf at the specified offset.

import { Buffer } from 'node:buffer';

const buf = Buffer.from([1, 2, 3, 4]);

console.log(buf.readFloatLE(0));
// Prints: 1.539989614439558e-36
console.log(buf.readFloatLE(1));
// Throws ERR_OUT_OF_RANGE.const { Buffer } = require('node:buffer');

const buf = Buffer.from([1, 2, 3, 4]);

console.log(buf.readFloatLE(0));
// Prints: 1.539989614439558e-36
console.log(buf.readFloatLE(1));
// Throws ERR_OUT_OF_RANGE.copy

buf.readInt8([offset])#

History

VersionChanges
v10.0.0
Removed noAssert and no implicit coercion of the offset to uint32 anymore.
v0.5.0
Added in: v0.5.0




offset <integer> Number of bytes to skip before starting to read. Must
satisfy 0 <= offset <= buf.length - 1. Default: 0.
Returns: <integer>

Reads a signed 8-bit integer from buf at the specified offset.
Integers read from a Buffer are interpreted as two's complement signed values.

import { Buffer } from 'node:buffer';

const buf = Buffer.from([-1, 5]);

console.log(buf.readInt8(0));
// Prints: -1
console.log(buf.readInt8(1));
// Prints: 5
console.log(buf.readInt8(2));
// Throws ERR_OUT_OF_RANGE.const { Buffer } = require('node:buffer');

const buf = Buffer.from([-1, 5]);

console.log(buf.readInt8(0));
// Prints: -1
console.log(buf.readInt8(1));
// Prints: 5
console.log(buf.readInt8(2));
// Throws ERR_OUT_OF_RANGE.copy

buf.readInt16BE([offset])#

History

VersionChanges
v10.0.0
Removed noAssert and no implicit coercion of the offset to uint32 anymore.
v0.5.5
Added in: v0.5.5




offset <integer> Number of bytes to skip before starting to read. Must
satisfy 0 <= offset <= buf.length - 2. Default: 0.
Returns: <integer>

Reads a signed, big-endian 16-bit integer from buf at the specified offset.
Integers read from a Buffer are interpreted as two's complement signed values.

import { Buffer } from 'node:buffer';

const buf = Buffer.from([0, 5]);

console.log(buf.readInt16BE(0));
// Prints: 5const { Buffer } = require('node:buffer');

const buf = Buffer.from([0, 5]);

console.log(buf.readInt16BE(0));
// Prints: 5copy

buf.readInt16LE([offset])#

History

VersionChanges
v10.0.0
Removed noAssert and no implicit coercion of the offset to uint32 anymore.
v0.5.5
Added in: v0.5.5




offset <integer> Number of bytes to skip before starting to read. Must
satisfy 0 <= offset <= buf.length - 2. Default: 0.
Returns: <integer>

Reads a signed, little-endian 16-bit integer from buf at the specified
offset.
Integers read from a Buffer are interpreted as two's complement signed values.

import { Buffer } from 'node:buffer';

const buf = Buffer.from([0, 5]);

console.log(buf.readInt16LE(0));
// Prints: 1280
console.log(buf.readInt16LE(1));
// Throws ERR_OUT_OF_RANGE.const { Buffer } = require('node:buffer');

const buf = Buffer.from([0, 5]);

console.log(buf.readInt16LE(0));
// Prints: 1280
console.log(buf.readInt16LE(1));
// Throws ERR_OUT_OF_RANGE.copy

buf.readInt32BE([offset])#

History

VersionChanges
v10.0.0
Removed noAssert and no implicit coercion of the offset to uint32 anymore.
v0.5.5
Added in: v0.5.5




offset <integer> Number of bytes to skip before starting to read. Must
satisfy 0 <= offset <= buf.length - 4. Default: 0.
Returns: <integer>

Reads a signed, big-endian 32-bit integer from buf at the specified offset.
Integers read from a Buffer are interpreted as two's complement signed values.

import { Buffer } from 'node:buffer';

const buf = Buffer.from([0, 0, 0, 5]);

console.log(buf.readInt32BE(0));
// Prints: 5const { Buffer } = require('node:buffer');

const buf = Buffer.from([0, 0, 0, 5]);

console.log(buf.readInt32BE(0));
// Prints: 5copy

buf.readInt32LE([offset])#

History

VersionChanges
v10.0.0
Removed noAssert and no implicit coercion of the offset to uint32 anymore.
v0.5.5
Added in: v0.5.5




offset <integer> Number of bytes to skip before starting to read. Must
satisfy 0 <= offset <= buf.length - 4. Default: 0.
Returns: <integer>

Reads a signed, little-endian 32-bit integer from buf at the specified
offset.
Integers read from a Buffer are interpreted as two's complement signed values.

import { Buffer } from 'node:buffer';

const buf = Buffer.from([0, 0, 0, 5]);

console.log(buf.readInt32LE(0));
// Prints: 83886080
console.log(buf.readInt32LE(1));
// Throws ERR_OUT_OF_RANGE.const { Buffer } = require('node:buffer');

const buf = Buffer.from([0, 0, 0, 5]);

console.log(buf.readInt32LE(0));
// Prints: 83886080
console.log(buf.readInt32LE(1));
// Throws ERR_OUT_OF_RANGE.copy

buf.readIntBE(offset, byteLength)#

History

VersionChanges
v10.0.0
Removed noAssert and no implicit coercion of the offset and byteLength to uint32 anymore.
v0.11.15
Added in: v0.11.15




offset <integer> Number of bytes to skip before starting to read. Must
satisfy 0 <= offset <= buf.length - byteLength.
byteLength <integer> Number of bytes to read. Must satisfy
0 < byteLength <= 6.
Returns: <integer>

Reads byteLength number of bytes from buf at the specified offset
and interprets the result as a big-endian, two's complement signed value
supporting up to 48 bits of accuracy.

import { Buffer } from 'node:buffer';

const buf = Buffer.from([0x12, 0x34, 0x56, 0x78, 0x90, 0xab]);

console.log(buf.readIntBE(0, 6).toString(16));
// Prints: 1234567890ab
console.log(buf.readIntBE(1, 6).toString(16));
// Throws ERR_OUT_OF_RANGE.
console.log(buf.readIntBE(1, 0).toString(16));
// Throws ERR_OUT_OF_RANGE.const { Buffer } = require('node:buffer');

const buf = Buffer.from([0x12, 0x34, 0x56, 0x78, 0x90, 0xab]);

console.log(buf.readIntBE(0, 6).toString(16));
// Prints: 1234567890ab
console.log(buf.readIntBE(1, 6).toString(16));
// Throws ERR_OUT_OF_RANGE.
console.log(buf.readIntBE(1, 0).toString(16));
// Throws ERR_OUT_OF_RANGE.copy

buf.readIntLE(offset, byteLength)#

History

VersionChanges
v10.0.0
Removed noAssert and no implicit coercion of the offset and byteLength to uint32 anymore.
v0.11.15
Added in: v0.11.15




offset <integer> Number of bytes to skip before starting to read. Must
satisfy 0 <= offset <= buf.length - byteLength.
byteLength <integer> Number of bytes to read. Must satisfy
0 < byteLength <= 6.
Returns: <integer>

Reads byteLength number of bytes from buf at the specified offset
and interprets the result as a little-endian, two's complement signed value
supporting up to 48 bits of accuracy.

import { Buffer } from 'node:buffer';

const buf = Buffer.from([0x12, 0x34, 0x56, 0x78, 0x90, 0xab]);

console.log(buf.readIntLE(0, 6).toString(16));
// Prints: -546f87a9cbeeconst { Buffer } = require('node:buffer');

const buf = Buffer.from([0x12, 0x34, 0x56, 0x78, 0x90, 0xab]);

console.log(buf.readIntLE(0, 6).toString(16));
// Prints: -546f87a9cbeecopy

buf.readUInt8([offset])#

History

VersionChanges
v14.9.0, v12.19.0
This function is also available as buf.readUint8().
v10.0.0
Removed noAssert and no implicit coercion of the offset to uint32 anymore.
v0.5.0
Added in: v0.5.0




offset <integer> Number of bytes to skip before starting to read. Must
satisfy 0 <= offset <= buf.length - 1. Default: 0.
Returns: <integer>

Reads an unsigned 8-bit integer from buf at the specified offset.
This function is also available under the readUint8 alias.

import { Buffer } from 'node:buffer';

const buf = Buffer.from([1, -2]);

console.log(buf.readUInt8(0));
// Prints: 1
console.log(buf.readUInt8(1));
// Prints: 254
console.log(buf.readUInt8(2));
// Throws ERR_OUT_OF_RANGE.const { Buffer } = require('node:buffer');

const buf = Buffer.from([1, -2]);

console.log(buf.readUInt8(0));
// Prints: 1
console.log(buf.readUInt8(1));
// Prints: 254
console.log(buf.readUInt8(2));
// Throws ERR_OUT_OF_RANGE.copy

buf.readUInt16BE([offset])#

History

VersionChanges
v14.9.0, v12.19.0
This function is also available as buf.readUint16BE().
v10.0.0
Removed noAssert and no implicit coercion of the offset to uint32 anymore.
v0.5.5
Added in: v0.5.5




offset <integer> Number of bytes to skip before starting to read. Must
satisfy 0 <= offset <= buf.length - 2. Default: 0.
Returns: <integer>

Reads an unsigned, big-endian 16-bit integer from buf at the specified
offset.
This function is also available under the readUint16BE alias.

import { Buffer } from 'node:buffer';

const buf = Buffer.from([0x12, 0x34, 0x56]);

console.log(buf.readUInt16BE(0).toString(16));
// Prints: 1234
console.log(buf.readUInt16BE(1).toString(16));
// Prints: 3456const { Buffer } = require('node:buffer');

const buf = Buffer.from([0x12, 0x34, 0x56]);

console.log(buf.readUInt16BE(0).toString(16));
// Prints: 1234
console.log(buf.readUInt16BE(1).toString(16));
// Prints: 3456copy

buf.readUInt16LE([offset])#

History

VersionChanges
v14.9.0, v12.19.0
This function is also available as buf.readUint16LE().
v10.0.0
Removed noAssert and no implicit coercion of the offset to uint32 anymore.
v0.5.5
Added in: v0.5.5




offset <integer> Number of bytes to skip before starting to read. Must
satisfy 0 <= offset <= buf.length - 2. Default: 0.
Returns: <integer>

Reads an unsigned, little-endian 16-bit integer from buf at the specified
offset.
This function is also available under the readUint16LE alias.

import { Buffer } from 'node:buffer';

const buf = Buffer.from([0x12, 0x34, 0x56]);

console.log(buf.readUInt16LE(0).toString(16));
// Prints: 3412
console.log(buf.readUInt16LE(1).toString(16));
// Prints: 5634
console.log(buf.readUInt16LE(2).toString(16));
// Throws ERR_OUT_OF_RANGE.const { Buffer } = require('node:buffer');

const buf = Buffer.from([0x12, 0x34, 0x56]);

console.log(buf.readUInt16LE(0).toString(16));
// Prints: 3412
console.log(buf.readUInt16LE(1).toString(16));
// Prints: 5634
console.log(buf.readUInt16LE(2).toString(16));
// Throws ERR_OUT_OF_RANGE.copy

buf.readUInt32BE([offset])#

History

VersionChanges
v14.9.0, v12.19.0
This function is also available as buf.readUint32BE().
v10.0.0
Removed noAssert and no implicit coercion of the offset to uint32 anymore.
v0.5.5
Added in: v0.5.5




offset <integer> Number of bytes to skip before starting to read. Must
satisfy 0 <= offset <= buf.length - 4. Default: 0.
Returns: <integer>

Reads an unsigned, big-endian 32-bit integer from buf at the specified
offset.
This function is also available under the readUint32BE alias.

import { Buffer } from 'node:buffer';

const buf = Buffer.from([0x12, 0x34, 0x56, 0x78]);

console.log(buf.readUInt32BE(0).toString(16));
// Prints: 12345678const { Buffer } = require('node:buffer');

const buf = Buffer.from([0x12, 0x34, 0x56, 0x78]);

console.log(buf.readUInt32BE(0).toString(16));
// Prints: 12345678copy

buf.readUInt32LE([offset])#

History

VersionChanges
v14.9.0, v12.19.0
This function is also available as buf.readUint32LE().
v10.0.0
Removed noAssert and no implicit coercion of the offset to uint32 anymore.
v0.5.5
Added in: v0.5.5




offset <integer> Number of bytes to skip before starting to read. Must
satisfy 0 <= offset <= buf.length - 4. Default: 0.
Returns: <integer>

Reads an unsigned, little-endian 32-bit integer from buf at the specified
offset.
This function is also available under the readUint32LE alias.

import { Buffer } from 'node:buffer';

const buf = Buffer.from([0x12, 0x34, 0x56, 0x78]);

console.log(buf.readUInt32LE(0).toString(16));
// Prints: 78563412
console.log(buf.readUInt32LE(1).toString(16));
// Throws ERR_OUT_OF_RANGE.const { Buffer } = require('node:buffer');

const buf = Buffer.from([0x12, 0x34, 0x56, 0x78]);

console.log(buf.readUInt32LE(0).toString(16));
// Prints: 78563412
console.log(buf.readUInt32LE(1).toString(16));
// Throws ERR_OUT_OF_RANGE.copy

buf.readUIntBE(offset, byteLength)#

History

VersionChanges
v14.9.0, v12.19.0
This function is also available as buf.readUintBE().
v10.0.0
Removed noAssert and no implicit coercion of the offset and byteLength to uint32 anymore.
v0.11.15
Added in: v0.11.15




offset <integer> Number of bytes to skip before starting to read. Must
satisfy 0 <= offset <= buf.length - byteLength.
byteLength <integer> Number of bytes to read. Must satisfy
0 < byteLength <= 6.
Returns: <integer>

Reads byteLength number of bytes from buf at the specified offset
and interprets the result as an unsigned big-endian integer supporting
up to 48 bits of accuracy.
This function is also available under the readUintBE alias.

import { Buffer } from 'node:buffer';

const buf = Buffer.from([0x12, 0x34, 0x56, 0x78, 0x90, 0xab]);

console.log(buf.readUIntBE(0, 6).toString(16));
// Prints: 1234567890ab
console.log(buf.readUIntBE(1, 6).toString(16));
// Throws ERR_OUT_OF_RANGE.const { Buffer } = require('node:buffer');

const buf = Buffer.from([0x12, 0x34, 0x56, 0x78, 0x90, 0xab]);

console.log(buf.readUIntBE(0, 6).toString(16));
// Prints: 1234567890ab
console.log(buf.readUIntBE(1, 6).toString(16));
// Throws ERR_OUT_OF_RANGE.copy

buf.readUIntLE(offset, byteLength)#

History

VersionChanges
v14.9.0, v12.19.0
This function is also available as buf.readUintLE().
v10.0.0
Removed noAssert and no implicit coercion of the offset and byteLength to uint32 anymore.
v0.11.15
Added in: v0.11.15




offset <integer> Number of bytes to skip before starting to read. Must
satisfy 0 <= offset <= buf.length - byteLength.
byteLength <integer> Number of bytes to read. Must satisfy
0 < byteLength <= 6.
Returns: <integer>

Reads byteLength number of bytes from buf at the specified offset
and interprets the result as an unsigned, little-endian integer supporting
up to 48 bits of accuracy.
This function is also available under the readUintLE alias.

import { Buffer } from 'node:buffer';

const buf = Buffer.from([0x12, 0x34, 0x56, 0x78, 0x90, 0xab]);

console.log(buf.readUIntLE(0, 6).toString(16));
// Prints: ab9078563412const { Buffer } = require('node:buffer');

const buf = Buffer.from([0x12, 0x34, 0x56, 0x78, 0x90, 0xab]);

console.log(buf.readUIntLE(0, 6).toString(16));
// Prints: ab9078563412copy

buf.subarray([start[, end]])#

Added in: v3.0.0


start <integer> Where the new Buffer will start. Default: 0.
end <integer> Where the new Buffer will end (not inclusive).
Default: buf.length.
Returns: <Buffer>

Returns a new Buffer that references the same memory as the original, but
offset and cropped by the start and end indexes.
Specifying end greater than buf.length will return the same result as
that of end equal to buf.length.
This method is inherited from TypedArray.prototype.subarray().
Modifying the new Buffer slice will modify the memory in the original Buffer
because the allocated memory of the two objects overlap.

import { Buffer } from 'node:buffer';

// Create a `Buffer` with the ASCII alphabet, take a slice, and modify one byte
// from the original `Buffer`.

const buf1 = Buffer.allocUnsafe(26);

for (let i = 0; i < 26; i++) {
  // 97 is the decimal ASCII value for 'a'.
  buf1[i] = i + 97;
}

const buf2 = buf1.subarray(0, 3);

console.log(buf2.toString('ascii', 0, buf2.length));
// Prints: abc

buf1[0] = 33;

console.log(buf2.toString('ascii', 0, buf2.length));
// Prints: !bcconst { Buffer } = require('node:buffer');

// Create a `Buffer` with the ASCII alphabet, take a slice, and modify one byte
// from the original `Buffer`.

const buf1 = Buffer.allocUnsafe(26);

for (let i = 0; i < 26; i++) {
  // 97 is the decimal ASCII value for 'a'.
  buf1[i] = i + 97;
}

const buf2 = buf1.subarray(0, 3);

console.log(buf2.toString('ascii', 0, buf2.length));
// Prints: abc

buf1[0] = 33;

console.log(buf2.toString('ascii', 0, buf2.length));
// Prints: !bccopy
Specifying negative indexes causes the slice to be generated relative to the
end of buf rather than the beginning.

import { Buffer } from 'node:buffer';

const buf = Buffer.from('buffer');

console.log(buf.subarray(-6, -1).toString());
// Prints: buffe
// (Equivalent to buf.subarray(0, 5).)

console.log(buf.subarray(-6, -2).toString());
// Prints: buff
// (Equivalent to buf.subarray(0, 4).)

console.log(buf.subarray(-5, -2).toString());
// Prints: uff
// (Equivalent to buf.subarray(1, 4).)const { Buffer } = require('node:buffer');

const buf = Buffer.from('buffer');

console.log(buf.subarray(-6, -1).toString());
// Prints: buffe
// (Equivalent to buf.subarray(0, 5).)

console.log(buf.subarray(-6, -2).toString());
// Prints: buff
// (Equivalent to buf.subarray(0, 4).)

console.log(buf.subarray(-5, -2).toString());
// Prints: uff
// (Equivalent to buf.subarray(1, 4).)copy

buf.slice([start[, end]])#

History

VersionChanges
v17.5.0, v16.15.0
The buf.slice() method has been deprecated.
v7.0.0
All offsets are now coerced to integers before doing any calculations with them.
v7.1.0, v6.9.2
Coercing the offsets to integers now handles values outside the 32-bit integer range properly.
v0.3.0
Added in: v0.3.0




start <integer> Where the new Buffer will start. Default: 0.
end <integer> Where the new Buffer will end (not inclusive).
Default: buf.length.
Returns: <Buffer>

Stability: 0 - Deprecated: Use buf.subarray instead.
Returns a new Buffer that references the same memory as the original, but
offset and cropped by the start and end indexes.
This method is not compatible with the Uint8Array.prototype.slice(),
which is a superclass of Buffer. To copy the slice, use
Uint8Array.prototype.slice().

import { Buffer } from 'node:buffer';

const buf = Buffer.from('buffer');

const copiedBuf = Uint8Array.prototype.slice.call(buf);
copiedBuf[0]++;
console.log(copiedBuf.toString());
// Prints: cuffer

console.log(buf.toString());
// Prints: buffer

// With buf.slice(), the original buffer is modified.
const notReallyCopiedBuf = buf.slice();
notReallyCopiedBuf[0]++;
console.log(notReallyCopiedBuf.toString());
// Prints: cuffer
console.log(buf.toString());
// Also prints: cuffer (!)const { Buffer } = require('node:buffer');

const buf = Buffer.from('buffer');

const copiedBuf = Uint8Array.prototype.slice.call(buf);
copiedBuf[0]++;
console.log(copiedBuf.toString());
// Prints: cuffer

console.log(buf.toString());
// Prints: buffer

// With buf.slice(), the original buffer is modified.
const notReallyCopiedBuf = buf.slice();
notReallyCopiedBuf[0]++;
console.log(notReallyCopiedBuf.toString());
// Prints: cuffer
console.log(buf.toString());
// Also prints: cuffer (!)copy

buf.swap16()#

Added in: v5.10.0


Returns: <Buffer> A reference to buf.

Interprets buf as an array of unsigned 16-bit integers and swaps the
byte order in-place. Throws ERR_INVALID_BUFFER_SIZE if buf.length
is not a multiple of 2.

import { Buffer } from 'node:buffer';

const buf1 = Buffer.from([0x1, 0x2, 0x3, 0x4, 0x5, 0x6, 0x7, 0x8]);

console.log(buf1);
// Prints: <Buffer 01 02 03 04 05 06 07 08>

buf1.swap16();

console.log(buf1);
// Prints: <Buffer 02 01 04 03 06 05 08 07>

const buf2 = Buffer.from([0x1, 0x2, 0x3]);

buf2.swap16();
// Throws ERR_INVALID_BUFFER_SIZE.const { Buffer } = require('node:buffer');

const buf1 = Buffer.from([0x1, 0x2, 0x3, 0x4, 0x5, 0x6, 0x7, 0x8]);

console.log(buf1);
// Prints: <Buffer 01 02 03 04 05 06 07 08>

buf1.swap16();

console.log(buf1);
// Prints: <Buffer 02 01 04 03 06 05 08 07>

const buf2 = Buffer.from([0x1, 0x2, 0x3]);

buf2.swap16();
// Throws ERR_INVALID_BUFFER_SIZE.copy
One convenient use of buf.swap16() is to perform a fast in-place conversion
between UTF-16 little-endian and UTF-16 big-endian:

import { Buffer } from 'node:buffer';

const buf = Buffer.from('This is little-endian UTF-16', 'utf16le');
buf.swap16(); // Convert to big-endian UTF-16 text.const { Buffer } = require('node:buffer');

const buf = Buffer.from('This is little-endian UTF-16', 'utf16le');
buf.swap16(); // Convert to big-endian UTF-16 text.copy

buf.swap32()#

Added in: v5.10.0


Returns: <Buffer> A reference to buf.

Interprets buf as an array of unsigned 32-bit integers and swaps the
byte order in-place. Throws ERR_INVALID_BUFFER_SIZE if buf.length
is not a multiple of 4.

import { Buffer } from 'node:buffer';

const buf1 = Buffer.from([0x1, 0x2, 0x3, 0x4, 0x5, 0x6, 0x7, 0x8]);

console.log(buf1);
// Prints: <Buffer 01 02 03 04 05 06 07 08>

buf1.swap32();

console.log(buf1);
// Prints: <Buffer 04 03 02 01 08 07 06 05>

const buf2 = Buffer.from([0x1, 0x2, 0x3]);

buf2.swap32();
// Throws ERR_INVALID_BUFFER_SIZE.const { Buffer } = require('node:buffer');

const buf1 = Buffer.from([0x1, 0x2, 0x3, 0x4, 0x5, 0x6, 0x7, 0x8]);

console.log(buf1);
// Prints: <Buffer 01 02 03 04 05 06 07 08>

buf1.swap32();

console.log(buf1);
// Prints: <Buffer 04 03 02 01 08 07 06 05>

const buf2 = Buffer.from([0x1, 0x2, 0x3]);

buf2.swap32();
// Throws ERR_INVALID_BUFFER_SIZE.copy

buf.swap64()#

Added in: v6.3.0


Returns: <Buffer> A reference to buf.

Interprets buf as an array of 64-bit numbers and swaps byte order in-place.
Throws ERR_INVALID_BUFFER_SIZE if buf.length is not a multiple of 8.

import { Buffer } from 'node:buffer';

const buf1 = Buffer.from([0x1, 0x2, 0x3, 0x4, 0x5, 0x6, 0x7, 0x8]);

console.log(buf1);
// Prints: <Buffer 01 02 03 04 05 06 07 08>

buf1.swap64();

console.log(buf1);
// Prints: <Buffer 08 07 06 05 04 03 02 01>

const buf2 = Buffer.from([0x1, 0x2, 0x3]);

buf2.swap64();
// Throws ERR_INVALID_BUFFER_SIZE.const { Buffer } = require('node:buffer');

const buf1 = Buffer.from([0x1, 0x2, 0x3, 0x4, 0x5, 0x6, 0x7, 0x8]);

console.log(buf1);
// Prints: <Buffer 01 02 03 04 05 06 07 08>

buf1.swap64();

console.log(buf1);
// Prints: <Buffer 08 07 06 05 04 03 02 01>

const buf2 = Buffer.from([0x1, 0x2, 0x3]);

buf2.swap64();
// Throws ERR_INVALID_BUFFER_SIZE.copy

buf.toJSON()#

Added in: v0.9.2


Returns: <Object>

Returns a JSON representation of buf. JSON.stringify() implicitly calls
this function when stringifying a Buffer instance.
Buffer.from() accepts objects in the format returned from this method.
In particular, Buffer.from(buf.toJSON()) works like Buffer.from(buf).

import { Buffer } from 'node:buffer';

const buf = Buffer.from([0x1, 0x2, 0x3, 0x4, 0x5]);
const json = JSON.stringify(buf);

console.log(json);
// Prints: {"type":"Buffer","data":[1,2,3,4,5]}

const copy = JSON.parse(json, (key, value) => {
  return value && value.type === 'Buffer' ?
    Buffer.from(value) :
    value;
});

console.log(copy);
// Prints: <Buffer 01 02 03 04 05>const { Buffer } = require('node:buffer');

const buf = Buffer.from([0x1, 0x2, 0x3, 0x4, 0x5]);
const json = JSON.stringify(buf);

console.log(json);
// Prints: {"type":"Buffer","data":[1,2,3,4,5]}

const copy = JSON.parse(json, (key, value) => {
  return value && value.type === 'Buffer' ?
    Buffer.from(value) :
    value;
});

console.log(copy);
// Prints: <Buffer 01 02 03 04 05>copy

buf.toString([encoding[, start[, end]]])#

Added in: v0.1.90


encoding <string> The character encoding to use. Default: 'utf8'.
start <integer> The byte offset to start decoding at. Default: 0.
end <integer> The byte offset to stop decoding at (not inclusive).
Default: buf.length.
Returns: <string>

Decodes buf to a string according to the specified character encoding in
encoding. start and end may be passed to decode only a subset of buf.
If encoding is 'utf8' and a byte sequence in the input is not valid UTF-8,
then each invalid byte is replaced with the replacement character U+FFFD.
The maximum length of a string instance (in UTF-16 code units) is available
as buffer.constants.MAX_STRING_LENGTH.

import { Buffer } from 'node:buffer';

const buf1 = Buffer.allocUnsafe(26);

for (let i = 0; i < 26; i++) {
  // 97 is the decimal ASCII value for 'a'.
  buf1[i] = i + 97;
}

console.log(buf1.toString('utf8'));
// Prints: abcdefghijklmnopqrstuvwxyz
console.log(buf1.toString('utf8', 0, 5));
// Prints: abcde

const buf2 = Buffer.from('tést');

console.log(buf2.toString('hex'));
// Prints: 74c3a97374
console.log(buf2.toString('utf8', 0, 3));
// Prints: té
console.log(buf2.toString(undefined, 0, 3));
// Prints: téconst { Buffer } = require('node:buffer');

const buf1 = Buffer.allocUnsafe(26);

for (let i = 0; i < 26; i++) {
  // 97 is the decimal ASCII value for 'a'.
  buf1[i] = i + 97;
}

console.log(buf1.toString('utf8'));
// Prints: abcdefghijklmnopqrstuvwxyz
console.log(buf1.toString('utf8', 0, 5));
// Prints: abcde

const buf2 = Buffer.from('tést');

console.log(buf2.toString('hex'));
// Prints: 74c3a97374
console.log(buf2.toString('utf8', 0, 3));
// Prints: té
console.log(buf2.toString(undefined, 0, 3));
// Prints: técopy

buf.values()#

Added in: v1.1.0


Returns: <Iterator>

Creates and returns an iterator for buf values (bytes). This function is
called automatically when a Buffer is used in a for..of statement.

import { Buffer } from 'node:buffer';

const buf = Buffer.from('buffer');

for (const value of buf.values()) {
  console.log(value);
}
// Prints:
//   98
//   117
//   102
//   102
//   101
//   114

for (const value of buf) {
  console.log(value);
}
// Prints:
//   98
//   117
//   102
//   102
//   101
//   114const { Buffer } = require('node:buffer');

const buf = Buffer.from('buffer');

for (const value of buf.values()) {
  console.log(value);
}
// Prints:
//   98
//   117
//   102
//   102
//   101
//   114

for (const value of buf) {
  console.log(value);
}
// Prints:
//   98
//   117
//   102
//   102
//   101
//   114copy

buf.write(string[, offset[, length]][, encoding])#

Added in: v0.1.90


string <string> String to write to buf.
offset <integer> Number of bytes to skip before starting to write string.
Default: 0.
length <integer> Maximum number of bytes to write (written bytes will not
exceed buf.length - offset). Default: buf.length - offset.
encoding <string> The character encoding of string. Default: 'utf8'.
Returns: <integer> Number of bytes written.

Writes string to buf at offset according to the character encoding in
encoding. The length parameter is the number of bytes to write. If buf did
not contain enough space to fit the entire string, only part of string will be
written. However, partially encoded characters will not be written.

import { Buffer } from 'node:buffer';

const buf = Buffer.alloc(256);

const len = buf.write('\u00bd + \u00bc = \u00be', 0);

console.log(`${len} bytes: ${buf.toString('utf8', 0, len)}`);
// Prints: 12 bytes: ½ + ¼ = ¾

const buffer = Buffer.alloc(10);

const length = buffer.write('abcd', 8);

console.log(`${length} bytes: ${buffer.toString('utf8', 8, 10)}`);
// Prints: 2 bytes : abconst { Buffer } = require('node:buffer');

const buf = Buffer.alloc(256);

const len = buf.write('\u00bd + \u00bc = \u00be', 0);

console.log(`${len} bytes: ${buf.toString('utf8', 0, len)}`);
// Prints: 12 bytes: ½ + ¼ = ¾

const buffer = Buffer.alloc(10);

const length = buffer.write('abcd', 8);

console.log(`${length} bytes: ${buffer.toString('utf8', 8, 10)}`);
// Prints: 2 bytes : abcopy

buf.writeBigInt64BE(value[, offset])#

Added in: v12.0.0, v10.20.0


value <bigint> Number to be written to buf.
offset <integer> Number of bytes to skip before starting to write. Must
satisfy: 0 <= offset <= buf.length - 8. Default: 0.
Returns: <integer> offset plus the number of bytes written.

Writes value to buf at the specified offset as big-endian.
value is interpreted and written as a two's complement signed integer.

import { Buffer } from 'node:buffer';

const buf = Buffer.allocUnsafe(8);

buf.writeBigInt64BE(0x0102030405060708n, 0);

console.log(buf);
// Prints: <Buffer 01 02 03 04 05 06 07 08>const { Buffer } = require('node:buffer');

const buf = Buffer.allocUnsafe(8);

buf.writeBigInt64BE(0x0102030405060708n, 0);

console.log(buf);
// Prints: <Buffer 01 02 03 04 05 06 07 08>copy

buf.writeBigInt64LE(value[, offset])#

Added in: v12.0.0, v10.20.0


value <bigint> Number to be written to buf.
offset <integer> Number of bytes to skip before starting to write. Must
satisfy: 0 <= offset <= buf.length - 8. Default: 0.
Returns: <integer> offset plus the number of bytes written.

Writes value to buf at the specified offset as little-endian.
value is interpreted and written as a two's complement signed integer.

import { Buffer } from 'node:buffer';

const buf = Buffer.allocUnsafe(8);

buf.writeBigInt64LE(0x0102030405060708n, 0);

console.log(buf);
// Prints: <Buffer 08 07 06 05 04 03 02 01>const { Buffer } = require('node:buffer');

const buf = Buffer.allocUnsafe(8);

buf.writeBigInt64LE(0x0102030405060708n, 0);

console.log(buf);
// Prints: <Buffer 08 07 06 05 04 03 02 01>copy

buf.writeBigUInt64BE(value[, offset])#

History

VersionChanges
v14.10.0, v12.19.0
This function is also available as buf.writeBigUint64BE().
v12.0.0, v10.20.0
Added in: v12.0.0, v10.20.0




value <bigint> Number to be written to buf.
offset <integer> Number of bytes to skip before starting to write. Must
satisfy: 0 <= offset <= buf.length - 8. Default: 0.
Returns: <integer> offset plus the number of bytes written.

Writes value to buf at the specified offset as big-endian.
This function is also available under the writeBigUint64BE alias.

import { Buffer } from 'node:buffer';

const buf = Buffer.allocUnsafe(8);

buf.writeBigUInt64BE(0xdecafafecacefaden, 0);

console.log(buf);
// Prints: <Buffer de ca fa fe ca ce fa de>const { Buffer } = require('node:buffer');

const buf = Buffer.allocUnsafe(8);

buf.writeBigUInt64BE(0xdecafafecacefaden, 0);

console.log(buf);
// Prints: <Buffer de ca fa fe ca ce fa de>copy

buf.writeBigUInt64LE(value[, offset])#

History

VersionChanges
v14.10.0, v12.19.0
This function is also available as buf.writeBigUint64LE().
v12.0.0, v10.20.0
Added in: v12.0.0, v10.20.0




value <bigint> Number to be written to buf.
offset <integer> Number of bytes to skip before starting to write. Must
satisfy: 0 <= offset <= buf.length - 8. Default: 0.
Returns: <integer> offset plus the number of bytes written.

Writes value to buf at the specified offset as little-endian

import { Buffer } from 'node:buffer';

const buf = Buffer.allocUnsafe(8);

buf.writeBigUInt64LE(0xdecafafecacefaden, 0);

console.log(buf);
// Prints: <Buffer de fa ce ca fe fa ca de>const { Buffer } = require('node:buffer');

const buf = Buffer.allocUnsafe(8);

buf.writeBigUInt64LE(0xdecafafecacefaden, 0);

console.log(buf);
// Prints: <Buffer de fa ce ca fe fa ca de>copy
This function is also available under the writeBigUint64LE alias.

buf.writeDoubleBE(value[, offset])#

History

VersionChanges
v10.0.0
Removed noAssert and no implicit coercion of the offset to uint32 anymore.
v0.11.15
Added in: v0.11.15




value <number> Number to be written to buf.
offset <integer> Number of bytes to skip before starting to write. Must
satisfy 0 <= offset <= buf.length - 8. Default: 0.
Returns: <integer> offset plus the number of bytes written.

Writes value to buf at the specified offset as big-endian. The value
must be a JavaScript number. Behavior is undefined when value is anything
other than a JavaScript number.

import { Buffer } from 'node:buffer';

const buf = Buffer.allocUnsafe(8);

buf.writeDoubleBE(123.456, 0);

console.log(buf);
// Prints: <Buffer 40 5e dd 2f 1a 9f be 77>const { Buffer } = require('node:buffer');

const buf = Buffer.allocUnsafe(8);

buf.writeDoubleBE(123.456, 0);

console.log(buf);
// Prints: <Buffer 40 5e dd 2f 1a 9f be 77>copy

buf.writeDoubleLE(value[, offset])#

History

VersionChanges
v10.0.0
Removed noAssert and no implicit coercion of the offset to uint32 anymore.
v0.11.15
Added in: v0.11.15




value <number> Number to be written to buf.
offset <integer> Number of bytes to skip before starting to write. Must
satisfy 0 <= offset <= buf.length - 8. Default: 0.
Returns: <integer> offset plus the number of bytes written.

Writes value to buf at the specified offset as little-endian. The value
must be a JavaScript number. Behavior is undefined when value is anything
other than a JavaScript number.

import { Buffer } from 'node:buffer';

const buf = Buffer.allocUnsafe(8);

buf.writeDoubleLE(123.456, 0);

console.log(buf);
// Prints: <Buffer 77 be 9f 1a 2f dd 5e 40>const { Buffer } = require('node:buffer');

const buf = Buffer.allocUnsafe(8);

buf.writeDoubleLE(123.456, 0);

console.log(buf);
// Prints: <Buffer 77 be 9f 1a 2f dd 5e 40>copy

buf.writeFloatBE(value[, offset])#

History

VersionChanges
v10.0.0
Removed noAssert and no implicit coercion of the offset to uint32 anymore.
v0.11.15
Added in: v0.11.15




value <number> Number to be written to buf.
offset <integer> Number of bytes to skip before starting to write. Must
satisfy 0 <= offset <= buf.length - 4. Default: 0.
Returns: <integer> offset plus the number of bytes written.

Writes value to buf at the specified offset as big-endian. Behavior is
undefined when value is anything other than a JavaScript number.

import { Buffer } from 'node:buffer';

const buf = Buffer.allocUnsafe(4);

buf.writeFloatBE(0xcafebabe, 0);

console.log(buf);
// Prints: <Buffer 4f 4a fe bb>const { Buffer } = require('node:buffer');

const buf = Buffer.allocUnsafe(4);

buf.writeFloatBE(0xcafebabe, 0);

console.log(buf);
// Prints: <Buffer 4f 4a fe bb>copy

buf.writeFloatLE(value[, offset])#

History

VersionChanges
v10.0.0
Removed noAssert and no implicit coercion of the offset to uint32 anymore.
v0.11.15
Added in: v0.11.15




value <number> Number to be written to buf.
offset <integer> Number of bytes to skip before starting to write. Must
satisfy 0 <= offset <= buf.length - 4. Default: 0.
Returns: <integer> offset plus the number of bytes written.

Writes value to buf at the specified offset as little-endian. Behavior is
undefined when value is anything other than a JavaScript number.

import { Buffer } from 'node:buffer';

const buf = Buffer.allocUnsafe(4);

buf.writeFloatLE(0xcafebabe, 0);

console.log(buf);
// Prints: <Buffer bb fe 4a 4f>const { Buffer } = require('node:buffer');

const buf = Buffer.allocUnsafe(4);

buf.writeFloatLE(0xcafebabe, 0);

console.log(buf);
// Prints: <Buffer bb fe 4a 4f>copy

buf.writeInt8(value[, offset])#

History

VersionChanges
v10.0.0
Removed noAssert and no implicit coercion of the offset to uint32 anymore.
v0.5.0
Added in: v0.5.0




value <integer> Number to be written to buf.
offset <integer> Number of bytes to skip before starting to write. Must
satisfy 0 <= offset <= buf.length - 1. Default: 0.
Returns: <integer> offset plus the number of bytes written.

Writes value to buf at the specified offset. value must be a valid
signed 8-bit integer. Behavior is undefined when value is anything other than
a signed 8-bit integer.
value is interpreted and written as a two's complement signed integer.

import { Buffer } from 'node:buffer';

const buf = Buffer.allocUnsafe(2);

buf.writeInt8(2, 0);
buf.writeInt8(-2, 1);

console.log(buf);
// Prints: <Buffer 02 fe>const { Buffer } = require('node:buffer');

const buf = Buffer.allocUnsafe(2);

buf.writeInt8(2, 0);
buf.writeInt8(-2, 1);

console.log(buf);
// Prints: <Buffer 02 fe>copy

buf.writeInt16BE(value[, offset])#

History

VersionChanges
v10.0.0
Removed noAssert and no implicit coercion of the offset to uint32 anymore.
v0.5.5
Added in: v0.5.5




value <integer> Number to be written to buf.
offset <integer> Number of bytes to skip before starting to write. Must
satisfy 0 <= offset <= buf.length - 2. Default: 0.
Returns: <integer> offset plus the number of bytes written.

Writes value to buf at the specified offset as big-endian.  The value
must be a valid signed 16-bit integer. Behavior is undefined when value is
anything other than a signed 16-bit integer.
The value is interpreted and written as a two's complement signed integer.

import { Buffer } from 'node:buffer';

const buf = Buffer.allocUnsafe(2);

buf.writeInt16BE(0x0102, 0);

console.log(buf);
// Prints: <Buffer 01 02>const { Buffer } = require('node:buffer');

const buf = Buffer.allocUnsafe(2);

buf.writeInt16BE(0x0102, 0);

console.log(buf);
// Prints: <Buffer 01 02>copy

buf.writeInt16LE(value[, offset])#

History

VersionChanges
v10.0.0
Removed noAssert and no implicit coercion of the offset to uint32 anymore.
v0.5.5
Added in: v0.5.5




value <integer> Number to be written to buf.
offset <integer> Number of bytes to skip before starting to write. Must
satisfy 0 <= offset <= buf.length - 2. Default: 0.
Returns: <integer> offset plus the number of bytes written.

Writes value to buf at the specified offset as little-endian.  The value
must be a valid signed 16-bit integer. Behavior is undefined when value is
anything other than a signed 16-bit integer.
The value is interpreted and written as a two's complement signed integer.

import { Buffer } from 'node:buffer';

const buf = Buffer.allocUnsafe(2);

buf.writeInt16LE(0x0304, 0);

console.log(buf);
// Prints: <Buffer 04 03>const { Buffer } = require('node:buffer');

const buf = Buffer.allocUnsafe(2);

buf.writeInt16LE(0x0304, 0);

console.log(buf);
// Prints: <Buffer 04 03>copy

buf.writeInt32BE(value[, offset])#

History

VersionChanges
v10.0.0
Removed noAssert and no implicit coercion of the offset to uint32 anymore.
v0.5.5
Added in: v0.5.5




value <integer> Number to be written to buf.
offset <integer> Number of bytes to skip before starting to write. Must
satisfy 0 <= offset <= buf.length - 4. Default: 0.
Returns: <integer> offset plus the number of bytes written.

Writes value to buf at the specified offset as big-endian. The value
must be a valid signed 32-bit integer. Behavior is undefined when value is
anything other than a signed 32-bit integer.
The value is interpreted and written as a two's complement signed integer.

import { Buffer } from 'node:buffer';

const buf = Buffer.allocUnsafe(4);

buf.writeInt32BE(0x01020304, 0);

console.log(buf);
// Prints: <Buffer 01 02 03 04>const { Buffer } = require('node:buffer');

const buf = Buffer.allocUnsafe(4);

buf.writeInt32BE(0x01020304, 0);

console.log(buf);
// Prints: <Buffer 01 02 03 04>copy

buf.writeInt32LE(value[, offset])#

History

VersionChanges
v10.0.0
Removed noAssert and no implicit coercion of the offset to uint32 anymore.
v0.5.5
Added in: v0.5.5




value <integer> Number to be written to buf.
offset <integer> Number of bytes to skip before starting to write. Must
satisfy 0 <= offset <= buf.length - 4. Default: 0.
Returns: <integer> offset plus the number of bytes written.

Writes value to buf at the specified offset as little-endian. The value
must be a valid signed 32-bit integer. Behavior is undefined when value is
anything other than a signed 32-bit integer.
The value is interpreted and written as a two's complement signed integer.

import { Buffer } from 'node:buffer';

const buf = Buffer.allocUnsafe(4);

buf.writeInt32LE(0x05060708, 0);

console.log(buf);
// Prints: <Buffer 08 07 06 05>const { Buffer } = require('node:buffer');

const buf = Buffer.allocUnsafe(4);

buf.writeInt32LE(0x05060708, 0);

console.log(buf);
// Prints: <Buffer 08 07 06 05>copy

buf.writeIntBE(value, offset, byteLength)#

History

VersionChanges
v10.0.0
Removed noAssert and no implicit coercion of the offset and byteLength to uint32 anymore.
v0.11.15
Added in: v0.11.15




value <integer> Number to be written to buf.
offset <integer> Number of bytes to skip before starting to write. Must
satisfy 0 <= offset <= buf.length - byteLength.
byteLength <integer> Number of bytes to write. Must satisfy
0 < byteLength <= 6.
Returns: <integer> offset plus the number of bytes written.

Writes byteLength bytes of value to buf at the specified offset
as big-endian. Supports up to 48 bits of accuracy. Behavior is undefined when
value is anything other than a signed integer.

import { Buffer } from 'node:buffer';

const buf = Buffer.allocUnsafe(6);

buf.writeIntBE(0x1234567890ab, 0, 6);

console.log(buf);
// Prints: <Buffer 12 34 56 78 90 ab>const { Buffer } = require('node:buffer');

const buf = Buffer.allocUnsafe(6);

buf.writeIntBE(0x1234567890ab, 0, 6);

console.log(buf);
// Prints: <Buffer 12 34 56 78 90 ab>copy

buf.writeIntLE(value, offset, byteLength)#

History

VersionChanges
v10.0.0
Removed noAssert and no implicit coercion of the offset and byteLength to uint32 anymore.
v0.11.15
Added in: v0.11.15




value <integer> Number to be written to buf.
offset <integer> Number of bytes to skip before starting to write. Must
satisfy 0 <= offset <= buf.length - byteLength.
byteLength <integer> Number of bytes to write. Must satisfy
0 < byteLength <= 6.
Returns: <integer> offset plus the number of bytes written.

Writes byteLength bytes of value to buf at the specified offset
as little-endian. Supports up to 48 bits of accuracy. Behavior is undefined
when value is anything other than a signed integer.

import { Buffer } from 'node:buffer';

const buf = Buffer.allocUnsafe(6);

buf.writeIntLE(0x1234567890ab, 0, 6);

console.log(buf);
// Prints: <Buffer ab 90 78 56 34 12>const { Buffer } = require('node:buffer');

const buf = Buffer.allocUnsafe(6);

buf.writeIntLE(0x1234567890ab, 0, 6);

console.log(buf);
// Prints: <Buffer ab 90 78 56 34 12>copy

buf.writeUInt8(value[, offset])#

History

VersionChanges
v14.9.0, v12.19.0
This function is also available as buf.writeUint8().
v10.0.0
Removed noAssert and no implicit coercion of the offset to uint32 anymore.
v0.5.0
Added in: v0.5.0




value <integer> Number to be written to buf.
offset <integer> Number of bytes to skip before starting to write. Must
satisfy 0 <= offset <= buf.length - 1. Default: 0.
Returns: <integer> offset plus the number of bytes written.

Writes value to buf at the specified offset. value must be a
valid unsigned 8-bit integer. Behavior is undefined when value is anything
other than an unsigned 8-bit integer.
This function is also available under the writeUint8 alias.

import { Buffer } from 'node:buffer';

const buf = Buffer.allocUnsafe(4);

buf.writeUInt8(0x3, 0);
buf.writeUInt8(0x4, 1);
buf.writeUInt8(0x23, 2);
buf.writeUInt8(0x42, 3);

console.log(buf);
// Prints: <Buffer 03 04 23 42>const { Buffer } = require('node:buffer');

const buf = Buffer.allocUnsafe(4);

buf.writeUInt8(0x3, 0);
buf.writeUInt8(0x4, 1);
buf.writeUInt8(0x23, 2);
buf.writeUInt8(0x42, 3);

console.log(buf);
// Prints: <Buffer 03 04 23 42>copy

buf.writeUInt16BE(value[, offset])#

History

VersionChanges
v14.9.0, v12.19.0
This function is also available as buf.writeUint16BE().
v10.0.0
Removed noAssert and no implicit coercion of the offset to uint32 anymore.
v0.5.5
Added in: v0.5.5




value <integer> Number to be written to buf.
offset <integer> Number of bytes to skip before starting to write. Must
satisfy 0 <= offset <= buf.length - 2. Default: 0.
Returns: <integer> offset plus the number of bytes written.

Writes value to buf at the specified offset as big-endian. The value
must be a valid unsigned 16-bit integer. Behavior is undefined when value
is anything other than an unsigned 16-bit integer.
This function is also available under the writeUint16BE alias.

import { Buffer } from 'node:buffer';

const buf = Buffer.allocUnsafe(4);

buf.writeUInt16BE(0xdead, 0);
buf.writeUInt16BE(0xbeef, 2);

console.log(buf);
// Prints: <Buffer de ad be ef>const { Buffer } = require('node:buffer');

const buf = Buffer.allocUnsafe(4);

buf.writeUInt16BE(0xdead, 0);
buf.writeUInt16BE(0xbeef, 2);

console.log(buf);
// Prints: <Buffer de ad be ef>copy

buf.writeUInt16LE(value[, offset])#

History

VersionChanges
v14.9.0, v12.19.0
This function is also available as buf.writeUint16LE().
v10.0.0
Removed noAssert and no implicit coercion of the offset to uint32 anymore.
v0.5.5
Added in: v0.5.5




value <integer> Number to be written to buf.
offset <integer> Number of bytes to skip before starting to write. Must
satisfy 0 <= offset <= buf.length - 2. Default: 0.
Returns: <integer> offset plus the number of bytes written.

Writes value to buf at the specified offset as little-endian. The value
must be a valid unsigned 16-bit integer. Behavior is undefined when value is
anything other than an unsigned 16-bit integer.
This function is also available under the writeUint16LE alias.

import { Buffer } from 'node:buffer';

const buf = Buffer.allocUnsafe(4);

buf.writeUInt16LE(0xdead, 0);
buf.writeUInt16LE(0xbeef, 2);

console.log(buf);
// Prints: <Buffer ad de ef be>const { Buffer } = require('node:buffer');

const buf = Buffer.allocUnsafe(4);

buf.writeUInt16LE(0xdead, 0);
buf.writeUInt16LE(0xbeef, 2);

console.log(buf);
// Prints: <Buffer ad de ef be>copy

buf.writeUInt32BE(value[, offset])#

History

VersionChanges
v14.9.0, v12.19.0
This function is also available as buf.writeUint32BE().
v10.0.0
Removed noAssert and no implicit coercion of the offset to uint32 anymore.
v0.5.5
Added in: v0.5.5




value <integer> Number to be written to buf.
offset <integer> Number of bytes to skip before starting to write. Must
satisfy 0 <= offset <= buf.length - 4. Default: 0.
Returns: <integer> offset plus the number of bytes written.

Writes value to buf at the specified offset as big-endian. The value
must be a valid unsigned 32-bit integer. Behavior is undefined when value
is anything other than an unsigned 32-bit integer.
This function is also available under the writeUint32BE alias.

import { Buffer } from 'node:buffer';

const buf = Buffer.allocUnsafe(4);

buf.writeUInt32BE(0xfeedface, 0);

console.log(buf);
// Prints: <Buffer fe ed fa ce>const { Buffer } = require('node:buffer');

const buf = Buffer.allocUnsafe(4);

buf.writeUInt32BE(0xfeedface, 0);

console.log(buf);
// Prints: <Buffer fe ed fa ce>copy

buf.writeUInt32LE(value[, offset])#

History

VersionChanges
v14.9.0, v12.19.0
This function is also available as buf.writeUint32LE().
v10.0.0
Removed noAssert and no implicit coercion of the offset to uint32 anymore.
v0.5.5
Added in: v0.5.5




value <integer> Number to be written to buf.
offset <integer> Number of bytes to skip before starting to write. Must
satisfy 0 <= offset <= buf.length - 4. Default: 0.
Returns: <integer> offset plus the number of bytes written.

Writes value to buf at the specified offset as little-endian. The value
must be a valid unsigned 32-bit integer. Behavior is undefined when value is
anything other than an unsigned 32-bit integer.
This function is also available under the writeUint32LE alias.

import { Buffer } from 'node:buffer';

const buf = Buffer.allocUnsafe(4);

buf.writeUInt32LE(0xfeedface, 0);

console.log(buf);
// Prints: <Buffer ce fa ed fe>const { Buffer } = require('node:buffer');

const buf = Buffer.allocUnsafe(4);

buf.writeUInt32LE(0xfeedface, 0);

console.log(buf);
// Prints: <Buffer ce fa ed fe>copy

buf.writeUIntBE(value, offset, byteLength)#

History

VersionChanges
v14.9.0, v12.19.0
This function is also available as buf.writeUintBE().
v10.0.0
Removed noAssert and no implicit coercion of the offset and byteLength to uint32 anymore.
v0.5.5
Added in: v0.5.5




value <integer> Number to be written to buf.
offset <integer> Number of bytes to skip before starting to write. Must
satisfy 0 <= offset <= buf.length - byteLength.
byteLength <integer> Number of bytes to write. Must satisfy
0 < byteLength <= 6.
Returns: <integer> offset plus the number of bytes written.

Writes byteLength bytes of value to buf at the specified offset
as big-endian. Supports up to 48 bits of accuracy. Behavior is undefined
when value is anything other than an unsigned integer.
This function is also available under the writeUintBE alias.

import { Buffer } from 'node:buffer';

const buf = Buffer.allocUnsafe(6);

buf.writeUIntBE(0x1234567890ab, 0, 6);

console.log(buf);
// Prints: <Buffer 12 34 56 78 90 ab>const { Buffer } = require('node:buffer');

const buf = Buffer.allocUnsafe(6);

buf.writeUIntBE(0x1234567890ab, 0, 6);

console.log(buf);
// Prints: <Buffer 12 34 56 78 90 ab>copy

buf.writeUIntLE(value, offset, byteLength)#

History

VersionChanges
v14.9.0, v12.19.0
This function is also available as buf.writeUintLE().
v10.0.0
Removed noAssert and no implicit coercion of the offset and byteLength to uint32 anymore.
v0.5.5
Added in: v0.5.5




value <integer> Number to be written to buf.
offset <integer> Number of bytes to skip before starting to write. Must
satisfy 0 <= offset <= buf.length - byteLength.
byteLength <integer> Number of bytes to write. Must satisfy
0 < byteLength <= 6.
Returns: <integer> offset plus the number of bytes written.

Writes byteLength bytes of value to buf at the specified offset
as little-endian. Supports up to 48 bits of accuracy. Behavior is undefined
when value is anything other than an unsigned integer.
This function is also available under the writeUintLE alias.

import { Buffer } from 'node:buffer';

const buf = Buffer.allocUnsafe(6);

buf.writeUIntLE(0x1234567890ab, 0, 6);

console.log(buf);
// Prints: <Buffer ab 90 78 56 34 12>const { Buffer } = require('node:buffer');

const buf = Buffer.allocUnsafe(6);

buf.writeUIntLE(0x1234567890ab, 0, 6);

console.log(buf);
// Prints: <Buffer ab 90 78 56 34 12>copy

new Buffer(array)#

History

VersionChanges
v10.0.0
Calling this constructor emits a deprecation warning when run from code outside the node_modules directory.
v7.2.1
Calling this constructor no longer emits a deprecation warning.
v7.0.0
Calling this constructor emits a deprecation warning now.
v6.0.0
Deprecated since: v6.0.0



Stability: 0 - Deprecated: Use Buffer.from(array) instead.

array <integer[]> An array of bytes to copy from.

See Buffer.from(array).

new Buffer(arrayBuffer[, byteOffset[, length]])#

History

VersionChanges
v10.0.0
Calling this constructor emits a deprecation warning when run from code outside the node_modules directory.
v7.2.1
Calling this constructor no longer emits a deprecation warning.
v7.0.0
Calling this constructor emits a deprecation warning now.
v6.0.0
The byteOffset and length parameters are supported now.
v6.0.0
Deprecated since: v6.0.0
v3.0.0
Added in: v3.0.0



Stability: 0 - Deprecated: Use
Buffer.from(arrayBuffer[, byteOffset[, length]])
instead.

arrayBuffer <ArrayBuffer> | <SharedArrayBuffer> An <ArrayBuffer>,
<SharedArrayBuffer> or the .buffer property of a <TypedArray>.
byteOffset <integer> Index of first byte to expose. Default: 0.
length <integer> Number of bytes to expose.
Default: arrayBuffer.byteLength - byteOffset.

See
Buffer.from(arrayBuffer[, byteOffset[, length]]).

new Buffer(buffer)#

History

VersionChanges
v10.0.0
Calling this constructor emits a deprecation warning when run from code outside the node_modules directory.
v7.2.1
Calling this constructor no longer emits a deprecation warning.
v7.0.0
Calling this constructor emits a deprecation warning now.
v6.0.0
Deprecated since: v6.0.0



Stability: 0 - Deprecated: Use Buffer.from(buffer) instead.

buffer <Buffer> | <Uint8Array> An existing Buffer or <Uint8Array> from
which to copy data.

See Buffer.from(buffer).

new Buffer(size)#

History

VersionChanges
v10.0.0
Calling this constructor emits a deprecation warning when run from code outside the node_modules directory.
v8.0.0
The new Buffer(size) will return zero-filled memory by default.
v7.2.1
Calling this constructor no longer emits a deprecation warning.
v7.0.0
Calling this constructor emits a deprecation warning now.
v6.0.0
Deprecated since: v6.0.0



Stability: 0 - Deprecated: Use Buffer.alloc() instead (also see
Buffer.allocUnsafe()).

size <integer> The desired length of the new Buffer.

See Buffer.alloc() and Buffer.allocUnsafe(). This variant of the
constructor is equivalent to Buffer.alloc().

new Buffer(string[, encoding])#

History

VersionChanges
v10.0.0
Calling this constructor emits a deprecation warning when run from code outside the node_modules directory.
v7.2.1
Calling this constructor no longer emits a deprecation warning.
v7.0.0
Calling this constructor emits a deprecation warning now.
v6.0.0
Deprecated since: v6.0.0



Stability: 0 - Deprecated:
Use Buffer.from(string[, encoding]) instead.

string <string> String to encode.
encoding <string> The encoding of string. Default: 'utf8'.

See Buffer.from(string[, encoding]).

Class: File#

History

VersionChanges
v23.0.0
Makes File instances cloneable.
v20.0.0
No longer experimental.
v19.2.0, v18.13.0
Added in: v19.2.0, v18.13.0




Extends: <Blob>

A <File> provides information about files.

new buffer.File(sources, fileName[, options])#

Added in: v19.2.0, v18.13.0


sources <string[]> | <ArrayBuffer[]> | <TypedArray[]> | <DataView[]> | <Blob[]> | <File[]>
An array of string, <ArrayBuffer>, <TypedArray>, <DataView>, <File>, or <Blob>
objects, or any mix of such objects, that will be stored within the File.
fileName <string> The name of the file.
options <Object>

endings <string> One of either 'transparent' or 'native'. When set
to 'native', line endings in string source parts will be converted to
the platform native line-ending as specified by require('node:os').EOL.
type <string> The File content-type.
lastModified <number> The last modified date of the file.
Default: Date.now().




file.name#

Added in: v19.2.0, v18.13.0


Type: <string>

The name of the File.

file.lastModified#

Added in: v19.2.0, v18.13.0


Type: <number>

The last modified date of the File.

node:buffer module APIs#
While, the Buffer object is available as a global, there are additional
Buffer-related APIs that are available only via the node:buffer module
accessed using require('node:buffer').

buffer.atob(data)#

Added in: v15.13.0, v14.17.0

Stability: 3 - Legacy. Use Buffer.from(data, 'base64') instead.

data <any> The Base64-encoded input string.

Decodes a string of Base64-encoded data into bytes, and encodes those bytes
into a string using Latin-1 (ISO-8859-1).
The data may be any JavaScript-value that can be coerced into a string.
This function is only provided for compatibility with legacy web platform APIs
and should never be used in new code, because they use strings to represent
binary data and predate the introduction of typed arrays in JavaScript.
For code running using Node.js APIs, converting between base64-encoded strings
and binary data should be performed using Buffer.from(str, 'base64') and
buf.toString('base64').

buffer.btoa(data)#

Added in: v15.13.0, v14.17.0

Stability: 3 - Legacy. Use buf.toString('base64') instead.

data <any> An ASCII (Latin1) string.

Decodes a string into bytes using Latin-1 (ISO-8859), and encodes those bytes
into a string using Base64.
The data may be any JavaScript-value that can be coerced into a string.
This function is only provided for compatibility with legacy web platform APIs
and should never be used in new code, because they use strings to represent
binary data and predate the introduction of typed arrays in JavaScript.
For code running using Node.js APIs, converting between base64-encoded strings
and binary data should be performed using Buffer.from(str, 'base64') and
buf.toString('base64').

buffer.isAscii(input)#

Added in: v19.6.0, v18.15.0


input <Buffer> | <ArrayBuffer> | <TypedArray> The input to validate.
Returns: <boolean>

This function returns true if input contains only valid ASCII-encoded data,
including the case in which input is empty.
Throws if the input is a detached array buffer.

buffer.isUtf8(input)#

Added in: v19.4.0, v18.14.0


input <Buffer> | <ArrayBuffer> | <TypedArray> The input to validate.
Returns: <boolean>

This function returns true if input contains only valid UTF-8-encoded data,
including the case in which input is empty.
Throws if the input is a detached array buffer.

buffer.INSPECT_MAX_BYTES#

Added in: v0.5.4


<integer> Default: 50

Returns the maximum number of bytes that will be returned when
buf.inspect() is called. This can be overridden by user modules. See
util.inspect() for more details on buf.inspect() behavior.

buffer.kMaxLength#

Added in: v3.0.0


<integer> The largest size allowed for a single Buffer instance.

An alias for buffer.constants.MAX_LENGTH.

buffer.kStringMaxLength#

Added in: v3.0.0


<integer> The largest length allowed for a single string instance.

An alias for buffer.constants.MAX_STRING_LENGTH.

buffer.resolveObjectURL(id)#

History

VersionChanges
v24.0.0
Marking the API stable.
v16.7.0
Added in: v16.7.0




id <string> A 'blob:nodedata:... URL string returned by a prior call to
URL.createObjectURL().
Returns: <Blob>

Resolves a 'blob:nodedata:...' an associated <Blob> object registered using
a prior call to URL.createObjectURL().

buffer.transcode(source, fromEnc, toEnc)#

History

VersionChanges
v8.0.0
The source parameter can now be a Uint8Array.
v7.1.0
Added in: v7.1.0




source <Buffer> | <Uint8Array> A Buffer or Uint8Array instance.
fromEnc <string> The current encoding.
toEnc <string> To target encoding.
Returns: <Buffer>

Re-encodes the given Buffer or Uint8Array instance from one character
encoding to another. Returns a new Buffer instance.
Throws if the fromEnc or toEnc specify invalid character encodings or if
conversion from fromEnc to toEnc is not permitted.
Encodings supported by buffer.transcode() are: 'ascii', 'utf8',
'utf16le', 'ucs2', 'latin1', and 'binary'.
The transcoding process will use substitution characters if a given byte
sequence cannot be adequately represented in the target encoding. For instance:

import { Buffer, transcode } from 'node:buffer';

const newBuf = transcode(Buffer.from('€'), 'utf8', 'ascii');
console.log(newBuf.toString('ascii'));
// Prints: '?'const { Buffer, transcode } = require('node:buffer');

const newBuf = transcode(Buffer.from('€'), 'utf8', 'ascii');
console.log(newBuf.toString('ascii'));
// Prints: '?'copy
Because the Euro (€) sign is not representable in US-ASCII, it is replaced
with ? in the transcoded Buffer.

Class: SlowBuffer#

Deprecated since: v6.0.0

Stability: 0 - Deprecated: Use Buffer.allocUnsafeSlow() instead.
See Buffer.allocUnsafeSlow(). This was never a class in the sense that
the constructor always returned a Buffer instance, rather than a SlowBuffer
instance.

new SlowBuffer(size)#

Deprecated since: v6.0.0


size <integer> The desired length of the new SlowBuffer.

See Buffer.allocUnsafeSlow().

Buffer constants#

Added in: v8.2.0


buffer.constants.MAX_LENGTH#

History

VersionChanges
v22.0.0
Value is changed to 253 - 1 on 64-bit architectures.
v15.0.0
Value is changed to 232 on 64-bit architectures.
v14.0.0
Value is changed from 231 - 1 to 232 - 1 on 64-bit architectures.
v8.2.0
Added in: v8.2.0




<integer> The largest size allowed for a single Buffer instance.

On 32-bit architectures, this value currently is 230 - 1 (about 1
GiB).
On 64-bit architectures, this value currently is 253 - 1 (about 8 PiB).
It reflects v8::TypedArray::kMaxLength under the hood.
This value is also available as buffer.kMaxLength.

buffer.constants.MAX_STRING_LENGTH#

Added in: v8.2.0


<integer> The largest length allowed for a single string instance.

Represents the largest length that a string primitive can have, counted
in UTF-16 code units.
This value may depend on the JS engine that is being used.

Buffer.from(), Buffer.alloc(), and Buffer.allocUnsafe()#
In versions of Node.js prior to 6.0.0, Buffer instances were created using the
Buffer constructor function, which allocates the returned Buffer
differently based on what arguments are provided:

Passing a number as the first argument to Buffer() (e.g. new Buffer(10))
allocates a new Buffer object of the specified size. Prior to Node.js 8.0.0,
the memory allocated for such Buffer instances is not initialized and
can contain sensitive data. Such Buffer instances must be subsequently
initialized by using either buf.fill(0) or by writing to the
entire Buffer before reading data from the Buffer.
While this behavior is intentional to improve performance,
development experience has demonstrated that a more explicit distinction is
required between creating a fast-but-uninitialized Buffer versus creating a
slower-but-safer Buffer. Since Node.js 8.0.0, Buffer(num) and new Buffer(num) return a Buffer with initialized memory.
Passing a string, array, or Buffer as the first argument copies the
passed object's data into the Buffer.
Passing an <ArrayBuffer> or a <SharedArrayBuffer> returns a Buffer
that shares allocated memory with the given array buffer.

Because the behavior of new Buffer() is different depending on the type of the
first argument, security and reliability issues can be inadvertently introduced
into applications when argument validation or Buffer initialization is not
performed.
For example, if an attacker can cause an application to receive a number where
a string is expected, the application may call new Buffer(100)
instead of new Buffer("100"), leading it to allocate a 100 byte buffer instead
of allocating a 3 byte buffer with content "100". This is commonly possible
using JSON API calls. Since JSON distinguishes between numeric and string types,
it allows injection of numbers where a naively written application that does not
validate its input sufficiently might expect to always receive a string.
Before Node.js 8.0.0, the 100 byte buffer might contain
arbitrary pre-existing in-memory data, so may be used to expose in-memory
secrets to a remote attacker. Since Node.js 8.0.0, exposure of memory cannot
occur because the data is zero-filled. However, other attacks are still
possible, such as causing very large buffers to be allocated by the server,
leading to performance degradation or crashing on memory exhaustion.
To make the creation of Buffer instances more reliable and less error-prone,
the various forms of the new Buffer() constructor have been deprecated
and replaced by separate Buffer.from(), Buffer.alloc(), and
Buffer.allocUnsafe() methods.
Developers should migrate all existing uses of the new Buffer() constructors
to one of these new APIs.

Buffer.from(array) returns a new Buffer that contains a copy of the
provided octets.
Buffer.from(arrayBuffer[, byteOffset[, length]])
returns a new Buffer that shares the same allocated memory as the given
<ArrayBuffer>.
Buffer.from(buffer) returns a new Buffer that contains a copy of the
contents of the given Buffer.
Buffer.from(string[, encoding]) returns a new
Buffer that contains a copy of the provided string.
Buffer.alloc(size[, fill[, encoding]]) returns a new
initialized Buffer of the specified size. This method is slower than
Buffer.allocUnsafe(size) but guarantees that newly
created Buffer instances never contain old data that is potentially
sensitive. A TypeError will be thrown if size is not a number.
Buffer.allocUnsafe(size) and
Buffer.allocUnsafeSlow(size) each return a
new uninitialized Buffer of the specified size. Because the Buffer is
uninitialized, the allocated segment of memory might contain old data that is
potentially sensitive.

Buffer instances returned by Buffer.allocUnsafe(), Buffer.from(string),
Buffer.concat() and Buffer.from(array) may be allocated off a shared
internal memory pool if size is less than or equal to half Buffer.poolSize.
Instances returned by Buffer.allocUnsafeSlow() never use the shared internal
memory pool.

The --zero-fill-buffers command-line option#

Added in: v5.10.0

Node.js can be started using the --zero-fill-buffers command-line option to
cause all newly-allocated Buffer instances to be zero-filled upon creation by
default. Without the option, buffers created with Buffer.allocUnsafe(),
Buffer.allocUnsafeSlow(), and new SlowBuffer(size) are not zero-filled.
Use of this flag can have a measurable negative impact on performance. Use the
--zero-fill-buffers option only when necessary to enforce that newly allocated
Buffer instances cannot contain old data that is potentially sensitive.
$ node --zero-fill-buffers
> Buffer.allocUnsafe(5);
<Buffer 00 00 00 00 00> copy

What makes Buffer.allocUnsafe() and Buffer.allocUnsafeSlow() "unsafe"?#
When calling Buffer.allocUnsafe() and Buffer.allocUnsafeSlow(), the
segment of allocated memory is uninitialized (it is not zeroed-out). While
this design makes the allocation of memory quite fast, the allocated segment of
memory might contain old data that is potentially sensitive. Using a Buffer
created by Buffer.allocUnsafe() without completely overwriting the
memory can allow this old data to be leaked when the Buffer memory is read.
While there are clear performance advantages to using
Buffer.allocUnsafe(), extra care must be taken in order to avoid
introducing security vulnerabilities into an application.\n\n\n\nNode.js
        
      
      
About this documentation
Usage and example



Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Modules: TypeScript
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
Readline
REPL
Report
Single executable applications
SQLite
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker

    

    
      
        
          Node.js v24.0.1 documentation
          
            
            
          
        
        
          
            Node.js v24.0.1
            
    
      
        
        Table of contents
      

      
C++ addons

Hello world

Context-aware addons

Worker support


Building
Linking to libraries included with Node.js
Loading addons using require()


Native abstractions for Node.js
Node-API
Addon examples

Function arguments
Callbacks
Object factory
Function factory
Wrapping C++ objects
Factory of wrapped objects
Passing wrapped objects around





    
  
            
    
      
        
        Index
      

      
About this documentation
Usage and example

      
        Index
      
    
  


Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Modules: TypeScript
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
Readline
REPL
Report
Single executable applications
SQLite
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker

    
  
            
    
      
        
        Other versions
      
      24.x
23.x
22.x LTS
21.x
20.x LTS
19.x
18.x
17.x
16.x
15.x
14.x
13.x
12.x
11.x
10.x
9.x
8.x
7.x
6.x
5.x
4.x
0.12.x
0.10.x
    
  
            
              
                
                Options
              
        
              
                
                  
                    View on single page
                  
                  
                    View as JSON
                  
                  Edit on GitHub    
                
              
            
          
        
        
      

      Table of contents
C++ addons

Hello world

Context-aware addons

Worker support


Building
Linking to libraries included with Node.js
Loading addons using require()


Native abstractions for Node.js
Node-API
Addon examples

Function arguments
Callbacks
Object factory
Function factory
Wrapping C++ objects
Factory of wrapped objects
Passing wrapped objects around






      
        C++ addons#


Addons are dynamically-linked shared objects written in C++. The
require() function can load addons as ordinary Node.js modules.
Addons provide an interface between JavaScript and C/C++ libraries.
There are three options for implementing addons:

Node-API
nan (Native Abstractions for Node.js)
direct use of internal V8, libuv, and Node.js libraries

Unless there is a need for direct access to functionality which is not
exposed by Node-API, use Node-API.
Refer to C/C++ addons with Node-API for more information on
Node-API.
When not using Node-API, implementing addons becomes more complex, requiring
knowledge of multiple components and APIs:


V8: the C++ library Node.js uses to provide the
JavaScript implementation. It provides the mechanisms for creating objects,
calling functions, etc. The V8's API is documented mostly in the
v8.h header file (deps/v8/include/v8.h in the Node.js source
tree), and is also available online.


libuv: The C library that implements the Node.js event loop, its worker
threads and all of the asynchronous behaviors of the platform. It also
serves as a cross-platform abstraction library, giving easy, POSIX-like
access across all major operating systems to many common system tasks, such
as interacting with the file system, sockets, timers, and system events. libuv
also provides a threading abstraction similar to POSIX threads for
more sophisticated asynchronous addons that need to move beyond the
standard event loop. Addon authors should
avoid blocking the event loop with I/O or other time-intensive tasks by
offloading work via libuv to non-blocking system operations, worker threads,
or a custom use of libuv threads.


Internal Node.js libraries: Node.js itself exports C++ APIs that addons can
use, the most important of which is the node::ObjectWrap class.


Other statically linked libraries (including OpenSSL): These
other libraries are located in the deps/ directory in the Node.js source
tree. Only the libuv, OpenSSL, V8, and zlib symbols are purposefully
re-exported by Node.js and may be used to various extents by addons. See
Linking to libraries included with Node.js for additional information.


All of the following examples are available for download and may
be used as the starting-point for an addon.
Hello world#
This "Hello world" example is a simple addon, written in C++, that is the
equivalent of the following JavaScript code:
module.exports.hello = () => 'world'; copy
First, create the file hello.cc:
// hello.cc
#include <node.h>

namespace demo {

using v8::FunctionCallbackInfo;
using v8::Isolate;
using v8::Local;
using v8::NewStringType;
using v8::Object;
using v8::String;
using v8::Value;

void Method(const FunctionCallbackInfo<Value>& args) {
  Isolate* isolate = args.GetIsolate();
  args.GetReturnValue().Set(String::NewFromUtf8(
      isolate, "world", NewStringType::kNormal).ToLocalChecked());
}

void Initialize(Local<Object> exports) {
  NODE_SET_METHOD(exports, "hello", Method);
}

NODE_MODULE(NODE_GYP_MODULE_NAME, Initialize)

}  // namespace demo copy
All Node.js addons must export an initialization function following
the pattern:
void Initialize(Local<Object> exports);
NODE_MODULE(NODE_GYP_MODULE_NAME, Initialize) copy
There is no semi-colon after NODE_MODULE as it's not a function (see
node.h).
The module_name must match the filename of the final binary (excluding
the .node suffix).
In the hello.cc example, then, the initialization function is Initialize
and the addon module name is addon.
When building addons with node-gyp, using the macro NODE_GYP_MODULE_NAME as
the first parameter of NODE_MODULE() will ensure that the name of the final
binary will be passed to NODE_MODULE().
Addons defined with NODE_MODULE() can not be loaded in multiple contexts or
multiple threads at the same time.

Context-aware addons#
There are environments in which Node.js addons may need to be loaded multiple
times in multiple contexts. For example, the Electron runtime runs multiple
instances of Node.js in a single process. Each instance will have its own
require() cache, and thus each instance will need a native addon to behave
correctly when loaded via require(). This means that the addon
must support multiple initializations.
A context-aware addon can be constructed by using the macro
NODE_MODULE_INITIALIZER, which expands to the name of a function which Node.js
will expect to find when it loads an addon. An addon can thus be initialized as
in the following example:
using namespace v8;

extern "C" NODE_MODULE_EXPORT void
NODE_MODULE_INITIALIZER(Local<Object> exports,
                        Local<Value> module,
                        Local<Context> context) {
  /* Perform addon initialization steps here. */
} copy
Another option is to use the macro NODE_MODULE_INIT(), which will also
construct a context-aware addon. Unlike NODE_MODULE(), which is used to
construct an addon around a given addon initializer function,
NODE_MODULE_INIT() serves as the declaration of such an initializer to be
followed by a function body.
The following three variables may be used inside the function body following an
invocation of NODE_MODULE_INIT():

Local<Object> exports,
Local<Value> module, and
Local<Context> context

Building a context-aware addon requires careful management of global static data
to ensure stability and correctness. Since the addon may be loaded multiple
times, potentially even from different threads, any global static data stored
in the addon must be properly protected, and must not contain any persistent
references to JavaScript objects. The reason for this is that JavaScript
objects are only valid in one context, and will likely cause a crash when
accessed from the wrong context or from a different thread than the one on which
they were created.
The context-aware addon can be structured to avoid global static data by
performing the following steps:

Define a class which will hold per-addon-instance data and which has a static
member of the form
static void DeleteInstance(void* data) {
  // Cast `data` to an instance of the class and delete it.
} copy

Heap-allocate an instance of this class in the addon initializer. This can be
accomplished using the new keyword.
Call node::AddEnvironmentCleanupHook(), passing it the above-created
instance and a pointer to DeleteInstance(). This will ensure the instance is
deleted when the environment is torn down.
Store the instance of the class in a v8::External, and
Pass the v8::External to all methods exposed to JavaScript by passing it
to v8::FunctionTemplate::New() or v8::Function::New() which creates the
native-backed JavaScript functions. The third parameter of
v8::FunctionTemplate::New() or v8::Function::New()  accepts the
v8::External and makes it available in the native callback using the
v8::FunctionCallbackInfo::Data() method.

This will ensure that the per-addon-instance data reaches each binding that can
be called from JavaScript. The per-addon-instance data must also be passed into
any asynchronous callbacks the addon may create.
The following example illustrates the implementation of a context-aware addon:
#include <node.h>

using namespace v8;

class AddonData {
 public:
  explicit AddonData(Isolate* isolate):
      call_count(0) {
    // Ensure this per-addon-instance data is deleted at environment cleanup.
    node::AddEnvironmentCleanupHook(isolate, DeleteInstance, this);
  }

  // Per-addon data.
  int call_count;

  static void DeleteInstance(void* data) {
    delete static_cast<AddonData*>(data);
  }
};

static void Method(const v8::FunctionCallbackInfo<v8::Value>& info) {
  // Retrieve the per-addon-instance data.
  AddonData* data =
      reinterpret_cast<AddonData*>(info.Data().As<External>()->Value());
  data->call_count++;
  info.GetReturnValue().Set((double)data->call_count);
}

// Initialize this addon to be context-aware.
NODE_MODULE_INIT(/* exports, module, context */) {
  Isolate* isolate = context->GetIsolate();

  // Create a new instance of `AddonData` for this instance of the addon and
  // tie its life cycle to that of the Node.js environment.
  AddonData* data = new AddonData(isolate);

  // Wrap the data in a `v8::External` so we can pass it to the method we
  // expose.
  Local<External> external = External::New(isolate, data);

  // Expose the method `Method` to JavaScript, and make sure it receives the
  // per-addon-instance data we created above by passing `external` as the
  // third parameter to the `FunctionTemplate` constructor.
  exports->Set(context,
               String::NewFromUtf8(isolate, "method").ToLocalChecked(),
               FunctionTemplate::New(isolate, Method, external)
                  ->GetFunction(context).ToLocalChecked()).FromJust();
} copy

Worker support#

History

VersionChanges
v14.8.0, v12.19.0
Cleanup hooks may now be asynchronous.



In order to be loaded from multiple Node.js environments,
such as a main thread and a Worker thread, an add-on needs to either:

Be an Node-API addon, or
Be declared as context-aware using NODE_MODULE_INIT() as described above

In order to support Worker threads, addons need to clean up any resources
they may have allocated when such a thread exits. This can be achieved through
the usage of the AddEnvironmentCleanupHook() function:
void AddEnvironmentCleanupHook(v8::Isolate* isolate,
                               void (*fun)(void* arg),
                               void* arg); copy
This function adds a hook that will run before a given Node.js instance shuts
down. If necessary, such hooks can be removed before they are run using
RemoveEnvironmentCleanupHook(), which has the same signature. Callbacks are
run in last-in first-out order.
If necessary, there is an additional pair of AddEnvironmentCleanupHook()
and RemoveEnvironmentCleanupHook() overloads, where the cleanup hook takes a
callback function. This can be used for shutting down asynchronous resources,
such as any libuv handles registered by the addon.
The following addon.cc uses AddEnvironmentCleanupHook:
// addon.cc
#include <node.h>
#include <assert.h>
#include <stdlib.h>

using node::AddEnvironmentCleanupHook;
using v8::HandleScope;
using v8::Isolate;
using v8::Local;
using v8::Object;

// Note: In a real-world application, do not rely on static/global data.
static char cookie[] = "yum yum";
static int cleanup_cb1_called = 0;
static int cleanup_cb2_called = 0;

static void cleanup_cb1(void* arg) {
  Isolate* isolate = static_cast<Isolate*>(arg);
  HandleScope scope(isolate);
  Local<Object> obj = Object::New(isolate);
  assert(!obj.IsEmpty());  // assert VM is still alive
  assert(obj->IsObject());
  cleanup_cb1_called++;
}

static void cleanup_cb2(void* arg) {
  assert(arg == static_cast<void*>(cookie));
  cleanup_cb2_called++;
}

static void sanity_check(void*) {
  assert(cleanup_cb1_called == 1);
  assert(cleanup_cb2_called == 1);
}

// Initialize this addon to be context-aware.
NODE_MODULE_INIT(/* exports, module, context */) {
  Isolate* isolate = context->GetIsolate();

  AddEnvironmentCleanupHook(isolate, sanity_check, nullptr);
  AddEnvironmentCleanupHook(isolate, cleanup_cb2, cookie);
  AddEnvironmentCleanupHook(isolate, cleanup_cb1, isolate);
} copy
Test in JavaScript by running:
// test.js
require('./build/Release/addon'); copy

Building#
Once the source code has been written, it must be compiled into the binary
addon.node file. To do so, create a file called binding.gyp in the
top-level of the project describing the build configuration of the module
using a JSON-like format. This file is used by node-gyp, a tool written
specifically to compile Node.js addons.
{
  "targets": [
    {
      "target_name": "addon",
      "sources": [ "hello.cc" ]
    }
  ]
} copy
A version of the node-gyp utility is bundled and distributed with
Node.js as part of npm. This version is not made directly available for
developers to use and is intended only to support the ability to use the
npm install command to compile and install addons. Developers who wish to
use node-gyp directly can install it using the command
npm install -g node-gyp. See the node-gyp installation instructions for
more information, including platform-specific requirements.
Once the binding.gyp file has been created, use node-gyp configure to
generate the appropriate project build files for the current platform. This
will generate either a Makefile (on Unix platforms) or a vcxproj file
(on Windows) in the build/ directory.
Next, invoke the node-gyp build command to generate the compiled addon.node
file. This will be put into the build/Release/ directory.
When using npm install to install a Node.js addon, npm uses its own bundled
version of node-gyp to perform this same set of actions, generating a
compiled version of the addon for the user's platform on demand.
Once built, the binary addon can be used from within Node.js by pointing
require() to the built addon.node module:
// hello.js
const addon = require('./build/Release/addon');

console.log(addon.hello());
// Prints: 'world' copy
Because the exact path to the compiled addon binary can vary depending on how
it is compiled (i.e. sometimes it may be in ./build/Debug/), addons can use
the bindings package to load the compiled module.
While the bindings package implementation is more sophisticated in how it
locates addon modules, it is essentially using a try…catch pattern similar to:
try {
  return require('./build/Release/addon.node');
} catch (err) {
  return require('./build/Debug/addon.node');
} copy

Linking to libraries included with Node.js#
Node.js uses statically linked libraries such as V8, libuv, and OpenSSL. All
addons are required to link to V8 and may link to any of the other dependencies
as well. Typically, this is as simple as including the appropriate
#include <...> statements (e.g. #include <v8.h>) and node-gyp will locate
the appropriate headers automatically. However, there are a few caveats to be
aware of:


When node-gyp runs, it will detect the specific release version of Node.js
and download either the full source tarball or just the headers. If the full
source is downloaded, addons will have complete access to the full set of
Node.js dependencies. However, if only the Node.js headers are downloaded,
then only the symbols exported by Node.js will be available.


node-gyp can be run using the --nodedir flag pointing at a local Node.js
source image. Using this option, the addon will have access to the full set of
dependencies.



Loading addons using require()#
The filename extension of the compiled addon binary is .node (as opposed
to .dll or .so). The require() function is written to look for
files with the .node file extension and initialize those as dynamically-linked
libraries.
When calling require(), the .node extension can usually be
omitted and Node.js will still find and initialize the addon. One caveat,
however, is that Node.js will first attempt to locate and load modules or
JavaScript files that happen to share the same base name. For instance, if
there is a file addon.js in the same directory as the binary addon.node,
then require('addon') will give precedence to the addon.js file
and load it instead.

Native abstractions for Node.js#
Each of the examples illustrated in this document directly use the
Node.js and V8 APIs for implementing addons. The V8 API can, and has, changed
dramatically from one V8 release to the next (and one major Node.js release to
the next). With each change, addons may need to be updated and recompiled in
order to continue functioning. The Node.js release schedule is designed to
minimize the frequency and impact of such changes but there is little that
Node.js can do to ensure stability of the V8 APIs.
The Native Abstractions for Node.js (or nan) provide a set of tools that
addon developers are recommended to use to keep compatibility between past and
future releases of V8 and Node.js. See the nan examples for an
illustration of how it can be used.
Node-API#
Stability: 2 - Stable
Node-API is an API for building native addons. It is independent from
the underlying JavaScript runtime (e.g. V8) and is maintained as part of
Node.js itself. This API will be Application Binary Interface (ABI) stable
across versions of Node.js. It is intended to insulate addons from
changes in the underlying JavaScript engine and allow modules
compiled for one version to run on later versions of Node.js without
recompilation. Addons are built/packaged with the same approach/tools
outlined in this document (node-gyp, etc.). The only difference is the
set of APIs that are used by the native code. Instead of using the V8
or Native Abstractions for Node.js APIs, the functions available
in the Node-API are used.
Creating and maintaining an addon that benefits from the ABI stability
provided by Node-API carries with it certain
implementation considerations.
To use Node-API in the above "Hello world" example, replace the content of
hello.cc with the following. All other instructions remain the same.
// hello.cc using Node-API
#include <node_api.h>

namespace demo {

napi_value Method(napi_env env, napi_callback_info args) {
  napi_value greeting;
  napi_status status;

  status = napi_create_string_utf8(env, "world", NAPI_AUTO_LENGTH, &greeting);
  if (status != napi_ok) return nullptr;
  return greeting;
}

napi_value init(napi_env env, napi_value exports) {
  napi_status status;
  napi_value fn;

  status = napi_create_function(env, nullptr, 0, Method, nullptr, &fn);
  if (status != napi_ok) return nullptr;

  status = napi_set_named_property(env, exports, "hello", fn);
  if (status != napi_ok) return nullptr;
  return exports;
}

NAPI_MODULE(NODE_GYP_MODULE_NAME, init)

}  // namespace demo copy
The functions available and how to use them are documented in
C/C++ addons with Node-API.
Addon examples#
Following are some example addons intended to help developers get started. The
examples use the V8 APIs. Refer to the online V8 reference
for help with the various V8 calls, and V8's Embedder's Guide for an
explanation of several concepts used such as handles, scopes, function
templates, etc.
Each of these examples using the following binding.gyp file:
{
  "targets": [
    {
      "target_name": "addon",
      "sources": [ "addon.cc" ]
    }
  ]
} copy
In cases where there is more than one .cc file, simply add the additional
filename to the sources array:
"sources": ["addon.cc", "myexample.cc"] copy
Once the binding.gyp file is ready, the example addons can be configured and
built using node-gyp:
node-gyp configure build copy

Function arguments#
Addons will typically expose objects and functions that can be accessed from
JavaScript running within Node.js. When functions are invoked from JavaScript,
the input arguments and return value must be mapped to and from the C/C++
code.
The following example illustrates how to read function arguments passed from
JavaScript and how to return a result:
// addon.cc
#include <node.h>

namespace demo {

using v8::Exception;
using v8::FunctionCallbackInfo;
using v8::Isolate;
using v8::Local;
using v8::Number;
using v8::Object;
using v8::String;
using v8::Value;

// This is the implementation of the "add" method
// Input arguments are passed using the
// const FunctionCallbackInfo<Value>& args struct
void Add(const FunctionCallbackInfo<Value>& args) {
  Isolate* isolate = args.GetIsolate();

  // Check the number of arguments passed.
  if (args.Length() < 2) {
    // Throw an Error that is passed back to JavaScript
    isolate->ThrowException(Exception::TypeError(
        String::NewFromUtf8(isolate,
                            "Wrong number of arguments").ToLocalChecked()));
    return;
  }

  // Check the argument types
  if (!args[0]->IsNumber() || !args[1]->IsNumber()) {
    isolate->ThrowException(Exception::TypeError(
        String::NewFromUtf8(isolate,
                            "Wrong arguments").ToLocalChecked()));
    return;
  }

  // Perform the operation
  double value =
      args[0].As<Number>()->Value() + args[1].As<Number>()->Value();
  Local<Number> num = Number::New(isolate, value);

  // Set the return value (using the passed in
  // FunctionCallbackInfo<Value>&)
  args.GetReturnValue().Set(num);
}

void Init(Local<Object> exports) {
  NODE_SET_METHOD(exports, "add", Add);
}

NODE_MODULE(NODE_GYP_MODULE_NAME, Init)

}  // namespace demo copy
Once compiled, the example addon can be required and used from within Node.js:
// test.js
const addon = require('./build/Release/addon');

console.log('This should be eight:', addon.add(3, 5)); copy

Callbacks#
It is common practice within addons to pass JavaScript functions to a C++
function and execute them from there. The following example illustrates how
to invoke such callbacks:
// addon.cc
#include <node.h>

namespace demo {

using v8::Context;
using v8::Function;
using v8::FunctionCallbackInfo;
using v8::Isolate;
using v8::Local;
using v8::Null;
using v8::Object;
using v8::String;
using v8::Value;

void RunCallback(const FunctionCallbackInfo<Value>& args) {
  Isolate* isolate = args.GetIsolate();
  Local<Context> context = isolate->GetCurrentContext();
  Local<Function> cb = Local<Function>::Cast(args[0]);
  const unsigned argc = 1;
  Local<Value> argv[argc] = {
      String::NewFromUtf8(isolate,
                          "hello world").ToLocalChecked() };
  cb->Call(context, Null(isolate), argc, argv).ToLocalChecked();
}

void Init(Local<Object> exports, Local<Object> module) {
  NODE_SET_METHOD(module, "exports", RunCallback);
}

NODE_MODULE(NODE_GYP_MODULE_NAME, Init)

}  // namespace demo copy
This example uses a two-argument form of Init() that receives the full
module object as the second argument. This allows the addon to completely
overwrite exports with a single function instead of adding the function as a
property of exports.
To test it, run the following JavaScript:
// test.js
const addon = require('./build/Release/addon');

addon((msg) => {
  console.log(msg);
// Prints: 'hello world'
}); copy
In this example, the callback function is invoked synchronously.

Object factory#
Addons can create and return new objects from within a C++ function as
illustrated in the following example. An object is created and returned with a
property msg that echoes the string passed to createObject():
// addon.cc
#include <node.h>

namespace demo {

using v8::Context;
using v8::FunctionCallbackInfo;
using v8::Isolate;
using v8::Local;
using v8::Object;
using v8::String;
using v8::Value;

void CreateObject(const FunctionCallbackInfo<Value>& args) {
  Isolate* isolate = args.GetIsolate();
  Local<Context> context = isolate->GetCurrentContext();

  Local<Object> obj = Object::New(isolate);
  obj->Set(context,
           String::NewFromUtf8(isolate,
                               "msg").ToLocalChecked(),
                               args[0]->ToString(context).ToLocalChecked())
           .FromJust();

  args.GetReturnValue().Set(obj);
}

void Init(Local<Object> exports, Local<Object> module) {
  NODE_SET_METHOD(module, "exports", CreateObject);
}

NODE_MODULE(NODE_GYP_MODULE_NAME, Init)

}  // namespace demo copy
To test it in JavaScript:
// test.js
const addon = require('./build/Release/addon');

const obj1 = addon('hello');
const obj2 = addon('world');
console.log(obj1.msg, obj2.msg);
// Prints: 'hello world' copy

Function factory#
Another common scenario is creating JavaScript functions that wrap C++
functions and returning those back to JavaScript:
// addon.cc
#include <node.h>

namespace demo {

using v8::Context;
using v8::Function;
using v8::FunctionCallbackInfo;
using v8::FunctionTemplate;
using v8::Isolate;
using v8::Local;
using v8::Object;
using v8::String;
using v8::Value;

void MyFunction(const FunctionCallbackInfo<Value>& args) {
  Isolate* isolate = args.GetIsolate();
  args.GetReturnValue().Set(String::NewFromUtf8(
      isolate, "hello world").ToLocalChecked());
}

void CreateFunction(const FunctionCallbackInfo<Value>& args) {
  Isolate* isolate = args.GetIsolate();

  Local<Context> context = isolate->GetCurrentContext();
  Local<FunctionTemplate> tpl = FunctionTemplate::New(isolate, MyFunction);
  Local<Function> fn = tpl->GetFunction(context).ToLocalChecked();

  // omit this to make it anonymous
  fn->SetName(String::NewFromUtf8(
      isolate, "theFunction").ToLocalChecked());

  args.GetReturnValue().Set(fn);
}

void Init(Local<Object> exports, Local<Object> module) {
  NODE_SET_METHOD(module, "exports", CreateFunction);
}

NODE_MODULE(NODE_GYP_MODULE_NAME, Init)

}  // namespace demo copy
To test:
// test.js
const addon = require('./build/Release/addon');

const fn = addon();
console.log(fn());
// Prints: 'hello world' copy

Wrapping C++ objects#
It is also possible to wrap C++ objects/classes in a way that allows new
instances to be created using the JavaScript new operator:
// addon.cc
#include <node.h>
#include "myobject.h"

namespace demo {

using v8::Local;
using v8::Object;

void InitAll(Local<Object> exports) {
  MyObject::Init(exports);
}

NODE_MODULE(NODE_GYP_MODULE_NAME, InitAll)

}  // namespace demo copy
Then, in myobject.h, the wrapper class inherits from node::ObjectWrap:
// myobject.h
#ifndef MYOBJECT_H
#define MYOBJECT_H

#include <node.h>
#include <node_object_wrap.h>

namespace demo {

class MyObject : public node::ObjectWrap {
 public:
  static void Init(v8::Local<v8::Object> exports);

 private:
  explicit MyObject(double value = 0);
  ~MyObject();

  static void New(const v8::FunctionCallbackInfo<v8::Value>& args);
  static void PlusOne(const v8::FunctionCallbackInfo<v8::Value>& args);

  double value_;
};

}  // namespace demo

#endif copy
In myobject.cc, implement the various methods that are to be exposed.
In the following code, the method plusOne() is exposed by adding it to the
constructor's prototype:
// myobject.cc
#include "myobject.h"

namespace demo {

using v8::Context;
using v8::Function;
using v8::FunctionCallbackInfo;
using v8::FunctionTemplate;
using v8::Isolate;
using v8::Local;
using v8::Number;
using v8::Object;
using v8::ObjectTemplate;
using v8::String;
using v8::Value;

MyObject::MyObject(double value) : value_(value) {
}

MyObject::~MyObject() {
}

void MyObject::Init(Local<Object> exports) {
  Isolate* isolate = exports->GetIsolate();
  Local<Context> context = isolate->GetCurrentContext();

  Local<ObjectTemplate> addon_data_tpl = ObjectTemplate::New(isolate);
  addon_data_tpl->SetInternalFieldCount(1);  // 1 field for the MyObject::New()
  Local<Object> addon_data =
      addon_data_tpl->NewInstance(context).ToLocalChecked();

  // Prepare constructor template
  Local<FunctionTemplate> tpl = FunctionTemplate::New(isolate, New, addon_data);
  tpl->SetClassName(String::NewFromUtf8(isolate, "MyObject").ToLocalChecked());
  tpl->InstanceTemplate()->SetInternalFieldCount(1);

  // Prototype
  NODE_SET_PROTOTYPE_METHOD(tpl, "plusOne", PlusOne);

  Local<Function> constructor = tpl->GetFunction(context).ToLocalChecked();
  addon_data->SetInternalField(0, constructor);
  exports->Set(context, String::NewFromUtf8(
      isolate, "MyObject").ToLocalChecked(),
      constructor).FromJust();
}

void MyObject::New(const FunctionCallbackInfo<Value>& args) {
  Isolate* isolate = args.GetIsolate();
  Local<Context> context = isolate->GetCurrentContext();

  if (args.IsConstructCall()) {
    // Invoked as constructor: `new MyObject(...)`
    double value = args[0]->IsUndefined() ?
        0 : args[0]->NumberValue(context).FromMaybe(0);
    MyObject* obj = new MyObject(value);
    obj->Wrap(args.This());
    args.GetReturnValue().Set(args.This());
  } else {
    // Invoked as plain function `MyObject(...)`, turn into construct call.
    const int argc = 1;
    Local<Value> argv[argc] = { args[0] };
    Local<Function> cons =
        args.Data().As<Object>()->GetInternalField(0)
            .As<Value>().As<Function>();
    Local<Object> result =
        cons->NewInstance(context, argc, argv).ToLocalChecked();
    args.GetReturnValue().Set(result);
  }
}

void MyObject::PlusOne(const FunctionCallbackInfo<Value>& args) {
  Isolate* isolate = args.GetIsolate();

  MyObject* obj = ObjectWrap::Unwrap<MyObject>(args.This());
  obj->value_ += 1;

  args.GetReturnValue().Set(Number::New(isolate, obj->value_));
}

}  // namespace demo copy
To build this example, the myobject.cc file must be added to the
binding.gyp:
{
  "targets": [
    {
      "target_name": "addon",
      "sources": [
        "addon.cc",
        "myobject.cc"
      ]
    }
  ]
} copy
Test it with:
// test.js
const addon = require('./build/Release/addon');

const obj = new addon.MyObject(10);
console.log(obj.plusOne());
// Prints: 11
console.log(obj.plusOne());
// Prints: 12
console.log(obj.plusOne());
// Prints: 13 copy
The destructor for a wrapper object will run when the object is
garbage-collected. For destructor testing, there are command-line flags that
can be used to make it possible to force garbage collection. These flags are
provided by the underlying V8 JavaScript engine. They are subject to change
or removal at any time. They are not documented by Node.js or V8, and they
should never be used outside of testing.
During shutdown of the process or worker threads destructors are not called
by the JS engine. Therefore it's the responsibility of the user to track
these objects and ensure proper destruction to avoid resource leaks.

Factory of wrapped objects#
Alternatively, it is possible to use a factory pattern to avoid explicitly
creating object instances using the JavaScript new operator:
const obj = addon.createObject();
// instead of:
// const obj = new addon.Object(); copy
First, the createObject() method is implemented in addon.cc:
// addon.cc
#include <node.h>
#include "myobject.h"

namespace demo {

using v8::FunctionCallbackInfo;
using v8::Isolate;
using v8::Local;
using v8::Object;
using v8::String;
using v8::Value;

void CreateObject(const FunctionCallbackInfo<Value>& args) {
  MyObject::NewInstance(args);
}

void InitAll(Local<Object> exports, Local<Object> module) {
  MyObject::Init(exports->GetIsolate());

  NODE_SET_METHOD(module, "exports", CreateObject);
}

NODE_MODULE(NODE_GYP_MODULE_NAME, InitAll)

}  // namespace demo copy
In myobject.h, the static method NewInstance() is added to handle
instantiating the object. This method takes the place of using new in
JavaScript:
// myobject.h
#ifndef MYOBJECT_H
#define MYOBJECT_H

#include <node.h>
#include <node_object_wrap.h>

namespace demo {

class MyObject : public node::ObjectWrap {
 public:
  static void Init(v8::Isolate* isolate);
  static void NewInstance(const v8::FunctionCallbackInfo<v8::Value>& args);

 private:
  explicit MyObject(double value = 0);
  ~MyObject();

  static void New(const v8::FunctionCallbackInfo<v8::Value>& args);
  static void PlusOne(const v8::FunctionCallbackInfo<v8::Value>& args);
  static v8::Global<v8::Function> constructor;
  double value_;
};

}  // namespace demo

#endif copy
The implementation in myobject.cc is similar to the previous example:
// myobject.cc
#include <node.h>
#include "myobject.h"

namespace demo {

using node::AddEnvironmentCleanupHook;
using v8::Context;
using v8::Function;
using v8::FunctionCallbackInfo;
using v8::FunctionTemplate;
using v8::Global;
using v8::Isolate;
using v8::Local;
using v8::Number;
using v8::Object;
using v8::String;
using v8::Value;

// Warning! This is not thread-safe, this addon cannot be used for worker
// threads.
Global<Function> MyObject::constructor;

MyObject::MyObject(double value) : value_(value) {
}

MyObject::~MyObject() {
}

void MyObject::Init(Isolate* isolate) {
  // Prepare constructor template
  Local<FunctionTemplate> tpl = FunctionTemplate::New(isolate, New);
  tpl->SetClassName(String::NewFromUtf8(isolate, "MyObject").ToLocalChecked());
  tpl->InstanceTemplate()->SetInternalFieldCount(1);

  // Prototype
  NODE_SET_PROTOTYPE_METHOD(tpl, "plusOne", PlusOne);

  Local<Context> context = isolate->GetCurrentContext();
  constructor.Reset(isolate, tpl->GetFunction(context).ToLocalChecked());

  AddEnvironmentCleanupHook(isolate, [](void*) {
    constructor.Reset();
  }, nullptr);
}

void MyObject::New(const FunctionCallbackInfo<Value>& args) {
  Isolate* isolate = args.GetIsolate();
  Local<Context> context = isolate->GetCurrentContext();

  if (args.IsConstructCall()) {
    // Invoked as constructor: `new MyObject(...)`
    double value = args[0]->IsUndefined() ?
        0 : args[0]->NumberValue(context).FromMaybe(0);
    MyObject* obj = new MyObject(value);
    obj->Wrap(args.This());
    args.GetReturnValue().Set(args.This());
  } else {
    // Invoked as plain function `MyObject(...)`, turn into construct call.
    const int argc = 1;
    Local<Value> argv[argc] = { args[0] };
    Local<Function> cons = Local<Function>::New(isolate, constructor);
    Local<Object> instance =
        cons->NewInstance(context, argc, argv).ToLocalChecked();
    args.GetReturnValue().Set(instance);
  }
}

void MyObject::NewInstance(const FunctionCallbackInfo<Value>& args) {
  Isolate* isolate = args.GetIsolate();

  const unsigned argc = 1;
  Local<Value> argv[argc] = { args[0] };
  Local<Function> cons = Local<Function>::New(isolate, constructor);
  Local<Context> context = isolate->GetCurrentContext();
  Local<Object> instance =
      cons->NewInstance(context, argc, argv).ToLocalChecked();

  args.GetReturnValue().Set(instance);
}

void MyObject::PlusOne(const FunctionCallbackInfo<Value>& args) {
  Isolate* isolate = args.GetIsolate();

  MyObject* obj = ObjectWrap::Unwrap<MyObject>(args.This());
  obj->value_ += 1;

  args.GetReturnValue().Set(Number::New(isolate, obj->value_));
}

}  // namespace demo copy
Once again, to build this example, the myobject.cc file must be added to the
binding.gyp:
{
  "targets": [
    {
      "target_name": "addon",
      "sources": [
        "addon.cc",
        "myobject.cc"
      ]
    }
  ]
} copy
Test it with:
// test.js
const createObject = require('./build/Release/addon');

const obj = createObject(10);
console.log(obj.plusOne());
// Prints: 11
console.log(obj.plusOne());
// Prints: 12
console.log(obj.plusOne());
// Prints: 13

const obj2 = createObject(20);
console.log(obj2.plusOne());
// Prints: 21
console.log(obj2.plusOne());
// Prints: 22
console.log(obj2.plusOne());
// Prints: 23 copy

Passing wrapped objects around#
In addition to wrapping and returning C++ objects, it is possible to pass
wrapped objects around by unwrapping them with the Node.js helper function
node::ObjectWrap::Unwrap. The following examples shows a function add()
that can take two MyObject objects as input arguments:
// addon.cc
#include <node.h>
#include <node_object_wrap.h>
#include "myobject.h"

namespace demo {

using v8::Context;
using v8::FunctionCallbackInfo;
using v8::Isolate;
using v8::Local;
using v8::Number;
using v8::Object;
using v8::String;
using v8::Value;

void CreateObject(const FunctionCallbackInfo<Value>& args) {
  MyObject::NewInstance(args);
}

void Add(const FunctionCallbackInfo<Value>& args) {
  Isolate* isolate = args.GetIsolate();
  Local<Context> context = isolate->GetCurrentContext();

  MyObject* obj1 = node::ObjectWrap::Unwrap<MyObject>(
      args[0]->ToObject(context).ToLocalChecked());
  MyObject* obj2 = node::ObjectWrap::Unwrap<MyObject>(
      args[1]->ToObject(context).ToLocalChecked());

  double sum = obj1->value() + obj2->value();
  args.GetReturnValue().Set(Number::New(isolate, sum));
}

void InitAll(Local<Object> exports) {
  MyObject::Init(exports->GetIsolate());

  NODE_SET_METHOD(exports, "createObject", CreateObject);
  NODE_SET_METHOD(exports, "add", Add);
}

NODE_MODULE(NODE_GYP_MODULE_NAME, InitAll)

}  // namespace demo copy
In myobject.h, a new public method is added to allow access to private values
after unwrapping the object.
// myobject.h
#ifndef MYOBJECT_H
#define MYOBJECT_H

#include <node.h>
#include <node_object_wrap.h>

namespace demo {

class MyObject : public node::ObjectWrap {
 public:
  static void Init(v8::Isolate* isolate);
  static void NewInstance(const v8::FunctionCallbackInfo<v8::Value>& args);
  inline double value() const { return value_; }

 private:
  explicit MyObject(double value = 0);
  ~MyObject();

  static void New(const v8::FunctionCallbackInfo<v8::Value>& args);
  static v8::Global<v8::Function> constructor;
  double value_;
};

}  // namespace demo

#endif copy
The implementation of myobject.cc remains similar to the previous version:
// myobject.cc
#include <node.h>
#include "myobject.h"

namespace demo {

using node::AddEnvironmentCleanupHook;
using v8::Context;
using v8::Function;
using v8::FunctionCallbackInfo;
using v8::FunctionTemplate;
using v8::Global;
using v8::Isolate;
using v8::Local;
using v8::Object;
using v8::String;
using v8::Value;

// Warning! This is not thread-safe, this addon cannot be used for worker
// threads.
Global<Function> MyObject::constructor;

MyObject::MyObject(double value) : value_(value) {
}

MyObject::~MyObject() {
}

void MyObject::Init(Isolate* isolate) {
  // Prepare constructor template
  Local<FunctionTemplate> tpl = FunctionTemplate::New(isolate, New);
  tpl->SetClassName(String::NewFromUtf8(isolate, "MyObject").ToLocalChecked());
  tpl->InstanceTemplate()->SetInternalFieldCount(1);

  Local<Context> context = isolate->GetCurrentContext();
  constructor.Reset(isolate, tpl->GetFunction(context).ToLocalChecked());

  AddEnvironmentCleanupHook(isolate, [](void*) {
    constructor.Reset();
  }, nullptr);
}

void MyObject::New(const FunctionCallbackInfo<Value>& args) {
  Isolate* isolate = args.GetIsolate();
  Local<Context> context = isolate->GetCurrentContext();

  if (args.IsConstructCall()) {
    // Invoked as constructor: `new MyObject(...)`
    double value = args[0]->IsUndefined() ?
        0 : args[0]->NumberValue(context).FromMaybe(0);
    MyObject* obj = new MyObject(value);
    obj->Wrap(args.This());
    args.GetReturnValue().Set(args.This());
  } else {
    // Invoked as plain function `MyObject(...)`, turn into construct call.
    const int argc = 1;
    Local<Value> argv[argc] = { args[0] };
    Local<Function> cons = Local<Function>::New(isolate, constructor);
    Local<Object> instance =
        cons->NewInstance(context, argc, argv).ToLocalChecked();
    args.GetReturnValue().Set(instance);
  }
}

void MyObject::NewInstance(const FunctionCallbackInfo<Value>& args) {
  Isolate* isolate = args.GetIsolate();

  const unsigned argc = 1;
  Local<Value> argv[argc] = { args[0] };
  Local<Function> cons = Local<Function>::New(isolate, constructor);
  Local<Context> context = isolate->GetCurrentContext();
  Local<Object> instance =
      cons->NewInstance(context, argc, argv).ToLocalChecked();

  args.GetReturnValue().Set(instance);
}

}  // namespace demo copy
Test it with:
// test.js
const addon = require('./build/Release/addon');

const obj1 = addon.createObject(10);
const obj2 = addon.createObject(20);
const result = addon.add(obj1, obj2);

console.log(result);
// Prints: 30 copy\n\n\n\nNode.js
        
      
      
About this documentation
Usage and example



Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Modules: TypeScript
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
Readline
REPL
Report
Single executable applications
SQLite
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker

    

    
      
        
          Node.js v24.0.1 documentation
          
            
            
          
        
        
          
            Node.js v24.0.1
            
    
      
        
        Table of contents
      

      
Node-API

Implications of ABI stability
Building

Build tools

node-gyp
CMake.js


Uploading precompiled binaries

node-pre-gyp
prebuild
prebuildify




Usage
Node-API version matrix
Environment life cycle APIs

napi_set_instance_data
napi_get_instance_data


Basic Node-API data types

napi_status
napi_extended_error_info
napi_env
node_api_basic_env
napi_value
napi_threadsafe_function
napi_threadsafe_function_release_mode
napi_threadsafe_function_call_mode
Node-API memory management types

napi_handle_scope
napi_escapable_handle_scope
napi_ref
napi_type_tag
napi_async_cleanup_hook_handle


Node-API callback types

napi_callback_info
napi_callback
node_api_basic_finalize
napi_finalize
napi_async_execute_callback
napi_async_complete_callback
napi_threadsafe_function_call_js
napi_cleanup_hook
napi_async_cleanup_hook




Error handling

Return values

napi_get_last_error_info


Exceptions

napi_throw
napi_throw_error
napi_throw_type_error
napi_throw_range_error
node_api_throw_syntax_error
napi_is_error
napi_create_error
napi_create_type_error
napi_create_range_error
node_api_create_syntax_error
napi_get_and_clear_last_exception
napi_is_exception_pending
napi_fatal_exception


Fatal errors

napi_fatal_error




Object lifetime management

Making handle lifespan shorter than that of the native method

napi_open_handle_scope
napi_close_handle_scope
napi_open_escapable_handle_scope
napi_close_escapable_handle_scope
napi_escape_handle


References to values with a lifespan longer than that of the native method

napi_create_reference
napi_delete_reference
napi_reference_ref
napi_reference_unref
napi_get_reference_value


Cleanup on exit of the current Node.js environment

napi_add_env_cleanup_hook
napi_remove_env_cleanup_hook
napi_add_async_cleanup_hook
napi_remove_async_cleanup_hook


Finalization on the exit of the Node.js environment


Module registration
Working with JavaScript values

Enum types

napi_key_collection_mode
napi_key_filter
napi_key_conversion
napi_valuetype
napi_typedarray_type


Object creation functions

napi_create_array
napi_create_array_with_length
napi_create_arraybuffer
napi_create_buffer
napi_create_buffer_copy
napi_create_date
napi_create_external
napi_create_external_arraybuffer
napi_create_external_buffer
napi_create_object
napi_create_symbol
node_api_symbol_for
napi_create_typedarray
node_api_create_buffer_from_arraybuffer
napi_create_dataview


Functions to convert from C types to Node-API

napi_create_int32
napi_create_uint32
napi_create_int64
napi_create_double
napi_create_bigint_int64
napi_create_bigint_uint64
napi_create_bigint_words
napi_create_string_latin1
node_api_create_external_string_latin1
napi_create_string_utf16
node_api_create_external_string_utf16
napi_create_string_utf8


Functions to create optimized property keys

node_api_create_property_key_latin1
node_api_create_property_key_utf16
node_api_create_property_key_utf8


Functions to convert from Node-API to C types

napi_get_array_length
napi_get_arraybuffer_info
napi_get_buffer_info
napi_get_prototype
napi_get_typedarray_info
napi_get_dataview_info
napi_get_date_value
napi_get_value_bool
napi_get_value_double
napi_get_value_bigint_int64
napi_get_value_bigint_uint64
napi_get_value_bigint_words
napi_get_value_external
napi_get_value_int32
napi_get_value_int64
napi_get_value_string_latin1
napi_get_value_string_utf8
napi_get_value_string_utf16
napi_get_value_uint32


Functions to get global instances

napi_get_boolean
napi_get_global
napi_get_null
napi_get_undefined




Working with JavaScript values and abstract operations

napi_coerce_to_bool
napi_coerce_to_number
napi_coerce_to_object
napi_coerce_to_string
napi_typeof
napi_instanceof
napi_is_array
napi_is_arraybuffer
napi_is_buffer
napi_is_date
napi_is_error
napi_is_typedarray
napi_is_dataview
napi_strict_equals
napi_detach_arraybuffer
napi_is_detached_arraybuffer


Working with JavaScript properties

Structures

napi_property_attributes
napi_property_descriptor


Functions

napi_get_property_names
napi_get_all_property_names
napi_set_property
napi_get_property
napi_has_property
napi_delete_property
napi_has_own_property
napi_set_named_property
napi_get_named_property
napi_has_named_property
napi_set_element
napi_get_element
napi_has_element
napi_delete_element
napi_define_properties
napi_object_freeze
napi_object_seal




Working with JavaScript functions

napi_call_function
napi_create_function
napi_get_cb_info
napi_get_new_target
napi_new_instance


Object wrap

napi_define_class
napi_wrap
napi_unwrap
napi_remove_wrap
napi_type_tag_object
napi_check_object_type_tag
napi_add_finalizer

node_api_post_finalizer




Simple asynchronous operations

napi_create_async_work
napi_delete_async_work
napi_queue_async_work
napi_cancel_async_work


Custom asynchronous operations

napi_async_init
napi_async_destroy
napi_make_callback
napi_open_callback_scope
napi_close_callback_scope


Version management

napi_get_node_version
napi_get_version


Memory management

napi_adjust_external_memory


Promises

napi_create_promise
napi_resolve_deferred
napi_reject_deferred
napi_is_promise


Script execution

napi_run_script


libuv event loop

napi_get_uv_event_loop


Asynchronous thread-safe function calls

Calling a thread-safe function
Reference counting of thread-safe functions
Deciding whether to keep the process running
napi_create_threadsafe_function
napi_get_threadsafe_function_context
napi_call_threadsafe_function
napi_acquire_threadsafe_function
napi_release_threadsafe_function
napi_ref_threadsafe_function
napi_unref_threadsafe_function


Miscellaneous utilities

node_api_get_module_file_name





    
  
            
    
      
        
        Index
      

      
About this documentation
Usage and example

      
        Index
      
    
  


Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Modules: TypeScript
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
Readline
REPL
Report
Single executable applications
SQLite
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker

    
  
            
    
      
        
        Other versions
      
      24.x
23.x
22.x LTS
21.x
20.x LTS
19.x
18.x
17.x
16.x
15.x
14.x
13.x
12.x
11.x
10.x
9.x
8.x
    
  
            
              
                
                Options
              
        
              
                
                  
                    View on single page
                  
                  
                    View as JSON
                  
                  Edit on GitHub    
                
              
            
          
        
        
      

      Table of contents
Node-API

Implications of ABI stability
Building

Build tools

node-gyp
CMake.js


Uploading precompiled binaries

node-pre-gyp
prebuild
prebuildify




Usage
Node-API version matrix
Environment life cycle APIs

napi_set_instance_data
napi_get_instance_data


Basic Node-API data types

napi_status
napi_extended_error_info
napi_env
node_api_basic_env
napi_value
napi_threadsafe_function
napi_threadsafe_function_release_mode
napi_threadsafe_function_call_mode
Node-API memory management types

napi_handle_scope
napi_escapable_handle_scope
napi_ref
napi_type_tag
napi_async_cleanup_hook_handle


Node-API callback types

napi_callback_info
napi_callback
node_api_basic_finalize
napi_finalize
napi_async_execute_callback
napi_async_complete_callback
napi_threadsafe_function_call_js
napi_cleanup_hook
napi_async_cleanup_hook




Error handling

Return values

napi_get_last_error_info


Exceptions

napi_throw
napi_throw_error
napi_throw_type_error
napi_throw_range_error
node_api_throw_syntax_error
napi_is_error
napi_create_error
napi_create_type_error
napi_create_range_error
node_api_create_syntax_error
napi_get_and_clear_last_exception
napi_is_exception_pending
napi_fatal_exception


Fatal errors

napi_fatal_error




Object lifetime management

Making handle lifespan shorter than that of the native method

napi_open_handle_scope
napi_close_handle_scope
napi_open_escapable_handle_scope
napi_close_escapable_handle_scope
napi_escape_handle


References to values with a lifespan longer than that of the native method

napi_create_reference
napi_delete_reference
napi_reference_ref
napi_reference_unref
napi_get_reference_value


Cleanup on exit of the current Node.js environment

napi_add_env_cleanup_hook
napi_remove_env_cleanup_hook
napi_add_async_cleanup_hook
napi_remove_async_cleanup_hook


Finalization on the exit of the Node.js environment


Module registration
Working with JavaScript values

Enum types

napi_key_collection_mode
napi_key_filter
napi_key_conversion
napi_valuetype
napi_typedarray_type


Object creation functions

napi_create_array
napi_create_array_with_length
napi_create_arraybuffer
napi_create_buffer
napi_create_buffer_copy
napi_create_date
napi_create_external
napi_create_external_arraybuffer
napi_create_external_buffer
napi_create_object
napi_create_symbol
node_api_symbol_for
napi_create_typedarray
node_api_create_buffer_from_arraybuffer
napi_create_dataview


Functions to convert from C types to Node-API

napi_create_int32
napi_create_uint32
napi_create_int64
napi_create_double
napi_create_bigint_int64
napi_create_bigint_uint64
napi_create_bigint_words
napi_create_string_latin1
node_api_create_external_string_latin1
napi_create_string_utf16
node_api_create_external_string_utf16
napi_create_string_utf8


Functions to create optimized property keys

node_api_create_property_key_latin1
node_api_create_property_key_utf16
node_api_create_property_key_utf8


Functions to convert from Node-API to C types

napi_get_array_length
napi_get_arraybuffer_info
napi_get_buffer_info
napi_get_prototype
napi_get_typedarray_info
napi_get_dataview_info
napi_get_date_value
napi_get_value_bool
napi_get_value_double
napi_get_value_bigint_int64
napi_get_value_bigint_uint64
napi_get_value_bigint_words
napi_get_value_external
napi_get_value_int32
napi_get_value_int64
napi_get_value_string_latin1
napi_get_value_string_utf8
napi_get_value_string_utf16
napi_get_value_uint32


Functions to get global instances

napi_get_boolean
napi_get_global
napi_get_null
napi_get_undefined




Working with JavaScript values and abstract operations

napi_coerce_to_bool
napi_coerce_to_number
napi_coerce_to_object
napi_coerce_to_string
napi_typeof
napi_instanceof
napi_is_array
napi_is_arraybuffer
napi_is_buffer
napi_is_date
napi_is_error
napi_is_typedarray
napi_is_dataview
napi_strict_equals
napi_detach_arraybuffer
napi_is_detached_arraybuffer


Working with JavaScript properties

Structures

napi_property_attributes
napi_property_descriptor


Functions

napi_get_property_names
napi_get_all_property_names
napi_set_property
napi_get_property
napi_has_property
napi_delete_property
napi_has_own_property
napi_set_named_property
napi_get_named_property
napi_has_named_property
napi_set_element
napi_get_element
napi_has_element
napi_delete_element
napi_define_properties
napi_object_freeze
napi_object_seal




Working with JavaScript functions

napi_call_function
napi_create_function
napi_get_cb_info
napi_get_new_target
napi_new_instance


Object wrap

napi_define_class
napi_wrap
napi_unwrap
napi_remove_wrap
napi_type_tag_object
napi_check_object_type_tag
napi_add_finalizer

node_api_post_finalizer




Simple asynchronous operations

napi_create_async_work
napi_delete_async_work
napi_queue_async_work
napi_cancel_async_work


Custom asynchronous operations

napi_async_init
napi_async_destroy
napi_make_callback
napi_open_callback_scope
napi_close_callback_scope


Version management

napi_get_node_version
napi_get_version


Memory management

napi_adjust_external_memory


Promises

napi_create_promise
napi_resolve_deferred
napi_reject_deferred
napi_is_promise


Script execution

napi_run_script


libuv event loop

napi_get_uv_event_loop


Asynchronous thread-safe function calls

Calling a thread-safe function
Reference counting of thread-safe functions
Deciding whether to keep the process running
napi_create_threadsafe_function
napi_get_threadsafe_function_context
napi_call_threadsafe_function
napi_acquire_threadsafe_function
napi_release_threadsafe_function
napi_ref_threadsafe_function
napi_unref_threadsafe_function


Miscellaneous utilities

node_api_get_module_file_name






      
        Node-API#


Stability: 2 - Stable
Node-API (formerly N-API) is an API for building native Addons. It is
independent from the underlying JavaScript runtime (for example, V8) and is
maintained as part of Node.js itself. This API will be Application Binary
Interface (ABI) stable across versions of Node.js. It is intended to insulate
addons from changes in the underlying JavaScript engine and allow modules
compiled for one major version to run on later major versions of Node.js without
recompilation. The ABI Stability guide provides a more in-depth explanation.
Addons are built/packaged with the same approach/tools outlined in the section
titled C++ Addons. The only difference is the set of APIs that are used by
the native code. Instead of using the V8 or Native Abstractions for Node.js
APIs, the functions available in Node-API are used.
APIs exposed by Node-API are generally used to create and manipulate
JavaScript values. Concepts and operations generally map to ideas specified
in the ECMA-262 Language Specification. The APIs have the following
properties:

All Node-API calls return a status code of type napi_status. This
status indicates whether the API call succeeded or failed.
The API's return value is passed via an out parameter.
All JavaScript values are abstracted behind an opaque type named
napi_value.
In case of an error status code, additional information can be obtained
using napi_get_last_error_info. More information can be found in the error
handling section Error handling.

Node-API is a C API that ensures ABI stability across Node.js versions
and different compiler levels. A C++ API can be easier to use.
To support using C++, the project maintains a
C++ wrapper module called node-addon-api.
This wrapper provides an inlinable C++ API. Binaries built
with node-addon-api will depend on the symbols for the Node-API C-based
functions exported by Node.js. node-addon-api is a more
efficient way to write code that calls Node-API. Take, for example, the
following node-addon-api code. The first section shows the
node-addon-api code and the second section shows what actually gets
used in the addon.
Object obj = Object::New(env);
obj["foo"] = String::New(env, "bar"); copy
napi_status status;
napi_value object, string;
status = napi_create_object(env, &object);
if (status != napi_ok) {
  napi_throw_error(env, ...);
  return;
}

status = napi_create_string_utf8(env, "bar", NAPI_AUTO_LENGTH, &string);
if (status != napi_ok) {
  napi_throw_error(env, ...);
  return;
}

status = napi_set_named_property(env, object, "foo", string);
if (status != napi_ok) {
  napi_throw_error(env, ...);
  return;
} copy
The end result is that the addon only uses the exported C APIs. As a result,
it still gets the benefits of the ABI stability provided by the C API.
When using node-addon-api instead of the C APIs, start with the API docs
for node-addon-api.
The Node-API Resource offers
an excellent orientation and tips for developers just getting started with
Node-API and node-addon-api. Additional media resources can be found on the
Node-API Media page.
Implications of ABI stability#
Although Node-API provides an ABI stability guarantee, other parts of Node.js do
not, and any external libraries used from the addon may not. In particular,
none of the following APIs provide an ABI stability guarantee across major
versions:


the Node.js C++ APIs available via any of
#include <node.h>
#include <node_buffer.h>
#include <node_version.h>
#include <node_object_wrap.h> copy


the libuv APIs which are also included with Node.js and available via
#include <uv.h> copy


the V8 API available via
#include <v8.h> copy


Thus, for an addon to remain ABI-compatible across Node.js major versions, it
must use Node-API exclusively by restricting itself to using
#include <node_api.h> copy
and by checking, for all external libraries that it uses, that the external
library makes ABI stability guarantees similar to Node-API.
Building#
Unlike modules written in JavaScript, developing and deploying Node.js
native addons using Node-API requires an additional set of tools. Besides the
basic tools required to develop for Node.js, the native addon developer
requires a toolchain that can compile C and C++ code into a binary. In
addition, depending upon how the native addon is deployed, the user of
the native addon will also need to have a C/C++ toolchain installed.
For Linux developers, the necessary C/C++ toolchain packages are readily
available. GCC is widely used in the Node.js community to build and
test across a variety of platforms. For many developers, the LLVM
compiler infrastructure is also a good choice.
For Mac developers, Xcode offers all the required compiler tools.
However, it is not necessary to install the entire Xcode IDE. The following
command installs the necessary toolchain:
xcode-select --install copy
For Windows developers, Visual Studio offers all the required compiler
tools. However, it is not necessary to install the entire Visual Studio
IDE. The following command installs the necessary toolchain:
npm install --global windows-build-tools copy
The sections below describe the additional tools available for developing
and deploying Node.js native addons.

Build tools#
Both the tools listed here require that users of the native
addon have a C/C++ toolchain installed in order to successfully install
the native addon.

node-gyp#
node-gyp is a build system based on the gyp-next fork of
Google's GYP tool and comes bundled with npm. GYP, and therefore node-gyp,
requires that Python be installed.
Historically, node-gyp has been the tool of choice for building native
addons. It has widespread adoption and documentation. However, some
developers have run into limitations in node-gyp.

CMake.js#
CMake.js is an alternative build system based on CMake.
CMake.js is a good choice for projects that already use CMake or for
developers affected by limitations in node-gyp. build_with_cmake is an
example of a CMake-based native addon project.

Uploading precompiled binaries#
The three tools listed here permit native addon developers and maintainers
to create and upload binaries to public or private servers. These tools are
typically integrated with CI/CD build systems like Travis CI and
AppVeyor to build and upload binaries for a variety of platforms and
architectures. These binaries are then available for download by users who
do not need to have a C/C++ toolchain installed.

node-pre-gyp#
node-pre-gyp is a tool based on node-gyp that adds the ability to
upload binaries to a server of the developer's choice. node-pre-gyp has
particularly good support for uploading binaries to Amazon S3.

prebuild#
prebuild is a tool that supports builds using either node-gyp or
CMake.js. Unlike node-pre-gyp which supports a variety of servers, prebuild
uploads binaries only to GitHub releases. prebuild is a good choice for
GitHub projects using CMake.js.

prebuildify#
prebuildify is a tool based on node-gyp. The advantage of prebuildify is
that the built binaries are bundled with the native addon when it's
uploaded to npm. The binaries are downloaded from npm and are immediately
available to the module user when the native addon is installed.

Usage#
In order to use the Node-API functions, include the file node_api.h which
is located in the src directory in the node development tree:
#include <node_api.h> copy
This will opt into the default NAPI_VERSION for the given release of Node.js.
In order to ensure compatibility with specific versions of Node-API, the version
can be specified explicitly when including the header:
#define NAPI_VERSION 3
#include <node_api.h> copy
This restricts the Node-API surface to just the functionality that was available
in the specified (and earlier) versions.
Some of the Node-API surface is experimental and requires explicit opt-in:
#define NAPI_EXPERIMENTAL
#include <node_api.h> copy
In this case the entire API surface, including any experimental APIs, will be
available to the module code.
Occasionally, experimental features are introduced that affect already-released
and stable APIs. These features can be disabled by an opt-out:
#define NAPI_EXPERIMENTAL
#define NODE_API_EXPERIMENTAL_<FEATURE_NAME>_OPT_OUT
#include <node_api.h> copy
where <FEATURE_NAME> is the name of an experimental feature that affects both
experimental and stable APIs.
Node-API version matrix#
Up until version 9, Node-API versions were additive and versioned
independently from Node.js. This meant that any version was
an extension to the previous version in that it had all of
the APIs from the previous version with some additions. Each
Node.js version only supported a single Node-API version.
For example v18.15.0 supports only Node-API version 8. ABI stability was
achieved because 8 was a strict superset of all previous versions.
As of version 9, while Node-API versions continue to be versioned
independently an add-on that ran with Node-API version 9 may need
code updates to run with Node-API version 10. ABI stability
is maintained, however, because Node.js versions that support
Node-API versions higher than 8 will support all versions
between 8 and the highest version they support and will default
to providing the version 8 APIs unless an add-on opts into a
higher Node-API version. This approach provides the flexibility
of better optimizing existing Node-API functions while
maintaining ABI stability. Existing add-ons can continue to run without
recompilation using an earlier version of Node-API. If an add-on
needs functionality from a newer Node-API version, changes to existing
code and recompilation will be needed to use those new functions anyway.
In versions of Node.js that support Node-API version 9 and later, defining
NAPI_VERSION=X and using the existing add-on initialization macros
will bake in the requested Node-API version that will be used at runtime
into the add-on. If NAPI_VERSION is not set it will default to 8.
This table may not be up to date in older streams, the most up to date
information is in the latest API documentation in:
Node-API version matrix


  
    Node-API version
    Supported In
  
  
    10
    v22.14.0+, 23.6.0+ and all later versions
  
  
    9
    v18.17.0+, 20.3.0+, 21.0.0 and all later versions
  
  
    8
    v12.22.0+, v14.17.0+, v15.12.0+, 16.0.0 and all later versions
  
  
    7
    v10.23.0+, v12.19.0+, v14.12.0+, 15.0.0 and all later versions
  
  
    6
    v10.20.0+, v12.17.0+, 14.0.0 and all later versions
  
  
    5
    v10.17.0+, v12.11.0+, 13.0.0 and all later versions
  
  
    4
    v10.16.0+, v11.8.0+, 12.0.0 and all later versions
  
  
    
    3
    v6.14.2*, 8.11.2+, v9.11.0+*, 10.0.0 and all later versions
  
  
    2
    v8.10.0+*, v9.3.0+*, 10.0.0 and all later versions
  
  
    1
    v8.6.0+**, v9.0.0+*, 10.0.0 and all later versions
  

* Node-API was experimental.
** Node.js 8.0.0 included Node-API as experimental. It was released as
Node-API version 1 but continued to evolve until Node.js 8.6.0. The API is
different in versions prior to Node.js 8.6.0. We recommend Node-API version 3 or
later.
Each API documented for Node-API will have a header named added in:, and APIs
which are stable will have the additional header Node-API version:.
APIs are directly usable when using a Node.js version which supports
the Node-API version shown in Node-API version: or higher.
When using a Node.js version that does not support the
Node-API version: listed or if there is no Node-API version: listed,
then the API will only be available if
#define NAPI_EXPERIMENTAL precedes the inclusion of node_api.h
or js_native_api.h. If an API appears not to be available on
a version of Node.js which is later than the one shown in added in: then
this is most likely the reason for the apparent absence.
The Node-APIs associated strictly with accessing ECMAScript features from native
code can be found separately in js_native_api.h and js_native_api_types.h.
The APIs defined in these headers are included in node_api.h and
node_api_types.h. The headers are structured in this way in order to allow
implementations of Node-API outside of Node.js. For those implementations the
Node.js specific APIs may not be applicable.
The Node.js-specific parts of an addon can be separated from the code that
exposes the actual functionality to the JavaScript environment so that the
latter may be used with multiple implementations of Node-API. In the example
below, addon.c and addon.h refer only to js_native_api.h. This ensures
that addon.c can be reused to compile against either the Node.js
implementation of Node-API or any implementation of Node-API outside of Node.js.
addon_node.c is a separate file that contains the Node.js specific entry point
to the addon and which instantiates the addon by calling into addon.c when the
addon is loaded into a Node.js environment.
// addon.h
#ifndef _ADDON_H_
#define _ADDON_H_
#include <js_native_api.h>
napi_value create_addon(napi_env env);
#endif  // _ADDON_H_ copy
// addon.c
#include "addon.h"

#define NODE_API_CALL(env, call)                                  \
  do {                                                            \
    napi_status status = (call);                                  \
    if (status != napi_ok) {                                      \
      const napi_extended_error_info* error_info = NULL;          \
      napi_get_last_error_info((env), &error_info);               \
      const char* err_message = error_info->error_message;        \
      bool is_pending;                                            \
      napi_is_exception_pending((env), &is_pending);              \
      /* If an exception is already pending, don't rethrow it */  \
      if (!is_pending) {                                          \
        const char* message = (err_message == NULL)               \
            ? "empty error message"                               \
            : err_message;                                        \
        napi_throw_error((env), NULL, message);                   \
      }                                                           \
      return NULL;                                                \
    }                                                             \
  } while(0)

static napi_value
DoSomethingUseful(napi_env env, napi_callback_info info) {
  // Do something useful.
  return NULL;
}

napi_value create_addon(napi_env env) {
  napi_value result;
  NODE_API_CALL(env, napi_create_object(env, &result));

  napi_value exported_function;
  NODE_API_CALL(env, napi_create_function(env,
                                          "doSomethingUseful",
                                          NAPI_AUTO_LENGTH,
                                          DoSomethingUseful,
                                          NULL,
                                          &exported_function));

  NODE_API_CALL(env, napi_set_named_property(env,
                                             result,
                                             "doSomethingUseful",
                                             exported_function));

  return result;
} copy
// addon_node.c
#include <node_api.h>
#include "addon.h"

NAPI_MODULE_INIT(/* napi_env env, napi_value exports */) {
  // This function body is expected to return a `napi_value`.
  // The variables `napi_env env` and `napi_value exports` may be used within
  // the body, as they are provided by the definition of `NAPI_MODULE_INIT()`.
  return create_addon(env);
} copy
Environment life cycle APIs#
Section 8.7 of the ECMAScript Language Specification defines the concept
of an "Agent" as a self-contained environment in which JavaScript code runs.
Multiple such Agents may be started and terminated either concurrently or in
sequence by the process.
A Node.js environment corresponds to an ECMAScript Agent. In the main process,
an environment is created at startup, and additional environments can be created
on separate threads to serve as worker threads. When Node.js is embedded in
another application, the main thread of the application may also construct and
destroy a Node.js environment multiple times during the life cycle of the
application process such that each Node.js environment created by the
application may, in turn, during its life cycle create and destroy additional
environments as worker threads.
From the perspective of a native addon this means that the bindings it provides
may be called multiple times, from multiple contexts, and even concurrently from
multiple threads.
Native addons may need to allocate global state which they use during
their life cycle of an Node.js environment such that the state can be
unique to each instance of the addon.
To this end, Node-API provides a way to associate data such that its life cycle
is tied to the life cycle of a Node.js environment.

napi_set_instance_data#

Added in: v12.8.0, v10.20.0
N-API version: 6

napi_status napi_set_instance_data(node_api_basic_env env,
                                   void* data,
                                   napi_finalize finalize_cb,
                                   void* finalize_hint); copy

[in] env: The environment that the Node-API call is invoked under.
[in] data: The data item to make available to bindings of this instance.
[in] finalize_cb: The function to call when the environment is being torn
down. The function receives data so that it might free it.
napi_finalize provides more details.
[in] finalize_hint: Optional hint to pass to the finalize callback during
collection.

Returns napi_ok if the API succeeded.
This API associates data with the currently running Node.js environment. data
can later be retrieved using napi_get_instance_data(). Any existing data
associated with the currently running Node.js environment which was set by means
of a previous call to napi_set_instance_data() will be overwritten. If a
finalize_cb was provided by the previous call, it will not be called.

napi_get_instance_data#

Added in: v12.8.0, v10.20.0
N-API version: 6

napi_status napi_get_instance_data(node_api_basic_env env,
                                   void** data); copy

[in] env: The environment that the Node-API call is invoked under.
[out] data: The data item that was previously associated with the currently
running Node.js environment by a call to napi_set_instance_data().

Returns napi_ok if the API succeeded.
This API retrieves data that was previously associated with the currently
running Node.js environment via napi_set_instance_data(). If no data is set,
the call will succeed and data will be set to NULL.

Basic Node-API data types#
Node-API exposes the following fundamental data types as abstractions that are
consumed by the various APIs. These APIs should be treated as opaque,
introspectable only with other Node-API calls.

napi_status#

Added in: v8.0.0
N-API version: 1

Integral status code indicating the success or failure of a Node-API call.
Currently, the following status codes are supported.
typedef enum {
  napi_ok,
  napi_invalid_arg,
  napi_object_expected,
  napi_string_expected,
  napi_name_expected,
  napi_function_expected,
  napi_number_expected,
  napi_boolean_expected,
  napi_array_expected,
  napi_generic_failure,
  napi_pending_exception,
  napi_cancelled,
  napi_escape_called_twice,
  napi_handle_scope_mismatch,
  napi_callback_scope_mismatch,
  napi_queue_full,
  napi_closing,
  napi_bigint_expected,
  napi_date_expected,
  napi_arraybuffer_expected,
  napi_detachable_arraybuffer_expected,
  napi_would_deadlock,  /* unused */
  napi_no_external_buffers_allowed,
  napi_cannot_run_js
} napi_status; copy
If additional information is required upon an API returning a failed status,
it can be obtained by calling napi_get_last_error_info.

napi_extended_error_info#

Added in: v8.0.0
N-API version: 1

typedef struct {
  const char* error_message;
  void* engine_reserved;
  uint32_t engine_error_code;
  napi_status error_code;
} napi_extended_error_info; copy

error_message: UTF8-encoded string containing a VM-neutral description of
the error.
engine_reserved: Reserved for VM-specific error details. This is currently
not implemented for any VM.
engine_error_code: VM-specific error code. This is currently
not implemented for any VM.
error_code: The Node-API status code that originated with the last error.

See the Error handling section for additional information.

napi_env#
napi_env is used to represent a context that the underlying Node-API
implementation can use to persist VM-specific state. This structure is passed
to native functions when they're invoked, and it must be passed back when
making Node-API calls. Specifically, the same napi_env that was passed in when
the initial native function was called must be passed to any subsequent
nested Node-API calls. Caching the napi_env for the purpose of general reuse,
and passing the napi_env between instances of the same addon running on
different Worker threads is not allowed. The napi_env becomes invalid
when an instance of a native addon is unloaded. Notification of this event is
delivered through the callbacks given to napi_add_env_cleanup_hook and
napi_set_instance_data.

node_api_basic_env#
Stability: 1 - Experimental
This variant of napi_env is passed to synchronous finalizers
(node_api_basic_finalize). There is a subset of Node-APIs which accept
a parameter of type node_api_basic_env as their first argument. These APIs do
not access the state of the JavaScript engine and are thus safe to call from
synchronous finalizers. Passing a parameter of type napi_env to these APIs is
allowed, however, passing a parameter of type node_api_basic_env to APIs that
access the JavaScript engine state is not allowed. Attempting to do so without
a cast will produce a compiler warning or an error when add-ons are compiled
with flags which cause them to emit warnings and/or errors when incorrect
pointer types are passed into a function. Calling such APIs from a synchronous
finalizer will ultimately result in the termination of the application.

napi_value#
This is an opaque pointer that is used to represent a JavaScript value.

napi_threadsafe_function#

Added in: v10.6.0
N-API version: 4

This is an opaque pointer that represents a JavaScript function which can be
called asynchronously from multiple threads via
napi_call_threadsafe_function().

napi_threadsafe_function_release_mode#

Added in: v10.6.0
N-API version: 4

A value to be given to napi_release_threadsafe_function() to indicate whether
the thread-safe function is to be closed immediately (napi_tsfn_abort) or
merely released (napi_tsfn_release) and thus available for subsequent use via
napi_acquire_threadsafe_function() and napi_call_threadsafe_function().
typedef enum {
  napi_tsfn_release,
  napi_tsfn_abort
} napi_threadsafe_function_release_mode; copy

napi_threadsafe_function_call_mode#

Added in: v10.6.0
N-API version: 4

A value to be given to napi_call_threadsafe_function() to indicate whether
the call should block whenever the queue associated with the thread-safe
function is full.
typedef enum {
  napi_tsfn_nonblocking,
  napi_tsfn_blocking
} napi_threadsafe_function_call_mode; copy

Node-API memory management types#

napi_handle_scope#
This is an abstraction used to control and modify the lifetime of objects
created within a particular scope. In general, Node-API values are created
within the context of a handle scope. When a native method is called from
JavaScript, a default handle scope will exist. If the user does not explicitly
create a new handle scope, Node-API values will be created in the default handle
scope. For any invocations of code outside the execution of a native method
(for instance, during a libuv callback invocation), the module is required to
create a scope before invoking any functions that can result in the creation
of JavaScript values.
Handle scopes are created using napi_open_handle_scope and are destroyed
using napi_close_handle_scope. Closing the scope can indicate to the GC
that all napi_values created during the lifetime of the handle scope are no
longer referenced from the current stack frame.
For more details, review the Object lifetime management.

napi_escapable_handle_scope#

Added in: v8.0.0
N-API version: 1

Escapable handle scopes are a special type of handle scope to return values
created within a particular handle scope to a parent scope.

napi_ref#

Added in: v8.0.0
N-API version: 1

This is the abstraction to use to reference a napi_value. This allows for
users to manage the lifetimes of JavaScript values, including defining their
minimum lifetimes explicitly.
For more details, review the Object lifetime management.

napi_type_tag#

Added in: v14.8.0, v12.19.0
N-API version: 8

A 128-bit value stored as two unsigned 64-bit integers. It serves as a UUID
with which JavaScript objects or externals can be "tagged" in order to
ensure that they are of a certain type. This is a stronger check than
napi_instanceof, because the latter can report a false positive if the
object's prototype has been manipulated. Type-tagging is most useful in
conjunction with napi_wrap because it ensures that the pointer retrieved
from a wrapped object can be safely cast to the native type corresponding to the
type tag that had been previously applied to the JavaScript object.
typedef struct {
  uint64_t lower;
  uint64_t upper;
} napi_type_tag; copy

napi_async_cleanup_hook_handle#

Added in: v14.10.0, v12.19.0

An opaque value returned by napi_add_async_cleanup_hook. It must be passed
to napi_remove_async_cleanup_hook when the chain of asynchronous cleanup
events completes.

Node-API callback types#

napi_callback_info#

Added in: v8.0.0
N-API version: 1

Opaque datatype that is passed to a callback function. It can be used for
getting additional information about the context in which the callback was
invoked.

napi_callback#

Added in: v8.0.0
N-API version: 1

Function pointer type for user-provided native functions which are to be
exposed to JavaScript via Node-API. Callback functions should satisfy the
following signature:
typedef napi_value (*napi_callback)(napi_env, napi_callback_info); copy
Unless for reasons discussed in Object Lifetime Management, creating a
handle and/or callback scope inside a napi_callback is not necessary.

node_api_basic_finalize#

Added in: v21.6.0, v20.12.0, v18.20.0

Stability: 1 - Experimental
Function pointer type for add-on provided functions that allow the user to be
notified when externally-owned data is ready to be cleaned up because the
object it was associated with has been garbage-collected. The user must provide
a function satisfying the following signature which would get called upon the
object's collection. Currently, node_api_basic_finalize can be used for
finding out when objects that have external data are collected.
typedef void (*node_api_basic_finalize)(node_api_basic_env env,
                                      void* finalize_data,
                                      void* finalize_hint); copy
Unless for reasons discussed in Object Lifetime Management, creating a
handle and/or callback scope inside the function body is not necessary.
Since these functions may be called while the JavaScript engine is in a state
where it cannot execute JavaScript code, only Node-APIs which accept a
node_api_basic_env as their first parameter may be called.
node_api_post_finalizer can be used to schedule Node-API calls that
require access to the JavaScript engine's state to run after the current
garbage collection cycle has completed.
In the case of node_api_create_external_string_latin1 and
node_api_create_external_string_utf16 the env parameter may be null,
because external strings can be collected during the latter part of environment
shutdown.
Change History:


experimental (NAPI_EXPERIMENTAL):
Only Node-API calls that accept a node_api_basic_env as their first
parameter may be called, otherwise the application will be terminated with an
appropriate error message. This feature can be turned off by defining
NODE_API_EXPERIMENTAL_BASIC_ENV_OPT_OUT.



napi_finalize#

Added in: v8.0.0
N-API version: 1

Function pointer type for add-on provided function that allow the user to
schedule a group of calls to Node-APIs in response to a garbage collection
event, after the garbage collection cycle has completed. These function
pointers can be used with node_api_post_finalizer.
typedef void (*napi_finalize)(napi_env env,
                              void* finalize_data,
                              void* finalize_hint); copy
Change History:


experimental (NAPI_EXPERIMENTAL is defined):
A function of this type may no longer be used as a finalizer, except with
node_api_post_finalizer. node_api_basic_finalize must be used
instead. This feature can be turned off by defining
NODE_API_EXPERIMENTAL_BASIC_ENV_OPT_OUT.



napi_async_execute_callback#

Added in: v8.0.0
N-API version: 1

Function pointer used with functions that support asynchronous
operations. Callback functions must satisfy the following signature:
typedef void (*napi_async_execute_callback)(napi_env env, void* data); copy
Implementations of this function must avoid making Node-API calls that execute
JavaScript or interact with JavaScript objects. Node-API calls should be in the
napi_async_complete_callback instead. Do not use the napi_env parameter as
it will likely result in execution of JavaScript.

napi_async_complete_callback#

Added in: v8.0.0
N-API version: 1

Function pointer used with functions that support asynchronous
operations. Callback functions must satisfy the following signature:
typedef void (*napi_async_complete_callback)(napi_env env,
                                             napi_status status,
                                             void* data); copy
Unless for reasons discussed in Object Lifetime Management, creating a
handle and/or callback scope inside the function body is not necessary.

napi_threadsafe_function_call_js#

Added in: v10.6.0
N-API version: 4

Function pointer used with asynchronous thread-safe function calls. The callback
will be called on the main thread. Its purpose is to use a data item arriving
via the queue from one of the secondary threads to construct the parameters
necessary for a call into JavaScript, usually via napi_call_function, and then
make the call into JavaScript.
The data arriving from the secondary thread via the queue is given in the data
parameter and the JavaScript function to call is given in the js_callback
parameter.
Node-API sets up the environment prior to calling this callback, so it is
sufficient to call the JavaScript function via napi_call_function rather than
via napi_make_callback.
Callback functions must satisfy the following signature:
typedef void (*napi_threadsafe_function_call_js)(napi_env env,
                                                 napi_value js_callback,
                                                 void* context,
                                                 void* data); copy

[in] env: The environment to use for API calls, or NULL if the thread-safe
function is being torn down and data may need to be freed.
[in] js_callback: The JavaScript function to call, or NULL if the
thread-safe function is being torn down and data may need to be freed. It
may also be NULL if the thread-safe function was created without
js_callback.
[in] context: The optional data with which the thread-safe function was
created.
[in] data: Data created by the secondary thread. It is the responsibility of
the callback to convert this native data to JavaScript values (with Node-API
functions) that can be passed as parameters when js_callback is invoked.
This pointer is managed entirely by the threads and this callback. Thus this
callback should free the data.

Unless for reasons discussed in Object Lifetime Management, creating a
handle and/or callback scope inside the function body is not necessary.

napi_cleanup_hook#

Added in: v19.2.0, v18.13.0
N-API version: 3

Function pointer used with napi_add_env_cleanup_hook. It will be called
when the environment is being torn down.
Callback functions must satisfy the following signature:
typedef void (*napi_cleanup_hook)(void* data); copy

[in] data: The data that was passed to napi_add_env_cleanup_hook.


napi_async_cleanup_hook#

Added in: v14.10.0, v12.19.0

Function pointer used with napi_add_async_cleanup_hook. It will be called
when the environment is being torn down.
Callback functions must satisfy the following signature:
typedef void (*napi_async_cleanup_hook)(napi_async_cleanup_hook_handle handle,
                                        void* data); copy

[in] handle: The handle that must be passed to
napi_remove_async_cleanup_hook after completion of the asynchronous
cleanup.
[in] data: The data that was passed to napi_add_async_cleanup_hook.

The body of the function should initiate the asynchronous cleanup actions at the
end of which handle must be passed in a call to
napi_remove_async_cleanup_hook.

Error handling#
Node-API uses both return values and JavaScript exceptions for error handling.
The following sections explain the approach for each case.

Return values#
All of the Node-API functions share the same error handling pattern. The
return type of all API functions is napi_status.
The return value will be napi_ok if the request was successful and
no uncaught JavaScript exception was thrown. If an error occurred AND
an exception was thrown, the napi_status value for the error
will be returned. If an exception was thrown, and no error occurred,
napi_pending_exception will be returned.
In cases where a return value other than napi_ok or
napi_pending_exception is returned, napi_is_exception_pending
must be called to check if an exception is pending.
See the section on exceptions for more details.
The full set of possible napi_status values is defined
in napi_api_types.h.
The napi_status return value provides a VM-independent representation of
the error which occurred. In some cases it is useful to be able to get
more detailed information, including a string representing the error as well as
VM (engine)-specific information.
In order to retrieve this information napi_get_last_error_info
is provided which returns a napi_extended_error_info structure.
The format of the napi_extended_error_info structure is as follows:

Added in: v8.0.0
N-API version: 1

typedef struct napi_extended_error_info {
  const char* error_message;
  void* engine_reserved;
  uint32_t engine_error_code;
  napi_status error_code;
}; copy

error_message: Textual representation of the error that occurred.
engine_reserved: Opaque handle reserved for engine use only.
engine_error_code: VM specific error code.
error_code: Node-API status code for the last error.

napi_get_last_error_info returns the information for the last
Node-API call that was made.
Do not rely on the content or format of any of the extended information as it
is not subject to SemVer and may change at any time. It is intended only for
logging purposes.

napi_get_last_error_info#

Added in: v8.0.0
N-API version: 1

napi_status
napi_get_last_error_info(node_api_basic_env env,
                         const napi_extended_error_info** result); copy

[in] env: The environment that the API is invoked under.
[out] result: The napi_extended_error_info structure with more
information about the error.

Returns napi_ok if the API succeeded.
This API retrieves a napi_extended_error_info structure with information
about the last error that occurred.
The content of the napi_extended_error_info returned is only valid up until
a Node-API function is called on the same env. This includes a call to
napi_is_exception_pending so it may often be necessary to make a copy
of the information so that it can be used later. The pointer returned
in error_message points to a statically-defined string so it is safe to use
that pointer if you have copied it out of the error_message field (which will
be overwritten) before another Node-API function was called.
Do not rely on the content or format of any of the extended information as it
is not subject to SemVer and may change at any time. It is intended only for
logging purposes.
This API can be called even if there is a pending JavaScript exception.

Exceptions#
Any Node-API function call may result in a pending JavaScript exception. This is
the case for any of the API functions, even those that may not cause the
execution of JavaScript.
If the napi_status returned by a function is napi_ok then no
exception is pending and no additional action is required. If the
napi_status returned is anything other than napi_ok or
napi_pending_exception, in order to try to recover and continue
instead of simply returning immediately, napi_is_exception_pending
must be called in order to determine if an exception is pending or not.
In many cases when a Node-API function is called and an exception is
already pending, the function will return immediately with a
napi_status of napi_pending_exception. However, this is not the case
for all functions. Node-API allows a subset of the functions to be
called to allow for some minimal cleanup before returning to JavaScript.
In that case, napi_status will reflect the status for the function. It
will not reflect previous pending exceptions. To avoid confusion, check
the error status after every function call.
When an exception is pending one of two approaches can be employed.
The first approach is to do any appropriate cleanup and then return so that
execution will return to JavaScript. As part of the transition back to
JavaScript, the exception will be thrown at the point in the JavaScript
code where the native method was invoked. The behavior of most Node-API calls
is unspecified while an exception is pending, and many will simply return
napi_pending_exception, so do as little as possible and then return to
JavaScript where the exception can be handled.
The second approach is to try to handle the exception. There will be cases
where the native code can catch the exception, take the appropriate action,
and then continue. This is only recommended in specific cases
where it is known that the exception can be safely handled. In these
cases napi_get_and_clear_last_exception can be used to get and
clear the exception. On success, result will contain the handle to
the last JavaScript Object thrown. If it is determined, after
retrieving the exception, the exception cannot be handled after all
it can be re-thrown it with napi_throw where error is the
JavaScript value to be thrown.
The following utility functions are also available in case native code
needs to throw an exception or determine if a napi_value is an instance
of a JavaScript Error object: napi_throw_error,
napi_throw_type_error, napi_throw_range_error, node_api_throw_syntax_error and napi_is_error.
The following utility functions are also available in case native
code needs to create an Error object: napi_create_error,
napi_create_type_error, napi_create_range_error and node_api_create_syntax_error,
where result is the napi_value that refers to the newly created
JavaScript Error object.
The Node.js project is adding error codes to all of the errors
generated internally. The goal is for applications to use these
error codes for all error checking. The associated error messages
will remain, but will only be meant to be used for logging and
display with the expectation that the message can change without
SemVer applying. In order to support this model with Node-API, both
in internal functionality and for module specific functionality
(as its good practice), the throw_ and create_ functions
take an optional code parameter which is the string for the code
to be added to the error object. If the optional parameter is NULL
then no code will be associated with the error. If a code is provided,
the name associated with the error is also updated to be:
originalName [code] copy
where originalName is the original name associated with the error
and code is the code that was provided. For example, if the code
is 'ERR_ERROR_1' and a TypeError is being created the name will be:
TypeError [ERR_ERROR_1] copy

napi_throw#

Added in: v8.0.0
N-API version: 1

NAPI_EXTERN napi_status napi_throw(napi_env env, napi_value error); copy

[in] env: The environment that the API is invoked under.
[in] error: The JavaScript value to be thrown.

Returns napi_ok if the API succeeded.
This API throws the JavaScript value provided.

napi_throw_error#

Added in: v8.0.0
N-API version: 1

NAPI_EXTERN napi_status napi_throw_error(napi_env env,
                                         const char* code,
                                         const char* msg); copy

[in] env: The environment that the API is invoked under.
[in] code: Optional error code to be set on the error.
[in] msg: C string representing the text to be associated with the error.

Returns napi_ok if the API succeeded.
This API throws a JavaScript Error with the text provided.

napi_throw_type_error#

Added in: v8.0.0
N-API version: 1

NAPI_EXTERN napi_status napi_throw_type_error(napi_env env,
                                              const char* code,
                                              const char* msg); copy

[in] env: The environment that the API is invoked under.
[in] code: Optional error code to be set on the error.
[in] msg: C string representing the text to be associated with the error.

Returns napi_ok if the API succeeded.
This API throws a JavaScript TypeError with the text provided.

napi_throw_range_error#

Added in: v8.0.0
N-API version: 1

NAPI_EXTERN napi_status napi_throw_range_error(napi_env env,
                                               const char* code,
                                               const char* msg); copy

[in] env: The environment that the API is invoked under.
[in] code: Optional error code to be set on the error.
[in] msg: C string representing the text to be associated with the error.

Returns napi_ok if the API succeeded.
This API throws a JavaScript RangeError with the text provided.

node_api_throw_syntax_error#

Added in: v17.2.0, v16.14.0
N-API version: 9

NAPI_EXTERN napi_status node_api_throw_syntax_error(napi_env env,
                                                    const char* code,
                                                    const char* msg); copy

[in] env: The environment that the API is invoked under.
[in] code: Optional error code to be set on the error.
[in] msg: C string representing the text to be associated with the error.

Returns napi_ok if the API succeeded.
This API throws a JavaScript SyntaxError with the text provided.

napi_is_error#

Added in: v8.0.0
N-API version: 1

NAPI_EXTERN napi_status napi_is_error(napi_env env,
                                      napi_value value,
                                      bool* result); copy

[in] env: The environment that the API is invoked under.
[in] value: The napi_value to be checked.
[out] result: Boolean value that is set to true if napi_value represents
an error, false otherwise.

Returns napi_ok if the API succeeded.
This API queries a napi_value to check if it represents an error object.

napi_create_error#

Added in: v8.0.0
N-API version: 1

NAPI_EXTERN napi_status napi_create_error(napi_env env,
                                          napi_value code,
                                          napi_value msg,
                                          napi_value* result); copy

[in] env: The environment that the API is invoked under.
[in] code: Optional napi_value with the string for the error code to be
associated with the error.
[in] msg: napi_value that references a JavaScript string to be used as
the message for the Error.
[out] result: napi_value representing the error created.

Returns napi_ok if the API succeeded.
This API returns a JavaScript Error with the text provided.

napi_create_type_error#

Added in: v8.0.0
N-API version: 1

NAPI_EXTERN napi_status napi_create_type_error(napi_env env,
                                               napi_value code,
                                               napi_value msg,
                                               napi_value* result); copy

[in] env: The environment that the API is invoked under.
[in] code: Optional napi_value with the string for the error code to be
associated with the error.
[in] msg: napi_value that references a JavaScript string to be used as
the message for the Error.
[out] result: napi_value representing the error created.

Returns napi_ok if the API succeeded.
This API returns a JavaScript TypeError with the text provided.

napi_create_range_error#

Added in: v8.0.0
N-API version: 1

NAPI_EXTERN napi_status napi_create_range_error(napi_env env,
                                                napi_value code,
                                                napi_value msg,
                                                napi_value* result); copy

[in] env: The environment that the API is invoked under.
[in] code: Optional napi_value with the string for the error code to be
associated with the error.
[in] msg: napi_value that references a JavaScript string to be used as
the message for the Error.
[out] result: napi_value representing the error created.

Returns napi_ok if the API succeeded.
This API returns a JavaScript RangeError with the text provided.

node_api_create_syntax_error#

Added in: v17.2.0, v16.14.0
N-API version: 9

NAPI_EXTERN napi_status node_api_create_syntax_error(napi_env env,
                                                     napi_value code,
                                                     napi_value msg,
                                                     napi_value* result); copy

[in] env: The environment that the API is invoked under.
[in] code: Optional napi_value with the string for the error code to be
associated with the error.
[in] msg: napi_value that references a JavaScript string to be used as
the message for the Error.
[out] result: napi_value representing the error created.

Returns napi_ok if the API succeeded.
This API returns a JavaScript SyntaxError with the text provided.

napi_get_and_clear_last_exception#

Added in: v8.0.0
N-API version: 1

napi_status napi_get_and_clear_last_exception(napi_env env,
                                              napi_value* result); copy

[in] env: The environment that the API is invoked under.
[out] result: The exception if one is pending, NULL otherwise.

Returns napi_ok if the API succeeded.
This API can be called even if there is a pending JavaScript exception.

napi_is_exception_pending#

Added in: v8.0.0
N-API version: 1

napi_status napi_is_exception_pending(napi_env env, bool* result); copy

[in] env: The environment that the API is invoked under.
[out] result: Boolean value that is set to true if an exception is pending.

Returns napi_ok if the API succeeded.
This API can be called even if there is a pending JavaScript exception.

napi_fatal_exception#

Added in: v9.10.0
N-API version: 3

napi_status napi_fatal_exception(napi_env env, napi_value err); copy

[in] env: The environment that the API is invoked under.
[in] err: The error that is passed to 'uncaughtException'.

Trigger an 'uncaughtException' in JavaScript. Useful if an async
callback throws an exception with no way to recover.

Fatal errors#
In the event of an unrecoverable error in a native addon, a fatal error can be
thrown to immediately terminate the process.

napi_fatal_error#

Added in: v8.2.0
N-API version: 1

NAPI_NO_RETURN void napi_fatal_error(const char* location,
                                     size_t location_len,
                                     const char* message,
                                     size_t message_len); copy

[in] location: Optional location at which the error occurred.
[in] location_len: The length of the location in bytes, or
NAPI_AUTO_LENGTH if it is null-terminated.
[in] message: The message associated with the error.
[in] message_len: The length of the message in bytes, or NAPI_AUTO_LENGTH
if it is null-terminated.

The function call does not return, the process will be terminated.
This API can be called even if there is a pending JavaScript exception.

Object lifetime management#
As Node-API calls are made, handles to objects in the heap for the underlying
VM may be returned as napi_values. These handles must hold the
objects 'live' until they are no longer required by the native code,
otherwise the objects could be collected before the native code was
finished using them.
As object handles are returned they are associated with a
'scope'. The lifespan for the default scope is tied to the lifespan
of the native method call. The result is that, by default, handles
remain valid and the objects associated with these handles will be
held live for the lifespan of the native method call.
In many cases, however, it is necessary that the handles remain valid for
either a shorter or longer lifespan than that of the native method.
The sections which follow describe the Node-API functions that can be used
to change the handle lifespan from the default.

Making handle lifespan shorter than that of the native method#
It is often necessary to make the lifespan of handles shorter than
the lifespan of a native method. For example, consider a native method
that has a loop which iterates through the elements in a large array:
for (int i = 0; i < 1000000; i++) {
  napi_value result;
  napi_status status = napi_get_element(env, object, i, &result);
  if (status != napi_ok) {
    break;
  }
  // do something with element
} copy
This would result in a large number of handles being created, consuming
substantial resources. In addition, even though the native code could only
use the most recent handle, all of the associated objects would also be
kept alive since they all share the same scope.
To handle this case, Node-API provides the ability to establish a new 'scope' to
which newly created handles will be associated. Once those handles
are no longer required, the scope can be 'closed' and any handles associated
with the scope are invalidated. The methods available to open/close scopes are
napi_open_handle_scope and napi_close_handle_scope.
Node-API only supports a single nested hierarchy of scopes. There is only one
active scope at any time, and all new handles will be associated with that
scope while it is active. Scopes must be closed in the reverse order from
which they are opened. In addition, all scopes created within a native method
must be closed before returning from that method.
Taking the earlier example, adding calls to napi_open_handle_scope and
napi_close_handle_scope would ensure that at most a single handle
is valid throughout the execution of the loop:
for (int i = 0; i < 1000000; i++) {
  napi_handle_scope scope;
  napi_status status = napi_open_handle_scope(env, &scope);
  if (status != napi_ok) {
    break;
  }
  napi_value result;
  status = napi_get_element(env, object, i, &result);
  if (status != napi_ok) {
    break;
  }
  // do something with element
  status = napi_close_handle_scope(env, scope);
  if (status != napi_ok) {
    break;
  }
} copy
When nesting scopes, there are cases where a handle from an
inner scope needs to live beyond the lifespan of that scope. Node-API supports
an 'escapable scope' in order to support this case. An escapable scope
allows one handle to be 'promoted' so that it 'escapes' the
current scope and the lifespan of the handle changes from the current
scope to that of the outer scope.
The methods available to open/close escapable scopes are
napi_open_escapable_handle_scope and
napi_close_escapable_handle_scope.
The request to promote a handle is made through napi_escape_handle which
can only be called once.

napi_open_handle_scope#

Added in: v8.0.0
N-API version: 1

NAPI_EXTERN napi_status napi_open_handle_scope(napi_env env,
                                               napi_handle_scope* result); copy

[in] env: The environment that the API is invoked under.
[out] result: napi_value representing the new scope.

Returns napi_ok if the API succeeded.
This API opens a new scope.

napi_close_handle_scope#

Added in: v8.0.0
N-API version: 1

NAPI_EXTERN napi_status napi_close_handle_scope(napi_env env,
                                                napi_handle_scope scope); copy

[in] env: The environment that the API is invoked under.
[in] scope: napi_value representing the scope to be closed.

Returns napi_ok if the API succeeded.
This API closes the scope passed in. Scopes must be closed in the
reverse order from which they were created.
This API can be called even if there is a pending JavaScript exception.

napi_open_escapable_handle_scope#

Added in: v8.0.0
N-API version: 1

NAPI_EXTERN napi_status
    napi_open_escapable_handle_scope(napi_env env,
                                     napi_handle_scope* result); copy

[in] env: The environment that the API is invoked under.
[out] result: napi_value representing the new scope.

Returns napi_ok if the API succeeded.
This API opens a new scope from which one object can be promoted
to the outer scope.

napi_close_escapable_handle_scope#

Added in: v8.0.0
N-API version: 1

NAPI_EXTERN napi_status
    napi_close_escapable_handle_scope(napi_env env,
                                      napi_handle_scope scope); copy

[in] env: The environment that the API is invoked under.
[in] scope: napi_value representing the scope to be closed.

Returns napi_ok if the API succeeded.
This API closes the scope passed in. Scopes must be closed in the
reverse order from which they were created.
This API can be called even if there is a pending JavaScript exception.

napi_escape_handle#

Added in: v8.0.0
N-API version: 1

napi_status napi_escape_handle(napi_env env,
                               napi_escapable_handle_scope scope,
                               napi_value escapee,
                               napi_value* result); copy

[in] env: The environment that the API is invoked under.
[in] scope: napi_value representing the current scope.
[in] escapee: napi_value representing the JavaScript Object to be
escaped.
[out] result: napi_value representing the handle to the escaped Object
in the outer scope.

Returns napi_ok if the API succeeded.
This API promotes the handle to the JavaScript object so that it is valid
for the lifetime of the outer scope. It can only be called once per scope.
If it is called more than once an error will be returned.
This API can be called even if there is a pending JavaScript exception.

References to values with a lifespan longer than that of the native method#
In some cases, an addon will need to be able to create and reference values
with a lifespan longer than that of a single native method invocation. For
example, to create a constructor and later use that constructor
in a request to create instances, it must be possible to reference
the constructor object across many different instance creation requests. This
would not be possible with a normal handle returned as a napi_value as
described in the earlier section. The lifespan of a normal handle is
managed by scopes and all scopes must be closed before the end of a native
method.
Node-API provides methods for creating persistent references to values.
Currently Node-API only allows references to be created for a
limited set of value types, including object, external, function, and symbol.
Each reference has an associated count with a value of 0 or higher,
which determines whether the reference will keep the corresponding value alive.
References with a count of 0 do not prevent values from being collected.
Values of object (object, function, external) and symbol types are becoming
'weak' references and can still be accessed while they are not collected.
Any count greater than 0 will prevent the values from being collected.
Symbol values have different flavors. The true weak reference behavior is
only supported by local symbols created with the napi_create_symbol function
or the JavaScript Symbol() constructor calls. Globally registered symbols
created with the node_api_symbol_for function or JavaScript Symbol.for()
function calls remain always strong references because the garbage collector
does not collect them. The same is true for well-known symbols such as
Symbol.iterator. They are also never collected by the garbage collector.
References can be created with an initial reference count. The count can
then be modified through napi_reference_ref and
napi_reference_unref. If an object is collected while the count
for a reference is 0, all subsequent calls to
get the object associated with the reference napi_get_reference_value
will return NULL for the returned napi_value. An attempt to call
napi_reference_ref for a reference whose object has been collected
results in an error.
References must be deleted once they are no longer required by the addon. When
a reference is deleted, it will no longer prevent the corresponding object from
being collected. Failure to delete a persistent reference results in
a 'memory leak' with both the native memory for the persistent reference and
the corresponding object on the heap being retained forever.
There can be multiple persistent references created which refer to the same
object, each of which will either keep the object live or not based on its
individual count. Multiple persistent references to the same object
can result in unexpectedly keeping alive native memory. The native structures
for a persistent reference must be kept alive until finalizers for the
referenced object are executed. If a new persistent reference is created
for the same object, the finalizers for that object will not be
run and the native memory pointed by the earlier persistent reference
will not be freed. This can be avoided by calling
napi_delete_reference in addition to napi_reference_unref when possible.
Change History:


Version 10 (NAPI_VERSION is defined as 10 or higher):
References can be created for all value types. The new supported value
types do not support weak reference semantic and the values of these types
are released when the reference count becomes 0 and cannot be accessed from
the reference anymore.



napi_create_reference#

Added in: v8.0.0
N-API version: 1

NAPI_EXTERN napi_status napi_create_reference(napi_env env,
                                              napi_value value,
                                              uint32_t initial_refcount,
                                              napi_ref* result); copy

[in] env: The environment that the API is invoked under.
[in] value: The napi_value for which a reference is being created.
[in] initial_refcount: Initial reference count for the new reference.
[out] result: napi_ref pointing to the new reference.

Returns napi_ok if the API succeeded.
This API creates a new reference with the specified reference count
to the value passed in.

napi_delete_reference#

Added in: v8.0.0
N-API version: 1

NAPI_EXTERN napi_status napi_delete_reference(napi_env env, napi_ref ref); copy

[in] env: The environment that the API is invoked under.
[in] ref: napi_ref to be deleted.

Returns napi_ok if the API succeeded.
This API deletes the reference passed in.
This API can be called even if there is a pending JavaScript exception.

napi_reference_ref#

Added in: v8.0.0
N-API version: 1

NAPI_EXTERN napi_status napi_reference_ref(napi_env env,
                                           napi_ref ref,
                                           uint32_t* result); copy

[in] env: The environment that the API is invoked under.
[in] ref: napi_ref for which the reference count will be incremented.
[out] result: The new reference count.

Returns napi_ok if the API succeeded.
This API increments the reference count for the reference
passed in and returns the resulting reference count.

napi_reference_unref#

Added in: v8.0.0
N-API version: 1

NAPI_EXTERN napi_status napi_reference_unref(napi_env env,
                                             napi_ref ref,
                                             uint32_t* result); copy

[in] env: The environment that the API is invoked under.
[in] ref: napi_ref for which the reference count will be decremented.
[out] result: The new reference count.

Returns napi_ok if the API succeeded.
This API decrements the reference count for the reference
passed in and returns the resulting reference count.

napi_get_reference_value#

Added in: v8.0.0
N-API version: 1

NAPI_EXTERN napi_status napi_get_reference_value(napi_env env,
                                                 napi_ref ref,
                                                 napi_value* result); copy

[in] env: The environment that the API is invoked under.
[in] ref: The napi_ref for which the corresponding value is
being requested.
[out] result: The napi_value referenced by the napi_ref.

Returns napi_ok if the API succeeded.
If still valid, this API returns the napi_value representing the
JavaScript value associated with the napi_ref. Otherwise, result
will be NULL.

Cleanup on exit of the current Node.js environment#
While a Node.js process typically releases all its resources when exiting,
embedders of Node.js, or future Worker support, may require addons to register
clean-up hooks that will be run once the current Node.js environment exits.
Node-API provides functions for registering and un-registering such callbacks.
When those callbacks are run, all resources that are being held by the addon
should be freed up.

napi_add_env_cleanup_hook#

Added in: v10.2.0
N-API version: 3

NODE_EXTERN napi_status napi_add_env_cleanup_hook(node_api_basic_env env,
                                                  napi_cleanup_hook fun,
                                                  void* arg); copy
Registers fun as a function to be run with the arg parameter once the
current Node.js environment exits.
A function can safely be specified multiple times with different
arg values. In that case, it will be called multiple times as well.
Providing the same fun and arg values multiple times is not allowed
and will lead the process to abort.
The hooks will be called in reverse order, i.e. the most recently added one
will be called first.
Removing this hook can be done by using napi_remove_env_cleanup_hook.
Typically, that happens when the resource for which this hook was added
is being torn down anyway.
For asynchronous cleanup, napi_add_async_cleanup_hook is available.

napi_remove_env_cleanup_hook#

Added in: v10.2.0
N-API version: 3

NAPI_EXTERN napi_status napi_remove_env_cleanup_hook(node_api_basic_env env,
                                                     void (*fun)(void* arg),
                                                     void* arg); copy
Unregisters fun as a function to be run with the arg parameter once the
current Node.js environment exits. Both the argument and the function value
need to be exact matches.
The function must have originally been registered
with napi_add_env_cleanup_hook, otherwise the process will abort.

napi_add_async_cleanup_hook#

History

VersionChanges
v14.10.0, v12.19.0
Changed signature of the hook callback.
v14.8.0, v12.19.0
Added in: v14.8.0, v12.19.0


N-API version: 8

NAPI_EXTERN napi_status napi_add_async_cleanup_hook(
    node_api_basic_env env,
    napi_async_cleanup_hook hook,
    void* arg,
    napi_async_cleanup_hook_handle* remove_handle); copy

[in] env: The environment that the API is invoked under.
[in] hook: The function pointer to call at environment teardown.
[in] arg: The pointer to pass to hook when it gets called.
[out] remove_handle: Optional handle that refers to the asynchronous cleanup
hook.

Registers hook, which is a function of type napi_async_cleanup_hook, as
a function to be run with the remove_handle and arg parameters once the
current Node.js environment exits.
Unlike napi_add_env_cleanup_hook, the hook is allowed to be asynchronous.
Otherwise, behavior generally matches that of napi_add_env_cleanup_hook.
If remove_handle is not NULL, an opaque value will be stored in it
that must later be passed to napi_remove_async_cleanup_hook,
regardless of whether the hook has already been invoked.
Typically, that happens when the resource for which this hook was added
is being torn down anyway.

napi_remove_async_cleanup_hook#

History

VersionChanges
v14.10.0, v12.19.0
Removed env parameter.
v14.8.0, v12.19.0
Added in: v14.8.0, v12.19.0



NAPI_EXTERN napi_status napi_remove_async_cleanup_hook(
    napi_async_cleanup_hook_handle remove_handle); copy

[in] remove_handle: The handle to an asynchronous cleanup hook that was
created with napi_add_async_cleanup_hook.

Unregisters the cleanup hook corresponding to remove_handle. This will prevent
the hook from being executed, unless it has already started executing.
This must be called on any napi_async_cleanup_hook_handle value obtained
from napi_add_async_cleanup_hook.

Finalization on the exit of the Node.js environment#
The Node.js environment may be torn down at an arbitrary time as soon as
possible with JavaScript execution disallowed, like on the request of
worker.terminate(). When the environment is being torn down, the
registered napi_finalize callbacks of JavaScript objects, thread-safe
functions and environment instance data are invoked immediately and
independently.
The invocation of napi_finalize callbacks is scheduled after the manually
registered cleanup hooks. In order to ensure a proper order of addon
finalization during environment shutdown to avoid use-after-free in the
napi_finalize callback, addons should register a cleanup hook with
napi_add_env_cleanup_hook and napi_add_async_cleanup_hook to manually
release the allocated resource in a proper order.

Module registration#
Node-API modules are registered in a manner similar to other modules
except that instead of using the NODE_MODULE macro the following
is used:
NAPI_MODULE(NODE_GYP_MODULE_NAME, Init) copy
The next difference is the signature for the Init method. For a Node-API
module it is as follows:
napi_value Init(napi_env env, napi_value exports); copy
The return value from Init is treated as the exports object for the module.
The Init method is passed an empty object via the exports parameter as a
convenience. If Init returns NULL, the parameter passed as exports is
exported by the module. Node-API modules cannot modify the module object but
can specify anything as the exports property of the module.
To add the method hello as a function so that it can be called as a method
provided by the addon:
napi_value Init(napi_env env, napi_value exports) {
  napi_status status;
  napi_property_descriptor desc = {
    "hello",
    NULL,
    Method,
    NULL,
    NULL,
    NULL,
    napi_writable | napi_enumerable | napi_configurable,
    NULL
  };
  status = napi_define_properties(env, exports, 1, &desc);
  if (status != napi_ok) return NULL;
  return exports;
} copy
To set a function to be returned by the require() for the addon:
napi_value Init(napi_env env, napi_value exports) {
  napi_value method;
  napi_status status;
  status = napi_create_function(env, "exports", NAPI_AUTO_LENGTH, Method, NULL, &method);
  if (status != napi_ok) return NULL;
  return method;
} copy
To define a class so that new instances can be created (often used with
Object wrap):
// NOTE: partial example, not all referenced code is included
napi_value Init(napi_env env, napi_value exports) {
  napi_status status;
  napi_property_descriptor properties[] = {
    { "value", NULL, NULL, GetValue, SetValue, NULL, napi_writable | napi_configurable, NULL },
    DECLARE_NAPI_METHOD("plusOne", PlusOne),
    DECLARE_NAPI_METHOD("multiply", Multiply),
  };

  napi_value cons;
  status =
      napi_define_class(env, "MyObject", New, NULL, 3, properties, &cons);
  if (status != napi_ok) return NULL;

  status = napi_create_reference(env, cons, 1, &constructor);
  if (status != napi_ok) return NULL;

  status = napi_set_named_property(env, exports, "MyObject", cons);
  if (status != napi_ok) return NULL;

  return exports;
} copy
You can also use the NAPI_MODULE_INIT macro, which acts as a shorthand
for NAPI_MODULE and defining an Init function:
NAPI_MODULE_INIT(/* napi_env env, napi_value exports */) {
  napi_value answer;
  napi_status result;

  status = napi_create_int64(env, 42, &answer);
  if (status != napi_ok) return NULL;

  status = napi_set_named_property(env, exports, "answer", answer);
  if (status != napi_ok) return NULL;

  return exports;
} copy
The parameters env and exports are provided to the body of the
NAPI_MODULE_INIT macro.
All Node-API addons are context-aware, meaning they may be loaded multiple
times. There are a few design considerations when declaring such a module.
The documentation on context-aware addons provides more details.
The variables env and exports will be available inside the function body
following the macro invocation.
For more details on setting properties on objects, see the section on
Working with JavaScript properties.
For more details on building addon modules in general, refer to the existing
API.
Working with JavaScript values#
Node-API exposes a set of APIs to create all types of JavaScript values.
Some of these types are documented under Section 6
of the ECMAScript Language Specification.
Fundamentally, these APIs are used to do one of the following:

Create a new JavaScript object
Convert from a primitive C type to a Node-API value
Convert from Node-API value to a primitive C type
Get global instances including undefined and null

Node-API values are represented by the type napi_value.
Any Node-API call that requires a JavaScript value takes in a napi_value.
In some cases, the API does check the type of the napi_value up-front.
However, for better performance, it's better for the caller to make sure that
the napi_value in question is of the JavaScript type expected by the API.

Enum types#

napi_key_collection_mode#

Added in: v13.7.0, v12.17.0, v10.20.0
N-API version: 6

typedef enum {
  napi_key_include_prototypes,
  napi_key_own_only
} napi_key_collection_mode; copy
Describes the Keys/Properties filter enums:
napi_key_collection_mode limits the range of collected properties.
napi_key_own_only limits the collected properties to the given
object only. napi_key_include_prototypes will include all keys
of the objects's prototype chain as well.

napi_key_filter#

Added in: v13.7.0, v12.17.0, v10.20.0
N-API version: 6

typedef enum {
  napi_key_all_properties = 0,
  napi_key_writable = 1,
  napi_key_enumerable = 1 << 1,
  napi_key_configurable = 1 << 2,
  napi_key_skip_strings = 1 << 3,
  napi_key_skip_symbols = 1 << 4
} napi_key_filter; copy
Property filter bits. They can be or'ed to build a composite filter.

napi_key_conversion#

Added in: v13.7.0, v12.17.0, v10.20.0
N-API version: 6

typedef enum {
  napi_key_keep_numbers,
  napi_key_numbers_to_strings
} napi_key_conversion; copy
napi_key_numbers_to_strings will convert integer indexes to
strings. napi_key_keep_numbers will return numbers for integer
indexes.

napi_valuetype#
typedef enum {
  // ES6 types (corresponds to typeof)
  napi_undefined,
  napi_null,
  napi_boolean,
  napi_number,
  napi_string,
  napi_symbol,
  napi_object,
  napi_function,
  napi_external,
  napi_bigint,
} napi_valuetype; copy
Describes the type of a napi_value. This generally corresponds to the types
described in Section 6.1 of the ECMAScript Language Specification.
In addition to types in that section, napi_valuetype can also represent
Functions and Objects with external data.
A JavaScript value of type napi_external appears in JavaScript as a plain
object such that no properties can be set on it, and no prototype.

napi_typedarray_type#
typedef enum {
  napi_int8_array,
  napi_uint8_array,
  napi_uint8_clamped_array,
  napi_int16_array,
  napi_uint16_array,
  napi_int32_array,
  napi_uint32_array,
  napi_float32_array,
  napi_float64_array,
  napi_bigint64_array,
  napi_biguint64_array,
} napi_typedarray_type; copy
This represents the underlying binary scalar datatype of the TypedArray.
Elements of this enum correspond to
Section 22.2 of the ECMAScript Language Specification.

Object creation functions#

napi_create_array#

Added in: v8.0.0
N-API version: 1

napi_status napi_create_array(napi_env env, napi_value* result) copy

[in] env: The environment that the Node-API call is invoked under.
[out] result: A napi_value representing a JavaScript Array.

Returns napi_ok if the API succeeded.
This API returns a Node-API value corresponding to a JavaScript Array type.
JavaScript arrays are described in
Section 22.1 of the ECMAScript Language Specification.

napi_create_array_with_length#

Added in: v8.0.0
N-API version: 1

napi_status napi_create_array_with_length(napi_env env,
                                          size_t length,
                                          napi_value* result) copy

[in] env: The environment that the API is invoked under.
[in] length: The initial length of the Array.
[out] result: A napi_value representing a JavaScript Array.

Returns napi_ok if the API succeeded.
This API returns a Node-API value corresponding to a JavaScript Array type.
The Array's length property is set to the passed-in length parameter.
However, the underlying buffer is not guaranteed to be pre-allocated by the VM
when the array is created. That behavior is left to the underlying VM
implementation. If the buffer must be a contiguous block of memory that can be
directly read and/or written via C, consider using
napi_create_external_arraybuffer.
JavaScript arrays are described in
Section 22.1 of the ECMAScript Language Specification.

napi_create_arraybuffer#

Added in: v8.0.0
N-API version: 1

napi_status napi_create_arraybuffer(napi_env env,
                                    size_t byte_length,
                                    void** data,
                                    napi_value* result) copy

[in] env: The environment that the API is invoked under.
[in] length: The length in bytes of the array buffer to create.
[out] data: Pointer to the underlying byte buffer of the ArrayBuffer.
data can optionally be ignored by passing NULL.
[out] result: A napi_value representing a JavaScript ArrayBuffer.

Returns napi_ok if the API succeeded.
This API returns a Node-API value corresponding to a JavaScript ArrayBuffer.
ArrayBuffers are used to represent fixed-length binary data buffers. They are
normally used as a backing-buffer for TypedArray objects.
The ArrayBuffer allocated will have an underlying byte buffer whose size is
determined by the length parameter that's passed in.
The underlying buffer is optionally returned back to the caller in case the
caller wants to directly manipulate the buffer. This buffer can only be
written to directly from native code. To write to this buffer from JavaScript,
a typed array or DataView object would need to be created.
JavaScript ArrayBuffer objects are described in
Section 24.1 of the ECMAScript Language Specification.

napi_create_buffer#

Added in: v8.0.0
N-API version: 1

napi_status napi_create_buffer(napi_env env,
                               size_t size,
                               void** data,
                               napi_value* result) copy

[in] env: The environment that the API is invoked under.
[in] size: Size in bytes of the underlying buffer.
[out] data: Raw pointer to the underlying buffer.
data can optionally be ignored by passing NULL.
[out] result: A napi_value representing a node::Buffer.

Returns napi_ok if the API succeeded.
This API allocates a node::Buffer object. While this is still a
fully-supported data structure, in most cases using a TypedArray will suffice.

napi_create_buffer_copy#

Added in: v8.0.0
N-API version: 1

napi_status napi_create_buffer_copy(napi_env env,
                                    size_t length,
                                    const void* data,
                                    void** result_data,
                                    napi_value* result) copy

[in] env: The environment that the API is invoked under.
[in] size: Size in bytes of the input buffer (should be the same as the size
of the new buffer).
[in] data: Raw pointer to the underlying buffer to copy from.
[out] result_data: Pointer to the new Buffer's underlying data buffer.
result_data can optionally be ignored by passing NULL.
[out] result: A napi_value representing a node::Buffer.

Returns napi_ok if the API succeeded.
This API allocates a node::Buffer object and initializes it with data copied
from the passed-in buffer. While this is still a fully-supported data
structure, in most cases using a TypedArray will suffice.

napi_create_date#

Added in: v11.11.0, v10.17.0
N-API version: 5

napi_status napi_create_date(napi_env env,
                             double time,
                             napi_value* result); copy

[in] env: The environment that the API is invoked under.
[in] time: ECMAScript time value in milliseconds since 01 January, 1970 UTC.
[out] result: A napi_value representing a JavaScript Date.

Returns napi_ok if the API succeeded.
This API does not observe leap seconds; they are ignored, as
ECMAScript aligns with POSIX time specification.
This API allocates a JavaScript Date object.
JavaScript Date objects are described in
Section 20.3 of the ECMAScript Language Specification.

napi_create_external#

Added in: v8.0.0
N-API version: 1

napi_status napi_create_external(napi_env env,
                                 void* data,
                                 napi_finalize finalize_cb,
                                 void* finalize_hint,
                                 napi_value* result) copy

[in] env: The environment that the API is invoked under.
[in] data: Raw pointer to the external data.
[in] finalize_cb: Optional callback to call when the external value is being
collected. napi_finalize provides more details.
[in] finalize_hint: Optional hint to pass to the finalize callback during
collection.
[out] result: A napi_value representing an external value.

Returns napi_ok if the API succeeded.
This API allocates a JavaScript value with external data attached to it. This
is used to pass external data through JavaScript code, so it can be retrieved
later by native code using napi_get_value_external.
The API adds a napi_finalize callback which will be called when the JavaScript
object just created has been garbage collected.
The created value is not an object, and therefore does not support additional
properties. It is considered a distinct value type: calling napi_typeof() with
an external value yields napi_external.

napi_create_external_arraybuffer#

Added in: v8.0.0
N-API version: 1

napi_status
napi_create_external_arraybuffer(napi_env env,
                                 void* external_data,
                                 size_t byte_length,
                                 napi_finalize finalize_cb,
                                 void* finalize_hint,
                                 napi_value* result) copy

[in] env: The environment that the API is invoked under.
[in] external_data: Pointer to the underlying byte buffer of the
ArrayBuffer.
[in] byte_length: The length in bytes of the underlying buffer.
[in] finalize_cb: Optional callback to call when the ArrayBuffer is being
collected. napi_finalize provides more details.
[in] finalize_hint: Optional hint to pass to the finalize callback during
collection.
[out] result: A napi_value representing a JavaScript ArrayBuffer.

Returns napi_ok if the API succeeded.
Some runtimes other than Node.js have dropped support for external buffers.
On runtimes other than Node.js this method may return
napi_no_external_buffers_allowed to indicate that external
buffers are not supported. One such runtime is Electron as
described in this issue
electron/issues/35801.
In order to maintain broadest compatibility with all runtimes
you may define NODE_API_NO_EXTERNAL_BUFFERS_ALLOWED in your addon before
includes for the node-api headers. Doing so will hide the 2 functions
that create external buffers. This will ensure a compilation error
occurs if you accidentally use one of these methods.
This API returns a Node-API value corresponding to a JavaScript ArrayBuffer.
The underlying byte buffer of the ArrayBuffer is externally allocated and
managed. The caller must ensure that the byte buffer remains valid until the
finalize callback is called.
The API adds a napi_finalize callback which will be called when the JavaScript
object just created has been garbage collected.
JavaScript ArrayBuffers are described in
Section 24.1 of the ECMAScript Language Specification.

napi_create_external_buffer#

Added in: v8.0.0
N-API version: 1

napi_status napi_create_external_buffer(napi_env env,
                                        size_t length,
                                        void* data,
                                        napi_finalize finalize_cb,
                                        void* finalize_hint,
                                        napi_value* result) copy

[in] env: The environment that the API is invoked under.
[in] length: Size in bytes of the input buffer (should be the same as the
size of the new buffer).
[in] data: Raw pointer to the underlying buffer to expose to JavaScript.
[in] finalize_cb: Optional callback to call when the ArrayBuffer is being
collected. napi_finalize provides more details.
[in] finalize_hint: Optional hint to pass to the finalize callback during
collection.
[out] result: A napi_value representing a node::Buffer.

Returns napi_ok if the API succeeded.
Some runtimes other than Node.js have dropped support for external buffers.
On runtimes other than Node.js this method may return
napi_no_external_buffers_allowed to indicate that external
buffers are not supported. One such runtime is Electron as
described in this issue
electron/issues/35801.
In order to maintain broadest compatibility with all runtimes
you may define NODE_API_NO_EXTERNAL_BUFFERS_ALLOWED in your addon before
includes for the node-api headers. Doing so will hide the 2 functions
that create external buffers. This will ensure a compilation error
occurs if you accidentally use one of these methods.
This API allocates a node::Buffer object and initializes it with data
backed by the passed in buffer. While this is still a fully-supported data
structure, in most cases using a TypedArray will suffice.
The API adds a napi_finalize callback which will be called when the JavaScript
object just created has been garbage collected.
For Node.js >=4 Buffers are Uint8Arrays.

napi_create_object#

Added in: v8.0.0
N-API version: 1

napi_status napi_create_object(napi_env env, napi_value* result) copy

[in] env: The environment that the API is invoked under.
[out] result: A napi_value representing a JavaScript Object.

Returns napi_ok if the API succeeded.
This API allocates a default JavaScript Object.
It is the equivalent of doing new Object() in JavaScript.
The JavaScript Object type is described in Section 6.1.7 of the
ECMAScript Language Specification.

napi_create_symbol#

Added in: v8.0.0
N-API version: 1

napi_status napi_create_symbol(napi_env env,
                               napi_value description,
                               napi_value* result) copy

[in] env: The environment that the API is invoked under.
[in] description: Optional napi_value which refers to a JavaScript
string to be set as the description for the symbol.
[out] result: A napi_value representing a JavaScript symbol.

Returns napi_ok if the API succeeded.
This API creates a JavaScript symbol value from a UTF8-encoded C string.
The JavaScript symbol type is described in Section 19.4
of the ECMAScript Language Specification.

node_api_symbol_for#

Added in: v17.5.0, v16.15.0
N-API version: 9

napi_status node_api_symbol_for(napi_env env,
                                const char* utf8description,
                                size_t length,
                                napi_value* result) copy

[in] env: The environment that the API is invoked under.
[in] utf8description: UTF-8 C string representing the text to be used as the
description for the symbol.
[in] length: The length of the description string in bytes, or
NAPI_AUTO_LENGTH if it is null-terminated.
[out] result: A napi_value representing a JavaScript symbol.

Returns napi_ok if the API succeeded.
This API searches in the global registry for an existing symbol with the given
description. If the symbol already exists it will be returned, otherwise a new
symbol will be created in the registry.
The JavaScript symbol type is described in Section 19.4 of the ECMAScript
Language Specification.

napi_create_typedarray#

Added in: v8.0.0
N-API version: 1

napi_status napi_create_typedarray(napi_env env,
                                   napi_typedarray_type type,
                                   size_t length,
                                   napi_value arraybuffer,
                                   size_t byte_offset,
                                   napi_value* result) copy

[in] env: The environment that the API is invoked under.
[in] type: Scalar datatype of the elements within the TypedArray.
[in] length: Number of elements in the TypedArray.
[in] arraybuffer: ArrayBuffer underlying the typed array.
[in] byte_offset: The byte offset within the ArrayBuffer from which to
start projecting the TypedArray.
[out] result: A napi_value representing a JavaScript TypedArray.

Returns napi_ok if the API succeeded.
This API creates a JavaScript TypedArray object over an existing
ArrayBuffer. TypedArray objects provide an array-like view over an
underlying data buffer where each element has the same underlying binary scalar
datatype.
It's required that (length * size_of_element) + byte_offset should
be <= the size in bytes of the array passed in. If not, a RangeError exception
is raised.
JavaScript TypedArray objects are described in
Section 22.2 of the ECMAScript Language Specification.

node_api_create_buffer_from_arraybuffer#

Added in: v23.0.0, v22.12.0
N-API version: 10

napi_status NAPI_CDECL node_api_create_buffer_from_arraybuffer(napi_env env,
                                                              napi_value arraybuffer,
                                                              size_t byte_offset,
                                                              size_t byte_length,
                                                              napi_value* result) copy

[in] env: The environment that the API is invoked under.
[in] arraybuffer: The ArrayBuffer from which the buffer will be created.
[in] byte_offset: The byte offset within the ArrayBuffer from which to start creating the buffer.
[in] byte_length: The length in bytes of the buffer to be created from the ArrayBuffer.
[out] result: A napi_value representing the created JavaScript Buffer object.

Returns napi_ok if the API succeeded.
This API creates a JavaScript Buffer object from an existing ArrayBuffer.
The Buffer object is a Node.js-specific class that provides a way to work with binary data directly in JavaScript.
The byte range [byte_offset, byte_offset + byte_length)
must be within the bounds of the ArrayBuffer. If byte_offset + byte_length
exceeds the size of the ArrayBuffer, a RangeError exception is raised.

napi_create_dataview#

Added in: v8.3.0
N-API version: 1

napi_status napi_create_dataview(napi_env env,
                                 size_t byte_length,
                                 napi_value arraybuffer,
                                 size_t byte_offset,
                                 napi_value* result) copy

[in] env: The environment that the API is invoked under.
[in] length: Number of elements in the DataView.
[in] arraybuffer: ArrayBuffer underlying the DataView.
[in] byte_offset: The byte offset within the ArrayBuffer from which to
start projecting the DataView.
[out] result: A napi_value representing a JavaScript DataView.

Returns napi_ok if the API succeeded.
This API creates a JavaScript DataView object over an existing ArrayBuffer.
DataView objects provide an array-like view over an underlying data buffer,
but one which allows items of different size and type in the ArrayBuffer.
It is required that byte_length + byte_offset is less than or equal to the
size in bytes of the array passed in. If not, a RangeError exception is
raised.
JavaScript DataView objects are described in
Section 24.3 of the ECMAScript Language Specification.

Functions to convert from C types to Node-API#

napi_create_int32#

Added in: v8.4.0
N-API version: 1

napi_status napi_create_int32(napi_env env, int32_t value, napi_value* result) copy

[in] env: The environment that the API is invoked under.
[in] value: Integer value to be represented in JavaScript.
[out] result: A napi_value representing a JavaScript number.

Returns napi_ok if the API succeeded.
This API is used to convert from the C int32_t type to the JavaScript
number type.
The JavaScript number type is described in
Section 6.1.6 of the ECMAScript Language Specification.

napi_create_uint32#

Added in: v8.4.0
N-API version: 1

napi_status napi_create_uint32(napi_env env, uint32_t value, napi_value* result) copy

[in] env: The environment that the API is invoked under.
[in] value: Unsigned integer value to be represented in JavaScript.
[out] result: A napi_value representing a JavaScript number.

Returns napi_ok if the API succeeded.
This API is used to convert from the C uint32_t type to the JavaScript
number type.
The JavaScript number type is described in
Section 6.1.6 of the ECMAScript Language Specification.

napi_create_int64#

Added in: v8.4.0
N-API version: 1

napi_status napi_create_int64(napi_env env, int64_t value, napi_value* result) copy

[in] env: The environment that the API is invoked under.
[in] value: Integer value to be represented in JavaScript.
[out] result: A napi_value representing a JavaScript number.

Returns napi_ok if the API succeeded.
This API is used to convert from the C int64_t type to the JavaScript
number type.
The JavaScript number type is described in Section 6.1.6
of the ECMAScript Language Specification. Note the complete range of int64_t
cannot be represented with full precision in JavaScript. Integer values
outside the range of Number.MIN_SAFE_INTEGER -(2**53 - 1) -
Number.MAX_SAFE_INTEGER (2**53 - 1) will lose precision.

napi_create_double#

Added in: v8.4.0
N-API version: 1

napi_status napi_create_double(napi_env env, double value, napi_value* result) copy

[in] env: The environment that the API is invoked under.
[in] value: Double-precision value to be represented in JavaScript.
[out] result: A napi_value representing a JavaScript number.

Returns napi_ok if the API succeeded.
This API is used to convert from the C double type to the JavaScript
number type.
The JavaScript number type is described in
Section 6.1.6 of the ECMAScript Language Specification.

napi_create_bigint_int64#

Added in: v10.7.0
N-API version: 6

napi_status napi_create_bigint_int64(napi_env env,
                                     int64_t value,
                                     napi_value* result); copy

[in] env: The environment that the API is invoked under.
[in] value: Integer value to be represented in JavaScript.
[out] result: A napi_value representing a JavaScript BigInt.

Returns napi_ok if the API succeeded.
This API converts the C int64_t type to the JavaScript BigInt type.

napi_create_bigint_uint64#

Added in: v10.7.0
N-API version: 6

napi_status napi_create_bigint_uint64(napi_env env,
                                      uint64_t value,
                                      napi_value* result); copy

[in] env: The environment that the API is invoked under.
[in] value: Unsigned integer value to be represented in JavaScript.
[out] result: A napi_value representing a JavaScript BigInt.

Returns napi_ok if the API succeeded.
This API converts the C uint64_t type to the JavaScript BigInt type.

napi_create_bigint_words#

Added in: v10.7.0
N-API version: 6

napi_status napi_create_bigint_words(napi_env env,
                                     int sign_bit,
                                     size_t word_count,
                                     const uint64_t* words,
                                     napi_value* result); copy

[in] env: The environment that the API is invoked under.
[in] sign_bit: Determines if the resulting BigInt will be positive or
negative.
[in] word_count: The length of the words array.
[in] words: An array of uint64_t little-endian 64-bit words.
[out] result: A napi_value representing a JavaScript BigInt.

Returns napi_ok if the API succeeded.
This API converts an array of unsigned 64-bit words into a single BigInt
value.
The resulting BigInt is calculated as: (–1)sign_bit (words[0]
× (264)0 + words[1] × (264)1 + …)

napi_create_string_latin1#

Added in: v8.0.0
N-API version: 1

napi_status napi_create_string_latin1(napi_env env,
                                      const char* str,
                                      size_t length,
                                      napi_value* result); copy

[in] env: The environment that the API is invoked under.
[in] str: Character buffer representing an ISO-8859-1-encoded string.
[in] length: The length of the string in bytes, or NAPI_AUTO_LENGTH if it
is null-terminated.
[out] result: A napi_value representing a JavaScript string.

Returns napi_ok if the API succeeded.
This API creates a JavaScript string value from an ISO-8859-1-encoded C
string. The native string is copied.
The JavaScript string type is described in
Section 6.1.4 of the ECMAScript Language Specification.

node_api_create_external_string_latin1#

Added in: v20.4.0, v18.18.0
N-API version: 10

napi_status
node_api_create_external_string_latin1(napi_env env,
                                       char* str,
                                       size_t length,
                                       napi_finalize finalize_callback,
                                       void* finalize_hint,
                                       napi_value* result,
                                       bool* copied); copy

[in] env: The environment that the API is invoked under.
[in] str: Character buffer representing an ISO-8859-1-encoded string.
[in] length: The length of the string in bytes, or NAPI_AUTO_LENGTH if it
is null-terminated.
[in] finalize_callback: The function to call when the string is being
collected. The function will be called with the following parameters:

[in] env: The environment in which the add-on is running. This value
may be null if the string is being collected as part of the termination
of the worker or the main Node.js instance.
[in] data: This is the value str as a void* pointer.
[in] finalize_hint: This is the value finalize_hint that was given
to the API.
napi_finalize provides more details.
This parameter is optional. Passing a null value means that the add-on
doesn't need to be notified when the corresponding JavaScript string is
collected.


[in] finalize_hint: Optional hint to pass to the finalize callback during
collection.
[out] result: A napi_value representing a JavaScript string.
[out] copied: Whether the string was copied. If it was, the finalizer will
already have been invoked to destroy str.

Returns napi_ok if the API succeeded.
This API creates a JavaScript string value from an ISO-8859-1-encoded C
string. The native string may not be copied and must thus exist for the entire
life cycle of the JavaScript value.
The JavaScript string type is described in
Section 6.1.4 of the ECMAScript Language Specification.

napi_create_string_utf16#

Added in: v8.0.0
N-API version: 1

napi_status napi_create_string_utf16(napi_env env,
                                     const char16_t* str,
                                     size_t length,
                                     napi_value* result) copy

[in] env: The environment that the API is invoked under.
[in] str: Character buffer representing a UTF16-LE-encoded string.
[in] length: The length of the string in two-byte code units, or
NAPI_AUTO_LENGTH if it is null-terminated.
[out] result: A napi_value representing a JavaScript string.

Returns napi_ok if the API succeeded.
This API creates a JavaScript string value from a UTF16-LE-encoded C string.
The native string is copied.
The JavaScript string type is described in
Section 6.1.4 of the ECMAScript Language Specification.

node_api_create_external_string_utf16#

Added in: v20.4.0, v18.18.0
N-API version: 10

napi_status
node_api_create_external_string_utf16(napi_env env,
                                      char16_t* str,
                                      size_t length,
                                      napi_finalize finalize_callback,
                                      void* finalize_hint,
                                      napi_value* result,
                                      bool* copied); copy

[in] env: The environment that the API is invoked under.
[in] str: Character buffer representing a UTF16-LE-encoded string.
[in] length: The length of the string in two-byte code units, or
NAPI_AUTO_LENGTH if it is null-terminated.
[in] finalize_callback: The function to call when the string is being
collected. The function will be called with the following parameters:

[in] env: The environment in which the add-on is running. This value
may be null if the string is being collected as part of the termination
of the worker or the main Node.js instance.
[in] data: This is the value str as a void* pointer.
[in] finalize_hint: This is the value finalize_hint that was given
to the API.
napi_finalize provides more details.
This parameter is optional. Passing a null value means that the add-on
doesn't need to be notified when the corresponding JavaScript string is
collected.


[in] finalize_hint: Optional hint to pass to the finalize callback during
collection.
[out] result: A napi_value representing a JavaScript string.
[out] copied: Whether the string was copied. If it was, the finalizer will
already have been invoked to destroy str.

Returns napi_ok if the API succeeded.
This API creates a JavaScript string value from a UTF16-LE-encoded C string.
The native string may not be copied and must thus exist for the entire life
cycle of the JavaScript value.
The JavaScript string type is described in
Section 6.1.4 of the ECMAScript Language Specification.

napi_create_string_utf8#

Added in: v8.0.0
N-API version: 1

napi_status napi_create_string_utf8(napi_env env,
                                    const char* str,
                                    size_t length,
                                    napi_value* result) copy

[in] env: The environment that the API is invoked under.
[in] str: Character buffer representing a UTF8-encoded string.
[in] length: The length of the string in bytes, or NAPI_AUTO_LENGTH if it
is null-terminated.
[out] result: A napi_value representing a JavaScript string.

Returns napi_ok if the API succeeded.
This API creates a JavaScript string value from a UTF8-encoded C string.
The native string is copied.
The JavaScript string type is described in
Section 6.1.4 of the ECMAScript Language Specification.

Functions to create optimized property keys#
Many JavaScript engines including V8 use internalized strings as keys
to set and get property values. They typically use a hash table to create
and lookup such strings. While it adds some cost per key creation, it improves
the performance after that by enabling comparison of string pointers instead
of the whole strings.
If a new JavaScript string is intended to be used as a property key, then for
some JavaScript engines it will be more efficient to use the functions in this
section. Otherwise, use the napi_create_string_utf8 or
node_api_create_external_string_utf8 series functions as there may be
additional overhead in creating/storing strings with the property key
creation methods.

node_api_create_property_key_latin1#

Added in: v22.9.0, v20.18.0
N-API version: 10

napi_status NAPI_CDECL node_api_create_property_key_latin1(napi_env env,
                                                           const char* str,
                                                           size_t length,
                                                           napi_value* result); copy

[in] env: The environment that the API is invoked under.
[in] str: Character buffer representing an ISO-8859-1-encoded string.
[in] length: The length of the string in bytes, or NAPI_AUTO_LENGTH if it
is null-terminated.
[out] result: A napi_value representing an optimized JavaScript string
to be used as a property key for objects.

Returns napi_ok if the API succeeded.
This API creates an optimized JavaScript string value from
an ISO-8859-1-encoded C string to be used as a property key for objects.
The native string is copied. In contrast with napi_create_string_latin1,
subsequent calls to this function with the same str pointer may benefit from a speedup
in the creation of the requested napi_value, depending on the engine.
The JavaScript string type is described in
Section 6.1.4 of the ECMAScript Language Specification.

node_api_create_property_key_utf16#

Added in: v21.7.0, v20.12.0
N-API version: 10

napi_status NAPI_CDECL node_api_create_property_key_utf16(napi_env env,
                                                          const char16_t* str,
                                                          size_t length,
                                                          napi_value* result); copy

[in] env: The environment that the API is invoked under.
[in] str: Character buffer representing a UTF16-LE-encoded string.
[in] length: The length of the string in two-byte code units, or
NAPI_AUTO_LENGTH if it is null-terminated.
[out] result: A napi_value representing an optimized JavaScript string
to be used as a property key for objects.

Returns napi_ok if the API succeeded.
This API creates an optimized JavaScript string value from
a UTF16-LE-encoded C string to be used as a property key for objects.
The native string is copied.
The JavaScript string type is described in
Section 6.1.4 of the ECMAScript Language Specification.

node_api_create_property_key_utf8#

Added in: v22.9.0, v20.18.0
N-API version: 10

napi_status NAPI_CDECL node_api_create_property_key_utf8(napi_env env,
                                                         const char* str,
                                                         size_t length,
                                                         napi_value* result); copy

[in] env: The environment that the API is invoked under.
[in] str: Character buffer representing a UTF8-encoded string.
[in] length: The length of the string in two-byte code units, or
NAPI_AUTO_LENGTH if it is null-terminated.
[out] result: A napi_value representing an optimized JavaScript string
to be used as a property key for objects.

Returns napi_ok if the API succeeded.
This API creates an optimized JavaScript string value from
a UTF8-encoded C string to be used as a property key for objects.
The native string is copied.
The JavaScript string type is described in
Section 6.1.4 of the ECMAScript Language Specification.

Functions to convert from Node-API to C types#

napi_get_array_length#

Added in: v8.0.0
N-API version: 1

napi_status napi_get_array_length(napi_env env,
                                  napi_value value,
                                  uint32_t* result) copy

[in] env: The environment that the API is invoked under.
[in] value: napi_value representing the JavaScript Array whose length is
being queried.
[out] result: uint32 representing length of the array.

Returns napi_ok if the API succeeded.
This API returns the length of an array.
Array length is described in Section 22.1.4.1 of the ECMAScript Language
Specification.

napi_get_arraybuffer_info#

Added in: v8.0.0
N-API version: 1

napi_status napi_get_arraybuffer_info(napi_env env,
                                      napi_value arraybuffer,
                                      void** data,
                                      size_t* byte_length) copy

[in] env: The environment that the API is invoked under.
[in] arraybuffer: napi_value representing the ArrayBuffer being queried.
[out] data: The underlying data buffer of the ArrayBuffer. If byte_length
is 0, this may be NULL or any other pointer value.
[out] byte_length: Length in bytes of the underlying data buffer.

Returns napi_ok if the API succeeded.
This API is used to retrieve the underlying data buffer of an ArrayBuffer and
its length.
WARNING: Use caution while using this API. The lifetime of the underlying data
buffer is managed by the ArrayBuffer even after it's returned. A
possible safe way to use this API is in conjunction with
napi_create_reference, which can be used to guarantee control over the
lifetime of the ArrayBuffer. It's also safe to use the returned data buffer
within the same callback as long as there are no calls to other APIs that might
trigger a GC.

napi_get_buffer_info#

Added in: v8.0.0
N-API version: 1

napi_status napi_get_buffer_info(napi_env env,
                                 napi_value value,
                                 void** data,
                                 size_t* length) copy

[in] env: The environment that the API is invoked under.
[in] value: napi_value representing the node::Buffer or Uint8Array
being queried.
[out] data: The underlying data buffer of the node::Buffer or
Uint8Array. If length is 0, this may be NULL or any other pointer value.
[out] length: Length in bytes of the underlying data buffer.

Returns napi_ok if the API succeeded.
This method returns the identical data and byte_length as
napi_get_typedarray_info. And napi_get_typedarray_info accepts a
node::Buffer (a Uint8Array) as the value too.
This API is used to retrieve the underlying data buffer of a node::Buffer
and its length.
Warning: Use caution while using this API since the underlying data buffer's
lifetime is not guaranteed if it's managed by the VM.

napi_get_prototype#

Added in: v8.0.0
N-API version: 1

napi_status napi_get_prototype(napi_env env,
                               napi_value object,
                               napi_value* result) copy

[in] env: The environment that the API is invoked under.
[in] object: napi_value representing JavaScript Object whose prototype
to return. This returns the equivalent of Object.getPrototypeOf (which is
not the same as the function's prototype property).
[out] result: napi_value representing prototype of the given object.

Returns napi_ok if the API succeeded.

napi_get_typedarray_info#

Added in: v8.0.0
N-API version: 1

napi_status napi_get_typedarray_info(napi_env env,
                                     napi_value typedarray,
                                     napi_typedarray_type* type,
                                     size_t* length,
                                     void** data,
                                     napi_value* arraybuffer,
                                     size_t* byte_offset) copy

[in] env: The environment that the API is invoked under.
[in] typedarray: napi_value representing the TypedArray whose
properties to query.
[out] type: Scalar datatype of the elements within the TypedArray.
[out] length: The number of elements in the TypedArray.
[out] data: The data buffer underlying the TypedArray adjusted by
the byte_offset value so that it points to the first element in the
TypedArray. If the length of the array is 0, this may be NULL or
any other pointer value.
[out] arraybuffer: The ArrayBuffer underlying the TypedArray.
[out] byte_offset: The byte offset within the underlying native array
at which the first element of the arrays is located. The value for the data
parameter has already been adjusted so that data points to the first element
in the array. Therefore, the first byte of the native array would be at
data - byte_offset.

Returns napi_ok if the API succeeded.
This API returns various properties of a typed array.
Any of the out parameters may be NULL if that property is unneeded.
Warning: Use caution while using this API since the underlying data buffer
is managed by the VM.

napi_get_dataview_info#

Added in: v8.3.0
N-API version: 1

napi_status napi_get_dataview_info(napi_env env,
                                   napi_value dataview,
                                   size_t* byte_length,
                                   void** data,
                                   napi_value* arraybuffer,
                                   size_t* byte_offset) copy

[in] env: The environment that the API is invoked under.
[in] dataview: napi_value representing the DataView whose
properties to query.
[out] byte_length: Number of bytes in the DataView.
[out] data: The data buffer underlying the DataView.
If byte_length is 0, this may be NULL or any other pointer value.
[out] arraybuffer: ArrayBuffer underlying the DataView.
[out] byte_offset: The byte offset within the data buffer from which
to start projecting the DataView.

Returns napi_ok if the API succeeded.
Any of the out parameters may be NULL if that property is unneeded.
This API returns various properties of a DataView.

napi_get_date_value#

Added in: v11.11.0, v10.17.0
N-API version: 5

napi_status napi_get_date_value(napi_env env,
                                napi_value value,
                                double* result) copy

[in] env: The environment that the API is invoked under.
[in] value: napi_value representing a JavaScript Date.
[out] result: Time value as a double represented as milliseconds since
midnight at the beginning of 01 January, 1970 UTC.

This API does not observe leap seconds; they are ignored, as
ECMAScript aligns with POSIX time specification.
Returns napi_ok if the API succeeded. If a non-date napi_value is passed
in it returns napi_date_expected.
This API returns the C double primitive of time value for the given JavaScript
Date.

napi_get_value_bool#

Added in: v8.0.0
N-API version: 1

napi_status napi_get_value_bool(napi_env env, napi_value value, bool* result) copy

[in] env: The environment that the API is invoked under.
[in] value: napi_value representing JavaScript Boolean.
[out] result: C boolean primitive equivalent of the given JavaScript
Boolean.

Returns napi_ok if the API succeeded. If a non-boolean napi_value is
passed in it returns napi_boolean_expected.
This API returns the C boolean primitive equivalent of the given JavaScript
Boolean.

napi_get_value_double#

Added in: v8.0.0
N-API version: 1

napi_status napi_get_value_double(napi_env env,
                                  napi_value value,
                                  double* result) copy

[in] env: The environment that the API is invoked under.
[in] value: napi_value representing JavaScript number.
[out] result: C double primitive equivalent of the given JavaScript
number.

Returns napi_ok if the API succeeded. If a non-number napi_value is passed
in it returns napi_number_expected.
This API returns the C double primitive equivalent of the given JavaScript
number.

napi_get_value_bigint_int64#

Added in: v10.7.0
N-API version: 6

napi_status napi_get_value_bigint_int64(napi_env env,
                                        napi_value value,
                                        int64_t* result,
                                        bool* lossless); copy

[in] env: The environment that the API is invoked under
[in] value: napi_value representing JavaScript BigInt.
[out] result: C int64_t primitive equivalent of the given JavaScript
BigInt.
[out] lossless: Indicates whether the BigInt value was converted
losslessly.

Returns napi_ok if the API succeeded. If a non-BigInt is passed in it
returns napi_bigint_expected.
This API returns the C int64_t primitive equivalent of the given JavaScript
BigInt. If needed it will truncate the value, setting lossless to false.

napi_get_value_bigint_uint64#

Added in: v10.7.0
N-API version: 6

napi_status napi_get_value_bigint_uint64(napi_env env,
                                        napi_value value,
                                        uint64_t* result,
                                        bool* lossless); copy

[in] env: The environment that the API is invoked under.
[in] value: napi_value representing JavaScript BigInt.
[out] result: C uint64_t primitive equivalent of the given JavaScript
BigInt.
[out] lossless: Indicates whether the BigInt value was converted
losslessly.

Returns napi_ok if the API succeeded. If a non-BigInt is passed in it
returns napi_bigint_expected.
This API returns the C uint64_t primitive equivalent of the given JavaScript
BigInt. If needed it will truncate the value, setting lossless to false.

napi_get_value_bigint_words#

Added in: v10.7.0
N-API version: 6

napi_status napi_get_value_bigint_words(napi_env env,
                                        napi_value value,
                                        int* sign_bit,
                                        size_t* word_count,
                                        uint64_t* words); copy

[in] env: The environment that the API is invoked under.
[in] value: napi_value representing JavaScript BigInt.
[out] sign_bit: Integer representing if the JavaScript BigInt is positive
or negative.
[in/out] word_count: Must be initialized to the length of the words
array. Upon return, it will be set to the actual number of words that
would be needed to store this BigInt.
[out] words: Pointer to a pre-allocated 64-bit word array.

Returns napi_ok if the API succeeded.
This API converts a single BigInt value into a sign bit, 64-bit little-endian
array, and the number of elements in the array. sign_bit and words may be
both set to NULL, in order to get only word_count.

napi_get_value_external#

Added in: v8.0.0
N-API version: 1

napi_status napi_get_value_external(napi_env env,
                                    napi_value value,
                                    void** result) copy

[in] env: The environment that the API is invoked under.
[in] value: napi_value representing JavaScript external value.
[out] result: Pointer to the data wrapped by the JavaScript external value.

Returns napi_ok if the API succeeded. If a non-external napi_value is
passed in it returns napi_invalid_arg.
This API retrieves the external data pointer that was previously passed to
napi_create_external().

napi_get_value_int32#

Added in: v8.0.0
N-API version: 1

napi_status napi_get_value_int32(napi_env env,
                                 napi_value value,
                                 int32_t* result) copy

[in] env: The environment that the API is invoked under.
[in] value: napi_value representing JavaScript number.
[out] result: C int32 primitive equivalent of the given JavaScript
number.

Returns napi_ok if the API succeeded. If a non-number napi_value
is passed in napi_number_expected.
This API returns the C int32 primitive equivalent
of the given JavaScript number.
If the number exceeds the range of the 32 bit integer, then the result is
truncated to the equivalent of the bottom 32 bits. This can result in a large
positive number becoming a negative number if the value is > 231 - 1.
Non-finite number values (NaN, +Infinity, or -Infinity) set the
result to zero.

napi_get_value_int64#

Added in: v8.0.0
N-API version: 1

napi_status napi_get_value_int64(napi_env env,
                                 napi_value value,
                                 int64_t* result) copy

[in] env: The environment that the API is invoked under.
[in] value: napi_value representing JavaScript number.
[out] result: C int64 primitive equivalent of the given JavaScript
number.

Returns napi_ok if the API succeeded. If a non-number napi_value
is passed in it returns napi_number_expected.
This API returns the C int64 primitive equivalent of the given JavaScript
number.
number values outside the range of Number.MIN_SAFE_INTEGER
-(2**53 - 1) - Number.MAX_SAFE_INTEGER (2**53 - 1) will lose
precision.
Non-finite number values (NaN, +Infinity, or -Infinity) set the
result to zero.

napi_get_value_string_latin1#

Added in: v8.0.0
N-API version: 1

napi_status napi_get_value_string_latin1(napi_env env,
                                         napi_value value,
                                         char* buf,
                                         size_t bufsize,
                                         size_t* result) copy

[in] env: The environment that the API is invoked under.
[in] value: napi_value representing JavaScript string.
[in] buf: Buffer to write the ISO-8859-1-encoded string into. If NULL is
passed in, the length of the string in bytes and excluding the null terminator
is returned in result.
[in] bufsize: Size of the destination buffer. When this value is
insufficient, the returned string is truncated and null-terminated.
[out] result: Number of bytes copied into the buffer, excluding the null
terminator.

Returns napi_ok if the API succeeded. If a non-string napi_value
is passed in it returns napi_string_expected.
This API returns the ISO-8859-1-encoded string corresponding the value passed
in.

napi_get_value_string_utf8#

Added in: v8.0.0
N-API version: 1

napi_status napi_get_value_string_utf8(napi_env env,
                                       napi_value value,
                                       char* buf,
                                       size_t bufsize,
                                       size_t* result) copy

[in] env: The environment that the API is invoked under.
[in] value: napi_value representing JavaScript string.
[in] buf: Buffer to write the UTF8-encoded string into. If NULL is passed
in, the length of the string in bytes and excluding the null terminator is
returned in result.
[in] bufsize: Size of the destination buffer. When this value is
insufficient, the returned string is truncated and null-terminated.
[out] result: Number of bytes copied into the buffer, excluding the null
terminator.

Returns napi_ok if the API succeeded. If a non-string napi_value
is passed in it returns napi_string_expected.
This API returns the UTF8-encoded string corresponding the value passed in.

napi_get_value_string_utf16#

Added in: v8.0.0
N-API version: 1

napi_status napi_get_value_string_utf16(napi_env env,
                                        napi_value value,
                                        char16_t* buf,
                                        size_t bufsize,
                                        size_t* result) copy

[in] env: The environment that the API is invoked under.
[in] value: napi_value representing JavaScript string.
[in] buf: Buffer to write the UTF16-LE-encoded string into. If NULL is
passed in, the length of the string in 2-byte code units and excluding the
null terminator is returned.
[in] bufsize: Size of the destination buffer. When this value is
insufficient, the returned string is truncated and null-terminated.
[out] result: Number of 2-byte code units copied into the buffer, excluding
the null terminator.

Returns napi_ok if the API succeeded. If a non-string napi_value
is passed in it returns napi_string_expected.
This API returns the UTF16-encoded string corresponding the value passed in.

napi_get_value_uint32#

Added in: v8.0.0
N-API version: 1

napi_status napi_get_value_uint32(napi_env env,
                                  napi_value value,
                                  uint32_t* result) copy

[in] env: The environment that the API is invoked under.
[in] value: napi_value representing JavaScript number.
[out] result: C primitive equivalent of the given napi_value as a
uint32_t.

Returns napi_ok if the API succeeded. If a non-number napi_value
is passed in it returns napi_number_expected.
This API returns the C primitive equivalent of the given napi_value as a
uint32_t.

Functions to get global instances#

napi_get_boolean#

Added in: v8.0.0
N-API version: 1

napi_status napi_get_boolean(napi_env env, bool value, napi_value* result) copy

[in] env: The environment that the API is invoked under.
[in] value: The value of the boolean to retrieve.
[out] result: napi_value representing JavaScript Boolean singleton to
retrieve.

Returns napi_ok if the API succeeded.
This API is used to return the JavaScript singleton object that is used to
represent the given boolean value.

napi_get_global#

Added in: v8.0.0
N-API version: 1

napi_status napi_get_global(napi_env env, napi_value* result) copy

[in] env: The environment that the API is invoked under.
[out] result: napi_value representing JavaScript global object.

Returns napi_ok if the API succeeded.
This API returns the global object.

napi_get_null#

Added in: v8.0.0
N-API version: 1

napi_status napi_get_null(napi_env env, napi_value* result) copy

[in] env: The environment that the API is invoked under.
[out] result: napi_value representing JavaScript null object.

Returns napi_ok if the API succeeded.
This API returns the null object.

napi_get_undefined#

Added in: v8.0.0
N-API version: 1

napi_status napi_get_undefined(napi_env env, napi_value* result) copy

[in] env: The environment that the API is invoked under.
[out] result: napi_value representing JavaScript Undefined value.

Returns napi_ok if the API succeeded.
This API returns the Undefined object.

Working with JavaScript values and abstract operations#
Node-API exposes a set of APIs to perform some abstract operations on JavaScript
values. Some of these operations are documented under Section 7
of the ECMAScript Language Specification.
These APIs support doing one of the following:

Coerce JavaScript values to specific JavaScript types (such as number or
string).
Check the type of a JavaScript value.
Check for equality between two JavaScript values.


napi_coerce_to_bool#

Added in: v8.0.0
N-API version: 1

napi_status napi_coerce_to_bool(napi_env env,
                                napi_value value,
                                napi_value* result) copy

[in] env: The environment that the API is invoked under.
[in] value: The JavaScript value to coerce.
[out] result: napi_value representing the coerced JavaScript Boolean.

Returns napi_ok if the API succeeded.
This API implements the abstract operation ToBoolean() as defined in
Section 7.1.2 of the ECMAScript Language Specification.

napi_coerce_to_number#

Added in: v8.0.0
N-API version: 1

napi_status napi_coerce_to_number(napi_env env,
                                  napi_value value,
                                  napi_value* result) copy

[in] env: The environment that the API is invoked under.
[in] value: The JavaScript value to coerce.
[out] result: napi_value representing the coerced JavaScript number.

Returns napi_ok if the API succeeded.
This API implements the abstract operation ToNumber() as defined in
Section 7.1.3 of the ECMAScript Language Specification.
This function potentially runs JS code if the passed-in value is an
object.

napi_coerce_to_object#

Added in: v8.0.0
N-API version: 1

napi_status napi_coerce_to_object(napi_env env,
                                  napi_value value,
                                  napi_value* result) copy

[in] env: The environment that the API is invoked under.
[in] value: The JavaScript value to coerce.
[out] result: napi_value representing the coerced JavaScript Object.

Returns napi_ok if the API succeeded.
This API implements the abstract operation ToObject() as defined in
Section 7.1.13 of the ECMAScript Language Specification.

napi_coerce_to_string#

Added in: v8.0.0
N-API version: 1

napi_status napi_coerce_to_string(napi_env env,
                                  napi_value value,
                                  napi_value* result) copy

[in] env: The environment that the API is invoked under.
[in] value: The JavaScript value to coerce.
[out] result: napi_value representing the coerced JavaScript string.

Returns napi_ok if the API succeeded.
This API implements the abstract operation ToString() as defined in
Section 7.1.13 of the ECMAScript Language Specification.
This function potentially runs JS code if the passed-in value is an
object.

napi_typeof#

Added in: v8.0.0
N-API version: 1

napi_status napi_typeof(napi_env env, napi_value value, napi_valuetype* result) copy

[in] env: The environment that the API is invoked under.
[in] value: The JavaScript value whose type to query.
[out] result: The type of the JavaScript value.

Returns napi_ok if the API succeeded.

napi_invalid_arg if the type of value is not a known ECMAScript type and
value is not an External value.

This API represents behavior similar to invoking the typeof Operator on
the object as defined in Section 12.5.5 of the ECMAScript Language
Specification. However, there are some differences:

It has support for detecting an External value.
It detects null as a separate type, while ECMAScript typeof would detect
object.

If value has a type that is invalid, an error is returned.

napi_instanceof#

Added in: v8.0.0
N-API version: 1

napi_status napi_instanceof(napi_env env,
                            napi_value object,
                            napi_value constructor,
                            bool* result) copy

[in] env: The environment that the API is invoked under.
[in] object: The JavaScript value to check.
[in] constructor: The JavaScript function object of the constructor function
to check against.
[out] result: Boolean that is set to true if object instanceof constructor
is true.

Returns napi_ok if the API succeeded.
This API represents invoking the instanceof Operator on the object as
defined in Section 12.10.4 of the ECMAScript Language Specification.

napi_is_array#

Added in: v8.0.0
N-API version: 1

napi_status napi_is_array(napi_env env, napi_value value, bool* result) copy

[in] env: The environment that the API is invoked under.
[in] value: The JavaScript value to check.
[out] result: Whether the given object is an array.

Returns napi_ok if the API succeeded.
This API represents invoking the IsArray operation on the object
as defined in Section 7.2.2 of the ECMAScript Language Specification.

napi_is_arraybuffer#

Added in: v8.0.0
N-API version: 1

napi_status napi_is_arraybuffer(napi_env env, napi_value value, bool* result) copy

[in] env: The environment that the API is invoked under.
[in] value: The JavaScript value to check.
[out] result: Whether the given object is an ArrayBuffer.

Returns napi_ok if the API succeeded.
This API checks if the Object passed in is an array buffer.

napi_is_buffer#

Added in: v8.0.0
N-API version: 1

napi_status napi_is_buffer(napi_env env, napi_value value, bool* result) copy

[in] env: The environment that the API is invoked under.
[in] value: The JavaScript value to check.
[out] result: Whether the given napi_value represents a node::Buffer or
Uint8Array object.

Returns napi_ok if the API succeeded.
This API checks if the Object passed in is a buffer or Uint8Array.
napi_is_typedarray should be preferred if the caller needs to check if the
value is a Uint8Array.

napi_is_date#

Added in: v11.11.0, v10.17.0
N-API version: 5

napi_status napi_is_date(napi_env env, napi_value value, bool* result) copy

[in] env: The environment that the API is invoked under.
[in] value: The JavaScript value to check.
[out] result: Whether the given napi_value represents a JavaScript Date
object.

Returns napi_ok if the API succeeded.
This API checks if the Object passed in is a date.

napi_is_error#

Added in: v8.0.0
N-API version: 1

napi_status napi_is_error(napi_env env, napi_value value, bool* result) copy

[in] env: The environment that the API is invoked under.
[in] value: The JavaScript value to check.
[out] result: Whether the given napi_value represents an Error object.

Returns napi_ok if the API succeeded.
This API checks if the Object passed in is an Error.

napi_is_typedarray#

Added in: v8.0.0
N-API version: 1

napi_status napi_is_typedarray(napi_env env, napi_value value, bool* result) copy

[in] env: The environment that the API is invoked under.
[in] value: The JavaScript value to check.
[out] result: Whether the given napi_value represents a TypedArray.

Returns napi_ok if the API succeeded.
This API checks if the Object passed in is a typed array.

napi_is_dataview#

Added in: v8.3.0
N-API version: 1

napi_status napi_is_dataview(napi_env env, napi_value value, bool* result) copy

[in] env: The environment that the API is invoked under.
[in] value: The JavaScript value to check.
[out] result: Whether the given napi_value represents a DataView.

Returns napi_ok if the API succeeded.
This API checks if the Object passed in is a DataView.

napi_strict_equals#

Added in: v8.0.0
N-API version: 1

napi_status napi_strict_equals(napi_env env,
                               napi_value lhs,
                               napi_value rhs,
                               bool* result) copy

[in] env: The environment that the API is invoked under.
[in] lhs: The JavaScript value to check.
[in] rhs: The JavaScript value to check against.
[out] result: Whether the two napi_value objects are equal.

Returns napi_ok if the API succeeded.
This API represents the invocation of the Strict Equality algorithm as
defined in Section 7.2.14 of the ECMAScript Language Specification.

napi_detach_arraybuffer#

Added in: v13.0.0, v12.16.0, v10.22.0
N-API version: 7

napi_status napi_detach_arraybuffer(napi_env env,
                                    napi_value arraybuffer) copy

[in] env: The environment that the API is invoked under.
[in] arraybuffer: The JavaScript ArrayBuffer to be detached.

Returns napi_ok if the API succeeded. If a non-detachable ArrayBuffer is
passed in it returns napi_detachable_arraybuffer_expected.
Generally, an ArrayBuffer is non-detachable if it has been detached before.
The engine may impose additional conditions on whether an ArrayBuffer is
detachable. For example, V8 requires that the ArrayBuffer be external,
that is, created with napi_create_external_arraybuffer.
This API represents the invocation of the ArrayBuffer detach operation as
defined in Section 24.1.1.3 of the ECMAScript Language Specification.

napi_is_detached_arraybuffer#

Added in: v13.3.0, v12.16.0, v10.22.0
N-API version: 7

napi_status napi_is_detached_arraybuffer(napi_env env,
                                         napi_value arraybuffer,
                                         bool* result) copy

[in] env: The environment that the API is invoked under.
[in] arraybuffer: The JavaScript ArrayBuffer to be checked.
[out] result: Whether the arraybuffer is detached.

Returns napi_ok if the API succeeded.
The ArrayBuffer is considered detached if its internal data is null.
This API represents the invocation of the ArrayBuffer IsDetachedBuffer
operation as defined in Section 24.1.1.2 of the ECMAScript Language
Specification.

Working with JavaScript properties#
Node-API exposes a set of APIs to get and set properties on JavaScript
objects. Some of these types are documented under Section 7 of the
ECMAScript Language Specification.
Properties in JavaScript are represented as a tuple of a key and a value.
Fundamentally, all property keys in Node-API can be represented in one of the
following forms:

Named: a simple UTF8-encoded string
Integer-Indexed: an index value represented by uint32_t
JavaScript value: these are represented in Node-API by napi_value. This can
be a napi_value representing a string, number, or symbol.

Node-API values are represented by the type napi_value.
Any Node-API call that requires a JavaScript value takes in a napi_value.
However, it's the caller's responsibility to make sure that the
napi_value in question is of the JavaScript type expected by the API.
The APIs documented in this section provide a simple interface to
get and set properties on arbitrary JavaScript objects represented by
napi_value.
For instance, consider the following JavaScript code snippet:
const obj = {};
obj.myProp = 123; copy
The equivalent can be done using Node-API values with the following snippet:
napi_status status = napi_generic_failure;

// const obj = {}
napi_value obj, value;
status = napi_create_object(env, &obj);
if (status != napi_ok) return status;

// Create a napi_value for 123
status = napi_create_int32(env, 123, &value);
if (status != napi_ok) return status;

// obj.myProp = 123
status = napi_set_named_property(env, obj, "myProp", value);
if (status != napi_ok) return status; copy
Indexed properties can be set in a similar manner. Consider the following
JavaScript snippet:
const arr = [];
arr[123] = 'hello'; copy
The equivalent can be done using Node-API values with the following snippet:
napi_status status = napi_generic_failure;

// const arr = [];
napi_value arr, value;
status = napi_create_array(env, &arr);
if (status != napi_ok) return status;

// Create a napi_value for 'hello'
status = napi_create_string_utf8(env, "hello", NAPI_AUTO_LENGTH, &value);
if (status != napi_ok) return status;

// arr[123] = 'hello';
status = napi_set_element(env, arr, 123, value);
if (status != napi_ok) return status; copy
Properties can be retrieved using the APIs described in this section.
Consider the following JavaScript snippet:
const arr = [];
const value = arr[123]; copy
The following is the approximate equivalent of the Node-API counterpart:
napi_status status = napi_generic_failure;

// const arr = []
napi_value arr, value;
status = napi_create_array(env, &arr);
if (status != napi_ok) return status;

// const value = arr[123]
status = napi_get_element(env, arr, 123, &value);
if (status != napi_ok) return status; copy
Finally, multiple properties can also be defined on an object for performance
reasons. Consider the following JavaScript:
const obj = {};
Object.defineProperties(obj, {
  'foo': { value: 123, writable: true, configurable: true, enumerable: true },
  'bar': { value: 456, writable: true, configurable: true, enumerable: true },
}); copy
The following is the approximate equivalent of the Node-API counterpart:
napi_status status = napi_status_generic_failure;

// const obj = {};
napi_value obj;
status = napi_create_object(env, &obj);
if (status != napi_ok) return status;

// Create napi_values for 123 and 456
napi_value fooValue, barValue;
status = napi_create_int32(env, 123, &fooValue);
if (status != napi_ok) return status;
status = napi_create_int32(env, 456, &barValue);
if (status != napi_ok) return status;

// Set the properties
napi_property_descriptor descriptors[] = {
  { "foo", NULL, NULL, NULL, NULL, fooValue, napi_writable | napi_configurable, NULL },
  { "bar", NULL, NULL, NULL, NULL, barValue, napi_writable | napi_configurable, NULL }
}
status = napi_define_properties(env,
                                obj,
                                sizeof(descriptors) / sizeof(descriptors[0]),
                                descriptors);
if (status != napi_ok) return status; copy

Structures#

napi_property_attributes#

History

VersionChanges
v14.12.0
added napi_default_method and napi_default_property.



typedef enum {
  napi_default = 0,
  napi_writable = 1 << 0,
  napi_enumerable = 1 << 1,
  napi_configurable = 1 << 2,

  // Used with napi_define_class to distinguish static properties
  // from instance properties. Ignored by napi_define_properties.
  napi_static = 1 << 10,

  // Default for class methods.
  napi_default_method = napi_writable | napi_configurable,

  // Default for object properties, like in JS obj[prop].
  napi_default_jsproperty = napi_writable |
                          napi_enumerable |
                          napi_configurable,
} napi_property_attributes; copy
napi_property_attributes are flags used to control the behavior of properties
set on a JavaScript object. Other than napi_static they correspond to the
attributes listed in Section 6.1.7.1
of the ECMAScript Language Specification.
They can be one or more of the following bitflags:

napi_default: No explicit attributes are set on the property. By default, a
property is read only, not enumerable and not configurable.
napi_writable: The property is writable.
napi_enumerable: The property is enumerable.
napi_configurable: The property is configurable as defined in
Section 6.1.7.1 of the ECMAScript Language Specification.
napi_static: The property will be defined as a static property on a class as
opposed to an instance property, which is the default. This is used only by
napi_define_class. It is ignored by napi_define_properties.
napi_default_method: Like a method in a JS class, the property is
configurable and writeable, but not enumerable.
napi_default_jsproperty: Like a property set via assignment in JavaScript,
the property is writable, enumerable, and configurable.


napi_property_descriptor#
typedef struct {
  // One of utf8name or name should be NULL.
  const char* utf8name;
  napi_value name;

  napi_callback method;
  napi_callback getter;
  napi_callback setter;
  napi_value value;

  napi_property_attributes attributes;
  void* data;
} napi_property_descriptor; copy

utf8name: Optional string describing the key for the property,
encoded as UTF8. One of utf8name or name must be provided for the
property.
name: Optional napi_value that points to a JavaScript string or symbol
to be used as the key for the property. One of utf8name or name must
be provided for the property.
value: The value that's retrieved by a get access of the property if the
property is a data property. If this is passed in, set getter, setter,
method and data to NULL (since these members won't be used).
getter: A function to call when a get access of the property is performed.
If this is passed in, set value and method to NULL (since these members
won't be used). The given function is called implicitly by the runtime when
the property is accessed from JavaScript code (or if a get on the property is
performed using a Node-API call). napi_callback provides more details.
setter: A function to call when a set access of the property is performed.
If this is passed in, set value and method to NULL (since these members
won't be used). The given function is called implicitly by the runtime when
the property is set from JavaScript code (or if a set on the property is
performed using a Node-API call). napi_callback provides more details.
method: Set this to make the property descriptor object's value
property to be a JavaScript function represented by method. If this is
passed in, set value, getter and setter to NULL (since these members
won't be used). napi_callback provides more details.
attributes: The attributes associated with the particular property. See
napi_property_attributes.
data: The callback data passed into method, getter and setter if this
function is invoked.


Functions#

napi_get_property_names#

Added in: v8.0.0
N-API version: 1

napi_status napi_get_property_names(napi_env env,
                                    napi_value object,
                                    napi_value* result); copy

[in] env: The environment that the Node-API call is invoked under.
[in] object: The object from which to retrieve the properties.
[out] result: A napi_value representing an array of JavaScript values
that represent the property names of the object. The API can be used to
iterate over result using napi_get_array_length
and napi_get_element.

Returns napi_ok if the API succeeded.
This API returns the names of the enumerable properties of object as an array
of strings. The properties of object whose key is a symbol will not be
included.

napi_get_all_property_names#

Added in: v13.7.0, v12.17.0, v10.20.0
N-API version: 6

napi_get_all_property_names(napi_env env,
                            napi_value object,
                            napi_key_collection_mode key_mode,
                            napi_key_filter key_filter,
                            napi_key_conversion key_conversion,
                            napi_value* result); copy

[in] env: The environment that the Node-API call is invoked under.
[in] object: The object from which to retrieve the properties.
[in] key_mode: Whether to retrieve prototype properties as well.
[in] key_filter: Which properties to retrieve
(enumerable/readable/writable).
[in] key_conversion: Whether to convert numbered property keys to strings.
[out] result: A napi_value representing an array of JavaScript values
that represent the property names of the object. napi_get_array_length
and napi_get_element can be used to iterate over result.

Returns napi_ok if the API succeeded.
This API returns an array containing the names of the available properties
of this object.

napi_set_property#

Added in: v8.0.0
N-API version: 1

napi_status napi_set_property(napi_env env,
                              napi_value object,
                              napi_value key,
                              napi_value value); copy

[in] env: The environment that the Node-API call is invoked under.
[in] object: The object on which to set the property.
[in] key: The name of the property to set.
[in] value: The property value.

Returns napi_ok if the API succeeded.
This API set a property on the Object passed in.

napi_get_property#

Added in: v8.0.0
N-API version: 1

napi_status napi_get_property(napi_env env,
                              napi_value object,
                              napi_value key,
                              napi_value* result); copy

[in] env: The environment that the Node-API call is invoked under.
[in] object: The object from which to retrieve the property.
[in] key: The name of the property to retrieve.
[out] result: The value of the property.

Returns napi_ok if the API succeeded.
This API gets the requested property from the Object passed in.

napi_has_property#

Added in: v8.0.0
N-API version: 1

napi_status napi_has_property(napi_env env,
                              napi_value object,
                              napi_value key,
                              bool* result); copy

[in] env: The environment that the Node-API call is invoked under.
[in] object: The object to query.
[in] key: The name of the property whose existence to check.
[out] result: Whether the property exists on the object or not.

Returns napi_ok if the API succeeded.
This API checks if the Object passed in has the named property.

napi_delete_property#

Added in: v8.2.0
N-API version: 1

napi_status napi_delete_property(napi_env env,
                                 napi_value object,
                                 napi_value key,
                                 bool* result); copy

[in] env: The environment that the Node-API call is invoked under.
[in] object: The object to query.
[in] key: The name of the property to delete.
[out] result: Whether the property deletion succeeded or not. result can
optionally be ignored by passing NULL.

Returns napi_ok if the API succeeded.
This API attempts to delete the key own property from object.

napi_has_own_property#

Added in: v8.2.0
N-API version: 1

napi_status napi_has_own_property(napi_env env,
                                  napi_value object,
                                  napi_value key,
                                  bool* result); copy

[in] env: The environment that the Node-API call is invoked under.
[in] object: The object to query.
[in] key: The name of the own property whose existence to check.
[out] result: Whether the own property exists on the object or not.

Returns napi_ok if the API succeeded.
This API checks if the Object passed in has the named own property. key must
be a string or a symbol, or an error will be thrown. Node-API will not
perform any conversion between data types.

napi_set_named_property#

Added in: v8.0.0
N-API version: 1

napi_status napi_set_named_property(napi_env env,
                                    napi_value object,
                                    const char* utf8Name,
                                    napi_value value); copy

[in] env: The environment that the Node-API call is invoked under.
[in] object: The object on which to set the property.
[in] utf8Name: The name of the property to set.
[in] value: The property value.

Returns napi_ok if the API succeeded.
This method is equivalent to calling napi_set_property with a napi_value
created from the string passed in as utf8Name.

napi_get_named_property#

Added in: v8.0.0
N-API version: 1

napi_status napi_get_named_property(napi_env env,
                                    napi_value object,
                                    const char* utf8Name,
                                    napi_value* result); copy

[in] env: The environment that the Node-API call is invoked under.
[in] object: The object from which to retrieve the property.
[in] utf8Name: The name of the property to get.
[out] result: The value of the property.

Returns napi_ok if the API succeeded.
This method is equivalent to calling napi_get_property with a napi_value
created from the string passed in as utf8Name.

napi_has_named_property#

Added in: v8.0.0
N-API version: 1

napi_status napi_has_named_property(napi_env env,
                                    napi_value object,
                                    const char* utf8Name,
                                    bool* result); copy

[in] env: The environment that the Node-API call is invoked under.
[in] object: The object to query.
[in] utf8Name: The name of the property whose existence to check.
[out] result: Whether the property exists on the object or not.

Returns napi_ok if the API succeeded.
This method is equivalent to calling napi_has_property with a napi_value
created from the string passed in as utf8Name.

napi_set_element#

Added in: v8.0.0
N-API version: 1

napi_status napi_set_element(napi_env env,
                             napi_value object,
                             uint32_t index,
                             napi_value value); copy

[in] env: The environment that the Node-API call is invoked under.
[in] object: The object from which to set the properties.
[in] index: The index of the property to set.
[in] value: The property value.

Returns napi_ok if the API succeeded.
This API sets an element on the Object passed in.

napi_get_element#

Added in: v8.0.0
N-API version: 1

napi_status napi_get_element(napi_env env,
                             napi_value object,
                             uint32_t index,
                             napi_value* result); copy

[in] env: The environment that the Node-API call is invoked under.
[in] object: The object from which to retrieve the property.
[in] index: The index of the property to get.
[out] result: The value of the property.

Returns napi_ok if the API succeeded.
This API gets the element at the requested index.

napi_has_element#

Added in: v8.0.0
N-API version: 1

napi_status napi_has_element(napi_env env,
                             napi_value object,
                             uint32_t index,
                             bool* result); copy

[in] env: The environment that the Node-API call is invoked under.
[in] object: The object to query.
[in] index: The index of the property whose existence to check.
[out] result: Whether the property exists on the object or not.

Returns napi_ok if the API succeeded.
This API returns if the Object passed in has an element at the
requested index.

napi_delete_element#

Added in: v8.2.0
N-API version: 1

napi_status napi_delete_element(napi_env env,
                                napi_value object,
                                uint32_t index,
                                bool* result); copy

[in] env: The environment that the Node-API call is invoked under.
[in] object: The object to query.
[in] index: The index of the property to delete.
[out] result: Whether the element deletion succeeded or not. result can
optionally be ignored by passing NULL.

Returns napi_ok if the API succeeded.
This API attempts to delete the specified index from object.

napi_define_properties#

Added in: v8.0.0
N-API version: 1

napi_status napi_define_properties(napi_env env,
                                   napi_value object,
                                   size_t property_count,
                                   const napi_property_descriptor* properties); copy

[in] env: The environment that the Node-API call is invoked under.
[in] object: The object from which to retrieve the properties.
[in] property_count: The number of elements in the properties array.
[in] properties: The array of property descriptors.

Returns napi_ok if the API succeeded.
This method allows the efficient definition of multiple properties on a given
object. The properties are defined using property descriptors (see
napi_property_descriptor). Given an array of such property descriptors,
this API will set the properties on the object one at a time, as defined by
DefineOwnProperty() (described in Section 9.1.6 of the ECMA-262
specification).

napi_object_freeze#

Added in: v14.14.0, v12.20.0
N-API version: 8

napi_status napi_object_freeze(napi_env env,
                               napi_value object); copy

[in] env: The environment that the Node-API call is invoked under.
[in] object: The object to freeze.

Returns napi_ok if the API succeeded.
This method freezes a given object. This prevents new properties from
being added to it, existing properties from being removed, prevents
changing the enumerability, configurability, or writability of existing
properties, and prevents the values of existing properties from being changed.
It also prevents the object's prototype from being changed. This is described
in Section 19.1.2.6 of the
ECMA-262 specification.

napi_object_seal#

Added in: v14.14.0, v12.20.0
N-API version: 8

napi_status napi_object_seal(napi_env env,
                             napi_value object); copy

[in] env: The environment that the Node-API call is invoked under.
[in] object: The object to seal.

Returns napi_ok if the API succeeded.
This method seals a given object. This prevents new properties from being
added to it, as well as marking all existing properties as non-configurable.
This is described in Section 19.1.2.20
of the ECMA-262 specification.

Working with JavaScript functions#
Node-API provides a set of APIs that allow JavaScript code to
call back into native code. Node-APIs that support calling back
into native code take in a callback functions represented by
the napi_callback type. When the JavaScript VM calls back to
native code, the napi_callback function provided is invoked. The APIs
documented in this section allow the callback function to do the
following:

Get information about the context in which the callback was invoked.
Get the arguments passed into the callback.
Return a napi_value back from the callback.

Additionally, Node-API provides a set of functions which allow calling
JavaScript functions from native code. One can either call a function
like a regular JavaScript function call, or as a constructor
function.
Any non-NULL data which is passed to this API via the data field of the
napi_property_descriptor items can be associated with object and freed
whenever object is garbage-collected by passing both object and the data to
napi_add_finalizer.

napi_call_function#

Added in: v8.0.0
N-API version: 1

NAPI_EXTERN napi_status napi_call_function(napi_env env,
                                           napi_value recv,
                                           napi_value func,
                                           size_t argc,
                                           const napi_value* argv,
                                           napi_value* result); copy

[in] env: The environment that the API is invoked under.
[in] recv: The this value passed to the called function.
[in] func: napi_value representing the JavaScript function to be invoked.
[in] argc: The count of elements in the argv array.
[in] argv: Array of napi_values representing JavaScript values passed in
as arguments to the function.
[out] result: napi_value representing the JavaScript object returned.

Returns napi_ok if the API succeeded.
This method allows a JavaScript function object to be called from a native
add-on. This is the primary mechanism of calling back from the add-on's
native code into JavaScript. For the special case of calling into JavaScript
after an async operation, see napi_make_callback.
A sample use case might look as follows. Consider the following JavaScript
snippet:
function AddTwo(num) {
  return num + 2;
}
global.AddTwo = AddTwo; copy
Then, the above function can be invoked from a native add-on using the
following code:
// Get the function named "AddTwo" on the global object
napi_value global, add_two, arg;
napi_status status = napi_get_global(env, &global);
if (status != napi_ok) return;

status = napi_get_named_property(env, global, "AddTwo", &add_two);
if (status != napi_ok) return;

// const arg = 1337
status = napi_create_int32(env, 1337, &arg);
if (status != napi_ok) return;

napi_value* argv = &arg;
size_t argc = 1;

// AddTwo(arg);
napi_value return_val;
status = napi_call_function(env, global, add_two, argc, argv, &return_val);
if (status != napi_ok) return;

// Convert the result back to a native type
int32_t result;
status = napi_get_value_int32(env, return_val, &result);
if (status != napi_ok) return; copy

napi_create_function#

Added in: v8.0.0
N-API version: 1

napi_status napi_create_function(napi_env env,
                                 const char* utf8name,
                                 size_t length,
                                 napi_callback cb,
                                 void* data,
                                 napi_value* result); copy

[in] env: The environment that the API is invoked under.
[in] utf8Name: Optional name of the function encoded as UTF8. This is
visible within JavaScript as the new function object's name property.
[in] length: The length of the utf8name in bytes, or NAPI_AUTO_LENGTH if
it is null-terminated.
[in] cb: The native function which should be called when this function
object is invoked. napi_callback provides more details.
[in] data: User-provided data context. This will be passed back into the
function when invoked later.
[out] result: napi_value representing the JavaScript function object for
the newly created function.

Returns napi_ok if the API succeeded.
This API allows an add-on author to create a function object in native code.
This is the primary mechanism to allow calling into the add-on's native code
from JavaScript.
The newly created function is not automatically visible from script after this
call. Instead, a property must be explicitly set on any object that is visible
to JavaScript, in order for the function to be accessible from script.
In order to expose a function as part of the
add-on's module exports, set the newly created function on the exports
object. A sample module might look as follows:
napi_value SayHello(napi_env env, napi_callback_info info) {
  printf("Hello\n");
  return NULL;
}

napi_value Init(napi_env env, napi_value exports) {
  napi_status status;

  napi_value fn;
  status = napi_create_function(env, NULL, 0, SayHello, NULL, &fn);
  if (status != napi_ok) return NULL;

  status = napi_set_named_property(env, exports, "sayHello", fn);
  if (status != napi_ok) return NULL;

  return exports;
}

NAPI_MODULE(NODE_GYP_MODULE_NAME, Init) copy
Given the above code, the add-on can be used from JavaScript as follows:
const myaddon = require('./addon');
myaddon.sayHello(); copy
The string passed to require() is the name of the target in binding.gyp
responsible for creating the .node file.
Any non-NULL data which is passed to this API via the data parameter can
be associated with the resulting JavaScript function (which is returned in the
result parameter) and freed whenever the function is garbage-collected by
passing both the JavaScript function and the data to napi_add_finalizer.
JavaScript Functions are described in Section 19.2 of the ECMAScript
Language Specification.

napi_get_cb_info#

Added in: v8.0.0
N-API version: 1

napi_status napi_get_cb_info(napi_env env,
                             napi_callback_info cbinfo,
                             size_t* argc,
                             napi_value* argv,
                             napi_value* thisArg,
                             void** data) copy

[in] env: The environment that the API is invoked under.
[in] cbinfo: The callback info passed into the callback function.
[in-out] argc: Specifies the length of the provided argv array and
receives the actual count of arguments. argc can
optionally be ignored by passing NULL.
[out] argv: C array of napi_values to which the arguments will be
copied. If there are more arguments than the provided count, only the
requested number of arguments are copied. If there are fewer arguments
provided than claimed, the rest of argv is filled with napi_value values
that represent undefined. argv can optionally be ignored by
passing NULL.
[out] thisArg: Receives the JavaScript this argument for the call.
thisArg can optionally be ignored by passing NULL.
[out] data: Receives the data pointer for the callback. data can
optionally be ignored by passing NULL.

Returns napi_ok if the API succeeded.
This method is used within a callback function to retrieve details about the
call like the arguments and the this pointer from a given callback info.

napi_get_new_target#

Added in: v8.6.0
N-API version: 1

napi_status napi_get_new_target(napi_env env,
                                napi_callback_info cbinfo,
                                napi_value* result) copy

[in] env: The environment that the API is invoked under.
[in] cbinfo: The callback info passed into the callback function.
[out] result: The new.target of the constructor call.

Returns napi_ok if the API succeeded.
This API returns the new.target of the constructor call. If the current
callback is not a constructor call, the result is NULL.

napi_new_instance#

Added in: v8.0.0
N-API version: 1

napi_status napi_new_instance(napi_env env,
                              napi_value cons,
                              size_t argc,
                              napi_value* argv,
                              napi_value* result) copy

[in] env: The environment that the API is invoked under.
[in] cons: napi_value representing the JavaScript function to be invoked
as a constructor.
[in] argc: The count of elements in the argv array.
[in] argv: Array of JavaScript values as napi_value representing the
arguments to the constructor. If argc is zero this parameter may be
omitted by passing in NULL.
[out] result: napi_value representing the JavaScript object returned,
which in this case is the constructed object.

This method is used to instantiate a new JavaScript value using a given
napi_value that represents the constructor for the object. For example,
consider the following snippet:
function MyObject(param) {
  this.param = param;
}

const arg = 'hello';
const value = new MyObject(arg); copy
The following can be approximated in Node-API using the following snippet:
// Get the constructor function MyObject
napi_value global, constructor, arg, value;
napi_status status = napi_get_global(env, &global);
if (status != napi_ok) return;

status = napi_get_named_property(env, global, "MyObject", &constructor);
if (status != napi_ok) return;

// const arg = "hello"
status = napi_create_string_utf8(env, "hello", NAPI_AUTO_LENGTH, &arg);
if (status != napi_ok) return;

napi_value* argv = &arg;
size_t argc = 1;

// const value = new MyObject(arg)
status = napi_new_instance(env, constructor, argc, argv, &value); copy
Returns napi_ok if the API succeeded.

Object wrap#
Node-API offers a way to "wrap" C++ classes and instances so that the class
constructor and methods can be called from JavaScript.

The napi_define_class API defines a JavaScript class with constructor,
static properties and methods, and instance properties and methods that
correspond to the C++ class.
When JavaScript code invokes the constructor, the constructor callback
uses napi_wrap to wrap a new C++ instance in a JavaScript object,
then returns the wrapper object.
When JavaScript code invokes a method or property accessor on the class,
the corresponding napi_callback C++ function is invoked. For an instance
callback, napi_unwrap obtains the C++ instance that is the target of
the call.

For wrapped objects it may be difficult to distinguish between a function
called on a class prototype and a function called on an instance of a class.
A common pattern used to address this problem is to save a persistent
reference to the class constructor for later instanceof checks.
napi_value MyClass_constructor = NULL;
status = napi_get_reference_value(env, MyClass::es_constructor, &MyClass_constructor);
assert(napi_ok == status);
bool is_instance = false;
status = napi_instanceof(env, es_this, MyClass_constructor, &is_instance);
assert(napi_ok == status);
if (is_instance) {
  // napi_unwrap() ...
} else {
  // otherwise...
} copy
The reference must be freed once it is no longer needed.
There are occasions where napi_instanceof() is insufficient for ensuring that
a JavaScript object is a wrapper for a certain native type. This is the case
especially when wrapped JavaScript objects are passed back into the addon via
static methods rather than as the this value of prototype methods. In such
cases there is a chance that they may be unwrapped incorrectly.
const myAddon = require('./build/Release/my_addon.node');

// `openDatabase()` returns a JavaScript object that wraps a native database
// handle.
const dbHandle = myAddon.openDatabase();

// `query()` returns a JavaScript object that wraps a native query handle.
const queryHandle = myAddon.query(dbHandle, 'Gimme ALL the things!');

// There is an accidental error in the line below. The first parameter to
// `myAddon.queryHasRecords()` should be the database handle (`dbHandle`), not
// the query handle (`query`), so the correct condition for the while-loop
// should be
//
// myAddon.queryHasRecords(dbHandle, queryHandle)
//
while (myAddon.queryHasRecords(queryHandle, dbHandle)) {
  // retrieve records
} copy
In the above example myAddon.queryHasRecords() is a method that accepts two
arguments. The first is a database handle and the second is a query handle.
Internally, it unwraps the first argument and casts the resulting pointer to a
native database handle. It then unwraps the second argument and casts the
resulting pointer to a query handle. If the arguments are passed in the wrong
order, the casts will work, however, there is a good chance that the underlying
database operation will fail, or will even cause an invalid memory access.
To ensure that the pointer retrieved from the first argument is indeed a pointer
to a database handle and, similarly, that the pointer retrieved from the second
argument is indeed a pointer to a query handle, the implementation of
queryHasRecords() has to perform a type validation. Retaining the JavaScript
class constructor from which the database handle was instantiated and the
constructor from which the query handle was instantiated in napi_refs can
help, because napi_instanceof() can then be used to ensure that the instances
passed into queryHashRecords() are indeed of the correct type.
Unfortunately, napi_instanceof() does not protect against prototype
manipulation. For example, the prototype of the database handle instance can be
set to the prototype of the constructor for query handle instances. In this
case, the database handle instance can appear as a query handle instance, and it
will pass the napi_instanceof() test for a query handle instance, while still
containing a pointer to a database handle.
To this end, Node-API provides type-tagging capabilities.
A type tag is a 128-bit integer unique to the addon. Node-API provides the
napi_type_tag structure for storing a type tag. When such a value is passed
along with a JavaScript object or external stored in a napi_value to
napi_type_tag_object(), the JavaScript object will be "marked" with the
type tag. The "mark" is invisible on the JavaScript side. When a JavaScript
object arrives into a native binding, napi_check_object_type_tag() can be used
along with the original type tag to determine whether the JavaScript object was
previously "marked" with the type tag. This creates a type-checking capability
of a higher fidelity than napi_instanceof() can provide, because such type-
tagging survives prototype manipulation and addon unloading/reloading.
Continuing the above example, the following skeleton addon implementation
illustrates the use of napi_type_tag_object() and
napi_check_object_type_tag().
// This value is the type tag for a database handle. The command
//
//   uuidgen | sed -r -e 's/-//g' -e 's/(.{16})(.*)/0x\1, 0x\2/'
//
// can be used to obtain the two values with which to initialize the structure.
static const napi_type_tag DatabaseHandleTypeTag = {
  0x1edf75a38336451d, 0xa5ed9ce2e4c00c38
};

// This value is the type tag for a query handle.
static const napi_type_tag QueryHandleTypeTag = {
  0x9c73317f9fad44a3, 0x93c3920bf3b0ad6a
};

static napi_value
openDatabase(napi_env env, napi_callback_info info) {
  napi_status status;
  napi_value result;

  // Perform the underlying action which results in a database handle.
  DatabaseHandle* dbHandle = open_database();

  // Create a new, empty JS object.
  status = napi_create_object(env, &result);
  if (status != napi_ok) return NULL;

  // Tag the object to indicate that it holds a pointer to a `DatabaseHandle`.
  status = napi_type_tag_object(env, result, &DatabaseHandleTypeTag);
  if (status != napi_ok) return NULL;

  // Store the pointer to the `DatabaseHandle` structure inside the JS object.
  status = napi_wrap(env, result, dbHandle, NULL, NULL, NULL);
  if (status != napi_ok) return NULL;

  return result;
}

// Later when we receive a JavaScript object purporting to be a database handle
// we can use `napi_check_object_type_tag()` to ensure that it is indeed such a
// handle.

static napi_value
query(napi_env env, napi_callback_info info) {
  napi_status status;
  size_t argc = 2;
  napi_value argv[2];
  bool is_db_handle;

  status = napi_get_cb_info(env, info, &argc, argv, NULL, NULL);
  if (status != napi_ok) return NULL;

  // Check that the object passed as the first parameter has the previously
  // applied tag.
  status = napi_check_object_type_tag(env,
                                      argv[0],
                                      &DatabaseHandleTypeTag,
                                      &is_db_handle);
  if (status != napi_ok) return NULL;

  // Throw a `TypeError` if it doesn't.
  if (!is_db_handle) {
    // Throw a TypeError.
    return NULL;
  }
} copy

napi_define_class#

Added in: v8.0.0
N-API version: 1

napi_status napi_define_class(napi_env env,
                              const char* utf8name,
                              size_t length,
                              napi_callback constructor,
                              void* data,
                              size_t property_count,
                              const napi_property_descriptor* properties,
                              napi_value* result); copy

[in] env: The environment that the API is invoked under.
[in] utf8name: Name of the JavaScript constructor function. For clarity,
it is recommended to use the C++ class name when wrapping a C++ class.
[in] length: The length of the utf8name in bytes, or NAPI_AUTO_LENGTH
if it is null-terminated.
[in] constructor: Callback function that handles constructing instances
of the class. When wrapping a C++ class, this method must be a static member
with the napi_callback signature. A C++ class constructor cannot be
used. napi_callback provides more details.
[in] data: Optional data to be passed to the constructor callback as
the data property of the callback info.
[in] property_count: Number of items in the properties array argument.
[in] properties: Array of property descriptors describing static and
instance data properties, accessors, and methods on the class
See napi_property_descriptor.
[out] result: A napi_value representing the constructor function for
the class.

Returns napi_ok if the API succeeded.
Defines a JavaScript class, including:

A JavaScript constructor function that has the class name. When wrapping a
corresponding C++ class, the callback passed via constructor can be used to
instantiate a new C++ class instance, which can then be placed inside the
JavaScript object instance being constructed using napi_wrap.
Properties on the constructor function whose implementation can call
corresponding static data properties, accessors, and methods of the C++
class (defined by property descriptors with the napi_static attribute).
Properties on the constructor function's prototype object. When wrapping a
C++ class, non-static data properties, accessors, and methods of the C++
class can be called from the static functions given in the property
descriptors without the napi_static attribute after retrieving the C++ class
instance placed inside the JavaScript object instance by using
napi_unwrap.

When wrapping a C++ class, the C++ constructor callback passed via constructor
should be a static method on the class that calls the actual class constructor,
then wraps the new C++ instance in a JavaScript object, and returns the wrapper
object. See napi_wrap for details.
The JavaScript constructor function returned from napi_define_class is
often saved and used later to construct new instances of the class from native
code, and/or to check whether provided values are instances of the class. In
that case, to prevent the function value from being garbage-collected, a
strong persistent reference to it can be created using
napi_create_reference, ensuring that the reference count is kept >= 1.
Any non-NULL data which is passed to this API via the data parameter or via
the data field of the napi_property_descriptor array items can be associated
with the resulting JavaScript constructor (which is returned in the result
parameter) and freed whenever the class is garbage-collected by passing both
the JavaScript function and the data to napi_add_finalizer.

napi_wrap#

Added in: v8.0.0
N-API version: 1

napi_status napi_wrap(napi_env env,
                      napi_value js_object,
                      void* native_object,
                      napi_finalize finalize_cb,
                      void* finalize_hint,
                      napi_ref* result); copy

[in] env: The environment that the API is invoked under.
[in] js_object: The JavaScript object that will be the wrapper for the
native object.
[in] native_object: The native instance that will be wrapped in the
JavaScript object.
[in] finalize_cb: Optional native callback that can be used to free the
native instance when the JavaScript object has been garbage-collected.
napi_finalize provides more details.
[in] finalize_hint: Optional contextual hint that is passed to the
finalize callback.
[out] result: Optional reference to the wrapped object.

Returns napi_ok if the API succeeded.
Wraps a native instance in a JavaScript object. The native instance can be
retrieved later using napi_unwrap().
When JavaScript code invokes a constructor for a class that was defined using
napi_define_class(), the napi_callback for the constructor is invoked.
After constructing an instance of the native class, the callback must then call
napi_wrap() to wrap the newly constructed instance in the already-created
JavaScript object that is the this argument to the constructor callback.
(That this object was created from the constructor function's prototype,
so it already has definitions of all the instance properties and methods.)
Typically when wrapping a class instance, a finalize callback should be
provided that simply deletes the native instance that is received as the data
argument to the finalize callback.
The optional returned reference is initially a weak reference, meaning it
has a reference count of 0. Typically this reference count would be incremented
temporarily during async operations that require the instance to remain valid.
Caution: The optional returned reference (if obtained) should be deleted via
napi_delete_reference ONLY in response to the finalize callback
invocation. If it is deleted before then, then the finalize callback may never
be invoked. Therefore, when obtaining a reference a finalize callback is also
required in order to enable correct disposal of the reference.
Finalizer callbacks may be deferred, leaving a window where the object has
been garbage collected (and the weak reference is invalid) but the finalizer
hasn't been called yet. When using napi_get_reference_value() on weak
references returned by napi_wrap(), you should still handle an empty result.
Calling napi_wrap() a second time on an object will return an error. To
associate another native instance with the object, use napi_remove_wrap()
first.

napi_unwrap#

Added in: v8.0.0
N-API version: 1

napi_status napi_unwrap(napi_env env,
                        napi_value js_object,
                        void** result); copy

[in] env: The environment that the API is invoked under.
[in] js_object: The object associated with the native instance.
[out] result: Pointer to the wrapped native instance.

Returns napi_ok if the API succeeded.
Retrieves a native instance that was previously wrapped in a JavaScript
object using napi_wrap().
When JavaScript code invokes a method or property accessor on the class, the
corresponding napi_callback is invoked. If the callback is for an instance
method or accessor, then the this argument to the callback is the wrapper
object; the wrapped C++ instance that is the target of the call can be obtained
then by calling napi_unwrap() on the wrapper object.

napi_remove_wrap#

Added in: v8.5.0
N-API version: 1

napi_status napi_remove_wrap(napi_env env,
                             napi_value js_object,
                             void** result); copy

[in] env: The environment that the API is invoked under.
[in] js_object: The object associated with the native instance.
[out] result: Pointer to the wrapped native instance.

Returns napi_ok if the API succeeded.
Retrieves a native instance that was previously wrapped in the JavaScript
object js_object using napi_wrap() and removes the wrapping. If a finalize
callback was associated with the wrapping, it will no longer be called when the
JavaScript object becomes garbage-collected.

napi_type_tag_object#

Added in: v14.8.0, v12.19.0
N-API version: 8

napi_status napi_type_tag_object(napi_env env,
                                 napi_value js_object,
                                 const napi_type_tag* type_tag); copy

[in] env: The environment that the API is invoked under.
[in] js_object: The JavaScript object or external to be marked.
[in] type_tag: The tag with which the object is to be marked.

Returns napi_ok if the API succeeded.
Associates the value of the type_tag pointer with the JavaScript object or
external. napi_check_object_type_tag() can then be used to compare the tag
that was attached to the object with one owned by the addon to ensure that the
object has the right type.
If the object already has an associated type tag, this API will return
napi_invalid_arg.

napi_check_object_type_tag#

Added in: v14.8.0, v12.19.0
N-API version: 8

napi_status napi_check_object_type_tag(napi_env env,
                                       napi_value js_object,
                                       const napi_type_tag* type_tag,
                                       bool* result); copy

[in] env: The environment that the API is invoked under.
[in] js_object: The JavaScript object or external whose type tag to
examine.
[in] type_tag: The tag with which to compare any tag found on the object.
[out] result: Whether the type tag given matched the type tag on the
object. false is also returned if no type tag was found on the object.

Returns napi_ok if the API succeeded.
Compares the pointer given as type_tag with any that can be found on
js_object. If no tag is found on js_object or, if a tag is found but it does
not match type_tag, then result is set to false. If a tag is found and it
matches type_tag, then result is set to true.

napi_add_finalizer#

Added in: v8.0.0
N-API version: 5

napi_status napi_add_finalizer(napi_env env,
                               napi_value js_object,
                               void* finalize_data,
                               node_api_basic_finalize finalize_cb,
                               void* finalize_hint,
                               napi_ref* result); copy

[in] env: The environment that the API is invoked under.
[in] js_object: The JavaScript object to which the native data will be
attached.
[in] finalize_data: Optional data to be passed to finalize_cb.
[in] finalize_cb: Native callback that will be used to free the
native data when the JavaScript object has been garbage-collected.
napi_finalize provides more details.
[in] finalize_hint: Optional contextual hint that is passed to the
finalize callback.
[out] result: Optional reference to the JavaScript object.

Returns napi_ok if the API succeeded.
Adds a napi_finalize callback which will be called when the JavaScript object
in js_object has been garbage-collected.
This API can be called multiple times on a single JavaScript object.
Caution: The optional returned reference (if obtained) should be deleted via
napi_delete_reference ONLY in response to the finalize callback
invocation. If it is deleted before then, then the finalize callback may never
be invoked. Therefore, when obtaining a reference a finalize callback is also
required in order to enable correct disposal of the reference.

node_api_post_finalizer#

Added in: v21.0.0, v20.10.0, v18.19.0

Stability: 1 - Experimental
napi_status node_api_post_finalizer(node_api_basic_env env,
                                    napi_finalize finalize_cb,
                                    void* finalize_data,
                                    void* finalize_hint); copy

[in] env: The environment that the API is invoked under.
[in] finalize_cb: Native callback that will be used to free the
native data when the JavaScript object has been garbage-collected.
napi_finalize provides more details.
[in] finalize_data: Optional data to be passed to finalize_cb.
[in] finalize_hint: Optional contextual hint that is passed to the
finalize callback.

Returns napi_ok if the API succeeded.
Schedules a napi_finalize callback to be called asynchronously in the
event loop.
Normally, finalizers are called while the GC (garbage collector) collects
objects. At that point calling any Node-API that may cause changes in the GC
state will be disabled and will crash Node.js.
node_api_post_finalizer helps to work around this limitation by allowing the
add-on to defer calls to such Node-APIs to a point in time outside of the GC
finalization.

Simple asynchronous operations#
Addon modules often need to leverage async helpers from libuv as part of their
implementation. This allows them to schedule work to be executed asynchronously
so that their methods can return in advance of the work being completed. This
allows them to avoid blocking overall execution of the Node.js application.
Node-API provides an ABI-stable interface for these
supporting functions which covers the most common asynchronous use cases.
Node-API defines the napi_async_work structure which is used to manage
asynchronous workers. Instances are created/deleted with
napi_create_async_work and napi_delete_async_work.
The execute and complete callbacks are functions that will be
invoked when the executor is ready to execute and when it completes its
task respectively.
The execute function should avoid making any Node-API calls
that could result in the execution of JavaScript or interaction with
JavaScript objects. Most often, any code that needs to make Node-API
calls should be made in complete callback instead.
Avoid using the napi_env parameter in the execute callback as
it will likely execute JavaScript.
These functions implement the following interfaces:
typedef void (*napi_async_execute_callback)(napi_env env,
                                            void* data);
typedef void (*napi_async_complete_callback)(napi_env env,
                                             napi_status status,
                                             void* data); copy
When these methods are invoked, the data parameter passed will be the
addon-provided void* data that was passed into the
napi_create_async_work call.
Once created the async worker can be queued
for execution using the napi_queue_async_work function:
napi_status napi_queue_async_work(node_api_basic_env env,
                                  napi_async_work work); copy
napi_cancel_async_work can be used if the work needs
to be cancelled before the work has started execution.
After calling napi_cancel_async_work, the complete callback
will be invoked with a status value of napi_cancelled.
The work should not be deleted before the complete
callback invocation, even when it was cancelled.

napi_create_async_work#

History

VersionChanges
v8.6.0
Added async_resource and async_resource_name parameters.
v8.0.0
Added in: v8.0.0


N-API version: 1

napi_status napi_create_async_work(napi_env env,
                                   napi_value async_resource,
                                   napi_value async_resource_name,
                                   napi_async_execute_callback execute,
                                   napi_async_complete_callback complete,
                                   void* data,
                                   napi_async_work* result); copy

[in] env: The environment that the API is invoked under.
[in] async_resource: An optional object associated with the async work
that will be passed to possible async_hooks init hooks.
[in] async_resource_name: Identifier for the kind of resource that is being
provided for diagnostic information exposed by the async_hooks API.
[in] execute: The native function which should be called to execute the
logic asynchronously. The given function is called from a worker pool thread
and can execute in parallel with the main event loop thread.
[in] complete: The native function which will be called when the
asynchronous logic is completed or is cancelled. The given function is called
from the main event loop thread. napi_async_complete_callback provides
more details.
[in] data: User-provided data context. This will be passed back into the
execute and complete functions.
[out] result: napi_async_work* which is the handle to the newly created
async work.

Returns napi_ok if the API succeeded.
This API allocates a work object that is used to execute logic asynchronously.
It should be freed using napi_delete_async_work once the work is no longer
required.
async_resource_name should be a null-terminated, UTF-8-encoded string.
The async_resource_name identifier is provided by the user and should be
representative of the type of async work being performed. It is also recommended
to apply namespacing to the identifier, e.g. by including the module name. See
the async_hooks documentation for more information.

napi_delete_async_work#

Added in: v8.0.0
N-API version: 1

napi_status napi_delete_async_work(napi_env env,
                                   napi_async_work work); copy

[in] env: The environment that the API is invoked under.
[in] work: The handle returned by the call to napi_create_async_work.

Returns napi_ok if the API succeeded.
This API frees a previously allocated work object.
This API can be called even if there is a pending JavaScript exception.

napi_queue_async_work#

Added in: v8.0.0
N-API version: 1

napi_status napi_queue_async_work(node_api_basic_env env,
                                  napi_async_work work); copy

[in] env: The environment that the API is invoked under.
[in] work: The handle returned by the call to napi_create_async_work.

Returns napi_ok if the API succeeded.
This API requests that the previously allocated work be scheduled
for execution. Once it returns successfully, this API must not be called again
with the same napi_async_work item or the result will be undefined.

napi_cancel_async_work#

Added in: v8.0.0
N-API version: 1

napi_status napi_cancel_async_work(node_api_basic_env env,
                                   napi_async_work work); copy

[in] env: The environment that the API is invoked under.
[in] work: The handle returned by the call to napi_create_async_work.

Returns napi_ok if the API succeeded.
This API cancels queued work if it has not yet
been started. If it has already started executing, it cannot be
cancelled and napi_generic_failure will be returned. If successful,
the complete callback will be invoked with a status value of
napi_cancelled. The work should not be deleted before the complete
callback invocation, even if it has been successfully cancelled.
This API can be called even if there is a pending JavaScript exception.

Custom asynchronous operations#
The simple asynchronous work APIs above may not be appropriate for every
scenario. When using any other asynchronous mechanism, the following APIs
are necessary to ensure an asynchronous operation is properly tracked by
the runtime.

napi_async_init#

Added in: v8.6.0
N-API version: 1

napi_status napi_async_init(napi_env env,
                            napi_value async_resource,
                            napi_value async_resource_name,
                            napi_async_context* result) copy

[in] env: The environment that the API is invoked under.
[in] async_resource: Object associated with the async work
that will be passed to possible async_hooks init hooks and can be
accessed by async_hooks.executionAsyncResource().
[in] async_resource_name: Identifier for the kind of resource that is being
provided for diagnostic information exposed by the async_hooks API.
[out] result: The initialized async context.

Returns napi_ok if the API succeeded.
The async_resource object needs to be kept alive until
napi_async_destroy to keep async_hooks related API acts correctly. In
order to retain ABI compatibility with previous versions, napi_async_contexts
are not maintaining the strong reference to the async_resource objects to
avoid introducing causing memory leaks. However, if the async_resource is
garbage collected by JavaScript engine before the napi_async_context was
destroyed by napi_async_destroy, calling napi_async_context related APIs
like napi_open_callback_scope and napi_make_callback can cause
problems like loss of async context when using the AsyncLocalStorage API.
In order to retain ABI compatibility with previous versions, passing NULL
for async_resource does not result in an error. However, this is not
recommended as this will result in undesirable behavior with  async_hooks
init hooks and async_hooks.executionAsyncResource() as the resource is
now required by the underlying async_hooks implementation in order to provide
the linkage between async callbacks.

napi_async_destroy#

Added in: v8.6.0
N-API version: 1

napi_status napi_async_destroy(napi_env env,
                               napi_async_context async_context); copy

[in] env: The environment that the API is invoked under.
[in] async_context: The async context to be destroyed.

Returns napi_ok if the API succeeded.
This API can be called even if there is a pending JavaScript exception.

napi_make_callback#

History

VersionChanges
v8.6.0
Added async_context parameter.
v8.0.0
Added in: v8.0.0


N-API version: 1

NAPI_EXTERN napi_status napi_make_callback(napi_env env,
                                           napi_async_context async_context,
                                           napi_value recv,
                                           napi_value func,
                                           size_t argc,
                                           const napi_value* argv,
                                           napi_value* result); copy

[in] env: The environment that the API is invoked under.
[in] async_context: Context for the async operation that is
invoking the callback. This should normally be a value previously
obtained from napi_async_init.
In order to retain ABI compatibility with previous versions, passing NULL
for async_context does not result in an error. However, this results
in incorrect operation of async hooks. Potential issues include loss of
async context when using the AsyncLocalStorage API.
[in] recv: The this value passed to the called function.
[in] func: napi_value representing the JavaScript function to be invoked.
[in] argc: The count of elements in the argv array.
[in] argv: Array of JavaScript values as napi_value representing the
arguments to the function. If argc is zero this parameter may be
omitted by passing in NULL.
[out] result: napi_value representing the JavaScript object returned.

Returns napi_ok if the API succeeded.
This method allows a JavaScript function object to be called from a native
add-on. This API is similar to napi_call_function. However, it is used to call
from native code back into JavaScript after returning from an async
operation (when there is no other script on the stack). It is a fairly simple
wrapper around node::MakeCallback.
Note it is not necessary to use napi_make_callback from within a
napi_async_complete_callback; in that situation the callback's async
context has already been set up, so a direct call to napi_call_function
is sufficient and appropriate. Use of the napi_make_callback function
may be required when implementing custom async behavior that does not use
napi_create_async_work.
Any process.nextTicks or Promises scheduled on the microtask queue by
JavaScript during the callback are ran before returning back to C/C++.

napi_open_callback_scope#

Added in: v9.6.0
N-API version: 3

NAPI_EXTERN napi_status napi_open_callback_scope(napi_env env,
                                                 napi_value resource_object,
                                                 napi_async_context context,
                                                 napi_callback_scope* result) copy

[in] env: The environment that the API is invoked under.
[in] resource_object: An object associated with the async work
that will be passed to possible async_hooks init hooks. This
parameter has been deprecated and is ignored at runtime. Use the
async_resource parameter in napi_async_init instead.
[in] context: Context for the async operation that is invoking the callback.
This should be a value previously obtained from napi_async_init.
[out] result: The newly created scope.

There are cases (for example, resolving promises) where it is
necessary to have the equivalent of the scope associated with a callback
in place when making certain Node-API calls. If there is no other script on
the stack the napi_open_callback_scope and
napi_close_callback_scope functions can be used to open/close
the required scope.

napi_close_callback_scope#

Added in: v9.6.0
N-API version: 3

NAPI_EXTERN napi_status napi_close_callback_scope(napi_env env,
                                                  napi_callback_scope scope) copy

[in] env: The environment that the API is invoked under.
[in] scope: The scope to be closed.

This API can be called even if there is a pending JavaScript exception.

Version management#

napi_get_node_version#

Added in: v8.4.0
N-API version: 1

typedef struct {
  uint32_t major;
  uint32_t minor;
  uint32_t patch;
  const char* release;
} napi_node_version;

napi_status napi_get_node_version(node_api_basic_env env,
                                  const napi_node_version** version); copy

[in] env: The environment that the API is invoked under.
[out] version: A pointer to version information for Node.js itself.

Returns napi_ok if the API succeeded.
This function fills the version struct with the major, minor, and patch
version of Node.js that is currently running, and the release field with the
value of process.release.name.
The returned buffer is statically allocated and does not need to be freed.

napi_get_version#

Added in: v8.0.0
N-API version: 1

napi_status napi_get_version(node_api_basic_env env,
                             uint32_t* result); copy

[in] env: The environment that the API is invoked under.
[out] result: The highest version of Node-API supported.

Returns napi_ok if the API succeeded.
This API returns the highest Node-API version supported by the
Node.js runtime. Node-API is planned to be additive such that
newer releases of Node.js may support additional API functions.
In order to allow an addon to use a newer function when running with
versions of Node.js that support it, while providing
fallback behavior when running with Node.js versions that don't
support it:

Call napi_get_version() to determine if the API is available.
If available, dynamically load a pointer to the function using uv_dlsym().
Use the dynamically loaded pointer to invoke the function.
If the function is not available, provide an alternate implementation
that does not use the function.


Memory management#

napi_adjust_external_memory#

Added in: v8.5.0
N-API version: 1

NAPI_EXTERN napi_status napi_adjust_external_memory(node_api_basic_env env,
                                                    int64_t change_in_bytes,
                                                    int64_t* result); copy

[in] env: The environment that the API is invoked under.
[in] change_in_bytes: The change in externally allocated memory that is kept
alive by JavaScript objects.
[out] result: The adjusted value. This value should reflect the
total amount of external memory with the given change_in_bytes included.
The absolute value of the returned value should not  be depended on.
For example, implementations may use a single counter for all addons, or a
counter for each addon.

Returns napi_ok if the API succeeded.
This function gives the runtime an indication of the amount of externally
allocated memory that is kept alive by JavaScript objects
(i.e. a JavaScript object that points to its own memory allocated by a
native addon). Registering externally allocated memory may, but is not
guaranteed to, trigger global garbage collections more
often than it would otherwise.
This function is expected to be called in a manner such that an
addon does not decrease the external memory more than it has
increased the external memory.

Promises#
Node-API provides facilities for creating Promise objects as described in
Section 25.4 of the ECMA specification. It implements promises as a pair of
objects. When a promise is created by napi_create_promise(), a "deferred"
object is created and returned alongside the Promise. The deferred object is
bound to the created Promise and is the only means to resolve or reject the
Promise using napi_resolve_deferred() or napi_reject_deferred(). The
deferred object that is created by napi_create_promise() is freed by
napi_resolve_deferred() or napi_reject_deferred(). The Promise object may
be returned to JavaScript where it can be used in the usual fashion.
For example, to create a promise and pass it to an asynchronous worker:
napi_deferred deferred;
napi_value promise;
napi_status status;

// Create the promise.
status = napi_create_promise(env, &deferred, &promise);
if (status != napi_ok) return NULL;

// Pass the deferred to a function that performs an asynchronous action.
do_something_asynchronous(deferred);

// Return the promise to JS
return promise; copy
The above function do_something_asynchronous() would perform its asynchronous
action and then it would resolve or reject the deferred, thereby concluding the
promise and freeing the deferred:
napi_deferred deferred;
napi_value undefined;
napi_status status;

// Create a value with which to conclude the deferred.
status = napi_get_undefined(env, &undefined);
if (status != napi_ok) return NULL;

// Resolve or reject the promise associated with the deferred depending on
// whether the asynchronous action succeeded.
if (asynchronous_action_succeeded) {
  status = napi_resolve_deferred(env, deferred, undefined);
} else {
  status = napi_reject_deferred(env, deferred, undefined);
}
if (status != napi_ok) return NULL;

// At this point the deferred has been freed, so we should assign NULL to it.
deferred = NULL; copy

napi_create_promise#

Added in: v8.5.0
N-API version: 1

napi_status napi_create_promise(napi_env env,
                                napi_deferred* deferred,
                                napi_value* promise); copy

[in] env: The environment that the API is invoked under.
[out] deferred: A newly created deferred object which can later be passed to
napi_resolve_deferred() or napi_reject_deferred() to resolve resp. reject
the associated promise.
[out] promise: The JavaScript promise associated with the deferred object.

Returns napi_ok if the API succeeded.
This API creates a deferred object and a JavaScript promise.

napi_resolve_deferred#

Added in: v8.5.0
N-API version: 1

napi_status napi_resolve_deferred(napi_env env,
                                  napi_deferred deferred,
                                  napi_value resolution); copy

[in] env: The environment that the API is invoked under.
[in] deferred: The deferred object whose associated promise to resolve.
[in] resolution: The value with which to resolve the promise.

This API resolves a JavaScript promise by way of the deferred object
with which it is associated. Thus, it can only be used to resolve JavaScript
promises for which the corresponding deferred object is available. This
effectively means that the promise must have been created using
napi_create_promise() and the deferred object returned from that call must
have been retained in order to be passed to this API.
The deferred object is freed upon successful completion.

napi_reject_deferred#

Added in: v8.5.0
N-API version: 1

napi_status napi_reject_deferred(napi_env env,
                                 napi_deferred deferred,
                                 napi_value rejection); copy

[in] env: The environment that the API is invoked under.
[in] deferred: The deferred object whose associated promise to resolve.
[in] rejection: The value with which to reject the promise.

This API rejects a JavaScript promise by way of the deferred object
with which it is associated. Thus, it can only be used to reject JavaScript
promises for which the corresponding deferred object is available. This
effectively means that the promise must have been created using
napi_create_promise() and the deferred object returned from that call must
have been retained in order to be passed to this API.
The deferred object is freed upon successful completion.

napi_is_promise#

Added in: v8.5.0
N-API version: 1

napi_status napi_is_promise(napi_env env,
                            napi_value value,
                            bool* is_promise); copy

[in] env: The environment that the API is invoked under.
[in] value: The value to examine
[out] is_promise: Flag indicating whether promise is a native promise
object (that is, a promise object created by the underlying engine).


Script execution#
Node-API provides an API for executing a string containing JavaScript using the
underlying JavaScript engine.

napi_run_script#

Added in: v8.5.0
N-API version: 1

NAPI_EXTERN napi_status napi_run_script(napi_env env,
                                        napi_value script,
                                        napi_value* result); copy

[in] env: The environment that the API is invoked under.
[in] script: A JavaScript string containing the script to execute.
[out] result: The value resulting from having executed the script.

This function executes a string of JavaScript code and returns its result with
the following caveats:

Unlike eval, this function does not allow the script to access the current
lexical scope, and therefore also does not allow to access the
module scope, meaning that pseudo-globals such as require will not be
available.
The script can access the global scope. Function and var declarations
in the script will be added to the global object. Variable declarations
made using let and const will be visible globally, but will not be added
to the global object.
The value of this is global within the script.


libuv event loop#
Node-API provides a function for getting the current event loop associated with
a specific napi_env.

napi_get_uv_event_loop#

Added in: v9.3.0, v8.10.0
N-API version: 2

NAPI_EXTERN napi_status napi_get_uv_event_loop(node_api_basic_env env,
                                               struct uv_loop_s** loop); copy

[in] env: The environment that the API is invoked under.
[out] loop: The current libuv loop instance.

Note: While libuv has been relatively stable over time, it does
not provide an ABI stability guarantee. Use of this function should be avoided.
Its use may result in an addon that does not work across Node.js versions.
asynchronous-thread-safe-function-calls
are an alternative for many use cases.

Asynchronous thread-safe function calls#
JavaScript functions can normally only be called from a native addon's main
thread. If an addon creates additional threads, then Node-API functions that
require a napi_env, napi_value, or napi_ref must not be called from those
threads.
When an addon has additional threads and JavaScript functions need to be invoked
based on the processing completed by those threads, those threads must
communicate with the addon's main thread so that the main thread can invoke the
JavaScript function on their behalf. The thread-safe function APIs provide an
easy way to do this.
These APIs provide the type napi_threadsafe_function as well as APIs to
create, destroy, and call objects of this type.
napi_create_threadsafe_function() creates a persistent reference to a
napi_value that holds a JavaScript function which can be called from multiple
threads. The calls happen asynchronously. This means that values with which the
JavaScript callback is to be called will be placed in a queue, and, for each
value in the queue, a call will eventually be made to the JavaScript function.
Upon creation of a napi_threadsafe_function a napi_finalize callback can be
provided. This callback will be invoked on the main thread when the thread-safe
function is about to be destroyed. It receives the context and the finalize data
given during construction, and provides an opportunity for cleaning up after the
threads e.g. by calling uv_thread_join(). Aside from the main loop thread,
no threads should be using the thread-safe function after the finalize callback
completes.
The context given during the call to napi_create_threadsafe_function() can
be retrieved from any thread with a call to
napi_get_threadsafe_function_context().

Calling a thread-safe function#
napi_call_threadsafe_function() can be used for initiating a call into
JavaScript. napi_call_threadsafe_function() accepts a parameter which controls
whether the API behaves blockingly. If set to napi_tsfn_nonblocking, the API
behaves non-blockingly, returning napi_queue_full if the queue was full,
preventing data from being successfully added to the queue. If set to
napi_tsfn_blocking, the API blocks until space becomes available in the queue.
napi_call_threadsafe_function() never blocks if the thread-safe function was
created with a maximum queue size of 0.
napi_call_threadsafe_function() should not be called with napi_tsfn_blocking
from a JavaScript thread, because, if the queue is full, it may cause the
JavaScript thread to deadlock.
The actual call into JavaScript is controlled by the callback given via the
call_js_cb parameter. call_js_cb is invoked on the main thread once for each
value that was placed into the queue by a successful call to
napi_call_threadsafe_function(). If such a callback is not given, a default
callback will be used, and the resulting JavaScript call will have no arguments.
The call_js_cb callback receives the JavaScript function to call as a
napi_value in its parameters, as well as the void* context pointer used when
creating the napi_threadsafe_function, and the next data pointer that was
created by one of the secondary threads. The callback can then use an API such
as napi_call_function() to call into JavaScript.
The callback may also be invoked with env and call_js_cb both set to NULL
to indicate that calls into JavaScript are no longer possible, while items
remain in the queue that may need to be freed. This normally occurs when the
Node.js process exits while there is a thread-safe function still active.
It is not necessary to call into JavaScript via napi_make_callback() because
Node-API runs call_js_cb in a context appropriate for callbacks.
Zero or more queued items may be invoked in each tick of the event loop.
Applications should not depend on a specific behavior other than progress in
invoking callbacks will be made and events will be invoked
as time moves forward.

Reference counting of thread-safe functions#
Threads can be added to and removed from a napi_threadsafe_function object
during its existence. Thus, in addition to specifying an initial number of
threads upon creation, napi_acquire_threadsafe_function can be called to
indicate that a new thread will start making use of the thread-safe function.
Similarly, napi_release_threadsafe_function can be called to indicate that an
existing thread will stop making use of the thread-safe function.
napi_threadsafe_function objects are destroyed when every thread which uses
the object has called napi_release_threadsafe_function() or has received a
return status of napi_closing in response to a call to
napi_call_threadsafe_function. The queue is emptied before the
napi_threadsafe_function is destroyed. napi_release_threadsafe_function()
should be the last API call made in conjunction with a given
napi_threadsafe_function, because after the call completes, there is no
guarantee that the napi_threadsafe_function is still allocated. For the same
reason, do not use a thread-safe function
after receiving a return value of napi_closing in response to a call to
napi_call_threadsafe_function. Data associated with the
napi_threadsafe_function can be freed in its napi_finalize callback which
was passed to napi_create_threadsafe_function(). The parameter
initial_thread_count of napi_create_threadsafe_function marks the initial
number of acquisitions of the thread-safe functions, instead of calling
napi_acquire_threadsafe_function multiple times at creation.
Once the number of threads making use of a napi_threadsafe_function reaches
zero, no further threads can start making use of it by calling
napi_acquire_threadsafe_function(). In fact, all subsequent API calls
associated with it, except napi_release_threadsafe_function(), will return an
error value of napi_closing.
The thread-safe function can be "aborted" by giving a value of napi_tsfn_abort
to napi_release_threadsafe_function(). This will cause all subsequent APIs
associated with the thread-safe function except
napi_release_threadsafe_function() to return napi_closing even before its
reference count reaches zero. In particular, napi_call_threadsafe_function()
will return napi_closing, thus informing the threads that it is no longer
possible to make asynchronous calls to the thread-safe function. This can be
used as a criterion for terminating the thread. Upon receiving a return value
of napi_closing from napi_call_threadsafe_function() a thread must not use
the thread-safe function anymore because it is no longer guaranteed to
be allocated.

Deciding whether to keep the process running#
Similarly to libuv handles, thread-safe functions can be "referenced" and
"unreferenced". A "referenced" thread-safe function will cause the event loop on
the thread on which it is created to remain alive until the thread-safe function
is destroyed. In contrast, an "unreferenced" thread-safe function will not
prevent the event loop from exiting. The APIs napi_ref_threadsafe_function and
napi_unref_threadsafe_function exist for this purpose.
Neither does napi_unref_threadsafe_function mark the thread-safe functions as
able to be destroyed nor does napi_ref_threadsafe_function prevent it from
being destroyed.

napi_create_threadsafe_function#

History

VersionChanges
v12.6.0, v10.17.0
Made func parameter optional with custom call_js_cb.
v10.6.0
Added in: v10.6.0


N-API version: 4

NAPI_EXTERN napi_status
napi_create_threadsafe_function(napi_env env,
                                napi_value func,
                                napi_value async_resource,
                                napi_value async_resource_name,
                                size_t max_queue_size,
                                size_t initial_thread_count,
                                void* thread_finalize_data,
                                napi_finalize thread_finalize_cb,
                                void* context,
                                napi_threadsafe_function_call_js call_js_cb,
                                napi_threadsafe_function* result); copy

[in] env: The environment that the API is invoked under.
[in] func: An optional JavaScript function to call from another thread. It
must be provided if NULL is passed to call_js_cb.
[in] async_resource: An optional object associated with the async work that
will be passed to possible async_hooks init hooks.
[in] async_resource_name: A JavaScript string to provide an identifier for
the kind of resource that is being provided for diagnostic information exposed
by the async_hooks API.
[in] max_queue_size: Maximum size of the queue. 0 for no limit.
[in] initial_thread_count: The initial number of acquisitions, i.e. the
initial number of threads, including the main thread, which will be making use
of this function.
[in] thread_finalize_data: Optional data to be passed to thread_finalize_cb.
[in] thread_finalize_cb: Optional function to call when the
napi_threadsafe_function is being destroyed.
[in] context: Optional data to attach to the resulting
napi_threadsafe_function.
[in] call_js_cb: Optional callback which calls the JavaScript function in
response to a call on a different thread. This callback will be called on the
main thread. If not given, the JavaScript function will be called with no
parameters and with undefined as its this value.
napi_threadsafe_function_call_js provides more details.
[out] result: The asynchronous thread-safe JavaScript function.

Change History:


Version 10 (NAPI_VERSION is defined as 10 or higher):
Uncaught exceptions thrown in call_js_cb are handled with the
'uncaughtException' event, instead of being ignored.



napi_get_threadsafe_function_context#

Added in: v10.6.0
N-API version: 4

NAPI_EXTERN napi_status
napi_get_threadsafe_function_context(napi_threadsafe_function func,
                                     void** result); copy

[in] func: The thread-safe function for which to retrieve the context.
[out] result: The location where to store the context.

This API may be called from any thread which makes use of func.

napi_call_threadsafe_function#

History

VersionChanges
v14.5.0
Support for napi_would_deadlock has been reverted.
v14.1.0
Return napi_would_deadlock when called with napi_tsfn_blocking from the main thread or a worker thread and the queue is full.
v10.6.0
Added in: v10.6.0


N-API version: 4

NAPI_EXTERN napi_status
napi_call_threadsafe_function(napi_threadsafe_function func,
                              void* data,
                              napi_threadsafe_function_call_mode is_blocking); copy

[in] func: The asynchronous thread-safe JavaScript function to invoke.
[in] data: Data to send into JavaScript via the callback call_js_cb
provided during the creation of the thread-safe JavaScript function.
[in] is_blocking: Flag whose value can be either napi_tsfn_blocking to
indicate that the call should block if the queue is full or
napi_tsfn_nonblocking to indicate that the call should return immediately
with a status of napi_queue_full whenever the queue is full.

This API should not be called with napi_tsfn_blocking from a JavaScript
thread, because, if the queue is full, it may cause the JavaScript thread to
deadlock.
This API will return napi_closing if napi_release_threadsafe_function() was
called with abort set to napi_tsfn_abort from any thread. The value is only
added to the queue if the API returns napi_ok.
This API may be called from any thread which makes use of func.

napi_acquire_threadsafe_function#

Added in: v10.6.0
N-API version: 4

NAPI_EXTERN napi_status
napi_acquire_threadsafe_function(napi_threadsafe_function func); copy

[in] func: The asynchronous thread-safe JavaScript function to start making
use of.

A thread should call this API before passing func to any other thread-safe
function APIs to indicate that it will be making use of func. This prevents
func from being destroyed when all other threads have stopped making use of
it.
This API may be called from any thread which will start making use of func.

napi_release_threadsafe_function#

Added in: v10.6.0
N-API version: 4

NAPI_EXTERN napi_status
napi_release_threadsafe_function(napi_threadsafe_function func,
                                 napi_threadsafe_function_release_mode mode); copy

[in] func: The asynchronous thread-safe JavaScript function whose reference
count to decrement.
[in] mode: Flag whose value can be either napi_tsfn_release to indicate
that the current thread will make no further calls to the thread-safe
function, or napi_tsfn_abort to indicate that in addition to the current
thread, no other thread should make any further calls to the thread-safe
function. If set to napi_tsfn_abort, further calls to
napi_call_threadsafe_function() will return napi_closing, and no further
values will be placed in the queue.

A thread should call this API when it stops making use of func. Passing func
to any thread-safe APIs after having called this API has undefined results, as
func may have been destroyed.
This API may be called from any thread which will stop making use of func.

napi_ref_threadsafe_function#

Added in: v10.6.0
N-API version: 4

NAPI_EXTERN napi_status
napi_ref_threadsafe_function(node_api_basic_env env, napi_threadsafe_function func); copy

[in] env: The environment that the API is invoked under.
[in] func: The thread-safe function to reference.

This API is used to indicate that the event loop running on the main thread
should not exit until func has been destroyed. Similar to uv_ref it is
also idempotent.
Neither does napi_unref_threadsafe_function mark the thread-safe functions as
able to be destroyed nor does napi_ref_threadsafe_function prevent it from
being destroyed. napi_acquire_threadsafe_function and
napi_release_threadsafe_function are available for that purpose.
This API may only be called from the main thread.

napi_unref_threadsafe_function#

Added in: v10.6.0
N-API version: 4

NAPI_EXTERN napi_status
napi_unref_threadsafe_function(node_api_basic_env env, napi_threadsafe_function func); copy

[in] env: The environment that the API is invoked under.
[in] func: The thread-safe function to unreference.

This API is used to indicate that the event loop running on the main thread
may exit before func is destroyed. Similar to uv_unref it is also
idempotent.
This API may only be called from the main thread.

Miscellaneous utilities#

node_api_get_module_file_name#

Added in: v15.9.0, v14.18.0, v12.22.0
N-API version: 9

NAPI_EXTERN napi_status
node_api_get_module_file_name(node_api_basic_env env, const char** result);
 copy

[in] env: The environment that the API is invoked under.
[out] result: A URL containing the absolute path of the
location from which the add-on was loaded. For a file on the local
file system it will start with file://. The string is null-terminated and
owned by env and must thus not be modified or freed.

result may be an empty string if the add-on loading process fails to establish
the add-on's file name during loading.\n\n\n\nNode.js
        
      
      
About this documentation
Usage and example



Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Modules: TypeScript
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
Readline
REPL
Report
Single executable applications
SQLite
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker

    

    
      
        
          Node.js v24.0.1 documentation
          
            
            
          
        
        
          
            Node.js v24.0.1
            
    
      
        
        Table of contents
      

      
C++ embedder API

Example embedding application

Setting up a per-process state
Setting up a per-instance state





    
  
            
    
      
        
        Index
      

      
About this documentation
Usage and example

      
        Index
      
    
  


Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Modules: TypeScript
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
Readline
REPL
Report
Single executable applications
SQLite
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker

    
  
            
    
      
        
        Other versions
      
      24.x
23.x
22.x LTS
21.x
20.x LTS
19.x
18.x
17.x
16.x
15.x
14.x
13.x
12.x
    
  
            
              
                
                Options
              
        
              
                
                  
                    View on single page
                  
                  
                    View as JSON
                  
                  Edit on GitHub    
                
              
            
          
        
        
      

      Table of contents
C++ embedder API

Example embedding application

Setting up a per-process state
Setting up a per-instance state






      
        C++ embedder API#

Node.js provides a number of C++ APIs that can be used to execute JavaScript
in a Node.js environment from other C++ software.
The documentation for these APIs can be found in src/node.h in the Node.js
source tree. In addition to the APIs exposed by Node.js, some required concepts
are provided by the V8 embedder API.
Because using Node.js as an embedded library is different from writing code
that is executed by Node.js, breaking changes do not follow typical Node.js
deprecation policy and may occur on each semver-major release without prior
warning.
Example embedding application#
The following sections will provide an overview over how to use these APIs
to create an application from scratch that will perform the equivalent of
node -e <code>, i.e. that will take a piece of JavaScript and run it in
a Node.js-specific environment.
The full code can be found in the Node.js source tree.

Setting up a per-process state#
Node.js requires some per-process state management in order to run:

Arguments parsing for Node.js CLI options,
V8 per-process requirements, such as a v8::Platform instance.

The following example shows how these can be set up. Some class names are from
the node and v8 C++ namespaces, respectively.
int main(int argc, char** argv) {
  argv = uv_setup_args(argc, argv);
  std::vector<std::string> args(argv, argv + argc);
  // Parse Node.js CLI options, and print any errors that have occurred while
  // trying to parse them.
  std::unique_ptr<node::InitializationResult> result =
      node::InitializeOncePerProcess(args, {
        node::ProcessInitializationFlags::kNoInitializeV8,
        node::ProcessInitializationFlags::kNoInitializeNodeV8Platform
      });

  for (const std::string& error : result->errors())
    fprintf(stderr, "%s: %s\n", args[0].c_str(), error.c_str());
  if (result->early_return() != 0) {
    return result->exit_code();
  }

  // Create a v8::Platform instance. `MultiIsolatePlatform::Create()` is a way
  // to create a v8::Platform instance that Node.js can use when creating
  // Worker threads. When no `MultiIsolatePlatform` instance is present,
  // Worker threads are disabled.
  std::unique_ptr<MultiIsolatePlatform> platform =
      MultiIsolatePlatform::Create(4);
  V8::InitializePlatform(platform.get());
  V8::Initialize();

  // See below for the contents of this function.
  int ret = RunNodeInstance(
      platform.get(), result->args(), result->exec_args());

  V8::Dispose();
  V8::DisposePlatform();

  node::TearDownOncePerProcess();
  return ret;
} copy

Setting up a per-instance state#

History

VersionChanges
v15.0.0
The CommonEnvironmentSetup and SpinEventLoop utilities were added.



Node.js has a concept of a “Node.js instance”, that is commonly being referred
to as node::Environment. Each node::Environment is associated with:

Exactly one v8::Isolate, i.e. one JS Engine instance,
Exactly one uv_loop_t, i.e. one event loop,
A number of v8::Contexts, but exactly one main v8::Context, and
One node::IsolateData instance that contains information that could be
shared by multiple node::Environments. The embedder should make sure
that node::IsolateData is shared only among node::Environments that
use the same v8::Isolate, Node.js does not perform this check.

In order to set up a v8::Isolate, an v8::ArrayBuffer::Allocator needs
to be provided. One possible choice is the default Node.js allocator, which
can be created through node::ArrayBufferAllocator::Create(). Using the Node.js
allocator allows minor performance optimizations when addons use the Node.js
C++ Buffer API, and is required in order to track ArrayBuffer memory in
process.memoryUsage().
Additionally, each v8::Isolate that is used for a Node.js instance needs to
be registered and unregistered with the MultiIsolatePlatform instance, if one
is being used, in order for the platform to know which event loop to use
for tasks scheduled by the v8::Isolate.
The node::NewIsolate() helper function creates a v8::Isolate,
sets it up with some Node.js-specific hooks (e.g. the Node.js error handler),
and registers it with the platform automatically.
int RunNodeInstance(MultiIsolatePlatform* platform,
                    const std::vector<std::string>& args,
                    const std::vector<std::string>& exec_args) {
  int exit_code = 0;

  // Setup up a libuv event loop, v8::Isolate, and Node.js Environment.
  std::vector<std::string> errors;
  std::unique_ptr<CommonEnvironmentSetup> setup =
      CommonEnvironmentSetup::Create(platform, &errors, args, exec_args);
  if (!setup) {
    for (const std::string& err : errors)
      fprintf(stderr, "%s: %s\n", args[0].c_str(), err.c_str());
    return 1;
  }

  Isolate* isolate = setup->isolate();
  Environment* env = setup->env();

  {
    Locker locker(isolate);
    Isolate::Scope isolate_scope(isolate);
    HandleScope handle_scope(isolate);
    // The v8::Context needs to be entered when node::CreateEnvironment() and
    // node::LoadEnvironment() are being called.
    Context::Scope context_scope(setup->context());

    // Set up the Node.js instance for execution, and run code inside of it.
    // There is also a variant that takes a callback and provides it with
    // the `require` and `process` objects, so that it can manually compile
    // and run scripts as needed.
    // The `require` function inside this script does *not* access the file
    // system, and can only load built-in Node.js modules.
    // `module.createRequire()` is being used to create one that is able to
    // load files from the disk, and uses the standard CommonJS file loader
    // instead of the internal-only `require` function.
    MaybeLocal<Value> loadenv_ret = node::LoadEnvironment(
        env,
        "const publicRequire ="
        "  require('node:module').createRequire(process.cwd() + '/');"
        "globalThis.require = publicRequire;"
        "require('node:vm').runInThisContext(process.argv[1]);");

    if (loadenv_ret.IsEmpty())  // There has been a JS exception.
      return 1;

    exit_code = node::SpinEventLoop(env).FromMaybe(1);

    // node::Stop() can be used to explicitly stop the event loop and keep
    // further JavaScript from running. It can be called from any thread,
    // and will act like worker.terminate() if called from another thread.
    node::Stop(env);
  }

  return exit_code;
} copy\n\n\n\nNode.js
        
      
      
About this documentation
Usage and example



Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Modules: TypeScript
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
Readline
REPL
Report
Single executable applications
SQLite
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker

    

    
      
        
          Node.js v24.0.1 documentation
          
            
            
          
        
        
          
            Node.js v24.0.1
            
    
      
        
        Table of contents
      

      
Child process

Asynchronous process creation

Spawning .bat and .cmd files on Windows
child_process.exec(command[, options][, callback])
child_process.execFile(file[, args][, options][, callback])
child_process.fork(modulePath[, args][, options])
child_process.spawn(command[, args][, options])

options.detached
options.stdio




Synchronous process creation

child_process.execFileSync(file[, args][, options])
child_process.execSync(command[, options])
child_process.spawnSync(command[, args][, options])


Class: ChildProcess

Event: 'close'
Event: 'disconnect'
Event: 'error'
Event: 'exit'
Event: 'message'
Event: 'spawn'
subprocess.channel

subprocess.channel.ref()
subprocess.channel.unref()


subprocess.connected
subprocess.disconnect()
subprocess.exitCode
subprocess.kill([signal])
subprocess[Symbol.dispose]()
subprocess.killed
subprocess.pid
subprocess.ref()
subprocess.send(message[, sendHandle[, options]][, callback])

Example: sending a server object
Example: sending a socket object


subprocess.signalCode
subprocess.spawnargs
subprocess.spawnfile
subprocess.stderr
subprocess.stdin
subprocess.stdio
subprocess.stdout
subprocess.unref()


maxBuffer and Unicode
Shell requirements
Default Windows shell
Advanced serialization



    
  
            
    
      
        
        Index
      

      
About this documentation
Usage and example

      
        Index
      
    
  


Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Modules: TypeScript
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
Readline
REPL
Report
Single executable applications
SQLite
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker

    
  
            
    
      
        
        Other versions
      
      24.x
23.x
22.x LTS
21.x
20.x LTS
19.x
18.x
17.x
16.x
15.x
14.x
13.x
12.x
11.x
10.x
9.x
8.x
7.x
6.x
5.x
4.x
0.12.x
0.10.x
    
  
            
              
                
                Options
              
        
              
                
                  
                    View on single page
                  
                  
                    View as JSON
                  
                  Edit on GitHub    
                
              
            
          
        
        
      

      Table of contents
Child process

Asynchronous process creation

Spawning .bat and .cmd files on Windows
child_process.exec(command[, options][, callback])
child_process.execFile(file[, args][, options][, callback])
child_process.fork(modulePath[, args][, options])
child_process.spawn(command[, args][, options])

options.detached
options.stdio




Synchronous process creation

child_process.execFileSync(file[, args][, options])
child_process.execSync(command[, options])
child_process.spawnSync(command[, args][, options])


Class: ChildProcess

Event: 'close'
Event: 'disconnect'
Event: 'error'
Event: 'exit'
Event: 'message'
Event: 'spawn'
subprocess.channel

subprocess.channel.ref()
subprocess.channel.unref()


subprocess.connected
subprocess.disconnect()
subprocess.exitCode
subprocess.kill([signal])
subprocess[Symbol.dispose]()
subprocess.killed
subprocess.pid
subprocess.ref()
subprocess.send(message[, sendHandle[, options]][, callback])

Example: sending a server object
Example: sending a socket object


subprocess.signalCode
subprocess.spawnargs
subprocess.spawnfile
subprocess.stderr
subprocess.stdin
subprocess.stdio
subprocess.stdout
subprocess.unref()


maxBuffer and Unicode
Shell requirements
Default Windows shell
Advanced serialization




      
        Child process#

Stability: 2 - Stable
Source Code: lib/child_process.js
The node:child_process module provides the ability to spawn subprocesses in
a manner that is similar, but not identical, to popen(3). This capability
is primarily provided by the child_process.spawn() function:

const { spawn } = require('node:child_process');
const ls = spawn('ls', ['-lh', '/usr']);

ls.stdout.on('data', (data) => {
  console.log(`stdout: ${data}`);
});

ls.stderr.on('data', (data) => {
  console.error(`stderr: ${data}`);
});

ls.on('close', (code) => {
  console.log(`child process exited with code ${code}`);
});import { spawn } from 'node:child_process';
const ls = spawn('ls', ['-lh', '/usr']);

ls.stdout.on('data', (data) => {
  console.log(`stdout: ${data}`);
});

ls.stderr.on('data', (data) => {
  console.error(`stderr: ${data}`);
});

ls.on('close', (code) => {
  console.log(`child process exited with code ${code}`);
});copy
By default, pipes for stdin, stdout, and stderr are established between
the parent Node.js process and the spawned subprocess. These pipes have
limited (and platform-specific) capacity. If the subprocess writes to
stdout in excess of that limit without the output being captured, the
subprocess blocks waiting for the pipe buffer to accept more data. This is
identical to the behavior of pipes in the shell. Use the { stdio: 'ignore' }
option if the output will not be consumed.
The command lookup is performed using the options.env.PATH environment
variable if env is in the options object. Otherwise, process.env.PATH is
used. If options.env is set without PATH, lookup on Unix is performed
on a default search path search of /usr/bin:/bin (see your operating system's
manual for execvpe/execvp), on Windows the current processes environment
variable PATH is used.
On Windows, environment variables are case-insensitive. Node.js
lexicographically sorts the env keys and uses the first one that
case-insensitively matches. Only first (in lexicographic order) entry will be
passed to the subprocess. This might lead to issues on Windows when passing
objects to the env option that have multiple variants of the same key, such as
PATH and Path.
The child_process.spawn() method spawns the child process asynchronously,
without blocking the Node.js event loop. The child_process.spawnSync()
function provides equivalent functionality in a synchronous manner that blocks
the event loop until the spawned process either exits or is terminated.
For convenience, the node:child_process module provides a handful of
synchronous and asynchronous alternatives to child_process.spawn() and
child_process.spawnSync(). Each of these alternatives are implemented on
top of child_process.spawn() or child_process.spawnSync().

child_process.exec(): spawns a shell and runs a command within that
shell, passing the stdout and stderr to a callback function when
complete.
child_process.execFile(): similar to child_process.exec() except
that it spawns the command directly without first spawning a shell by
default.
child_process.fork(): spawns a new Node.js process and invokes a
specified module with an IPC communication channel established that allows
sending messages between parent and child.
child_process.execSync(): a synchronous version of
child_process.exec() that will block the Node.js event loop.
child_process.execFileSync(): a synchronous version of
child_process.execFile() that will block the Node.js event loop.

For certain use cases, such as automating shell scripts, the
synchronous counterparts may be more convenient. In many cases, however,
the synchronous methods can have significant impact on performance due to
stalling the event loop while spawned processes complete.
Asynchronous process creation#
The child_process.spawn(), child_process.fork(), child_process.exec(),
and child_process.execFile() methods all follow the idiomatic asynchronous
programming pattern typical of other Node.js APIs.
Each of the methods returns a ChildProcess instance. These objects
implement the Node.js EventEmitter API, allowing the parent process to
register listener functions that are called when certain events occur during
the life cycle of the child process.
The child_process.exec() and child_process.execFile() methods
additionally allow for an optional callback function to be specified that is
invoked when the child process terminates.

Spawning .bat and .cmd files on Windows#
The importance of the distinction between child_process.exec() and
child_process.execFile() can vary based on platform. On Unix-type
operating systems (Unix, Linux, macOS) child_process.execFile() can be
more efficient because it does not spawn a shell by default. On Windows,
however, .bat and .cmd files are not executable on their own without a
terminal, and therefore cannot be launched using child_process.execFile().
When running on Windows, .bat and .cmd files can be invoked using
child_process.spawn() with the shell option set, with
child_process.exec(), or by spawning cmd.exe and passing the .bat or
.cmd file as an argument (which is what the shell option and
child_process.exec() do). In any case, if the script filename contains
spaces it needs to be quoted.

// OR...
const { exec, spawn } = require('node:child_process');

exec('my.bat', (err, stdout, stderr) => {
  if (err) {
    console.error(err);
    return;
  }
  console.log(stdout);
});

// Script with spaces in the filename:
const bat = spawn('"my script.cmd" a b', { shell: true });
// or:
exec('"my script.cmd" a b', (err, stdout, stderr) => {
  // ...
});// OR...
import { exec, spawn } from 'node:child_process';

exec('my.bat', (err, stdout, stderr) => {
  if (err) {
    console.error(err);
    return;
  }
  console.log(stdout);
});

// Script with spaces in the filename:
const bat = spawn('"my script.cmd" a b', { shell: true });
// or:
exec('"my script.cmd" a b', (err, stdout, stderr) => {
  // ...
});copy

child_process.exec(command[, options][, callback])#

History

VersionChanges
v15.4.0
AbortSignal support was added.
v16.4.0, v14.18.0
The cwd option can be a WHATWG URL object using file: protocol.
v8.8.0
The windowsHide option is supported now.
v0.1.90
Added in: v0.1.90




command <string> The command to run, with space-separated arguments.
options <Object>

cwd <string> | <URL> Current working directory of the child process.
Default: process.cwd().
env <Object> Environment key-value pairs. Default: process.env.
encoding <string> Default: 'utf8'
shell <string> Shell to execute the command with. See
Shell requirements and Default Windows shell. Default:
'/bin/sh' on Unix, process.env.ComSpec on Windows.
signal <AbortSignal> allows aborting the child process using an
AbortSignal.
timeout <number> Default: 0
maxBuffer <number> Largest amount of data in bytes allowed on stdout or
stderr. If exceeded, the child process is terminated and any output is
truncated. See caveat at maxBuffer and Unicode.
Default: 1024 * 1024.
killSignal <string> | <integer> Default: 'SIGTERM'
uid <number> Sets the user identity of the process (see setuid(2)).
gid <number> Sets the group identity of the process (see setgid(2)).
windowsHide <boolean> Hide the subprocess console window that would
normally be created on Windows systems. Default: false.


callback <Function> called with the output when process terminates.

error <Error>
stdout <string> | <Buffer>
stderr <string> | <Buffer>


Returns: <ChildProcess>

Spawns a shell then executes the command within that shell, buffering any
generated output. The command string passed to the exec function is processed
directly by the shell and special characters (vary based on
shell)
need to be dealt with accordingly:

const { exec } = require('node:child_process');

exec('"/path/to/test file/test.sh" arg1 arg2');
// Double quotes are used so that the space in the path is not interpreted as
// a delimiter of multiple arguments.

exec('echo "The \\$HOME variable is $HOME"');
// The $HOME variable is escaped in the first instance, but not in the second.import { exec } from 'node:child_process';

exec('"/path/to/test file/test.sh" arg1 arg2');
// Double quotes are used so that the space in the path is not interpreted as
// a delimiter of multiple arguments.

exec('echo "The \\$HOME variable is $HOME"');
// The $HOME variable is escaped in the first instance, but not in the second.copy
Never pass unsanitized user input to this function. Any input containing shell
metacharacters may be used to trigger arbitrary command execution.
If a callback function is provided, it is called with the arguments
(error, stdout, stderr). On success, error will be null. On error,
error will be an instance of Error. The error.code property will be
the exit code of the process. By convention, any exit code other than 0
indicates an error. error.signal will be the signal that terminated the
process.
The stdout and stderr arguments passed to the callback will contain the
stdout and stderr output of the child process. By default, Node.js will decode
the output as UTF-8 and pass strings to the callback. The encoding option
can be used to specify the character encoding used to decode the stdout and
stderr output. If encoding is 'buffer', or an unrecognized character
encoding, Buffer objects will be passed to the callback instead.

const { exec } = require('node:child_process');
exec('cat *.js missing_file | wc -l', (error, stdout, stderr) => {
  if (error) {
    console.error(`exec error: ${error}`);
    return;
  }
  console.log(`stdout: ${stdout}`);
  console.error(`stderr: ${stderr}`);
});import { exec } from 'node:child_process';
exec('cat *.js missing_file | wc -l', (error, stdout, stderr) => {
  if (error) {
    console.error(`exec error: ${error}`);
    return;
  }
  console.log(`stdout: ${stdout}`);
  console.error(`stderr: ${stderr}`);
});copy
If timeout is greater than 0, the parent process will send the signal
identified by the killSignal property (the default is 'SIGTERM') if the
child process runs longer than timeout milliseconds.
Unlike the exec(3) POSIX system call, child_process.exec() does not replace
the existing process and uses a shell to execute the command.
If this method is invoked as its util.promisify()ed version, it returns
a Promise for an Object with stdout and stderr properties. The returned
ChildProcess instance is attached to the Promise as a child property. In
case of an error (including any error resulting in an exit code other than 0), a
rejected promise is returned, with the same error object given in the
callback, but with two additional properties stdout and stderr.

const util = require('node:util');
const exec = util.promisify(require('node:child_process').exec);

async function lsExample() {
  const { stdout, stderr } = await exec('ls');
  console.log('stdout:', stdout);
  console.error('stderr:', stderr);
}
lsExample();import { promisify } from 'node:util';
import child_process from 'node:child_process';
const exec = promisify(child_process.exec);

async function lsExample() {
  const { stdout, stderr } = await exec('ls');
  console.log('stdout:', stdout);
  console.error('stderr:', stderr);
}
lsExample();copy
If the signal option is enabled, calling .abort() on the corresponding
AbortController is similar to calling .kill() on the child process except
the error passed to the callback will be an AbortError:

const { exec } = require('node:child_process');
const controller = new AbortController();
const { signal } = controller;
const child = exec('grep ssh', { signal }, (error) => {
  console.error(error); // an AbortError
});
controller.abort();import { exec } from 'node:child_process';
const controller = new AbortController();
const { signal } = controller;
const child = exec('grep ssh', { signal }, (error) => {
  console.error(error); // an AbortError
});
controller.abort();copy

child_process.execFile(file[, args][, options][, callback])#

History

VersionChanges
v23.11.0, v22.15.0
Passing args when shell is set to true is deprecated.
v16.4.0, v14.18.0
The cwd option can be a WHATWG URL object using file: protocol.
v15.4.0, v14.17.0
AbortSignal support was added.
v8.8.0
The windowsHide option is supported now.
v0.1.91
Added in: v0.1.91




file <string> The name or path of the executable file to run.
args <string[]> List of string arguments.
options <Object>

cwd <string> | <URL> Current working directory of the child process.
env <Object> Environment key-value pairs. Default: process.env.
encoding <string> Default: 'utf8'
timeout <number> Default: 0
maxBuffer <number> Largest amount of data in bytes allowed on stdout or
stderr. If exceeded, the child process is terminated and any output is
truncated. See caveat at maxBuffer and Unicode.
Default: 1024 * 1024.
killSignal <string> | <integer> Default: 'SIGTERM'
uid <number> Sets the user identity of the process (see setuid(2)).
gid <number> Sets the group identity of the process (see setgid(2)).
windowsHide <boolean> Hide the subprocess console window that would
normally be created on Windows systems. Default: false.
windowsVerbatimArguments <boolean> No quoting or escaping of arguments is
done on Windows. Ignored on Unix. Default: false.
shell <boolean> | <string> If true, runs command inside of a shell. Uses
'/bin/sh' on Unix, and process.env.ComSpec on Windows. A different
shell can be specified as a string. See Shell requirements and
Default Windows shell. Default: false (no shell).
signal <AbortSignal> allows aborting the child process using an
AbortSignal.


callback <Function> Called with the output when process terminates.

error <Error>
stdout <string> | <Buffer>
stderr <string> | <Buffer>


Returns: <ChildProcess>

The child_process.execFile() function is similar to child_process.exec()
except that it does not spawn a shell by default. Rather, the specified
executable file is spawned directly as a new process making it slightly more
efficient than child_process.exec().
The same options as child_process.exec() are supported. Since a shell is
not spawned, behaviors such as I/O redirection and file globbing are not
supported.

const { execFile } = require('node:child_process');
const child = execFile('node', ['--version'], (error, stdout, stderr) => {
  if (error) {
    throw error;
  }
  console.log(stdout);
});import { execFile } from 'node:child_process';
const child = execFile('node', ['--version'], (error, stdout, stderr) => {
  if (error) {
    throw error;
  }
  console.log(stdout);
});copy
The stdout and stderr arguments passed to the callback will contain the
stdout and stderr output of the child process. By default, Node.js will decode
the output as UTF-8 and pass strings to the callback. The encoding option
can be used to specify the character encoding used to decode the stdout and
stderr output. If encoding is 'buffer', or an unrecognized character
encoding, Buffer objects will be passed to the callback instead.
If this method is invoked as its util.promisify()ed version, it returns
a Promise for an Object with stdout and stderr properties. The returned
ChildProcess instance is attached to the Promise as a child property. In
case of an error (including any error resulting in an exit code other than 0), a
rejected promise is returned, with the same error object given in the
callback, but with two additional properties stdout and stderr.

const util = require('node:util');
const execFile = util.promisify(require('node:child_process').execFile);
async function getVersion() {
  const { stdout } = await execFile('node', ['--version']);
  console.log(stdout);
}
getVersion();import { promisify } from 'node:util';
import child_process from 'node:child_process';
const execFile = promisify(child_process.execFile);
async function getVersion() {
  const { stdout } = await execFile('node', ['--version']);
  console.log(stdout);
}
getVersion();copy
If the shell option is enabled, do not pass unsanitized user input to this
function. Any input containing shell metacharacters may be used to trigger
arbitrary command execution.
If the signal option is enabled, calling .abort() on the corresponding
AbortController is similar to calling .kill() on the child process except
the error passed to the callback will be an AbortError:

const { execFile } = require('node:child_process');
const controller = new AbortController();
const { signal } = controller;
const child = execFile('node', ['--version'], { signal }, (error) => {
  console.error(error); // an AbortError
});
controller.abort();import { execFile } from 'node:child_process';
const controller = new AbortController();
const { signal } = controller;
const child = execFile('node', ['--version'], { signal }, (error) => {
  console.error(error); // an AbortError
});
controller.abort();copy

child_process.fork(modulePath[, args][, options])#

History

VersionChanges
v17.4.0, v16.14.0
The modulePath parameter can be a WHATWG URL object using file: protocol.
v16.4.0, v14.18.0
The cwd option can be a WHATWG URL object using file: protocol.
v15.13.0, v14.18.0
timeout was added.
v15.11.0, v14.18.0
killSignal for AbortSignal was added.
v15.6.0, v14.17.0
AbortSignal support was added.
v13.2.0, v12.16.0
The serialization option is supported now.
v8.0.0
The stdio option can now be a string.
v6.4.0
The stdio option is supported now.
v0.5.0
Added in: v0.5.0




modulePath <string> | <URL> The module to run in the child.
args <string[]> List of string arguments.
options <Object>

cwd <string> | <URL> Current working directory of the child process.
detached <boolean> Prepare child process to run independently of its
parent process. Specific behavior depends on the platform (see
options.detached).
env <Object> Environment key-value pairs. Default: process.env.
execPath <string> Executable used to create the child process.
execArgv <string[]> List of string arguments passed to the executable.
Default: process.execArgv.
gid <number> Sets the group identity of the process (see setgid(2)).
serialization <string> Specify the kind of serialization used for sending
messages between processes. Possible values are 'json' and 'advanced'.
See Advanced serialization for more details. Default: 'json'.
signal <AbortSignal> Allows closing the child process using an
AbortSignal.
killSignal <string> | <integer> The signal value to be used when the spawned
process will be killed by timeout or abort signal. Default: 'SIGTERM'.
silent <boolean> If true, stdin, stdout, and stderr of the child
process will be piped to the parent process, otherwise they will be inherited
from the parent process, see the 'pipe' and 'inherit' options for
child_process.spawn()'s stdio for more details.
Default: false.
stdio <Array> | <string> See child_process.spawn()'s stdio.
When this option is provided, it overrides silent. If the array variant
is used, it must contain exactly one item with value 'ipc' or an error
will be thrown. For instance [0, 1, 2, 'ipc'].
uid <number> Sets the user identity of the process (see setuid(2)).
windowsVerbatimArguments <boolean> No quoting or escaping of arguments is
done on Windows. Ignored on Unix. Default: false.
timeout <number> In milliseconds the maximum amount of time the process
is allowed to run. Default: undefined.


Returns: <ChildProcess>

The child_process.fork() method is a special case of
child_process.spawn() used specifically to spawn new Node.js processes.
Like child_process.spawn(), a ChildProcess object is returned. The
returned ChildProcess will have an additional communication channel
built-in that allows messages to be passed back and forth between the parent and
child. See subprocess.send() for details.
Keep in mind that spawned Node.js child processes are
independent of the parent with exception of the IPC communication channel
that is established between the two. Each process has its own memory, with
their own V8 instances. Because of the additional resource allocations
required, spawning a large number of child Node.js processes is not
recommended.
By default, child_process.fork() will spawn new Node.js instances using the
process.execPath of the parent process. The execPath property in the
options object allows for an alternative execution path to be used.
Node.js processes launched with a custom execPath will communicate with the
parent process using the file descriptor (fd) identified using the
environment variable NODE_CHANNEL_FD on the child process.
Unlike the fork(2) POSIX system call, child_process.fork() does not clone the
current process.
The shell option available in child_process.spawn() is not supported by
child_process.fork() and will be ignored if set.
If the signal option is enabled, calling .abort() on the corresponding
AbortController is similar to calling .kill() on the child process except
the error passed to the callback will be an AbortError:

const { fork } = require('node:child_process');
const process = require('node:process');

if (process.argv[2] === 'child') {
  setTimeout(() => {
    console.log(`Hello from ${process.argv[2]}!`);
  }, 1_000);
} else {
  const controller = new AbortController();
  const { signal } = controller;
  const child = fork(__filename, ['child'], { signal });
  child.on('error', (err) => {
    // This will be called with err being an AbortError if the controller aborts
  });
  controller.abort(); // Stops the child process
}import { fork } from 'node:child_process';
import process from 'node:process';

if (process.argv[2] === 'child') {
  setTimeout(() => {
    console.log(`Hello from ${process.argv[2]}!`);
  }, 1_000);
} else {
  const controller = new AbortController();
  const { signal } = controller;
  const child = fork(import.meta.url, ['child'], { signal });
  child.on('error', (err) => {
    // This will be called with err being an AbortError if the controller aborts
  });
  controller.abort(); // Stops the child process
}copy

child_process.spawn(command[, args][, options])#

History

VersionChanges
v23.11.0, v22.15.0
Passing args when shell is set to true is deprecated.
v16.4.0, v14.18.0
The cwd option can be a WHATWG URL object using file: protocol.
v15.13.0, v14.18.0
timeout was added.
v15.11.0, v14.18.0
killSignal for AbortSignal was added.
v15.5.0, v14.17.0
AbortSignal support was added.
v13.2.0, v12.16.0
The serialization option is supported now.
v8.8.0
The windowsHide option is supported now.
v6.4.0
The argv0 option is supported now.
v5.7.0
The shell option is supported now.
v0.1.90
Added in: v0.1.90




command <string> The command to run.
args <string[]> List of string arguments.
options <Object>

cwd <string> | <URL> Current working directory of the child process.
env <Object> Environment key-value pairs. Default: process.env.
argv0 <string> Explicitly set the value of argv[0] sent to the child
process. This will be set to command if not specified.
stdio <Array> | <string> Child's stdio configuration (see
options.stdio).
detached <boolean> Prepare child process to run independently of
its parent process. Specific behavior depends on the platform (see
options.detached).
uid <number> Sets the user identity of the process (see setuid(2)).
gid <number> Sets the group identity of the process (see setgid(2)).
serialization <string> Specify the kind of serialization used for sending
messages between processes. Possible values are 'json' and 'advanced'.
See Advanced serialization for more details. Default: 'json'.
shell <boolean> | <string> If true, runs command inside of a shell. Uses
'/bin/sh' on Unix, and process.env.ComSpec on Windows. A different
shell can be specified as a string. See Shell requirements and
Default Windows shell. Default: false (no shell).
windowsVerbatimArguments <boolean> No quoting or escaping of arguments is
done on Windows. Ignored on Unix. This is set to true automatically
when shell is specified and is CMD. Default: false.
windowsHide <boolean> Hide the subprocess console window that would
normally be created on Windows systems. Default: false.
signal <AbortSignal> allows aborting the child process using an
AbortSignal.
timeout <number> In milliseconds the maximum amount of time the process
is allowed to run. Default: undefined.
killSignal <string> | <integer> The signal value to be used when the spawned
process will be killed by timeout or abort signal. Default: 'SIGTERM'.


Returns: <ChildProcess>

The child_process.spawn() method spawns a new process using the given
command, with command-line arguments in args. If omitted, args defaults
to an empty array.
If the shell option is enabled, do not pass unsanitized user input to this
function. Any input containing shell metacharacters may be used to trigger
arbitrary command execution.
A third argument may be used to specify additional options, with these defaults:
const defaults = {
  cwd: undefined,
  env: process.env,
}; copy
Use cwd to specify the working directory from which the process is spawned.
If not given, the default is to inherit the current working directory. If given,
but the path does not exist, the child process emits an ENOENT error
and exits immediately. ENOENT is also emitted when the command
does not exist.
Use env to specify environment variables that will be visible to the new
process, the default is process.env.
undefined values in env will be ignored.
Example of running ls -lh /usr, capturing stdout, stderr, and the
exit code:

const { spawn } = require('node:child_process');
const ls = spawn('ls', ['-lh', '/usr']);

ls.stdout.on('data', (data) => {
  console.log(`stdout: ${data}`);
});

ls.stderr.on('data', (data) => {
  console.error(`stderr: ${data}`);
});

ls.on('close', (code) => {
  console.log(`child process exited with code ${code}`);
});import { spawn } from 'node:child_process';
const ls = spawn('ls', ['-lh', '/usr']);

ls.stdout.on('data', (data) => {
  console.log(`stdout: ${data}`);
});

ls.stderr.on('data', (data) => {
  console.error(`stderr: ${data}`);
});

ls.on('close', (code) => {
  console.log(`child process exited with code ${code}`);
});copy
Example: A very elaborate way to run ps ax | grep ssh

const { spawn } = require('node:child_process');
const ps = spawn('ps', ['ax']);
const grep = spawn('grep', ['ssh']);

ps.stdout.on('data', (data) => {
  grep.stdin.write(data);
});

ps.stderr.on('data', (data) => {
  console.error(`ps stderr: ${data}`);
});

ps.on('close', (code) => {
  if (code !== 0) {
    console.log(`ps process exited with code ${code}`);
  }
  grep.stdin.end();
});

grep.stdout.on('data', (data) => {
  console.log(data.toString());
});

grep.stderr.on('data', (data) => {
  console.error(`grep stderr: ${data}`);
});

grep.on('close', (code) => {
  if (code !== 0) {
    console.log(`grep process exited with code ${code}`);
  }
});import { spawn } from 'node:child_process';
const ps = spawn('ps', ['ax']);
const grep = spawn('grep', ['ssh']);

ps.stdout.on('data', (data) => {
  grep.stdin.write(data);
});

ps.stderr.on('data', (data) => {
  console.error(`ps stderr: ${data}`);
});

ps.on('close', (code) => {
  if (code !== 0) {
    console.log(`ps process exited with code ${code}`);
  }
  grep.stdin.end();
});

grep.stdout.on('data', (data) => {
  console.log(data.toString());
});

grep.stderr.on('data', (data) => {
  console.error(`grep stderr: ${data}`);
});

grep.on('close', (code) => {
  if (code !== 0) {
    console.log(`grep process exited with code ${code}`);
  }
});copy
Example of checking for failed spawn:

const { spawn } = require('node:child_process');
const subprocess = spawn('bad_command');

subprocess.on('error', (err) => {
  console.error('Failed to start subprocess.');
});import { spawn } from 'node:child_process';
const subprocess = spawn('bad_command');

subprocess.on('error', (err) => {
  console.error('Failed to start subprocess.');
});copy
Certain platforms (macOS, Linux) will use the value of argv[0] for the process
title while others (Windows, SunOS) will use command.
Node.js overwrites argv[0] with process.execPath on startup, so
process.argv[0] in a Node.js child process will not match the argv0
parameter passed to spawn from the parent. Retrieve it with the
process.argv0 property instead.
If the signal option is enabled, calling .abort() on the corresponding
AbortController is similar to calling .kill() on the child process except
the error passed to the callback will be an AbortError:

const { spawn } = require('node:child_process');
const controller = new AbortController();
const { signal } = controller;
const grep = spawn('grep', ['ssh'], { signal });
grep.on('error', (err) => {
  // This will be called with err being an AbortError if the controller aborts
});
controller.abort(); // Stops the child processimport { spawn } from 'node:child_process';
const controller = new AbortController();
const { signal } = controller;
const grep = spawn('grep', ['ssh'], { signal });
grep.on('error', (err) => {
  // This will be called with err being an AbortError if the controller aborts
});
controller.abort(); // Stops the child processcopy

options.detached#

Added in: v0.7.10

On Windows, setting options.detached to true makes it possible for the
child process to continue running after the parent exits. The child process
will have its own console window. Once enabled for a child process,
it cannot be disabled.
On non-Windows platforms, if options.detached is set to true, the child
process will be made the leader of a new process group and session. Child
processes may continue running after the parent exits regardless of whether
they are detached or not. See setsid(2) for more information.
By default, the parent will wait for the detached child process to exit.
To prevent the parent process from waiting for a given subprocess to exit, use
the subprocess.unref() method. Doing so will cause the parent process' event
loop to not include the child process in its reference count, allowing the
parent process to exit independently of the child process, unless there is an established
IPC channel between the child and the parent processes.
When using the detached option to start a long-running process, the process
will not stay running in the background after the parent exits unless it is
provided with a stdio configuration that is not connected to the parent.
If the parent process' stdio is inherited, the child process will remain attached
to the controlling terminal.
Example of a long-running process, by detaching and also ignoring its parent
stdio file descriptors, in order to ignore the parent's termination:

const { spawn } = require('node:child_process');
const process = require('node:process');

const subprocess = spawn(process.argv[0], ['child_program.js'], {
  detached: true,
  stdio: 'ignore',
});

subprocess.unref();import { spawn } from 'node:child_process';
import process from 'node:process';

const subprocess = spawn(process.argv[0], ['child_program.js'], {
  detached: true,
  stdio: 'ignore',
});

subprocess.unref();copy
Alternatively one can redirect the child process' output into files:

const { openSync } = require('node:fs');
const { spawn } = require('node:child_process');
const out = openSync('./out.log', 'a');
const err = openSync('./out.log', 'a');

const subprocess = spawn('prg', [], {
  detached: true,
  stdio: [ 'ignore', out, err ],
});

subprocess.unref();import { openSync } from 'node:fs';
import { spawn } from 'node:child_process';
const out = openSync('./out.log', 'a');
const err = openSync('./out.log', 'a');

const subprocess = spawn('prg', [], {
  detached: true,
  stdio: [ 'ignore', out, err ],
});

subprocess.unref();copy

options.stdio#

History

VersionChanges
v15.6.0, v14.18.0
Added the overlapped stdio flag.
v3.3.1
The value 0 is now accepted as a file descriptor.
v0.7.10
Added in: v0.7.10



The options.stdio option is used to configure the pipes that are established
between the parent and child process. By default, the child's stdin, stdout,
and stderr are redirected to corresponding subprocess.stdin,
subprocess.stdout, and subprocess.stderr streams on the
ChildProcess object. This is equivalent to setting the options.stdio
equal to ['pipe', 'pipe', 'pipe'].
For convenience, options.stdio may be one of the following strings:

'pipe': equivalent to ['pipe', 'pipe', 'pipe'] (the default)
'overlapped': equivalent to ['overlapped', 'overlapped', 'overlapped']
'ignore': equivalent to ['ignore', 'ignore', 'ignore']
'inherit': equivalent to ['inherit', 'inherit', 'inherit'] or [0, 1, 2]

Otherwise, the value of options.stdio is an array where each index corresponds
to an fd in the child. The fds 0, 1, and 2 correspond to stdin, stdout,
and stderr, respectively. Additional fds can be specified to create additional
pipes between the parent and child. The value is one of the following:


'pipe': Create a pipe between the child process and the parent process.
The parent end of the pipe is exposed to the parent as a property on the
child_process object as subprocess.stdio[fd]. Pipes
created for fds 0, 1, and 2 are also available as subprocess.stdin,
subprocess.stdout and subprocess.stderr, respectively.
These are not actual Unix pipes and therefore the child process
can not use them by their descriptor files,
e.g. /dev/fd/2 or /dev/stdout.


'overlapped': Same as 'pipe' except that the FILE_FLAG_OVERLAPPED flag
is set on the handle. This is necessary for overlapped I/O on the child
process's stdio handles. See the
docs
for more details. This is exactly the same as 'pipe' on non-Windows
systems.


'ipc': Create an IPC channel for passing messages/file descriptors
between parent and child. A ChildProcess may have at most one IPC
stdio file descriptor. Setting this option enables the
subprocess.send() method. If the child process is a Node.js instance,
the presence of an IPC channel will enable process.send() and
process.disconnect() methods, as well as 'disconnect' and
'message' events within the child process.
Accessing the IPC channel fd in any way other than process.send()
or using the IPC channel with a child process that is not a Node.js instance
is not supported.


'ignore': Instructs Node.js to ignore the fd in the child. While Node.js
will always open fds 0, 1, and 2 for the processes it spawns, setting the fd
to 'ignore' will cause Node.js to open /dev/null and attach it to the
child's fd.


'inherit': Pass through the corresponding stdio stream to/from the
parent process. In the first three positions, this is equivalent to
process.stdin, process.stdout, and process.stderr, respectively. In
any other position, equivalent to 'ignore'.


<Stream> object: Share a readable or writable stream that refers to a tty,
file, socket, or a pipe with the child process. The stream's underlying
file descriptor is duplicated in the child process to the fd that
corresponds to the index in the stdio array. The stream must have an
underlying descriptor (file streams do not start until the 'open' event has
occurred).
NOTE: While it is technically possible to pass stdin as a writable or
stdout/stderr as readable, it is not recommended.
Readable and writable streams are designed with distinct behaviors, and using
them incorrectly (e.g., passing a readable stream where a writable stream is
expected) can lead to unexpected results or errors. This practice is discouraged
as it may result in undefined behavior or dropped callbacks if the stream
encounters errors. Always ensure that stdin is used as writable and
stdout/stderr as readable to maintain the intended flow of data between
the parent and child processes.


Positive integer: The integer value is interpreted as a file descriptor
that is open in the parent process. It is shared with the child
process, similar to how <Stream> objects can be shared. Passing sockets
is not supported on Windows.


null, undefined: Use default value. For stdio fds 0, 1, and 2 (in other
words, stdin, stdout, and stderr) a pipe is created. For fd 3 and up, the
default is 'ignore'.



const { spawn } = require('node:child_process');
const process = require('node:process');

// Child will use parent's stdios.
spawn('prg', [], { stdio: 'inherit' });

// Spawn child sharing only stderr.
spawn('prg', [], { stdio: ['pipe', 'pipe', process.stderr] });

// Open an extra fd=4, to interact with programs presenting a
// startd-style interface.
spawn('prg', [], { stdio: ['pipe', null, null, null, 'pipe'] });import { spawn } from 'node:child_process';
import process from 'node:process';

// Child will use parent's stdios.
spawn('prg', [], { stdio: 'inherit' });

// Spawn child sharing only stderr.
spawn('prg', [], { stdio: ['pipe', 'pipe', process.stderr] });

// Open an extra fd=4, to interact with programs presenting a
// startd-style interface.
spawn('prg', [], { stdio: ['pipe', null, null, null, 'pipe'] });copy
It is worth noting that when an IPC channel is established between the
parent and child processes, and the child process is a Node.js instance,
the child process is launched with the IPC channel unreferenced (using
unref()) until the child process registers an event handler for the
'disconnect' event or the 'message' event. This allows the
child process to exit normally without the process being held open by the
open IPC channel.
See also: child_process.exec() and child_process.fork().

Synchronous process creation#
The child_process.spawnSync(), child_process.execSync(), and
child_process.execFileSync() methods are synchronous and will block the
Node.js event loop, pausing execution of any additional code until the spawned
process exits.
Blocking calls like these are mostly useful for simplifying general-purpose
scripting tasks and for simplifying the loading/processing of application
configuration at startup.

child_process.execFileSync(file[, args][, options])#

History

VersionChanges
v16.4.0, v14.18.0
The cwd option can be a WHATWG URL object using file: protocol.
v10.10.0
The input option can now be any TypedArray or a DataView.
v8.8.0
The windowsHide option is supported now.
v8.0.0
The input option can now be a Uint8Array.
v6.2.1, v4.5.0
The encoding option can now explicitly be set to buffer.
v0.11.12
Added in: v0.11.12




file <string> The name or path of the executable file to run.
args <string[]> List of string arguments.
options <Object>

cwd <string> | <URL> Current working directory of the child process.
input <string> | <Buffer> | <TypedArray> | <DataView> The value which will be passed
as stdin to the spawned process. If stdio[0] is set to 'pipe', Supplying
this value will override stdio[0].
stdio <string> | <Array> Child's stdio configuration.
See child_process.spawn()'s stdio. stderr by default will
be output to the parent process' stderr unless stdio is specified.
Default: 'pipe'.
env <Object> Environment key-value pairs. Default: process.env.
uid <number> Sets the user identity of the process (see setuid(2)).
gid <number> Sets the group identity of the process (see setgid(2)).
timeout <number> In milliseconds the maximum amount of time the process
is allowed to run. Default: undefined.
killSignal <string> | <integer> The signal value to be used when the spawned
process will be killed. Default: 'SIGTERM'.
maxBuffer <number> Largest amount of data in bytes allowed on stdout or
stderr. If exceeded, the child process is terminated. See caveat at
maxBuffer and Unicode. Default: 1024 * 1024.
encoding <string> The encoding used for all stdio inputs and outputs.
Default: 'buffer'.
windowsHide <boolean> Hide the subprocess console window that would
normally be created on Windows systems. Default: false.
shell <boolean> | <string> If true, runs command inside of a shell. Uses
'/bin/sh' on Unix, and process.env.ComSpec on Windows. A different
shell can be specified as a string. See Shell requirements and
Default Windows shell. Default: false (no shell).


Returns: <Buffer> | <string> The stdout from the command.

The child_process.execFileSync() method is generally identical to
child_process.execFile() with the exception that the method will not
return until the child process has fully closed. When a timeout has been
encountered and killSignal is sent, the method won't return until the process
has completely exited.
If the child process intercepts and handles the SIGTERM signal and
does not exit, the parent process will still wait until the child process has
exited.
If the process times out or has a non-zero exit code, this method will throw an
Error that will include the full result of the underlying
child_process.spawnSync().
If the shell option is enabled, do not pass unsanitized user input to this
function. Any input containing shell metacharacters may be used to trigger
arbitrary command execution.

const { execFileSync } = require('node:child_process');

try {
  const stdout = execFileSync('my-script.sh', ['my-arg'], {
    // Capture stdout and stderr from child process. Overrides the
    // default behavior of streaming child stderr to the parent stderr
    stdio: 'pipe',

    // Use utf8 encoding for stdio pipes
    encoding: 'utf8',
  });

  console.log(stdout);
} catch (err) {
  if (err.code) {
    // Spawning child process failed
    console.error(err.code);
  } else {
    // Child was spawned but exited with non-zero exit code
    // Error contains any stdout and stderr from the child
    const { stdout, stderr } = err;

    console.error({ stdout, stderr });
  }
}import { execFileSync } from 'node:child_process';

try {
  const stdout = execFileSync('my-script.sh', ['my-arg'], {
    // Capture stdout and stderr from child process. Overrides the
    // default behavior of streaming child stderr to the parent stderr
    stdio: 'pipe',

    // Use utf8 encoding for stdio pipes
    encoding: 'utf8',
  });

  console.log(stdout);
} catch (err) {
  if (err.code) {
    // Spawning child process failed
    console.error(err.code);
  } else {
    // Child was spawned but exited with non-zero exit code
    // Error contains any stdout and stderr from the child
    const { stdout, stderr } = err;

    console.error({ stdout, stderr });
  }
}copy

child_process.execSync(command[, options])#

History

VersionChanges
v16.4.0, v14.18.0
The cwd option can be a WHATWG URL object using file: protocol.
v10.10.0
The input option can now be any TypedArray or a DataView.
v8.8.0
The windowsHide option is supported now.
v8.0.0
The input option can now be a Uint8Array.
v0.11.12
Added in: v0.11.12




command <string> The command to run.
options <Object>

cwd <string> | <URL> Current working directory of the child process.
input <string> | <Buffer> | <TypedArray> | <DataView> The value which will be passed
as stdin to the spawned process. If stdio[0] is set to 'pipe', Supplying
this value will override stdio[0].
stdio <string> | <Array> Child's stdio configuration.
See child_process.spawn()'s stdio. stderr by default will
be output to the parent process' stderr unless stdio is specified.
Default: 'pipe'.
env <Object> Environment key-value pairs. Default: process.env.
shell <string> Shell to execute the command with. See
Shell requirements and Default Windows shell. Default:
'/bin/sh' on Unix, process.env.ComSpec on Windows.
uid <number> Sets the user identity of the process. (See setuid(2)).
gid <number> Sets the group identity of the process. (See setgid(2)).
timeout <number> In milliseconds the maximum amount of time the process
is allowed to run. Default: undefined.
killSignal <string> | <integer> The signal value to be used when the spawned
process will be killed. Default: 'SIGTERM'.
maxBuffer <number> Largest amount of data in bytes allowed on stdout or
stderr. If exceeded, the child process is terminated and any output is
truncated. See caveat at maxBuffer and Unicode.
Default: 1024 * 1024.
encoding <string> The encoding used for all stdio inputs and outputs.
Default: 'buffer'.
windowsHide <boolean> Hide the subprocess console window that would
normally be created on Windows systems. Default: false.


Returns: <Buffer> | <string> The stdout from the command.

The child_process.execSync() method is generally identical to
child_process.exec() with the exception that the method will not return
until the child process has fully closed. When a timeout has been encountered
and killSignal is sent, the method won't return until the process has
completely exited. If the child process intercepts and handles the SIGTERM
signal and doesn't exit, the parent process will wait until the child process
has exited.
If the process times out or has a non-zero exit code, this method will throw.
The Error object will contain the entire result from
child_process.spawnSync().
Never pass unsanitized user input to this function. Any input containing shell
metacharacters may be used to trigger arbitrary command execution.

child_process.spawnSync(command[, args][, options])#

History

VersionChanges
v16.4.0, v14.18.0
The cwd option can be a WHATWG URL object using file: protocol.
v10.10.0
The input option can now be any TypedArray or a DataView.
v8.8.0
The windowsHide option is supported now.
v8.0.0
The input option can now be a Uint8Array.
v5.7.0
The shell option is supported now.
v6.2.1, v4.5.0
The encoding option can now explicitly be set to buffer.
v0.11.12
Added in: v0.11.12




command <string> The command to run.
args <string[]> List of string arguments.
options <Object>

cwd <string> | <URL> Current working directory of the child process.
input <string> | <Buffer> | <TypedArray> | <DataView> The value which will be passed
as stdin to the spawned process. If stdio[0] is set to 'pipe', Supplying
this value will override stdio[0].
argv0 <string> Explicitly set the value of argv[0] sent to the child
process. This will be set to command if not specified.
stdio <string> | <Array> Child's stdio configuration.
See child_process.spawn()'s stdio. Default: 'pipe'.
env <Object> Environment key-value pairs. Default: process.env.
uid <number> Sets the user identity of the process (see setuid(2)).
gid <number> Sets the group identity of the process (see setgid(2)).
timeout <number> In milliseconds the maximum amount of time the process
is allowed to run. Default: undefined.
killSignal <string> | <integer> The signal value to be used when the spawned
process will be killed. Default: 'SIGTERM'.
maxBuffer <number> Largest amount of data in bytes allowed on stdout or
stderr. If exceeded, the child process is terminated and any output is
truncated. See caveat at maxBuffer and Unicode.
Default: 1024 * 1024.
encoding <string> The encoding used for all stdio inputs and outputs.
Default: 'buffer'.
shell <boolean> | <string> If true, runs command inside of a shell. Uses
'/bin/sh' on Unix, and process.env.ComSpec on Windows. A different
shell can be specified as a string. See Shell requirements and
Default Windows shell. Default: false (no shell).
windowsVerbatimArguments <boolean> No quoting or escaping of arguments is
done on Windows. Ignored on Unix. This is set to true automatically
when shell is specified and is CMD. Default: false.
windowsHide <boolean> Hide the subprocess console window that would
normally be created on Windows systems. Default: false.


Returns: <Object>

pid <number> Pid of the child process.
output <Array> Array of results from stdio output.
stdout <Buffer> | <string> The contents of output[1].
stderr <Buffer> | <string> The contents of output[2].
status <number> | <null> The exit code of the subprocess, or null if the
subprocess terminated due to a signal.
signal <string> | <null> The signal used to kill the subprocess, or null if
the subprocess did not terminate due to a signal.
error <Error> The error object if the child process failed or timed out.



The child_process.spawnSync() method is generally identical to
child_process.spawn() with the exception that the function will not return
until the child process has fully closed. When a timeout has been encountered
and killSignal is sent, the method won't return until the process has
completely exited. If the process intercepts and handles the SIGTERM signal
and doesn't exit, the parent process will wait until the child process has
exited.
If the shell option is enabled, do not pass unsanitized user input to this
function. Any input containing shell metacharacters may be used to trigger
arbitrary command execution.

Class: ChildProcess#

Added in: v2.2.0


Extends: <EventEmitter>

Instances of the ChildProcess represent spawned child processes.
Instances of ChildProcess are not intended to be created directly. Rather,
use the child_process.spawn(), child_process.exec(),
child_process.execFile(), or child_process.fork() methods to create
instances of ChildProcess.

Event: 'close'#

Added in: v0.7.7


code <number> The exit code if the child process exited on its own.
signal <string> The signal by which the child process was terminated.

The 'close' event is emitted after a process has ended and the stdio
streams of a child process have been closed. This is distinct from the
'exit' event, since multiple processes might share the same stdio
streams. The 'close' event will always emit after 'exit' was
already emitted, or 'error' if the child process failed to spawn.

const { spawn } = require('node:child_process');
const ls = spawn('ls', ['-lh', '/usr']);

ls.stdout.on('data', (data) => {
  console.log(`stdout: ${data}`);
});

ls.on('close', (code) => {
  console.log(`child process close all stdio with code ${code}`);
});

ls.on('exit', (code) => {
  console.log(`child process exited with code ${code}`);
});import { spawn } from 'node:child_process';
const ls = spawn('ls', ['-lh', '/usr']);

ls.stdout.on('data', (data) => {
  console.log(`stdout: ${data}`);
});

ls.on('close', (code) => {
  console.log(`child process close all stdio with code ${code}`);
});

ls.on('exit', (code) => {
  console.log(`child process exited with code ${code}`);
});copy

Event: 'disconnect'#

Added in: v0.7.2

The 'disconnect' event is emitted after calling the
subprocess.disconnect() method in parent process or
process.disconnect() in child process. After disconnecting it is no longer
possible to send or receive messages, and the subprocess.connected
property is false.

Event: 'error'#

err <Error> The error.

The 'error' event is emitted whenever:

The process could not be spawned.
The process could not be killed.
Sending a message to the child process failed.
The child process was aborted via the signal option.

The 'exit' event may or may not fire after an error has occurred. When
listening to both the 'exit' and 'error' events, guard
against accidentally invoking handler functions multiple times.
See also subprocess.kill() and subprocess.send().

Event: 'exit'#

Added in: v0.1.90


code <number> The exit code if the child process exited on its own.
signal <string> The signal by which the child process was terminated.

The 'exit' event is emitted after the child process ends. If the process
exited, code is the final exit code of the process, otherwise null. If the
process terminated due to receipt of a signal, signal is the string name of
the signal, otherwise null. One of the two will always be non-null.
When the 'exit' event is triggered, child process stdio streams might still be
open.
Node.js establishes signal handlers for SIGINT and SIGTERM and Node.js
processes will not terminate immediately due to receipt of those signals.
Rather, Node.js will perform a sequence of cleanup actions and then will
re-raise the handled signal.
See waitpid(2).

Event: 'message'#

Added in: v0.5.9


message <Object> A parsed JSON object or primitive value.
sendHandle <Handle> | <undefined> undefined or a net.Socket,
net.Server, or dgram.Socket object.

The 'message' event is triggered when a child process uses
process.send() to send messages.
The message goes through serialization and parsing. The resulting
message might not be the same as what is originally sent.
If the serialization option was set to 'advanced' used when spawning the
child process, the message argument can contain data that JSON is not able
to represent.
See Advanced serialization for more details.

Event: 'spawn'#

Added in: v15.1.0, v14.17.0

The 'spawn' event is emitted once the child process has spawned successfully.
If the child process does not spawn successfully, the 'spawn' event is not
emitted and the 'error' event is emitted instead.
If emitted, the 'spawn' event comes before all other events and before any
data is received via stdout or stderr.
The 'spawn' event will fire regardless of whether an error occurs within
the spawned process. For example, if bash some-command spawns successfully,
the 'spawn' event will fire, though bash may fail to spawn some-command.
This caveat also applies when using { shell: true }.

subprocess.channel#

History

VersionChanges
v14.0.0
The object no longer accidentally exposes native C++ bindings.
v7.1.0
Added in: v7.1.0




<Object> A pipe representing the IPC channel to the child process.

The subprocess.channel property is a reference to the child's IPC channel. If
no IPC channel exists, this property is undefined.

subprocess.channel.ref()#

Added in: v7.1.0

This method makes the IPC channel keep the event loop of the parent process
running if .unref() has been called before.

subprocess.channel.unref()#

Added in: v7.1.0

This method makes the IPC channel not keep the event loop of the parent process
running, and lets it finish even while the channel is open.

subprocess.connected#

Added in: v0.7.2


<boolean> Set to false after subprocess.disconnect() is called.

The subprocess.connected property indicates whether it is still possible to
send and receive messages from a child process. When subprocess.connected is
false, it is no longer possible to send or receive messages.

subprocess.disconnect()#

Added in: v0.7.2

Closes the IPC channel between parent and child processes, allowing the child
process to exit gracefully once there are no other connections keeping it alive.
After calling this method the subprocess.connected and
process.connected properties in both the parent and child processes
(respectively) will be set to false, and it will be no longer possible
to pass messages between the processes.
The 'disconnect' event will be emitted when there are no messages in the
process of being received. This will most often be triggered immediately after
calling subprocess.disconnect().
When the child process is a Node.js instance (e.g. spawned using
child_process.fork()), the process.disconnect() method can be invoked
within the child process to close the IPC channel as well.

subprocess.exitCode#

<integer>

The subprocess.exitCode property indicates the exit code of the child process.
If the child process is still running, the field will be null.

subprocess.kill([signal])#

Added in: v0.1.90


signal <number> | <string>
Returns: <boolean>

The subprocess.kill() method sends a signal to the child process. If no
argument is given, the process will be sent the 'SIGTERM' signal. See
signal(7) for a list of available signals. This function returns true if
kill(2) succeeds, and false otherwise.

const { spawn } = require('node:child_process');
const grep = spawn('grep', ['ssh']);

grep.on('close', (code, signal) => {
  console.log(
    `child process terminated due to receipt of signal ${signal}`);
});

// Send SIGHUP to process.
grep.kill('SIGHUP');import { spawn } from 'node:child_process';
const grep = spawn('grep', ['ssh']);

grep.on('close', (code, signal) => {
  console.log(
    `child process terminated due to receipt of signal ${signal}`);
});

// Send SIGHUP to process.
grep.kill('SIGHUP');copy
The ChildProcess object may emit an 'error' event if the signal
cannot be delivered. Sending a signal to a child process that has already exited
is not an error but may have unforeseen consequences. Specifically, if the
process identifier (PID) has been reassigned to another process, the signal will
be delivered to that process instead which can have unexpected results.
While the function is called kill, the signal delivered to the child process
may not actually terminate the process.
See kill(2) for reference.
On Windows, where POSIX signals do not exist, the signal argument will be
ignored except for 'SIGKILL', 'SIGTERM', 'SIGINT' and 'SIGQUIT', and the
process will always be killed forcefully and abruptly (similar to 'SIGKILL').
See Signal Events for more details.
On Linux, child processes of child processes will not be terminated
when attempting to kill their parent. This is likely to happen when running a
new process in a shell or with the use of the shell option of ChildProcess:

const { spawn } = require('node:child_process');

const subprocess = spawn(
  'sh',
  [
    '-c',
    `node -e "setInterval(() => {
      console.log(process.pid, 'is alive')
    }, 500);"`,
  ], {
    stdio: ['inherit', 'inherit', 'inherit'],
  },
);

setTimeout(() => {
  subprocess.kill(); // Does not terminate the Node.js process in the shell.
}, 2000);import { spawn } from 'node:child_process';

const subprocess = spawn(
  'sh',
  [
    '-c',
    `node -e "setInterval(() => {
      console.log(process.pid, 'is alive')
    }, 500);"`,
  ], {
    stdio: ['inherit', 'inherit', 'inherit'],
  },
);

setTimeout(() => {
  subprocess.kill(); // Does not terminate the Node.js process in the shell.
}, 2000);copy

subprocess[Symbol.dispose]()#

Added in: v20.5.0, v18.18.0

Stability: 1 - Experimental
Calls subprocess.kill() with 'SIGTERM'.

subprocess.killed#

Added in: v0.5.10


<boolean> Set to true after subprocess.kill() is used to successfully
send a signal to the child process.

The subprocess.killed property indicates whether the child process
successfully received a signal from subprocess.kill(). The killed property
does not indicate that the child process has been terminated.

subprocess.pid#

Added in: v0.1.90


<integer> | <undefined>

Returns the process identifier (PID) of the child process. If the child process
fails to spawn due to errors, then the value is undefined and error is
emitted.

const { spawn } = require('node:child_process');
const grep = spawn('grep', ['ssh']);

console.log(`Spawned child pid: ${grep.pid}`);
grep.stdin.end();import { spawn } from 'node:child_process';
const grep = spawn('grep', ['ssh']);

console.log(`Spawned child pid: ${grep.pid}`);
grep.stdin.end();copy

subprocess.ref()#

Added in: v0.7.10

Calling subprocess.ref() after making a call to subprocess.unref() will
restore the removed reference count for the child process, forcing the parent
process to wait for the child process to exit before exiting itself.

const { spawn } = require('node:child_process');
const process = require('node:process');

const subprocess = spawn(process.argv[0], ['child_program.js'], {
  detached: true,
  stdio: 'ignore',
});

subprocess.unref();
subprocess.ref();import { spawn } from 'node:child_process';
import process from 'node:process';

const subprocess = spawn(process.argv[0], ['child_program.js'], {
  detached: true,
  stdio: 'ignore',
});

subprocess.unref();
subprocess.ref();copy

subprocess.send(message[, sendHandle[, options]][, callback])#

History

VersionChanges
v5.8.0
The options parameter, and the keepOpen option in particular, is supported now.
v5.0.0
This method returns a boolean for flow control now.
v4.0.0
The callback parameter is supported now.
v0.5.9
Added in: v0.5.9




message <Object>
sendHandle <Handle> | <undefined> undefined, or a net.Socket,
net.Server, or dgram.Socket object.
options <Object> The options argument, if present, is an object used to
parameterize the sending of certain types of handles. options supports
the following properties:

keepOpen <boolean> A value that can be used when passing instances of
net.Socket. When true, the socket is kept open in the sending process.
Default: false.


callback <Function>
Returns: <boolean>

When an IPC channel has been established between the parent and child processes
( i.e. when using child_process.fork()), the subprocess.send() method
can be used to send messages to the child process. When the child process is a
Node.js instance, these messages can be received via the 'message' event.
The message goes through serialization and parsing. The resulting
message might not be the same as what is originally sent.
For example, in the parent script:

const { fork } = require('node:child_process');
const forkedProcess = fork(`${__dirname}/sub.js`);

forkedProcess.on('message', (message) => {
  console.log('PARENT got message:', message);
});

// Causes the child to print: CHILD got message: { hello: 'world' }
forkedProcess.send({ hello: 'world' });import { fork } from 'node:child_process';
const forkedProcess = fork(`${import.meta.dirname}/sub.js`);

forkedProcess.on('message', (message) => {
  console.log('PARENT got message:', message);
});

// Causes the child to print: CHILD got message: { hello: 'world' }
forkedProcess.send({ hello: 'world' });copy
And then the child script, 'sub.js' might look like this:
process.on('message', (message) => {
  console.log('CHILD got message:', message);
});

// Causes the parent to print: PARENT got message: { foo: 'bar', baz: null }
process.send({ foo: 'bar', baz: NaN }); copy
Child Node.js processes will have a process.send() method of their own
that allows the child process to send messages back to the parent process.
There is a special case when sending a {cmd: 'NODE_foo'} message. Messages
containing a NODE_ prefix in the cmd property are reserved for use within
Node.js core and will not be emitted in the child's 'message'
event. Rather, such messages are emitted using the
'internalMessage' event and are consumed internally by Node.js.
Applications should avoid using such messages or listening for
'internalMessage' events as it is subject to change without notice.
The optional sendHandle argument that may be passed to subprocess.send() is
for passing a TCP server or socket object to the child process. The child process will
receive the object as the second argument passed to the callback function
registered on the 'message' event. Any data that is received
and buffered in the socket will not be sent to the child. Sending IPC sockets is
not supported on Windows.
The optional callback is a function that is invoked after the message is
sent but before the child process may have received it. The function is called with a
single argument: null on success, or an Error object on failure.
If no callback function is provided and the message cannot be sent, an
'error' event will be emitted by the ChildProcess object. This can
happen, for instance, when the child process has already exited.
subprocess.send() will return false if the channel has closed or when the
backlog of unsent messages exceeds a threshold that makes it unwise to send
more. Otherwise, the method returns true. The callback function can be
used to implement flow control.

Example: sending a server object#
The sendHandle argument can be used, for instance, to pass the handle of
a TCP server object to the child process as illustrated in the example below:

const { fork } = require('node:child_process');
const { createServer } = require('node:net');

const subprocess = fork('subprocess.js');

// Open up the server object and send the handle.
const server = createServer();
server.on('connection', (socket) => {
  socket.end('handled by parent');
});
server.listen(1337, () => {
  subprocess.send('server', server);
});import { fork } from 'node:child_process';
import { createServer } from 'node:net';

const subprocess = fork('subprocess.js');

// Open up the server object and send the handle.
const server = createServer();
server.on('connection', (socket) => {
  socket.end('handled by parent');
});
server.listen(1337, () => {
  subprocess.send('server', server);
});copy
The child process would then receive the server object as:
process.on('message', (m, server) => {
  if (m === 'server') {
    server.on('connection', (socket) => {
      socket.end('handled by child');
    });
  }
}); copy
Once the server is now shared between the parent and child, some connections
can be handled by the parent and some by the child.
While the example above uses a server created using the node:net module,
node:dgram module servers use exactly the same workflow with the exceptions of
listening on a 'message' event instead of 'connection' and using
server.bind() instead of server.listen(). This is, however, only
supported on Unix platforms.

Example: sending a socket object#
Similarly, the sendHandler argument can be used to pass the handle of a
socket to the child process. The example below spawns two children that each
handle connections with "normal" or "special" priority:

const { fork } = require('node:child_process');
const { createServer } = require('node:net');

const normal = fork('subprocess.js', ['normal']);
const special = fork('subprocess.js', ['special']);

// Open up the server and send sockets to child. Use pauseOnConnect to prevent
// the sockets from being read before they are sent to the child process.
const server = createServer({ pauseOnConnect: true });
server.on('connection', (socket) => {

  // If this is special priority...
  if (socket.remoteAddress === '74.125.127.100') {
    special.send('socket', socket);
    return;
  }
  // This is normal priority.
  normal.send('socket', socket);
});
server.listen(1337);import { fork } from 'node:child_process';
import { createServer } from 'node:net';

const normal = fork('subprocess.js', ['normal']);
const special = fork('subprocess.js', ['special']);

// Open up the server and send sockets to child. Use pauseOnConnect to prevent
// the sockets from being read before they are sent to the child process.
const server = createServer({ pauseOnConnect: true });
server.on('connection', (socket) => {

  // If this is special priority...
  if (socket.remoteAddress === '74.125.127.100') {
    special.send('socket', socket);
    return;
  }
  // This is normal priority.
  normal.send('socket', socket);
});
server.listen(1337);copy
The subprocess.js would receive the socket handle as the second argument
passed to the event callback function:
process.on('message', (m, socket) => {
  if (m === 'socket') {
    if (socket) {
      // Check that the client socket exists.
      // It is possible for the socket to be closed between the time it is
      // sent and the time it is received in the child process.
      socket.end(`Request handled with ${process.argv[2]} priority`);
    }
  }
}); copy
Do not use .maxConnections on a socket that has been passed to a subprocess.
The parent cannot track when the socket is destroyed.
Any 'message' handlers in the subprocess should verify that socket exists,
as the connection may have been closed during the time it takes to send the
connection to the child.

subprocess.signalCode#

<string> | <null>

The subprocess.signalCode property indicates the signal received by
the child process if any, else null.

subprocess.spawnargs#

<Array>

The subprocess.spawnargs property represents the full list of command-line
arguments the child process was launched with.

subprocess.spawnfile#

<string>

The subprocess.spawnfile property indicates the executable file name of
the child process that is launched.
For child_process.fork(), its value will be equal to
process.execPath.
For child_process.spawn(), its value will be the name of
the executable file.
For child_process.exec(),  its value will be the name of the shell
in which the child process is launched.

subprocess.stderr#

Added in: v0.1.90


<stream.Readable> | <null> | <undefined>

A Readable Stream that represents the child process's stderr.
If the child process was spawned with stdio[2] set to anything other than 'pipe',
then this will be null.
subprocess.stderr is an alias for subprocess.stdio[2]. Both properties will
refer to the same value.
The subprocess.stderr property can be null or undefined
if the child process could not be successfully spawned.

subprocess.stdin#

Added in: v0.1.90


<stream.Writable> | <null> | <undefined>

A Writable Stream that represents the child process's stdin.
If a child process waits to read all of its input, the child process will not continue
until this stream has been closed via end().
If the child process was spawned with stdio[0] set to anything other than 'pipe',
then this will be null.
subprocess.stdin is an alias for subprocess.stdio[0]. Both properties will
refer to the same value.
The subprocess.stdin property can be null or undefined
if the child process could not be successfully spawned.

subprocess.stdio#

Added in: v0.7.10


<Array>

A sparse array of pipes to the child process, corresponding with positions in
the stdio option passed to child_process.spawn() that have been set
to the value 'pipe'. subprocess.stdio[0], subprocess.stdio[1], and
subprocess.stdio[2] are also available as subprocess.stdin,
subprocess.stdout, and subprocess.stderr, respectively.
In the following example, only the child's fd 1 (stdout) is configured as a
pipe, so only the parent's subprocess.stdio[1] is a stream, all other values
in the array are null.

const assert = require('node:assert');
const fs = require('node:fs');
const child_process = require('node:child_process');

const subprocess = child_process.spawn('ls', {
  stdio: [
    0, // Use parent's stdin for child.
    'pipe', // Pipe child's stdout to parent.
    fs.openSync('err.out', 'w'), // Direct child's stderr to a file.
  ],
});

assert.strictEqual(subprocess.stdio[0], null);
assert.strictEqual(subprocess.stdio[0], subprocess.stdin);

assert(subprocess.stdout);
assert.strictEqual(subprocess.stdio[1], subprocess.stdout);

assert.strictEqual(subprocess.stdio[2], null);
assert.strictEqual(subprocess.stdio[2], subprocess.stderr);import assert from 'node:assert';
import fs from 'node:fs';
import child_process from 'node:child_process';

const subprocess = child_process.spawn('ls', {
  stdio: [
    0, // Use parent's stdin for child.
    'pipe', // Pipe child's stdout to parent.
    fs.openSync('err.out', 'w'), // Direct child's stderr to a file.
  ],
});

assert.strictEqual(subprocess.stdio[0], null);
assert.strictEqual(subprocess.stdio[0], subprocess.stdin);

assert(subprocess.stdout);
assert.strictEqual(subprocess.stdio[1], subprocess.stdout);

assert.strictEqual(subprocess.stdio[2], null);
assert.strictEqual(subprocess.stdio[2], subprocess.stderr);copy
The subprocess.stdio property can be undefined if the child process could
not be successfully spawned.

subprocess.stdout#

Added in: v0.1.90


<stream.Readable> | <null> | <undefined>

A Readable Stream that represents the child process's stdout.
If the child process was spawned with stdio[1] set to anything other than 'pipe',
then this will be null.
subprocess.stdout is an alias for subprocess.stdio[1]. Both properties will
refer to the same value.

const { spawn } = require('node:child_process');

const subprocess = spawn('ls');

subprocess.stdout.on('data', (data) => {
  console.log(`Received chunk ${data}`);
});import { spawn } from 'node:child_process';

const subprocess = spawn('ls');

subprocess.stdout.on('data', (data) => {
  console.log(`Received chunk ${data}`);
});copy
The subprocess.stdout property can be null or undefined
if the child process could not be successfully spawned.

subprocess.unref()#

Added in: v0.7.10

By default, the parent process will wait for the detached child process to exit.
To prevent the parent process from waiting for a given subprocess to exit, use the
subprocess.unref() method. Doing so will cause the parent's event loop to not
include the child process in its reference count, allowing the parent to exit
independently of the child, unless there is an established IPC channel between
the child and the parent processes.

const { spawn } = require('node:child_process');
const process = require('node:process');

const subprocess = spawn(process.argv[0], ['child_program.js'], {
  detached: true,
  stdio: 'ignore',
});

subprocess.unref();import { spawn } from 'node:child_process';
import process from 'node:process';

const subprocess = spawn(process.argv[0], ['child_program.js'], {
  detached: true,
  stdio: 'ignore',
});

subprocess.unref();copy

maxBuffer and Unicode#
The maxBuffer option specifies the largest number of bytes allowed on stdout
or stderr. If this value is exceeded, then the child process is terminated.
This impacts output that includes multibyte character encodings such as UTF-8 or
UTF-16. For instance, console.log('中文测试') will send 13 UTF-8 encoded bytes
to stdout although there are only 4 characters.
Shell requirements#
The shell should understand the -c switch. If the shell is 'cmd.exe', it
should understand the /d /s /c switches and command-line parsing should be
compatible.
Default Windows shell#
Although Microsoft specifies %COMSPEC% must contain the path to
'cmd.exe' in the root environment, child processes are not always subject to
the same requirement. Thus, in child_process functions where a shell can be
spawned, 'cmd.exe' is used as a fallback if process.env.ComSpec is
unavailable.
Advanced serialization#

Added in: v13.2.0, v12.16.0

Child processes support a serialization mechanism for IPC that is based on the
serialization API of the node:v8 module, based on the
HTML structured clone algorithm. This is generally more powerful and
supports more built-in JavaScript object types, such as BigInt, Map
and Set, ArrayBuffer and TypedArray, Buffer, Error, RegExp etc.
However, this format is not a full superset of JSON, and e.g. properties set on
objects of such built-in types will not be passed on through the serialization
step. Additionally, performance may not be equivalent to that of JSON, depending
on the structure of the passed data.
Therefore, this feature requires opting in by setting the
serialization option to 'advanced' when calling child_process.spawn()
or child_process.fork().\n\n\n\nNode.js
        
      
      
About this documentation
Usage and example



Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Modules: TypeScript
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
Readline
REPL
Report
Single executable applications
SQLite
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker

    

    
      
        
          Node.js v24.0.1 documentation
          
            
            
          
        
        
          
            Node.js v24.0.1
            
    
      
        
        Table of contents
      

      
Cluster

How it works
Class: Worker

Event: 'disconnect'
Event: 'error'
Event: 'exit'
Event: 'listening'
Event: 'message'
Event: 'online'
worker.disconnect()
worker.exitedAfterDisconnect
worker.id
worker.isConnected()
worker.isDead()
worker.kill([signal])
worker.process
worker.send(message[, sendHandle[, options]][, callback])


Event: 'disconnect'
Event: 'exit'
Event: 'fork'
Event: 'listening'
Event: 'message'
Event: 'online'
Event: 'setup'
cluster.disconnect([callback])
cluster.fork([env])
cluster.isMaster
cluster.isPrimary
cluster.isWorker
cluster.schedulingPolicy
cluster.settings
cluster.setupMaster([settings])
cluster.setupPrimary([settings])
cluster.worker
cluster.workers



    
  
            
    
      
        
        Index
      

      
About this documentation
Usage and example

      
        Index
      
    
  


Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Modules: TypeScript
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
Readline
REPL
Report
Single executable applications
SQLite
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker

    
  
            
    
      
        
        Other versions
      
      24.x
23.x
22.x LTS
21.x
20.x LTS
19.x
18.x
17.x
16.x
15.x
14.x
13.x
12.x
11.x
10.x
9.x
8.x
7.x
6.x
5.x
4.x
0.12.x
0.10.x
    
  
            
              
                
                Options
              
        
              
                
                  
                    View on single page
                  
                  
                    View as JSON
                  
                  Edit on GitHub    
                
              
            
          
        
        
      

      Table of contents
Cluster

How it works
Class: Worker

Event: 'disconnect'
Event: 'error'
Event: 'exit'
Event: 'listening'
Event: 'message'
Event: 'online'
worker.disconnect()
worker.exitedAfterDisconnect
worker.id
worker.isConnected()
worker.isDead()
worker.kill([signal])
worker.process
worker.send(message[, sendHandle[, options]][, callback])


Event: 'disconnect'
Event: 'exit'
Event: 'fork'
Event: 'listening'
Event: 'message'
Event: 'online'
Event: 'setup'
cluster.disconnect([callback])
cluster.fork([env])
cluster.isMaster
cluster.isPrimary
cluster.isWorker
cluster.schedulingPolicy
cluster.settings
cluster.setupMaster([settings])
cluster.setupPrimary([settings])
cluster.worker
cluster.workers




      
        Cluster#

Stability: 2 - Stable
Source Code: lib/cluster.js
Clusters of Node.js processes can be used to run multiple instances of Node.js
that can distribute workloads among their application threads. When process
isolation is not needed, use the worker_threads module instead, which
allows running multiple application threads within a single Node.js instance.
The cluster module allows easy creation of child processes that all share
server ports.

import cluster from 'node:cluster';
import http from 'node:http';
import { availableParallelism } from 'node:os';
import process from 'node:process';

const numCPUs = availableParallelism();

if (cluster.isPrimary) {
  console.log(`Primary ${process.pid} is running`);

  // Fork workers.
  for (let i = 0; i < numCPUs; i++) {
    cluster.fork();
  }

  cluster.on('exit', (worker, code, signal) => {
    console.log(`worker ${worker.process.pid} died`);
  });
} else {
  // Workers can share any TCP connection
  // In this case it is an HTTP server
  http.createServer((req, res) => {
    res.writeHead(200);
    res.end('hello world\n');
  }).listen(8000);

  console.log(`Worker ${process.pid} started`);
}const cluster = require('node:cluster');
const http = require('node:http');
const numCPUs = require('node:os').availableParallelism();
const process = require('node:process');

if (cluster.isPrimary) {
  console.log(`Primary ${process.pid} is running`);

  // Fork workers.
  for (let i = 0; i < numCPUs; i++) {
    cluster.fork();
  }

  cluster.on('exit', (worker, code, signal) => {
    console.log(`worker ${worker.process.pid} died`);
  });
} else {
  // Workers can share any TCP connection
  // In this case it is an HTTP server
  http.createServer((req, res) => {
    res.writeHead(200);
    res.end('hello world\n');
  }).listen(8000);

  console.log(`Worker ${process.pid} started`);
}copy
Running Node.js will now share port 8000 between the workers:
$ node server.js
Primary 3596 is running
Worker 4324 started
Worker 4520 started
Worker 6056 started
Worker 5644 started copy
On Windows, it is not yet possible to set up a named pipe server in a worker.
How it works#

The worker processes are spawned using the child_process.fork() method,
so that they can communicate with the parent via IPC and pass server
handles back and forth.
The cluster module supports two methods of distributing incoming
connections.
The first one (and the default one on all platforms except Windows)
is the round-robin approach, where the primary process listens on a
port, accepts new connections and distributes them across the workers
in a round-robin fashion, with some built-in smarts to avoid
overloading a worker process.
The second approach is where the primary process creates the listen
socket and sends it to interested workers. The workers then accept
incoming connections directly.
The second approach should, in theory, give the best performance.
In practice however, distribution tends to be very unbalanced due
to operating system scheduler vagaries. Loads have been observed
where over 70% of all connections ended up in just two processes,
out of a total of eight.
Because server.listen() hands off most of the work to the primary
process, there are three cases where the behavior between a normal
Node.js process and a cluster worker differs:

server.listen({fd: 7}) Because the message is passed to the primary,
file descriptor 7 in the parent will be listened on, and the
handle passed to the worker, rather than listening to the worker's
idea of what the number 7 file descriptor references.
server.listen(handle) Listening on handles explicitly will cause
the worker to use the supplied handle, rather than talk to the primary
process.
server.listen(0) Normally, this will cause servers to listen on a
random port. However, in a cluster, each worker will receive the
same "random" port each time they do listen(0). In essence, the
port is random the first time, but predictable thereafter. To listen
on a unique port, generate a port number based on the cluster worker ID.

Node.js does not provide routing logic. It is therefore important to design an
application such that it does not rely too heavily on in-memory data objects for
things like sessions and login.
Because workers are all separate processes, they can be killed or
re-spawned depending on a program's needs, without affecting other
workers. As long as there are some workers still alive, the server will
continue to accept connections. If no workers are alive, existing connections
will be dropped and new connections will be refused. Node.js does not
automatically manage the number of workers, however. It is the application's
responsibility to manage the worker pool based on its own needs.
Although a primary use case for the node:cluster module is networking, it can
also be used for other use cases requiring worker processes.
Class: Worker#

Added in: v0.7.0


Extends: <EventEmitter>

A Worker object contains all public information and method about a worker.
In the primary it can be obtained using cluster.workers. In a worker
it can be obtained using cluster.worker.

Event: 'disconnect'#

Added in: v0.7.7

Similar to the cluster.on('disconnect') event, but specific to this worker.
cluster.fork().on('disconnect', () => {
  // Worker has disconnected
}); copy

Event: 'error'#

Added in: v0.7.3

This event is the same as the one provided by child_process.fork().
Within a worker, process.on('error') may also be used.

Event: 'exit'#

Added in: v0.11.2


code <number> The exit code, if it exited normally.
signal <string> The name of the signal (e.g. 'SIGHUP') that caused
the process to be killed.

Similar to the cluster.on('exit') event, but specific to this worker.

import cluster from 'node:cluster';

if (cluster.isPrimary) {
  const worker = cluster.fork();
  worker.on('exit', (code, signal) => {
    if (signal) {
      console.log(`worker was killed by signal: ${signal}`);
    } else if (code !== 0) {
      console.log(`worker exited with error code: ${code}`);
    } else {
      console.log('worker success!');
    }
  });
}const cluster = require('node:cluster');

if (cluster.isPrimary) {
  const worker = cluster.fork();
  worker.on('exit', (code, signal) => {
    if (signal) {
      console.log(`worker was killed by signal: ${signal}`);
    } else if (code !== 0) {
      console.log(`worker exited with error code: ${code}`);
    } else {
      console.log('worker success!');
    }
  });
}copy

Event: 'listening'#

Added in: v0.7.0


address <Object>

Similar to the cluster.on('listening') event, but specific to this worker.

cluster.fork().on('listening', (address) => {
  // Worker is listening
});cluster.fork().on('listening', (address) => {
  // Worker is listening
});copy
It is not emitted in the worker.

Event: 'message'#

Added in: v0.7.0


message <Object>
handle <undefined> | <Object>

Similar to the 'message' event of cluster, but specific to this worker.
Within a worker, process.on('message') may also be used.
See process event: 'message'.
Here is an example using the message system. It keeps a count in the primary
process of the number of HTTP requests received by the workers:

import cluster from 'node:cluster';
import http from 'node:http';
import { availableParallelism } from 'node:os';
import process from 'node:process';

if (cluster.isPrimary) {

  // Keep track of http requests
  let numReqs = 0;
  setInterval(() => {
    console.log(`numReqs = ${numReqs}`);
  }, 1000);

  // Count requests
  function messageHandler(msg) {
    if (msg.cmd && msg.cmd === 'notifyRequest') {
      numReqs += 1;
    }
  }

  // Start workers and listen for messages containing notifyRequest
  const numCPUs = availableParallelism();
  for (let i = 0; i < numCPUs; i++) {
    cluster.fork();
  }

  for (const id in cluster.workers) {
    cluster.workers[id].on('message', messageHandler);
  }

} else {

  // Worker processes have a http server.
  http.Server((req, res) => {
    res.writeHead(200);
    res.end('hello world\n');

    // Notify primary about the request
    process.send({ cmd: 'notifyRequest' });
  }).listen(8000);
}const cluster = require('node:cluster');
const http = require('node:http');
const numCPUs = require('node:os').availableParallelism();
const process = require('node:process');

if (cluster.isPrimary) {

  // Keep track of http requests
  let numReqs = 0;
  setInterval(() => {
    console.log(`numReqs = ${numReqs}`);
  }, 1000);

  // Count requests
  function messageHandler(msg) {
    if (msg.cmd && msg.cmd === 'notifyRequest') {
      numReqs += 1;
    }
  }

  // Start workers and listen for messages containing notifyRequest
  for (let i = 0; i < numCPUs; i++) {
    cluster.fork();
  }

  for (const id in cluster.workers) {
    cluster.workers[id].on('message', messageHandler);
  }

} else {

  // Worker processes have a http server.
  http.Server((req, res) => {
    res.writeHead(200);
    res.end('hello world\n');

    // Notify primary about the request
    process.send({ cmd: 'notifyRequest' });
  }).listen(8000);
}copy

Event: 'online'#

Added in: v0.7.0

Similar to the cluster.on('online') event, but specific to this worker.
cluster.fork().on('online', () => {
  // Worker is online
}); copy
It is not emitted in the worker.

worker.disconnect()#

History

VersionChanges
v7.3.0
This method now returns a reference to worker.
v0.7.7
Added in: v0.7.7




Returns: <cluster.Worker> A reference to worker.

In a worker, this function will close all servers, wait for the 'close' event
on those servers, and then disconnect the IPC channel.
In the primary, an internal message is sent to the worker causing it to call
.disconnect() on itself.
Causes .exitedAfterDisconnect to be set.
After a server is closed, it will no longer accept new connections,
but connections may be accepted by any other listening worker. Existing
connections will be allowed to close as usual. When no more connections exist,
see server.close(), the IPC channel to the worker will close allowing it
to die gracefully.
The above applies only to server connections, client connections are not
automatically closed by workers, and disconnect does not wait for them to close
before exiting.
In a worker, process.disconnect exists, but it is not this function;
it is disconnect().
Because long living server connections may block workers from disconnecting, it
may be useful to send a message, so application specific actions may be taken to
close them. It also may be useful to implement a timeout, killing a worker if
the 'disconnect' event has not been emitted after some time.
if (cluster.isPrimary) {
  const worker = cluster.fork();
  let timeout;

  worker.on('listening', (address) => {
    worker.send('shutdown');
    worker.disconnect();
    timeout = setTimeout(() => {
      worker.kill();
    }, 2000);
  });

  worker.on('disconnect', () => {
    clearTimeout(timeout);
  });

} else if (cluster.isWorker) {
  const net = require('node:net');
  const server = net.createServer((socket) => {
    // Connections never end
  });

  server.listen(8000);

  process.on('message', (msg) => {
    if (msg === 'shutdown') {
      // Initiate graceful close of any connections to server
    }
  });
} copy

worker.exitedAfterDisconnect#

Added in: v6.0.0


<boolean>

This property is true if the worker exited due to .disconnect().
If the worker exited any other way, it is false. If the
worker has not exited, it is undefined.
The boolean worker.exitedAfterDisconnect allows distinguishing between
voluntary and accidental exit, the primary may choose not to respawn a worker
based on this value.
cluster.on('exit', (worker, code, signal) => {
  if (worker.exitedAfterDisconnect === true) {
    console.log('Oh, it was just voluntary – no need to worry');
  }
});

// kill worker
worker.kill(); copy

worker.id#

Added in: v0.8.0


<integer>

Each new worker is given its own unique id, this id is stored in the
id.
While a worker is alive, this is the key that indexes it in
cluster.workers.

worker.isConnected()#

Added in: v0.11.14

This function returns true if the worker is connected to its primary via its
IPC channel, false otherwise. A worker is connected to its primary after it
has been created. It is disconnected after the 'disconnect' event is emitted.

worker.isDead()#

Added in: v0.11.14

This function returns true if the worker's process has terminated (either
because of exiting or being signaled). Otherwise, it returns false.

import cluster from 'node:cluster';
import http from 'node:http';
import { availableParallelism } from 'node:os';
import process from 'node:process';

const numCPUs = availableParallelism();

if (cluster.isPrimary) {
  console.log(`Primary ${process.pid} is running`);

  // Fork workers.
  for (let i = 0; i < numCPUs; i++) {
    cluster.fork();
  }

  cluster.on('fork', (worker) => {
    console.log('worker is dead:', worker.isDead());
  });

  cluster.on('exit', (worker, code, signal) => {
    console.log('worker is dead:', worker.isDead());
  });
} else {
  // Workers can share any TCP connection. In this case, it is an HTTP server.
  http.createServer((req, res) => {
    res.writeHead(200);
    res.end(`Current process\n ${process.pid}`);
    process.kill(process.pid);
  }).listen(8000);
}const cluster = require('node:cluster');
const http = require('node:http');
const numCPUs = require('node:os').availableParallelism();
const process = require('node:process');

if (cluster.isPrimary) {
  console.log(`Primary ${process.pid} is running`);

  // Fork workers.
  for (let i = 0; i < numCPUs; i++) {
    cluster.fork();
  }

  cluster.on('fork', (worker) => {
    console.log('worker is dead:', worker.isDead());
  });

  cluster.on('exit', (worker, code, signal) => {
    console.log('worker is dead:', worker.isDead());
  });
} else {
  // Workers can share any TCP connection. In this case, it is an HTTP server.
  http.createServer((req, res) => {
    res.writeHead(200);
    res.end(`Current process\n ${process.pid}`);
    process.kill(process.pid);
  }).listen(8000);
}copy

worker.kill([signal])#

Added in: v0.9.12


signal <string> Name of the kill signal to send to the worker
process. Default: 'SIGTERM'

This function will kill the worker. In the primary worker, it does this by
disconnecting the worker.process, and once disconnected, killing with
signal. In the worker, it does it by killing the process with signal.
The kill() function kills the worker process without waiting for a graceful
disconnect, it has the same behavior as worker.process.kill().
This method is aliased as worker.destroy() for backwards compatibility.
In a worker, process.kill() exists, but it is not this function;
it is kill().

worker.process#

Added in: v0.7.0


<ChildProcess>

All workers are created using child_process.fork(), the returned object
from this function is stored as .process. In a worker, the global process
is stored.
See: Child Process module.
Workers will call process.exit(0) if the 'disconnect' event occurs
on process and .exitedAfterDisconnect is not true. This protects against
accidental disconnection.

worker.send(message[, sendHandle[, options]][, callback])#

History

VersionChanges
v4.0.0
The callback parameter is supported now.
v0.7.0
Added in: v0.7.0




message <Object>
sendHandle <Handle>
options <Object> The options argument, if present, is an object used to
parameterize the sending of certain types of handles. options supports
the following properties:

keepOpen <boolean> A value that can be used when passing instances of
net.Socket. When true, the socket is kept open in the sending process.
Default: false.


callback <Function>
Returns: <boolean>

Send a message to a worker or primary, optionally with a handle.
In the primary, this sends a message to a specific worker. It is identical to
ChildProcess.send().
In a worker, this sends a message to the primary. It is identical to
process.send().
This example will echo back all messages from the primary:
if (cluster.isPrimary) {
  const worker = cluster.fork();
  worker.send('hi there');

} else if (cluster.isWorker) {
  process.on('message', (msg) => {
    process.send(msg);
  });
} copy

Event: 'disconnect'#

Added in: v0.7.9


worker <cluster.Worker>

Emitted after the worker IPC channel has disconnected. This can occur when a
worker exits gracefully, is killed, or is disconnected manually (such as with
worker.disconnect()).
There may be a delay between the 'disconnect' and 'exit' events. These
events can be used to detect if the process is stuck in a cleanup or if there
are long-living connections.
cluster.on('disconnect', (worker) => {
  console.log(`The worker #${worker.id} has disconnected`);
}); copy
Event: 'exit'#

Added in: v0.7.9


worker <cluster.Worker>
code <number> The exit code, if it exited normally.
signal <string> The name of the signal (e.g. 'SIGHUP') that caused
the process to be killed.

When any of the workers die the cluster module will emit the 'exit' event.
This can be used to restart the worker by calling .fork() again.
cluster.on('exit', (worker, code, signal) => {
  console.log('worker %d died (%s). restarting...',
              worker.process.pid, signal || code);
  cluster.fork();
}); copy
See child_process event: 'exit'.
Event: 'fork'#

Added in: v0.7.0


worker <cluster.Worker>

When a new worker is forked the cluster module will emit a 'fork' event.
This can be used to log worker activity, and create a custom timeout.
const timeouts = [];
function errorMsg() {
  console.error('Something must be wrong with the connection ...');
}

cluster.on('fork', (worker) => {
  timeouts[worker.id] = setTimeout(errorMsg, 2000);
});
cluster.on('listening', (worker, address) => {
  clearTimeout(timeouts[worker.id]);
});
cluster.on('exit', (worker, code, signal) => {
  clearTimeout(timeouts[worker.id]);
  errorMsg();
}); copy
Event: 'listening'#

Added in: v0.7.0


worker <cluster.Worker>
address <Object>

After calling listen() from a worker, when the 'listening' event is emitted
on the server, a 'listening' event will also be emitted on cluster in the
primary.
The event handler is executed with two arguments, the worker contains the
worker object and the address object contains the following connection
properties: address, port, and addressType. This is very useful if the
worker is listening on more than one address.
cluster.on('listening', (worker, address) => {
  console.log(
    `A worker is now connected to ${address.address}:${address.port}`);
}); copy
The addressType is one of:

4 (TCPv4)
6 (TCPv6)
-1 (Unix domain socket)
'udp4' or 'udp6' (UDPv4 or UDPv6)

Event: 'message'#

History

VersionChanges
v6.0.0
The worker parameter is passed now; see below for details.
v2.5.0
Added in: v2.5.0




worker <cluster.Worker>
message <Object>
handle <undefined> | <Object>

Emitted when the cluster primary receives a message from any worker.
See child_process event: 'message'.
Event: 'online'#

Added in: v0.7.0


worker <cluster.Worker>

After forking a new worker, the worker should respond with an online message.
When the primary receives an online message it will emit this event.
The difference between 'fork' and 'online' is that fork is emitted when the
primary forks a worker, and 'online' is emitted when the worker is running.
cluster.on('online', (worker) => {
  console.log('Yay, the worker responded after it was forked');
}); copy
Event: 'setup'#

Added in: v0.7.1


settings <Object>

Emitted every time .setupPrimary() is called.
The settings object is the cluster.settings object at the time
.setupPrimary() was called and is advisory only, since multiple calls to
.setupPrimary() can be made in a single tick.
If accuracy is important, use cluster.settings.
cluster.disconnect([callback])#

Added in: v0.7.7


callback <Function> Called when all workers are disconnected and handles are
closed.

Calls .disconnect() on each worker in cluster.workers.
When they are disconnected all internal handles will be closed, allowing the
primary process to die gracefully if no other event is waiting.
The method takes an optional callback argument which will be called when
finished.
This can only be called from the primary process.
cluster.fork([env])#

Added in: v0.6.0


env <Object> Key/value pairs to add to worker process environment.
Returns: <cluster.Worker>

Spawn a new worker process.
This can only be called from the primary process.
cluster.isMaster#

Added in: v0.8.1Deprecated since: v16.0.0

Stability: 0 - Deprecated
Deprecated alias for cluster.isPrimary.
cluster.isPrimary#

Added in: v16.0.0


<boolean>

True if the process is a primary. This is determined
by the process.env.NODE_UNIQUE_ID. If process.env.NODE_UNIQUE_ID is
undefined, then isPrimary is true.
cluster.isWorker#

Added in: v0.6.0


<boolean>

True if the process is not a primary (it is the negation of cluster.isPrimary).
cluster.schedulingPolicy#

Added in: v0.11.2

The scheduling policy, either cluster.SCHED_RR for round-robin or
cluster.SCHED_NONE to leave it to the operating system. This is a
global setting and effectively frozen once either the first worker is spawned,
or .setupPrimary() is called, whichever comes first.
SCHED_RR is the default on all operating systems except Windows.
Windows will change to SCHED_RR once libuv is able to effectively
distribute IOCP handles without incurring a large performance hit.
cluster.schedulingPolicy can also be set through the
NODE_CLUSTER_SCHED_POLICY environment variable. Valid
values are 'rr' and 'none'.
cluster.settings#

History

VersionChanges
v13.2.0, v12.16.0
The serialization option is supported now.
v9.5.0
The cwd option is supported now.
v9.4.0
The windowsHide option is supported now.
v8.2.0
The inspectPort option is supported now.
v6.4.0
The stdio option is supported now.
v0.7.1
Added in: v0.7.1




<Object>

execArgv <string[]> List of string arguments passed to the Node.js
executable. Default: process.execArgv.
exec <string> File path to worker file. Default: process.argv[1].
args <string[]> String arguments passed to worker.
Default: process.argv.slice(2).
cwd <string> Current working directory of the worker process. Default:
undefined (inherits from parent process).
serialization <string> Specify the kind of serialization used for sending
messages between processes. Possible values are 'json' and 'advanced'.
See Advanced serialization for child_process for more details.
Default: false.
silent <boolean> Whether or not to send output to parent's stdio.
Default: false.
stdio <Array> Configures the stdio of forked processes. Because the
cluster module relies on IPC to function, this configuration must contain an
'ipc' entry. When this option is provided, it overrides silent. See
child_process.spawn()'s stdio.
uid <number> Sets the user identity of the process. (See setuid(2).)
gid <number> Sets the group identity of the process. (See setgid(2).)
inspectPort <number> | <Function> Sets inspector port of worker.
This can be a number, or a function that takes no arguments and returns a
number. By default each worker gets its own port, incremented from the
primary's process.debugPort.
windowsHide <boolean> Hide the forked processes console window that would
normally be created on Windows systems. Default: false.



After calling .setupPrimary() (or .fork()) this settings object will
contain the settings, including the default values.
This object is not intended to be changed or set manually.
cluster.setupMaster([settings])#

History

VersionChanges
v16.0.0
Deprecated since: v16.0.0
v6.4.0
The stdio option is supported now.
v0.7.1
Added in: v0.7.1



Stability: 0 - Deprecated
Deprecated alias for .setupPrimary().
cluster.setupPrimary([settings])#

Added in: v16.0.0


settings <Object> See cluster.settings.

setupPrimary is used to change the default 'fork' behavior. Once called,
the settings will be present in cluster.settings.
Any settings changes only affect future calls to .fork() and have no
effect on workers that are already running.
The only attribute of a worker that cannot be set via .setupPrimary() is
the env passed to .fork().
The defaults above apply to the first call only; the defaults for later
calls are the current values at the time of cluster.setupPrimary() is called.

import cluster from 'node:cluster';

cluster.setupPrimary({
  exec: 'worker.js',
  args: ['--use', 'https'],
  silent: true,
});
cluster.fork(); // https worker
cluster.setupPrimary({
  exec: 'worker.js',
  args: ['--use', 'http'],
});
cluster.fork(); // http workerconst cluster = require('node:cluster');

cluster.setupPrimary({
  exec: 'worker.js',
  args: ['--use', 'https'],
  silent: true,
});
cluster.fork(); // https worker
cluster.setupPrimary({
  exec: 'worker.js',
  args: ['--use', 'http'],
});
cluster.fork(); // http workercopy
This can only be called from the primary process.
cluster.worker#

Added in: v0.7.0


<Object>

A reference to the current worker object. Not available in the primary process.

import cluster from 'node:cluster';

if (cluster.isPrimary) {
  console.log('I am primary');
  cluster.fork();
  cluster.fork();
} else if (cluster.isWorker) {
  console.log(`I am worker #${cluster.worker.id}`);
}const cluster = require('node:cluster');

if (cluster.isPrimary) {
  console.log('I am primary');
  cluster.fork();
  cluster.fork();
} else if (cluster.isWorker) {
  console.log(`I am worker #${cluster.worker.id}`);
}copy
cluster.workers#

Added in: v0.7.0


<Object>

A hash that stores the active worker objects, keyed by id field. This makes it
easy to loop through all the workers. It is only available in the primary
process.
A worker is removed from cluster.workers after the worker has disconnected
and exited. The order between these two events cannot be determined in
advance. However, it is guaranteed that the removal from the cluster.workers
list happens before the last 'disconnect' or 'exit' event is emitted.

import cluster from 'node:cluster';

for (const worker of Object.values(cluster.workers)) {
  worker.send('big announcement to all workers');
}const cluster = require('node:cluster');

for (const worker of Object.values(cluster.workers)) {
  worker.send('big announcement to all workers');
}copy\n\n\n\nNode.js
        
      
      
About this documentation
Usage and example



Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Modules: TypeScript
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
Readline
REPL
Report
Single executable applications
SQLite
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker

    

    
      
        
          Node.js v24.0.1 documentation
          
            
            
          
        
        
          
            Node.js v24.0.1
            
    
      
        
        Table of contents
      

      
Command-line API

Synopsis
Program entry point

ECMAScript modules loader entry point caveat


Options

-
--
--abort-on-uncaught-exception
--allow-addons
--allow-child-process
--allow-fs-read
--allow-fs-write
--allow-wasi
--allow-worker
--build-snapshot
--build-snapshot-config
-c, --check
--completion-bash
-C condition, --conditions=condition
--cpu-prof
--cpu-prof-dir
--cpu-prof-interval
--cpu-prof-name
--diagnostic-dir=directory
--disable-proto=mode
--disable-sigusr1
--disable-warning=code-or-type
--disable-wasm-trap-handler
--disallow-code-generation-from-strings
--dns-result-order=order
--enable-fips
--enable-network-family-autoselection
--enable-source-maps
--entry-url
--env-file-if-exists=config
--env-file=config
-e, --eval "script"
--experimental-addon-modules
--experimental-config-file=config
--experimental-default-config-file
--experimental-eventsource
--experimental-import-meta-resolve
--experimental-loader=module
--experimental-network-inspection
--experimental-print-required-tla
--experimental-require-module
--experimental-sea-config
--experimental-shadow-realm
--experimental-test-coverage
--experimental-test-module-mocks
--experimental-transform-types
--experimental-vm-modules
--experimental-wasi-unstable-preview1
--experimental-wasm-modules
--experimental-webstorage
--expose-gc
--force-context-aware
--force-fips
--force-node-api-uncaught-exceptions-policy
--frozen-intrinsics
--heap-prof
--heap-prof-dir
--heap-prof-interval
--heap-prof-name
--heapsnapshot-near-heap-limit=max_count
--heapsnapshot-signal=signal
-h, --help
--icu-data-dir=file
--import=module
--input-type=type
--insecure-http-parser

Warning: binding inspector to a public IP:port combination is insecure


--inspect-brk[=[host:]port]
--inspect-port=[host:]port
--inspect-publish-uid=stderr,http
--inspect-wait[=[host:]port]
--inspect[=[host:]port]
-i, --interactive
--jitless
--localstorage-file=file
--max-http-header-size=size
--napi-modules
--network-family-autoselection-attempt-timeout
--no-addons
--no-async-context-frame
--no-deprecation
--no-experimental-detect-module
--no-experimental-global-navigator
--no-experimental-repl-await
--no-experimental-require-module
--no-experimental-sqlite
--no-experimental-strip-types
--no-experimental-websocket
--no-extra-info-on-fatal-exception
--no-force-async-hooks-checks
--no-global-search-paths
--no-network-family-autoselection
--no-warnings
--node-memory-debug
--openssl-config=file
--openssl-legacy-provider
--openssl-shared-config
--pending-deprecation
--permission
--preserve-symlinks
--preserve-symlinks-main
-p, --print "script"
--prof
--prof-process
--redirect-warnings=file
--report-compact
--report-dir=directory, report-directory=directory
--report-exclude-env
--report-exclude-network
--report-filename=filename
--report-on-fatalerror
--report-on-signal
--report-signal=signal
--report-uncaught-exception
-r, --require module
--run

Intentional limitations
Environment variables


--secure-heap-min=n
--secure-heap=n
--snapshot-blob=path
--test
--test-concurrency
--test-coverage-branches=threshold
--test-coverage-exclude
--test-coverage-functions=threshold
--test-coverage-include
--test-coverage-lines=threshold
--test-force-exit
--test-global-setup=module
--test-isolation=mode
--test-name-pattern
--test-only
--test-reporter
--test-reporter-destination
--test-shard
--test-skip-pattern
--test-timeout
--test-update-snapshots
--throw-deprecation
--title=title
--tls-cipher-list=list
--tls-keylog=file
--tls-max-v1.2
--tls-max-v1.3
--tls-min-v1.0
--tls-min-v1.1
--tls-min-v1.2
--tls-min-v1.3
--trace-deprecation
--trace-env
--trace-env-js-stack
--trace-env-native-stack
--trace-event-categories
--trace-event-file-pattern
--trace-events-enabled
--trace-exit
--trace-require-module=mode
--trace-sigint
--trace-sync-io
--trace-tls
--trace-uncaught
--trace-warnings
--track-heap-objects
--unhandled-rejections=mode
--use-bundled-ca, --use-openssl-ca
--use-largepages=mode
--use-system-ca
--v8-options
--v8-pool-size=num
-v, --version
--watch
--watch-path
--watch-preserve-output
--zero-fill-buffers


Environment variables

FORCE_COLOR=[1, 2, 3]
NODE_COMPILE_CACHE=dir
NODE_DEBUG=module[,…]
NODE_DEBUG_NATIVE=module[,…]
NODE_DISABLE_COLORS=1
NODE_DISABLE_COMPILE_CACHE=1
NODE_EXTRA_CA_CERTS=file
NODE_ICU_DATA=file
NODE_NO_WARNINGS=1
NODE_OPTIONS=options...
NODE_PATH=path[:…]
NODE_PENDING_DEPRECATION=1
NODE_PENDING_PIPE_INSTANCES=instances
NODE_PRESERVE_SYMLINKS=1
NODE_REDIRECT_WARNINGS=file
NODE_REPL_EXTERNAL_MODULE=file
NODE_REPL_HISTORY=file
NODE_SKIP_PLATFORM_CHECK=value
NODE_TEST_CONTEXT=value
NODE_TLS_REJECT_UNAUTHORIZED=value
NODE_USE_ENV_PROXY=1
NODE_V8_COVERAGE=dir

Coverage output
Source map cache


NO_COLOR=<any>
OPENSSL_CONF=file
SSL_CERT_DIR=dir
SSL_CERT_FILE=file
TZ
UV_THREADPOOL_SIZE=size


Useful V8 options

--abort-on-uncaught-exception
--disallow-code-generation-from-strings
--enable-etw-stack-walking
--expose-gc
--harmony-shadow-realm
--interpreted-frames-native-stack
--jitless
--max-old-space-size=SIZE (in MiB)
--max-semi-space-size=SIZE (in MiB)
--perf-basic-prof
--perf-basic-prof-only-functions
--perf-prof
--perf-prof-unwinding-info
--prof
--security-revert
--stack-trace-limit=limit





    
  
            
    
      
        
        Index
      

      
About this documentation
Usage and example

      
        Index
      
    
  


Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Modules: TypeScript
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
Readline
REPL
Report
Single executable applications
SQLite
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker

    
  
            
    
      
        
        Other versions
      
      24.x
23.x
22.x LTS
21.x
20.x LTS
19.x
18.x
17.x
16.x
15.x
14.x
13.x
12.x
11.x
10.x
9.x
8.x
7.x
6.x
5.x
    
  
            
              
                
                Options
              
        
              
                
                  
                    View on single page
                  
                  
                    View as JSON
                  
                  Edit on GitHub    
                
              
            
          
        
        
      

      Table of contents
Command-line API

Synopsis
Program entry point

ECMAScript modules loader entry point caveat


Options

-
--
--abort-on-uncaught-exception
--allow-addons
--allow-child-process
--allow-fs-read
--allow-fs-write
--allow-wasi
--allow-worker
--build-snapshot
--build-snapshot-config
-c, --check
--completion-bash
-C condition, --conditions=condition
--cpu-prof
--cpu-prof-dir
--cpu-prof-interval
--cpu-prof-name
--diagnostic-dir=directory
--disable-proto=mode
--disable-sigusr1
--disable-warning=code-or-type
--disable-wasm-trap-handler
--disallow-code-generation-from-strings
--dns-result-order=order
--enable-fips
--enable-network-family-autoselection
--enable-source-maps
--entry-url
--env-file-if-exists=config
--env-file=config
-e, --eval "script"
--experimental-addon-modules
--experimental-config-file=config
--experimental-default-config-file
--experimental-eventsource
--experimental-import-meta-resolve
--experimental-loader=module
--experimental-network-inspection
--experimental-print-required-tla
--experimental-require-module
--experimental-sea-config
--experimental-shadow-realm
--experimental-test-coverage
--experimental-test-module-mocks
--experimental-transform-types
--experimental-vm-modules
--experimental-wasi-unstable-preview1
--experimental-wasm-modules
--experimental-webstorage
--expose-gc
--force-context-aware
--force-fips
--force-node-api-uncaught-exceptions-policy
--frozen-intrinsics
--heap-prof
--heap-prof-dir
--heap-prof-interval
--heap-prof-name
--heapsnapshot-near-heap-limit=max_count
--heapsnapshot-signal=signal
-h, --help
--icu-data-dir=file
--import=module
--input-type=type
--insecure-http-parser

Warning: binding inspector to a public IP:port combination is insecure


--inspect-brk[=[host:]port]
--inspect-port=[host:]port
--inspect-publish-uid=stderr,http
--inspect-wait[=[host:]port]
--inspect[=[host:]port]
-i, --interactive
--jitless
--localstorage-file=file
--max-http-header-size=size
--napi-modules
--network-family-autoselection-attempt-timeout
--no-addons
--no-async-context-frame
--no-deprecation
--no-experimental-detect-module
--no-experimental-global-navigator
--no-experimental-repl-await
--no-experimental-require-module
--no-experimental-sqlite
--no-experimental-strip-types
--no-experimental-websocket
--no-extra-info-on-fatal-exception
--no-force-async-hooks-checks
--no-global-search-paths
--no-network-family-autoselection
--no-warnings
--node-memory-debug
--openssl-config=file
--openssl-legacy-provider
--openssl-shared-config
--pending-deprecation
--permission
--preserve-symlinks
--preserve-symlinks-main
-p, --print "script"
--prof
--prof-process
--redirect-warnings=file
--report-compact
--report-dir=directory, report-directory=directory
--report-exclude-env
--report-exclude-network
--report-filename=filename
--report-on-fatalerror
--report-on-signal
--report-signal=signal
--report-uncaught-exception
-r, --require module
--run

Intentional limitations
Environment variables


--secure-heap-min=n
--secure-heap=n
--snapshot-blob=path
--test
--test-concurrency
--test-coverage-branches=threshold
--test-coverage-exclude
--test-coverage-functions=threshold
--test-coverage-include
--test-coverage-lines=threshold
--test-force-exit
--test-global-setup=module
--test-isolation=mode
--test-name-pattern
--test-only
--test-reporter
--test-reporter-destination
--test-shard
--test-skip-pattern
--test-timeout
--test-update-snapshots
--throw-deprecation
--title=title
--tls-cipher-list=list
--tls-keylog=file
--tls-max-v1.2
--tls-max-v1.3
--tls-min-v1.0
--tls-min-v1.1
--tls-min-v1.2
--tls-min-v1.3
--trace-deprecation
--trace-env
--trace-env-js-stack
--trace-env-native-stack
--trace-event-categories
--trace-event-file-pattern
--trace-events-enabled
--trace-exit
--trace-require-module=mode
--trace-sigint
--trace-sync-io
--trace-tls
--trace-uncaught
--trace-warnings
--track-heap-objects
--unhandled-rejections=mode
--use-bundled-ca, --use-openssl-ca
--use-largepages=mode
--use-system-ca
--v8-options
--v8-pool-size=num
-v, --version
--watch
--watch-path
--watch-preserve-output
--zero-fill-buffers


Environment variables

FORCE_COLOR=[1, 2, 3]
NODE_COMPILE_CACHE=dir
NODE_DEBUG=module[,…]
NODE_DEBUG_NATIVE=module[,…]
NODE_DISABLE_COLORS=1
NODE_DISABLE_COMPILE_CACHE=1
NODE_EXTRA_CA_CERTS=file
NODE_ICU_DATA=file
NODE_NO_WARNINGS=1
NODE_OPTIONS=options...
NODE_PATH=path[:…]
NODE_PENDING_DEPRECATION=1
NODE_PENDING_PIPE_INSTANCES=instances
NODE_PRESERVE_SYMLINKS=1
NODE_REDIRECT_WARNINGS=file
NODE_REPL_EXTERNAL_MODULE=file
NODE_REPL_HISTORY=file
NODE_SKIP_PLATFORM_CHECK=value
NODE_TEST_CONTEXT=value
NODE_TLS_REJECT_UNAUTHORIZED=value
NODE_USE_ENV_PROXY=1
NODE_V8_COVERAGE=dir

Coverage output
Source map cache


NO_COLOR=<any>
OPENSSL_CONF=file
SSL_CERT_DIR=dir
SSL_CERT_FILE=file
TZ
UV_THREADPOOL_SIZE=size


Useful V8 options

--abort-on-uncaught-exception
--disallow-code-generation-from-strings
--enable-etw-stack-walking
--expose-gc
--harmony-shadow-realm
--interpreted-frames-native-stack
--jitless
--max-old-space-size=SIZE (in MiB)
--max-semi-space-size=SIZE (in MiB)
--perf-basic-prof
--perf-basic-prof-only-functions
--perf-prof
--perf-prof-unwinding-info
--prof
--security-revert
--stack-trace-limit=limit






      
        Command-line API#


Node.js comes with a variety of CLI options. These options expose built-in
debugging, multiple ways to execute scripts, and other helpful runtime options.
To view this documentation as a manual page in a terminal, run man node.
Synopsis#
node [options] [V8 options] [<program-entry-point> | -e "script" | -] [--] [arguments]
node inspect [<program-entry-point> | -e "script" | <host>:<port>] …
node --v8-options
Execute without arguments to start the REPL.
For more info about node inspect, see the debugger documentation.
Program entry point#
The program entry point is a specifier-like string. If the string is not an
absolute path, it's resolved as a relative path from the current working
directory. That path is then resolved by CommonJS module loader. If no
corresponding file is found, an error is thrown.
If a file is found, its path will be passed to the
ES module loader under any of the following conditions:

The program was started with a command-line flag that forces the entry
point to be loaded with ECMAScript module loader, such as --import.
The file has an .mjs or .wasm (with --experimental-wasm-modules)
extension.
The file does not have a .cjs extension, and the nearest parent
package.json file contains a top-level "type" field with a value of
"module".

Otherwise, the file is loaded using the CommonJS module loader. See
Modules loaders for more details.

ECMAScript modules loader entry point caveat#
When loading, the ES module loader loads the program
entry point, the node command will accept as input only files with .js,
.mjs, or .cjs extensions. With the following flags, additional file
extensions are enabled:

--experimental-wasm-modules for files with .wasm extension.
--experimental-addon-modules for files with .node extension.


Options#

History

VersionChanges
v10.12.0
Underscores instead of dashes are now allowed for Node.js options as well, in addition to V8 options.



Stability: 2 - Stable
All options, including V8 options, allow words to be separated by both
dashes (-) or underscores (_). For example, --pending-deprecation is
equivalent to --pending_deprecation.
If an option that takes a single value (such as --max-http-header-size) is
passed more than once, then the last passed value is used. Options from the
command line take precedence over options passed through the NODE_OPTIONS
environment variable.

-#

Added in: v8.0.0

Alias for stdin. Analogous to the use of - in other command-line utilities,
meaning that the script is read from stdin, and the rest of the options
are passed to that script.

--#

Added in: v6.11.0

Indicate the end of node options. Pass the rest of the arguments to the script.
If no script filename or eval/print script is supplied prior to this, then
the next argument is used as a script filename.

--abort-on-uncaught-exception#

Added in: v0.10.8

Aborting instead of exiting causes a core file to be generated for post-mortem
analysis using a debugger (such as lldb, gdb, and mdb).
If this flag is passed, the behavior can still be set to not abort through
process.setUncaughtExceptionCaptureCallback() (and through usage of the
node:domain module that uses it).

--allow-addons#

Added in: v21.6.0, v20.12.0

Stability: 1.1 - Active development
When using the Permission Model, the process will not be able to use
native addons by default.
Attempts to do so will throw an ERR_DLOPEN_DISABLED unless the
user explicitly passes the --allow-addons flag when starting Node.js.
Example:
// Attempt to require an native addon
require('nodejs-addon-example'); copy
$ node --permission --allow-fs-read=* index.js
node:internal/modules/cjs/loader:1319
  return process.dlopen(module, path.toNamespacedPath(filename));
                 ^

Error: Cannot load native addon because loading addons is disabled.
    at Module._extensions..node (node:internal/modules/cjs/loader:1319:18)
    at Module.load (node:internal/modules/cjs/loader:1091:32)
    at Module._load (node:internal/modules/cjs/loader:938:12)
    at Module.require (node:internal/modules/cjs/loader:1115:19)
    at require (node:internal/modules/helpers:130:18)
    at Object.<anonymous> (/home/index.js:1:15)
    at Module._compile (node:internal/modules/cjs/loader:1233:14)
    at Module._extensions..js (node:internal/modules/cjs/loader:1287:10)
    at Module.load (node:internal/modules/cjs/loader:1091:32)
    at Module._load (node:internal/modules/cjs/loader:938:12) {
  code: 'ERR_DLOPEN_DISABLED'
} copy

--allow-child-process#

Added in: v20.0.0

Stability: 1.1 - Active development
When using the Permission Model, the process will not be able to spawn any
child process by default.
Attempts to do so will throw an ERR_ACCESS_DENIED unless the
user explicitly passes the --allow-child-process flag when starting Node.js.
Example:
const childProcess = require('node:child_process');
// Attempt to bypass the permission
childProcess.spawn('node', ['-e', 'require("fs").writeFileSync("/new-file", "example")']); copy
$ node --permission --allow-fs-read=* index.js
node:internal/child_process:388
  const err = this._handle.spawn(options);
                           ^
Error: Access to this API has been restricted
    at ChildProcess.spawn (node:internal/child_process:388:28)
    at node:internal/main/run_main_module:17:47 {
  code: 'ERR_ACCESS_DENIED',
  permission: 'ChildProcess'
} copy
Unlike child_process.spawn, the child_process.fork API copies the execution
arguments from the parent process. This means that if you start Node.js with the
Permission Model enabled and include the --allow-child-process flag, calling
child_process.fork() will propagate all Permission Model flags to the child
process.

--allow-fs-read#

History

VersionChanges
v23.5.0, v22.13.0
Permission Model and --allow-fs flags are stable.
v20.7.0
Paths delimited by comma (,) are no longer allowed.
v20.0.0
Added in: v20.0.0



This flag configures file system read permissions using
the Permission Model.
The valid arguments for the --allow-fs-read flag are:

* - To allow all FileSystemRead operations.
Multiple paths can be allowed using multiple --allow-fs-read flags.
Example --allow-fs-read=/folder1/ --allow-fs-read=/folder1/

Examples can be found in the File System Permissions documentation.
The initializer module also needs to be allowed. Consider the following example:
$ node --permission index.js

Error: Access to this API has been restricted
    at node:internal/main/run_main_module:23:47 {
  code: 'ERR_ACCESS_DENIED',
  permission: 'FileSystemRead',
  resource: '/Users/rafaelgss/repos/os/node/index.js'
} copy
The process needs to have access to the index.js module:
node --permission --allow-fs-read=/path/to/index.js index.js copy

--allow-fs-write#

History

VersionChanges
v23.5.0, v22.13.0
Permission Model and --allow-fs flags are stable.
v20.7.0
Paths delimited by comma (,) are no longer allowed.
v20.0.0
Added in: v20.0.0



This flag configures file system write permissions using
the Permission Model.
The valid arguments for the --allow-fs-write flag are:

* - To allow all FileSystemWrite operations.
Multiple paths can be allowed using multiple --allow-fs-write flags.
Example --allow-fs-write=/folder1/ --allow-fs-write=/folder1/

Paths delimited by comma (,) are no longer allowed.
When passing a single flag with a comma a warning will be displayed.
Examples can be found in the File System Permissions documentation.

--allow-wasi#

Added in: v22.3.0, v20.16.0

Stability: 1.1 - Active development
When using the Permission Model, the process will not be capable of creating
any WASI instances by default.
For security reasons, the call will throw an ERR_ACCESS_DENIED unless the
user explicitly passes the flag --allow-wasi in the main Node.js process.
Example:
const { WASI } = require('node:wasi');
// Attempt to bypass the permission
new WASI({
  version: 'preview1',
  // Attempt to mount the whole filesystem
  preopens: {
    '/': '/',
  },
}); copy
$ node --permission --allow-fs-read=* index.js

Error: Access to this API has been restricted
    at node:internal/main/run_main_module:30:49 {
  code: 'ERR_ACCESS_DENIED',
  permission: 'WASI',
} copy

--allow-worker#

Added in: v20.0.0

Stability: 1.1 - Active development
When using the Permission Model, the process will not be able to create any
worker threads by default.
For security reasons, the call will throw an ERR_ACCESS_DENIED unless the
user explicitly pass the flag --allow-worker in the main Node.js process.
Example:
const { Worker } = require('node:worker_threads');
// Attempt to bypass the permission
new Worker(__filename); copy
$ node --permission --allow-fs-read=* index.js

Error: Access to this API has been restricted
    at node:internal/main/run_main_module:17:47 {
  code: 'ERR_ACCESS_DENIED',
  permission: 'WorkerThreads'
} copy

--build-snapshot#

Added in: v18.8.0

Stability: 1 - Experimental
Generates a snapshot blob when the process exits and writes it to
disk, which can be loaded later with --snapshot-blob.
When building the snapshot, if --snapshot-blob is not specified,
the generated blob will be written, by default, to snapshot.blob
in the current working directory. Otherwise it will be written to
the path specified by --snapshot-blob.
$ echo "globalThis.foo = 'I am from the snapshot'" > snapshot.js

# Run snapshot.js to initialize the application and snapshot the
# state of it into snapshot.blob.
$ node --snapshot-blob snapshot.blob --build-snapshot snapshot.js

$ echo "console.log(globalThis.foo)" > index.js

# Load the generated snapshot and start the application from index.js.
$ node --snapshot-blob snapshot.blob index.js
I am from the snapshot copy
The v8.startupSnapshot API can be used to specify an entry point at
snapshot building time, thus avoiding the need of an additional entry
script at deserialization time:
$ echo "require('v8').startupSnapshot.setDeserializeMainFunction(() => console.log('I am from the snapshot'))" > snapshot.js
$ node --snapshot-blob snapshot.blob --build-snapshot snapshot.js
$ node --snapshot-blob snapshot.blob
I am from the snapshot copy
For more information, check out the v8.startupSnapshot API documentation.
Currently the support for run-time snapshot is experimental in that:

User-land modules are not yet supported in the snapshot, so only
one single file can be snapshotted. Users can bundle their applications
into a single script with their bundler of choice before building
a snapshot, however.
Only a subset of the built-in modules work in the snapshot, though the
Node.js core test suite checks that a few fairly complex applications
can be snapshotted. Support for more modules are being added. If any
crashes or buggy behaviors occur when building a snapshot, please file
a report in the Node.js issue tracker and link to it in the
tracking issue for user-land snapshots.


--build-snapshot-config#

Added in: v21.6.0, v20.12.0

Stability: 1 - Experimental
Specifies the path to a JSON configuration file which configures snapshot
creation behavior.
The following options are currently supported:

builder <string> Required. Provides the name to the script that is executed
before building the snapshot, as if --build-snapshot had been passed
with builder as the main script name.
withoutCodeCache <boolean> Optional. Including the code cache reduces the
time spent on compiling functions included in the snapshot at the expense
of a bigger snapshot size and potentially breaking portability of the
snapshot.

When using this flag, additional script files provided on the command line will
not be executed and instead be interpreted as regular command line arguments.

-c, --check#

History

VersionChanges
v10.0.0
The --require option is now supported when checking a file.
v5.0.0, v4.2.0
Added in: v5.0.0, v4.2.0



Syntax check the script without executing.

--completion-bash#

Added in: v10.12.0

Print source-able bash completion script for Node.js.
node --completion-bash > node_bash_completion
source node_bash_completion copy

-C condition, --conditions=condition#

History

VersionChanges
v22.9.0, v20.18.0
The flag is no longer experimental.
v14.9.0, v12.19.0
Added in: v14.9.0, v12.19.0



Provide custom conditional exports resolution conditions.
Any number of custom string condition names are permitted.
The default Node.js conditions of "node", "default", "import", and
"require" will always apply as defined.
For example, to run a module with "development" resolutions:
node -C development app.js copy

--cpu-prof#

History

VersionChanges
v22.4.0, v20.16.0
The --cpu-prof flags are now stable.
v12.0.0
Added in: v12.0.0



Starts the V8 CPU profiler on start up, and writes the CPU profile to disk
before exit.
If --cpu-prof-dir is not specified, the generated profile is placed
in the current working directory.
If --cpu-prof-name is not specified, the generated profile is
named CPU.${yyyymmdd}.${hhmmss}.${pid}.${tid}.${seq}.cpuprofile.
$ node --cpu-prof index.js
$ ls *.cpuprofile
CPU.20190409.202950.15293.0.0.cpuprofile copy
If --cpu-prof-name is specified, the provided value will be used as-is; patterns such as
${hhmmss} or ${pid} are not supported.
$ node --cpu-prof --cpu-prof-name 'CPU.${pid}.cpuprofile' index.js
$ ls *.cpuprofile
'CPU.${pid}.cpuprofile' copy

--cpu-prof-dir#

History

VersionChanges
v22.4.0, v20.16.0
The --cpu-prof flags are now stable.
v12.0.0
Added in: v12.0.0



Specify the directory where the CPU profiles generated by --cpu-prof will
be placed.
The default value is controlled by the
--diagnostic-dir command-line option.

--cpu-prof-interval#

History

VersionChanges
v22.4.0, v20.16.0
The --cpu-prof flags are now stable.
v12.2.0
Added in: v12.2.0



Specify the sampling interval in microseconds for the CPU profiles generated
by --cpu-prof. The default is 1000 microseconds.

--cpu-prof-name#

History

VersionChanges
v22.4.0, v20.16.0
The --cpu-prof flags are now stable.
v12.0.0
Added in: v12.0.0



Specify the file name of the CPU profile generated by --cpu-prof.

--diagnostic-dir=directory#
Set the directory to which all diagnostic output files are written.
Defaults to current working directory.
Affects the default output directory of:

--cpu-prof-dir
--heap-prof-dir
--redirect-warnings


--disable-proto=mode#

Added in: v13.12.0, v12.17.0

Disable the Object.prototype.__proto__ property. If mode is delete, the
property is removed entirely. If mode is throw, accesses to the
property throw an exception with the code ERR_PROTO_ACCESS.

--disable-sigusr1#

Added in: v23.7.0, v22.14.0

Stability: 1.2 - Release candidate
Disable the ability of starting a debugging session by sending a
SIGUSR1 signal to the process.

--disable-warning=code-or-type#

Added in: v21.3.0, v20.11.0

Stability: 1.1 - Active development
Disable specific process warnings by code or type.
Warnings emitted from process.emitWarning() may contain a
code and a type. This option will not-emit warnings that have a matching
code or type.
List of deprecation warnings.
The Node.js core warning types are: DeprecationWarning and
ExperimentalWarning
For example, the following script will not emit
DEP0025 require('node:sys') when executed with
node --disable-warning=DEP0025:

import sys from 'node:sys';const sys = require('node:sys');copy
For example, the following script will emit the
DEP0025 require('node:sys'), but not any Experimental
Warnings (such as
ExperimentalWarning: vm.measureMemory is an experimental feature
in <=v21) when executed with node --disable-warning=ExperimentalWarning:

import sys from 'node:sys';
import vm from 'node:vm';

vm.measureMemory();const sys = require('node:sys');
const vm = require('node:vm');

vm.measureMemory();copy

--disable-wasm-trap-handler#

Added in: v22.2.0, v20.15.0

By default, Node.js enables trap-handler-based WebAssembly bound
checks. As a result, V8 does not need to insert inline bound checks
int the code compiled from WebAssembly which may speedup WebAssembly
execution significantly, but this optimization requires allocating
a big virtual memory cage (currently 10GB). If the Node.js process
does not have access to a large enough virtual memory address space
due to system configurations or hardware limitations, users won't
be able to run any WebAssembly that involves allocation in this
virtual memory cage and will see an out-of-memory error.
$ ulimit -v 5000000
$ node -p "new WebAssembly.Memory({ initial: 10, maximum: 100 });"
[eval]:1
new WebAssembly.Memory({ initial: 10, maximum: 100 });
^

RangeError: WebAssembly.Memory(): could not allocate memory
    at [eval]:1:1
    at runScriptInThisContext (node:internal/vm:209:10)
    at node:internal/process/execution:118:14
    at [eval]-wrapper:6:24
    at runScript (node:internal/process/execution:101:62)
    at evalScript (node:internal/process/execution:136:3)
    at node:internal/main/eval_string:49:3
 copy
--disable-wasm-trap-handler disables this optimization so that
users can at least run WebAssembly (with less optimal performance)
when the virtual memory address space available to their Node.js
process is lower than what the V8 WebAssembly memory cage needs.

--disallow-code-generation-from-strings#

Added in: v9.8.0

Make built-in language features like eval and new Function that generate
code from strings throw an exception instead. This does not affect the Node.js
node:vm module.

--dns-result-order=order#

History

VersionChanges
v22.1.0, v20.13.0
The ipv6first is supported now.
v17.0.0
Changed default value to verbatim.
v16.4.0, v14.18.0
Added in: v16.4.0, v14.18.0



Set the default value of order in dns.lookup() and
dnsPromises.lookup(). The value could be:

ipv4first: sets default order to ipv4first.
ipv6first: sets default order to ipv6first.
verbatim: sets default order to verbatim.

The default is verbatim and dns.setDefaultResultOrder() have higher
priority than --dns-result-order.

--enable-fips#

Added in: v6.0.0

Enable FIPS-compliant crypto at startup. (Requires Node.js to be built
against FIPS-compatible OpenSSL.)

--enable-network-family-autoselection#

Added in: v18.18.0

Enables the family autoselection algorithm unless connection options explicitly
disables it.

--enable-source-maps#

History

VersionChanges
v15.11.0, v14.18.0
This API is no longer experimental.
v12.12.0
Added in: v12.12.0



Enable Source Map v3 support for stack traces.
When using a transpiler, such as TypeScript, stack traces thrown by an
application reference the transpiled code, not the original source position.
--enable-source-maps enables caching of Source Maps and makes a best
effort to report stack traces relative to the original source file.
Overriding Error.prepareStackTrace may prevent --enable-source-maps from
modifying the stack trace. Call and return the results of the original
Error.prepareStackTrace in the overriding function to modify the stack trace
with source maps.
const originalPrepareStackTrace = Error.prepareStackTrace;
Error.prepareStackTrace = (error, trace) => {
  // Modify error and trace and format stack trace with
  // original Error.prepareStackTrace.
  return originalPrepareStackTrace(error, trace);
}; copy
Note, enabling source maps can introduce latency to your application
when Error.stack is accessed. If you access Error.stack frequently
in your application, take into account the performance implications
of --enable-source-maps.

--entry-url#

Added in: v23.0.0, v22.10.0

Stability: 1 - Experimental
When present, Node.js will interpret the entry point as a URL, rather than a
path.
Follows ECMAScript module resolution rules.
Any query parameter or hash in the URL will be accessible via import.meta.url.
node --entry-url 'file:///path/to/file.js?queryparams=work#and-hashes-too'
node --entry-url 'file.ts?query#hash'
node --entry-url 'data:text/javascript,console.log("Hello")' copy

--env-file-if-exists=config#

Added in: v22.9.0

Stability: 1.1 - Active development
Behavior is the same as --env-file, but an error is not thrown if the file
does not exist.

--env-file=config#

History

VersionChanges
v21.7.0, v20.12.0
Add support to multi-line values.
v20.6.0
Added in: v20.6.0



Stability: 1.1 - Active development
Loads environment variables from a file relative to the current directory,
making them available to applications on process.env. The environment
variables which configure Node.js, such as NODE_OPTIONS,
are parsed and applied. If the same variable is defined in the environment and
in the file, the value from the environment takes precedence.
You can pass multiple --env-file arguments. Subsequent files override
pre-existing variables defined in previous files.
An error is thrown if the file does not exist.
node --env-file=.env --env-file=.development.env index.js copy
The format of the file should be one line per key-value pair of environment
variable name and value separated by =:
PORT=3000 copy
Any text after a # is treated as a comment:
# This is a comment
PORT=3000 # This is also a comment copy
Values can start and end with the following quotes: `, " or '.
They are omitted from the values.
USERNAME="nodejs" # will result in `nodejs` as the value. copy
Multi-line values are supported:
MULTI_LINE="THIS IS
A MULTILINE"
# will result in `THIS IS\nA MULTILINE` as the value. copy
Export keyword before a key is ignored:
export USERNAME="nodejs" # will result in `nodejs` as the value. copy
If you want to load environment variables from a file that may not exist, you
can use the --env-file-if-exists flag instead.

-e, --eval "script"#

History

VersionChanges
v22.6.0
Eval now supports experimental type-stripping.
v5.11.0
Built-in libraries are now available as predefined variables.
v0.5.2
Added in: v0.5.2



Evaluate the following argument as JavaScript. The modules which are
predefined in the REPL can also be used in script.
On Windows, using cmd.exe a single quote will not work correctly because it
only recognizes double " for quoting. In Powershell or Git bash, both '
and " are usable.
It is possible to run code containing inline types unless the
--no-experimental-strip-types flag is provided.

--experimental-addon-modules#

Added in: v23.6.0

Stability: 1.0 - Early development
Enable experimental import support for .node addons.

--experimental-config-file=config#

Added in: v23.10.0

Stability: 1.0 - Early development
If present, Node.js will look for a configuration file at the specified path.
Node.js will read the configuration file and apply the settings. The
configuration file should be a JSON file with the following structure. vX.Y.Z
in the $schema must be replaced with the version of Node.js you are using.
{
  "$schema": "https://nodejs.org/dist/vX.Y.Z/docs/node-config-schema.json",
  "nodeOptions": {
    "import": [
      "amaro/strip"
    ],
    "watch-path": "src",
    "watch-preserve-output": true
  }
} copy
In the nodeOptions field, only flags that are allowed in NODE_OPTIONS are supported.
No-op flags are not supported.
Not all V8 flags are currently supported.
It is possible to use the official JSON schema
to validate the configuration file, which may vary depending on the Node.js version.
Each key in the configuration file corresponds to a flag that can be passed
as a command-line argument. The value of the key is the value that would be
passed to the flag.
For example, the configuration file above is equivalent to
the following command-line arguments:
node --import amaro/strip --watch-path=src --watch-preserve-output copy
The priority in configuration is as follows:

NODE_OPTIONS and command-line options
Configuration file
Dotenv NODE_OPTIONS

Values in the configuration file will not override the values in the environment
variables and command-line options, but will override the values in the NODE_OPTIONS
env file parsed by the --env-file flag.
If duplicate keys are present in the configuration file, only
the first key will be used.
The configuration parser will throw an error if the configuration file contains
unknown keys or keys that cannot used in NODE_OPTIONS.
Node.js will not sanitize or perform validation on the user-provided configuration,
so NEVER use untrusted configuration files.

--experimental-default-config-file#

Added in: v23.10.0

Stability: 1.0 - Early development
If the --experimental-default-config-file flag is present, Node.js will look for a
node.config.json file in the current working directory and load it as a
as configuration file.

--experimental-eventsource#

Added in: v22.3.0, v20.18.0

Enable exposition of EventSource Web API on the global scope.

--experimental-import-meta-resolve#

History

VersionChanges
v20.6.0, v18.19.0
synchronous import.meta.resolve made available by default, with the flag retained for enabling the experimental second argument as previously supported.
v13.9.0, v12.16.2
Added in: v13.9.0, v12.16.2



Enable experimental import.meta.resolve() parent URL support, which allows
passing a second parentURL argument for contextual resolution.
Previously gated the entire import.meta.resolve feature.

--experimental-loader=module#

History

VersionChanges
v23.6.1, v22.13.1, v20.18.2
Using this feature with the permission model enabled requires passing --allow-worker.
v12.11.1
This flag was renamed from --loader to --experimental-loader.
v8.8.0
Added in: v8.8.0




This flag is discouraged and may be removed in a future version of Node.js.
Please use
--import with register() instead.

Specify the module containing exported module customization hooks.
module may be any string accepted as an import specifier.
This feature requires --allow-worker if used with the Permission Model.

--experimental-network-inspection#

Added in: v22.6.0, v20.18.0

Stability: 1 - Experimental
Enable experimental support for the network inspection with Chrome DevTools.

--experimental-print-required-tla#

Added in: v22.0.0, v20.17.0

If the ES module being require()'d contains top-level await, this flag
allows Node.js to evaluate the module, try to locate the
top-level awaits, and print their location to help users find them.

--experimental-require-module#

History

VersionChanges
v23.0.0, v22.12.0, v20.19.0
This is now true by default.
v22.0.0, v20.17.0
Added in: v22.0.0, v20.17.0



Stability: 1.1 - Active Development
Supports loading a synchronous ES module graph in require().
See Loading ECMAScript modules using require().

--experimental-sea-config#

Added in: v20.0.0

Stability: 1 - Experimental
Use this flag to generate a blob that can be injected into the Node.js
binary to produce a single executable application. See the documentation
about this configuration for details.

--experimental-shadow-realm#

Added in: v19.0.0, v18.13.0

Use this flag to enable ShadowRealm support.

--experimental-test-coverage#

History

VersionChanges
v20.1.0, v18.17.0
This option can be used with --test.
v19.7.0, v18.15.0
Added in: v19.7.0, v18.15.0



When used in conjunction with the node:test module, a code coverage report is
generated as part of the test runner output. If no tests are run, a coverage
report is not generated. See the documentation on
collecting code coverage from tests for more details.

--experimental-test-module-mocks#

History

VersionChanges
v23.6.1, v22.13.1, v20.18.2
Using this feature with the permission model enabled requires passing --allow-worker.
v22.3.0, v20.18.0
Added in: v22.3.0, v20.18.0



Stability: 1.0 - Early development
Enable module mocking in the test runner.
This feature requires --allow-worker if used with the Permission Model.

--experimental-transform-types#

Added in: v22.7.0

Stability: 1.2 - Release candidate
Enables the transformation of TypeScript-only syntax into JavaScript code.
Implies --enable-source-maps.

--experimental-vm-modules#

Added in: v9.6.0

Enable experimental ES Module support in the node:vm module.

--experimental-wasi-unstable-preview1#

History

VersionChanges
v20.0.0, v18.17.0
This option is no longer required as WASI is enabled by default, but can still be passed.
v13.6.0
changed from --experimental-wasi-unstable-preview0 to --experimental-wasi-unstable-preview1.
v13.3.0, v12.16.0
Added in: v13.3.0, v12.16.0



Enable experimental WebAssembly System Interface (WASI) support.

--experimental-wasm-modules#

Added in: v12.3.0

Enable experimental WebAssembly module support.

--experimental-webstorage#

Added in: v22.4.0

Enable experimental Web Storage support.

--expose-gc#

Added in: v22.3.0, v20.18.0

Stability: 1 - Experimental. This flag is inherited from V8 and is subject to
change upstream.
This flag will expose the gc extension from V8.
if (globalThis.gc) {
  globalThis.gc();
} copy

--force-context-aware#

Added in: v12.12.0

Disable loading native addons that are not context-aware.

--force-fips#

Added in: v6.0.0

Force FIPS-compliant crypto on startup. (Cannot be disabled from script code.)
(Same requirements as --enable-fips.)

--force-node-api-uncaught-exceptions-policy#

Added in: v18.3.0, v16.17.0

Enforces uncaughtException event on Node-API asynchronous callbacks.
To prevent from an existing add-on from crashing the process, this flag is not
enabled by default. In the future, this flag will be enabled by default to
enforce the correct behavior.

--frozen-intrinsics#

Added in: v11.12.0

Stability: 1 - Experimental
Enable experimental frozen intrinsics like Array and Object.
Only the root context is supported. There is no guarantee that
globalThis.Array is indeed the default intrinsic reference. Code may break
under this flag.
To allow polyfills to be added,
--require and --import both run before freezing intrinsics.

--heap-prof#

History

VersionChanges
v22.4.0, v20.16.0
The --heap-prof flags are now stable.
v12.4.0
Added in: v12.4.0



Starts the V8 heap profiler on start up, and writes the heap profile to disk
before exit.
If --heap-prof-dir is not specified, the generated profile is placed
in the current working directory.
If --heap-prof-name is not specified, the generated profile is
named Heap.${yyyymmdd}.${hhmmss}.${pid}.${tid}.${seq}.heapprofile.
$ node --heap-prof index.js
$ ls *.heapprofile
Heap.20190409.202950.15293.0.001.heapprofile copy

--heap-prof-dir#

History

VersionChanges
v22.4.0, v20.16.0
The --heap-prof flags are now stable.
v12.4.0
Added in: v12.4.0



Specify the directory where the heap profiles generated by --heap-prof will
be placed.
The default value is controlled by the
--diagnostic-dir command-line option.

--heap-prof-interval#

History

VersionChanges
v22.4.0, v20.16.0
The --heap-prof flags are now stable.
v12.4.0
Added in: v12.4.0



Specify the average sampling interval in bytes for the heap profiles generated
by --heap-prof. The default is 512 * 1024 bytes.

--heap-prof-name#

History

VersionChanges
v22.4.0, v20.16.0
The --heap-prof flags are now stable.
v12.4.0
Added in: v12.4.0



Specify the file name of the heap profile generated by --heap-prof.

--heapsnapshot-near-heap-limit=max_count#

Added in: v15.1.0, v14.18.0

Stability: 1 - Experimental
Writes a V8 heap snapshot to disk when the V8 heap usage is approaching the
heap limit. count should be a non-negative integer (in which case
Node.js will write no more than max_count snapshots to disk).
When generating snapshots, garbage collection may be triggered and bring
the heap usage down. Therefore multiple snapshots may be written to disk
before the Node.js instance finally runs out of memory. These heap snapshots
can be compared to determine what objects are being allocated during the
time consecutive snapshots are taken. It's not guaranteed that Node.js will
write exactly max_count snapshots to disk, but it will try
its best to generate at least one and up to max_count snapshots before the
Node.js instance runs out of memory when max_count is greater than 0.
Generating V8 snapshots takes time and memory (both memory managed by the
V8 heap and native memory outside the V8 heap). The bigger the heap is,
the more resources it needs. Node.js will adjust the V8 heap to accommodate
the additional V8 heap memory overhead, and try its best to avoid using up
all the memory available to the process. When the process uses
more memory than the system deems appropriate, the process may be terminated
abruptly by the system, depending on the system configuration.
$ node --max-old-space-size=100 --heapsnapshot-near-heap-limit=3 index.js
Wrote snapshot to Heap.20200430.100036.49580.0.001.heapsnapshot
Wrote snapshot to Heap.20200430.100037.49580.0.002.heapsnapshot
Wrote snapshot to Heap.20200430.100038.49580.0.003.heapsnapshot

<--- Last few GCs --->

[49580:0x110000000]     4826 ms: Mark-sweep 130.6 (147.8) -> 130.5 (147.8) MB, 27.4 / 0.0 ms  (average mu = 0.126, current mu = 0.034) allocation failure scavenge might not succeed
[49580:0x110000000]     4845 ms: Mark-sweep 130.6 (147.8) -> 130.6 (147.8) MB, 18.8 / 0.0 ms  (average mu = 0.088, current mu = 0.031) allocation failure scavenge might not succeed


<--- JS stacktrace --->

FATAL ERROR: Ineffective mark-compacts near heap limit Allocation failed - JavaScript heap out of memory
.... copy

--heapsnapshot-signal=signal#

Added in: v12.0.0

Enables a signal handler that causes the Node.js process to write a heap dump
when the specified signal is received. signal must be a valid signal name.
Disabled by default.
$ node --heapsnapshot-signal=SIGUSR2 index.js &
$ ps aux
USER       PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND
node         1  5.5  6.1 787252 247004 ?       Ssl  16:43   0:02 node --heapsnapshot-signal=SIGUSR2 index.js
$ kill -USR2 1
$ ls
Heap.20190718.133405.15554.0.001.heapsnapshot copy

-h, --help#

Added in: v0.1.3

Print node command-line options.
The output of this option is less detailed than this document.

--icu-data-dir=file#

Added in: v0.11.15

Specify ICU data load path. (Overrides NODE_ICU_DATA.)

--import=module#

Added in: v19.0.0, v18.18.0

Stability: 1 - Experimental
Preload the specified module at startup. If the flag is provided several times,
each module will be executed sequentially in the order they appear, starting
with the ones provided in NODE_OPTIONS.
Follows ECMAScript module resolution rules.
Use --require to load a CommonJS module.
Modules preloaded with --require will run before modules preloaded with --import.
Modules are preloaded into the main thread as well as any worker threads,
forked processes, or clustered processes.

--input-type=type#

History

VersionChanges
v23.6.0
Add support for -typescript values.
v22.7.0, v20.19.0
ESM syntax detection is enabled by default.
v12.0.0
Added in: v12.0.0



This configures Node.js to interpret --eval or STDIN input as CommonJS or
as an ES module. Valid values are "commonjs", "module", "module-typescript" and "commonjs-typescript".
The "-typescript" values are not available with the flag --no-experimental-strip-types.
The default is no value, or "commonjs" if --no-experimental-detect-module is passed.
If --input-type is not provided,
Node.js will try to detect the syntax with the following steps:

Run the input as CommonJS.
If step 1 fails, run the input as an ES module.
If step 2 fails with a SyntaxError, strip the types.
If step 3 fails with an error code ERR_UNSUPPORTED_TYPESCRIPT_SYNTAX
or ERR_INVALID_TYPESCRIPT_SYNTAX,
throw the error from step 2, including the TypeScript error in the message,
else run as CommonJS.
If step 4 fails, run the input as an ES module.

To avoid the delay of multiple syntax detection passes, the --input-type=type flag can be used to specify
how the --eval input should be interpreted.
The REPL does not support this option. Usage of --input-type=module with
--print will throw an error, as --print does not support ES module
syntax.

--insecure-http-parser#

Added in: v13.4.0, v12.15.0, v10.19.0

Enable leniency flags on the HTTP parser. This may allow
interoperability with non-conformant HTTP implementations.
When enabled, the parser will accept the following:

Invalid HTTP headers values.
Invalid HTTP versions.
Allow message containing both Transfer-Encoding
and Content-Length headers.
Allow extra data after message when Connection: close is present.
Allow extra transfer encodings after chunked has been provided.
Allow \n to be used as token separator instead of \r\n.
Allow \r\n not to be provided after a chunk.
Allow spaces to be present after a chunk size and before \r\n.

All the above will expose your application to request smuggling
or poisoning attack. Avoid using this option.



Warning: binding inspector to a public IP:port combination is insecure#
Binding the inspector to a public IP (including 0.0.0.0) with an open port is
insecure, as it allows external hosts to connect to the inspector and perform
a remote code execution attack.
If specifying a host, make sure that either:

The host is not accessible from public networks.
A firewall disallows unwanted connections on the port.

More specifically, --inspect=0.0.0.0 is insecure if the port (9229 by
default) is not firewall-protected.
See the debugging security implications section for more information.

--inspect-brk[=[host:]port]#

Added in: v7.6.0

Activate inspector on host:port and break at start of user script.
Default host:port is 127.0.0.1:9229. If port 0 is specified,
a random available port will be used.
See V8 Inspector integration for Node.js for further explanation on Node.js debugger.

--inspect-port=[host:]port#

Added in: v7.6.0

Set the host:port to be used when the inspector is activated.
Useful when activating the inspector by sending the SIGUSR1 signal.
Except when --disable-sigusr1 is passed.
Default host is 127.0.0.1. If port 0 is specified,
a random available port will be used.
See the security warning below regarding the host
parameter usage.

--inspect-publish-uid=stderr,http#
Specify ways of the inspector web socket url exposure.
By default inspector websocket url is available in stderr and under /json/list
endpoint on http://host:port/json/list.

--inspect-wait[=[host:]port]#

Added in: v22.2.0, v20.15.0

Activate inspector on host:port and wait for debugger to be attached.
Default host:port is 127.0.0.1:9229. If port 0 is specified,
a random available port will be used.
See V8 Inspector integration for Node.js for further explanation on Node.js debugger.

--inspect[=[host:]port]#

Added in: v6.3.0

Activate inspector on host:port. Default is 127.0.0.1:9229. If port 0 is
specified, a random available port will be used.
V8 inspector integration allows tools such as Chrome DevTools and IDEs to debug
and profile Node.js instances. The tools attach to Node.js instances via a
tcp port and communicate using the Chrome DevTools Protocol.
See V8 Inspector integration for Node.js for further explanation on Node.js debugger.

-i, --interactive#

Added in: v0.7.7

Opens the REPL even if stdin does not appear to be a terminal.

--jitless#

Added in: v12.0.0

Stability: 1 - Experimental. This flag is inherited from V8 and is subject to
change upstream.
Disable runtime allocation of executable memory. This may be
required on some platforms for security reasons. It can also reduce attack
surface on other platforms, but the performance impact may be severe.

--localstorage-file=file#

Added in: v22.4.0

The file used to store localStorage data. If the file does not exist, it is
created the first time localStorage is accessed. The same file may be shared
between multiple Node.js processes concurrently. This flag is a no-op unless
Node.js is started with the --experimental-webstorage flag.

--max-http-header-size=size#

History

VersionChanges
v13.13.0
Change maximum default size of HTTP headers from 8 KiB to 16 KiB.
v11.6.0, v10.15.0
Added in: v11.6.0, v10.15.0



Specify the maximum size, in bytes, of HTTP headers. Defaults to 16 KiB.

--napi-modules#

Added in: v7.10.0

This option is a no-op. It is kept for compatibility.

--network-family-autoselection-attempt-timeout#

Added in: v22.1.0, v20.13.0

Sets the default value for the network family autoselection attempt timeout.
For more information, see net.getDefaultAutoSelectFamilyAttemptTimeout().

--no-addons#

Added in: v16.10.0, v14.19.0

Disable the node-addons exports condition as well as disable loading
native addons. When --no-addons is specified, calling process.dlopen or
requiring a native C++ addon will fail and throw an exception.

--no-async-context-frame#

Added in: v24.0.0

Disables the use of AsyncLocalStorage backed by AsyncContextFrame and
uses the prior implementation which relied on async_hooks. The previous model
is retained for compatibility with Electron and for cases where the context
flow may differ. However, if a difference in flow is found please report it.

--no-deprecation#

Added in: v0.8.0

Silence deprecation warnings.

--no-experimental-detect-module#

History

VersionChanges
v22.7.0, v20.19.0
Syntax detection is enabled by default.
v21.1.0, v20.10.0
Added in: v21.1.0, v20.10.0



Disable using syntax detection to determine module type.

--no-experimental-global-navigator#

Added in: v21.2.0

Stability: 1 - Experimental
Disable exposition of Navigator API on the global scope.

--no-experimental-repl-await#

Added in: v16.6.0

Use this flag to disable top-level await in REPL.

--no-experimental-require-module#

History

VersionChanges
v23.0.0, v22.12.0, v20.19.0
This is now false by default.
v22.0.0, v20.17.0
Added in: v22.0.0, v20.17.0



Stability: 1.1 - Active Development
Disable support for loading a synchronous ES module graph in require().
See Loading ECMAScript modules using require().

--no-experimental-sqlite#

History

VersionChanges
v23.4.0, v22.13.0
SQLite is unflagged but still experimental.
v22.5.0
Added in: v22.5.0



Disable the experimental node:sqlite module.

--no-experimental-strip-types#

History

VersionChanges
v23.6.0
Type stripping is enabled by default.
v22.6.0
Added in: v22.6.0



Stability: 1.2 - Release candidate
Disable experimental type-stripping for TypeScript files.
For more information, see the TypeScript type-stripping documentation.

--no-experimental-websocket#

Added in: v22.0.0

Disable exposition of WebSocket on the global scope.

--no-extra-info-on-fatal-exception#

Added in: v17.0.0

Hide extra information on fatal exception that causes exit.

--no-force-async-hooks-checks#

Added in: v9.0.0

Disables runtime checks for async_hooks. These will still be enabled
dynamically when async_hooks is enabled.

--no-global-search-paths#

Added in: v16.10.0

Do not search modules from global paths like $HOME/.node_modules and
$NODE_PATH.

--no-network-family-autoselection#

History

VersionChanges
v20.0.0
The flag was renamed from --no-enable-network-family-autoselection to --no-network-family-autoselection. The old name can still work as an alias.
v19.4.0
Added in: v19.4.0



Disables the family autoselection algorithm unless connection options explicitly
enables it.

--no-warnings#

Added in: v6.0.0

Silence all process warnings (including deprecations).

--node-memory-debug#

Added in: v15.0.0, v14.18.0

Enable extra debug checks for memory leaks in Node.js internals. This is
usually only useful for developers debugging Node.js itself.

--openssl-config=file#

Added in: v6.9.0

Load an OpenSSL configuration file on startup. Among other uses, this can be
used to enable FIPS-compliant crypto if Node.js is built
against FIPS-enabled OpenSSL.

--openssl-legacy-provider#

Added in: v17.0.0, v16.17.0

Enable OpenSSL 3.0 legacy provider. For more information please see
OSSL_PROVIDER-legacy.

--openssl-shared-config#

Added in: v18.5.0, v16.17.0, v14.21.0

Enable OpenSSL default configuration section, openssl_conf to be read from
the OpenSSL configuration file. The default configuration file is named
openssl.cnf but this can be changed using the environment variable
OPENSSL_CONF, or by using the command line option --openssl-config.
The location of the default OpenSSL configuration file depends on how OpenSSL
is being linked to Node.js. Sharing the OpenSSL configuration may have unwanted
implications and it is recommended to use a configuration section specific to
Node.js which is nodejs_conf and is default when this option is not used.

--pending-deprecation#

Added in: v8.0.0

Emit pending deprecation warnings.
Pending deprecations are generally identical to a runtime deprecation with the
notable exception that they are turned off by default and will not be emitted
unless either the --pending-deprecation command-line flag, or the
NODE_PENDING_DEPRECATION=1 environment variable, is set. Pending deprecations
are used to provide a kind of selective "early warning" mechanism that
developers may leverage to detect deprecated API usage.

--permission#

History

VersionChanges
v23.5.0, v22.13.0
Permission Model is now stable.
v20.0.0
Added in: v20.0.0



Enable the Permission Model for current process. When enabled, the
following permissions are restricted:

File System - manageable through
--allow-fs-read, --allow-fs-write flags
Child Process - manageable through --allow-child-process flag
Worker Threads - manageable through --allow-worker flag
WASI - manageable through --allow-wasi flag
Addons - manageable through --allow-addons flag


--preserve-symlinks#

Added in: v6.3.0

Instructs the module loader to preserve symbolic links when resolving and
caching modules.
By default, when Node.js loads a module from a path that is symbolically linked
to a different on-disk location, Node.js will dereference the link and use the
actual on-disk "real path" of the module as both an identifier and as a root
path to locate other dependency modules. In most cases, this default behavior
is acceptable. However, when using symbolically linked peer dependencies, as
illustrated in the example below, the default behavior causes an exception to
be thrown if moduleA attempts to require moduleB as a peer dependency:
{appDir}
 ├── app
 │   ├── index.js
 │   └── node_modules
 │       ├── moduleA -> {appDir}/moduleA
 │       └── moduleB
 │           ├── index.js
 │           └── package.json
 └── moduleA
     ├── index.js
     └── package.json copy
The --preserve-symlinks command-line flag instructs Node.js to use the
symlink path for modules as opposed to the real path, allowing symbolically
linked peer dependencies to be found.
Note, however, that using --preserve-symlinks can have other side effects.
Specifically, symbolically linked native modules can fail to load if those
are linked from more than one location in the dependency tree (Node.js would
see those as two separate modules and would attempt to load the module multiple
times, causing an exception to be thrown).
The --preserve-symlinks flag does not apply to the main module, which allows
node --preserve-symlinks node_module/.bin/<foo> to work. To apply the same
behavior for the main module, also use --preserve-symlinks-main.

--preserve-symlinks-main#

Added in: v10.2.0

Instructs the module loader to preserve symbolic links when resolving and
caching the main module (require.main).
This flag exists so that the main module can be opted-in to the same behavior
that --preserve-symlinks gives to all other imports; they are separate flags,
however, for backward compatibility with older Node.js versions.
--preserve-symlinks-main does not imply --preserve-symlinks; use
--preserve-symlinks-main in addition to
--preserve-symlinks when it is not desirable to follow symlinks before
resolving relative paths.
See --preserve-symlinks for more information.

-p, --print "script"#

History

VersionChanges
v5.11.0
Built-in libraries are now available as predefined variables.
v0.6.4
Added in: v0.6.4



Identical to -e but prints the result.

--prof#

Added in: v2.0.0

Generate V8 profiler output.

--prof-process#

Added in: v5.2.0

Process V8 profiler output generated using the V8 option --prof.

--redirect-warnings=file#

Added in: v8.0.0

Write process warnings to the given file instead of printing to stderr. The
file will be created if it does not exist, and will be appended to if it does.
If an error occurs while attempting to write the warning to the file, the
warning will be written to stderr instead.
The file name may be an absolute path. If it is not, the default directory it
will be written to is controlled by the
--diagnostic-dir command-line option.

--report-compact#

Added in: v13.12.0, v12.17.0

Write reports in a compact format, single-line JSON, more easily consumable
by log processing systems than the default multi-line format designed for
human consumption.

--report-dir=directory, report-directory=directory#

History

VersionChanges
v13.12.0, v12.17.0
This option is no longer experimental.
v12.0.0
Changed from --diagnostic-report-directory to --report-directory.
v11.8.0
Added in: v11.8.0



Location at which the report will be generated.

--report-exclude-env#

Added in: v23.3.0, v22.13.0

When --report-exclude-env is passed the diagnostic report generated will not
contain the environmentVariables data.

--report-exclude-network#

Added in: v22.0.0, v20.13.0

Exclude header.networkInterfaces from the diagnostic report. By default
this is not set and the network interfaces are included.

--report-filename=filename#

History

VersionChanges
v13.12.0, v12.17.0
This option is no longer experimental.
v12.0.0
changed from --diagnostic-report-filename to --report-filename.
v11.8.0
Added in: v11.8.0



Name of the file to which the report will be written.
If the filename is set to 'stdout' or 'stderr', the report is written to
the stdout or stderr of the process respectively.

--report-on-fatalerror#

History

VersionChanges
v14.0.0, v13.14.0, v12.17.0
This option is no longer experimental.
v12.0.0
changed from --diagnostic-report-on-fatalerror to --report-on-fatalerror.
v11.8.0
Added in: v11.8.0



Enables the report to be triggered on fatal errors (internal errors within
the Node.js runtime such as out of memory) that lead to termination of the
application. Useful to inspect various diagnostic data elements such as heap,
stack, event loop state, resource consumption etc. to reason about the fatal
error.

--report-on-signal#

History

VersionChanges
v13.12.0, v12.17.0
This option is no longer experimental.
v12.0.0
changed from --diagnostic-report-on-signal to --report-on-signal.
v11.8.0
Added in: v11.8.0



Enables report to be generated upon receiving the specified (or predefined)
signal to the running Node.js process. The signal to trigger the report is
specified through --report-signal.

--report-signal=signal#

History

VersionChanges
v13.12.0, v12.17.0
This option is no longer experimental.
v12.0.0
changed from --diagnostic-report-signal to --report-signal.
v11.8.0
Added in: v11.8.0



Sets or resets the signal for report generation (not supported on Windows).
Default signal is SIGUSR2.

--report-uncaught-exception#

History

VersionChanges
v18.8.0, v16.18.0
Report is not generated if the uncaught exception is handled.
v13.12.0, v12.17.0
This option is no longer experimental.
v12.0.0
changed from --diagnostic-report-uncaught-exception to --report-uncaught-exception.
v11.8.0
Added in: v11.8.0



Enables report to be generated when the process exits due to an uncaught
exception. Useful when inspecting the JavaScript stack in conjunction with
native stack and other runtime environment data.

-r, --require module#

History

VersionChanges
v23.0.0, v22.12.0, v20.19.0
This option also supports ECMAScript module.
v1.6.0
Added in: v1.6.0



Preload the specified module at startup.
Follows require()'s module resolution
rules. module may be either a path to a file, or a node module name.
Modules preloaded with --require will run before modules preloaded with --import.
Modules are preloaded into the main thread as well as any worker threads,
forked processes, or clustered processes.

--run#

History

VersionChanges
v22.3.0
NODE_RUN_SCRIPT_NAME environment variable is added.
v22.3.0
NODE_RUN_PACKAGE_JSON_PATH environment variable is added.
v22.3.0
Traverses up to the root directory and finds a package.json file to run the command from, and updates PATH environment variable accordingly.
v22.0.0
Added in: v22.0.0



This runs a specified command from a package.json's "scripts" object.
If a missing "command" is provided, it will list the available scripts.
--run will traverse up to the root directory and finds a package.json
file to run the command from.
--run prepends ./node_modules/.bin for each ancestor of
the current directory, to the PATH in order to execute the binaries from
different folders where multiple node_modules directories are present, if
ancestor-folder/node_modules/.bin is a directory.
--run executes the command in the directory containing the related package.json.
For example, the following command will run the test script of
the package.json in the current folder:
$ node --run test copy
You can also pass arguments to the command. Any argument after -- will
be appended to the script:
$ node --run test -- --verbose copy

Intentional limitations#
node --run is not meant to match the behaviors of npm run or of the run
commands of other package managers. The Node.js implementation is intentionally
more limited, in order to focus on top performance for the most common use
cases.
Some features of other run implementations that are intentionally excluded
are:

Running pre or post scripts in addition to the specified script.
Defining package manager-specific environment variables.


Environment variables#
The following environment variables are set when running a script with --run:

NODE_RUN_SCRIPT_NAME: The name of the script being run. For example, if
--run is used to run test, the value of this variable will be test.
NODE_RUN_PACKAGE_JSON_PATH: The path to the package.json that is being
processed.


--secure-heap-min=n#

Added in: v15.6.0

When using --secure-heap, the --secure-heap-min flag specifies the
minimum allocation from the secure heap. The minimum value is 2.
The maximum value is the lesser of --secure-heap or 2147483647.
The value given must be a power of two.

--secure-heap=n#

Added in: v15.6.0

Initializes an OpenSSL secure heap of n bytes. When initialized, the
secure heap is used for selected types of allocations within OpenSSL
during key generation and other operations. This is useful, for instance,
to prevent sensitive information from leaking due to pointer overruns
or underruns.
The secure heap is a fixed size and cannot be resized at runtime so,
if used, it is important to select a large enough heap to cover all
application uses.
The heap size given must be a power of two. Any value less than 2
will disable the secure heap.
The secure heap is disabled by default.
The secure heap is not available on Windows.
See CRYPTO_secure_malloc_init for more details.

--snapshot-blob=path#

Added in: v18.8.0

Stability: 1 - Experimental
When used with --build-snapshot, --snapshot-blob specifies the path
where the generated snapshot blob is written to. If not specified, the
generated blob is written to snapshot.blob in the current working directory.
When used without --build-snapshot, --snapshot-blob specifies the
path to the blob that is used to restore the application state.
When loading a snapshot, Node.js checks that:

The version, architecture, and platform of the running Node.js binary
are exactly the same as that of the binary that generates the snapshot.
The V8 flags and CPU features are compatible with that of the binary
that generates the snapshot.

If they don't match, Node.js refuses to load the snapshot and exits with
status code 1.

--test#

History

VersionChanges
v20.0.0
The test runner is now stable.
v19.2.0, v18.13.0
Test runner now supports running in watch mode.
v18.1.0, v16.17.0
Added in: v18.1.0, v16.17.0



Starts the Node.js command line test runner. This flag cannot be combined with
--watch-path, --check, --eval, --interactive, or the inspector.
See the documentation on running tests from the command line
for more details.

--test-concurrency#

Added in: v21.0.0, v20.10.0, v18.19.0

The maximum number of test files that the test runner CLI will execute
concurrently. If --test-isolation is set to 'none', this flag is ignored and
concurrency is one. Otherwise, concurrency defaults to
os.availableParallelism() - 1.

--test-coverage-branches=threshold#

Added in: v22.8.0

Stability: 1 - Experimental
Require a minimum percent of covered branches. If code coverage does not reach
the threshold specified, the process will exit with code 1.

--test-coverage-exclude#

Added in: v22.5.0

Stability: 1 - Experimental
Excludes specific files from code coverage using a glob pattern, which can match
both absolute and relative file paths.
This option may be specified multiple times to exclude multiple glob patterns.
If both --test-coverage-exclude and --test-coverage-include are provided,
files must meet both criteria to be included in the coverage report.
By default all the matching test files are excluded from the coverage report.
Specifying this option will override the default behavior.

--test-coverage-functions=threshold#

Added in: v22.8.0

Stability: 1 - Experimental
Require a minimum percent of covered functions. If code coverage does not reach
the threshold specified, the process will exit with code 1.

--test-coverage-include#

Added in: v22.5.0

Stability: 1 - Experimental
Includes specific files in code coverage using a glob pattern, which can match
both absolute and relative file paths.
This option may be specified multiple times to include multiple glob patterns.
If both --test-coverage-exclude and --test-coverage-include are provided,
files must meet both criteria to be included in the coverage report.

--test-coverage-lines=threshold#

Added in: v22.8.0

Stability: 1 - Experimental
Require a minimum percent of covered lines. If code coverage does not reach
the threshold specified, the process will exit with code 1.

--test-force-exit#

Added in: v22.0.0, v20.14.0

Configures the test runner to exit the process once all known tests have
finished executing even if the event loop would otherwise remain active.

--test-global-setup=module#

Added in: v24.0.0

Stability: 1.0 - Early development
Specify a module that will be evaluated before all tests are executed and
can be used to setup global state or fixtures for tests.
See the documentation on global setup and teardown for more details.

--test-isolation=mode#

History

VersionChanges
v23.6.0
This flag was renamed from --experimental-test-isolation to --test-isolation.
v22.8.0
Added in: v22.8.0



Configures the type of test isolation used in the test runner. When mode is
'process', each test file is run in a separate child process. When mode is
'none', all test files run in the same process as the test runner. The default
isolation mode is 'process'. This flag is ignored if the --test flag is not
present. See the test runner execution model section for more information.

--test-name-pattern#

History

VersionChanges
v20.0.0
The test runner is now stable.
v18.11.0
Added in: v18.11.0



A regular expression that configures the test runner to only execute tests
whose name matches the provided pattern. See the documentation on
filtering tests by name for more details.
If both --test-name-pattern and --test-skip-pattern are supplied,
tests must satisfy both requirements in order to be executed.

--test-only#

History

VersionChanges
v20.0.0
The test runner is now stable.
v18.0.0, v16.17.0
Added in: v18.0.0, v16.17.0



Configures the test runner to only execute top level tests that have the only
option set. This flag is not necessary when test isolation is disabled.

--test-reporter#

History

VersionChanges
v20.0.0
The test runner is now stable.
v19.6.0, v18.15.0
Added in: v19.6.0, v18.15.0



A test reporter to use when running tests. See the documentation on
test reporters for more details.

--test-reporter-destination#

History

VersionChanges
v20.0.0
The test runner is now stable.
v19.6.0, v18.15.0
Added in: v19.6.0, v18.15.0



The destination for the corresponding test reporter. See the documentation on
test reporters for more details.

--test-shard#

Added in: v20.5.0, v18.19.0

Test suite shard to execute in a format of <index>/<total>, where
index is a positive integer, index of divided parts
total is a positive integer, total of divided part
This command will divide all tests files into total equal parts,
and will run only those that happen to be in an index part.
For example, to split your tests suite into three parts, use this:
node --test --test-shard=1/3
node --test --test-shard=2/3
node --test --test-shard=3/3 copy

--test-skip-pattern#

Added in: v22.1.0

A regular expression that configures the test runner to skip tests
whose name matches the provided pattern. See the documentation on
filtering tests by name for more details.
If both --test-name-pattern and --test-skip-pattern are supplied,
tests must satisfy both requirements in order to be executed.

--test-timeout#

Added in: v21.2.0, v20.11.0

A number of milliseconds the test execution will fail after. If unspecified,
subtests inherit this value from their parent. The default value is Infinity.

--test-update-snapshots#

History

VersionChanges
v23.4.0, v22.13.0
Snapsnot testing is no longer experimental.
v22.3.0
Added in: v22.3.0



Regenerates the snapshot files used by the test runner for snapshot testing.

--throw-deprecation#

Added in: v0.11.14

Throw errors for deprecations.

--title=title#

Added in: v10.7.0

Set process.title on startup.

--tls-cipher-list=list#

Added in: v4.0.0

Specify an alternative default TLS cipher list. Requires Node.js to be built
with crypto support (default).

--tls-keylog=file#

Added in: v13.2.0, v12.16.0

Log TLS key material to a file. The key material is in NSS SSLKEYLOGFILE
format and can be used by software (such as Wireshark) to decrypt the TLS
traffic.

--tls-max-v1.2#

Added in: v12.0.0, v10.20.0

Set tls.DEFAULT_MAX_VERSION to 'TLSv1.2'. Use to disable support for
TLSv1.3.

--tls-max-v1.3#

Added in: v12.0.0

Set default tls.DEFAULT_MAX_VERSION to 'TLSv1.3'. Use to enable support
for TLSv1.3.

--tls-min-v1.0#

Added in: v12.0.0, v10.20.0

Set default tls.DEFAULT_MIN_VERSION to 'TLSv1'. Use for compatibility with
old TLS clients or servers.

--tls-min-v1.1#

Added in: v12.0.0, v10.20.0

Set default tls.DEFAULT_MIN_VERSION to 'TLSv1.1'. Use for compatibility
with old TLS clients or servers.

--tls-min-v1.2#

Added in: v12.2.0, v10.20.0

Set default tls.DEFAULT_MIN_VERSION to 'TLSv1.2'. This is the default for
12.x and later, but the option is supported for compatibility with older Node.js
versions.

--tls-min-v1.3#

Added in: v12.0.0

Set default tls.DEFAULT_MIN_VERSION to 'TLSv1.3'. Use to disable support
for TLSv1.2, which is not as secure as TLSv1.3.

--trace-deprecation#

Added in: v0.8.0

Print stack traces for deprecations.

--trace-env#

Added in: v23.4.0, v22.13.0

Print information about any access to environment variables done in the current Node.js
instance to stderr, including:

The environment variable reads that Node.js does internally.
Writes in the form of process.env.KEY = "SOME VALUE".
Reads in the form of process.env.KEY.
Definitions in the form of Object.defineProperty(process.env, 'KEY', {...}).
Queries in the form of Object.hasOwn(process.env, 'KEY'),
process.env.hasOwnProperty('KEY') or 'KEY' in process.env.
Deletions in the form of delete process.env.KEY.
Enumerations inf the form of ...process.env or Object.keys(process.env).

Only the names of the environment variables being accessed are printed. The values are not printed.
To print the stack trace of the access, use --trace-env-js-stack and/or
--trace-env-native-stack.

--trace-env-js-stack#

Added in: v23.4.0, v22.13.0

In addition to what --trace-env does, this prints the JavaScript stack trace of the access.

--trace-env-native-stack#

Added in: v23.4.0, v22.13.0

In addition to what --trace-env does, this prints the native stack trace of the access.

--trace-event-categories#

Added in: v7.7.0

A comma separated list of categories that should be traced when trace event
tracing is enabled using --trace-events-enabled.

--trace-event-file-pattern#

Added in: v9.8.0

Template string specifying the filepath for the trace event data, it
supports ${rotation} and ${pid}.

--trace-events-enabled#

Added in: v7.7.0

Enables the collection of trace event tracing information.

--trace-exit#

Added in: v13.5.0, v12.16.0

Prints a stack trace whenever an environment is exited proactively,
i.e. invoking process.exit().

--trace-require-module=mode#

Added in: v23.5.0, v22.13.0, v20.19.0

Prints information about usage of Loading ECMAScript modules using require().
When mode is all, all usage is printed. When mode is no-node-modules, usage
from the node_modules folder is excluded.

--trace-sigint#

Added in: v13.9.0, v12.17.0

Prints a stack trace on SIGINT.

--trace-sync-io#

Added in: v2.1.0

Prints a stack trace whenever synchronous I/O is detected after the first turn
of the event loop.

--trace-tls#

Added in: v12.2.0

Prints TLS packet trace information to stderr. This can be used to debug TLS
connection problems.

--trace-uncaught#

Added in: v13.1.0

Print stack traces for uncaught exceptions; usually, the stack trace associated
with the creation of an Error is printed, whereas this makes Node.js also
print the stack trace associated with throwing the value (which does not need
to be an Error instance).
Enabling this option may affect garbage collection behavior negatively.

--trace-warnings#

Added in: v6.0.0

Print stack traces for process warnings (including deprecations).

--track-heap-objects#

Added in: v2.4.0

Track heap object allocations for heap snapshots.

--unhandled-rejections=mode#

History

VersionChanges
v15.0.0
Changed default mode to throw. Previously, a warning was emitted.
v12.0.0, v10.17.0
Added in: v12.0.0, v10.17.0



Using this flag allows to change what should happen when an unhandled rejection
occurs. One of the following modes can be chosen:

throw: Emit unhandledRejection. If this hook is not set, raise the
unhandled rejection as an uncaught exception. This is the default.
strict: Raise the unhandled rejection as an uncaught exception. If the
exception is handled, unhandledRejection is emitted.
warn: Always trigger a warning, no matter if the unhandledRejection
hook is set or not but do not print the deprecation warning.
warn-with-error-code: Emit unhandledRejection. If this hook is not
set, trigger a warning, and set the process exit code to 1.
none: Silence all warnings.

If a rejection happens during the command line entry point's ES module static
loading phase, it will always raise it as an uncaught exception.

--use-bundled-ca, --use-openssl-ca#

Added in: v6.11.0

Use bundled Mozilla CA store as supplied by current Node.js version
or use OpenSSL's default CA store. The default store is selectable
at build-time.
The bundled CA store, as supplied by Node.js, is a snapshot of Mozilla CA store
that is fixed at release time. It is identical on all supported platforms.
Using OpenSSL store allows for external modifications of the store. For most
Linux and BSD distributions, this store is maintained by the distribution
maintainers and system administrators. OpenSSL CA store location is dependent on
configuration of the OpenSSL library but this can be altered at runtime using
environment variables.
See SSL_CERT_DIR and SSL_CERT_FILE.

--use-largepages=mode#

Added in: v13.6.0, v12.17.0

Re-map the Node.js static code to large memory pages at startup. If supported on
the target system, this will cause the Node.js static code to be moved onto 2
MiB pages instead of 4 KiB pages.
The following values are valid for mode:

off: No mapping will be attempted. This is the default.
on: If supported by the OS, mapping will be attempted. Failure to map will
be ignored and a message will be printed to standard error.
silent: If supported by the OS, mapping will be attempted. Failure to map
will be ignored and will not be reported.


--use-system-ca#

History

VersionChanges
v23.9.0
Added support on non-Windows and non-macOS.
v23.8.0
Added in: v23.8.0



Node.js uses the trusted CA certificates present in the system store along with
the --use-bundled-ca option and the NODE_EXTRA_CA_CERTS environment variable.
On platforms other than Windows and macOS, this loads certificates from the directory
and file trusted by OpenSSL, similar to --use-openssl-ca, with the difference being
that it caches the certificates after first load.
On Windows and macOS, the certificate trust policy is planned to follow
Chromium's policy for locally trusted certificates:
On macOS, the following settings are respected:

Default and System Keychains

Trust:

Any certificate where the “When using this certificate” flag is set to “Always Trust” or
Any certificate where the “Secure Sockets Layer (SSL)” flag is set to “Always Trust.”


Distrust:

Any certificate where the “When using this certificate” flag is set to “Never Trust” or
Any certificate where the “Secure Sockets Layer (SSL)” flag is set to “Never Trust.”





On Windows, the following settings are respected (unlike Chromium's policy, distrust
and intermediate CA are not currently supported):

Local Machine (accessed via certlm.msc)

Trust:

Trusted Root Certification Authorities
Trusted People
Enterprise Trust -> Enterprise -> Trusted Root Certification Authorities
Enterprise Trust -> Enterprise -> Trusted People
Enterprise Trust -> Group Policy -> Trusted Root Certification Authorities
Enterprise Trust -> Group Policy -> Trusted People




Current User (accessed via certmgr.msc)

Trust:

Trusted Root Certification Authorities
Enterprise Trust -> Group Policy -> Trusted Root Certification Authorities





On Windows and macOS, Node.js would check that the user settings for the certificates
do not forbid them for TLS server authentication before using them.
On other systems, Node.js loads certificates from the default certificate file
(typically /etc/ssl/cert.pem) and default certificate directory (typically
/etc/ssl/certs) that the version of OpenSSL that Node.js links to respects.
This typically works with the convention on major Linux distributions and other
Unix-like systems. If the overriding OpenSSL environment variables
(typically SSL_CERT_FILE and SSL_CERT_DIR, depending on the configuration
of the OpenSSL that Node.js links to) are set, the specified paths will be used to load
certificates instead. These environment variables can be used as workarounds
if the conventional paths used by the version of OpenSSL Node.js links to are
not consistent with the system configuration that the users have for some reason.

--v8-options#

Added in: v0.1.3

Print V8 command-line options.

--v8-pool-size=num#

Added in: v5.10.0

Set V8's thread pool size which will be used to allocate background jobs.
If set to 0 then Node.js will choose an appropriate size of the thread pool
based on an estimate of the amount of parallelism.
The amount of parallelism refers to the number of computations that can be
carried out simultaneously in a given machine. In general, it's the same as the
amount of CPUs, but it may diverge in environments such as VMs or containers.

-v, --version#

Added in: v0.1.3

Print node's version.

--watch#

History

VersionChanges
v22.0.0, v20.13.0
Watch mode is now stable.
v19.2.0, v18.13.0
Test runner now supports running in watch mode.
v18.11.0, v16.19.0
Added in: v18.11.0, v16.19.0



Starts Node.js in watch mode.
When in watch mode, changes in the watched files cause the Node.js process to
restart.
By default, watch mode will watch the entry point
and any required or imported module.
Use --watch-path to specify what paths to watch.
This flag cannot be combined with
--check, --eval, --interactive, or the REPL.
node --watch index.js copy

--watch-path#

History

VersionChanges
v22.0.0, v20.13.0
Watch mode is now stable.
v18.11.0, v16.19.0
Added in: v18.11.0, v16.19.0



Starts Node.js in watch mode and specifies what paths to watch.
When in watch mode, changes in the watched paths cause the Node.js process to
restart.
This will turn off watching of required or imported modules, even when used in
combination with --watch.
This flag cannot be combined with
--check, --eval, --interactive, --test, or the REPL.
node --watch-path=./src --watch-path=./tests index.js copy
This option is only supported on macOS and Windows.
An ERR_FEATURE_UNAVAILABLE_ON_PLATFORM exception will be thrown
when the option is used on a platform that does not support it.

--watch-preserve-output#

Added in: v19.3.0, v18.13.0

Disable the clearing of the console when watch mode restarts the process.
node --watch --watch-preserve-output test.js copy

--zero-fill-buffers#

Added in: v6.0.0

Automatically zero-fills all newly allocated Buffer and SlowBuffer
instances.

Environment variables#
Stability: 2 - Stable

FORCE_COLOR=[1, 2, 3]#
The FORCE_COLOR environment variable is used to
enable ANSI colorized output. The value may be:

1, true, or the empty string '' indicate 16-color support,
2 to indicate 256-color support, or
3 to indicate 16 million-color support.

When FORCE_COLOR is used and set to a supported value, both the NO_COLOR,
and NODE_DISABLE_COLORS environment variables are ignored.
Any other value will result in colorized output being disabled.

NODE_COMPILE_CACHE=dir#

Added in: v22.1.0

Stability: 1.1 - Active Development
Enable the module compile cache for the Node.js instance. See the documentation of
module compile cache for details.

NODE_DEBUG=module[,…]#

Added in: v0.1.32

','-separated list of core modules that should print debug information.

NODE_DEBUG_NATIVE=module[,…]#
','-separated list of core C++ modules that should print debug information.

NODE_DISABLE_COLORS=1#

Added in: v0.3.0

When set, colors will not be used in the REPL.

NODE_DISABLE_COMPILE_CACHE=1#

Added in: v22.8.0

Stability: 1.1 - Active Development
Disable the module compile cache for the Node.js instance. See the documentation of
module compile cache for details.

NODE_EXTRA_CA_CERTS=file#

Added in: v7.3.0

When set, the well known "root" CAs (like VeriSign) will be extended with the
extra certificates in file. The file should consist of one or more trusted
certificates in PEM format. A message will be emitted (once) with
process.emitWarning() if the file is missing or
malformed, but any errors are otherwise ignored.
Neither the well known nor extra certificates are used when the ca
options property is explicitly specified for a TLS or HTTPS client or server.
This environment variable is ignored when node runs as setuid root or
has Linux file capabilities set.
The NODE_EXTRA_CA_CERTS environment variable is only read when the Node.js
process is first launched. Changing the value at runtime using
process.env.NODE_EXTRA_CA_CERTS has no effect on the current process.

NODE_ICU_DATA=file#

Added in: v0.11.15

Data path for ICU (Intl object) data. Will extend linked-in data when compiled
with small-icu support.

NODE_NO_WARNINGS=1#

Added in: v6.11.0

When set to 1, process warnings are silenced.

NODE_OPTIONS=options...#

Added in: v8.0.0

A space-separated list of command-line options. options... are interpreted
before command-line options, so command-line options will override or
compound after anything in options.... Node.js will exit with an error if
an option that is not allowed in the environment is used, such as -p or a
script file.
If an option value contains a space, it can be escaped using double quotes:
NODE_OPTIONS='--require "./my path/file.js"' copy
A singleton flag passed as a command-line option will override the same flag
passed into NODE_OPTIONS:
# The inspector will be available on port 5555
NODE_OPTIONS='--inspect=localhost:4444' node --inspect=localhost:5555 copy
A flag that can be passed multiple times will be treated as if its
NODE_OPTIONS instances were passed first, and then its command-line
instances afterwards:
NODE_OPTIONS='--require "./a.js"' node --require "./b.js"
# is equivalent to:
node --require "./a.js" --require "./b.js" copy
Node.js options that are allowed are in the following list. If an option
supports both --XX and --no-XX variants, they are both supported but only
one is included in the list below.


--allow-addons
--allow-child-process
--allow-fs-read
--allow-fs-write
--allow-wasi
--allow-worker
--conditions, -C
--cpu-prof-dir
--cpu-prof-interval
--cpu-prof-name
--cpu-prof
--diagnostic-dir
--disable-proto
--disable-sigusr1
--disable-warning
--disable-wasm-trap-handler
--dns-result-order
--enable-fips
--enable-network-family-autoselection
--enable-source-maps
--entry-url
--experimental-abortcontroller
--experimental-addon-modules
--experimental-detect-module
--experimental-eventsource
--experimental-import-meta-resolve
--experimental-json-modules
--experimental-loader
--experimental-modules
--experimental-print-required-tla
--experimental-require-module
--experimental-shadow-realm
--experimental-specifier-resolution
--experimental-test-isolation
--experimental-top-level-await
--experimental-transform-types
--experimental-vm-modules
--experimental-wasi-unstable-preview1
--experimental-wasm-modules
--experimental-webstorage
--force-context-aware
--force-fips
--force-node-api-uncaught-exceptions-policy
--frozen-intrinsics
--heap-prof-dir
--heap-prof-interval
--heap-prof-name
--heap-prof
--heapsnapshot-near-heap-limit
--heapsnapshot-signal
--http-parser
--icu-data-dir
--import
--input-type
--insecure-http-parser
--inspect-brk
--inspect-port, --debug-port
--inspect-publish-uid
--inspect-wait
--inspect
--localstorage-file
--max-http-header-size
--napi-modules
--network-family-autoselection-attempt-timeout
--no-addons
--no-async-context-frame
--no-deprecation
--no-experimental-global-navigator
--no-experimental-repl-await
--no-experimental-sqlite
--no-experimental-strip-types
--no-experimental-websocket
--no-extra-info-on-fatal-exception
--no-force-async-hooks-checks
--no-global-search-paths
--no-network-family-autoselection
--no-warnings
--node-memory-debug
--openssl-config
--openssl-legacy-provider
--openssl-shared-config
--pending-deprecation
--permission
--preserve-symlinks-main
--preserve-symlinks
--prof-process
--redirect-warnings
--report-compact
--report-dir, --report-directory
--report-exclude-env
--report-exclude-network
--report-filename
--report-on-fatalerror
--report-on-signal
--report-signal
--report-uncaught-exception
--require, -r
--secure-heap-min
--secure-heap
--snapshot-blob
--test-coverage-branches
--test-coverage-exclude
--test-coverage-functions
--test-coverage-include
--test-coverage-lines
--test-global-setup
--test-isolation
--test-name-pattern
--test-only
--test-reporter-destination
--test-reporter
--test-shard
--test-skip-pattern
--throw-deprecation
--title
--tls-cipher-list
--tls-keylog
--tls-max-v1.2
--tls-max-v1.3
--tls-min-v1.0
--tls-min-v1.1
--tls-min-v1.2
--tls-min-v1.3
--trace-deprecation
--trace-env-js-stack
--trace-env-native-stack
--trace-env
--trace-event-categories
--trace-event-file-pattern
--trace-events-enabled
--trace-exit
--trace-require-module
--trace-sigint
--trace-sync-io
--trace-tls
--trace-uncaught
--trace-warnings
--track-heap-objects
--unhandled-rejections
--use-bundled-ca
--use-largepages
--use-openssl-ca
--use-system-ca
--v8-pool-size
--watch-path
--watch-preserve-output
--watch
--zero-fill-buffers


V8 options that are allowed are:


--abort-on-uncaught-exception
--disallow-code-generation-from-strings
--enable-etw-stack-walking
--expose-gc
--interpreted-frames-native-stack
--jitless
--max-old-space-size
--max-semi-space-size
--perf-basic-prof-only-functions
--perf-basic-prof
--perf-prof-unwinding-info
--perf-prof
--stack-trace-limit



--perf-basic-prof-only-functions, --perf-basic-prof,
--perf-prof-unwinding-info, and --perf-prof are only available on Linux.
--enable-etw-stack-walking is only available on Windows.


NODE_PATH=path[:…]#

Added in: v0.1.32

':'-separated list of directories prefixed to the module search path.
On Windows, this is a ';'-separated list instead.

NODE_PENDING_DEPRECATION=1#

Added in: v8.0.0

When set to 1, emit pending deprecation warnings.
Pending deprecations are generally identical to a runtime deprecation with the
notable exception that they are turned off by default and will not be emitted
unless either the --pending-deprecation command-line flag, or the
NODE_PENDING_DEPRECATION=1 environment variable, is set. Pending deprecations
are used to provide a kind of selective "early warning" mechanism that
developers may leverage to detect deprecated API usage.

NODE_PENDING_PIPE_INSTANCES=instances#
Set the number of pending pipe instance handles when the pipe server is waiting
for connections. This setting applies to Windows only.

NODE_PRESERVE_SYMLINKS=1#

Added in: v7.1.0

When set to 1, instructs the module loader to preserve symbolic links when
resolving and caching modules.

NODE_REDIRECT_WARNINGS=file#

Added in: v8.0.0

When set, process warnings will be emitted to the given file instead of
printing to stderr. The file will be created if it does not exist, and will be
appended to if it does. If an error occurs while attempting to write the
warning to the file, the warning will be written to stderr instead. This is
equivalent to using the --redirect-warnings=file command-line flag.

NODE_REPL_EXTERNAL_MODULE=file#

History

VersionChanges
v22.3.0, v20.16.0
Remove the possibility to use this env var with kDisableNodeOptionsEnv for embedders.
v13.0.0, v12.16.0
Added in: v13.0.0, v12.16.0



Path to a Node.js module which will be loaded in place of the built-in REPL.
Overriding this value to an empty string ('') will use the built-in REPL.

NODE_REPL_HISTORY=file#

Added in: v3.0.0

Path to the file used to store the persistent REPL history. The default path is
~/.node_repl_history, which is overridden by this variable. Setting the value
to an empty string ('' or ' ') disables persistent REPL history.

NODE_SKIP_PLATFORM_CHECK=value#

Added in: v14.5.0

If value equals '1', the check for a supported platform is skipped during
Node.js startup. Node.js might not execute correctly. Any issues encountered
on unsupported platforms will not be fixed.

NODE_TEST_CONTEXT=value#
If value equals 'child', test reporter options will be overridden and test
output will be sent to stdout in the TAP format. If any other value is provided,
Node.js makes no guarantees about the reporter format used or its stability.

NODE_TLS_REJECT_UNAUTHORIZED=value#
If value equals '0', certificate validation is disabled for TLS connections.
This makes TLS, and HTTPS by extension, insecure. The use of this environment
variable is strongly discouraged.

NODE_USE_ENV_PROXY=1#

Added in: v24.0.0

Stability: 1.1 - Active Development
When enabled, Node.js parses the HTTP_PROXY, HTTPS_PROXY and NO_PROXY
environment variables during startup, and tunnels requests over the
specified proxy.
This currently only affects requests sent over fetch(). Support for other
built-in http and https methods is under way.

NODE_V8_COVERAGE=dir#
When set, Node.js will begin outputting V8 JavaScript code coverage and
Source Map data to the directory provided as an argument (coverage
information is written as JSON to files with a coverage prefix).
NODE_V8_COVERAGE will automatically propagate to subprocesses, making it
easier to instrument applications that call the child_process.spawn() family
of functions. NODE_V8_COVERAGE can be set to an empty string, to prevent
propagation.

Coverage output#
Coverage is output as an array of ScriptCoverage objects on the top-level
key result:
{
  "result": [
    {
      "scriptId": "67",
      "url": "internal/tty.js",
      "functions": []
    }
  ]
} copy

Source map cache#
Stability: 1 - Experimental
If found, source map data is appended to the top-level key source-map-cache
on the JSON coverage object.
source-map-cache is an object with keys representing the files source maps
were extracted from, and values which include the raw source-map URL
(in the key url), the parsed Source Map v3 information (in the key data),
and the line lengths of the source file (in the key lineLengths).
{
  "result": [
    {
      "scriptId": "68",
      "url": "file:///absolute/path/to/source.js",
      "functions": []
    }
  ],
  "source-map-cache": {
    "file:///absolute/path/to/source.js": {
      "url": "./path-to-map.json",
      "data": {
        "version": 3,
        "sources": [
          "file:///absolute/path/to/original.js"
        ],
        "names": [
          "Foo",
          "console",
          "info"
        ],
        "mappings": "MAAMA,IACJC,YAAaC",
        "sourceRoot": "./"
      },
      "lineLengths": [
        13,
        62,
        38,
        27
      ]
    }
  }
} copy

NO_COLOR=<any>#
NO_COLOR  is an alias for NODE_DISABLE_COLORS. The value of the
environment variable is arbitrary.

OPENSSL_CONF=file#

Added in: v6.11.0

Load an OpenSSL configuration file on startup. Among other uses, this can be
used to enable FIPS-compliant crypto if Node.js is built with
./configure --openssl-fips.
If the --openssl-config command-line option is used, the environment
variable is ignored.

SSL_CERT_DIR=dir#

Added in: v7.7.0

If --use-openssl-ca is enabled, or if --use-system-ca is enabled on
platforms other than macOS and Windows, this overrides and sets OpenSSL's directory
containing trusted certificates.
Be aware that unless the child environment is explicitly set, this environment
variable will be inherited by any child processes, and if they use OpenSSL, it
may cause them to trust the same CAs as node.

SSL_CERT_FILE=file#

Added in: v7.7.0

If --use-openssl-ca is enabled, or if --use-system-ca is enabled on
platforms other than macOS and Windows, this overrides and sets OpenSSL's file
containing trusted certificates.
Be aware that unless the child environment is explicitly set, this environment
variable will be inherited by any child processes, and if they use OpenSSL, it
may cause them to trust the same CAs as node.

TZ#

History

VersionChanges
v16.2.0
Changing the TZ variable using process.env.TZ = changes the timezone on Windows as well.
v13.0.0
Changing the TZ variable using process.env.TZ = changes the timezone on POSIX systems.
v0.0.1
Added in: v0.0.1



The TZ environment variable is used to specify the timezone configuration.
While Node.js does not support all of the various ways that TZ is handled in
other environments, it does support basic timezone IDs (such as
'Etc/UTC', 'Europe/Paris', or 'America/New_York').
It may support a few other abbreviations or aliases, but these are strongly
discouraged and not guaranteed.
$ TZ=Europe/Dublin node -pe "new Date().toString()"
Wed May 12 2021 20:30:48 GMT+0100 (Irish Standard Time) copy

UV_THREADPOOL_SIZE=size#
Set the number of threads used in libuv's threadpool to size threads.
Asynchronous system APIs are used by Node.js whenever possible, but where they
do not exist, libuv's threadpool is used to create asynchronous node APIs based
on synchronous system APIs. Node.js APIs that use the threadpool are:

all fs APIs, other than the file watcher APIs and those that are explicitly
synchronous
asynchronous crypto APIs such as crypto.pbkdf2(), crypto.scrypt(),
crypto.randomBytes(), crypto.randomFill(), crypto.generateKeyPair()
dns.lookup()
all zlib APIs, other than those that are explicitly synchronous

Because libuv's threadpool has a fixed size, it means that if for whatever
reason any of these APIs takes a long time, other (seemingly unrelated) APIs
that run in libuv's threadpool will experience degraded performance. In order to
mitigate this issue, one potential solution is to increase the size of libuv's
threadpool by setting the 'UV_THREADPOOL_SIZE' environment variable to a value
greater than 4 (its current default value). However, setting this from inside
the process using process.env.UV_THREADPOOL_SIZE=size is not guranteed to work
as the threadpool would have been created as part of the runtime initialisation
much before user code is run. For more information, see the libuv threadpool documentation.

Useful V8 options#
V8 has its own set of CLI options. Any V8 CLI option that is provided to node
will be passed on to V8 to handle. V8's options have no stability guarantee.
The V8 team themselves don't consider them to be part of their formal API,
and reserve the right to change them at any time. Likewise, they are not
covered by the Node.js stability guarantees. Many of the V8
options are of interest only to V8 developers. Despite this, there is a small
set of V8 options that are widely applicable to Node.js, and they are
documented here:


--abort-on-uncaught-exception#

--disallow-code-generation-from-strings#

--enable-etw-stack-walking#

--expose-gc#

--harmony-shadow-realm#

--interpreted-frames-native-stack#

--jitless#



--max-old-space-size=SIZE (in MiB)#
Sets the max memory size of V8's old memory section. As memory
consumption approaches the limit, V8 will spend more time on
garbage collection in an effort to free unused memory.
On a machine with 2 GiB of memory, consider setting this to
1536 (1.5 GiB) to leave some memory for other uses and avoid swapping.
node --max-old-space-size=1536 index.js copy



--max-semi-space-size=SIZE (in MiB)#
Sets the maximum semi-space size for V8's scavenge garbage collector in
MiB (mebibytes).
Increasing the max size of a semi-space may improve throughput for Node.js at
the cost of more memory consumption.
Since the young generation size of the V8 heap is three times (see
YoungGenerationSizeFromSemiSpaceSize in V8) the size of the semi-space,
an increase of 1 MiB to semi-space applies to each of the three individual
semi-spaces and causes the heap size to increase by 3 MiB. The throughput
improvement depends on your workload (see #42511).
The default value depends on the memory limit. For example, on 64-bit systems
with a memory limit of 512 MiB, the max size of a semi-space defaults to 1 MiB.
For memory limits up to and including 2GiB, the default max size of a
semi-space will be less than 16 MiB on 64-bit systems.
To get the best configuration for your application, you should try different
max-semi-space-size values when running benchmarks for your application.
For example, benchmark on a 64-bit systems:
for MiB in 16 32 64 128; do
    node --max-semi-space-size=$MiB index.js
done copy

--perf-basic-prof#

--perf-basic-prof-only-functions#

--perf-prof#

--perf-prof-unwinding-info#

--prof#

--security-revert#

--stack-trace-limit=limit#
The maximum number of stack frames to collect in an error's stack trace.
Setting it to 0 disables stack trace collection. The default value is 10.
node --stack-trace-limit=12 -p -e "Error.stackTraceLimit" # prints 12 copy\n\n\n\nNode.js
        
      
      
About this documentation
Usage and example



Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Modules: TypeScript
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
Readline
REPL
Report
Single executable applications
SQLite
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker

    

    
      
        
          Node.js v24.0.1 documentation
          
            
            
          
        
        
          
            Node.js v24.0.1
            
    
      
        
        Table of contents
      

      
Console

Class: Console

new Console(stdout[, stderr][, ignoreErrors])
new Console(options)
console.assert(value[, ...message])
console.clear()
console.count([label])
console.countReset([label])
console.debug(data[, ...args])
console.dir(obj[, options])
console.dirxml(...data)
console.error([data][, ...args])
console.group([...label])
console.groupCollapsed()
console.groupEnd()
console.info([data][, ...args])
console.log([data][, ...args])
console.table(tabularData[, properties])
console.time([label])
console.timeEnd([label])
console.timeLog([label][, ...data])
console.trace([message][, ...args])
console.warn([data][, ...args])


Inspector only methods

console.profile([label])
console.profileEnd([label])
console.timeStamp([label])





    
  
            
    
      
        
        Index
      

      
About this documentation
Usage and example

      
        Index
      
    
  


Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Modules: TypeScript
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
Readline
REPL
Report
Single executable applications
SQLite
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker

    
  
            
    
      
        
        Other versions
      
      24.x
23.x
22.x LTS
21.x
20.x LTS
19.x
18.x
17.x
16.x
15.x
14.x
13.x
12.x
11.x
10.x
9.x
8.x
7.x
6.x
5.x
4.x
0.12.x
0.10.x
    
  
            
              
                
                Options
              
        
              
                
                  
                    View on single page
                  
                  
                    View as JSON
                  
                  Edit on GitHub    
                
              
            
          
        
        
      

      Table of contents
Console

Class: Console

new Console(stdout[, stderr][, ignoreErrors])
new Console(options)
console.assert(value[, ...message])
console.clear()
console.count([label])
console.countReset([label])
console.debug(data[, ...args])
console.dir(obj[, options])
console.dirxml(...data)
console.error([data][, ...args])
console.group([...label])
console.groupCollapsed()
console.groupEnd()
console.info([data][, ...args])
console.log([data][, ...args])
console.table(tabularData[, properties])
console.time([label])
console.timeEnd([label])
console.timeLog([label][, ...data])
console.trace([message][, ...args])
console.warn([data][, ...args])


Inspector only methods

console.profile([label])
console.profileEnd([label])
console.timeStamp([label])






      
        Console#

Stability: 2 - Stable
Source Code: lib/console.js
The node:console module provides a simple debugging console that is similar to
the JavaScript console mechanism provided by web browsers.
The module exports two specific components:

A Console class with methods such as console.log(), console.error(), and
console.warn() that can be used to write to any Node.js stream.
A global console instance configured to write to process.stdout and
process.stderr. The global console can be used without calling
require('node:console').

Warning: The global console object's methods are neither consistently
synchronous like the browser APIs they resemble, nor are they consistently
asynchronous like all other Node.js streams. Programs that desire to depend
on the synchronous / asynchronous behavior of the console functions should
first figure out the nature of console's backing stream. This is because the
stream is dependent on the underlying platform and standard stream
configuration of the current process. See the note on process I/O for
more information.
Example using the global console:
console.log('hello world');
// Prints: hello world, to stdout
console.log('hello %s', 'world');
// Prints: hello world, to stdout
console.error(new Error('Whoops, something bad happened'));
// Prints error message and stack trace to stderr:
//   Error: Whoops, something bad happened
//     at [eval]:5:15
//     at Script.runInThisContext (node:vm:132:18)
//     at Object.runInThisContext (node:vm:309:38)
//     at node:internal/process/execution:77:19
//     at [eval]-wrapper:6:22
//     at evalScript (node:internal/process/execution:76:60)
//     at node:internal/main/eval_string:23:3

const name = 'Will Robinson';
console.warn(`Danger ${name}! Danger!`);
// Prints: Danger Will Robinson! Danger!, to stderr copy
Example using the Console class:
const out = getStreamSomehow();
const err = getStreamSomehow();
const myConsole = new console.Console(out, err);

myConsole.log('hello world');
// Prints: hello world, to out
myConsole.log('hello %s', 'world');
// Prints: hello world, to out
myConsole.error(new Error('Whoops, something bad happened'));
// Prints: [Error: Whoops, something bad happened], to err

const name = 'Will Robinson';
myConsole.warn(`Danger ${name}! Danger!`);
// Prints: Danger Will Robinson! Danger!, to err copy
Class: Console#

History

VersionChanges
v8.0.0
Errors that occur while writing to the underlying streams will now be ignored by default.




The Console class can be used to create a simple logger with configurable
output streams and can be accessed using either require('node:console').Console
or console.Console (or their destructured counterparts):

import { Console } from 'node:console';const { Console } = require('node:console');copy
const { Console } = console; copy

new Console(stdout[, stderr][, ignoreErrors])#

new Console(options)#

History

VersionChanges
v14.2.0, v12.17.0
The groupIndentation option was introduced.
v11.7.0
The inspectOptions option is introduced.
v10.0.0
The Console constructor now supports an options argument, and the colorMode option was introduced.
v8.0.0
The ignoreErrors option was introduced.




options <Object>

stdout <stream.Writable>
stderr <stream.Writable>
ignoreErrors <boolean> Ignore errors when writing to the underlying
streams. Default: true.
colorMode <boolean> | <string> Set color support for this Console instance.
Setting to true enables coloring while inspecting values. Setting to
false disables coloring while inspecting values. Setting to
'auto' makes color support depend on the value of the isTTY property
and the value returned by getColorDepth() on the respective stream. This
option can not be used, if inspectOptions.colors is set as well.
Default: 'auto'.
inspectOptions <Object> Specifies options that are passed along to
util.inspect().
groupIndentation <number> Set group indentation.
Default: 2.



Creates a new Console with one or two writable stream instances. stdout is a
writable stream to print log or info output. stderr is used for warning or
error output. If stderr is not provided, stdout is used for stderr.

import { createWriteStream } from 'node:fs';
import { Console } from 'node:console';
// Alternatively
// const { Console } = console;

const output = createWriteStream('./stdout.log');
const errorOutput = createWriteStream('./stderr.log');
// Custom simple logger
const logger = new Console({ stdout: output, stderr: errorOutput });
// use it like console
const count = 5;
logger.log('count: %d', count);
// In stdout.log: count 5const fs = require('node:fs');
const { Console } = require('node:console');
// Alternatively
// const { Console } = console;

const output = fs.createWriteStream('./stdout.log');
const errorOutput = fs.createWriteStream('./stderr.log');
// Custom simple logger
const logger = new Console({ stdout: output, stderr: errorOutput });
// use it like console
const count = 5;
logger.log('count: %d', count);
// In stdout.log: count 5copy
The global console is a special Console whose output is sent to
process.stdout and process.stderr. It is equivalent to calling:
new Console({ stdout: process.stdout, stderr: process.stderr }); copy

console.assert(value[, ...message])#

History

VersionChanges
v10.0.0
The implementation is now spec compliant and does not throw anymore.
v0.1.101
Added in: v0.1.101




value <any> The value tested for being truthy.
...message <any> All arguments besides value are used as error message.

console.assert() writes a message if value is falsy or omitted. It only
writes a message and does not otherwise affect execution. The output always
starts with "Assertion failed". If provided, message is formatted using
util.format().
If value is truthy, nothing happens.
console.assert(true, 'does nothing');

console.assert(false, 'Whoops %s work', 'didn\'t');
// Assertion failed: Whoops didn't work

console.assert();
// Assertion failed copy

console.clear()#

Added in: v8.3.0

When stdout is a TTY, calling console.clear() will attempt to clear the
TTY. When stdout is not a TTY, this method does nothing.
The specific operation of console.clear() can vary across operating systems
and terminal types. For most Linux operating systems, console.clear()
operates similarly to the clear shell command. On Windows, console.clear()
will clear only the output in the current terminal viewport for the Node.js
binary.

console.count([label])#

Added in: v8.3.0


label <string> The display label for the counter. Default: 'default'.

Maintains an internal counter specific to label and outputs to stdout the
number of times console.count() has been called with the given label.

> console.count()
default: 1
undefined
> console.count('default')
default: 2
undefined
> console.count('abc')
abc: 1
undefined
> console.count('xyz')
xyz: 1
undefined
> console.count('abc')
abc: 2
undefined
> console.count()
default: 3
undefined
> copy

console.countReset([label])#

Added in: v8.3.0


label <string> The display label for the counter. Default: 'default'.

Resets the internal counter specific to label.

> console.count('abc');
abc: 1
undefined
> console.countReset('abc');
undefined
> console.count('abc');
abc: 1
undefined
> copy

console.debug(data[, ...args])#

History

VersionChanges
v8.10.0
console.debug is now an alias for console.log.
v8.0.0
Added in: v8.0.0




data <any>
...args <any>

The console.debug() function is an alias for console.log().

console.dir(obj[, options])#

Added in: v0.1.101


obj <any>
options <Object>

showHidden <boolean> If true then the object's non-enumerable and symbol
properties will be shown too. Default: false.
depth <number> Tells util.inspect() how many times to recurse while
formatting the object. This is useful for inspecting large complicated
objects. To make it recurse indefinitely, pass null. Default: 2.
colors <boolean> If true, then the output will be styled with ANSI color
codes. Colors are customizable;
see customizing util.inspect() colors. Default: false.



Uses util.inspect() on obj and prints the resulting string to stdout.
This function bypasses any custom inspect() function defined on obj.

console.dirxml(...data)#

History

VersionChanges
v9.3.0
console.dirxml now calls console.log for its arguments.
v8.0.0
Added in: v8.0.0




...data <any>

This method calls console.log() passing it the arguments received.
This method does not produce any XML formatting.

console.error([data][, ...args])#

Added in: v0.1.100


data <any>
...args <any>

Prints to stderr with newline. Multiple arguments can be passed, with the
first used as the primary message and all additional used as substitution
values similar to printf(3) (the arguments are all passed to
util.format()).
const code = 5;
console.error('error #%d', code);
// Prints: error #5, to stderr
console.error('error', code);
// Prints: error 5, to stderr copy
If formatting elements (e.g. %d) are not found in the first string then
util.inspect() is called on each argument and the resulting string
values are concatenated. See util.format() for more information.

console.group([...label])#

Added in: v8.5.0


...label <any>

Increases indentation of subsequent lines by spaces for groupIndentation
length.
If one or more labels are provided, those are printed first without the
additional indentation.

console.groupCollapsed()#

Added in: v8.5.0

An alias for console.group().

console.groupEnd()#

Added in: v8.5.0

Decreases indentation of subsequent lines by spaces for groupIndentation
length.

console.info([data][, ...args])#

Added in: v0.1.100


data <any>
...args <any>

The console.info() function is an alias for console.log().

console.log([data][, ...args])#

Added in: v0.1.100


data <any>
...args <any>

Prints to stdout with newline. Multiple arguments can be passed, with the
first used as the primary message and all additional used as substitution
values similar to printf(3) (the arguments are all passed to
util.format()).
const count = 5;
console.log('count: %d', count);
// Prints: count: 5, to stdout
console.log('count:', count);
// Prints: count: 5, to stdout copy
See util.format() for more information.

console.table(tabularData[, properties])#

Added in: v10.0.0


tabularData <any>
properties <string[]> Alternate properties for constructing the table.

Try to construct a table with the columns of the properties of tabularData
(or use properties) and rows of tabularData and log it. Falls back to just
logging the argument if it can't be parsed as tabular.
// These can't be parsed as tabular data
console.table(Symbol());
// Symbol()

console.table(undefined);
// undefined

console.table([{ a: 1, b: 'Y' }, { a: 'Z', b: 2 }]);
// ┌─────────┬─────┬─────┐
// │ (index) │ a   │ b   │
// ├─────────┼─────┼─────┤
// │ 0       │ 1   │ 'Y' │
// │ 1       │ 'Z' │ 2   │
// └─────────┴─────┴─────┘

console.table([{ a: 1, b: 'Y' }, { a: 'Z', b: 2 }], ['a']);
// ┌─────────┬─────┐
// │ (index) │ a   │
// ├─────────┼─────┤
// │ 0       │ 1   │
// │ 1       │ 'Z' │
// └─────────┴─────┘ copy

console.time([label])#

Added in: v0.1.104


label <string> Default: 'default'

Starts a timer that can be used to compute the duration of an operation. Timers
are identified by a unique label. Use the same label when calling
console.timeEnd() to stop the timer and output the elapsed time in
suitable time units to stdout. For example, if the elapsed
time is 3869ms, console.timeEnd() displays "3.869s".

console.timeEnd([label])#

History

VersionChanges
v13.0.0
The elapsed time is displayed with a suitable time unit.
v6.0.0
This method no longer supports multiple calls that don't map to individual console.time() calls; see below for details.
v0.1.104
Added in: v0.1.104




label <string> Default: 'default'

Stops a timer that was previously started by calling console.time() and
prints the result to stdout:
console.time('bunch-of-stuff');
// Do a bunch of stuff.
console.timeEnd('bunch-of-stuff');
// Prints: bunch-of-stuff: 225.438ms copy

console.timeLog([label][, ...data])#

Added in: v10.7.0


label <string> Default: 'default'
...data <any>

For a timer that was previously started by calling console.time(), prints
the elapsed time and other data arguments to stdout:
console.time('process');
const value = expensiveProcess1(); // Returns 42
console.timeLog('process', value);
// Prints "process: 365.227ms 42".
doExpensiveProcess2(value);
console.timeEnd('process'); copy

console.trace([message][, ...args])#

Added in: v0.1.104


message <any>
...args <any>

Prints to stderr the string 'Trace: ', followed by the util.format()
formatted message and stack trace to the current position in the code.
console.trace('Show me');
// Prints: (stack trace will vary based on where trace is called)
//  Trace: Show me
//    at repl:2:9
//    at REPLServer.defaultEval (repl.js:248:27)
//    at bound (domain.js:287:14)
//    at REPLServer.runBound [as eval] (domain.js:300:12)
//    at REPLServer.<anonymous> (repl.js:412:12)
//    at emitOne (events.js:82:20)
//    at REPLServer.emit (events.js:169:7)
//    at REPLServer.Interface._onLine (readline.js:210:10)
//    at REPLServer.Interface._line (readline.js:549:8)
//    at REPLServer.Interface._ttyWrite (readline.js:826:14) copy

console.warn([data][, ...args])#

Added in: v0.1.100


data <any>
...args <any>

The console.warn() function is an alias for console.error().

Inspector only methods#
The following methods are exposed by the V8 engine in the general API but do
not display anything unless used in conjunction with the inspector
(--inspect flag).

console.profile([label])#

Added in: v8.0.0


label <string>

This method does not display anything unless used in the inspector. The
console.profile() method starts a JavaScript CPU profile with an optional
label until console.profileEnd() is called. The profile is then added to
the Profile panel of the inspector.
console.profile('MyLabel');
// Some code
console.profileEnd('MyLabel');
// Adds the profile 'MyLabel' to the Profiles panel of the inspector. copy

console.profileEnd([label])#

Added in: v8.0.0


label <string>

This method does not display anything unless used in the inspector. Stops the
current JavaScript CPU profiling session if one has been started and prints
the report to the Profiles panel of the inspector. See
console.profile() for an example.
If this method is called without a label, the most recently started profile is
stopped.

console.timeStamp([label])#

Added in: v8.0.0


label <string>

This method does not display anything unless used in the inspector. The
console.timeStamp() method adds an event with the label 'label' to the
Timeline panel of the inspector.\n\n\n\nNode.js
        
      
      
About this documentation
Usage and example



Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Modules: TypeScript
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
Readline
REPL
Report
Single executable applications
SQLite
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker

    

    
      
        
          Node.js v24.0.1 documentation
          
            
            
          
        
        
          
            Node.js v24.0.1
            
    
      
        
        Table of contents
      

      
Crypto

Determining if crypto support is unavailable
Class: Certificate

Static method: Certificate.exportChallenge(spkac[, encoding])
Static method: Certificate.exportPublicKey(spkac[, encoding])
Static method: Certificate.verifySpkac(spkac[, encoding])
Legacy API

new crypto.Certificate()
certificate.exportChallenge(spkac[, encoding])
certificate.exportPublicKey(spkac[, encoding])
certificate.verifySpkac(spkac[, encoding])




Class: Cipheriv

cipher.final([outputEncoding])
cipher.getAuthTag()
cipher.setAAD(buffer[, options])
cipher.setAutoPadding([autoPadding])
cipher.update(data[, inputEncoding][, outputEncoding])


Class: Decipheriv

decipher.final([outputEncoding])
decipher.setAAD(buffer[, options])
decipher.setAuthTag(buffer[, encoding])
decipher.setAutoPadding([autoPadding])
decipher.update(data[, inputEncoding][, outputEncoding])


Class: DiffieHellman

diffieHellman.computeSecret(otherPublicKey[, inputEncoding][, outputEncoding])
diffieHellman.generateKeys([encoding])
diffieHellman.getGenerator([encoding])
diffieHellman.getPrime([encoding])
diffieHellman.getPrivateKey([encoding])
diffieHellman.getPublicKey([encoding])
diffieHellman.setPrivateKey(privateKey[, encoding])
diffieHellman.setPublicKey(publicKey[, encoding])
diffieHellman.verifyError


Class: DiffieHellmanGroup
Class: ECDH

Static method: ECDH.convertKey(key, curve[, inputEncoding[, outputEncoding[, format]]])
ecdh.computeSecret(otherPublicKey[, inputEncoding][, outputEncoding])
ecdh.generateKeys([encoding[, format]])
ecdh.getPrivateKey([encoding])
ecdh.getPublicKey([encoding][, format])
ecdh.setPrivateKey(privateKey[, encoding])
ecdh.setPublicKey(publicKey[, encoding])


Class: Hash

hash.copy([options])
hash.digest([encoding])
hash.update(data[, inputEncoding])


Class: Hmac

hmac.digest([encoding])
hmac.update(data[, inputEncoding])


Class: KeyObject

Static method: KeyObject.from(key)
keyObject.asymmetricKeyDetails
keyObject.asymmetricKeyType
keyObject.equals(otherKeyObject)
keyObject.export([options])
keyObject.symmetricKeySize
keyObject.toCryptoKey(algorithm, extractable, keyUsages)
keyObject.type


Class: Sign

sign.sign(privateKey[, outputEncoding])
sign.update(data[, inputEncoding])


Class: Verify

verify.update(data[, inputEncoding])
verify.verify(object, signature[, signatureEncoding])


Class: X509Certificate

new X509Certificate(buffer)
x509.ca
x509.checkEmail(email[, options])
x509.checkHost(name[, options])
x509.checkIP(ip)
x509.checkIssued(otherCert)
x509.checkPrivateKey(privateKey)
x509.extKeyUsage
x509.fingerprint
x509.fingerprint256
x509.fingerprint512
x509.infoAccess
x509.issuer
x509.issuerCertificate
x509.publicKey
x509.raw
x509.serialNumber
x509.subject
x509.subjectAltName
x509.toJSON()
x509.toLegacyObject()
x509.toString()
x509.validFrom
x509.validFromDate
x509.validTo
x509.validToDate
x509.verify(publicKey)


node:crypto module methods and properties

crypto.checkPrime(candidate[, options], callback)
crypto.checkPrimeSync(candidate[, options])
crypto.constants
crypto.createCipheriv(algorithm, key, iv[, options])
crypto.createDecipheriv(algorithm, key, iv[, options])
crypto.createDiffieHellman(prime[, primeEncoding][, generator][, generatorEncoding])
crypto.createDiffieHellman(primeLength[, generator])
crypto.createDiffieHellmanGroup(name)
crypto.createECDH(curveName)
crypto.createHash(algorithm[, options])
crypto.createHmac(algorithm, key[, options])
crypto.createPrivateKey(key)
crypto.createPublicKey(key)
crypto.createSecretKey(key[, encoding])
crypto.createSign(algorithm[, options])
crypto.createVerify(algorithm[, options])
crypto.diffieHellman(options[, callback])
crypto.fips
crypto.generateKey(type, options, callback)
crypto.generateKeyPair(type, options, callback)
crypto.generateKeyPairSync(type, options)
crypto.generateKeySync(type, options)
crypto.generatePrime(size[, options[, callback]])
crypto.generatePrimeSync(size[, options])
crypto.getCipherInfo(nameOrNid[, options])
crypto.getCiphers()
crypto.getCurves()
crypto.getDiffieHellman(groupName)
crypto.getFips()
crypto.getHashes()
crypto.getRandomValues(typedArray)
crypto.hash(algorithm, data[, outputEncoding])
crypto.hkdf(digest, ikm, salt, info, keylen, callback)
crypto.hkdfSync(digest, ikm, salt, info, keylen)
crypto.pbkdf2(password, salt, iterations, keylen, digest, callback)
crypto.pbkdf2Sync(password, salt, iterations, keylen, digest)
crypto.privateDecrypt(privateKey, buffer)
crypto.privateEncrypt(privateKey, buffer)
crypto.publicDecrypt(key, buffer)
crypto.publicEncrypt(key, buffer)
crypto.randomBytes(size[, callback])
crypto.randomFill(buffer[, offset][, size], callback)
crypto.randomFillSync(buffer[, offset][, size])
crypto.randomInt([min, ]max[, callback])
crypto.randomUUID([options])
crypto.scrypt(password, salt, keylen[, options], callback)
crypto.scryptSync(password, salt, keylen[, options])
crypto.secureHeapUsed()
crypto.setEngine(engine[, flags])
crypto.setFips(bool)
crypto.sign(algorithm, data, key[, callback])
crypto.subtle
crypto.timingSafeEqual(a, b)
crypto.verify(algorithm, data, key, signature[, callback])
crypto.webcrypto


Notes

Using strings as inputs to cryptographic APIs
Legacy streams API (prior to Node.js 0.10)
Support for weak or compromised algorithms
CCM mode
FIPS mode


Crypto constants

OpenSSL options
OpenSSL engine constants
Other OpenSSL constants
Node.js crypto constants





    
  
            
    
      
        
        Index
      

      
About this documentation
Usage and example

      
        Index
      
    
  


Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Modules: TypeScript
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
Readline
REPL
Report
Single executable applications
SQLite
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker

    
  
            
    
      
        
        Other versions
      
      24.x
23.x
22.x LTS
21.x
20.x LTS
19.x
18.x
17.x
16.x
15.x
14.x
13.x
12.x
11.x
10.x
9.x
8.x
7.x
6.x
5.x
4.x
0.12.x
0.10.x
    
  
            
              
                
                Options
              
        
              
                
                  
                    View on single page
                  
                  
                    View as JSON
                  
                  Edit on GitHub    
                
              
            
          
        
        
      

      Table of contents
Crypto

Determining if crypto support is unavailable
Class: Certificate

Static method: Certificate.exportChallenge(spkac[, encoding])
Static method: Certificate.exportPublicKey(spkac[, encoding])
Static method: Certificate.verifySpkac(spkac[, encoding])
Legacy API

new crypto.Certificate()
certificate.exportChallenge(spkac[, encoding])
certificate.exportPublicKey(spkac[, encoding])
certificate.verifySpkac(spkac[, encoding])




Class: Cipheriv

cipher.final([outputEncoding])
cipher.getAuthTag()
cipher.setAAD(buffer[, options])
cipher.setAutoPadding([autoPadding])
cipher.update(data[, inputEncoding][, outputEncoding])


Class: Decipheriv

decipher.final([outputEncoding])
decipher.setAAD(buffer[, options])
decipher.setAuthTag(buffer[, encoding])
decipher.setAutoPadding([autoPadding])
decipher.update(data[, inputEncoding][, outputEncoding])


Class: DiffieHellman

diffieHellman.computeSecret(otherPublicKey[, inputEncoding][, outputEncoding])
diffieHellman.generateKeys([encoding])
diffieHellman.getGenerator([encoding])
diffieHellman.getPrime([encoding])
diffieHellman.getPrivateKey([encoding])
diffieHellman.getPublicKey([encoding])
diffieHellman.setPrivateKey(privateKey[, encoding])
diffieHellman.setPublicKey(publicKey[, encoding])
diffieHellman.verifyError


Class: DiffieHellmanGroup
Class: ECDH

Static method: ECDH.convertKey(key, curve[, inputEncoding[, outputEncoding[, format]]])
ecdh.computeSecret(otherPublicKey[, inputEncoding][, outputEncoding])
ecdh.generateKeys([encoding[, format]])
ecdh.getPrivateKey([encoding])
ecdh.getPublicKey([encoding][, format])
ecdh.setPrivateKey(privateKey[, encoding])
ecdh.setPublicKey(publicKey[, encoding])


Class: Hash

hash.copy([options])
hash.digest([encoding])
hash.update(data[, inputEncoding])


Class: Hmac

hmac.digest([encoding])
hmac.update(data[, inputEncoding])


Class: KeyObject

Static method: KeyObject.from(key)
keyObject.asymmetricKeyDetails
keyObject.asymmetricKeyType
keyObject.equals(otherKeyObject)
keyObject.export([options])
keyObject.symmetricKeySize
keyObject.toCryptoKey(algorithm, extractable, keyUsages)
keyObject.type


Class: Sign

sign.sign(privateKey[, outputEncoding])
sign.update(data[, inputEncoding])


Class: Verify

verify.update(data[, inputEncoding])
verify.verify(object, signature[, signatureEncoding])


Class: X509Certificate

new X509Certificate(buffer)
x509.ca
x509.checkEmail(email[, options])
x509.checkHost(name[, options])
x509.checkIP(ip)
x509.checkIssued(otherCert)
x509.checkPrivateKey(privateKey)
x509.extKeyUsage
x509.fingerprint
x509.fingerprint256
x509.fingerprint512
x509.infoAccess
x509.issuer
x509.issuerCertificate
x509.publicKey
x509.raw
x509.serialNumber
x509.subject
x509.subjectAltName
x509.toJSON()
x509.toLegacyObject()
x509.toString()
x509.validFrom
x509.validFromDate
x509.validTo
x509.validToDate
x509.verify(publicKey)


node:crypto module methods and properties

crypto.checkPrime(candidate[, options], callback)
crypto.checkPrimeSync(candidate[, options])
crypto.constants
crypto.createCipheriv(algorithm, key, iv[, options])
crypto.createDecipheriv(algorithm, key, iv[, options])
crypto.createDiffieHellman(prime[, primeEncoding][, generator][, generatorEncoding])
crypto.createDiffieHellman(primeLength[, generator])
crypto.createDiffieHellmanGroup(name)
crypto.createECDH(curveName)
crypto.createHash(algorithm[, options])
crypto.createHmac(algorithm, key[, options])
crypto.createPrivateKey(key)
crypto.createPublicKey(key)
crypto.createSecretKey(key[, encoding])
crypto.createSign(algorithm[, options])
crypto.createVerify(algorithm[, options])
crypto.diffieHellman(options[, callback])
crypto.fips
crypto.generateKey(type, options, callback)
crypto.generateKeyPair(type, options, callback)
crypto.generateKeyPairSync(type, options)
crypto.generateKeySync(type, options)
crypto.generatePrime(size[, options[, callback]])
crypto.generatePrimeSync(size[, options])
crypto.getCipherInfo(nameOrNid[, options])
crypto.getCiphers()
crypto.getCurves()
crypto.getDiffieHellman(groupName)
crypto.getFips()
crypto.getHashes()
crypto.getRandomValues(typedArray)
crypto.hash(algorithm, data[, outputEncoding])
crypto.hkdf(digest, ikm, salt, info, keylen, callback)
crypto.hkdfSync(digest, ikm, salt, info, keylen)
crypto.pbkdf2(password, salt, iterations, keylen, digest, callback)
crypto.pbkdf2Sync(password, salt, iterations, keylen, digest)
crypto.privateDecrypt(privateKey, buffer)
crypto.privateEncrypt(privateKey, buffer)
crypto.publicDecrypt(key, buffer)
crypto.publicEncrypt(key, buffer)
crypto.randomBytes(size[, callback])
crypto.randomFill(buffer[, offset][, size], callback)
crypto.randomFillSync(buffer[, offset][, size])
crypto.randomInt([min, ]max[, callback])
crypto.randomUUID([options])
crypto.scrypt(password, salt, keylen[, options], callback)
crypto.scryptSync(password, salt, keylen[, options])
crypto.secureHeapUsed()
crypto.setEngine(engine[, flags])
crypto.setFips(bool)
crypto.sign(algorithm, data, key[, callback])
crypto.subtle
crypto.timingSafeEqual(a, b)
crypto.verify(algorithm, data, key, signature[, callback])
crypto.webcrypto


Notes

Using strings as inputs to cryptographic APIs
Legacy streams API (prior to Node.js 0.10)
Support for weak or compromised algorithms
CCM mode
FIPS mode


Crypto constants

OpenSSL options
OpenSSL engine constants
Other OpenSSL constants
Node.js crypto constants






      
        Crypto#

Stability: 2 - Stable
Source Code: lib/crypto.js
The node:crypto module provides cryptographic functionality that includes a
set of wrappers for OpenSSL's hash, HMAC, cipher, decipher, sign, and verify
functions.

const { createHmac } = await import('node:crypto');

const secret = 'abcdefg';
const hash = createHmac('sha256', secret)
               .update('I love cupcakes')
               .digest('hex');
console.log(hash);
// Prints:
//   c0fa1bc00531bd78ef38c628449c5102aeabd49b5dc3a2a516ea6ea959d6658econst { createHmac } = require('node:crypto');

const secret = 'abcdefg';
const hash = createHmac('sha256', secret)
               .update('I love cupcakes')
               .digest('hex');
console.log(hash);
// Prints:
//   c0fa1bc00531bd78ef38c628449c5102aeabd49b5dc3a2a516ea6ea959d6658ecopy
Determining if crypto support is unavailable#
It is possible for Node.js to be built without including support for the
node:crypto module. In such cases, attempting to import from crypto or
calling require('node:crypto') will result in an error being thrown.
When using CommonJS, the error thrown can be caught using try/catch:

let crypto;
try {
  crypto = require('node:crypto');
} catch (err) {
  console.error('crypto support is disabled!');
} copy

When using the lexical ESM import keyword, the error can only be
caught if a handler for process.on('uncaughtException') is registered
before any attempt to load the module is made (using, for instance,
a preload module).
When using ESM, if there is a chance that the code may be run on a build
of Node.js where crypto support is not enabled, consider using the
import() function instead of the lexical import keyword:
let crypto;
try {
  crypto = await import('node:crypto');
} catch (err) {
  console.error('crypto support is disabled!');
} copy
Class: Certificate#

Added in: v0.11.8

SPKAC is a Certificate Signing Request mechanism originally implemented by
Netscape and was specified formally as part of HTML5's keygen element.
<keygen> is deprecated since HTML 5.2 and new projects
should not use this element anymore.
The node:crypto module provides the Certificate class for working with SPKAC
data. The most common usage is handling output generated by the HTML5
<keygen> element. Node.js uses OpenSSL's SPKAC implementation internally.

Static method: Certificate.exportChallenge(spkac[, encoding])#

History

VersionChanges
v15.0.0
The spkac argument can be an ArrayBuffer. Limited the size of the spkac argument to a maximum of 2**31 - 1 bytes.
v9.0.0
Added in: v9.0.0




spkac <string> | <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView>
encoding <string> The encoding of the spkac string.
Returns: <Buffer> The challenge component of the spkac data structure, which
includes a public key and a challenge.


const { Certificate } = await import('node:crypto');
const spkac = getSpkacSomehow();
const challenge = Certificate.exportChallenge(spkac);
console.log(challenge.toString('utf8'));
// Prints: the challenge as a UTF8 stringconst { Certificate } = require('node:crypto');
const spkac = getSpkacSomehow();
const challenge = Certificate.exportChallenge(spkac);
console.log(challenge.toString('utf8'));
// Prints: the challenge as a UTF8 stringcopy

Static method: Certificate.exportPublicKey(spkac[, encoding])#

History

VersionChanges
v15.0.0
The spkac argument can be an ArrayBuffer. Limited the size of the spkac argument to a maximum of 2**31 - 1 bytes.
v9.0.0
Added in: v9.0.0




spkac <string> | <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView>
encoding <string> The encoding of the spkac string.
Returns: <Buffer> The public key component of the spkac data structure,
which includes a public key and a challenge.


const { Certificate } = await import('node:crypto');
const spkac = getSpkacSomehow();
const publicKey = Certificate.exportPublicKey(spkac);
console.log(publicKey);
// Prints: the public key as <Buffer ...>const { Certificate } = require('node:crypto');
const spkac = getSpkacSomehow();
const publicKey = Certificate.exportPublicKey(spkac);
console.log(publicKey);
// Prints: the public key as <Buffer ...>copy

Static method: Certificate.verifySpkac(spkac[, encoding])#

History

VersionChanges
v15.0.0
The spkac argument can be an ArrayBuffer. Added encoding. Limited the size of the spkac argument to a maximum of 2**31 - 1 bytes.
v9.0.0
Added in: v9.0.0




spkac <string> | <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView>
encoding <string> The encoding of the spkac string.
Returns: <boolean> true if the given spkac data structure is valid,
false otherwise.


import { Buffer } from 'node:buffer';
const { Certificate } = await import('node:crypto');

const spkac = getSpkacSomehow();
console.log(Certificate.verifySpkac(Buffer.from(spkac)));
// Prints: true or falseconst { Buffer } = require('node:buffer');
const { Certificate } = require('node:crypto');

const spkac = getSpkacSomehow();
console.log(Certificate.verifySpkac(Buffer.from(spkac)));
// Prints: true or falsecopy

Legacy API#
Stability: 0 - Deprecated
As a legacy interface, it is possible to create new instances of
the crypto.Certificate class as illustrated in the examples below.

new crypto.Certificate()#
Instances of the Certificate class can be created using the new keyword
or by calling crypto.Certificate() as a function:

const { Certificate } = await import('node:crypto');

const cert1 = new Certificate();
const cert2 = Certificate();const { Certificate } = require('node:crypto');

const cert1 = new Certificate();
const cert2 = Certificate();copy

certificate.exportChallenge(spkac[, encoding])#

Added in: v0.11.8


spkac <string> | <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView>
encoding <string> The encoding of the spkac string.
Returns: <Buffer> The challenge component of the spkac data structure, which
includes a public key and a challenge.


const { Certificate } = await import('node:crypto');
const cert = Certificate();
const spkac = getSpkacSomehow();
const challenge = cert.exportChallenge(spkac);
console.log(challenge.toString('utf8'));
// Prints: the challenge as a UTF8 stringconst { Certificate } = require('node:crypto');
const cert = Certificate();
const spkac = getSpkacSomehow();
const challenge = cert.exportChallenge(spkac);
console.log(challenge.toString('utf8'));
// Prints: the challenge as a UTF8 stringcopy

certificate.exportPublicKey(spkac[, encoding])#

Added in: v0.11.8


spkac <string> | <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView>
encoding <string> The encoding of the spkac string.
Returns: <Buffer> The public key component of the spkac data structure,
which includes a public key and a challenge.


const { Certificate } = await import('node:crypto');
const cert = Certificate();
const spkac = getSpkacSomehow();
const publicKey = cert.exportPublicKey(spkac);
console.log(publicKey);
// Prints: the public key as <Buffer ...>const { Certificate } = require('node:crypto');
const cert = Certificate();
const spkac = getSpkacSomehow();
const publicKey = cert.exportPublicKey(spkac);
console.log(publicKey);
// Prints: the public key as <Buffer ...>copy

certificate.verifySpkac(spkac[, encoding])#

Added in: v0.11.8


spkac <string> | <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView>
encoding <string> The encoding of the spkac string.
Returns: <boolean> true if the given spkac data structure is valid,
false otherwise.


import { Buffer } from 'node:buffer';
const { Certificate } = await import('node:crypto');

const cert = Certificate();
const spkac = getSpkacSomehow();
console.log(cert.verifySpkac(Buffer.from(spkac)));
// Prints: true or falseconst { Buffer } = require('node:buffer');
const { Certificate } = require('node:crypto');

const cert = Certificate();
const spkac = getSpkacSomehow();
console.log(cert.verifySpkac(Buffer.from(spkac)));
// Prints: true or falsecopy

Class: Cipheriv#

Added in: v0.1.94


Extends: <stream.Transform>

Instances of the Cipheriv class are used to encrypt data. The class can be
used in one of two ways:

As a stream that is both readable and writable, where plain unencrypted
data is written to produce encrypted data on the readable side, or
Using the cipher.update() and cipher.final() methods to produce
the encrypted data.

The crypto.createCipheriv() method is
used to create Cipheriv instances. Cipheriv objects are not to be created
directly using the new keyword.
Example: Using Cipheriv objects as streams:

const {
  scrypt,
  randomFill,
  createCipheriv,
} = await import('node:crypto');

const algorithm = 'aes-192-cbc';
const password = 'Password used to generate key';

// First, we'll generate the key. The key length is dependent on the algorithm.
// In this case for aes192, it is 24 bytes (192 bits).
scrypt(password, 'salt', 24, (err, key) => {
  if (err) throw err;
  // Then, we'll generate a random initialization vector
  randomFill(new Uint8Array(16), (err, iv) => {
    if (err) throw err;

    // Once we have the key and iv, we can create and use the cipher...
    const cipher = createCipheriv(algorithm, key, iv);

    let encrypted = '';
    cipher.setEncoding('hex');

    cipher.on('data', (chunk) => encrypted += chunk);
    cipher.on('end', () => console.log(encrypted));

    cipher.write('some clear text data');
    cipher.end();
  });
});const {
  scrypt,
  randomFill,
  createCipheriv,
} = require('node:crypto');

const algorithm = 'aes-192-cbc';
const password = 'Password used to generate key';

// First, we'll generate the key. The key length is dependent on the algorithm.
// In this case for aes192, it is 24 bytes (192 bits).
scrypt(password, 'salt', 24, (err, key) => {
  if (err) throw err;
  // Then, we'll generate a random initialization vector
  randomFill(new Uint8Array(16), (err, iv) => {
    if (err) throw err;

    // Once we have the key and iv, we can create and use the cipher...
    const cipher = createCipheriv(algorithm, key, iv);

    let encrypted = '';
    cipher.setEncoding('hex');

    cipher.on('data', (chunk) => encrypted += chunk);
    cipher.on('end', () => console.log(encrypted));

    cipher.write('some clear text data');
    cipher.end();
  });
});copy
Example: Using Cipheriv and piped streams:

import {
  createReadStream,
  createWriteStream,
} from 'node:fs';

import {
  pipeline,
} from 'node:stream';

const {
  scrypt,
  randomFill,
  createCipheriv,
} = await import('node:crypto');

const algorithm = 'aes-192-cbc';
const password = 'Password used to generate key';

// First, we'll generate the key. The key length is dependent on the algorithm.
// In this case for aes192, it is 24 bytes (192 bits).
scrypt(password, 'salt', 24, (err, key) => {
  if (err) throw err;
  // Then, we'll generate a random initialization vector
  randomFill(new Uint8Array(16), (err, iv) => {
    if (err) throw err;

    const cipher = createCipheriv(algorithm, key, iv);

    const input = createReadStream('test.js');
    const output = createWriteStream('test.enc');

    pipeline(input, cipher, output, (err) => {
      if (err) throw err;
    });
  });
});const {
  createReadStream,
  createWriteStream,
} = require('node:fs');

const {
  pipeline,
} = require('node:stream');

const {
  scrypt,
  randomFill,
  createCipheriv,
} = require('node:crypto');

const algorithm = 'aes-192-cbc';
const password = 'Password used to generate key';

// First, we'll generate the key. The key length is dependent on the algorithm.
// In this case for aes192, it is 24 bytes (192 bits).
scrypt(password, 'salt', 24, (err, key) => {
  if (err) throw err;
  // Then, we'll generate a random initialization vector
  randomFill(new Uint8Array(16), (err, iv) => {
    if (err) throw err;

    const cipher = createCipheriv(algorithm, key, iv);

    const input = createReadStream('test.js');
    const output = createWriteStream('test.enc');

    pipeline(input, cipher, output, (err) => {
      if (err) throw err;
    });
  });
});copy
Example: Using the cipher.update() and cipher.final() methods:

const {
  scrypt,
  randomFill,
  createCipheriv,
} = await import('node:crypto');

const algorithm = 'aes-192-cbc';
const password = 'Password used to generate key';

// First, we'll generate the key. The key length is dependent on the algorithm.
// In this case for aes192, it is 24 bytes (192 bits).
scrypt(password, 'salt', 24, (err, key) => {
  if (err) throw err;
  // Then, we'll generate a random initialization vector
  randomFill(new Uint8Array(16), (err, iv) => {
    if (err) throw err;

    const cipher = createCipheriv(algorithm, key, iv);

    let encrypted = cipher.update('some clear text data', 'utf8', 'hex');
    encrypted += cipher.final('hex');
    console.log(encrypted);
  });
});const {
  scrypt,
  randomFill,
  createCipheriv,
} = require('node:crypto');

const algorithm = 'aes-192-cbc';
const password = 'Password used to generate key';

// First, we'll generate the key. The key length is dependent on the algorithm.
// In this case for aes192, it is 24 bytes (192 bits).
scrypt(password, 'salt', 24, (err, key) => {
  if (err) throw err;
  // Then, we'll generate a random initialization vector
  randomFill(new Uint8Array(16), (err, iv) => {
    if (err) throw err;

    const cipher = createCipheriv(algorithm, key, iv);

    let encrypted = cipher.update('some clear text data', 'utf8', 'hex');
    encrypted += cipher.final('hex');
    console.log(encrypted);
  });
});copy

cipher.final([outputEncoding])#

Added in: v0.1.94


outputEncoding <string> The encoding of the return value.
Returns: <Buffer> | <string> Any remaining enciphered contents.
If outputEncoding is specified, a string is
returned. If an outputEncoding is not provided, a Buffer is returned.

Once the cipher.final() method has been called, the Cipheriv object can no
longer be used to encrypt data. Attempts to call cipher.final() more than
once will result in an error being thrown.

cipher.getAuthTag()#

Added in: v1.0.0


Returns: <Buffer> When using an authenticated encryption mode (GCM, CCM,
OCB, and chacha20-poly1305 are currently supported), the
cipher.getAuthTag() method returns a
Buffer containing the authentication tag that has been computed from
the given data.

The cipher.getAuthTag() method should only be called after encryption has
been completed using the cipher.final() method.
If the authTagLength option was set during the cipher instance's creation,
this function will return exactly authTagLength bytes.

cipher.setAAD(buffer[, options])#

Added in: v1.0.0


buffer <string> | <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView>
options <Object> stream.transform options

plaintextLength <number>
encoding <string> The string encoding to use when buffer is a string.


Returns: <Cipheriv> The same Cipheriv instance for method chaining.

When using an authenticated encryption mode (GCM, CCM, OCB, and
chacha20-poly1305 are
currently supported), the cipher.setAAD() method sets the value used for the
additional authenticated data (AAD) input parameter.
The plaintextLength option is optional for GCM and OCB. When using CCM,
the plaintextLength option must be specified and its value must match the
length of the plaintext in bytes. See CCM mode.
The cipher.setAAD() method must be called before cipher.update().

cipher.setAutoPadding([autoPadding])#

Added in: v0.7.1


autoPadding <boolean> Default: true
Returns: <Cipheriv> The same Cipheriv instance for method chaining.

When using block encryption algorithms, the Cipheriv class will automatically
add padding to the input data to the appropriate block size. To disable the
default padding call cipher.setAutoPadding(false).
When autoPadding is false, the length of the entire input data must be a
multiple of the cipher's block size or cipher.final() will throw an error.
Disabling automatic padding is useful for non-standard padding, for instance
using 0x0 instead of PKCS padding.
The cipher.setAutoPadding() method must be called before
cipher.final().

cipher.update(data[, inputEncoding][, outputEncoding])#

History

VersionChanges
v6.0.0
The default inputEncoding changed from binary to utf8.
v0.1.94
Added in: v0.1.94




data <string> | <Buffer> | <TypedArray> | <DataView>
inputEncoding <string> The encoding of the data.
outputEncoding <string> The encoding of the return value.
Returns: <Buffer> | <string>

Updates the cipher with data. If the inputEncoding argument is given,
the data
argument is a string using the specified encoding. If the inputEncoding
argument is not given, data must be a Buffer, TypedArray, or
DataView. If data is a Buffer, TypedArray, or DataView, then
inputEncoding is ignored.
The outputEncoding specifies the output format of the enciphered
data. If the outputEncoding
is specified, a string using the specified encoding is returned. If no
outputEncoding is provided, a Buffer is returned.
The cipher.update() method can be called multiple times with new data until
cipher.final() is called. Calling cipher.update() after
cipher.final() will result in an error being thrown.

Class: Decipheriv#

Added in: v0.1.94


Extends: <stream.Transform>

Instances of the Decipheriv class are used to decrypt data. The class can be
used in one of two ways:

As a stream that is both readable and writable, where plain encrypted
data is written to produce unencrypted data on the readable side, or
Using the decipher.update() and decipher.final() methods to
produce the unencrypted data.

The crypto.createDecipheriv() method is
used to create Decipheriv instances. Decipheriv objects are not to be created
directly using the new keyword.
Example: Using Decipheriv objects as streams:

import { Buffer } from 'node:buffer';
const {
  scryptSync,
  createDecipheriv,
} = await import('node:crypto');

const algorithm = 'aes-192-cbc';
const password = 'Password used to generate key';
// Key length is dependent on the algorithm. In this case for aes192, it is
// 24 bytes (192 bits).
// Use the async `crypto.scrypt()` instead.
const key = scryptSync(password, 'salt', 24);
// The IV is usually passed along with the ciphertext.
const iv = Buffer.alloc(16, 0); // Initialization vector.

const decipher = createDecipheriv(algorithm, key, iv);

let decrypted = '';
decipher.on('readable', () => {
  let chunk;
  while (null !== (chunk = decipher.read())) {
    decrypted += chunk.toString('utf8');
  }
});
decipher.on('end', () => {
  console.log(decrypted);
  // Prints: some clear text data
});

// Encrypted with same algorithm, key and iv.
const encrypted =
  'e5f79c5915c02171eec6b212d5520d44480993d7d622a7c4c2da32f6efda0ffa';
decipher.write(encrypted, 'hex');
decipher.end();const {
  scryptSync,
  createDecipheriv,
} = require('node:crypto');
const { Buffer } = require('node:buffer');

const algorithm = 'aes-192-cbc';
const password = 'Password used to generate key';
// Key length is dependent on the algorithm. In this case for aes192, it is
// 24 bytes (192 bits).
// Use the async `crypto.scrypt()` instead.
const key = scryptSync(password, 'salt', 24);
// The IV is usually passed along with the ciphertext.
const iv = Buffer.alloc(16, 0); // Initialization vector.

const decipher = createDecipheriv(algorithm, key, iv);

let decrypted = '';
decipher.on('readable', () => {
  let chunk;
  while (null !== (chunk = decipher.read())) {
    decrypted += chunk.toString('utf8');
  }
});
decipher.on('end', () => {
  console.log(decrypted);
  // Prints: some clear text data
});

// Encrypted with same algorithm, key and iv.
const encrypted =
  'e5f79c5915c02171eec6b212d5520d44480993d7d622a7c4c2da32f6efda0ffa';
decipher.write(encrypted, 'hex');
decipher.end();copy
Example: Using Decipheriv and piped streams:

import {
  createReadStream,
  createWriteStream,
} from 'node:fs';
import { Buffer } from 'node:buffer';
const {
  scryptSync,
  createDecipheriv,
} = await import('node:crypto');

const algorithm = 'aes-192-cbc';
const password = 'Password used to generate key';
// Use the async `crypto.scrypt()` instead.
const key = scryptSync(password, 'salt', 24);
// The IV is usually passed along with the ciphertext.
const iv = Buffer.alloc(16, 0); // Initialization vector.

const decipher = createDecipheriv(algorithm, key, iv);

const input = createReadStream('test.enc');
const output = createWriteStream('test.js');

input.pipe(decipher).pipe(output);const {
  createReadStream,
  createWriteStream,
} = require('node:fs');
const {
  scryptSync,
  createDecipheriv,
} = require('node:crypto');
const { Buffer } = require('node:buffer');

const algorithm = 'aes-192-cbc';
const password = 'Password used to generate key';
// Use the async `crypto.scrypt()` instead.
const key = scryptSync(password, 'salt', 24);
// The IV is usually passed along with the ciphertext.
const iv = Buffer.alloc(16, 0); // Initialization vector.

const decipher = createDecipheriv(algorithm, key, iv);

const input = createReadStream('test.enc');
const output = createWriteStream('test.js');

input.pipe(decipher).pipe(output);copy
Example: Using the decipher.update() and decipher.final() methods:

import { Buffer } from 'node:buffer';
const {
  scryptSync,
  createDecipheriv,
} = await import('node:crypto');

const algorithm = 'aes-192-cbc';
const password = 'Password used to generate key';
// Use the async `crypto.scrypt()` instead.
const key = scryptSync(password, 'salt', 24);
// The IV is usually passed along with the ciphertext.
const iv = Buffer.alloc(16, 0); // Initialization vector.

const decipher = createDecipheriv(algorithm, key, iv);

// Encrypted using same algorithm, key and iv.
const encrypted =
  'e5f79c5915c02171eec6b212d5520d44480993d7d622a7c4c2da32f6efda0ffa';
let decrypted = decipher.update(encrypted, 'hex', 'utf8');
decrypted += decipher.final('utf8');
console.log(decrypted);
// Prints: some clear text dataconst {
  scryptSync,
  createDecipheriv,
} = require('node:crypto');
const { Buffer } = require('node:buffer');

const algorithm = 'aes-192-cbc';
const password = 'Password used to generate key';
// Use the async `crypto.scrypt()` instead.
const key = scryptSync(password, 'salt', 24);
// The IV is usually passed along with the ciphertext.
const iv = Buffer.alloc(16, 0); // Initialization vector.

const decipher = createDecipheriv(algorithm, key, iv);

// Encrypted using same algorithm, key and iv.
const encrypted =
  'e5f79c5915c02171eec6b212d5520d44480993d7d622a7c4c2da32f6efda0ffa';
let decrypted = decipher.update(encrypted, 'hex', 'utf8');
decrypted += decipher.final('utf8');
console.log(decrypted);
// Prints: some clear text datacopy

decipher.final([outputEncoding])#

Added in: v0.1.94


outputEncoding <string> The encoding of the return value.
Returns: <Buffer> | <string> Any remaining deciphered contents.
If outputEncoding is specified, a string is
returned. If an outputEncoding is not provided, a Buffer is returned.

Once the decipher.final() method has been called, the Decipheriv object can
no longer be used to decrypt data. Attempts to call decipher.final() more
than once will result in an error being thrown.

decipher.setAAD(buffer[, options])#

History

VersionChanges
v15.0.0
The buffer argument can be a string or ArrayBuffer and is limited to no more than 2 ** 31 - 1 bytes.
v7.2.0
This method now returns a reference to decipher.
v1.0.0
Added in: v1.0.0




buffer <string> | <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView>
options <Object> stream.transform options

plaintextLength <number>
encoding <string> String encoding to use when buffer is a string.


Returns: <Decipheriv> The same Decipher for method chaining.

When using an authenticated encryption mode (GCM, CCM, OCB, and
chacha20-poly1305 are
currently supported), the decipher.setAAD() method sets the value used for the
additional authenticated data (AAD) input parameter.
The options argument is optional for GCM. When using CCM, the
plaintextLength option must be specified and its value must match the length
of the ciphertext in bytes. See CCM mode.
The decipher.setAAD() method must be called before decipher.update().
When passing a string as the buffer, please consider
caveats when using strings as inputs to cryptographic APIs.

decipher.setAuthTag(buffer[, encoding])#

History

VersionChanges
v22.0.0, v20.13.0
Using GCM tag lengths other than 128 bits without specifying the authTagLength option when creating decipher is deprecated.
v15.0.0
The buffer argument can be a string or ArrayBuffer and is limited to no more than 2 ** 31 - 1 bytes.
v11.0.0
This method now throws if the GCM tag length is invalid.
v7.2.0
This method now returns a reference to decipher.
v1.0.0
Added in: v1.0.0




buffer <string> | <Buffer> | <ArrayBuffer> | <TypedArray> | <DataView>
encoding <string> String encoding to use when buffer is a string.
Returns: <Decipheriv> The same Decipher for method chaining.

When using an authenticated encryption mode (GCM, CCM, OCB, and
chacha20-poly1305 are
currently supported), the decipher.setAuthTag() method is used to pass in the
received authentication tag. If no tag is provided, or if the cipher text
has been tampered with, decipher.final() will throw, indicating that the
cipher text should be discarded due to failed authentication. If the tag length
is invalid according to NIST SP 800-38D or does not match the value of the
authTagLength option, decipher.setAuthTag() will throw an error.
The decipher.setAuthTag() method must be called before decipher.update()
for CCM mode or before decipher.final() for GCM and OCB modes and
chacha20-poly1305.
decipher.setAuthTag() can only be called once.
When passing a string as the authentication tag, please consider
caveats when using strings as inputs to cryptographic APIs.

decipher.setAutoPadding([autoPadding])#

Added in: v0.7.1


autoPadding <boolean> Default: true
Returns: <Decipheriv> The same Decipher for method chaining.

When data has been encrypted without standard block padding, calling
decipher.setAutoPadding(false) will disable automatic padding to prevent
decipher.final() from checking for and removing padding.
Turning auto padding off will only work if the input data's length is a
multiple of the ciphers block size.
The decipher.setAutoPadding() method must be called before
decipher.final().

decipher.update(data[, inputEncoding][, outputEncoding])#

History

VersionChanges
v6.0.0
The default inputEncoding changed from binary to utf8.
v0.1.94
Added in: v0.1.94




data <string> | <Buffer> | <TypedArray> | <DataView>
inputEncoding <string> The encoding of the data string.
outputEncoding <string> The encoding of the return value.
Returns: <Buffer> | <string>

Updates the decipher with data. If the inputEncoding argument is given,
the data
argument is a string using the specified encoding. If the inputEncoding
argument is not given, data must be a Buffer. If data is a
Buffer then inputEncoding is ignored.
The outputEncoding specifies the output format of the enciphered
data. If the outputEncoding
is specified, a string using the specified encoding is returned. If no
outputEncoding is provided, a Buffer is returned.
The decipher.update() method can be called multiple times with new data until
decipher.final() is called. Calling decipher.update() after
decipher.final() will result in an error being thrown.
Even if the underlying cipher implements authentication, the authenticity and
integrity of the plaintext returned from this function may be uncertain at this
time. For authenticated encryption algorithms, authenticity is generally only
established when the application calls decipher.final().

Class: DiffieHellman#

Added in: v0.5.0

The DiffieHellman class is a utility for creating Diffie-Hellman key
exchanges.
Instances of the DiffieHellman class can be created using the
crypto.createDiffieHellman() function.

import assert from 'node:assert';

const {
  createDiffieHellman,
} = await import('node:crypto');

// Generate Alice's keys...
const alice = createDiffieHellman(2048);
const aliceKey = alice.generateKeys();

// Generate Bob's keys...
const bob = createDiffieHellman(alice.getPrime(), alice.getGenerator());
const bobKey = bob.generateKeys();

// Exchange and generate the secret...
const aliceSecret = alice.computeSecret(bobKey);
const bobSecret = bob.computeSecret(aliceKey);

// OK
assert.strictEqual(aliceSecret.toString('hex'), bobSecret.toString('hex'));const assert = require('node:assert');

const {
  createDiffieHellman,
} = require('node:crypto');

// Generate Alice's keys...
const alice = createDiffieHellman(2048);
const aliceKey = alice.generateKeys();

// Generate Bob's keys...
const bob = createDiffieHellman(alice.getPrime(), alice.getGenerator());
const bobKey = bob.generateKeys();

// Exchange and generate the secret...
const aliceSecret = alice.computeSecret(bobKey);
const bobSecret = bob.computeSecret(aliceKey);

// OK
assert.strictEqual(aliceSecret.toString('hex'), bobSecret.toString('hex'));copy

diffieHellman.computeSecret(otherPublicKey[, inputEncoding][, outputEncoding])#

Added in: v0.5.0


otherPublicKey <string> | <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView>
inputEncoding <string> The encoding of an otherPublicKey string.
outputEncoding <string> The encoding of the return value.
Returns: <Buffer> | <string>

Computes the shared secret using otherPublicKey as the other
party's public key and returns the computed shared secret. The supplied
key is interpreted using the specified inputEncoding, and secret is
encoded using specified outputEncoding.
If the inputEncoding is not
provided, otherPublicKey is expected to be a Buffer,
TypedArray, or DataView.
If outputEncoding is given a string is returned; otherwise, a
Buffer is returned.

diffieHellman.generateKeys([encoding])#

Added in: v0.5.0


encoding <string> The encoding of the return value.
Returns: <Buffer> | <string>

Generates private and public Diffie-Hellman key values unless they have been
generated or computed already, and returns
the public key in the specified encoding. This key should be
transferred to the other party.
If encoding is provided a string is returned; otherwise a
Buffer is returned.
This function is a thin wrapper around DH_generate_key(). In particular,
once a private key has been generated or set, calling this function only updates
the public key but does not generate a new private key.

diffieHellman.getGenerator([encoding])#

Added in: v0.5.0


encoding <string> The encoding of the return value.
Returns: <Buffer> | <string>

Returns the Diffie-Hellman generator in the specified encoding.
If encoding is provided a string is
returned; otherwise a Buffer is returned.

diffieHellman.getPrime([encoding])#

Added in: v0.5.0


encoding <string> The encoding of the return value.
Returns: <Buffer> | <string>

Returns the Diffie-Hellman prime in the specified encoding.
If encoding is provided a string is
returned; otherwise a Buffer is returned.

diffieHellman.getPrivateKey([encoding])#

Added in: v0.5.0


encoding <string> The encoding of the return value.
Returns: <Buffer> | <string>

Returns the Diffie-Hellman private key in the specified encoding.
If encoding is provided a
string is returned; otherwise a Buffer is returned.

diffieHellman.getPublicKey([encoding])#

Added in: v0.5.0


encoding <string> The encoding of the return value.
Returns: <Buffer> | <string>

Returns the Diffie-Hellman public key in the specified encoding.
If encoding is provided a
string is returned; otherwise a Buffer is returned.

diffieHellman.setPrivateKey(privateKey[, encoding])#

Added in: v0.5.0


privateKey <string> | <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView>
encoding <string> The encoding of the privateKey string.

Sets the Diffie-Hellman private key. If the encoding argument is provided,
privateKey is expected
to be a string. If no encoding is provided, privateKey is expected
to be a Buffer, TypedArray, or DataView.
This function does not automatically compute the associated public key. Either
diffieHellman.setPublicKey() or diffieHellman.generateKeys() can be
used to manually provide the public key or to automatically derive it.

diffieHellman.setPublicKey(publicKey[, encoding])#

Added in: v0.5.0


publicKey <string> | <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView>
encoding <string> The encoding of the publicKey string.

Sets the Diffie-Hellman public key. If the encoding argument is provided,
publicKey is expected
to be a string. If no encoding is provided, publicKey is expected
to be a Buffer, TypedArray, or DataView.

diffieHellman.verifyError#

Added in: v0.11.12

A bit field containing any warnings and/or errors resulting from a check
performed during initialization of the DiffieHellman object.
The following values are valid for this property (as defined in node:constants module):

DH_CHECK_P_NOT_SAFE_PRIME
DH_CHECK_P_NOT_PRIME
DH_UNABLE_TO_CHECK_GENERATOR
DH_NOT_SUITABLE_GENERATOR


Class: DiffieHellmanGroup#

Added in: v0.7.5

The DiffieHellmanGroup class takes a well-known modp group as its argument.
It works the same as DiffieHellman, except that it does not allow changing
its keys after creation. In other words, it does not implement setPublicKey()
or setPrivateKey() methods.

const { createDiffieHellmanGroup } = await import('node:crypto');
const dh = createDiffieHellmanGroup('modp16');const { createDiffieHellmanGroup } = require('node:crypto');
const dh = createDiffieHellmanGroup('modp16');copy
The following groups are supported:

'modp14' (2048 bits, RFC 3526 Section 3)
'modp15' (3072 bits, RFC 3526 Section 4)
'modp16' (4096 bits, RFC 3526 Section 5)
'modp17' (6144 bits, RFC 3526 Section 6)
'modp18' (8192 bits, RFC 3526 Section 7)

The following groups are still supported but deprecated (see Caveats):

'modp1' (768 bits, RFC 2409 Section 6.1) 
'modp2' (1024 bits, RFC 2409 Section 6.2) 
'modp5' (1536 bits, RFC 3526 Section 2) 

These deprecated groups might be removed in future versions of Node.js.
Class: ECDH#

Added in: v0.11.14

The ECDH class is a utility for creating Elliptic Curve Diffie-Hellman (ECDH)
key exchanges.
Instances of the ECDH class can be created using the
crypto.createECDH() function.

import assert from 'node:assert';

const {
  createECDH,
} = await import('node:crypto');

// Generate Alice's keys...
const alice = createECDH('secp521r1');
const aliceKey = alice.generateKeys();

// Generate Bob's keys...
const bob = createECDH('secp521r1');
const bobKey = bob.generateKeys();

// Exchange and generate the secret...
const aliceSecret = alice.computeSecret(bobKey);
const bobSecret = bob.computeSecret(aliceKey);

assert.strictEqual(aliceSecret.toString('hex'), bobSecret.toString('hex'));
// OKconst assert = require('node:assert');

const {
  createECDH,
} = require('node:crypto');

// Generate Alice's keys...
const alice = createECDH('secp521r1');
const aliceKey = alice.generateKeys();

// Generate Bob's keys...
const bob = createECDH('secp521r1');
const bobKey = bob.generateKeys();

// Exchange and generate the secret...
const aliceSecret = alice.computeSecret(bobKey);
const bobSecret = bob.computeSecret(aliceKey);

assert.strictEqual(aliceSecret.toString('hex'), bobSecret.toString('hex'));
// OKcopy

Static method: ECDH.convertKey(key, curve[, inputEncoding[, outputEncoding[, format]]])#

Added in: v10.0.0


key <string> | <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView>
curve <string>
inputEncoding <string> The encoding of the key string.
outputEncoding <string> The encoding of the return value.
format <string> Default: 'uncompressed'
Returns: <Buffer> | <string>

Converts the EC Diffie-Hellman public key specified by key and curve to the
format specified by format. The format argument specifies point encoding
and can be 'compressed', 'uncompressed' or 'hybrid'. The supplied key is
interpreted using the specified inputEncoding, and the returned key is encoded
using the specified outputEncoding.
Use crypto.getCurves() to obtain a list of available curve names.
On recent OpenSSL releases, openssl ecparam -list_curves will also display
the name and description of each available elliptic curve.
If format is not specified the point will be returned in 'uncompressed'
format.
If the inputEncoding is not provided, key is expected to be a Buffer,
TypedArray, or DataView.
Example (uncompressing a key):

const {
  createECDH,
  ECDH,
} = await import('node:crypto');

const ecdh = createECDH('secp256k1');
ecdh.generateKeys();

const compressedKey = ecdh.getPublicKey('hex', 'compressed');

const uncompressedKey = ECDH.convertKey(compressedKey,
                                        'secp256k1',
                                        'hex',
                                        'hex',
                                        'uncompressed');

// The converted key and the uncompressed public key should be the same
console.log(uncompressedKey === ecdh.getPublicKey('hex'));const {
  createECDH,
  ECDH,
} = require('node:crypto');

const ecdh = createECDH('secp256k1');
ecdh.generateKeys();

const compressedKey = ecdh.getPublicKey('hex', 'compressed');

const uncompressedKey = ECDH.convertKey(compressedKey,
                                        'secp256k1',
                                        'hex',
                                        'hex',
                                        'uncompressed');

// The converted key and the uncompressed public key should be the same
console.log(uncompressedKey === ecdh.getPublicKey('hex'));copy

ecdh.computeSecret(otherPublicKey[, inputEncoding][, outputEncoding])#

History

VersionChanges
v10.0.0
Changed error format to better support invalid public key error.
v6.0.0
The default inputEncoding changed from binary to utf8.
v0.11.14
Added in: v0.11.14




otherPublicKey <string> | <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView>
inputEncoding <string> The encoding of the otherPublicKey string.
outputEncoding <string> The encoding of the return value.
Returns: <Buffer> | <string>

Computes the shared secret using otherPublicKey as the other
party's public key and returns the computed shared secret. The supplied
key is interpreted using specified inputEncoding, and the returned secret
is encoded using the specified outputEncoding.
If the inputEncoding is not
provided, otherPublicKey is expected to be a Buffer, TypedArray, or
DataView.
If outputEncoding is given a string will be returned; otherwise a
Buffer is returned.
ecdh.computeSecret will throw an
ERR_CRYPTO_ECDH_INVALID_PUBLIC_KEY error when otherPublicKey
lies outside of the elliptic curve. Since otherPublicKey is
usually supplied from a remote user over an insecure network,
be sure to handle this exception accordingly.

ecdh.generateKeys([encoding[, format]])#

Added in: v0.11.14


encoding <string> The encoding of the return value.
format <string> Default: 'uncompressed'
Returns: <Buffer> | <string>

Generates private and public EC Diffie-Hellman key values, and returns
the public key in the specified format and encoding. This key should be
transferred to the other party.
The format argument specifies point encoding and can be 'compressed' or
'uncompressed'. If format is not specified, the point will be returned in
'uncompressed' format.
If encoding is provided a string is returned; otherwise a Buffer
is returned.

ecdh.getPrivateKey([encoding])#

Added in: v0.11.14


encoding <string> The encoding of the return value.
Returns: <Buffer> | <string> The EC Diffie-Hellman in the specified encoding.

If encoding is specified, a string is returned; otherwise a Buffer is
returned.

ecdh.getPublicKey([encoding][, format])#

Added in: v0.11.14


encoding <string> The encoding of the return value.
format <string> Default: 'uncompressed'
Returns: <Buffer> | <string> The EC Diffie-Hellman public key in the specified
encoding and format.

The format argument specifies point encoding and can be 'compressed' or
'uncompressed'. If format is not specified the point will be returned in
'uncompressed' format.
If encoding is specified, a string is returned; otherwise a Buffer is
returned.

ecdh.setPrivateKey(privateKey[, encoding])#

Added in: v0.11.14


privateKey <string> | <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView>
encoding <string> The encoding of the privateKey string.

Sets the EC Diffie-Hellman private key.
If encoding is provided, privateKey is expected
to be a string; otherwise privateKey is expected to be a Buffer,
TypedArray, or DataView.
If privateKey is not valid for the curve specified when the ECDH object was
created, an error is thrown. Upon setting the private key, the associated
public point (key) is also generated and set in the ECDH object.

ecdh.setPublicKey(publicKey[, encoding])#

Added in: v0.11.14Deprecated since: v5.2.0

Stability: 0 - Deprecated

publicKey <string> | <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView>
encoding <string> The encoding of the publicKey string.

Sets the EC Diffie-Hellman public key.
If encoding is provided publicKey is expected to
be a string; otherwise a Buffer, TypedArray, or DataView is expected.
There is not normally a reason to call this method because ECDH
only requires a private key and the other party's public key to compute the
shared secret. Typically either ecdh.generateKeys() or
ecdh.setPrivateKey() will be called. The ecdh.setPrivateKey() method
attempts to generate the public point/key associated with the private key being
set.
Example (obtaining a shared secret):

const {
  createECDH,
  createHash,
} = await import('node:crypto');

const alice = createECDH('secp256k1');
const bob = createECDH('secp256k1');

// This is a shortcut way of specifying one of Alice's previous private
// keys. It would be unwise to use such a predictable private key in a real
// application.
alice.setPrivateKey(
  createHash('sha256').update('alice', 'utf8').digest(),
);

// Bob uses a newly generated cryptographically strong
// pseudorandom key pair
bob.generateKeys();

const aliceSecret = alice.computeSecret(bob.getPublicKey(), null, 'hex');
const bobSecret = bob.computeSecret(alice.getPublicKey(), null, 'hex');

// aliceSecret and bobSecret should be the same shared secret value
console.log(aliceSecret === bobSecret);const {
  createECDH,
  createHash,
} = require('node:crypto');

const alice = createECDH('secp256k1');
const bob = createECDH('secp256k1');

// This is a shortcut way of specifying one of Alice's previous private
// keys. It would be unwise to use such a predictable private key in a real
// application.
alice.setPrivateKey(
  createHash('sha256').update('alice', 'utf8').digest(),
);

// Bob uses a newly generated cryptographically strong
// pseudorandom key pair
bob.generateKeys();

const aliceSecret = alice.computeSecret(bob.getPublicKey(), null, 'hex');
const bobSecret = bob.computeSecret(alice.getPublicKey(), null, 'hex');

// aliceSecret and bobSecret should be the same shared secret value
console.log(aliceSecret === bobSecret);copy

Class: Hash#

Added in: v0.1.92


Extends: <stream.Transform>

The Hash class is a utility for creating hash digests of data. It can be
used in one of two ways:

As a stream that is both readable and writable, where data is written
to produce a computed hash digest on the readable side, or
Using the hash.update() and hash.digest() methods to produce the
computed hash.

The crypto.createHash() method is used to create Hash instances. Hash
objects are not to be created directly using the new keyword.
Example: Using Hash objects as streams:

const {
  createHash,
} = await import('node:crypto');

const hash = createHash('sha256');

hash.on('readable', () => {
  // Only one element is going to be produced by the
  // hash stream.
  const data = hash.read();
  if (data) {
    console.log(data.toString('hex'));
    // Prints:
    //   6a2da20943931e9834fc12cfe5bb47bbd9ae43489a30726962b576f4e3993e50
  }
});

hash.write('some data to hash');
hash.end();const {
  createHash,
} = require('node:crypto');

const hash = createHash('sha256');

hash.on('readable', () => {
  // Only one element is going to be produced by the
  // hash stream.
  const data = hash.read();
  if (data) {
    console.log(data.toString('hex'));
    // Prints:
    //   6a2da20943931e9834fc12cfe5bb47bbd9ae43489a30726962b576f4e3993e50
  }
});

hash.write('some data to hash');
hash.end();copy
Example: Using Hash and piped streams:

import { createReadStream } from 'node:fs';
import { stdout } from 'node:process';
const { createHash } = await import('node:crypto');

const hash = createHash('sha256');

const input = createReadStream('test.js');
input.pipe(hash).setEncoding('hex').pipe(stdout);const { createReadStream } = require('node:fs');
const { createHash } = require('node:crypto');
const { stdout } = require('node:process');

const hash = createHash('sha256');

const input = createReadStream('test.js');
input.pipe(hash).setEncoding('hex').pipe(stdout);copy
Example: Using the hash.update() and hash.digest() methods:

const {
  createHash,
} = await import('node:crypto');

const hash = createHash('sha256');

hash.update('some data to hash');
console.log(hash.digest('hex'));
// Prints:
//   6a2da20943931e9834fc12cfe5bb47bbd9ae43489a30726962b576f4e3993e50const {
  createHash,
} = require('node:crypto');

const hash = createHash('sha256');

hash.update('some data to hash');
console.log(hash.digest('hex'));
// Prints:
//   6a2da20943931e9834fc12cfe5bb47bbd9ae43489a30726962b576f4e3993e50copy

hash.copy([options])#

Added in: v13.1.0


options <Object> stream.transform options
Returns: <Hash>

Creates a new Hash object that contains a deep copy of the internal state
of the current Hash object.
The optional options argument controls stream behavior. For XOF hash
functions such as 'shake256', the outputLength option can be used to
specify the desired output length in bytes.
An error is thrown when an attempt is made to copy the Hash object after
its hash.digest() method has been called.

// Calculate a rolling hash.
const {
  createHash,
} = await import('node:crypto');

const hash = createHash('sha256');

hash.update('one');
console.log(hash.copy().digest('hex'));

hash.update('two');
console.log(hash.copy().digest('hex'));

hash.update('three');
console.log(hash.copy().digest('hex'));

// Etc.// Calculate a rolling hash.
const {
  createHash,
} = require('node:crypto');

const hash = createHash('sha256');

hash.update('one');
console.log(hash.copy().digest('hex'));

hash.update('two');
console.log(hash.copy().digest('hex'));

hash.update('three');
console.log(hash.copy().digest('hex'));

// Etc.copy

hash.digest([encoding])#

Added in: v0.1.92


encoding <string> The encoding of the return value.
Returns: <Buffer> | <string>

Calculates the digest of all of the data passed to be hashed (using the
hash.update() method).
If encoding is provided a string will be returned; otherwise
a Buffer is returned.
The Hash object can not be used again after hash.digest() method has been
called. Multiple calls will cause an error to be thrown.

hash.update(data[, inputEncoding])#

History

VersionChanges
v6.0.0
The default inputEncoding changed from binary to utf8.
v0.1.92
Added in: v0.1.92




data <string> | <Buffer> | <TypedArray> | <DataView>
inputEncoding <string> The encoding of the data string.

Updates the hash content with the given data, the encoding of which
is given in inputEncoding.
If encoding is not provided, and the data is a string, an
encoding of 'utf8' is enforced. If data is a Buffer, TypedArray, or
DataView, then inputEncoding is ignored.
This can be called many times with new data as it is streamed.

Class: Hmac#

Added in: v0.1.94


Extends: <stream.Transform>

The Hmac class is a utility for creating cryptographic HMAC digests. It can
be used in one of two ways:

As a stream that is both readable and writable, where data is written
to produce a computed HMAC digest on the readable side, or
Using the hmac.update() and hmac.digest() methods to produce the
computed HMAC digest.

The crypto.createHmac() method is used to create Hmac instances. Hmac
objects are not to be created directly using the new keyword.
Example: Using Hmac objects as streams:

const {
  createHmac,
} = await import('node:crypto');

const hmac = createHmac('sha256', 'a secret');

hmac.on('readable', () => {
  // Only one element is going to be produced by the
  // hash stream.
  const data = hmac.read();
  if (data) {
    console.log(data.toString('hex'));
    // Prints:
    //   7fd04df92f636fd450bc841c9418e5825c17f33ad9c87c518115a45971f7f77e
  }
});

hmac.write('some data to hash');
hmac.end();const {
  createHmac,
} = require('node:crypto');

const hmac = createHmac('sha256', 'a secret');

hmac.on('readable', () => {
  // Only one element is going to be produced by the
  // hash stream.
  const data = hmac.read();
  if (data) {
    console.log(data.toString('hex'));
    // Prints:
    //   7fd04df92f636fd450bc841c9418e5825c17f33ad9c87c518115a45971f7f77e
  }
});

hmac.write('some data to hash');
hmac.end();copy
Example: Using Hmac and piped streams:

import { createReadStream } from 'node:fs';
import { stdout } from 'node:process';
const {
  createHmac,
} = await import('node:crypto');

const hmac = createHmac('sha256', 'a secret');

const input = createReadStream('test.js');
input.pipe(hmac).pipe(stdout);const {
  createReadStream,
} = require('node:fs');
const {
  createHmac,
} = require('node:crypto');
const { stdout } = require('node:process');

const hmac = createHmac('sha256', 'a secret');

const input = createReadStream('test.js');
input.pipe(hmac).pipe(stdout);copy
Example: Using the hmac.update() and hmac.digest() methods:

const {
  createHmac,
} = await import('node:crypto');

const hmac = createHmac('sha256', 'a secret');

hmac.update('some data to hash');
console.log(hmac.digest('hex'));
// Prints:
//   7fd04df92f636fd450bc841c9418e5825c17f33ad9c87c518115a45971f7f77econst {
  createHmac,
} = require('node:crypto');

const hmac = createHmac('sha256', 'a secret');

hmac.update('some data to hash');
console.log(hmac.digest('hex'));
// Prints:
//   7fd04df92f636fd450bc841c9418e5825c17f33ad9c87c518115a45971f7f77ecopy

hmac.digest([encoding])#

Added in: v0.1.94


encoding <string> The encoding of the return value.
Returns: <Buffer> | <string>

Calculates the HMAC digest of all of the data passed using hmac.update().
If encoding is
provided a string is returned; otherwise a Buffer is returned;
The Hmac object can not be used again after hmac.digest() has been
called. Multiple calls to hmac.digest() will result in an error being thrown.

hmac.update(data[, inputEncoding])#

History

VersionChanges
v6.0.0
The default inputEncoding changed from binary to utf8.
v0.1.94
Added in: v0.1.94




data <string> | <Buffer> | <TypedArray> | <DataView>
inputEncoding <string> The encoding of the data string.

Updates the Hmac content with the given data, the encoding of which
is given in inputEncoding.
If encoding is not provided, and the data is a string, an
encoding of 'utf8' is enforced. If data is a Buffer, TypedArray, or
DataView, then inputEncoding is ignored.
This can be called many times with new data as it is streamed.

Class: KeyObject#

History

VersionChanges
v14.5.0, v12.19.0
Instances of this class can now be passed to worker threads using postMessage.
v11.13.0
This class is now exported.
v11.6.0
Added in: v11.6.0



Node.js uses a KeyObject class to represent a symmetric or asymmetric key,
and each kind of key exposes different functions. The
crypto.createSecretKey(), crypto.createPublicKey() and
crypto.createPrivateKey() methods are used to create KeyObject
instances. KeyObject objects are not to be created directly using the new
keyword.
Most applications should consider using the new KeyObject API instead of
passing keys as strings or Buffers due to improved security features.
KeyObject instances can be passed to other threads via postMessage().
The receiver obtains a cloned KeyObject, and the KeyObject does not need to
be listed in the transferList argument.

Static method: KeyObject.from(key)#

Added in: v15.0.0


key <CryptoKey>
Returns: <KeyObject>

Example: Converting a CryptoKey instance to a KeyObject:

const { KeyObject } = await import('node:crypto');
const { subtle } = globalThis.crypto;

const key = await subtle.generateKey({
  name: 'HMAC',
  hash: 'SHA-256',
  length: 256,
}, true, ['sign', 'verify']);

const keyObject = KeyObject.from(key);
console.log(keyObject.symmetricKeySize);
// Prints: 32 (symmetric key size in bytes)const { KeyObject } = require('node:crypto');
const { subtle } = globalThis.crypto;

(async function() {
  const key = await subtle.generateKey({
    name: 'HMAC',
    hash: 'SHA-256',
    length: 256,
  }, true, ['sign', 'verify']);

  const keyObject = KeyObject.from(key);
  console.log(keyObject.symmetricKeySize);
  // Prints: 32 (symmetric key size in bytes)
})();copy

keyObject.asymmetricKeyDetails#

History

VersionChanges
v16.9.0
Expose RSASSA-PSS-params sequence parameters for RSA-PSS keys.
v15.7.0
Added in: v15.7.0




<Object>

modulusLength: <number> Key size in bits (RSA, DSA).
publicExponent: <bigint> Public exponent (RSA).
hashAlgorithm: <string> Name of the message digest (RSA-PSS).
mgf1HashAlgorithm: <string> Name of the message digest used by
MGF1 (RSA-PSS).
saltLength: <number> Minimal salt length in bytes (RSA-PSS).
divisorLength: <number> Size of q in bits (DSA).
namedCurve: <string> Name of the curve (EC).



This property exists only on asymmetric keys. Depending on the type of the key,
this object contains information about the key. None of the information obtained
through this property can be used to uniquely identify a key or to compromise
the security of the key.
For RSA-PSS keys, if the key material contains a RSASSA-PSS-params sequence,
the hashAlgorithm, mgf1HashAlgorithm, and saltLength properties will be
set.
Other key details might be exposed via this API using additional attributes.

keyObject.asymmetricKeyType#

History

VersionChanges
v13.9.0, v12.17.0
Added support for 'dh'.
v12.0.0
Added support for 'rsa-pss'.
v12.0.0
This property now returns undefined for KeyObject instances of unrecognized type instead of aborting.
v12.0.0
Added support for 'x25519' and 'x448'.
v12.0.0
Added support for 'ed25519' and 'ed448'.
v11.6.0
Added in: v11.6.0




<string>

For asymmetric keys, this property represents the type of the key. Supported key
types are:

'rsa' (OID 1.2.840.113549.1.1.1)
'rsa-pss' (OID 1.2.840.113549.1.1.10)
'dsa' (OID 1.2.840.10040.4.1)
'ec' (OID 1.2.840.10045.2.1)
'x25519' (OID 1.3.101.110)
'x448' (OID 1.3.101.111)
'ed25519' (OID 1.3.101.112)
'ed448' (OID 1.3.101.113)
'dh' (OID 1.2.840.113549.1.3.1)

This property is undefined for unrecognized KeyObject types and symmetric
keys.

keyObject.equals(otherKeyObject)#

Added in: v17.7.0, v16.15.0


otherKeyObject: <KeyObject> A KeyObject with which to
compare keyObject.
Returns: <boolean>

Returns true or false depending on whether the keys have exactly the same
type, value, and parameters. This method is not
constant time.

keyObject.export([options])#

History

VersionChanges
v15.9.0
Added support for 'jwk' format.
v11.6.0
Added in: v11.6.0




options: <Object>
Returns: <string> | <Buffer> | <Object>

For symmetric keys, the following encoding options can be used:

format: <string> Must be 'buffer' (default) or 'jwk'.

For public keys, the following encoding options can be used:

type: <string> Must be one of 'pkcs1' (RSA only) or 'spki'.
format: <string> Must be 'pem', 'der', or 'jwk'.

For private keys, the following encoding options can be used:

type: <string> Must be one of 'pkcs1' (RSA only), 'pkcs8' or
'sec1' (EC only).
format: <string> Must be 'pem', 'der', or 'jwk'.
cipher: <string> If specified, the private key will be encrypted with
the given cipher and passphrase using PKCS#5 v2.0 password based
encryption.
passphrase: <string> | <Buffer> The passphrase to use for encryption, see
cipher.

The result type depends on the selected encoding format, when PEM the
result is a string, when DER it will be a buffer containing the data
encoded as DER, when JWK it will be an object.
When JWK encoding format was selected, all other encoding options are
ignored.
PKCS#1, SEC1, and PKCS#8 type keys can be encrypted by using a combination of
the cipher and format options. The PKCS#8 type can be used with any
format to encrypt any key algorithm (RSA, EC, or DH) by specifying a
cipher. PKCS#1 and SEC1 can only be encrypted by specifying a cipher
when the PEM format is used. For maximum compatibility, use PKCS#8 for
encrypted private keys. Since PKCS#8 defines its own
encryption mechanism, PEM-level encryption is not supported when encrypting
a PKCS#8 key. See RFC 5208 for PKCS#8 encryption and RFC 1421 for
PKCS#1 and SEC1 encryption.

keyObject.symmetricKeySize#

Added in: v11.6.0


<number>

For secret keys, this property represents the size of the key in bytes. This
property is undefined for asymmetric keys.

keyObject.toCryptoKey(algorithm, extractable, keyUsages)#

Added in: v23.0.0, v22.10.0



algorithm: <AlgorithmIdentifier> | <RsaHashedImportParams> | <EcKeyImportParams> | <HmacImportParams>



extractable: <boolean>
keyUsages: <string[]> See Key usages.
Returns: <CryptoKey>

Converts a KeyObject instance to a CryptoKey.

keyObject.type#

Added in: v11.6.0


<string>

Depending on the type of this KeyObject, this property is either
'secret' for secret (symmetric) keys, 'public' for public (asymmetric) keys
or 'private' for private (asymmetric) keys.

Class: Sign#

Added in: v0.1.92


Extends: <stream.Writable>

The Sign class is a utility for generating signatures. It can be used in one
of two ways:

As a writable stream, where data to be signed is written and the
sign.sign() method is used to generate and return the signature, or
Using the sign.update() and sign.sign() methods to produce the
signature.

The crypto.createSign() method is used to create Sign instances. The
argument is the string name of the hash function to use. Sign objects are not
to be created directly using the new keyword.
Example: Using Sign and Verify objects as streams:

const {
  generateKeyPairSync,
  createSign,
  createVerify,
} = await import('node:crypto');

const { privateKey, publicKey } = generateKeyPairSync('ec', {
  namedCurve: 'sect239k1',
});

const sign = createSign('SHA256');
sign.write('some data to sign');
sign.end();
const signature = sign.sign(privateKey, 'hex');

const verify = createVerify('SHA256');
verify.write('some data to sign');
verify.end();
console.log(verify.verify(publicKey, signature, 'hex'));
// Prints: trueconst {
  generateKeyPairSync,
  createSign,
  createVerify,
} = require('node:crypto');

const { privateKey, publicKey } = generateKeyPairSync('ec', {
  namedCurve: 'sect239k1',
});

const sign = createSign('SHA256');
sign.write('some data to sign');
sign.end();
const signature = sign.sign(privateKey, 'hex');

const verify = createVerify('SHA256');
verify.write('some data to sign');
verify.end();
console.log(verify.verify(publicKey, signature, 'hex'));
// Prints: truecopy
Example: Using the sign.update() and verify.update() methods:

const {
  generateKeyPairSync,
  createSign,
  createVerify,
} = await import('node:crypto');

const { privateKey, publicKey } = generateKeyPairSync('rsa', {
  modulusLength: 2048,
});

const sign = createSign('SHA256');
sign.update('some data to sign');
sign.end();
const signature = sign.sign(privateKey);

const verify = createVerify('SHA256');
verify.update('some data to sign');
verify.end();
console.log(verify.verify(publicKey, signature));
// Prints: trueconst {
  generateKeyPairSync,
  createSign,
  createVerify,
} = require('node:crypto');

const { privateKey, publicKey } = generateKeyPairSync('rsa', {
  modulusLength: 2048,
});

const sign = createSign('SHA256');
sign.update('some data to sign');
sign.end();
const signature = sign.sign(privateKey);

const verify = createVerify('SHA256');
verify.update('some data to sign');
verify.end();
console.log(verify.verify(publicKey, signature));
// Prints: truecopy

sign.sign(privateKey[, outputEncoding])#

History

VersionChanges
v15.0.0
The privateKey can also be an ArrayBuffer and CryptoKey.
v13.2.0, v12.16.0
This function now supports IEEE-P1363 DSA and ECDSA signatures.
v12.0.0
This function now supports RSA-PSS keys.
v11.6.0
This function now supports key objects.
v8.0.0
Support for RSASSA-PSS and additional options was added.
v0.1.92
Added in: v0.1.92





privateKey <Object> | <string> | <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView> | <KeyObject> | <CryptoKey>

dsaEncoding <string>
padding <integer>
saltLength <integer>


outputEncoding <string> The encoding of the return value.
Returns: <Buffer> | <string>


Calculates the signature on all the data passed through using either
sign.update() or sign.write().
If privateKey is not a KeyObject, this function behaves as if
privateKey had been passed to crypto.createPrivateKey(). If it is an
object, the following additional properties can be passed:


dsaEncoding <string> For DSA and ECDSA, this option specifies the
format of the generated signature. It can be one of the following:

'der' (default): DER-encoded ASN.1 signature structure encoding (r, s).
'ieee-p1363': Signature format r || s as proposed in IEEE-P1363.



padding <integer> Optional padding value for RSA, one of the following:

crypto.constants.RSA_PKCS1_PADDING (default)
crypto.constants.RSA_PKCS1_PSS_PADDING

RSA_PKCS1_PSS_PADDING will use MGF1 with the same hash function
used to sign the message as specified in section 3.1 of RFC 4055, unless
an MGF1 hash function has been specified as part of the key in compliance with
section 3.3 of RFC 4055.


saltLength <integer> Salt length for when padding is
RSA_PKCS1_PSS_PADDING. The special value
crypto.constants.RSA_PSS_SALTLEN_DIGEST sets the salt length to the digest
size, crypto.constants.RSA_PSS_SALTLEN_MAX_SIGN (default) sets it to the
maximum permissible value.


If outputEncoding is provided a string is returned; otherwise a Buffer
is returned.
The Sign object can not be again used after sign.sign() method has been
called. Multiple calls to sign.sign() will result in an error being thrown.

sign.update(data[, inputEncoding])#

History

VersionChanges
v6.0.0
The default inputEncoding changed from binary to utf8.
v0.1.92
Added in: v0.1.92




data <string> | <Buffer> | <TypedArray> | <DataView>
inputEncoding <string> The encoding of the data string.

Updates the Sign content with the given data, the encoding of which
is given in inputEncoding.
If encoding is not provided, and the data is a string, an
encoding of 'utf8' is enforced. If data is a Buffer, TypedArray, or
DataView, then inputEncoding is ignored.
This can be called many times with new data as it is streamed.

Class: Verify#

Added in: v0.1.92


Extends: <stream.Writable>

The Verify class is a utility for verifying signatures. It can be used in one
of two ways:

As a writable stream where written data is used to validate against the
supplied signature, or
Using the verify.update() and verify.verify() methods to verify
the signature.

The crypto.createVerify() method is used to create Verify instances.
Verify objects are not to be created directly using the new keyword.
See Sign for examples.

verify.update(data[, inputEncoding])#

History

VersionChanges
v6.0.0
The default inputEncoding changed from binary to utf8.
v0.1.92
Added in: v0.1.92




data <string> | <Buffer> | <TypedArray> | <DataView>
inputEncoding <string> The encoding of the data string.

Updates the Verify content with the given data, the encoding of which
is given in inputEncoding.
If inputEncoding is not provided, and the data is a string, an
encoding of 'utf8' is enforced. If data is a Buffer, TypedArray, or
DataView, then inputEncoding is ignored.
This can be called many times with new data as it is streamed.

verify.verify(object, signature[, signatureEncoding])#

History

VersionChanges
v15.0.0
The object can also be an ArrayBuffer and CryptoKey.
v13.2.0, v12.16.0
This function now supports IEEE-P1363 DSA and ECDSA signatures.
v12.0.0
This function now supports RSA-PSS keys.
v11.7.0
The key can now be a private key.
v8.0.0
Support for RSASSA-PSS and additional options was added.
v0.1.92
Added in: v0.1.92





object <Object> | <string> | <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView> | <KeyObject> | <CryptoKey>

dsaEncoding <string>
padding <integer>
saltLength <integer>


signature <string> | <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView>
signatureEncoding <string> The encoding of the signature string.
Returns: <boolean> true or false depending on the validity of the
signature for the data and public key.


Verifies the provided data using the given object and signature.
If object is not a KeyObject, this function behaves as if
object had been passed to crypto.createPublicKey(). If it is an
object, the following additional properties can be passed:


dsaEncoding <string> For DSA and ECDSA, this option specifies the
format of the signature. It can be one of the following:

'der' (default): DER-encoded ASN.1 signature structure encoding (r, s).
'ieee-p1363': Signature format r || s as proposed in IEEE-P1363.



padding <integer> Optional padding value for RSA, one of the following:

crypto.constants.RSA_PKCS1_PADDING (default)
crypto.constants.RSA_PKCS1_PSS_PADDING

RSA_PKCS1_PSS_PADDING will use MGF1 with the same hash function
used to verify the message as specified in section 3.1 of RFC 4055, unless
an MGF1 hash function has been specified as part of the key in compliance with
section 3.3 of RFC 4055.


saltLength <integer> Salt length for when padding is
RSA_PKCS1_PSS_PADDING. The special value
crypto.constants.RSA_PSS_SALTLEN_DIGEST sets the salt length to the digest
size, crypto.constants.RSA_PSS_SALTLEN_AUTO (default) causes it to be
determined automatically.


The signature argument is the previously calculated signature for the data, in
the signatureEncoding.
If a signatureEncoding is specified, the signature is expected to be a
string; otherwise signature is expected to be a Buffer,
TypedArray, or DataView.
The verify object can not be used again after verify.verify() has been
called. Multiple calls to verify.verify() will result in an error being
thrown.
Because public keys can be derived from private keys, a private key may
be passed instead of a public key.

Class: X509Certificate#

Added in: v15.6.0

Encapsulates an X509 certificate and provides read-only access to
its information.

const { X509Certificate } = await import('node:crypto');

const x509 = new X509Certificate('{... pem encoded cert ...}');

console.log(x509.subject);const { X509Certificate } = require('node:crypto');

const x509 = new X509Certificate('{... pem encoded cert ...}');

console.log(x509.subject);copy

new X509Certificate(buffer)#

Added in: v15.6.0


buffer <string> | <TypedArray> | <Buffer> | <DataView> A PEM or DER encoded
X509 Certificate.


x509.ca#

Added in: v15.6.0


Type: <boolean> Will be true if this is a Certificate Authority (CA)
certificate.


x509.checkEmail(email[, options])#

History

VersionChanges
v18.0.0
The subject option now defaults to 'default'.
v17.5.0, v16.15.0
The subject option can now be set to 'default'.
v17.5.0, v16.14.1
The wildcards, partialWildcards, multiLabelWildcards, and singleLabelSubdomains options have been removed since they had no effect.
v15.6.0
Added in: v15.6.0




email <string>
options <Object>

subject <string> 'default', 'always', or 'never'.
Default: 'default'.


Returns: <string> | <undefined> Returns email if the certificate matches,
undefined if it does not.

Checks whether the certificate matches the given email address.
If the 'subject' option is undefined or set to 'default', the certificate
subject is only considered if the subject alternative name extension either does
not exist or does not contain any email addresses.
If the 'subject' option is set to 'always' and if the subject alternative
name extension either does not exist or does not contain a matching email
address, the certificate subject is considered.
If the 'subject' option is set to 'never', the certificate subject is never
considered, even if the certificate contains no subject alternative names.

x509.checkHost(name[, options])#

History

VersionChanges
v18.0.0
The subject option now defaults to 'default'.
v17.5.0, v16.15.0
The subject option can now be set to 'default'.
v15.6.0
Added in: v15.6.0




name <string>
options <Object>

subject <string> 'default', 'always', or 'never'.
Default: 'default'.
wildcards <boolean> Default: true.
partialWildcards <boolean> Default: true.
multiLabelWildcards <boolean> Default: false.
singleLabelSubdomains <boolean> Default: false.


Returns: <string> | <undefined> Returns a subject name that matches name,
or undefined if no subject name matches name.

Checks whether the certificate matches the given host name.
If the certificate matches the given host name, the matching subject name is
returned. The returned name might be an exact match (e.g., foo.example.com)
or it might contain wildcards (e.g., *.example.com). Because host name
comparisons are case-insensitive, the returned subject name might also differ
from the given name in capitalization.
If the 'subject' option is undefined or set to 'default', the certificate
subject is only considered if the subject alternative name extension either does
not exist or does not contain any DNS names. This behavior is consistent with
RFC 2818 ("HTTP Over TLS").
If the 'subject' option is set to 'always' and if the subject alternative
name extension either does not exist or does not contain a matching DNS name,
the certificate subject is considered.
If the 'subject' option is set to 'never', the certificate subject is never
considered, even if the certificate contains no subject alternative names.

x509.checkIP(ip)#

History

VersionChanges
v17.5.0, v16.14.1
The options argument has been removed since it had no effect.
v15.6.0
Added in: v15.6.0




ip <string>
Returns: <string> | <undefined> Returns ip if the certificate matches,
undefined if it does not.

Checks whether the certificate matches the given IP address (IPv4 or IPv6).
Only RFC 5280 iPAddress subject alternative names are considered, and they
must match the given ip address exactly. Other subject alternative names as
well as the subject field of the certificate are ignored.

x509.checkIssued(otherCert)#

Added in: v15.6.0


otherCert <X509Certificate>
Returns: <boolean>

Checks whether this certificate was issued by the given otherCert.

x509.checkPrivateKey(privateKey)#

Added in: v15.6.0


privateKey <KeyObject> A private key.
Returns: <boolean>

Checks whether the public key for this certificate is consistent with
the given private key.

x509.extKeyUsage#

Added in: v15.6.0


Type: <string[]>

An array detailing the key extended usages for this certificate.

x509.fingerprint#

Added in: v15.6.0


Type: <string>

The SHA-1 fingerprint of this certificate.
Because SHA-1 is cryptographically broken and because the security of SHA-1 is
significantly worse than that of algorithms that are commonly used to sign
certificates, consider using x509.fingerprint256 instead.

x509.fingerprint256#

Added in: v15.6.0


Type: <string>

The SHA-256 fingerprint of this certificate.

x509.fingerprint512#

Added in: v17.2.0, v16.14.0


Type: <string>

The SHA-512 fingerprint of this certificate.
Because computing the SHA-256 fingerprint is usually faster and because it is
only half the size of the SHA-512 fingerprint, x509.fingerprint256 may be
a better choice. While SHA-512 presumably provides a higher level of security in
general, the security of SHA-256 matches that of most algorithms that are
commonly used to sign certificates.

x509.infoAccess#

History

VersionChanges
v17.3.1, v16.13.2
Parts of this string may be encoded as JSON string literals in response to CVE-2021-44532.
v15.6.0
Added in: v15.6.0




Type: <string>

A textual representation of the certificate's authority information access
extension.
This is a line feed separated list of access descriptions. Each line begins with
the access method and the kind of the access location, followed by a colon and
the value associated with the access location.
After the prefix denoting the access method and the kind of the access location,
the remainder of each line might be enclosed in quotes to indicate that the
value is a JSON string literal. For backward compatibility, Node.js only uses
JSON string literals within this property when necessary to avoid ambiguity.
Third-party code should be prepared to handle both possible entry formats.

x509.issuer#

Added in: v15.6.0


Type: <string>

The issuer identification included in this certificate.

x509.issuerCertificate#

Added in: v15.9.0


Type: <X509Certificate>

The issuer certificate or undefined if the issuer certificate is not
available.

x509.publicKey#

Added in: v15.6.0


Type: <KeyObject>

The public key <KeyObject> for this certificate.

x509.raw#

Added in: v15.6.0


Type: <Buffer>

A Buffer containing the DER encoding of this certificate.

x509.serialNumber#

Added in: v15.6.0


Type: <string>

The serial number of this certificate.
Serial numbers are assigned by certificate authorities and do not uniquely
identify certificates. Consider using x509.fingerprint256 as a unique
identifier instead.

x509.subject#

Added in: v15.6.0


Type: <string>

The complete subject of this certificate.

x509.subjectAltName#

History

VersionChanges
v17.3.1, v16.13.2
Parts of this string may be encoded as JSON string literals in response to CVE-2021-44532.
v15.6.0
Added in: v15.6.0




Type: <string>

The subject alternative name specified for this certificate.
This is a comma-separated list of subject alternative names. Each entry begins
with a string identifying the kind of the subject alternative name followed by
a colon and the value associated with the entry.
Earlier versions of Node.js incorrectly assumed that it is safe to split this
property at the two-character sequence ', ' (see CVE-2021-44532). However,
both malicious and legitimate certificates can contain subject alternative names
that include this sequence when represented as a string.
After the prefix denoting the type of the entry, the remainder of each entry
might be enclosed in quotes to indicate that the value is a JSON string literal.
For backward compatibility, Node.js only uses JSON string literals within this
property when necessary to avoid ambiguity. Third-party code should be prepared
to handle both possible entry formats.

x509.toJSON()#

Added in: v15.6.0


Type: <string>

There is no standard JSON encoding for X509 certificates. The
toJSON() method returns a string containing the PEM encoded
certificate.

x509.toLegacyObject()#

Added in: v15.6.0


Type: <Object>

Returns information about this certificate using the legacy
certificate object encoding.

x509.toString()#

Added in: v15.6.0


Type: <string>

Returns the PEM-encoded certificate.

x509.validFrom#

Added in: v15.6.0


Type: <string>

The date/time from which this certificate is valid.

x509.validFromDate#

Added in: v23.0.0, v22.10.0


Type: <Date>

The date/time from which this certificate is valid, encapsulated in a Date object.

x509.validTo#

Added in: v15.6.0


Type: <string>

The date/time until which this certificate is valid.

x509.validToDate#

Added in: v23.0.0, v22.10.0


Type: <Date>

The date/time until which this certificate is valid, encapsulated in a Date object.

x509.verify(publicKey)#

Added in: v15.6.0


publicKey <KeyObject> A public key.
Returns: <boolean>

Verifies that this certificate was signed by the given public key.
Does not perform any other validation checks on the certificate.

node:crypto module methods and properties#

crypto.checkPrime(candidate[, options], callback)#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v15.8.0
Added in: v15.8.0




candidate <ArrayBuffer> | <SharedArrayBuffer> | <TypedArray> | <Buffer> | <DataView> | <bigint>
A possible prime encoded as a sequence of big endian octets of arbitrary
length.
options <Object>

checks <number> The number of Miller-Rabin probabilistic primality
iterations to perform. When the value is 0 (zero), a number of checks
is used that yields a false positive rate of at most 2-64 for
random input. Care must be used when selecting a number of checks. Refer
to the OpenSSL documentation for the BN_is_prime_ex function nchecks
options for more details. Default: 0


callback <Function>

err <Error> Set to an <Error> object if an error occurred during check.
result <boolean> true if the candidate is a prime with an error
probability less than 0.25 ** options.checks.



Checks the primality of the candidate.

crypto.checkPrimeSync(candidate[, options])#

Added in: v15.8.0


candidate <ArrayBuffer> | <SharedArrayBuffer> | <TypedArray> | <Buffer> | <DataView> | <bigint>
A possible prime encoded as a sequence of big endian octets of arbitrary
length.
options <Object>

checks <number> The number of Miller-Rabin probabilistic primality
iterations to perform. When the value is 0 (zero), a number of checks
is used that yields a false positive rate of at most 2-64 for
random input. Care must be used when selecting a number of checks. Refer
to the OpenSSL documentation for the BN_is_prime_ex function nchecks
options for more details. Default: 0


Returns: <boolean> true if the candidate is a prime with an error
probability less than 0.25 ** options.checks.

Checks the primality of the candidate.

crypto.constants#

Added in: v6.3.0


<Object>

An object containing commonly used constants for crypto and security related
operations. The specific constants currently defined are described in
Crypto constants.

crypto.createCipheriv(algorithm, key, iv[, options])#

History

VersionChanges
v17.9.0, v16.17.0
The authTagLength option is now optional when using the chacha20-poly1305 cipher and defaults to 16 bytes.
v15.0.0
The password and iv arguments can be an ArrayBuffer and are each limited to a maximum of 2 ** 31 - 1 bytes.
v11.6.0
The key argument can now be a KeyObject.
v11.2.0, v10.17.0
The cipher chacha20-poly1305 (the IETF variant of ChaCha20-Poly1305) is now supported.
v10.10.0
Ciphers in OCB mode are now supported.
v10.2.0
The authTagLength option can now be used to produce shorter authentication tags in GCM mode and defaults to 16 bytes.
v9.9.0
The iv parameter may now be null for ciphers which do not need an initialization vector.
v0.1.94
Added in: v0.1.94




algorithm <string>
key <string> | <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView> | <KeyObject> | <CryptoKey>
iv <string> | <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView> | <null>
options <Object> stream.transform options
Returns: <Cipheriv>

Creates and returns a Cipheriv object, with the given algorithm, key and
initialization vector (iv).
The options argument controls stream behavior and is optional except when a
cipher in CCM or OCB mode (e.g. 'aes-128-ccm') is used. In that case, the
authTagLength option is required and specifies the length of the
authentication tag in bytes, see CCM mode. In GCM mode, the authTagLength
option is not required but can be used to set the length of the authentication
tag that will be returned by getAuthTag() and defaults to 16 bytes.
For chacha20-poly1305, the authTagLength option defaults to 16 bytes.
The algorithm is dependent on OpenSSL, examples are 'aes192', etc. On
recent OpenSSL releases, openssl list -cipher-algorithms will
display the available cipher algorithms.
The key is the raw key used by the algorithm and iv is an
initialization vector. Both arguments must be 'utf8' encoded strings,
Buffers, TypedArray, or DataViews. The key may optionally be
a KeyObject of type secret. If the cipher does not need
an initialization vector, iv may be null.
When passing strings for key or iv, please consider
caveats when using strings as inputs to cryptographic APIs.
Initialization vectors should be unpredictable and unique; ideally, they will be
cryptographically random. They do not have to be secret: IVs are typically just
added to ciphertext messages unencrypted. It may sound contradictory that
something has to be unpredictable and unique, but does not have to be secret;
remember that an attacker must not be able to predict ahead of time what a
given IV will be.

crypto.createDecipheriv(algorithm, key, iv[, options])#

History

VersionChanges
v17.9.0, v16.17.0
The authTagLength option is now optional when using the chacha20-poly1305 cipher and defaults to 16 bytes.
v11.6.0
The key argument can now be a KeyObject.
v11.2.0, v10.17.0
The cipher chacha20-poly1305 (the IETF variant of ChaCha20-Poly1305) is now supported.
v10.10.0
Ciphers in OCB mode are now supported.
v10.2.0
The authTagLength option can now be used to restrict accepted GCM authentication tag lengths.
v9.9.0
The iv parameter may now be null for ciphers which do not need an initialization vector.
v0.1.94
Added in: v0.1.94




algorithm <string>
key <string> | <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView> | <KeyObject> | <CryptoKey>
iv <string> | <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView> | <null>
options <Object> stream.transform options
Returns: <Decipheriv>

Creates and returns a Decipheriv object that uses the given algorithm, key
and initialization vector (iv).
The options argument controls stream behavior and is optional except when a
cipher in CCM or OCB mode (e.g. 'aes-128-ccm') is used. In that case, the
authTagLength option is required and specifies the length of the
authentication tag in bytes, see CCM mode.
For AES-GCM and chacha20-poly1305, the authTagLength option defaults to 16
bytes and must be set to a different value if a different length is used.
The algorithm is dependent on OpenSSL, examples are 'aes192', etc. On
recent OpenSSL releases, openssl list -cipher-algorithms will
display the available cipher algorithms.
The key is the raw key used by the algorithm and iv is an
initialization vector. Both arguments must be 'utf8' encoded strings,
Buffers, TypedArray, or DataViews. The key may optionally be
a KeyObject of type secret. If the cipher does not need
an initialization vector, iv may be null.
When passing strings for key or iv, please consider
caveats when using strings as inputs to cryptographic APIs.
Initialization vectors should be unpredictable and unique; ideally, they will be
cryptographically random. They do not have to be secret: IVs are typically just
added to ciphertext messages unencrypted. It may sound contradictory that
something has to be unpredictable and unique, but does not have to be secret;
remember that an attacker must not be able to predict ahead of time what a given
IV will be.

crypto.createDiffieHellman(prime[, primeEncoding][, generator][, generatorEncoding])#

History

VersionChanges
v8.0.0
The prime argument can be any TypedArray or DataView now.
v8.0.0
The prime argument can be a Uint8Array now.
v6.0.0
The default for the encoding parameters changed from binary to utf8.
v0.11.12
Added in: v0.11.12




prime <string> | <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView>
primeEncoding <string> The encoding of the prime string.
generator <number> | <string> | <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView>
Default: 2
generatorEncoding <string> The encoding of the generator string.
Returns: <DiffieHellman>

Creates a DiffieHellman key exchange object using the supplied prime and an
optional specific generator.
The generator argument can be a number, string, or Buffer. If
generator is not specified, the value 2 is used.
If primeEncoding is specified, prime is expected to be a string; otherwise
a Buffer, TypedArray, or DataView is expected.
If generatorEncoding is specified, generator is expected to be a string;
otherwise a number, Buffer, TypedArray, or DataView is expected.

crypto.createDiffieHellman(primeLength[, generator])#

Added in: v0.5.0


primeLength <number>
generator <number> Default: 2
Returns: <DiffieHellman>

Creates a DiffieHellman key exchange object and generates a prime of
primeLength bits using an optional specific numeric generator.
If generator is not specified, the value 2 is used.

crypto.createDiffieHellmanGroup(name)#

Added in: v0.9.3


name <string>
Returns: <DiffieHellmanGroup>

An alias for crypto.getDiffieHellman()

crypto.createECDH(curveName)#

Added in: v0.11.14


curveName <string>
Returns: <ECDH>

Creates an Elliptic Curve Diffie-Hellman (ECDH) key exchange object using a
predefined curve specified by the curveName string. Use
crypto.getCurves() to obtain a list of available curve names. On recent
OpenSSL releases, openssl ecparam -list_curves will also display the name
and description of each available elliptic curve.

crypto.createHash(algorithm[, options])#

History

VersionChanges
v12.8.0
The outputLength option was added for XOF hash functions.
v0.1.92
Added in: v0.1.92




algorithm <string>
options <Object> stream.transform options
Returns: <Hash>

Creates and returns a Hash object that can be used to generate hash digests
using the given algorithm. Optional options argument controls stream
behavior. For XOF hash functions such as 'shake256', the outputLength option
can be used to specify the desired output length in bytes.
The algorithm is dependent on the available algorithms supported by the
version of OpenSSL on the platform. Examples are 'sha256', 'sha512', etc.
On recent releases of OpenSSL, openssl list -digest-algorithms will
display the available digest algorithms.
Example: generating the sha256 sum of a file

import {
  createReadStream,
} from 'node:fs';
import { argv } from 'node:process';
const {
  createHash,
} = await import('node:crypto');

const filename = argv[2];

const hash = createHash('sha256');

const input = createReadStream(filename);
input.on('readable', () => {
  // Only one element is going to be produced by the
  // hash stream.
  const data = input.read();
  if (data)
    hash.update(data);
  else {
    console.log(`${hash.digest('hex')} ${filename}`);
  }
});const {
  createReadStream,
} = require('node:fs');
const {
  createHash,
} = require('node:crypto');
const { argv } = require('node:process');

const filename = argv[2];

const hash = createHash('sha256');

const input = createReadStream(filename);
input.on('readable', () => {
  // Only one element is going to be produced by the
  // hash stream.
  const data = input.read();
  if (data)
    hash.update(data);
  else {
    console.log(`${hash.digest('hex')} ${filename}`);
  }
});copy

crypto.createHmac(algorithm, key[, options])#

History

VersionChanges
v15.0.0
The key can also be an ArrayBuffer or CryptoKey. The encoding option was added. The key cannot contain more than 2 ** 32 - 1 bytes.
v11.6.0
The key argument can now be a KeyObject.
v0.1.94
Added in: v0.1.94




algorithm <string>
key <string> | <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView> | <KeyObject> | <CryptoKey>
options <Object> stream.transform options

encoding <string> The string encoding to use when key is a string.


Returns: <Hmac>

Creates and returns an Hmac object that uses the given algorithm and key.
Optional options argument controls stream behavior.
The algorithm is dependent on the available algorithms supported by the
version of OpenSSL on the platform. Examples are 'sha256', 'sha512', etc.
On recent releases of OpenSSL, openssl list -digest-algorithms will
display the available digest algorithms.
The key is the HMAC key used to generate the cryptographic HMAC hash. If it is
a KeyObject, its type must be secret. If it is a string, please consider
caveats when using strings as inputs to cryptographic APIs. If it was
obtained from a cryptographically secure source of entropy, such as
crypto.randomBytes() or crypto.generateKey(), its length should not
exceed the block size of algorithm (e.g., 512 bits for SHA-256).
Example: generating the sha256 HMAC of a file

import {
  createReadStream,
} from 'node:fs';
import { argv } from 'node:process';
const {
  createHmac,
} = await import('node:crypto');

const filename = argv[2];

const hmac = createHmac('sha256', 'a secret');

const input = createReadStream(filename);
input.on('readable', () => {
  // Only one element is going to be produced by the
  // hash stream.
  const data = input.read();
  if (data)
    hmac.update(data);
  else {
    console.log(`${hmac.digest('hex')} ${filename}`);
  }
});const {
  createReadStream,
} = require('node:fs');
const {
  createHmac,
} = require('node:crypto');
const { argv } = require('node:process');

const filename = argv[2];

const hmac = createHmac('sha256', 'a secret');

const input = createReadStream(filename);
input.on('readable', () => {
  // Only one element is going to be produced by the
  // hash stream.
  const data = input.read();
  if (data)
    hmac.update(data);
  else {
    console.log(`${hmac.digest('hex')} ${filename}`);
  }
});copy

crypto.createPrivateKey(key)#

History

VersionChanges
v15.12.0
The key can also be a JWK object.
v15.0.0
The key can also be an ArrayBuffer. The encoding option was added. The key cannot contain more than 2 ** 32 - 1 bytes.
v11.6.0
Added in: v11.6.0





key <Object> | <string> | <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView>

key: <string> | <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView> | <Object> The key
material, either in PEM, DER, or JWK format.
format: <string> Must be 'pem', 'der', or ''jwk'.
Default: 'pem'.
type: <string> Must be 'pkcs1', 'pkcs8' or 'sec1'. This option is
required only if the format is 'der' and ignored otherwise.
passphrase: <string> | <Buffer> The passphrase to use for decryption.
encoding: <string> The string encoding to use when key is a string.


Returns: <KeyObject>


Creates and returns a new key object containing a private key. If key is a
string or Buffer, format is assumed to be 'pem'; otherwise, key
must be an object with the properties described above.
If the private key is encrypted, a passphrase must be specified. The length
of the passphrase is limited to 1024 bytes.

crypto.createPublicKey(key)#

History

VersionChanges
v15.12.0
The key can also be a JWK object.
v15.0.0
The key can also be an ArrayBuffer. The encoding option was added. The key cannot contain more than 2 ** 32 - 1 bytes.
v11.13.0
The key argument can now be a KeyObject with type private.
v11.7.0
The key argument can now be a private key.
v11.6.0
Added in: v11.6.0





key <Object> | <string> | <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView>

key: <string> | <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView> | <Object> The key
material, either in PEM, DER, or JWK format.
format: <string> Must be 'pem', 'der', or 'jwk'.
Default: 'pem'.
type: <string> Must be 'pkcs1' or 'spki'. This option is
required only if the format is 'der' and ignored otherwise.
encoding <string> The string encoding to use when key is a string.


Returns: <KeyObject>


Creates and returns a new key object containing a public key. If key is a
string or Buffer, format is assumed to be 'pem'; if key is a KeyObject
with type 'private', the public key is derived from the given private key;
otherwise, key must be an object with the properties described above.
If the format is 'pem', the 'key' may also be an X.509 certificate.
Because public keys can be derived from private keys, a private key may be
passed instead of a public key. In that case, this function behaves as if
crypto.createPrivateKey() had been called, except that the type of the
returned KeyObject will be 'public' and that the private key cannot be
extracted from the returned KeyObject. Similarly, if a KeyObject with type
'private' is given, a new KeyObject with type 'public' will be returned
and it will be impossible to extract the private key from the returned object.

crypto.createSecretKey(key[, encoding])#

History

VersionChanges
v18.8.0, v16.18.0
The key can now be zero-length.
v15.0.0
The key can also be an ArrayBuffer or string. The encoding argument was added. The key cannot contain more than 2 ** 32 - 1 bytes.
v11.6.0
Added in: v11.6.0




key <string> | <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView>
encoding <string> The string encoding when key is a string.
Returns: <KeyObject>

Creates and returns a new key object containing a secret key for symmetric
encryption or Hmac.

crypto.createSign(algorithm[, options])#

Added in: v0.1.92


algorithm <string>
options <Object> stream.Writable options
Returns: <Sign>

Creates and returns a Sign object that uses the given algorithm. Use
crypto.getHashes() to obtain the names of the available digest algorithms.
Optional options argument controls the stream.Writable behavior.
In some cases, a Sign instance can be created using the name of a signature
algorithm, such as 'RSA-SHA256', instead of a digest algorithm. This will use
the corresponding digest algorithm. This does not work for all signature
algorithms, such as 'ecdsa-with-SHA256', so it is best to always use digest
algorithm names.

crypto.createVerify(algorithm[, options])#

Added in: v0.1.92


algorithm <string>
options <Object> stream.Writable options
Returns: <Verify>

Creates and returns a Verify object that uses the given algorithm.
Use crypto.getHashes() to obtain an array of names of the available
signing algorithms. Optional options argument controls the
stream.Writable behavior.
In some cases, a Verify instance can be created using the name of a signature
algorithm, such as 'RSA-SHA256', instead of a digest algorithm. This will use
the corresponding digest algorithm. This does not work for all signature
algorithms, such as 'ecdsa-with-SHA256', so it is best to always use digest
algorithm names.

crypto.diffieHellman(options[, callback])#

History

VersionChanges
v23.11.0
Optional callback argument added.
v13.9.0, v12.17.0
Added in: v13.9.0, v12.17.0




options: <Object>

privateKey: <KeyObject>
publicKey: <KeyObject>


callback <Function>

err <Error>
secret <Buffer>


Returns: <Buffer> if the callback function is not provided.

Computes the Diffie-Hellman secret based on a privateKey and a publicKey.
Both keys must have the same asymmetricKeyType, which must be one of 'dh'
(for Diffie-Hellman), 'ec', 'x448', or 'x25519' (for ECDH).
If the callback function is provided this function uses libuv's threadpool.

crypto.fips#

Added in: v6.0.0Deprecated since: v10.0.0

Stability: 0 - Deprecated
Property for checking and controlling whether a FIPS compliant crypto provider
is currently in use. Setting to true requires a FIPS build of Node.js.
This property is deprecated. Please use crypto.setFips() and
crypto.getFips() instead.

crypto.generateKey(type, options, callback)#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v15.0.0
Added in: v15.0.0




type: <string> The intended use of the generated secret key. Currently
accepted values are 'hmac' and 'aes'.
options: <Object>

length: <number> The bit length of the key to generate. This must be a
value greater than 0.

If type is 'hmac', the minimum is 8, and the maximum length is
231-1. If the value is not a multiple of 8, the generated
key will be truncated to Math.floor(length / 8).
If type is 'aes', the length must be one of 128, 192, or 256.




callback: <Function>

err: <Error>
key: <KeyObject>



Asynchronously generates a new random secret key of the given length. The
type will determine which validations will be performed on the length.

const {
  generateKey,
} = await import('node:crypto');

generateKey('hmac', { length: 512 }, (err, key) => {
  if (err) throw err;
  console.log(key.export().toString('hex'));  // 46e..........620
});const {
  generateKey,
} = require('node:crypto');

generateKey('hmac', { length: 512 }, (err, key) => {
  if (err) throw err;
  console.log(key.export().toString('hex'));  // 46e..........620
});copy
The size of a generated HMAC key should not exceed the block size of the
underlying hash function. See crypto.createHmac() for more information.

crypto.generateKeyPair(type, options, callback)#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v16.10.0
Add ability to define RSASSA-PSS-params sequence parameters for RSA-PSS keys pairs.
v13.9.0, v12.17.0
Add support for Diffie-Hellman.
v12.0.0
Add support for RSA-PSS key pairs.
v12.0.0
Add ability to generate X25519 and X448 key pairs.
v12.0.0
Add ability to generate Ed25519 and Ed448 key pairs.
v11.6.0
The generateKeyPair and generateKeyPairSync functions now produce key objects if no encoding was specified.
v10.12.0
Added in: v10.12.0




type: <string> Must be 'rsa', 'rsa-pss', 'dsa', 'ec', 'ed25519',
'ed448', 'x25519', 'x448', or 'dh'.
options: <Object>

modulusLength: <number> Key size in bits (RSA, DSA).
publicExponent: <number> Public exponent (RSA). Default: 0x10001.
hashAlgorithm: <string> Name of the message digest (RSA-PSS).
mgf1HashAlgorithm: <string> Name of the message digest used by
MGF1 (RSA-PSS).
saltLength: <number> Minimal salt length in bytes (RSA-PSS).
divisorLength: <number> Size of q in bits (DSA).
namedCurve: <string> Name of the curve to use (EC).
prime: <Buffer> The prime parameter (DH).
primeLength: <number> Prime length in bits (DH).
generator: <number> Custom generator (DH). Default: 2.
groupName: <string> Diffie-Hellman group name (DH). See
crypto.getDiffieHellman().
paramEncoding: <string> Must be 'named' or 'explicit' (EC).
Default: 'named'.
publicKeyEncoding: <Object> See keyObject.export().
privateKeyEncoding: <Object> See keyObject.export().


callback: <Function>

err: <Error>
publicKey: <string> | <Buffer> | <KeyObject>
privateKey: <string> | <Buffer> | <KeyObject>



Generates a new asymmetric key pair of the given type. RSA, RSA-PSS, DSA, EC,
Ed25519, Ed448, X25519, X448, and DH are currently supported.
If a publicKeyEncoding or privateKeyEncoding was specified, this function
behaves as if keyObject.export() had been called on its result. Otherwise,
the respective part of the key is returned as a KeyObject.
It is recommended to encode public keys as 'spki' and private keys as
'pkcs8' with encryption for long-term storage:

const {
  generateKeyPair,
} = await import('node:crypto');

generateKeyPair('rsa', {
  modulusLength: 4096,
  publicKeyEncoding: {
    type: 'spki',
    format: 'pem',
  },
  privateKeyEncoding: {
    type: 'pkcs8',
    format: 'pem',
    cipher: 'aes-256-cbc',
    passphrase: 'top secret',
  },
}, (err, publicKey, privateKey) => {
  // Handle errors and use the generated key pair.
});const {
  generateKeyPair,
} = require('node:crypto');

generateKeyPair('rsa', {
  modulusLength: 4096,
  publicKeyEncoding: {
    type: 'spki',
    format: 'pem',
  },
  privateKeyEncoding: {
    type: 'pkcs8',
    format: 'pem',
    cipher: 'aes-256-cbc',
    passphrase: 'top secret',
  },
}, (err, publicKey, privateKey) => {
  // Handle errors and use the generated key pair.
});copy
On completion, callback will be called with err set to undefined and
publicKey / privateKey representing the generated key pair.
If this method is invoked as its util.promisify()ed version, it returns
a Promise for an Object with publicKey and privateKey properties.

crypto.generateKeyPairSync(type, options)#

History

VersionChanges
v16.10.0
Add ability to define RSASSA-PSS-params sequence parameters for RSA-PSS keys pairs.
v13.9.0, v12.17.0
Add support for Diffie-Hellman.
v12.0.0
Add support for RSA-PSS key pairs.
v12.0.0
Add ability to generate X25519 and X448 key pairs.
v12.0.0
Add ability to generate Ed25519 and Ed448 key pairs.
v11.6.0
The generateKeyPair and generateKeyPairSync functions now produce key objects if no encoding was specified.
v10.12.0
Added in: v10.12.0




type: <string> Must be 'rsa', 'rsa-pss', 'dsa', 'ec', 'ed25519',
'ed448', 'x25519', 'x448', or 'dh'.
options: <Object>

modulusLength: <number> Key size in bits (RSA, DSA).
publicExponent: <number> Public exponent (RSA). Default: 0x10001.
hashAlgorithm: <string> Name of the message digest (RSA-PSS).
mgf1HashAlgorithm: <string> Name of the message digest used by
MGF1 (RSA-PSS).
saltLength: <number> Minimal salt length in bytes (RSA-PSS).
divisorLength: <number> Size of q in bits (DSA).
namedCurve: <string> Name of the curve to use (EC).
prime: <Buffer> The prime parameter (DH).
primeLength: <number> Prime length in bits (DH).
generator: <number> Custom generator (DH). Default: 2.
groupName: <string> Diffie-Hellman group name (DH). See
crypto.getDiffieHellman().
paramEncoding: <string> Must be 'named' or 'explicit' (EC).
Default: 'named'.
publicKeyEncoding: <Object> See keyObject.export().
privateKeyEncoding: <Object> See keyObject.export().


Returns: <Object>

publicKey: <string> | <Buffer> | <KeyObject>
privateKey: <string> | <Buffer> | <KeyObject>



Generates a new asymmetric key pair of the given type. RSA, RSA-PSS, DSA, EC,
Ed25519, Ed448, X25519, X448, and DH are currently supported.
If a publicKeyEncoding or privateKeyEncoding was specified, this function
behaves as if keyObject.export() had been called on its result. Otherwise,
the respective part of the key is returned as a KeyObject.
When encoding public keys, it is recommended to use 'spki'. When encoding
private keys, it is recommended to use 'pkcs8' with a strong passphrase,
and to keep the passphrase confidential.

const {
  generateKeyPairSync,
} = await import('node:crypto');

const {
  publicKey,
  privateKey,
} = generateKeyPairSync('rsa', {
  modulusLength: 4096,
  publicKeyEncoding: {
    type: 'spki',
    format: 'pem',
  },
  privateKeyEncoding: {
    type: 'pkcs8',
    format: 'pem',
    cipher: 'aes-256-cbc',
    passphrase: 'top secret',
  },
});const {
  generateKeyPairSync,
} = require('node:crypto');

const {
  publicKey,
  privateKey,
} = generateKeyPairSync('rsa', {
  modulusLength: 4096,
  publicKeyEncoding: {
    type: 'spki',
    format: 'pem',
  },
  privateKeyEncoding: {
    type: 'pkcs8',
    format: 'pem',
    cipher: 'aes-256-cbc',
    passphrase: 'top secret',
  },
});copy
The return value { publicKey, privateKey } represents the generated key pair.
When PEM encoding was selected, the respective key will be a string, otherwise
it will be a buffer containing the data encoded as DER.

crypto.generateKeySync(type, options)#

Added in: v15.0.0


type: <string> The intended use of the generated secret key. Currently
accepted values are 'hmac' and 'aes'.
options: <Object>

length: <number> The bit length of the key to generate.

If type is 'hmac', the minimum is 8, and the maximum length is
231-1. If the value is not a multiple of 8, the generated
key will be truncated to Math.floor(length / 8).
If type is 'aes', the length must be one of 128, 192, or 256.




Returns: <KeyObject>

Synchronously generates a new random secret key of the given length. The
type will determine which validations will be performed on the length.

const {
  generateKeySync,
} = await import('node:crypto');

const key = generateKeySync('hmac', { length: 512 });
console.log(key.export().toString('hex'));  // e89..........41econst {
  generateKeySync,
} = require('node:crypto');

const key = generateKeySync('hmac', { length: 512 });
console.log(key.export().toString('hex'));  // e89..........41ecopy
The size of a generated HMAC key should not exceed the block size of the
underlying hash function. See crypto.createHmac() for more information.

crypto.generatePrime(size[, options[, callback]])#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v15.8.0
Added in: v15.8.0




size <number> The size (in bits) of the prime to generate.
options <Object>

add <ArrayBuffer> | <SharedArrayBuffer> | <TypedArray> | <Buffer> | <DataView> | <bigint>
rem <ArrayBuffer> | <SharedArrayBuffer> | <TypedArray> | <Buffer> | <DataView> | <bigint>
safe <boolean> Default: false.
bigint <boolean> When true, the generated prime is returned
as a bigint.


callback <Function>

err <Error>
prime <ArrayBuffer> | <bigint>



Generates a pseudorandom prime of size bits.
If options.safe is true, the prime will be a safe prime -- that is,
(prime - 1) / 2 will also be a prime.
The options.add and options.rem parameters can be used to enforce additional
requirements, e.g., for Diffie-Hellman:

If options.add and options.rem are both set, the prime will satisfy the
condition that prime % add = rem.
If only options.add is set and options.safe is not true, the prime will
satisfy the condition that prime % add = 1.
If only options.add is set and options.safe is set to true, the prime
will instead satisfy the condition that prime % add = 3. This is necessary
because prime % add = 1 for options.add > 2 would contradict the condition
enforced by options.safe.
options.rem is ignored if options.add is not given.

Both options.add and options.rem must be encoded as big-endian sequences
if given as an ArrayBuffer, SharedArrayBuffer, TypedArray, Buffer, or
DataView.
By default, the prime is encoded as a big-endian sequence of octets
in an <ArrayBuffer>. If the bigint option is true, then a <bigint>
is provided.
The size of the prime will have a direct impact on how long it takes to
generate the prime. The larger the size, the longer it will take. Because
we use OpenSSL's BN_generate_prime_ex function, which provides only
minimal control over our ability to interrupt the generation process,
it is not recommended to generate overly large primes, as doing so may make
the process unresponsive.

crypto.generatePrimeSync(size[, options])#

Added in: v15.8.0


size <number> The size (in bits) of the prime to generate.
options <Object>

add <ArrayBuffer> | <SharedArrayBuffer> | <TypedArray> | <Buffer> | <DataView> | <bigint>
rem <ArrayBuffer> | <SharedArrayBuffer> | <TypedArray> | <Buffer> | <DataView> | <bigint>
safe <boolean> Default: false.
bigint <boolean> When true, the generated prime is returned
as a bigint.


Returns: <ArrayBuffer> | <bigint>

Generates a pseudorandom prime of size bits.
If options.safe is true, the prime will be a safe prime -- that is,
(prime - 1) / 2 will also be a prime.
The options.add and options.rem parameters can be used to enforce additional
requirements, e.g., for Diffie-Hellman:

If options.add and options.rem are both set, the prime will satisfy the
condition that prime % add = rem.
If only options.add is set and options.safe is not true, the prime will
satisfy the condition that prime % add = 1.
If only options.add is set and options.safe is set to true, the prime
will instead satisfy the condition that prime % add = 3. This is necessary
because prime % add = 1 for options.add > 2 would contradict the condition
enforced by options.safe.
options.rem is ignored if options.add is not given.

Both options.add and options.rem must be encoded as big-endian sequences
if given as an ArrayBuffer, SharedArrayBuffer, TypedArray, Buffer, or
DataView.
By default, the prime is encoded as a big-endian sequence of octets
in an <ArrayBuffer>. If the bigint option is true, then a <bigint>
is provided.
The size of the prime will have a direct impact on how long it takes to
generate the prime. The larger the size, the longer it will take. Because
we use OpenSSL's BN_generate_prime_ex function, which provides only
minimal control over our ability to interrupt the generation process,
it is not recommended to generate overly large primes, as doing so may make
the process unresponsive.

crypto.getCipherInfo(nameOrNid[, options])#

Added in: v15.0.0


nameOrNid: <string> | <number> The name or nid of the cipher to query.
options: <Object>

keyLength: <number> A test key length.
ivLength: <number> A test IV length.


Returns: <Object>

name <string> The name of the cipher
nid <number> The nid of the cipher
blockSize <number> The block size of the cipher in bytes. This property
is omitted when mode is 'stream'.
ivLength <number> The expected or default initialization vector length in
bytes. This property is omitted if the cipher does not use an initialization
vector.
keyLength <number> The expected or default key length in bytes.
mode <string> The cipher mode. One of 'cbc', 'ccm', 'cfb', 'ctr',
'ecb', 'gcm', 'ocb', 'ofb', 'stream', 'wrap', 'xts'.



Returns information about a given cipher.
Some ciphers accept variable length keys and initialization vectors. By default,
the crypto.getCipherInfo() method will return the default values for these
ciphers. To test if a given key length or iv length is acceptable for given
cipher, use the keyLength and ivLength options. If the given values are
unacceptable, undefined will be returned.

crypto.getCiphers()#

Added in: v0.9.3


Returns: <string[]> An array with the names of the supported cipher
algorithms.


const {
  getCiphers,
} = await import('node:crypto');

console.log(getCiphers()); // ['aes-128-cbc', 'aes-128-ccm', ...]const {
  getCiphers,
} = require('node:crypto');

console.log(getCiphers()); // ['aes-128-cbc', 'aes-128-ccm', ...]copy

crypto.getCurves()#

Added in: v2.3.0


Returns: <string[]> An array with the names of the supported elliptic curves.


const {
  getCurves,
} = await import('node:crypto');

console.log(getCurves()); // ['Oakley-EC2N-3', 'Oakley-EC2N-4', ...]const {
  getCurves,
} = require('node:crypto');

console.log(getCurves()); // ['Oakley-EC2N-3', 'Oakley-EC2N-4', ...]copy

crypto.getDiffieHellman(groupName)#

Added in: v0.7.5


groupName <string>
Returns: <DiffieHellmanGroup>

Creates a predefined DiffieHellmanGroup key exchange object. The
supported groups are listed in the documentation for DiffieHellmanGroup.
The returned object mimics the interface of objects created by
crypto.createDiffieHellman(), but will not allow changing
the keys (with diffieHellman.setPublicKey(), for example). The
advantage of using this method is that the parties do not have to
generate nor exchange a group modulus beforehand, saving both processor
and communication time.
Example (obtaining a shared secret):

const {
  getDiffieHellman,
} = await import('node:crypto');
const alice = getDiffieHellman('modp14');
const bob = getDiffieHellman('modp14');

alice.generateKeys();
bob.generateKeys();

const aliceSecret = alice.computeSecret(bob.getPublicKey(), null, 'hex');
const bobSecret = bob.computeSecret(alice.getPublicKey(), null, 'hex');

/* aliceSecret and bobSecret should be the same */
console.log(aliceSecret === bobSecret);const {
  getDiffieHellman,
} = require('node:crypto');

const alice = getDiffieHellman('modp14');
const bob = getDiffieHellman('modp14');

alice.generateKeys();
bob.generateKeys();

const aliceSecret = alice.computeSecret(bob.getPublicKey(), null, 'hex');
const bobSecret = bob.computeSecret(alice.getPublicKey(), null, 'hex');

/* aliceSecret and bobSecret should be the same */
console.log(aliceSecret === bobSecret);copy

crypto.getFips()#

Added in: v10.0.0


Returns: <number> 1 if and only if a FIPS compliant crypto provider is
currently in use, 0 otherwise. A future semver-major release may change
the return type of this API to a <boolean>.


crypto.getHashes()#

Added in: v0.9.3


Returns: <string[]> An array of the names of the supported hash algorithms,
such as 'RSA-SHA256'. Hash algorithms are also called "digest" algorithms.


const {
  getHashes,
} = await import('node:crypto');

console.log(getHashes()); // ['DSA', 'DSA-SHA', 'DSA-SHA1', ...]const {
  getHashes,
} = require('node:crypto');

console.log(getHashes()); // ['DSA', 'DSA-SHA', 'DSA-SHA1', ...]copy

crypto.getRandomValues(typedArray)#

Added in: v17.4.0


typedArray <Buffer> | <TypedArray> | <DataView> | <ArrayBuffer>
Returns: <Buffer> | <TypedArray> | <DataView> | <ArrayBuffer> Returns typedArray.

A convenient alias for crypto.webcrypto.getRandomValues(). This
implementation is not compliant with the Web Crypto spec, to write
web-compatible code use crypto.webcrypto.getRandomValues() instead.

crypto.hash(algorithm, data[, outputEncoding])#

Added in: v21.7.0, v20.12.0

Stability: 1.2 - Release candidate

algorithm <string> | <undefined>
data <string> | <Buffer> | <TypedArray> | <DataView> When data is a
string, it will be encoded as UTF-8 before being hashed. If a different
input encoding is desired for a string input, user could encode the string
into a TypedArray using either TextEncoder or Buffer.from() and passing
the encoded TypedArray into this API instead.
outputEncoding <string> | <undefined>  Encoding used to encode the
returned digest. Default: 'hex'.
Returns: <string> | <Buffer>

A utility for creating one-shot hash digests of data. It can be faster than
the object-based crypto.createHash() when hashing a smaller amount of data
(<= 5MB) that's readily available. If the data can be big or if it is streamed,
it's still recommended to use crypto.createHash() instead.
The algorithm is dependent on the available algorithms supported by the
version of OpenSSL on the platform. Examples are 'sha256', 'sha512', etc.
On recent releases of OpenSSL, openssl list -digest-algorithms will
display the available digest algorithms.
Example:

const crypto = require('node:crypto');
const { Buffer } = require('node:buffer');

// Hashing a string and return the result as a hex-encoded string.
const string = 'Node.js';
// 10b3493287f831e81a438811a1ffba01f8cec4b7
console.log(crypto.hash('sha1', string));

// Encode a base64-encoded string into a Buffer, hash it and return
// the result as a buffer.
const base64 = 'Tm9kZS5qcw==';
// <Buffer 10 b3 49 32 87 f8 31 e8 1a 43 88 11 a1 ff ba 01 f8 ce c4 b7>
console.log(crypto.hash('sha1', Buffer.from(base64, 'base64'), 'buffer'));import crypto from 'node:crypto';
import { Buffer } from 'node:buffer';

// Hashing a string and return the result as a hex-encoded string.
const string = 'Node.js';
// 10b3493287f831e81a438811a1ffba01f8cec4b7
console.log(crypto.hash('sha1', string));

// Encode a base64-encoded string into a Buffer, hash it and return
// the result as a buffer.
const base64 = 'Tm9kZS5qcw==';
// <Buffer 10 b3 49 32 87 f8 31 e8 1a 43 88 11 a1 ff ba 01 f8 ce c4 b7>
console.log(crypto.hash('sha1', Buffer.from(base64, 'base64'), 'buffer'));copy

crypto.hkdf(digest, ikm, salt, info, keylen, callback)#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v18.8.0, v16.18.0
The input keying material can now be zero-length.
v15.0.0
Added in: v15.0.0




digest <string> The digest algorithm to use.
ikm <string> | <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView> | <KeyObject> The input
keying material. Must be provided but can be zero-length.
salt <string> | <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView> The salt value. Must
be provided but can be zero-length.
info <string> | <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView> Additional info value.
Must be provided but can be zero-length, and cannot be more than 1024 bytes.
keylen <number> The length of the key to generate. Must be greater than 0.
The maximum allowable value is 255 times the number of bytes produced by
the selected digest function (e.g. sha512 generates 64-byte hashes, making
the maximum HKDF output 16320 bytes).
callback <Function>

err <Error>
derivedKey <ArrayBuffer>



HKDF is a simple key derivation function defined in RFC 5869. The given ikm,
salt and info are used with the digest to derive a key of keylen bytes.
The supplied callback function is called with two arguments: err and
derivedKey. If an errors occurs while deriving the key, err will be set;
otherwise err will be null. The successfully generated derivedKey will
be passed to the callback as an <ArrayBuffer>. An error will be thrown if any
of the input arguments specify invalid values or types.

import { Buffer } from 'node:buffer';
const {
  hkdf,
} = await import('node:crypto');

hkdf('sha512', 'key', 'salt', 'info', 64, (err, derivedKey) => {
  if (err) throw err;
  console.log(Buffer.from(derivedKey).toString('hex'));  // '24156e2...5391653'
});const {
  hkdf,
} = require('node:crypto');
const { Buffer } = require('node:buffer');

hkdf('sha512', 'key', 'salt', 'info', 64, (err, derivedKey) => {
  if (err) throw err;
  console.log(Buffer.from(derivedKey).toString('hex'));  // '24156e2...5391653'
});copy

crypto.hkdfSync(digest, ikm, salt, info, keylen)#

History

VersionChanges
v18.8.0, v16.18.0
The input keying material can now be zero-length.
v15.0.0
Added in: v15.0.0




digest <string> The digest algorithm to use.
ikm <string> | <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView> | <KeyObject> The input
keying material. Must be provided but can be zero-length.
salt <string> | <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView> The salt value. Must
be provided but can be zero-length.
info <string> | <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView> Additional info value.
Must be provided but can be zero-length, and cannot be more than 1024 bytes.
keylen <number> The length of the key to generate. Must be greater than 0.
The maximum allowable value is 255 times the number of bytes produced by
the selected digest function (e.g. sha512 generates 64-byte hashes, making
the maximum HKDF output 16320 bytes).
Returns: <ArrayBuffer>

Provides a synchronous HKDF key derivation function as defined in RFC 5869. The
given ikm, salt and info are used with the digest to derive a key of
keylen bytes.
The successfully generated derivedKey will be returned as an <ArrayBuffer>.
An error will be thrown if any of the input arguments specify invalid values or
types, or if the derived key cannot be generated.

import { Buffer } from 'node:buffer';
const {
  hkdfSync,
} = await import('node:crypto');

const derivedKey = hkdfSync('sha512', 'key', 'salt', 'info', 64);
console.log(Buffer.from(derivedKey).toString('hex'));  // '24156e2...5391653'const {
  hkdfSync,
} = require('node:crypto');
const { Buffer } = require('node:buffer');

const derivedKey = hkdfSync('sha512', 'key', 'salt', 'info', 64);
console.log(Buffer.from(derivedKey).toString('hex'));  // '24156e2...5391653'copy

crypto.pbkdf2(password, salt, iterations, keylen, digest, callback)#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v15.0.0
The password and salt arguments can also be ArrayBuffer instances.
v14.0.0
The iterations parameter is now restricted to positive values. Earlier releases treated other values as one.
v8.0.0
The digest parameter is always required now.
v6.0.0
Calling this function without passing the digest parameter is deprecated now and will emit a warning.
v6.0.0
The default encoding for password if it is a string changed from binary to utf8.
v0.5.5
Added in: v0.5.5




password <string> | <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView>
salt <string> | <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView>
iterations <number>
keylen <number>
digest <string>
callback <Function>

err <Error>
derivedKey <Buffer>



Provides an asynchronous Password-Based Key Derivation Function 2 (PBKDF2)
implementation. A selected HMAC digest algorithm specified by digest is
applied to derive a key of the requested byte length (keylen) from the
password, salt and iterations.
The supplied callback function is called with two arguments: err and
derivedKey. If an error occurs while deriving the key, err will be set;
otherwise err will be null. By default, the successfully generated
derivedKey will be passed to the callback as a Buffer. An error will be
thrown if any of the input arguments specify invalid values or types.
The iterations argument must be a number set as high as possible. The
higher the number of iterations, the more secure the derived key will be,
but will take a longer amount of time to complete.
The salt should be as unique as possible. It is recommended that a salt is
random and at least 16 bytes long. See NIST SP 800-132 for details.
When passing strings for password or salt, please consider
caveats when using strings as inputs to cryptographic APIs.

const {
  pbkdf2,
} = await import('node:crypto');

pbkdf2('secret', 'salt', 100000, 64, 'sha512', (err, derivedKey) => {
  if (err) throw err;
  console.log(derivedKey.toString('hex'));  // '3745e48...08d59ae'
});const {
  pbkdf2,
} = require('node:crypto');

pbkdf2('secret', 'salt', 100000, 64, 'sha512', (err, derivedKey) => {
  if (err) throw err;
  console.log(derivedKey.toString('hex'));  // '3745e48...08d59ae'
});copy
An array of supported digest functions can be retrieved using
crypto.getHashes().
This API uses libuv's threadpool, which can have surprising and
negative performance implications for some applications; see the
UV_THREADPOOL_SIZE documentation for more information.

crypto.pbkdf2Sync(password, salt, iterations, keylen, digest)#

History

VersionChanges
v14.0.0
The iterations parameter is now restricted to positive values. Earlier releases treated other values as one.
v6.0.0
Calling this function without passing the digest parameter is deprecated now and will emit a warning.
v6.0.0
The default encoding for password if it is a string changed from binary to utf8.
v0.9.3
Added in: v0.9.3




password <string> | <Buffer> | <TypedArray> | <DataView>
salt <string> | <Buffer> | <TypedArray> | <DataView>
iterations <number>
keylen <number>
digest <string>
Returns: <Buffer>

Provides a synchronous Password-Based Key Derivation Function 2 (PBKDF2)
implementation. A selected HMAC digest algorithm specified by digest is
applied to derive a key of the requested byte length (keylen) from the
password, salt and iterations.
If an error occurs an Error will be thrown, otherwise the derived key will be
returned as a Buffer.
The iterations argument must be a number set as high as possible. The
higher the number of iterations, the more secure the derived key will be,
but will take a longer amount of time to complete.
The salt should be as unique as possible. It is recommended that a salt is
random and at least 16 bytes long. See NIST SP 800-132 for details.
When passing strings for password or salt, please consider
caveats when using strings as inputs to cryptographic APIs.

const {
  pbkdf2Sync,
} = await import('node:crypto');

const key = pbkdf2Sync('secret', 'salt', 100000, 64, 'sha512');
console.log(key.toString('hex'));  // '3745e48...08d59ae'const {
  pbkdf2Sync,
} = require('node:crypto');

const key = pbkdf2Sync('secret', 'salt', 100000, 64, 'sha512');
console.log(key.toString('hex'));  // '3745e48...08d59ae'copy
An array of supported digest functions can be retrieved using
crypto.getHashes().

crypto.privateDecrypt(privateKey, buffer)#

History

VersionChanges
v21.6.2, v20.11.1, v18.19.1
The RSA_PKCS1_PADDING padding was disabled unless the OpenSSL build supports implicit rejection.
v15.0.0
Added string, ArrayBuffer, and CryptoKey as allowable key types. The oaepLabel can be an ArrayBuffer. The buffer can be a string or ArrayBuffer. All types that accept buffers are limited to a maximum of 2 ** 31 - 1 bytes.
v12.11.0
The oaepLabel option was added.
v12.9.0
The oaepHash option was added.
v11.6.0
This function now supports key objects.
v0.11.14
Added in: v0.11.14





privateKey <Object> | <string> | <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView> | <KeyObject> | <CryptoKey>

oaepHash <string> The hash function to use for OAEP padding and MGF1.
Default: 'sha1'
oaepLabel <string> | <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView> The label to
use for OAEP padding. If not specified, no label is used.
padding <crypto.constants> An optional padding value defined in
crypto.constants, which may be: crypto.constants.RSA_NO_PADDING,
crypto.constants.RSA_PKCS1_PADDING, or
crypto.constants.RSA_PKCS1_OAEP_PADDING.


buffer <string> | <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView>
Returns: <Buffer> A new Buffer with the decrypted content.


Decrypts buffer with privateKey. buffer was previously encrypted using
the corresponding public key, for example using crypto.publicEncrypt().
If privateKey is not a KeyObject, this function behaves as if
privateKey had been passed to crypto.createPrivateKey(). If it is an
object, the padding property can be passed. Otherwise, this function uses
RSA_PKCS1_OAEP_PADDING.
Using crypto.constants.RSA_PKCS1_PADDING in crypto.privateDecrypt()
requires OpenSSL to support implicit rejection (rsa_pkcs1_implicit_rejection).
If the version of OpenSSL used by Node.js does not support this feature,
attempting to use RSA_PKCS1_PADDING will fail.

crypto.privateEncrypt(privateKey, buffer)#

History

VersionChanges
v15.0.0
Added string, ArrayBuffer, and CryptoKey as allowable key types. The passphrase can be an ArrayBuffer. The buffer can be a string or ArrayBuffer. All types that accept buffers are limited to a maximum of 2 ** 31 - 1 bytes.
v11.6.0
This function now supports key objects.
v1.1.0
Added in: v1.1.0





privateKey <Object> | <string> | <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView> | <KeyObject> | <CryptoKey>

key <string> | <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView> | <KeyObject> | <CryptoKey>
A PEM encoded private key.
passphrase <string> | <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView> An optional
passphrase for the private key.
padding <crypto.constants> An optional padding value defined in
crypto.constants, which may be: crypto.constants.RSA_NO_PADDING or
crypto.constants.RSA_PKCS1_PADDING.
encoding <string> The string encoding to use when buffer, key,
or passphrase are strings.


buffer <string> | <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView>
Returns: <Buffer> A new Buffer with the encrypted content.


Encrypts buffer with privateKey. The returned data can be decrypted using
the corresponding public key, for example using crypto.publicDecrypt().
If privateKey is not a KeyObject, this function behaves as if
privateKey had been passed to crypto.createPrivateKey(). If it is an
object, the padding property can be passed. Otherwise, this function uses
RSA_PKCS1_PADDING.

crypto.publicDecrypt(key, buffer)#

History

VersionChanges
v15.0.0
Added string, ArrayBuffer, and CryptoKey as allowable key types. The passphrase can be an ArrayBuffer. The buffer can be a string or ArrayBuffer. All types that accept buffers are limited to a maximum of 2 ** 31 - 1 bytes.
v11.6.0
This function now supports key objects.
v1.1.0
Added in: v1.1.0





key <Object> | <string> | <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView> | <KeyObject> | <CryptoKey>

passphrase <string> | <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView> An optional
passphrase for the private key.
padding <crypto.constants> An optional padding value defined in
crypto.constants, which may be: crypto.constants.RSA_NO_PADDING or
crypto.constants.RSA_PKCS1_PADDING.
encoding <string> The string encoding to use when buffer, key,
or passphrase are strings.


buffer <string> | <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView>
Returns: <Buffer> A new Buffer with the decrypted content.


Decrypts buffer with key.buffer was previously encrypted using
the corresponding private key, for example using crypto.privateEncrypt().
If key is not a KeyObject, this function behaves as if
key had been passed to crypto.createPublicKey(). If it is an
object, the padding property can be passed. Otherwise, this function uses
RSA_PKCS1_PADDING.
Because RSA public keys can be derived from private keys, a private key may
be passed instead of a public key.

crypto.publicEncrypt(key, buffer)#

History

VersionChanges
v15.0.0
Added string, ArrayBuffer, and CryptoKey as allowable key types. The oaepLabel and passphrase can be ArrayBuffers. The buffer can be a string or ArrayBuffer. All types that accept buffers are limited to a maximum of 2 ** 31 - 1 bytes.
v12.11.0
The oaepLabel option was added.
v12.9.0
The oaepHash option was added.
v11.6.0
This function now supports key objects.
v0.11.14
Added in: v0.11.14





key <Object> | <string> | <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView> | <KeyObject> | <CryptoKey>

key <string> | <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView> | <KeyObject> | <CryptoKey>
A PEM encoded public or private key, <KeyObject>, or <CryptoKey>.
oaepHash <string> The hash function to use for OAEP padding and MGF1.
Default: 'sha1'
oaepLabel <string> | <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView> The label to
use for OAEP padding. If not specified, no label is used.
passphrase <string> | <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView> An optional
passphrase for the private key.
padding <crypto.constants> An optional padding value defined in
crypto.constants, which may be: crypto.constants.RSA_NO_PADDING,
crypto.constants.RSA_PKCS1_PADDING, or
crypto.constants.RSA_PKCS1_OAEP_PADDING.
encoding <string> The string encoding to use when buffer, key,
oaepLabel, or passphrase are strings.


buffer <string> | <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView>
Returns: <Buffer> A new Buffer with the encrypted content.


Encrypts the content of buffer with key and returns a new
Buffer with encrypted content. The returned data can be decrypted using
the corresponding private key, for example using crypto.privateDecrypt().
If key is not a KeyObject, this function behaves as if
key had been passed to crypto.createPublicKey(). If it is an
object, the padding property can be passed. Otherwise, this function uses
RSA_PKCS1_OAEP_PADDING.
Because RSA public keys can be derived from private keys, a private key may
be passed instead of a public key.

crypto.randomBytes(size[, callback])#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v9.0.0
Passing null as the callback argument now throws ERR_INVALID_CALLBACK.
v0.5.8
Added in: v0.5.8




size <number> The number of bytes to generate.  The size must
not be larger than 2**31 - 1.
callback <Function>

err <Error>
buf <Buffer>


Returns: <Buffer> if the callback function is not provided.

Generates cryptographically strong pseudorandom data. The size argument
is a number indicating the number of bytes to generate.
If a callback function is provided, the bytes are generated asynchronously
and the callback function is invoked with two arguments: err and buf.
If an error occurs, err will be an Error object; otherwise it is null. The
buf argument is a Buffer containing the generated bytes.

// Asynchronous
const {
  randomBytes,
} = await import('node:crypto');

randomBytes(256, (err, buf) => {
  if (err) throw err;
  console.log(`${buf.length} bytes of random data: ${buf.toString('hex')}`);
});// Asynchronous
const {
  randomBytes,
} = require('node:crypto');

randomBytes(256, (err, buf) => {
  if (err) throw err;
  console.log(`${buf.length} bytes of random data: ${buf.toString('hex')}`);
});copy
If the callback function is not provided, the random bytes are generated
synchronously and returned as a Buffer. An error will be thrown if
there is a problem generating the bytes.

// Synchronous
const {
  randomBytes,
} = await import('node:crypto');

const buf = randomBytes(256);
console.log(
  `${buf.length} bytes of random data: ${buf.toString('hex')}`);// Synchronous
const {
  randomBytes,
} = require('node:crypto');

const buf = randomBytes(256);
console.log(
  `${buf.length} bytes of random data: ${buf.toString('hex')}`);copy
The crypto.randomBytes() method will not complete until there is
sufficient entropy available.
This should normally never take longer than a few milliseconds. The only time
when generating the random bytes may conceivably block for a longer period of
time is right after boot, when the whole system is still low on entropy.
This API uses libuv's threadpool, which can have surprising and
negative performance implications for some applications; see the
UV_THREADPOOL_SIZE documentation for more information.
The asynchronous version of crypto.randomBytes() is carried out in a single
threadpool request. To minimize threadpool task length variation, partition
large randomBytes requests when doing so as part of fulfilling a client
request.

crypto.randomFill(buffer[, offset][, size], callback)#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v9.0.0
The buffer argument may be any TypedArray or DataView.
v7.10.0, v6.13.0
Added in: v7.10.0, v6.13.0




buffer <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView> Must be supplied. The
size of the provided buffer must not be larger than 2**31 - 1.
offset <number> Default: 0
size <number> Default: buffer.length - offset. The size must
not be larger than 2**31 - 1.
callback <Function> function(err, buf) {}.

This function is similar to crypto.randomBytes() but requires the first
argument to be a Buffer that will be filled. It also
requires that a callback is passed in.
If the callback function is not provided, an error will be thrown.

import { Buffer } from 'node:buffer';
const { randomFill } = await import('node:crypto');

const buf = Buffer.alloc(10);
randomFill(buf, (err, buf) => {
  if (err) throw err;
  console.log(buf.toString('hex'));
});

randomFill(buf, 5, (err, buf) => {
  if (err) throw err;
  console.log(buf.toString('hex'));
});

// The above is equivalent to the following:
randomFill(buf, 5, 5, (err, buf) => {
  if (err) throw err;
  console.log(buf.toString('hex'));
});const { randomFill } = require('node:crypto');
const { Buffer } = require('node:buffer');

const buf = Buffer.alloc(10);
randomFill(buf, (err, buf) => {
  if (err) throw err;
  console.log(buf.toString('hex'));
});

randomFill(buf, 5, (err, buf) => {
  if (err) throw err;
  console.log(buf.toString('hex'));
});

// The above is equivalent to the following:
randomFill(buf, 5, 5, (err, buf) => {
  if (err) throw err;
  console.log(buf.toString('hex'));
});copy
Any ArrayBuffer, TypedArray, or DataView instance may be passed as
buffer.
While this includes instances of Float32Array and Float64Array, this
function should not be used to generate random floating-point numbers. The
result may contain +Infinity, -Infinity, and NaN, and even if the array
contains finite numbers only, they are not drawn from a uniform random
distribution and have no meaningful lower or upper bounds.

import { Buffer } from 'node:buffer';
const { randomFill } = await import('node:crypto');

const a = new Uint32Array(10);
randomFill(a, (err, buf) => {
  if (err) throw err;
  console.log(Buffer.from(buf.buffer, buf.byteOffset, buf.byteLength)
    .toString('hex'));
});

const b = new DataView(new ArrayBuffer(10));
randomFill(b, (err, buf) => {
  if (err) throw err;
  console.log(Buffer.from(buf.buffer, buf.byteOffset, buf.byteLength)
    .toString('hex'));
});

const c = new ArrayBuffer(10);
randomFill(c, (err, buf) => {
  if (err) throw err;
  console.log(Buffer.from(buf).toString('hex'));
});const { randomFill } = require('node:crypto');
const { Buffer } = require('node:buffer');

const a = new Uint32Array(10);
randomFill(a, (err, buf) => {
  if (err) throw err;
  console.log(Buffer.from(buf.buffer, buf.byteOffset, buf.byteLength)
    .toString('hex'));
});

const b = new DataView(new ArrayBuffer(10));
randomFill(b, (err, buf) => {
  if (err) throw err;
  console.log(Buffer.from(buf.buffer, buf.byteOffset, buf.byteLength)
    .toString('hex'));
});

const c = new ArrayBuffer(10);
randomFill(c, (err, buf) => {
  if (err) throw err;
  console.log(Buffer.from(buf).toString('hex'));
});copy
This API uses libuv's threadpool, which can have surprising and
negative performance implications for some applications; see the
UV_THREADPOOL_SIZE documentation for more information.
The asynchronous version of crypto.randomFill() is carried out in a single
threadpool request. To minimize threadpool task length variation, partition
large randomFill requests when doing so as part of fulfilling a client
request.

crypto.randomFillSync(buffer[, offset][, size])#

History

VersionChanges
v9.0.0
The buffer argument may be any TypedArray or DataView.
v7.10.0, v6.13.0
Added in: v7.10.0, v6.13.0




buffer <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView> Must be supplied. The
size of the provided buffer must not be larger than 2**31 - 1.
offset <number> Default: 0
size <number> Default: buffer.length - offset. The size must
not be larger than 2**31 - 1.
Returns: <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView> The object passed as
buffer argument.

Synchronous version of crypto.randomFill().

import { Buffer } from 'node:buffer';
const { randomFillSync } = await import('node:crypto');

const buf = Buffer.alloc(10);
console.log(randomFillSync(buf).toString('hex'));

randomFillSync(buf, 5);
console.log(buf.toString('hex'));

// The above is equivalent to the following:
randomFillSync(buf, 5, 5);
console.log(buf.toString('hex'));const { randomFillSync } = require('node:crypto');
const { Buffer } = require('node:buffer');

const buf = Buffer.alloc(10);
console.log(randomFillSync(buf).toString('hex'));

randomFillSync(buf, 5);
console.log(buf.toString('hex'));

// The above is equivalent to the following:
randomFillSync(buf, 5, 5);
console.log(buf.toString('hex'));copy
Any ArrayBuffer, TypedArray or DataView instance may be passed as
buffer.

import { Buffer } from 'node:buffer';
const { randomFillSync } = await import('node:crypto');

const a = new Uint32Array(10);
console.log(Buffer.from(randomFillSync(a).buffer,
                        a.byteOffset, a.byteLength).toString('hex'));

const b = new DataView(new ArrayBuffer(10));
console.log(Buffer.from(randomFillSync(b).buffer,
                        b.byteOffset, b.byteLength).toString('hex'));

const c = new ArrayBuffer(10);
console.log(Buffer.from(randomFillSync(c)).toString('hex'));const { randomFillSync } = require('node:crypto');
const { Buffer } = require('node:buffer');

const a = new Uint32Array(10);
console.log(Buffer.from(randomFillSync(a).buffer,
                        a.byteOffset, a.byteLength).toString('hex'));

const b = new DataView(new ArrayBuffer(10));
console.log(Buffer.from(randomFillSync(b).buffer,
                        b.byteOffset, b.byteLength).toString('hex'));

const c = new ArrayBuffer(10);
console.log(Buffer.from(randomFillSync(c)).toString('hex'));copy

crypto.randomInt([min, ]max[, callback])#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v14.10.0, v12.19.0
Added in: v14.10.0, v12.19.0




min <integer> Start of random range (inclusive). Default: 0.
max <integer> End of random range (exclusive).
callback <Function> function(err, n) {}.

Return a random integer n such that min <= n < max.  This
implementation avoids modulo bias.
The range (max - min) must be less than 248. min and max must
be safe integers.
If the callback function is not provided, the random integer is
generated synchronously.

// Asynchronous
const {
  randomInt,
} = await import('node:crypto');

randomInt(3, (err, n) => {
  if (err) throw err;
  console.log(`Random number chosen from (0, 1, 2): ${n}`);
});// Asynchronous
const {
  randomInt,
} = require('node:crypto');

randomInt(3, (err, n) => {
  if (err) throw err;
  console.log(`Random number chosen from (0, 1, 2): ${n}`);
});copy

// Synchronous
const {
  randomInt,
} = await import('node:crypto');

const n = randomInt(3);
console.log(`Random number chosen from (0, 1, 2): ${n}`);// Synchronous
const {
  randomInt,
} = require('node:crypto');

const n = randomInt(3);
console.log(`Random number chosen from (0, 1, 2): ${n}`);copy

// With `min` argument
const {
  randomInt,
} = await import('node:crypto');

const n = randomInt(1, 7);
console.log(`The dice rolled: ${n}`);// With `min` argument
const {
  randomInt,
} = require('node:crypto');

const n = randomInt(1, 7);
console.log(`The dice rolled: ${n}`);copy

crypto.randomUUID([options])#

Added in: v15.6.0, v14.17.0


options <Object>

disableEntropyCache <boolean> By default, to improve performance,
Node.js generates and caches enough
random data to generate up to 128 random UUIDs. To generate a UUID
without using the cache, set disableEntropyCache to true.
Default: false.


Returns: <string>

Generates a random RFC 4122 version 4 UUID. The UUID is generated using a
cryptographic pseudorandom number generator.

crypto.scrypt(password, salt, keylen[, options], callback)#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v15.0.0
The password and salt arguments can also be ArrayBuffer instances.
v12.8.0, v10.17.0
The maxmem value can now be any safe integer.
v10.9.0
The cost, blockSize and parallelization option names have been added.
v10.5.0
Added in: v10.5.0




password <string> | <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView>
salt <string> | <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView>
keylen <number>
options <Object>

cost <number> CPU/memory cost parameter. Must be a power of two greater
than one. Default: 16384.
blockSize <number> Block size parameter. Default: 8.
parallelization <number> Parallelization parameter. Default: 1.
N <number> Alias for cost. Only one of both may be specified.
r <number> Alias for blockSize. Only one of both may be specified.
p <number> Alias for parallelization. Only one of both may be specified.
maxmem <number> Memory upper bound. It is an error when (approximately)
128 * N * r > maxmem. Default: 32 * 1024 * 1024.


callback <Function>

err <Error>
derivedKey <Buffer>



Provides an asynchronous scrypt implementation. Scrypt is a password-based
key derivation function that is designed to be expensive computationally and
memory-wise in order to make brute-force attacks unrewarding.
The salt should be as unique as possible. It is recommended that a salt is
random and at least 16 bytes long. See NIST SP 800-132 for details.
When passing strings for password or salt, please consider
caveats when using strings as inputs to cryptographic APIs.
The callback function is called with two arguments: err and derivedKey.
err is an exception object when key derivation fails, otherwise err is
null. derivedKey is passed to the callback as a Buffer.
An exception is thrown when any of the input arguments specify invalid values
or types.

const {
  scrypt,
} = await import('node:crypto');

// Using the factory defaults.
scrypt('password', 'salt', 64, (err, derivedKey) => {
  if (err) throw err;
  console.log(derivedKey.toString('hex'));  // '3745e48...08d59ae'
});
// Using a custom N parameter. Must be a power of two.
scrypt('password', 'salt', 64, { N: 1024 }, (err, derivedKey) => {
  if (err) throw err;
  console.log(derivedKey.toString('hex'));  // '3745e48...aa39b34'
});const {
  scrypt,
} = require('node:crypto');

// Using the factory defaults.
scrypt('password', 'salt', 64, (err, derivedKey) => {
  if (err) throw err;
  console.log(derivedKey.toString('hex'));  // '3745e48...08d59ae'
});
// Using a custom N parameter. Must be a power of two.
scrypt('password', 'salt', 64, { N: 1024 }, (err, derivedKey) => {
  if (err) throw err;
  console.log(derivedKey.toString('hex'));  // '3745e48...aa39b34'
});copy

crypto.scryptSync(password, salt, keylen[, options])#

History

VersionChanges
v12.8.0, v10.17.0
The maxmem value can now be any safe integer.
v10.9.0
The cost, blockSize and parallelization option names have been added.
v10.5.0
Added in: v10.5.0




password <string> | <Buffer> | <TypedArray> | <DataView>
salt <string> | <Buffer> | <TypedArray> | <DataView>
keylen <number>
options <Object>

cost <number> CPU/memory cost parameter. Must be a power of two greater
than one. Default: 16384.
blockSize <number> Block size parameter. Default: 8.
parallelization <number> Parallelization parameter. Default: 1.
N <number> Alias for cost. Only one of both may be specified.
r <number> Alias for blockSize. Only one of both may be specified.
p <number> Alias for parallelization. Only one of both may be specified.
maxmem <number> Memory upper bound. It is an error when (approximately)
128 * N * r > maxmem. Default: 32 * 1024 * 1024.


Returns: <Buffer>

Provides a synchronous scrypt implementation. Scrypt is a password-based
key derivation function that is designed to be expensive computationally and
memory-wise in order to make brute-force attacks unrewarding.
The salt should be as unique as possible. It is recommended that a salt is
random and at least 16 bytes long. See NIST SP 800-132 for details.
When passing strings for password or salt, please consider
caveats when using strings as inputs to cryptographic APIs.
An exception is thrown when key derivation fails, otherwise the derived key is
returned as a Buffer.
An exception is thrown when any of the input arguments specify invalid values
or types.

const {
  scryptSync,
} = await import('node:crypto');
// Using the factory defaults.

const key1 = scryptSync('password', 'salt', 64);
console.log(key1.toString('hex'));  // '3745e48...08d59ae'
// Using a custom N parameter. Must be a power of two.
const key2 = scryptSync('password', 'salt', 64, { N: 1024 });
console.log(key2.toString('hex'));  // '3745e48...aa39b34'const {
  scryptSync,
} = require('node:crypto');
// Using the factory defaults.

const key1 = scryptSync('password', 'salt', 64);
console.log(key1.toString('hex'));  // '3745e48...08d59ae'
// Using a custom N parameter. Must be a power of two.
const key2 = scryptSync('password', 'salt', 64, { N: 1024 });
console.log(key2.toString('hex'));  // '3745e48...aa39b34'copy

crypto.secureHeapUsed()#

Added in: v15.6.0


Returns: <Object>

total <number> The total allocated secure heap size as specified
using the --secure-heap=n command-line flag.
min <number> The minimum allocation from the secure heap as
specified using the --secure-heap-min command-line flag.
used <number> The total number of bytes currently allocated from
the secure heap.
utilization <number> The calculated ratio of used to total
allocated bytes.




crypto.setEngine(engine[, flags])#

History

VersionChanges
v22.4.0, v20.16.0
Custom engine support in OpenSSL 3 is deprecated.
v0.11.11
Added in: v0.11.11




engine <string>
flags <crypto.constants> Default: crypto.constants.ENGINE_METHOD_ALL

Load and set the engine for some or all OpenSSL functions (selected by flags).
Support for custom engines in OpenSSL is deprecated from OpenSSL 3.
engine could be either an id or a path to the engine's shared library.
The optional flags argument uses ENGINE_METHOD_ALL by default. The flags
is a bit field taking one of or a mix of the following flags (defined in
crypto.constants):

crypto.constants.ENGINE_METHOD_RSA
crypto.constants.ENGINE_METHOD_DSA
crypto.constants.ENGINE_METHOD_DH
crypto.constants.ENGINE_METHOD_RAND
crypto.constants.ENGINE_METHOD_EC
crypto.constants.ENGINE_METHOD_CIPHERS
crypto.constants.ENGINE_METHOD_DIGESTS
crypto.constants.ENGINE_METHOD_PKEY_METHS
crypto.constants.ENGINE_METHOD_PKEY_ASN1_METHS
crypto.constants.ENGINE_METHOD_ALL
crypto.constants.ENGINE_METHOD_NONE


crypto.setFips(bool)#

Added in: v10.0.0


bool <boolean> true to enable FIPS mode.

Enables the FIPS compliant crypto provider in a FIPS-enabled Node.js build.
Throws an error if FIPS mode is not available.

crypto.sign(algorithm, data, key[, callback])#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v15.12.0
Optional callback argument added.
v13.2.0, v12.16.0
This function now supports IEEE-P1363 DSA and ECDSA signatures.
v12.0.0
Added in: v12.0.0





algorithm <string> | <null> | <undefined>
data <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView>
key <Object> | <string> | <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView> | <KeyObject> | <CryptoKey>
callback <Function>

err <Error>
signature <Buffer>


Returns: <Buffer> if the callback function is not provided.


Calculates and returns the signature for data using the given private key and
algorithm. If algorithm is null or undefined, then the algorithm is
dependent upon the key type (especially Ed25519 and Ed448).
If key is not a KeyObject, this function behaves as if key had been
passed to crypto.createPrivateKey(). If it is an object, the following
additional properties can be passed:


dsaEncoding <string> For DSA and ECDSA, this option specifies the
format of the generated signature. It can be one of the following:

'der' (default): DER-encoded ASN.1 signature structure encoding (r, s).
'ieee-p1363': Signature format r || s as proposed in IEEE-P1363.



padding <integer> Optional padding value for RSA, one of the following:

crypto.constants.RSA_PKCS1_PADDING (default)
crypto.constants.RSA_PKCS1_PSS_PADDING

RSA_PKCS1_PSS_PADDING will use MGF1 with the same hash function
used to sign the message as specified in section 3.1 of RFC 4055.


saltLength <integer> Salt length for when padding is
RSA_PKCS1_PSS_PADDING. The special value
crypto.constants.RSA_PSS_SALTLEN_DIGEST sets the salt length to the digest
size, crypto.constants.RSA_PSS_SALTLEN_MAX_SIGN (default) sets it to the
maximum permissible value.


If the callback function is provided this function uses libuv's threadpool.

crypto.subtle#

Added in: v17.4.0


Type: <SubtleCrypto>

A convenient alias for crypto.webcrypto.subtle.

crypto.timingSafeEqual(a, b)#

History

VersionChanges
v15.0.0
The a and b arguments can also be ArrayBuffer.
v6.6.0
Added in: v6.6.0




a <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView>
b <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView>
Returns: <boolean>

This function compares the underlying bytes that represent the given
ArrayBuffer, TypedArray, or DataView instances using a constant-time
algorithm.
This function does not leak timing information that
would allow an attacker to guess one of the values. This is suitable for
comparing HMAC digests or secret values like authentication cookies or
capability urls.
a and b must both be Buffers, TypedArrays, or DataViews, and they
must have the same byte length. An error is thrown if a and b have
different byte lengths.
If at least one of a and b is a TypedArray with more than one byte per
entry, such as Uint16Array, the result will be computed using the platform
byte order.
When both of the inputs are Float32Arrays or
Float64Arrays, this function might return unexpected results due to IEEE 754
encoding of floating-point numbers. In particular, neither x === y nor
Object.is(x, y) implies that the byte representations of two floating-point
numbers x and y are equal.
Use of crypto.timingSafeEqual does not guarantee that the surrounding code
is timing-safe. Care should be taken to ensure that the surrounding code does
not introduce timing vulnerabilities.

crypto.verify(algorithm, data, key, signature[, callback])#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v15.12.0
Optional callback argument added.
v15.0.0
The data, key, and signature arguments can also be ArrayBuffer.
v13.2.0, v12.16.0
This function now supports IEEE-P1363 DSA and ECDSA signatures.
v12.0.0
Added in: v12.0.0





algorithm <string> | <null> | <undefined>
data <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView>
key <Object> | <string> | <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView> | <KeyObject> | <CryptoKey>
signature <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView>
callback <Function>

err <Error>
result <boolean>


Returns: <boolean> true or false depending on the validity of the
signature for the data and public key if the callback function is not
provided.


Verifies the given signature for data using the given key and algorithm. If
algorithm is null or undefined, then the algorithm is dependent upon the
key type (especially Ed25519 and Ed448).
If key is not a KeyObject, this function behaves as if key had been
passed to crypto.createPublicKey(). If it is an object, the following
additional properties can be passed:


dsaEncoding <string> For DSA and ECDSA, this option specifies the
format of the signature. It can be one of the following:

'der' (default): DER-encoded ASN.1 signature structure encoding (r, s).
'ieee-p1363': Signature format r || s as proposed in IEEE-P1363.



padding <integer> Optional padding value for RSA, one of the following:

crypto.constants.RSA_PKCS1_PADDING (default)
crypto.constants.RSA_PKCS1_PSS_PADDING

RSA_PKCS1_PSS_PADDING will use MGF1 with the same hash function
used to sign the message as specified in section 3.1 of RFC 4055.


saltLength <integer> Salt length for when padding is
RSA_PKCS1_PSS_PADDING. The special value
crypto.constants.RSA_PSS_SALTLEN_DIGEST sets the salt length to the digest
size, crypto.constants.RSA_PSS_SALTLEN_MAX_SIGN (default) sets it to the
maximum permissible value.


The signature argument is the previously calculated signature for the data.
Because public keys can be derived from private keys, a private key or a public
key may be passed for key.
If the callback function is provided this function uses libuv's threadpool.

crypto.webcrypto#

Added in: v15.0.0

Type: <Crypto> An implementation of the Web Crypto API standard.
See the Web Crypto API documentation for details.

Notes#

Using strings as inputs to cryptographic APIs#
For historical reasons, many cryptographic APIs provided by Node.js accept
strings as inputs where the underlying cryptographic algorithm works on byte
sequences. These instances include plaintexts, ciphertexts, symmetric keys,
initialization vectors, passphrases, salts, authentication tags,
and additional authenticated data.
When passing strings to cryptographic APIs, consider the following factors.


Not all byte sequences are valid UTF-8 strings. Therefore, when a byte
sequence of length n is derived from a string, its entropy is generally
lower than the entropy of a random or pseudorandom n byte sequence.
For example, no UTF-8 string will result in the byte sequence c0 af. Secret
keys should almost exclusively be random or pseudorandom byte sequences.


Similarly, when converting random or pseudorandom byte sequences to UTF-8
strings, subsequences that do not represent valid code points may be replaced
by the Unicode replacement character (U+FFFD). The byte representation of
the resulting Unicode string may, therefore, not be equal to the byte sequence
that the string was created from.
const original = [0xc0, 0xaf];
const bytesAsString = Buffer.from(original).toString('utf8');
const stringAsBytes = Buffer.from(bytesAsString, 'utf8');
console.log(stringAsBytes);
// Prints '<Buffer ef bf bd ef bf bd>'. copy
The outputs of ciphers, hash functions, signature algorithms, and key
derivation functions are pseudorandom byte sequences and should not be
used as Unicode strings.


When strings are obtained from user input, some Unicode characters can be
represented in multiple equivalent ways that result in different byte
sequences. For example, when passing a user passphrase to a key derivation
function, such as PBKDF2 or scrypt, the result of the key derivation function
depends on whether the string uses composed or decomposed characters. Node.js
does not normalize character representations. Developers should consider using
String.prototype.normalize() on user inputs before passing them to
cryptographic APIs.



Legacy streams API (prior to Node.js 0.10)#
The Crypto module was added to Node.js before there was the concept of a
unified Stream API, and before there were Buffer objects for handling
binary data. As such, many crypto classes have methods not
typically found on other Node.js classes that implement the streams
API (e.g. update(), final(), or digest()). Also, many methods accepted
and returned 'latin1' encoded strings by default rather than Buffers. This
default was changed after Node.js v0.8 to use Buffer objects by default
instead.

Support for weak or compromised algorithms#
The node:crypto module still supports some algorithms which are already
compromised and are not recommended for use. The API also allows
the use of ciphers and hashes with a small key size that are too weak for safe
use.
Users should take full responsibility for selecting the crypto
algorithm and key size according to their security requirements.
Based on the recommendations of NIST SP 800-131A:

MD5 and SHA-1 are no longer acceptable where collision resistance is
required such as digital signatures.
The key used with RSA, DSA, and DH algorithms is recommended to have
at least 2048 bits and that of the curve of ECDSA and ECDH at least
224 bits, to be safe to use for several years.
The DH groups of modp1, modp2 and modp5 have a key size
smaller than 2048 bits and are not recommended.

See the reference for other recommendations and details.
Some algorithms that have known weaknesses and are of little relevance in
practice are only available through the legacy provider, which is not
enabled by default.

CCM mode#
CCM is one of the supported AEAD algorithms. Applications which use this
mode must adhere to certain restrictions when using the cipher API:

The authentication tag length must be specified during cipher creation by
setting the authTagLength option and must be one of 4, 6, 8, 10, 12, 14 or
16 bytes.
The length of the initialization vector (nonce) N must be between 7 and 13
bytes (7 ≤ N ≤ 13).
The length of the plaintext is limited to 2 ** (8 * (15 - N)) bytes.
When decrypting, the authentication tag must be set via setAuthTag() before
calling update().
Otherwise, decryption will fail and final() will throw an error in
compliance with section 2.6 of RFC 3610.
Using stream methods such as write(data), end(data) or pipe() in CCM
mode might fail as CCM cannot handle more than one chunk of data per instance.
When passing additional authenticated data (AAD), the length of the actual
message in bytes must be passed to setAAD() via the plaintextLength
option.
Many crypto libraries include the authentication tag in the ciphertext,
which means that they produce ciphertexts of the length
plaintextLength + authTagLength. Node.js does not include the authentication
tag, so the ciphertext length is always plaintextLength.
This is not necessary if no AAD is used.
As CCM processes the whole message at once, update() must be called exactly
once.
Even though calling update() is sufficient to encrypt/decrypt the message,
applications must call final() to compute or verify the
authentication tag.


import { Buffer } from 'node:buffer';
const {
  createCipheriv,
  createDecipheriv,
  randomBytes,
} = await import('node:crypto');

const key = 'keykeykeykeykeykeykeykey';
const nonce = randomBytes(12);

const aad = Buffer.from('0123456789', 'hex');

const cipher = createCipheriv('aes-192-ccm', key, nonce, {
  authTagLength: 16,
});
const plaintext = 'Hello world';
cipher.setAAD(aad, {
  plaintextLength: Buffer.byteLength(plaintext),
});
const ciphertext = cipher.update(plaintext, 'utf8');
cipher.final();
const tag = cipher.getAuthTag();

// Now transmit { ciphertext, nonce, tag }.

const decipher = createDecipheriv('aes-192-ccm', key, nonce, {
  authTagLength: 16,
});
decipher.setAuthTag(tag);
decipher.setAAD(aad, {
  plaintextLength: ciphertext.length,
});
const receivedPlaintext = decipher.update(ciphertext, null, 'utf8');

try {
  decipher.final();
} catch (err) {
  throw new Error('Authentication failed!', { cause: err });
}

console.log(receivedPlaintext);const { Buffer } = require('node:buffer');
const {
  createCipheriv,
  createDecipheriv,
  randomBytes,
} = require('node:crypto');

const key = 'keykeykeykeykeykeykeykey';
const nonce = randomBytes(12);

const aad = Buffer.from('0123456789', 'hex');

const cipher = createCipheriv('aes-192-ccm', key, nonce, {
  authTagLength: 16,
});
const plaintext = 'Hello world';
cipher.setAAD(aad, {
  plaintextLength: Buffer.byteLength(plaintext),
});
const ciphertext = cipher.update(plaintext, 'utf8');
cipher.final();
const tag = cipher.getAuthTag();

// Now transmit { ciphertext, nonce, tag }.

const decipher = createDecipheriv('aes-192-ccm', key, nonce, {
  authTagLength: 16,
});
decipher.setAuthTag(tag);
decipher.setAAD(aad, {
  plaintextLength: ciphertext.length,
});
const receivedPlaintext = decipher.update(ciphertext, null, 'utf8');

try {
  decipher.final();
} catch (err) {
  throw new Error('Authentication failed!', { cause: err });
}

console.log(receivedPlaintext);copy

FIPS mode#
When using OpenSSL 3, Node.js supports FIPS 140-2 when used with an appropriate
OpenSSL 3 provider, such as the FIPS provider from OpenSSL 3 which can be
installed by following the instructions in OpenSSL's FIPS README file.
For FIPS support in Node.js you will need:

A correctly installed OpenSSL 3 FIPS provider.
An OpenSSL 3 FIPS module configuration file.
An OpenSSL 3 configuration file that references the FIPS module
configuration file.

Node.js will need to be configured with an OpenSSL configuration file that
points to the FIPS provider. An example configuration file looks like this:
nodejs_conf = nodejs_init

.include /<absolute path>/fipsmodule.cnf

[nodejs_init]
providers = provider_sect

[provider_sect]
default = default_sect
# The fips section name should match the section name inside the
# included fipsmodule.cnf.
fips = fips_sect

[default_sect]
activate = 1 copy
where fipsmodule.cnf is the FIPS module configuration file generated from the
FIPS provider installation step:
openssl fipsinstall copy
Set the OPENSSL_CONF environment variable to point to
your configuration file and OPENSSL_MODULES to the location of the FIPS
provider dynamic library. e.g.
export OPENSSL_CONF=/<path to configuration file>/nodejs.cnf
export OPENSSL_MODULES=/<path to openssl lib>/ossl-modules copy
FIPS mode can then be enabled in Node.js either by:

Starting Node.js with --enable-fips or --force-fips command line flags.
Programmatically calling crypto.setFips(true).

Optionally FIPS mode can be enabled in Node.js via the OpenSSL configuration
file. e.g.
nodejs_conf = nodejs_init

.include /<absolute path>/fipsmodule.cnf

[nodejs_init]
providers = provider_sect
alg_section = algorithm_sect

[provider_sect]
default = default_sect
# The fips section name should match the section name inside the
# included fipsmodule.cnf.
fips = fips_sect

[default_sect]
activate = 1

[algorithm_sect]
default_properties = fips=yes copy

Crypto constants#
The following constants exported by crypto.constants apply to various uses of
the node:crypto, node:tls, and node:https modules and are generally
specific to OpenSSL.

OpenSSL options#
See the list of SSL OP Flags for details.

  
    Constant
    Description
  
  
    SSL_OP_ALL
    Applies multiple bug workarounds within OpenSSL. See
    https://www.openssl.org/docs/man3.0/man3/SSL_CTX_set_options.html
    for detail.
  
  
    SSL_OP_ALLOW_NO_DHE_KEX
    Instructs OpenSSL to allow a non-[EC]DHE-based key exchange mode
    for TLS v1.3
  
  
    SSL_OP_ALLOW_UNSAFE_LEGACY_RENEGOTIATION
    Allows legacy insecure renegotiation between OpenSSL and unpatched
    clients or servers. See
    https://www.openssl.org/docs/man3.0/man3/SSL_CTX_set_options.html.
  
  
    SSL_OP_CIPHER_SERVER_PREFERENCE
    Attempts to use the server's preferences instead of the client's when
    selecting a cipher. Behavior depends on protocol version. See
    https://www.openssl.org/docs/man3.0/man3/SSL_CTX_set_options.html.
  
  
    SSL_OP_CISCO_ANYCONNECT
    Instructs OpenSSL to use Cisco's version identifier of DTLS_BAD_VER.
  
  
    SSL_OP_COOKIE_EXCHANGE
    Instructs OpenSSL to turn on cookie exchange.
  
  
    SSL_OP_CRYPTOPRO_TLSEXT_BUG
    Instructs OpenSSL to add server-hello extension from an early version
    of the cryptopro draft.
  
  
    SSL_OP_DONT_INSERT_EMPTY_FRAGMENTS
    Instructs OpenSSL to disable a SSL 3.0/TLS 1.0 vulnerability
    workaround added in OpenSSL 0.9.6d.
  
  
    SSL_OP_LEGACY_SERVER_CONNECT
    Allows initial connection to servers that do not support RI.
  
  
    SSL_OP_NO_COMPRESSION
    Instructs OpenSSL to disable support for SSL/TLS compression.
  
  
    SSL_OP_NO_ENCRYPT_THEN_MAC
    Instructs OpenSSL to disable encrypt-then-MAC.
  
  
    SSL_OP_NO_QUERY_MTU
    
  
  
    SSL_OP_NO_RENEGOTIATION
    Instructs OpenSSL to disable renegotiation.
  
  
    SSL_OP_NO_SESSION_RESUMPTION_ON_RENEGOTIATION
    Instructs OpenSSL to always start a new session when performing
    renegotiation.
  
  
    SSL_OP_NO_SSLv2
    Instructs OpenSSL to turn off SSL v2
  
  
    SSL_OP_NO_SSLv3
    Instructs OpenSSL to turn off SSL v3
  
  
    SSL_OP_NO_TICKET
    Instructs OpenSSL to disable use of RFC4507bis tickets.
  
  
    SSL_OP_NO_TLSv1
    Instructs OpenSSL to turn off TLS v1
  
  
    SSL_OP_NO_TLSv1_1
    Instructs OpenSSL to turn off TLS v1.1
  
  
    SSL_OP_NO_TLSv1_2
    Instructs OpenSSL to turn off TLS v1.2
  
  
    SSL_OP_NO_TLSv1_3
    Instructs OpenSSL to turn off TLS v1.3
  
  
    SSL_OP_PRIORITIZE_CHACHA
    Instructs OpenSSL server to prioritize ChaCha20-Poly1305
    when the client does.
    This option has no effect if
    SSL_OP_CIPHER_SERVER_PREFERENCE
    is not enabled.
  
  
    SSL_OP_TLS_ROLLBACK_BUG
    Instructs OpenSSL to disable version rollback attack detection.
  


OpenSSL engine constants#

  
    Constant
    Description
  
  
    ENGINE_METHOD_RSA
    Limit engine usage to RSA
  
  
    ENGINE_METHOD_DSA
    Limit engine usage to DSA
  
  
    ENGINE_METHOD_DH
    Limit engine usage to DH
  
  
    ENGINE_METHOD_RAND
    Limit engine usage to RAND
  
  
    ENGINE_METHOD_EC
    Limit engine usage to EC
  
  
    ENGINE_METHOD_CIPHERS
    Limit engine usage to CIPHERS
  
  
    ENGINE_METHOD_DIGESTS
    Limit engine usage to DIGESTS
  
  
    ENGINE_METHOD_PKEY_METHS
    Limit engine usage to PKEY_METHS
  
  
    ENGINE_METHOD_PKEY_ASN1_METHS
    Limit engine usage to PKEY_ASN1_METHS
  
  
    ENGINE_METHOD_ALL
    
  
  
    ENGINE_METHOD_NONE
    
  


Other OpenSSL constants#

  
    Constant
    Description
  
  
    DH_CHECK_P_NOT_SAFE_PRIME
    
  
  
    DH_CHECK_P_NOT_PRIME
    
  
  
    DH_UNABLE_TO_CHECK_GENERATOR
    
  
  
    DH_NOT_SUITABLE_GENERATOR
    
  
  
    RSA_PKCS1_PADDING
    
  
  
    RSA_SSLV23_PADDING
    
  
  
    RSA_NO_PADDING
    
  
  
    RSA_PKCS1_OAEP_PADDING
    
  
  
    RSA_X931_PADDING
    
  
  
    RSA_PKCS1_PSS_PADDING
    
  
  
    RSA_PSS_SALTLEN_DIGEST
    Sets the salt length for RSA_PKCS1_PSS_PADDING to the
        digest size when signing or verifying.
  
  
    RSA_PSS_SALTLEN_MAX_SIGN
    Sets the salt length for RSA_PKCS1_PSS_PADDING to the
        maximum permissible value when signing data.
  
  
    RSA_PSS_SALTLEN_AUTO
    Causes the salt length for RSA_PKCS1_PSS_PADDING to be
        determined automatically when verifying a signature.
  
  
    POINT_CONVERSION_COMPRESSED
    
  
  
    POINT_CONVERSION_UNCOMPRESSED
    
  
  
    POINT_CONVERSION_HYBRID
    
  


Node.js crypto constants#

  
    Constant
    Description
  
  
    defaultCoreCipherList
    Specifies the built-in default cipher list used by Node.js.
  
  
    defaultCipherList
    Specifies the active default cipher list used by the current Node.js
    process.\n\n\n\nNode.js
        
      
      
About this documentation
Usage and example



Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Modules: TypeScript
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
Readline
REPL
Report
Single executable applications
SQLite
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker

    

    
      
        
          Node.js v24.0.1 documentation
          
            
            
          
        
        
          
            Node.js v24.0.1
            
    
      
        
        Table of contents
      

      
Debugger

Watchers
Command reference

Stepping
Breakpoints
Information
Execution control
Various


Advanced usage

V8 inspector integration for Node.js





    
  
            
    
      
        
        Index
      

      
About this documentation
Usage and example

      
        Index
      
    
  


Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Modules: TypeScript
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
Readline
REPL
Report
Single executable applications
SQLite
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker

    
  
            
    
      
        
        Other versions
      
      24.x
23.x
22.x LTS
21.x
20.x LTS
19.x
18.x
17.x
16.x
15.x
14.x
13.x
12.x
11.x
10.x
9.x
8.x
7.x
6.x
5.x
4.x
0.12.x
0.10.x
    
  
            
              
                
                Options
              
        
              
                
                  
                    View on single page
                  
                  
                    View as JSON
                  
                  Edit on GitHub    
                
              
            
          
        
        
      

      Table of contents
Debugger

Watchers
Command reference

Stepping
Breakpoints
Information
Execution control
Various


Advanced usage

V8 inspector integration for Node.js






      
        Debugger#

Stability: 2 - Stable

Node.js includes a command-line debugging utility. The Node.js debugger client
is not a full-featured debugger, but simple stepping and inspection are
possible.
To use it, start Node.js with the inspect argument followed by the path to the
script to debug.
$ node inspect myscript.js
< Debugger listening on ws://127.0.0.1:9229/621111f9-ffcb-4e82-b718-48a145fa5db8
< For help, see: https://nodejs.org/en/docs/inspector
<
connecting to 127.0.0.1:9229 ... ok
< Debugger attached.
<
 ok
Break on start in myscript.js:2
  1 // myscript.js
> 2 global.x = 5;
  3 setTimeout(() => {
  4   debugger;
debug> copy
The debugger automatically breaks on the first executable line. To instead
run until the first breakpoint (specified by a debugger statement), set
the NODE_INSPECT_RESUME_ON_START environment variable to 1.
$ cat myscript.js
// myscript.js
global.x = 5;
setTimeout(() => {
  debugger;
  console.log('world');
}, 1000);
console.log('hello');
$ NODE_INSPECT_RESUME_ON_START=1 node inspect myscript.js
< Debugger listening on ws://127.0.0.1:9229/f1ed133e-7876-495b-83ae-c32c6fc319c2
< For help, see: https://nodejs.org/en/docs/inspector
<
connecting to 127.0.0.1:9229 ... ok
< Debugger attached.
<
< hello
<
break in myscript.js:4
  2 global.x = 5;
  3 setTimeout(() => {
> 4   debugger;
  5   console.log('world');
  6 }, 1000);
debug> next
break in myscript.js:5
  3 setTimeout(() => {
  4   debugger;
> 5   console.log('world');
  6 }, 1000);
  7 console.log('hello');
debug> repl
Press Ctrl+C to leave debug repl
> x
5
> 2 + 2
4
debug> next
< world
<
break in myscript.js:6
  4   debugger;
  5   console.log('world');
> 6 }, 1000);
  7 console.log('hello');
  8
debug> .exit
$ copy
The repl command allows code to be evaluated remotely. The next command
steps to the next line. Type help to see what other commands are available.
Pressing enter without typing a command will repeat the previous debugger
command.
Watchers#
It is possible to watch expression and variable values while debugging. On
every breakpoint, each expression from the watchers list will be evaluated
in the current context and displayed immediately before the breakpoint's
source code listing.
To begin watching an expression, type watch('my_expression'). The command
watchers will print the active watchers. To remove a watcher, type
unwatch('my_expression').
Command reference#

Stepping#

cont, c: Continue execution
next, n: Step next
step, s: Step in
out, o: Step out
pause: Pause running code (like pause button in Developer Tools)


Breakpoints#

setBreakpoint(), sb(): Set breakpoint on current line
setBreakpoint(line), sb(line): Set breakpoint on specific line
setBreakpoint('fn()'), sb(...): Set breakpoint on a first statement in
function's body
setBreakpoint('script.js', 1), sb(...): Set breakpoint on first line of
script.js
setBreakpoint('script.js', 1, 'num < 4'), sb(...): Set conditional
breakpoint on first line of script.js that only breaks when num < 4
evaluates to true
clearBreakpoint('script.js', 1), cb(...): Clear breakpoint in script.js
on line 1

It is also possible to set a breakpoint in a file (module) that
is not loaded yet:
$ node inspect main.js
< Debugger listening on ws://127.0.0.1:9229/48a5b28a-550c-471b-b5e1-d13dd7165df9
< For help, see: https://nodejs.org/en/docs/inspector
<
connecting to 127.0.0.1:9229 ... ok
< Debugger attached.
<
Break on start in main.js:1
> 1 const mod = require('./mod.js');
  2 mod.hello();
  3 mod.hello();
debug> setBreakpoint('mod.js', 22)
Warning: script 'mod.js' was not loaded yet.
debug> c
break in mod.js:22
 20 // USE OR OTHER DEALINGS IN THE SOFTWARE.
 21
>22 exports.hello = function() {
 23   return 'hello from module';
 24 };
debug> copy
It is also possible to set a conditional breakpoint that only breaks when a
given expression evaluates to true:
$ node inspect main.js
< Debugger listening on ws://127.0.0.1:9229/ce24daa8-3816-44d4-b8ab-8273c8a66d35
< For help, see: https://nodejs.org/en/docs/inspector
<
connecting to 127.0.0.1:9229 ... ok
< Debugger attached.
Break on start in main.js:7
  5 }
  6
> 7 addOne(10);
  8 addOne(-1);
  9
debug> setBreakpoint('main.js', 4, 'num < 0')
  1 'use strict';
  2
  3 function addOne(num) {
> 4   return num + 1;
  5 }
  6
  7 addOne(10);
  8 addOne(-1);
  9
debug> cont
break in main.js:4
  2
  3 function addOne(num) {
> 4   return num + 1;
  5 }
  6
debug> exec('num')
-1
debug> copy

Information#

backtrace, bt: Print backtrace of current execution frame
list(5): List scripts source code with 5 line context (5 lines before and
after)
watch(expr): Add expression to watch list
unwatch(expr): Remove expression from watch list
unwatch(index): Remove expression at specific index from watch list
watchers: List all watchers and their values (automatically listed on each
breakpoint)
repl: Open debugger's repl for evaluation in debugging script's context
exec expr, p expr: Execute an expression in debugging script's context and
print its value
profile: Start CPU profiling session
profileEnd: Stop current CPU profiling session
profiles: List all completed CPU profiling sessions
profiles[n].save(filepath = 'node.cpuprofile'): Save CPU profiling session
to disk as JSON
takeHeapSnapshot(filepath = 'node.heapsnapshot'): Take a heap snapshot
and save to disk as JSON


Execution control#

run: Run script (automatically runs on debugger's start)
restart: Restart script
kill: Kill script


Various#

scripts: List all loaded scripts
version: Display V8's version


Advanced usage#

V8 inspector integration for Node.js#
V8 Inspector integration allows attaching Chrome DevTools to Node.js
instances for debugging and profiling. It uses the
Chrome DevTools Protocol.
V8 Inspector can be enabled by passing the --inspect flag when starting a
Node.js application. It is also possible to supply a custom port with that flag,
e.g. --inspect=9222 will accept DevTools connections on port 9222.
Using the --inspect flag will execute the code immediately before debugger is connected.
This means that the code will start running before you can start debugging, which might
not be ideal if you want to debug from the very beginning.
In such cases, you have two alternatives:

--inspect-wait flag: This flag will wait for debugger to be attached before executing the code.
This allows you to start debugging right from the beginning of the execution.
--inspect-brk flag: Unlike --inspect, this flag will break on the first line of the code
as soon as debugger is attached. This is useful when you want to debug the code step by step
from the very beginning, without any code execution prior to debugging.

So, when deciding between --inspect, --inspect-wait, and --inspect-brk, consider whether you want
the code to start executing immediately, wait for debugger to be attached before execution,
or break on the first line for step-by-step debugging.
$ node --inspect index.js
Debugger listening on ws://127.0.0.1:9229/dc9010dd-f8b8-4ac5-a510-c1a114ec7d29
For help, see: https://nodejs.org/en/docs/inspector copy
(In the example above, the UUID dc9010dd-f8b8-4ac5-a510-c1a114ec7d29
at the end of the URL is generated on the fly, it varies in different
debugging sessions.)
If the Chrome browser is older than 66.0.3345.0,
use inspector.html instead of js_app.html in the above URL.
Chrome DevTools doesn't support debugging worker threads yet.
ndb can be used to debug them.\n\n\n\nNode.js
        
      
      
About this documentation
Usage and example



Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Modules: TypeScript
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
Readline
REPL
Report
Single executable applications
SQLite
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker

    

    
      
        
          Node.js v24.0.1 documentation
          
            
            
          
        
        
          
            Node.js v24.0.1
            
    
      
        
        Table of contents
      

      
Deprecated APIs

Revoking deprecations
List of deprecated APIs

DEP0001: http.OutgoingMessage.prototype.flush
DEP0002: require('_linklist')
DEP0003: _writableState.buffer
DEP0004: CryptoStream.prototype.readyState
DEP0005: Buffer() constructor
DEP0006: child_process options.customFds
DEP0007: Replace cluster worker.suicide with worker.exitedAfterDisconnect
DEP0008: require('node:constants')
DEP0009: crypto.pbkdf2 without digest
DEP0010: crypto.createCredentials
DEP0011: crypto.Credentials
DEP0012: Domain.dispose
DEP0013: fs asynchronous function without callback
DEP0014: fs.read legacy String interface
DEP0015: fs.readSync legacy String interface
DEP0016: GLOBAL/root
DEP0017: Intl.v8BreakIterator
DEP0018: Unhandled promise rejections
DEP0019: require('.') resolved outside directory
DEP0020: Server.connections
DEP0021: Server.listenFD
DEP0022: os.tmpDir()
DEP0023: os.getNetworkInterfaces()
DEP0024: REPLServer.prototype.convertToContext()
DEP0025: require('node:sys')
DEP0026: util.print()
DEP0027: util.puts()
DEP0028: util.debug()
DEP0029: util.error()
DEP0030: SlowBuffer
DEP0031: ecdh.setPublicKey()
DEP0032: node:domain module
DEP0033: EventEmitter.listenerCount()
DEP0034: fs.exists(path, callback)
DEP0035: fs.lchmod(path, mode, callback)
DEP0036: fs.lchmodSync(path, mode)
DEP0037: fs.lchown(path, uid, gid, callback)
DEP0038: fs.lchownSync(path, uid, gid)
DEP0039: require.extensions
DEP0040: node:punycode module
DEP0041: NODE_REPL_HISTORY_FILE environment variable
DEP0042: tls.CryptoStream
DEP0043: tls.SecurePair
DEP0044: util.isArray()
DEP0045: util.isBoolean()
DEP0046: util.isBuffer()
DEP0047: util.isDate()
DEP0048: util.isError()
DEP0049: util.isFunction()
DEP0050: util.isNull()
DEP0051: util.isNullOrUndefined()
DEP0052: util.isNumber()
DEP0053: util.isObject()
DEP0054: util.isPrimitive()
DEP0055: util.isRegExp()
DEP0056: util.isString()
DEP0057: util.isSymbol()
DEP0058: util.isUndefined()
DEP0059: util.log()
DEP0060: util._extend()
DEP0061: fs.SyncWriteStream
DEP0062: node --debug
DEP0063: ServerResponse.prototype.writeHeader()
DEP0064: tls.createSecurePair()
DEP0065: repl.REPL_MODE_MAGIC and NODE_REPL_MODE=magic
DEP0066: OutgoingMessage.prototype._headers, OutgoingMessage.prototype._headerNames
DEP0067: OutgoingMessage.prototype._renderHeaders
DEP0068: node debug
DEP0069: vm.runInDebugContext(string)
DEP0070: async_hooks.currentId()
DEP0071: async_hooks.triggerId()
DEP0072: async_hooks.AsyncResource.triggerId()
DEP0073: Several internal properties of net.Server
DEP0074: REPLServer.bufferedCommand
DEP0075: REPLServer.parseREPLKeyword()
DEP0076: tls.parseCertString()
DEP0077: Module._debug()
DEP0078: REPLServer.turnOffEditorMode()
DEP0079: Custom inspection function on objects via .inspect()
DEP0080: path._makeLong()
DEP0081: fs.truncate() using a file descriptor
DEP0082: REPLServer.prototype.memory()
DEP0083: Disabling ECDH by setting ecdhCurve to false
DEP0084: requiring bundled internal dependencies
DEP0085: AsyncHooks sensitive API
DEP0086: Remove runInAsyncIdScope
DEP0089: require('node:assert')
DEP0090: Invalid GCM authentication tag lengths
DEP0091: crypto.DEFAULT_ENCODING
DEP0092: Top-level this bound to module.exports
DEP0093: crypto.fips is deprecated and replaced
DEP0094: Using assert.fail() with more than one argument
DEP0095: timers.enroll()
DEP0096: timers.unenroll()
DEP0097: MakeCallback with domain property
DEP0098: AsyncHooks embedder AsyncResource.emitBefore and AsyncResource.emitAfter APIs
DEP0099: Async context-unaware node::MakeCallback C++ APIs
DEP0100: process.assert()
DEP0101: --with-lttng
DEP0102: Using noAssert in Buffer#(read|write) operations
DEP0103: process.binding('util').is[...] typechecks
DEP0104: process.env string coercion
DEP0105: decipher.finaltol
DEP0106: crypto.createCipher and crypto.createDecipher
DEP0107: tls.convertNPNProtocols()
DEP0108: zlib.bytesRead
DEP0109: http, https, and tls support for invalid URLs
DEP0110: vm.Script cached data
DEP0111: process.binding()
DEP0112: dgram private APIs
DEP0113: Cipher.setAuthTag(), Decipher.getAuthTag()
DEP0114: crypto._toBuf()
DEP0115: crypto.prng(), crypto.pseudoRandomBytes(), crypto.rng()
DEP0116: Legacy URL API
DEP0117: Native crypto handles
DEP0118: dns.lookup() support for a falsy host name
DEP0119: process.binding('uv').errname() private API
DEP0120: Windows Performance Counter support
DEP0121: net._setSimultaneousAccepts()
DEP0122: tls Server.prototype.setOptions()
DEP0123: setting the TLS ServerName to an IP address
DEP0124: using REPLServer.rli
DEP0125: require('node:_stream_wrap')
DEP0126: timers.active()
DEP0127: timers._unrefActive()
DEP0128: modules with an invalid main entry and an index.js file
DEP0129: ChildProcess._channel
DEP0130: Module.createRequireFromPath()
DEP0131: Legacy HTTP parser
DEP0132: worker.terminate() with callback
DEP0133: http connection
DEP0134: process._tickCallback
DEP0135: WriteStream.open() and ReadStream.open() are internal
DEP0136: http finished
DEP0137: Closing fs.FileHandle on garbage collection
DEP0138: process.mainModule
DEP0139: process.umask() with no arguments
DEP0140: Use request.destroy() instead of request.abort()
DEP0141: repl.inputStream and repl.outputStream
DEP0142: repl._builtinLibs
DEP0143: Transform._transformState
DEP0144: module.parent
DEP0145: socket.bufferSize
DEP0146: new crypto.Certificate()
DEP0147: fs.rmdir(path, { recursive: true })
DEP0148: Folder mappings in "exports" (trailing "/")
DEP0149: http.IncomingMessage#connection
DEP0150: Changing the value of process.config
DEP0151: Main index lookup and extension searching
DEP0152: Extension PerformanceEntry properties
DEP0153: dns.lookup and dnsPromises.lookup options type coercion
DEP0154: RSA-PSS generate key pair options
DEP0155: Trailing slashes in pattern specifier resolutions
DEP0156: .aborted property and 'abort', 'aborted' event in http
DEP0157: Thenable support in streams
DEP0158: buffer.slice(start, end)
DEP0159: ERR_INVALID_CALLBACK
DEP0160: process.on('multipleResolves', handler)
DEP0161: process._getActiveRequests() and process._getActiveHandles()
DEP0162: fs.write(), fs.writeFileSync() coercion to string
DEP0163: channel.subscribe(onMessage), channel.unsubscribe(onMessage)
DEP0164: process.exit(code), process.exitCode coercion to integer
DEP0165: --trace-atomics-wait
DEP0166: Double slashes in imports and exports targets
DEP0167: Weak DiffieHellmanGroup instances (modp1, modp2, modp5)
DEP0168: Unhandled exception in Node-API callbacks
DEP0169: Insecure url.parse()
DEP0170: Invalid port when using url.parse()
DEP0171: Setters for http.IncomingMessage headers and trailers
DEP0172: The asyncResource property of AsyncResource bound functions
DEP0173: the assert.CallTracker class
DEP0174: calling promisify on a function that returns a Promise
DEP0175: util.toUSVString
DEP0176: fs.F_OK, fs.R_OK, fs.W_OK, fs.X_OK
DEP0177: util.types.isWebAssemblyCompiledModule
DEP0178: dirent.path
DEP0179: Hash constructor
DEP0180: fs.Stats constructor
DEP0181: Hmac constructor
DEP0182: Short GCM authentication tags without explicit authTagLength
DEP0183: OpenSSL engine-based APIs
DEP0184: Instantiating node:zlib classes without new
DEP0185: Instantiating node:repl classes without new
DEP0187: Passing invalid argument types to fs.existsSync
DEP0188: process.features.ipv6 and process.features.uv
DEP0189: process.features.tls_*
DEP0190: Passing args to node:child_process execFile/spawn with shell option true
DEP0191: repl.builtinModules





    
  
            
    
      
        
        Index
      

      
About this documentation
Usage and example

      
        Index
      
    
  


Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Modules: TypeScript
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
Readline
REPL
Report
Single executable applications
SQLite
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker

    
  
            
    
      
        
        Other versions
      
      24.x
23.x
22.x LTS
21.x
20.x LTS
19.x
18.x
17.x
16.x
15.x
14.x
13.x
12.x
11.x
10.x
9.x
8.x
7.x
    
  
            
              
                
                Options
              
        
              
                
                  
                    View on single page
                  
                  
                    View as JSON
                  
                  Edit on GitHub    
                
              
            
          
        
        
      

      Table of contents
Deprecated APIs

Revoking deprecations
List of deprecated APIs

DEP0001: http.OutgoingMessage.prototype.flush
DEP0002: require('_linklist')
DEP0003: _writableState.buffer
DEP0004: CryptoStream.prototype.readyState
DEP0005: Buffer() constructor
DEP0006: child_process options.customFds
DEP0007: Replace cluster worker.suicide with worker.exitedAfterDisconnect
DEP0008: require('node:constants')
DEP0009: crypto.pbkdf2 without digest
DEP0010: crypto.createCredentials
DEP0011: crypto.Credentials
DEP0012: Domain.dispose
DEP0013: fs asynchronous function without callback
DEP0014: fs.read legacy String interface
DEP0015: fs.readSync legacy String interface
DEP0016: GLOBAL/root
DEP0017: Intl.v8BreakIterator
DEP0018: Unhandled promise rejections
DEP0019: require('.') resolved outside directory
DEP0020: Server.connections
DEP0021: Server.listenFD
DEP0022: os.tmpDir()
DEP0023: os.getNetworkInterfaces()
DEP0024: REPLServer.prototype.convertToContext()
DEP0025: require('node:sys')
DEP0026: util.print()
DEP0027: util.puts()
DEP0028: util.debug()
DEP0029: util.error()
DEP0030: SlowBuffer
DEP0031: ecdh.setPublicKey()
DEP0032: node:domain module
DEP0033: EventEmitter.listenerCount()
DEP0034: fs.exists(path, callback)
DEP0035: fs.lchmod(path, mode, callback)
DEP0036: fs.lchmodSync(path, mode)
DEP0037: fs.lchown(path, uid, gid, callback)
DEP0038: fs.lchownSync(path, uid, gid)
DEP0039: require.extensions
DEP0040: node:punycode module
DEP0041: NODE_REPL_HISTORY_FILE environment variable
DEP0042: tls.CryptoStream
DEP0043: tls.SecurePair
DEP0044: util.isArray()
DEP0045: util.isBoolean()
DEP0046: util.isBuffer()
DEP0047: util.isDate()
DEP0048: util.isError()
DEP0049: util.isFunction()
DEP0050: util.isNull()
DEP0051: util.isNullOrUndefined()
DEP0052: util.isNumber()
DEP0053: util.isObject()
DEP0054: util.isPrimitive()
DEP0055: util.isRegExp()
DEP0056: util.isString()
DEP0057: util.isSymbol()
DEP0058: util.isUndefined()
DEP0059: util.log()
DEP0060: util._extend()
DEP0061: fs.SyncWriteStream
DEP0062: node --debug
DEP0063: ServerResponse.prototype.writeHeader()
DEP0064: tls.createSecurePair()
DEP0065: repl.REPL_MODE_MAGIC and NODE_REPL_MODE=magic
DEP0066: OutgoingMessage.prototype._headers, OutgoingMessage.prototype._headerNames
DEP0067: OutgoingMessage.prototype._renderHeaders
DEP0068: node debug
DEP0069: vm.runInDebugContext(string)
DEP0070: async_hooks.currentId()
DEP0071: async_hooks.triggerId()
DEP0072: async_hooks.AsyncResource.triggerId()
DEP0073: Several internal properties of net.Server
DEP0074: REPLServer.bufferedCommand
DEP0075: REPLServer.parseREPLKeyword()
DEP0076: tls.parseCertString()
DEP0077: Module._debug()
DEP0078: REPLServer.turnOffEditorMode()
DEP0079: Custom inspection function on objects via .inspect()
DEP0080: path._makeLong()
DEP0081: fs.truncate() using a file descriptor
DEP0082: REPLServer.prototype.memory()
DEP0083: Disabling ECDH by setting ecdhCurve to false
DEP0084: requiring bundled internal dependencies
DEP0085: AsyncHooks sensitive API
DEP0086: Remove runInAsyncIdScope
DEP0089: require('node:assert')
DEP0090: Invalid GCM authentication tag lengths
DEP0091: crypto.DEFAULT_ENCODING
DEP0092: Top-level this bound to module.exports
DEP0093: crypto.fips is deprecated and replaced
DEP0094: Using assert.fail() with more than one argument
DEP0095: timers.enroll()
DEP0096: timers.unenroll()
DEP0097: MakeCallback with domain property
DEP0098: AsyncHooks embedder AsyncResource.emitBefore and AsyncResource.emitAfter APIs
DEP0099: Async context-unaware node::MakeCallback C++ APIs
DEP0100: process.assert()
DEP0101: --with-lttng
DEP0102: Using noAssert in Buffer#(read|write) operations
DEP0103: process.binding('util').is[...] typechecks
DEP0104: process.env string coercion
DEP0105: decipher.finaltol
DEP0106: crypto.createCipher and crypto.createDecipher
DEP0107: tls.convertNPNProtocols()
DEP0108: zlib.bytesRead
DEP0109: http, https, and tls support for invalid URLs
DEP0110: vm.Script cached data
DEP0111: process.binding()
DEP0112: dgram private APIs
DEP0113: Cipher.setAuthTag(), Decipher.getAuthTag()
DEP0114: crypto._toBuf()
DEP0115: crypto.prng(), crypto.pseudoRandomBytes(), crypto.rng()
DEP0116: Legacy URL API
DEP0117: Native crypto handles
DEP0118: dns.lookup() support for a falsy host name
DEP0119: process.binding('uv').errname() private API
DEP0120: Windows Performance Counter support
DEP0121: net._setSimultaneousAccepts()
DEP0122: tls Server.prototype.setOptions()
DEP0123: setting the TLS ServerName to an IP address
DEP0124: using REPLServer.rli
DEP0125: require('node:_stream_wrap')
DEP0126: timers.active()
DEP0127: timers._unrefActive()
DEP0128: modules with an invalid main entry and an index.js file
DEP0129: ChildProcess._channel
DEP0130: Module.createRequireFromPath()
DEP0131: Legacy HTTP parser
DEP0132: worker.terminate() with callback
DEP0133: http connection
DEP0134: process._tickCallback
DEP0135: WriteStream.open() and ReadStream.open() are internal
DEP0136: http finished
DEP0137: Closing fs.FileHandle on garbage collection
DEP0138: process.mainModule
DEP0139: process.umask() with no arguments
DEP0140: Use request.destroy() instead of request.abort()
DEP0141: repl.inputStream and repl.outputStream
DEP0142: repl._builtinLibs
DEP0143: Transform._transformState
DEP0144: module.parent
DEP0145: socket.bufferSize
DEP0146: new crypto.Certificate()
DEP0147: fs.rmdir(path, { recursive: true })
DEP0148: Folder mappings in "exports" (trailing "/")
DEP0149: http.IncomingMessage#connection
DEP0150: Changing the value of process.config
DEP0151: Main index lookup and extension searching
DEP0152: Extension PerformanceEntry properties
DEP0153: dns.lookup and dnsPromises.lookup options type coercion
DEP0154: RSA-PSS generate key pair options
DEP0155: Trailing slashes in pattern specifier resolutions
DEP0156: .aborted property and 'abort', 'aborted' event in http
DEP0157: Thenable support in streams
DEP0158: buffer.slice(start, end)
DEP0159: ERR_INVALID_CALLBACK
DEP0160: process.on('multipleResolves', handler)
DEP0161: process._getActiveRequests() and process._getActiveHandles()
DEP0162: fs.write(), fs.writeFileSync() coercion to string
DEP0163: channel.subscribe(onMessage), channel.unsubscribe(onMessage)
DEP0164: process.exit(code), process.exitCode coercion to integer
DEP0165: --trace-atomics-wait
DEP0166: Double slashes in imports and exports targets
DEP0167: Weak DiffieHellmanGroup instances (modp1, modp2, modp5)
DEP0168: Unhandled exception in Node-API callbacks
DEP0169: Insecure url.parse()
DEP0170: Invalid port when using url.parse()
DEP0171: Setters for http.IncomingMessage headers and trailers
DEP0172: The asyncResource property of AsyncResource bound functions
DEP0173: the assert.CallTracker class
DEP0174: calling promisify on a function that returns a Promise
DEP0175: util.toUSVString
DEP0176: fs.F_OK, fs.R_OK, fs.W_OK, fs.X_OK
DEP0177: util.types.isWebAssemblyCompiledModule
DEP0178: dirent.path
DEP0179: Hash constructor
DEP0180: fs.Stats constructor
DEP0181: Hmac constructor
DEP0182: Short GCM authentication tags without explicit authTagLength
DEP0183: OpenSSL engine-based APIs
DEP0184: Instantiating node:zlib classes without new
DEP0185: Instantiating node:repl classes without new
DEP0187: Passing invalid argument types to fs.existsSync
DEP0188: process.features.ipv6 and process.features.uv
DEP0189: process.features.tls_*
DEP0190: Passing args to node:child_process execFile/spawn with shell option true
DEP0191: repl.builtinModules






      
        Deprecated APIs#


Node.js APIs might be deprecated for any of the following reasons:

Use of the API is unsafe.
An improved alternative API is available.
Breaking changes to the API are expected in a future major release.

Node.js uses four kinds of deprecations:

Documentation-only
Application (non-node_modules code only)
Runtime (all code)
End-of-Life

A Documentation-only deprecation is one that is expressed only within the
Node.js API docs. These generate no side-effects while running Node.js.
Some Documentation-only deprecations trigger a runtime warning when launched
with --pending-deprecation flag (or its alternative,
NODE_PENDING_DEPRECATION=1 environment variable), similarly to Runtime
deprecations below. Documentation-only deprecations that support that flag
are explicitly labeled as such in the
list of Deprecated APIs.
An Application deprecation for only non-node_modules code will, by default,
generate a process warning that will be printed to stderr the first time
the deprecated API is used in code that's not loaded from node_modules.
When the --throw-deprecation command-line flag is used, a Runtime
deprecation will cause an error to be thrown. When
--pending-deprecation is used, warnings will also be emitted for
code loaded from node_modules.
A runtime deprecation for all code is similar to the runtime deprecation
for non-node_modules code, except that it also emits a warning for
code loaded from node_modules.
An End-of-Life deprecation is used when functionality is or will soon be removed
from Node.js.
Revoking deprecations#
Occasionally, the deprecation of an API might be reversed. In such situations,
this document will be updated with information relevant to the decision.
However, the deprecation identifier will not be modified.
List of deprecated APIs#

DEP0001: http.OutgoingMessage.prototype.flush#

History

VersionChanges
v14.0.0
End-of-Life.
v6.12.0, v4.8.6
A deprecation code has been assigned.
v1.6.0
Runtime deprecation.



Type: End-of-Life
OutgoingMessage.prototype.flush() has been removed. Use
OutgoingMessage.prototype.flushHeaders() instead.

DEP0002: require('_linklist')#

History

VersionChanges
v8.0.0
End-of-Life.
v6.12.0
A deprecation code has been assigned.
v5.0.0
Runtime deprecation.



Type: End-of-Life
The _linklist module is deprecated. Please use a userland alternative.

DEP0003: _writableState.buffer#

History

VersionChanges
v14.0.0
End-of-Life.
v6.12.0, v4.8.6
A deprecation code has been assigned.
v0.11.15
Runtime deprecation.



Type: End-of-Life
The _writableState.buffer has been removed. Use _writableState.getBuffer()
instead.

DEP0004: CryptoStream.prototype.readyState#

History

VersionChanges
v10.0.0
End-of-Life.
v6.12.0, v4.8.6
A deprecation code has been assigned.
v0.4.0
Documentation-only deprecation.



Type: End-of-Life
The CryptoStream.prototype.readyState property was removed.

DEP0005: Buffer() constructor#

History

VersionChanges
v10.0.0
Runtime deprecation.
v6.12.0
A deprecation code has been assigned.
v6.0.0
Documentation-only deprecation.



Type: Application (non-node_modules code only)
The Buffer() function and new Buffer() constructor are deprecated due to
API usability issues that can lead to accidental security issues.
As an alternative, use one of the following methods of constructing Buffer
objects:

Buffer.alloc(size[, fill[, encoding]]): Create a Buffer with
initialized memory.
Buffer.allocUnsafe(size): Create a Buffer with
uninitialized memory.
Buffer.allocUnsafeSlow(size): Create a Buffer with uninitialized
memory.
Buffer.from(array): Create a Buffer with a copy of array
Buffer.from(arrayBuffer[, byteOffset[, length]]) -
Create a Buffer that wraps the given arrayBuffer.
Buffer.from(buffer): Create a Buffer that copies buffer.
Buffer.from(string[, encoding]): Create a Buffer
that copies string.

Without --pending-deprecation, runtime warnings occur only for code not in
node_modules. This means there will not be deprecation warnings for
Buffer() usage in dependencies. With --pending-deprecation, a runtime
warning results no matter where the Buffer() usage occurs.

DEP0006: child_process options.customFds#

History

VersionChanges
v12.0.0
End-of-Life.
v6.12.0, v4.8.6
A deprecation code has been assigned.
v0.11.14
Runtime deprecation.
v0.5.10
Documentation-only deprecation.



Type: End-of-Life
Within the child_process module's spawn(), fork(), and exec()
methods, the options.customFds option is deprecated. The options.stdio
option should be used instead.

DEP0007: Replace cluster worker.suicide with worker.exitedAfterDisconnect#

History

VersionChanges
v9.0.0
End-of-Life.
v7.0.0
Runtime deprecation.
v6.12.0
A deprecation code has been assigned.
v6.0.0
Documentation-only deprecation.



Type: End-of-Life
In an earlier version of the Node.js cluster, a boolean property with the name
suicide was added to the Worker object. The intent of this property was to
provide an indication of how and why the Worker instance exited. In Node.js
6.0.0, the old property was deprecated and replaced with a new
worker.exitedAfterDisconnect property. The old property name did not
precisely describe the actual semantics and was unnecessarily emotion-laden.

DEP0008: require('node:constants')#

History

VersionChanges
v6.12.0
A deprecation code has been assigned.
v6.3.0
Documentation-only deprecation.



Type: Documentation-only
The node:constants module is deprecated. When requiring access to constants
relevant to specific Node.js builtin modules, developers should instead refer
to the constants property exposed by the relevant module. For instance,
require('node:fs').constants and require('node:os').constants.

DEP0009: crypto.pbkdf2 without digest#

History

VersionChanges
v14.0.0
End-of-Life (for digest === null).
v11.0.0
Runtime deprecation (for digest === null).
v8.0.0
End-of-Life (for digest === undefined).
v6.12.0
A deprecation code has been assigned.
v6.0.0
Runtime deprecation (for digest === undefined).



Type: End-of-Life
Use of the crypto.pbkdf2() API without specifying a digest was deprecated
in Node.js 6.0 because the method defaulted to using the non-recommended
'SHA1' digest. Previously, a deprecation warning was printed. Starting in
Node.js 8.0.0, calling crypto.pbkdf2() or crypto.pbkdf2Sync() with
digest set to undefined will throw a TypeError.
Beginning in Node.js v11.0.0, calling these functions with digest set to
null would print a deprecation warning to align with the behavior when digest
is undefined.
Now, however, passing either undefined or null will throw a TypeError.

DEP0010: crypto.createCredentials#

History

VersionChanges
v11.0.0
End-of-Life.
v6.12.0, v4.8.6
A deprecation code has been assigned.
v0.11.13
Runtime deprecation.



Type: End-of-Life
The crypto.createCredentials() API was removed. Please use
tls.createSecureContext() instead.

DEP0011: crypto.Credentials#

History

VersionChanges
v11.0.0
End-of-Life.
v6.12.0, v4.8.6
A deprecation code has been assigned.
v0.11.13
Runtime deprecation.



Type: End-of-Life
The crypto.Credentials class was removed. Please use tls.SecureContext
instead.

DEP0012: Domain.dispose#

History

VersionChanges
v9.0.0
End-of-Life.
v6.12.0, v4.8.6
A deprecation code has been assigned.
v0.11.7
Runtime deprecation.



Type: End-of-Life
Domain.dispose() has been removed. Recover from failed I/O actions
explicitly via error event handlers set on the domain instead.

DEP0013: fs asynchronous function without callback#

History

VersionChanges
v10.0.0
End-of-Life.
v7.0.0
Runtime deprecation.



Type: End-of-Life
Calling an asynchronous function without a callback throws a TypeError
in Node.js 10.0.0 onwards. See https://github.com/nodejs/node/pull/12562.

DEP0014: fs.read legacy String interface#

History

VersionChanges
v8.0.0
End-of-Life.
v6.0.0
Runtime deprecation.
v6.12.0, v4.8.6
A deprecation code has been assigned.
v0.1.96
Documentation-only deprecation.



Type: End-of-Life
The fs.read() legacy String interface is deprecated. Use the Buffer
API as mentioned in the documentation instead.

DEP0015: fs.readSync legacy String interface#

History

VersionChanges
v8.0.0
End-of-Life.
v6.0.0
Runtime deprecation.
v6.12.0, v4.8.6
A deprecation code has been assigned.
v0.1.96
Documentation-only deprecation.



Type: End-of-Life
The fs.readSync() legacy String interface is deprecated. Use the
Buffer API as mentioned in the documentation instead.

DEP0016: GLOBAL/root#

History

VersionChanges
v14.0.0
End-of-Life.
v6.12.0
A deprecation code has been assigned.
v6.0.0
Runtime deprecation.



Type: End-of-Life
The GLOBAL and root aliases for the global property were deprecated
in Node.js 6.0.0 and have since been removed.

DEP0017: Intl.v8BreakIterator#

History

VersionChanges
v9.0.0
End-of-Life.
v7.0.0
Runtime deprecation.



Type: End-of-Life
Intl.v8BreakIterator was a non-standard extension and has been removed.
See Intl.Segmenter.

DEP0018: Unhandled promise rejections#

History

VersionChanges
v15.0.0
End-of-Life.
v7.0.0
Runtime deprecation.



Type: End-of-Life
Unhandled promise rejections are deprecated. By default, promise rejections
that are not handled terminate the Node.js process with a non-zero exit
code. To change the way Node.js treats unhandled rejections, use the
--unhandled-rejections command-line option.

DEP0019: require('.') resolved outside directory#

History

VersionChanges
v12.0.0
Removed functionality.
v6.12.0, v4.8.6
A deprecation code has been assigned.
v1.8.1
Runtime deprecation.



Type: End-of-Life
In certain cases, require('.') could resolve outside the package directory.
This behavior has been removed.

DEP0020: Server.connections#

History

VersionChanges
v15.0.0
Server.connections has been removed.
v6.12.0, v4.8.6
A deprecation code has been assigned.
v0.9.7
Runtime deprecation.



Type: End-of-Life
The Server.connections property was deprecated in Node.js v0.9.7 and has
been removed. Please use the Server.getConnections() method instead.

DEP0021: Server.listenFD#

History

VersionChanges
v12.0.0
End-of-Life.
v6.12.0, v4.8.6
A deprecation code has been assigned.
v0.7.12
Runtime deprecation.



Type: End-of-Life
The Server.listenFD() method was deprecated and removed. Please use
Server.listen({fd: <number>}) instead.

DEP0022: os.tmpDir()#

History

VersionChanges
v14.0.0
End-of-Life.
v7.0.0
Runtime deprecation.



Type: End-of-Life
The os.tmpDir() API was deprecated in Node.js 7.0.0 and has since been
removed. Please use os.tmpdir() instead.

DEP0023: os.getNetworkInterfaces()#

History

VersionChanges
v12.0.0
End-of-Life.
v6.12.0, v4.8.6
A deprecation code has been assigned.
v0.6.0
Runtime deprecation.



Type: End-of-Life
The os.getNetworkInterfaces() method is deprecated. Please use the
os.networkInterfaces() method instead.

DEP0024: REPLServer.prototype.convertToContext()#

History

VersionChanges
v9.0.0
End-of-Life.
v7.0.0
Runtime deprecation.



Type: End-of-Life
The REPLServer.prototype.convertToContext() API has been removed.

DEP0025: require('node:sys')#

History

VersionChanges
v6.12.0, v4.8.6
A deprecation code has been assigned.
v1.0.0
Runtime deprecation.



Type: Runtime
The node:sys module is deprecated. Please use the util module instead.

DEP0026: util.print()#

History

VersionChanges
v12.0.0
End-of-Life.
v6.12.0, v4.8.6
A deprecation code has been assigned.
v0.11.3
Runtime deprecation.



Type: End-of-Life
util.print() has been removed. Please use console.log() instead.

DEP0027: util.puts()#

History

VersionChanges
v12.0.0
End-of-Life.
v6.12.0, v4.8.6
A deprecation code has been assigned.
v0.11.3
Runtime deprecation.



Type: End-of-Life
util.puts() has been removed. Please use console.log() instead.

DEP0028: util.debug()#

History

VersionChanges
v12.0.0
End-of-Life.
v6.12.0, v4.8.6
A deprecation code has been assigned.
v0.11.3
Runtime deprecation.



Type: End-of-Life
util.debug() has been removed. Please use console.error() instead.

DEP0029: util.error()#

History

VersionChanges
v12.0.0
End-of-Life.
v6.12.0, v4.8.6
A deprecation code has been assigned.
v0.11.3
Runtime deprecation.



Type: End-of-Life
util.error() has been removed. Please use console.error() instead.

DEP0030: SlowBuffer#

History

VersionChanges
v24.0.0
Runtime deprecation.
v6.12.0
A deprecation code has been assigned.
v6.0.0
Documentation-only deprecation.



Type: Runtime
The SlowBuffer class is deprecated. Please use
Buffer.allocUnsafeSlow(size) instead.

DEP0031: ecdh.setPublicKey()#

History

VersionChanges
v6.12.0
A deprecation code has been assigned.
v5.2.0
Documentation-only deprecation.



Type: Documentation-only
The ecdh.setPublicKey() method is now deprecated as its inclusion in the
API is not useful.

DEP0032: node:domain module#

History

VersionChanges
v6.12.0, v4.8.6
A deprecation code has been assigned.
v1.4.2
Documentation-only deprecation.



Type: Documentation-only
The domain module is deprecated and should not be used.

DEP0033: EventEmitter.listenerCount()#

History

VersionChanges
v6.12.0, v4.8.6
A deprecation code has been assigned.
v3.2.0
Documentation-only deprecation.



Type: Documentation-only
The events.listenerCount(emitter, eventName) API is
deprecated. Please use emitter.listenerCount(eventName) instead.

DEP0034: fs.exists(path, callback)#

History

VersionChanges
v6.12.0, v4.8.6
A deprecation code has been assigned.
v1.0.0
Documentation-only deprecation.



Type: Documentation-only
The fs.exists(path, callback) API is deprecated. Please use
fs.stat() or fs.access() instead.

DEP0035: fs.lchmod(path, mode, callback)#

History

VersionChanges
v6.12.0, v4.8.6
A deprecation code has been assigned.
v0.4.7
Documentation-only deprecation.



Type: Documentation-only
The fs.lchmod(path, mode, callback) API is deprecated.

DEP0036: fs.lchmodSync(path, mode)#

History

VersionChanges
v6.12.0, v4.8.6
A deprecation code has been assigned.
v0.4.7
Documentation-only deprecation.



Type: Documentation-only
The fs.lchmodSync(path, mode) API is deprecated.

DEP0037: fs.lchown(path, uid, gid, callback)#

History

VersionChanges
v10.6.0
Deprecation revoked.
v6.12.0, v4.8.6
A deprecation code has been assigned.
v0.4.7
Documentation-only deprecation.



Type: Deprecation revoked
The fs.lchown(path, uid, gid, callback) API was deprecated. The
deprecation was revoked because the requisite supporting APIs were added in
libuv.

DEP0038: fs.lchownSync(path, uid, gid)#

History

VersionChanges
v10.6.0
Deprecation revoked.
v6.12.0, v4.8.6
A deprecation code has been assigned.
v0.4.7
Documentation-only deprecation.



Type: Deprecation revoked
The fs.lchownSync(path, uid, gid) API was deprecated. The deprecation was
revoked because the requisite supporting APIs were added in libuv.

DEP0039: require.extensions#

History

VersionChanges
v6.12.0, v4.8.6
A deprecation code has been assigned.
v0.10.6
Documentation-only deprecation.



Type: Documentation-only
The require.extensions property is deprecated.

DEP0040: node:punycode module#

History

VersionChanges
v21.0.0
Runtime deprecation.
v16.6.0
Added support for --pending-deprecation.
v7.0.0
Documentation-only deprecation.



Type: Runtime
The punycode module is deprecated. Please use a userland alternative
instead.

DEP0041: NODE_REPL_HISTORY_FILE environment variable#

History

VersionChanges
v10.0.0
End-of-Life.
v6.12.0, v4.8.6
A deprecation code has been assigned.
v3.0.0
Documentation-only deprecation.



Type: End-of-Life
The NODE_REPL_HISTORY_FILE environment variable was removed. Please use
NODE_REPL_HISTORY instead.

DEP0042: tls.CryptoStream#

History

VersionChanges
v10.0.0
End-of-Life.
v6.12.0, v4.8.6
A deprecation code has been assigned.
v0.11.3
Documentation-only deprecation.



Type: End-of-Life
The tls.CryptoStream class was removed. Please use
tls.TLSSocket instead.

DEP0043: tls.SecurePair#

History

VersionChanges
v24.0.0
End-of-Life.
v8.0.0
Runtime deprecation.
v6.12.0
A deprecation code has been assigned.
v6.0.0
Documentation-only deprecation.
v0.11.15
Deprecation revoked.
v0.11.3
Runtime deprecation.



Type: End-of-Life
The tls.SecurePair class is deprecated. Please use
tls.TLSSocket instead.

DEP0044: util.isArray()#

History

VersionChanges
v22.0.0
Runtime deprecation.
v6.12.0, v4.8.6
A deprecation code has been assigned.
v4.0.0, v3.3.1
Documentation-only deprecation.



Type: Runtime
The util.isArray() API is deprecated. Please use Array.isArray()
instead.

DEP0045: util.isBoolean()#

History

VersionChanges
v23.0.0
End-of-Life deprecation.
v22.0.0
Runtime deprecation.
v6.12.0, v4.8.6
A deprecation code has been assigned.
v4.0.0, v3.3.1
Documentation-only deprecation.



Type: End-of-Life
The util.isBoolean() API has been removed. Please use
typeof arg === 'boolean' instead.

DEP0046: util.isBuffer()#

History

VersionChanges
v23.0.0
End-of-Life deprecation.
v22.0.0
Runtime deprecation.
v6.12.0, v4.8.6
A deprecation code has been assigned.
v4.0.0, v3.3.1
Documentation-only deprecation.



Type: End-of-Life
The util.isBuffer() API has been removed. Please use
Buffer.isBuffer() instead.

DEP0047: util.isDate()#

History

VersionChanges
v23.0.0
End-of-Life deprecation.
v22.0.0
Runtime deprecation.
v6.12.0, v4.8.6
A deprecation code has been assigned.
v4.0.0, v3.3.1
Documentation-only deprecation.



Type: End-of-Life
The util.isDate() API has been removed. Please use
arg instanceof Date instead.

DEP0048: util.isError()#

History

VersionChanges
v23.0.0
End-of-Life deprecation.
v22.0.0
Runtime deprecation.
v6.12.0, v4.8.6
A deprecation code has been assigned.
v4.0.0, v3.3.1
Documentation-only deprecation.



Type: End-of-Life
The util.isError() API has been removed. Please use
Object.prototype.toString(arg) === '[object Error]' || arg instanceof Error
instead.

DEP0049: util.isFunction()#

History

VersionChanges
v23.0.0
End-of-Life deprecation.
v22.0.0
Runtime deprecation.
v6.12.0, v4.8.6
A deprecation code has been assigned.
v4.0.0, v3.3.1
Documentation-only deprecation.



Type: End-of-Life
The util.isFunction() API has been removed. Please use
typeof arg === 'function' instead.

DEP0050: util.isNull()#

History

VersionChanges
v23.0.0
End-of-Life deprecation.
v22.0.0
Runtime deprecation.
v6.12.0, v4.8.6
A deprecation code has been assigned.
v4.0.0, v3.3.1
Documentation-only deprecation.



Type: End-of-Life
The util.isNull() API has been removed. Please use
arg === null instead.

DEP0051: util.isNullOrUndefined()#

History

VersionChanges
v23.0.0
End-of-Life deprecation.
v22.0.0
Runtime deprecation.
v6.12.0, v4.8.6
A deprecation code has been assigned.
v4.0.0, v3.3.1
Documentation-only deprecation.



Type: End-of-Life
The util.isNullOrUndefined() API has been removed. Please use
arg === null || arg === undefined instead.

DEP0052: util.isNumber()#

History

VersionChanges
v23.0.0
End-of-Life deprecation.
v22.0.0
Runtime deprecation.
v6.12.0, v4.8.6
A deprecation code has been assigned.
v4.0.0, v3.3.1
Documentation-only deprecation.



Type: End-of-Life
The util.isNumber() API has been removed. Please use
typeof arg === 'number' instead.

DEP0053: util.isObject()#

History

VersionChanges
v23.0.0
End-of-Life deprecation.
v22.0.0
Runtime deprecation.
v6.12.0, v4.8.6
A deprecation code has been assigned.
v4.0.0, v3.3.1
Documentation-only deprecation.



Type: End-of-Life
The util.isObject() API has been removed. Please use
arg && typeof arg === 'object' instead.

DEP0054: util.isPrimitive()#

History

VersionChanges
v23.0.0
End-of-Life deprecation.
v22.0.0
Runtime deprecation.
v6.12.0, v4.8.6
A deprecation code has been assigned.
v4.0.0, v3.3.1
Documentation-only deprecation.



Type: End-of-Life
The util.isPrimitive() API has been removed. Please use
arg === null || (typeof arg !=='object' && typeof arg !== 'function')
instead.

DEP0055: util.isRegExp()#

History

VersionChanges
v23.0.0
End-of-Life deprecation.
v22.0.0
Runtime deprecation.
v6.12.0, v4.8.6
A deprecation code has been assigned.
v4.0.0, v3.3.1
Documentation-only deprecation.



Type: End-of-Life
The util.isRegExp() API has been removed. Please use
arg instanceof RegExp instead.

DEP0056: util.isString()#

History

VersionChanges
v23.0.0
End-of-Life deprecation.
v22.0.0
Runtime deprecation.
v6.12.0, v4.8.6
A deprecation code has been assigned.
v4.0.0, v3.3.1
Documentation-only deprecation.



Type: End-of-Life
The util.isString() API has been removed. Please use
typeof arg === 'string' instead.

DEP0057: util.isSymbol()#

History

VersionChanges
v23.0.0
End-of-Life deprecation.
v22.0.0
Runtime deprecation.
v6.12.0, v4.8.6
A deprecation code has been assigned.
v4.0.0, v3.3.1
Documentation-only deprecation.



Type: End-of-Life
The util.isSymbol() API has been removed. Please use
typeof arg === 'symbol' instead.

DEP0058: util.isUndefined()#

History

VersionChanges
v23.0.0
End-of-Life deprecation.
v22.0.0
Runtime deprecation.
v6.12.0, v4.8.6
A deprecation code has been assigned.
v4.0.0, v3.3.1
Documentation-only deprecation.



Type: End-of-Life
The util.isUndefined() API has been removed. Please use
arg === undefined instead.

DEP0059: util.log()#

History

VersionChanges
v23.0.0
End-of-Life deprecation.
v22.0.0
Runtime deprecation.
v6.12.0
A deprecation code has been assigned.
v6.0.0
Documentation-only deprecation.



Type: End-of-Life
The util.log() API has been removed because it's an unmaintained
legacy API that was exposed to user land by accident. Instead,
consider the following alternatives based on your specific needs:


Third-Party Logging Libraries


Use console.log(new Date().toLocaleString(), message)


By adopting one of these alternatives, you can transition away from util.log()
and choose a logging strategy that aligns with the specific
requirements and complexity of your application.

DEP0060: util._extend()#

History

VersionChanges
v22.0.0
Runtime deprecation.
v6.12.0
A deprecation code has been assigned.
v6.0.0
Documentation-only deprecation.



Type: Runtime
The util._extend() API is deprecated because it's an unmaintained
legacy API that was exposed to user land by accident.
Please use target = Object.assign(target, source) instead.

DEP0061: fs.SyncWriteStream#

History

VersionChanges
v11.0.0
End-of-Life.
v8.0.0
Runtime deprecation.
v7.0.0
Documentation-only deprecation.



Type: End-of-Life
The fs.SyncWriteStream class was never intended to be a publicly accessible
API and has been removed. No alternative API is available. Please use a userland
alternative.

DEP0062: node --debug#

History

VersionChanges
v12.0.0
End-of-Life.
v8.0.0
Runtime deprecation.



Type: End-of-Life
--debug activates the legacy V8 debugger interface, which was removed as
of V8 5.8. It is replaced by Inspector which is activated with --inspect
instead.

DEP0063: ServerResponse.prototype.writeHeader()#

History

VersionChanges
v8.0.0
Documentation-only deprecation.



Type: Documentation-only
The node:http module ServerResponse.prototype.writeHeader() API is
deprecated. Please use ServerResponse.prototype.writeHead() instead.
The ServerResponse.prototype.writeHeader() method was never documented as an
officially supported API.

DEP0064: tls.createSecurePair()#

History

VersionChanges
v24.0.0
End-of-Life.
v8.0.0
Runtime deprecation.
v6.12.0
A deprecation code has been assigned.
v6.0.0
Documentation-only deprecation.
v0.11.15
Deprecation revoked.
v0.11.3
Runtime deprecation.



Type: End-of-Life
The tls.createSecurePair() API was deprecated in documentation in Node.js
0.11.3. Users should use tls.Socket instead.

DEP0065: repl.REPL_MODE_MAGIC and NODE_REPL_MODE=magic#

History

VersionChanges
v10.0.0
End-of-Life.
v8.0.0
Documentation-only deprecation.



Type: End-of-Life
The node:repl module's REPL_MODE_MAGIC constant, used for replMode option,
has been removed. Its behavior has been functionally identical to that of
REPL_MODE_SLOPPY since Node.js 6.0.0, when V8 5.0 was imported. Please use
REPL_MODE_SLOPPY instead.
The NODE_REPL_MODE environment variable is used to set the underlying
replMode of an interactive node session. Its value, magic, is also
removed. Please use sloppy instead.

DEP0066: OutgoingMessage.prototype._headers, OutgoingMessage.prototype._headerNames#

History

VersionChanges
v24.0.0
End-of-Life.
v12.0.0
Runtime deprecation.
v8.0.0
Documentation-only deprecation.



Type: End-of-Life
The node:http module OutgoingMessage.prototype._headers and
OutgoingMessage.prototype._headerNames properties are deprecated. Use one of
the public methods (e.g. OutgoingMessage.prototype.getHeader(),
OutgoingMessage.prototype.getHeaders(),
OutgoingMessage.prototype.getHeaderNames(),
OutgoingMessage.prototype.getRawHeaderNames(),
OutgoingMessage.prototype.hasHeader(),
OutgoingMessage.prototype.removeHeader(),
OutgoingMessage.prototype.setHeader()) for working with outgoing headers.
The OutgoingMessage.prototype._headers and
OutgoingMessage.prototype._headerNames properties were never documented as
officially supported properties.

DEP0067: OutgoingMessage.prototype._renderHeaders#

History

VersionChanges
v8.0.0
Documentation-only deprecation.



Type: Documentation-only
The node:http module OutgoingMessage.prototype._renderHeaders() API is
deprecated.
The OutgoingMessage.prototype._renderHeaders property was never documented as
an officially supported API.

DEP0068: node debug#

History

VersionChanges
v15.0.0
The legacy node debug command was removed.
v8.0.0
Runtime deprecation.



Type: End-of-Life
node debug corresponds to the legacy CLI debugger which has been replaced with
a V8-inspector based CLI debugger available through node inspect.

DEP0069: vm.runInDebugContext(string)#

History

VersionChanges
v10.0.0
End-of-Life.
v9.0.0
Runtime deprecation.
v8.0.0
Documentation-only deprecation.



Type: End-of-Life
DebugContext has been removed in V8 and is not available in Node.js 10+.
DebugContext was an experimental API.

DEP0070: async_hooks.currentId()#

History

VersionChanges
v9.0.0
End-of-Life.
v8.2.0
Runtime deprecation.



Type: End-of-Life
async_hooks.currentId() was renamed to async_hooks.executionAsyncId() for
clarity.
This change was made while async_hooks was an experimental API.

DEP0071: async_hooks.triggerId()#

History

VersionChanges
v9.0.0
End-of-Life.
v8.2.0
Runtime deprecation.



Type: End-of-Life
async_hooks.triggerId() was renamed to async_hooks.triggerAsyncId() for
clarity.
This change was made while async_hooks was an experimental API.

DEP0072: async_hooks.AsyncResource.triggerId()#

History

VersionChanges
v9.0.0
End-of-Life.
v8.2.0
Runtime deprecation.



Type: End-of-Life
async_hooks.AsyncResource.triggerId() was renamed to
async_hooks.AsyncResource.triggerAsyncId() for clarity.
This change was made while async_hooks was an experimental API.

DEP0073: Several internal properties of net.Server#

History

VersionChanges
v10.0.0
End-of-Life.
v9.0.0
Runtime deprecation.



Type: End-of-Life
Accessing several internal, undocumented properties of net.Server instances
with inappropriate names is deprecated.
As the original API was undocumented and not generally useful for non-internal
code, no replacement API is provided.

DEP0074: REPLServer.bufferedCommand#

History

VersionChanges
v15.0.0
End-of-Life.
v9.0.0
Runtime deprecation.



Type: End-of-Life
The REPLServer.bufferedCommand property was deprecated in favor of
REPLServer.clearBufferedCommand().

DEP0075: REPLServer.parseREPLKeyword()#

History

VersionChanges
v15.0.0
End-of-Life.
v9.0.0
Runtime deprecation.



Type: End-of-Life
REPLServer.parseREPLKeyword() was removed from userland visibility.

DEP0076: tls.parseCertString()#

History

VersionChanges
v18.0.0
End-of-Life.
v9.0.0
Runtime deprecation.
v8.6.0
Documentation-only deprecation.



Type: End-of-Life
tls.parseCertString() was a trivial parsing helper that was made public by
mistake. While it was supposed to parse certificate subject and issuer strings,
it never handled multi-value Relative Distinguished Names correctly.
Earlier versions of this document suggested using querystring.parse() as an
alternative to tls.parseCertString(). However, querystring.parse() also does
not handle all certificate subjects correctly and should not be used.

DEP0077: Module._debug()#

History

VersionChanges
v9.0.0
Runtime deprecation.



Type: Runtime
Module._debug() is deprecated.
The Module._debug() function was never documented as an officially
supported API.

DEP0078: REPLServer.turnOffEditorMode()#

History

VersionChanges
v15.0.0
End-of-Life.
v9.0.0
Runtime deprecation.



Type: End-of-Life
REPLServer.turnOffEditorMode() was removed from userland visibility.

DEP0079: Custom inspection function on objects via .inspect()#

History

VersionChanges
v11.0.0
End-of-Life.
v10.0.0
Runtime deprecation.
v8.7.0
Documentation-only deprecation.



Type: End-of-Life
Using a property named inspect on an object to specify a custom inspection
function for util.inspect() is deprecated. Use util.inspect.custom
instead. For backward compatibility with Node.js prior to version 6.4.0, both
can be specified.

DEP0080: path._makeLong()#

History

VersionChanges
v9.0.0
Documentation-only deprecation.



Type: Documentation-only
The internal path._makeLong() was not intended for public use. However,
userland modules have found it useful. The internal API is deprecated
and replaced with an identical, public path.toNamespacedPath() method.

DEP0081: fs.truncate() using a file descriptor#

History

VersionChanges
v24.0.0
End-of-Life.
v9.0.0
Runtime deprecation.



Type: End-of-Life
fs.truncate() fs.truncateSync() usage with a file descriptor is
deprecated. Please use fs.ftruncate() or fs.ftruncateSync() to work with
file descriptors.

DEP0082: REPLServer.prototype.memory()#

History

VersionChanges
v15.0.0
End-of-Life.
v9.0.0
Runtime deprecation.



Type: End-of-Life
REPLServer.prototype.memory() is only necessary for the internal mechanics of
the REPLServer itself. Do not use this function.

DEP0083: Disabling ECDH by setting ecdhCurve to false#

History

VersionChanges
v10.0.0
End-of-Life.
v9.2.0
Runtime deprecation.



Type: End-of-Life
The ecdhCurve option to tls.createSecureContext() and tls.TLSSocket could
be set to false to disable ECDH entirely on the server only. This mode was
deprecated in preparation for migrating to OpenSSL 1.1.0 and consistency with
the client and is now unsupported. Use the ciphers parameter instead.

DEP0084: requiring bundled internal dependencies#

History

VersionChanges
v12.0.0
This functionality has been removed.
v10.0.0
Runtime deprecation.



Type: End-of-Life
Since Node.js versions 4.4.0 and 5.2.0, several modules only intended for
internal usage were mistakenly exposed to user code through require(). These
modules were:

v8/tools/codemap
v8/tools/consarray
v8/tools/csvparser
v8/tools/logreader
v8/tools/profile_view
v8/tools/profile
v8/tools/SourceMap
v8/tools/splaytree
v8/tools/tickprocessor-driver
v8/tools/tickprocessor
node-inspect/lib/_inspect (from 7.6.0)
node-inspect/lib/internal/inspect_client (from 7.6.0)
node-inspect/lib/internal/inspect_repl (from 7.6.0)

The v8/* modules do not have any exports, and if not imported in a specific
order would in fact throw errors. As such there are virtually no legitimate use
cases for importing them through require().
On the other hand, node-inspect can be installed locally through a package
manager, as it is published on the npm registry under the same name. No source
code modification is necessary if that is done.

DEP0085: AsyncHooks sensitive API#

History

VersionChanges
v10.0.0
End-of-Life.
v9.4.0, v8.10.0
Runtime deprecation.



Type: End-of-Life
The AsyncHooks sensitive API was never documented and had various minor issues.
Use the AsyncResource API instead. See
https://github.com/nodejs/node/issues/15572.

DEP0086: Remove runInAsyncIdScope#

History

VersionChanges
v10.0.0
End-of-Life.
v9.4.0, v8.10.0
Runtime deprecation.



Type: End-of-Life
runInAsyncIdScope doesn't emit the 'before' or 'after' event and can thus
cause a lot of issues. See https://github.com/nodejs/node/issues/14328.



DEP0089: require('node:assert')#

History

VersionChanges
v12.8.0
Deprecation revoked.
v9.9.0, v8.13.0
Documentation-only deprecation.



Type: Deprecation revoked
Importing assert directly was not recommended as the exposed functions use
loose equality checks. The deprecation was revoked because use of the
node:assert module is not discouraged, and the deprecation caused developer
confusion.

DEP0090: Invalid GCM authentication tag lengths#

History

VersionChanges
v11.0.0
End-of-Life.
v10.0.0
Runtime deprecation.



Type: End-of-Life
Node.js used to support all GCM authentication tag lengths which are accepted by
OpenSSL when calling decipher.setAuthTag(). Beginning with Node.js
v11.0.0, only authentication tag lengths of 128, 120, 112, 104, 96, 64, and 32
bits are allowed. Authentication tags of other lengths are invalid per
NIST SP 800-38D.

DEP0091: crypto.DEFAULT_ENCODING#

History

VersionChanges
v20.0.0
End-of-Life.
v10.0.0
Runtime deprecation.



Type: End-of-Life
The crypto.DEFAULT_ENCODING property only existed for compatibility with
Node.js releases prior to versions 0.9.3 and has been removed.

DEP0092: Top-level this bound to module.exports#

History

VersionChanges
v10.0.0
Documentation-only deprecation.



Type: Documentation-only
Assigning properties to the top-level this as an alternative
to module.exports is deprecated. Developers should use exports
or module.exports instead.

DEP0093: crypto.fips is deprecated and replaced#

History

VersionChanges
v23.0.0
Runtime deprecation.
v10.0.0
Documentation-only deprecation.



Type: Runtime
The crypto.fips property is deprecated. Please use crypto.setFips()
and crypto.getFips() instead.

DEP0094: Using assert.fail() with more than one argument#

History

VersionChanges
v10.0.0
Runtime deprecation.



Type: Runtime
Using assert.fail() with more than one argument is deprecated. Use
assert.fail() with only one argument or use a different node:assert module
method.

DEP0095: timers.enroll()#

History

VersionChanges
v24.0.0
End-of-Life.
v10.0.0
Runtime deprecation.



Type: End-of-Life
timers.enroll() has been removed. Please use the publicly documented
setTimeout() or setInterval() instead.

DEP0096: timers.unenroll()#

History

VersionChanges
v24.0.0
End-of-Life.
v10.0.0
Runtime deprecation.



Type: End-of-Life
timers.unenroll() has been removed. Please use the publicly documented
clearTimeout() or clearInterval() instead.

DEP0097: MakeCallback with domain property#

History

VersionChanges
v10.0.0
Runtime deprecation.



Type: Runtime
Users of MakeCallback that add the domain property to carry context,
should start using the async_context variant of MakeCallback or
CallbackScope, or the high-level AsyncResource class.

DEP0098: AsyncHooks embedder AsyncResource.emitBefore and AsyncResource.emitAfter APIs#

History

VersionChanges
v12.0.0
End-of-Life.
v10.0.0, v9.6.0, v8.12.0
Runtime deprecation.



Type: End-of-Life
The embedded API provided by AsyncHooks exposes .emitBefore() and
.emitAfter() methods which are very easy to use incorrectly which can lead
to unrecoverable errors.
Use asyncResource.runInAsyncScope() API instead which provides a much
safer, and more convenient, alternative. See
https://github.com/nodejs/node/pull/18513.

DEP0099: Async context-unaware node::MakeCallback C++ APIs#

History

VersionChanges
v10.0.0
Compile-time deprecation.



Type: Compile-time
Certain versions of node::MakeCallback APIs available to native addons are
deprecated. Please use the versions of the API that accept an async_context
parameter.

DEP0100: process.assert()#

History

VersionChanges
v23.0.0
End-of-Life.
v10.0.0
Runtime deprecation.
v0.3.7
Documentation-only deprecation.



Type: End-of-Life
process.assert() is deprecated. Please use the assert module instead.
This was never a documented feature.

DEP0101: --with-lttng#

History

VersionChanges
v10.0.0
End-of-Life.



Type: End-of-Life
The --with-lttng compile-time option has been removed.

DEP0102: Using noAssert in Buffer#(read|write) operations#

History

VersionChanges
v10.0.0
End-of-Life.



Type: End-of-Life
Using the noAssert argument has no functionality anymore. All input is
verified regardless of the value of noAssert. Skipping the verification
could lead to hard-to-find errors and crashes.

DEP0103: process.binding('util').is[...] typechecks#

History

VersionChanges
v10.9.0
Superseded by DEP0111.
v10.0.0
Documentation-only deprecation.



Type: Documentation-only (supports --pending-deprecation)
Using process.binding() in general should be avoided. The type checking
methods in particular can be replaced by using util.types.
This deprecation has been superseded by the deprecation of the
process.binding() API (DEP0111).

DEP0104: process.env string coercion#

History

VersionChanges
v10.0.0
Documentation-only deprecation with --pending-deprecation support.



Type: Documentation-only (supports --pending-deprecation)
When assigning a non-string property to process.env, the assigned value is
implicitly converted to a string. This behavior is deprecated if the assigned
value is not a string, boolean, or number. In the future, such assignment might
result in a thrown error. Please convert the property to a string before
assigning it to process.env.

DEP0105: decipher.finaltol#

History

VersionChanges
v11.0.0
End-of-Life.
v10.0.0
Runtime deprecation.



Type: End-of-Life
decipher.finaltol() has never been documented and was an alias for
decipher.final(). This API has been removed, and it is recommended to use
decipher.final() instead.

DEP0106: crypto.createCipher and crypto.createDecipher#

History

VersionChanges
v22.0.0
End-of-Life.
v11.0.0
Runtime deprecation.
v10.0.0
Documentation-only deprecation.



Type: End-of-Life
crypto.createCipher() and crypto.createDecipher() have been removed
as they use a weak key derivation function (MD5 with no salt) and static
initialization vectors.
It is recommended to derive a key using
crypto.pbkdf2() or crypto.scrypt() with random salts and to use
crypto.createCipheriv() and crypto.createDecipheriv() to obtain the
Cipheriv and Decipheriv objects respectively.

DEP0107: tls.convertNPNProtocols()#

History

VersionChanges
v11.0.0
End-of-Life.
v10.0.0
Runtime deprecation.



Type: End-of-Life
This was an undocumented helper function not intended for use outside Node.js
core and obsoleted by the removal of NPN (Next Protocol Negotiation) support.

DEP0108: zlib.bytesRead#

History

VersionChanges
v23.0.0
End-of-Life.
v11.0.0
Runtime deprecation.
v10.0.0
Documentation-only deprecation.



Type: End-of-Life
Deprecated alias for zlib.bytesWritten. This original name was chosen
because it also made sense to interpret the value as the number of bytes
read by the engine, but is inconsistent with other streams in Node.js that
expose values under these names.

DEP0109: http, https, and tls support for invalid URLs#

History

VersionChanges
v16.0.0
End-of-Life.
v11.0.0
Runtime deprecation.



Type: End-of-Life
Some previously supported (but strictly invalid) URLs were accepted through the
http.request(), http.get(), https.request(),
https.get(), and tls.checkServerIdentity() APIs because those were
accepted by the legacy url.parse() API. The mentioned APIs now use the WHATWG
URL parser that requires strictly valid URLs. Passing an invalid URL is
deprecated and support will be removed in the future.

DEP0110: vm.Script cached data#

History

VersionChanges
v10.6.0
Documentation-only deprecation.



Type: Documentation-only
The produceCachedData option is deprecated. Use
script.createCachedData() instead.

DEP0111: process.binding()#

History

VersionChanges
v11.12.0
Added support for --pending-deprecation.
v10.9.0
Documentation-only deprecation.



Type: Documentation-only (supports --pending-deprecation)
process.binding() is for use by Node.js internal code only.
While process.binding() has not reached End-of-Life status in general, it is
unavailable when the permission model is enabled.

DEP0112: dgram private APIs#

History

VersionChanges
v11.0.0
Runtime deprecation.



Type: Runtime
The node:dgram module previously contained several APIs that were never meant
to accessed outside of Node.js core: Socket.prototype._handle,
Socket.prototype._receiving, Socket.prototype._bindState,
Socket.prototype._queue, Socket.prototype._reuseAddr,
Socket.prototype._healthCheck(), Socket.prototype._stopReceiving(), and
dgram._createSocketHandle().

DEP0113: Cipher.setAuthTag(), Decipher.getAuthTag()#

History

VersionChanges
v12.0.0
End-of-Life.
v11.0.0
Runtime deprecation.



Type: End-of-Life
Cipher.setAuthTag() and Decipher.getAuthTag() are no longer available. They
were never documented and would throw when called.

DEP0114: crypto._toBuf()#

History

VersionChanges
v12.0.0
End-of-Life.
v11.0.0
Runtime deprecation.



Type: End-of-Life
The crypto._toBuf() function was not designed to be used by modules outside
of Node.js core and was removed.


DEP0115: crypto.prng(), crypto.pseudoRandomBytes(), crypto.rng()#

History

VersionChanges
v11.0.0
Documentation-only deprecation with --pending-deprecation support.



Type: Documentation-only (supports --pending-deprecation)

In recent versions of Node.js, there is no difference between
crypto.randomBytes() and crypto.pseudoRandomBytes(). The latter is
deprecated along with the undocumented aliases crypto.prng() and
crypto.rng() in favor of crypto.randomBytes() and might be removed in a
future release.

DEP0116: Legacy URL API#

History

VersionChanges
v19.0.0, v18.13.0
`url.parse()` is deprecated again in DEP0169.
v15.13.0, v14.17.0
Deprecation revoked. Status changed to "Legacy".
v11.0.0
Documentation-only deprecation.



Type: Deprecation revoked
The legacy URL API is deprecated. This includes url.format(),
url.parse(), url.resolve(), and the legacy urlObject. Please
use the WHATWG URL API instead.

DEP0117: Native crypto handles#

History

VersionChanges
v12.0.0
End-of-Life.
v11.0.0
Runtime deprecation.



Type: End-of-Life
Previous versions of Node.js exposed handles to internal native objects through
the _handle property of the Cipher, Decipher, DiffieHellman,
DiffieHellmanGroup, ECDH, Hash, Hmac, Sign, and Verify classes.
The _handle property has been removed because improper use of the native
object can lead to crashing the application.

DEP0118: dns.lookup() support for a falsy host name#

History

VersionChanges
v11.0.0
Runtime deprecation.



Type: Runtime
Previous versions of Node.js supported dns.lookup() with a falsy host name
like dns.lookup(false) due to backward compatibility.
This behavior is undocumented and is thought to be unused in real world apps.
It will become an error in future versions of Node.js.

DEP0119: process.binding('uv').errname() private API#

History

VersionChanges
v11.0.0
Documentation-only deprecation with --pending-deprecation support.



Type: Documentation-only (supports --pending-deprecation)
process.binding('uv').errname() is deprecated. Please use
util.getSystemErrorName() instead.

DEP0120: Windows Performance Counter support#

History

VersionChanges
v12.0.0
End-of-Life.
v11.0.0
Runtime deprecation.



Type: End-of-Life
Windows Performance Counter support has been removed from Node.js. The
undocumented COUNTER_NET_SERVER_CONNECTION(),
COUNTER_NET_SERVER_CONNECTION_CLOSE(), COUNTER_HTTP_SERVER_REQUEST(),
COUNTER_HTTP_SERVER_RESPONSE(), COUNTER_HTTP_CLIENT_REQUEST(), and
COUNTER_HTTP_CLIENT_RESPONSE() functions have been deprecated.

DEP0121: net._setSimultaneousAccepts()#

History

VersionChanges
v24.0.0
End-of-Life.
v12.0.0
Runtime deprecation.



Type: End-of-Life
The undocumented net._setSimultaneousAccepts() function was originally
intended for debugging and performance tuning when using the
node:child_process and node:cluster modules on Windows. The function is not
generally useful and is being removed. See discussion here:
https://github.com/nodejs/node/issues/18391

DEP0122: tls Server.prototype.setOptions()#

History

VersionChanges
v24.0.0
End-of-Life.
v12.0.0
Runtime deprecation.



Type: End-of-Life
Please use Server.prototype.setSecureContext() instead.

DEP0123: setting the TLS ServerName to an IP address#

History

VersionChanges
v12.0.0
Runtime deprecation.



Type: Runtime
Setting the TLS ServerName to an IP address is not permitted by
RFC 6066. This will be ignored in a future version.

DEP0124: using REPLServer.rli#

History

VersionChanges
v15.0.0
End-of-Life.
v12.0.0
Runtime deprecation.



Type: End-of-Life
This property is a reference to the instance itself.

DEP0125: require('node:_stream_wrap')#

History

VersionChanges
v12.0.0
Runtime deprecation.



Type: Runtime
The node:_stream_wrap module is deprecated.

DEP0126: timers.active()#

History

VersionChanges
v24.0.0
End-of-Life.
v11.14.0
Runtime deprecation.



Type: End-of-Life
The previously undocumented timers.active() has been removed.
Please use the publicly documented timeout.refresh() instead.
If re-referencing the timeout is necessary, timeout.ref() can be used
with no performance impact since Node.js 10.

DEP0127: timers._unrefActive()#

History

VersionChanges
v24.0.0
End-of-Life.
v11.14.0
Runtime deprecation.



Type: End-of-Life
The previously undocumented and "private" timers._unrefActive() has been removed.
Please use the publicly documented timeout.refresh() instead.
If unreferencing the timeout is necessary, timeout.unref() can be used
with no performance impact since Node.js 10.

DEP0128: modules with an invalid main entry and an index.js file#

History

VersionChanges
v16.0.0
Runtime deprecation.
v12.0.0
Documentation-only.



Type: Runtime
Modules that have an invalid main entry (e.g., ./does-not-exist.js) and
also have an index.js file in the top level directory will resolve the
index.js file. That is deprecated and is going to throw an error in future
Node.js versions.

DEP0129: ChildProcess._channel#

History

VersionChanges
v13.0.0
Runtime deprecation.
v11.14.0
Documentation-only.



Type: Runtime
The _channel property of child process objects returned by spawn() and
similar functions is not intended for public use. Use ChildProcess.channel
instead.

DEP0130: Module.createRequireFromPath()#

History

VersionChanges
v16.0.0
End-of-life.
v13.0.0
Runtime deprecation.
v12.2.0
Documentation-only.



Type: End-of-Life
Use module.createRequire() instead.

DEP0131: Legacy HTTP parser#

History

VersionChanges
v13.0.0
This feature has been removed.
v12.22.0
Runtime deprecation.
v12.3.0
Documentation-only.



Type: End-of-Life
The legacy HTTP parser, used by default in versions of Node.js prior to 12.0.0,
is deprecated and has been removed in v13.0.0. Prior to v13.0.0, the
--http-parser=legacy command-line flag could be used to revert to using the
legacy parser.

DEP0132: worker.terminate() with callback#

History

VersionChanges
v12.5.0
Runtime deprecation.



Type: Runtime
Passing a callback to worker.terminate() is deprecated. Use the returned
Promise instead, or a listener to the worker's 'exit' event.

DEP0133: http connection#

History

VersionChanges
v12.12.0
Documentation-only deprecation.



Type: Documentation-only
Prefer response.socket over response.connection and
request.socket over request.connection.

DEP0134: process._tickCallback#

History

VersionChanges
v12.12.0
Documentation-only deprecation with --pending-deprecation support.



Type: Documentation-only (supports --pending-deprecation)
The process._tickCallback property was never documented as
an officially supported API.

DEP0135: WriteStream.open() and ReadStream.open() are internal#

History

VersionChanges
v13.0.0
Runtime deprecation.



Type: Runtime
WriteStream.open() and ReadStream.open() are undocumented internal
APIs that do not make sense to use in userland. File streams should always be
opened through their corresponding factory methods fs.createWriteStream()
and fs.createReadStream()) or by passing a file descriptor in options.

DEP0136: http finished#

History

VersionChanges
v13.4.0, v12.16.0
Documentation-only deprecation.



Type: Documentation-only
response.finished indicates whether response.end() has been
called, not whether 'finish' has been emitted and the underlying data
is flushed.
Use response.writableFinished or response.writableEnded
accordingly instead to avoid the ambiguity.
To maintain existing behavior response.finished should be replaced with
response.writableEnded.

DEP0137: Closing fs.FileHandle on garbage collection#

History

VersionChanges
v14.0.0
Runtime deprecation.



Type: Runtime
Allowing a fs.FileHandle object to be closed on garbage collection is
deprecated. In the future, doing so might result in a thrown error that will
terminate the process.
Please ensure that all fs.FileHandle objects are explicitly closed using
FileHandle.prototype.close() when the fs.FileHandle is no longer needed:
const fsPromises = require('node:fs').promises;
async function openAndClose() {
  let filehandle;
  try {
    filehandle = await fsPromises.open('thefile.txt', 'r');
  } finally {
    if (filehandle !== undefined)
      await filehandle.close();
  }
} copy

DEP0138: process.mainModule#

History

VersionChanges
v14.0.0
Documentation-only deprecation.



Type: Documentation-only
process.mainModule is a CommonJS-only feature while process global
object is shared with non-CommonJS environment. Its use within ECMAScript
modules is unsupported.
It is deprecated in favor of require.main, because it serves the same
purpose and is only available on CommonJS environment.

DEP0139: process.umask() with no arguments#

History

VersionChanges
v14.0.0, v12.19.0
Documentation-only deprecation.



Type: Documentation-only
Calling process.umask() with no argument causes the process-wide umask to be
written twice. This introduces a race condition between threads, and is a
potential security vulnerability. There is no safe, cross-platform alternative
API.

DEP0140: Use request.destroy() instead of request.abort()#

History

VersionChanges
v14.1.0, v13.14.0
Documentation-only deprecation.



Type: Documentation-only
Use request.destroy() instead of request.abort().

DEP0141: repl.inputStream and repl.outputStream#

History

VersionChanges
v14.3.0
Documentation-only deprecation with --pending-deprecation support.



Type: Documentation-only (supports --pending-deprecation)
The node:repl module exported the input and output stream twice. Use .input
instead of .inputStream and .output instead of .outputStream.

DEP0142: repl._builtinLibs#

History

VersionChanges
v14.3.0
Documentation-only deprecation with --pending-deprecation support.



Type: Documentation-only (supports --pending-deprecation)
The node:repl module exports a _builtinLibs property that contains an array
of built-in modules. It was incomplete so far and instead it's better to rely
upon require('node:module').builtinModules.

DEP0143: Transform._transformState#

History

VersionChanges
v14.5.0
Runtime deprecation.



Type: Runtime
Transform._transformState will be removed in future versions where it is
no longer required due to simplification of the implementation.

DEP0144: module.parent#

History

VersionChanges
v14.6.0, v12.19.0
Documentation-only deprecation.



Type: Documentation-only (supports --pending-deprecation)
A CommonJS module can access the first module that required it using
module.parent. This feature is deprecated because it does not work
consistently in the presence of ECMAScript modules and because it gives an
inaccurate representation of the CommonJS module graph.
Some modules use it to check if they are the entry point of the current process.
Instead, it is recommended to compare require.main and module:
if (require.main === module) {
  // Code section that will run only if current file is the entry point.
} copy
When looking for the CommonJS modules that have required the current one,
require.cache and module.children can be used:
const moduleParents = Object.values(require.cache)
  .filter((m) => m.children.includes(module)); copy

DEP0145: socket.bufferSize#

History

VersionChanges
v14.6.0
Documentation-only deprecation.



Type: Documentation-only
socket.bufferSize is just an alias for writable.writableLength.

DEP0146: new crypto.Certificate()#

History

VersionChanges
v14.9.0
Documentation-only deprecation.



Type: Documentation-only
The crypto.Certificate() constructor is deprecated. Use
static methods of crypto.Certificate() instead.

DEP0147: fs.rmdir(path, { recursive: true })#

History

VersionChanges
v16.0.0
Runtime deprecation.
v15.0.0
Runtime deprecation for permissive behavior.
v14.14.0
Documentation-only deprecation.



Type: Runtime
In future versions of Node.js, recursive option will be ignored for
fs.rmdir, fs.rmdirSync, and fs.promises.rmdir.
Use fs.rm(path, { recursive: true, force: true }),
fs.rmSync(path, { recursive: true, force: true }) or
fs.promises.rm(path, { recursive: true, force: true }) instead.

DEP0148: Folder mappings in "exports" (trailing "/")#

History

VersionChanges
v17.0.0
End-of-Life.
v16.0.0
Runtime deprecation.
v15.1.0
Runtime deprecation for self-referencing imports.
v14.13.0
Documentation-only deprecation.



Type: End-of-Life
Using a trailing "/" to define subpath folder mappings in the
subpath exports or subpath imports fields is no longer supported.
Use subpath patterns instead.

DEP0149: http.IncomingMessage#connection#

History

VersionChanges
v16.0.0
Documentation-only deprecation.



Type: Documentation-only
Prefer message.socket over message.connection.

DEP0150: Changing the value of process.config#

History

VersionChanges
v19.0.0
End-of-Life.
v16.0.0
Runtime deprecation.



Type: End-of-Life
The process.config property provides access to Node.js compile-time settings.
However, the property is mutable and therefore subject to tampering. The ability
to change the value will be removed in a future version of Node.js.

DEP0151: Main index lookup and extension searching#

History

VersionChanges
v16.0.0
Runtime deprecation.
v15.8.0, v14.18.0
Documentation-only deprecation with --pending-deprecation support.



Type: Runtime
Previously, index.js and extension searching lookups would apply to
import 'pkg' main entry point resolution, even when resolving ES modules.
With this deprecation, all ES module main entry point resolutions require
an explicit "exports" or "main" entry with the exact file extension.

DEP0152: Extension PerformanceEntry properties#

History

VersionChanges
v16.0.0
Runtime deprecation.



Type: Runtime
The 'gc', 'http2', and 'http' <PerformanceEntry> object types have
additional properties assigned to them that provide additional information.
These properties are now available within the standard detail property
of the PerformanceEntry object. The existing accessors have been
deprecated and should no longer be used.

DEP0153: dns.lookup and dnsPromises.lookup options type coercion#

History

VersionChanges
v18.0.0
End-of-Life.
v17.0.0
Runtime deprecation.
v16.8.0
Documentation-only deprecation.



Type: End-of-Life
Using a non-nullish non-integer value for family option, a non-nullish
non-number value for hints option, a non-nullish non-boolean value for all
option, or a non-nullish non-boolean value for verbatim option in
dns.lookup() and dnsPromises.lookup() throws an
ERR_INVALID_ARG_TYPE error.

DEP0154: RSA-PSS generate key pair options#

History

VersionChanges
v20.0.0
Runtime deprecation.
v16.10.0
Documentation-only deprecation.



Type: Runtime
The 'hash' and 'mgf1Hash' options are replaced with 'hashAlgorithm'
and 'mgf1HashAlgorithm'.

DEP0155: Trailing slashes in pattern specifier resolutions#

History

VersionChanges
v17.0.0
Runtime deprecation.
v16.10.0
Documentation-only deprecation with --pending-deprecation support.



Type: Runtime
The remapping of specifiers ending in "/" like import 'pkg/x/' is deprecated
for package "exports" and "imports" pattern resolutions.

DEP0156: .aborted property and 'abort', 'aborted' event in http#

History

VersionChanges
v17.0.0, v16.12.0
Documentation-only deprecation.



Type: Documentation-only
Move to <Stream> API instead, as the http.ClientRequest,
http.ServerResponse, and http.IncomingMessage are all stream-based.
Check stream.destroyed instead of the .aborted property, and listen for
'close' instead of 'abort', 'aborted' event.
The .aborted property and 'abort' event are only useful for detecting
.abort() calls. For closing a request early, use the Stream
.destroy([error]) then check the .destroyed property and 'close' event
should have the same effect. The receiving end should also check the
readable.readableEnded value on http.IncomingMessage to get whether
it was an aborted or graceful destroy.

DEP0157: Thenable support in streams#

History

VersionChanges
v18.0.0
End-of-life.
v17.2.0, v16.14.0
Documentation-only deprecation.



Type: End-of-Life
An undocumented feature of Node.js streams was to support thenables in
implementation methods. This is now deprecated, use callbacks instead and avoid
use of async function for streams implementation methods.
This feature caused users to encounter unexpected problems where the user
implements the function in callback style but uses e.g. an async method which
would cause an error since mixing promise and callback semantics is not valid.
const w = new Writable({
  async final(callback) {
    await someOp();
    callback();
  },
}); copy

DEP0158: buffer.slice(start, end)#

History

VersionChanges
v17.5.0, v16.15.0
Documentation-only deprecation.



Type: Documentation-only
This method was deprecated because it is not compatible with
Uint8Array.prototype.slice(), which is a superclass of Buffer.
Use buffer.subarray which does the same thing instead.

DEP0159: ERR_INVALID_CALLBACK#

History

VersionChanges
v18.0.0
End-of-Life.



Type: End-of-Life
This error code was removed due to adding more confusion to
the errors used for value type validation.

DEP0160: process.on('multipleResolves', handler)#

History

VersionChanges
v18.0.0
Runtime deprecation.
v17.6.0, v16.15.0
Documentation-only deprecation.



Type: Runtime
This event was deprecated because it did not work with V8 promise combinators
which diminished its usefulness.

DEP0161: process._getActiveRequests() and process._getActiveHandles()#

History

VersionChanges
v17.6.0, v16.15.0
Documentation-only deprecation.



Type: Documentation-only
The process._getActiveHandles() and process._getActiveRequests()
functions are not intended for public use and can be removed in future
releases.
Use process.getActiveResourcesInfo() to get a list of types of active
resources and not the actual references.

DEP0162: fs.write(), fs.writeFileSync() coercion to string#

History

VersionChanges
v19.0.0
End-of-Life.
v18.0.0
Runtime deprecation.
v17.8.0, v16.15.0
Documentation-only deprecation.



Type: End-of-Life
Implicit coercion of objects with own toString property, passed as second
parameter in fs.write(), fs.writeFile(), fs.appendFile(),
fs.writeFileSync(), and fs.appendFileSync() is deprecated.
Convert them to primitive strings.

DEP0163: channel.subscribe(onMessage), channel.unsubscribe(onMessage)#

History

VersionChanges
v18.7.0, v16.17.0
Documentation-only deprecation.



Type: Documentation-only
These methods were deprecated because they can be used in a way which does not
hold the channel reference alive long enough to receive the events.
Use diagnostics_channel.subscribe(name, onMessage) or
diagnostics_channel.unsubscribe(name, onMessage) which does the same
thing instead.

DEP0164: process.exit(code), process.exitCode coercion to integer#

History

VersionChanges
v20.0.0
End-of-Life.
v19.0.0
Runtime deprecation.
v18.10.0, v16.18.0
Documentation-only deprecation of process.exitCode integer coercion.
v18.7.0, v16.17.0
Documentation-only deprecation of process.exit(code) integer coercion.



Type: End-of-Life
Values other than undefined, null, integer numbers, and integer strings
(e.g., '1') are deprecated as value for the code parameter in
process.exit() and as value to assign to process.exitCode.

DEP0165: --trace-atomics-wait#

History

VersionChanges
v23.0.0
End-of-Life.
v22.0.0
Runtime deprecation.
v18.8.0, v16.18.0
Documentation-only deprecation.



Type: End-of-Life
The --trace-atomics-wait flag has been removed because
it uses the V8 hook SetAtomicsWaitCallback,
that will be removed in a future V8 release.

DEP0166: Double slashes in imports and exports targets#

History

VersionChanges
v19.0.0
Runtime deprecation.
v18.10.0
Documentation-only deprecation with --pending-deprecation support.



Type: Runtime
Package imports and exports targets mapping into paths including a double slash
(of "/" or "\") are deprecated and will fail with a resolution validation
error in a future release. This same deprecation also applies to pattern matches
starting or ending in a slash.

DEP0167: Weak DiffieHellmanGroup instances (modp1, modp2, modp5)#

History

VersionChanges
v18.10.0, v16.18.0
Documentation-only deprecation.



Type: Documentation-only
The well-known MODP groups modp1, modp2, and modp5 are deprecated because
they are not secure against practical attacks. See RFC 8247 Section 2.4 for
details.
These groups might be removed in future versions of Node.js. Applications that
rely on these groups should evaluate using stronger MODP groups instead.

DEP0168: Unhandled exception in Node-API callbacks#

History

VersionChanges
v18.3.0, v16.17.0
Runtime deprecation.



Type: Runtime
The implicit suppression of uncaught exceptions in Node-API callbacks is now
deprecated.
Set the flag --force-node-api-uncaught-exceptions-policy to force Node.js
to emit an 'uncaughtException' event if the exception is not handled in
Node-API callbacks.

DEP0169: Insecure url.parse()#

History

VersionChanges
v24.0.0
Application deprecation.
v19.9.0, v18.17.0
Added support for --pending-deprecation.
v19.0.0, v18.13.0
Documentation-only deprecation.



Type: Application (non-node_modules code only)
url.parse() behavior is not standardized and prone to errors that
have security implications. Use the WHATWG URL API instead. CVEs are not
issued for url.parse() vulnerabilities.

DEP0170: Invalid port when using url.parse()#

History

VersionChanges
v20.0.0
Runtime deprecation.
v19.2.0, v18.13.0
Documentation-only deprecation.



Type: Runtime
url.parse() accepts URLs with ports that are not numbers. This behavior
might result in host name spoofing with unexpected input. These URLs will throw
an error in future versions of Node.js, as the WHATWG URL API does already.

DEP0171: Setters for http.IncomingMessage headers and trailers#

History

VersionChanges
v19.3.0, v18.13.0
Documentation-only deprecation.



Type: Documentation-only
In a future version of Node.js, message.headers,
message.headersDistinct, message.trailers, and
message.trailersDistinct will be read-only.

DEP0172: The asyncResource property of AsyncResource bound functions#

History

VersionChanges
v20.0.0
Runtime-deprecation.



Type: Runtime
In a future version of Node.js, the asyncResource property will no longer
be added when a function is bound to an AsyncResource.

DEP0173: the assert.CallTracker class#

History

VersionChanges
v20.1.0
Runtime deprecation.



Type: Runtime
In a future version of Node.js, assert.CallTracker,
will be removed.
Consider using alternatives such as the mock helper function.

DEP0174: calling promisify on a function that returns a Promise#

History

VersionChanges
v21.0.0
Runtime deprecation.
v20.8.0
Documentation-only deprecation.



Type: Runtime
Calling util.promisify on a function that returns a Promise will ignore
the result of said promise, which can lead to unhandled promise rejections.

DEP0175: util.toUSVString#

History

VersionChanges
v20.8.0
Documentation-only deprecation.



Type: Documentation-only
The util.toUSVString() API is deprecated. Please use
String.prototype.toWellFormed instead.

DEP0176: fs.F_OK, fs.R_OK, fs.W_OK, fs.X_OK#

History

VersionChanges
v24.0.0
Runtime deprecation.
v20.8.0
Documentation-only deprecation.



Type: Runtime
F_OK, R_OK, W_OK and X_OK getters exposed directly on node:fs are
deprecated. Get them from fs.constants or fs.promises.constants instead.

DEP0177: util.types.isWebAssemblyCompiledModule#

History

VersionChanges
v21.7.0, v20.12.0
End-of-Life.
v21.3.0, v20.11.0
A deprecation code has been assigned.
v14.0.0
Documentation-only deprecation.



Type: End-of-Life
The util.types.isWebAssemblyCompiledModule API has been removed.
Please use value instanceof WebAssembly.Module instead.

DEP0178: dirent.path#

History

VersionChanges
v24.0.0
End-of-Life.
v23.0.0
Runtime deprecation.
v21.5.0, v20.12.0, v18.20.0
Documentation-only deprecation.



Type: End-of-Life
The dirent.path property has been removed due to its lack of consistency across
release lines. Please use dirent.parentPath instead.

DEP0179: Hash constructor#

History

VersionChanges
v22.0.0
Runtime deprecation.
v21.5.0, v20.12.0
Documentation-only deprecation.



Type: Runtime
Calling Hash class directly with Hash() or new Hash() is
deprecated due to being internals, not intended for public use.
Please use the crypto.createHash() method to create Hash instances.

DEP0180: fs.Stats constructor#

History

VersionChanges
v22.0.0
Runtime deprecation.
v20.13.0
Documentation-only deprecation.



Type: Runtime
Calling fs.Stats class directly with Stats() or new Stats() is
deprecated due to being internals, not intended for public use.

DEP0181: Hmac constructor#

History

VersionChanges
v22.0.0
Runtime deprecation.
v20.13.0
Documentation-only deprecation.



Type: Runtime
Calling Hmac class directly with Hmac() or new Hmac() is
deprecated due to being internals, not intended for public use.
Please use the crypto.createHmac() method to create Hmac instances.

DEP0182: Short GCM authentication tags without explicit authTagLength#

History

VersionChanges
v23.0.0
Runtime deprecation.
v20.13.0
Documentation-only deprecation.



Type: Runtime
Applications that intend to use authentication tags that are shorter than the
default authentication tag length must set the authTagLength option of the
crypto.createDecipheriv() function to the appropriate length.
For ciphers in GCM mode, the decipher.setAuthTag() function accepts
authentication tags of any valid length (see DEP0090). This behavior
is deprecated to better align with recommendations per NIST SP 800-38D.

DEP0183: OpenSSL engine-based APIs#

History

VersionChanges
v22.4.0, v20.16.0
Documentation-only deprecation.



Type: Documentation-only
OpenSSL 3 has deprecated support for custom engines with a recommendation to
switch to its new provider model. The clientCertEngine option for
https.request(), tls.createSecureContext(), and tls.createServer();
the privateKeyEngine and privateKeyIdentifier for tls.createSecureContext();
and crypto.setEngine() all depend on this functionality from OpenSSL.

DEP0184: Instantiating node:zlib classes without new#

History

VersionChanges
v24.0.0
Runtime deprecation.
v22.9.0, v20.18.0
Documentation-only deprecation.



Type: Runtime
Instantiating classes without the new qualifier exported by the node:zlib module is deprecated.
It is recommended to use the new qualifier instead. This applies to all Zlib classes, such as Deflate,
DeflateRaw, Gunzip, Inflate, InflateRaw, Unzip, and Zlib.

DEP0185: Instantiating node:repl classes without new#

History

VersionChanges
v24.0.0
Runtime deprecation.
v22.9.0, v20.18.0
Documentation-only deprecation.



Type: Runtime
Instantiating classes without the new qualifier exported by the node:repl module is deprecated.
It is recommended to use the new qualifier instead. This applies to all REPL classes, including
REPLServer and Recoverable.


DEP0187: Passing invalid argument types to fs.existsSync#

History

VersionChanges
v24.0.0
Runtime deprecation.
v23.4.0, v22.13.0
Documentation-only.



Type: Runtime
Passing non-supported argument types is deprecated and, instead of returning false,
will throw an error in a future version.

DEP0188: process.features.ipv6 and process.features.uv#

History

VersionChanges
v23.4.0, v22.13.0
Documentation-only deprecation.



Type: Documentation-only
These properties are unconditionally true. Any checks based on these properties are redundant.

DEP0189: process.features.tls_*#

History

VersionChanges
v23.4.0, v22.13.0
Documentation-only deprecation.



Type: Documentation-only
process.features.tls_alpn, process.features.tls_ocsp, and process.features.tls_sni are
deprecated, as their values are guaranteed to be identical to that of process.features.tls.

DEP0190: Passing args to node:child_process execFile/spawn with shell option true#

History

VersionChanges
v24.0.0
Runtime deprecation.
v23.11.0, v22.15.0
Documentation-only deprecation.



Type: Runtime
When an args array is passed to child_process.execFile or child_process.spawn with the option
{ shell: true }, the values are not escaped, only space-separated, which can lead to shell injection.

DEP0191: repl.builtinModules#

History

VersionChanges
v24.0.0
Documentation-only deprecation with --pending-deprecation support.



Type: Documentation-only (supports --pending-deprecation)
The node:repl module exports a builtinModules property that contains an array
of built-in modules. This was incomplete and matched the already deprecated
repl._builtinLibs (DEP0142) instead it's better to rely
upon require('node:module').builtinModules.\n\n\n\nNode.js
        
      
      
About this documentation
Usage and example



Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Modules: TypeScript
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
Readline
REPL
Report
Single executable applications
SQLite
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker

    

    
      
        
          Node.js v24.0.1 documentation
          
            
            
          
        
        
          
            Node.js v24.0.1
            
    
      
        
        Table of contents
      

      
Diagnostics Channel

Public API

Overview

diagnostics_channel.hasSubscribers(name)
diagnostics_channel.channel(name)
diagnostics_channel.subscribe(name, onMessage)
diagnostics_channel.unsubscribe(name, onMessage)
diagnostics_channel.tracingChannel(nameOrChannels)


Class: Channel

channel.hasSubscribers
channel.publish(message)
channel.subscribe(onMessage)
channel.unsubscribe(onMessage)
channel.bindStore(store[, transform])
channel.unbindStore(store)
channel.runStores(context, fn[, thisArg[, ...args]])


Class: TracingChannel

tracingChannel.subscribe(subscribers)
tracingChannel.unsubscribe(subscribers)
tracingChannel.traceSync(fn[, context[, thisArg[, ...args]]])
tracingChannel.tracePromise(fn[, context[, thisArg[, ...args]]])
tracingChannel.traceCallback(fn[, position[, context[, thisArg[, ...args]]]])
tracingChannel.hasSubscribers


TracingChannel Channels

start(event)
end(event)
asyncStart(event)
asyncEnd(event)
error(event)


Built-in Channels

Console
HTTP
Modules
NET
UDP
Process
Worker Thread







    
  
            
    
      
        
        Index
      

      
About this documentation
Usage and example

      
        Index
      
    
  


Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Modules: TypeScript
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
Readline
REPL
Report
Single executable applications
SQLite
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker

    
  
            
    
      
        
        Other versions
      
      24.x
23.x
22.x LTS
21.x
20.x LTS
19.x
18.x
17.x
16.x
15.x
    
  
            
              
                
                Options
              
        
              
                
                  
                    View on single page
                  
                  
                    View as JSON
                  
                  Edit on GitHub    
                
              
            
          
        
        
      

      Table of contents
Diagnostics Channel

Public API

Overview

diagnostics_channel.hasSubscribers(name)
diagnostics_channel.channel(name)
diagnostics_channel.subscribe(name, onMessage)
diagnostics_channel.unsubscribe(name, onMessage)
diagnostics_channel.tracingChannel(nameOrChannels)


Class: Channel

channel.hasSubscribers
channel.publish(message)
channel.subscribe(onMessage)
channel.unsubscribe(onMessage)
channel.bindStore(store[, transform])
channel.unbindStore(store)
channel.runStores(context, fn[, thisArg[, ...args]])


Class: TracingChannel

tracingChannel.subscribe(subscribers)
tracingChannel.unsubscribe(subscribers)
tracingChannel.traceSync(fn[, context[, thisArg[, ...args]]])
tracingChannel.tracePromise(fn[, context[, thisArg[, ...args]]])
tracingChannel.traceCallback(fn[, position[, context[, thisArg[, ...args]]]])
tracingChannel.hasSubscribers


TracingChannel Channels

start(event)
end(event)
asyncStart(event)
asyncEnd(event)
error(event)


Built-in Channels

Console
HTTP
Modules
NET
UDP
Process
Worker Thread








      
        Diagnostics Channel#

History

VersionChanges
v19.2.0, v18.13.0
diagnostics_channel is now Stable.
v15.1.0, v14.17.0
Added in: v15.1.0, v14.17.0




Stability: 2 - Stable
Source Code: lib/diagnostics_channel.js
The node:diagnostics_channel module provides an API to create named channels
to report arbitrary message data for diagnostics purposes.
It can be accessed using:

import diagnostics_channel from 'node:diagnostics_channel';const diagnostics_channel = require('node:diagnostics_channel');copy
It is intended that a module writer wanting to report diagnostics messages
will create one or many top-level channels to report messages through.
Channels may also be acquired at runtime but it is not encouraged
due to the additional overhead of doing so. Channels may be exported for
convenience, but as long as the name is known it can be acquired anywhere.
If you intend for your module to produce diagnostics data for others to
consume it is recommended that you include documentation of what named
channels are used along with the shape of the message data. Channel names
should generally include the module name to avoid collisions with data from
other modules.
Public API#

Overview#
Following is a simple overview of the public API.

import diagnostics_channel from 'node:diagnostics_channel';

// Get a reusable channel object
const channel = diagnostics_channel.channel('my-channel');

function onMessage(message, name) {
  // Received data
}

// Subscribe to the channel
diagnostics_channel.subscribe('my-channel', onMessage);

// Check if the channel has an active subscriber
if (channel.hasSubscribers) {
  // Publish data to the channel
  channel.publish({
    some: 'data',
  });
}

// Unsubscribe from the channel
diagnostics_channel.unsubscribe('my-channel', onMessage);const diagnostics_channel = require('node:diagnostics_channel');

// Get a reusable channel object
const channel = diagnostics_channel.channel('my-channel');

function onMessage(message, name) {
  // Received data
}

// Subscribe to the channel
diagnostics_channel.subscribe('my-channel', onMessage);

// Check if the channel has an active subscriber
if (channel.hasSubscribers) {
  // Publish data to the channel
  channel.publish({
    some: 'data',
  });
}

// Unsubscribe from the channel
diagnostics_channel.unsubscribe('my-channel', onMessage);copy

diagnostics_channel.hasSubscribers(name)#

Added in: v15.1.0, v14.17.0


name <string> | <symbol> The channel name
Returns: <boolean> If there are active subscribers

Check if there are active subscribers to the named channel. This is helpful if
the message you want to send might be expensive to prepare.
This API is optional but helpful when trying to publish messages from very
performance-sensitive code.

import diagnostics_channel from 'node:diagnostics_channel';

if (diagnostics_channel.hasSubscribers('my-channel')) {
  // There are subscribers, prepare and publish message
}const diagnostics_channel = require('node:diagnostics_channel');

if (diagnostics_channel.hasSubscribers('my-channel')) {
  // There are subscribers, prepare and publish message
}copy

diagnostics_channel.channel(name)#

Added in: v15.1.0, v14.17.0


name <string> | <symbol> The channel name
Returns: <Channel> The named channel object

This is the primary entry-point for anyone wanting to publish to a named
channel. It produces a channel object which is optimized to reduce overhead at
publish time as much as possible.

import diagnostics_channel from 'node:diagnostics_channel';

const channel = diagnostics_channel.channel('my-channel');const diagnostics_channel = require('node:diagnostics_channel');

const channel = diagnostics_channel.channel('my-channel');copy

diagnostics_channel.subscribe(name, onMessage)#

Added in: v18.7.0, v16.17.0


name <string> | <symbol> The channel name
onMessage <Function> The handler to receive channel messages

message <any> The message data
name <string> | <symbol> The name of the channel



Register a message handler to subscribe to this channel. This message handler
will be run synchronously whenever a message is published to the channel. Any
errors thrown in the message handler will trigger an 'uncaughtException'.

import diagnostics_channel from 'node:diagnostics_channel';

diagnostics_channel.subscribe('my-channel', (message, name) => {
  // Received data
});const diagnostics_channel = require('node:diagnostics_channel');

diagnostics_channel.subscribe('my-channel', (message, name) => {
  // Received data
});copy

diagnostics_channel.unsubscribe(name, onMessage)#

Added in: v18.7.0, v16.17.0


name <string> | <symbol> The channel name
onMessage <Function> The previous subscribed handler to remove
Returns: <boolean> true if the handler was found, false otherwise.

Remove a message handler previously registered to this channel with
diagnostics_channel.subscribe(name, onMessage).

import diagnostics_channel from 'node:diagnostics_channel';

function onMessage(message, name) {
  // Received data
}

diagnostics_channel.subscribe('my-channel', onMessage);

diagnostics_channel.unsubscribe('my-channel', onMessage);const diagnostics_channel = require('node:diagnostics_channel');

function onMessage(message, name) {
  // Received data
}

diagnostics_channel.subscribe('my-channel', onMessage);

diagnostics_channel.unsubscribe('my-channel', onMessage);copy

diagnostics_channel.tracingChannel(nameOrChannels)#

Added in: v19.9.0, v18.19.0

Stability: 1 - Experimental

nameOrChannels <string> | <TracingChannel> Channel name or
object containing all the TracingChannel Channels
Returns: <TracingChannel> Collection of channels to trace with

Creates a TracingChannel wrapper for the given
TracingChannel Channels. If a name is given, the corresponding tracing
channels will be created in the form of tracing:${name}:${eventType} where
eventType corresponds to the types of TracingChannel Channels.

import diagnostics_channel from 'node:diagnostics_channel';

const channelsByName = diagnostics_channel.tracingChannel('my-channel');

// or...

const channelsByCollection = diagnostics_channel.tracingChannel({
  start: diagnostics_channel.channel('tracing:my-channel:start'),
  end: diagnostics_channel.channel('tracing:my-channel:end'),
  asyncStart: diagnostics_channel.channel('tracing:my-channel:asyncStart'),
  asyncEnd: diagnostics_channel.channel('tracing:my-channel:asyncEnd'),
  error: diagnostics_channel.channel('tracing:my-channel:error'),
});const diagnostics_channel = require('node:diagnostics_channel');

const channelsByName = diagnostics_channel.tracingChannel('my-channel');

// or...

const channelsByCollection = diagnostics_channel.tracingChannel({
  start: diagnostics_channel.channel('tracing:my-channel:start'),
  end: diagnostics_channel.channel('tracing:my-channel:end'),
  asyncStart: diagnostics_channel.channel('tracing:my-channel:asyncStart'),
  asyncEnd: diagnostics_channel.channel('tracing:my-channel:asyncEnd'),
  error: diagnostics_channel.channel('tracing:my-channel:error'),
});copy

Class: Channel#

Added in: v15.1.0, v14.17.0

The class Channel represents an individual named channel within the data
pipeline. It is used to track subscribers and to publish messages when there
are subscribers present. It exists as a separate object to avoid channel
lookups at publish time, enabling very fast publish speeds and allowing
for heavy use while incurring very minimal cost. Channels are created with
diagnostics_channel.channel(name), constructing a channel directly
with new Channel(name) is not supported.

channel.hasSubscribers#

Added in: v15.1.0, v14.17.0


Returns: <boolean> If there are active subscribers

Check if there are active subscribers to this channel. This is helpful if
the message you want to send might be expensive to prepare.
This API is optional but helpful when trying to publish messages from very
performance-sensitive code.

import diagnostics_channel from 'node:diagnostics_channel';

const channel = diagnostics_channel.channel('my-channel');

if (channel.hasSubscribers) {
  // There are subscribers, prepare and publish message
}const diagnostics_channel = require('node:diagnostics_channel');

const channel = diagnostics_channel.channel('my-channel');

if (channel.hasSubscribers) {
  // There are subscribers, prepare and publish message
}copy

channel.publish(message)#

Added in: v15.1.0, v14.17.0


message <any> The message to send to the channel subscribers

Publish a message to any subscribers to the channel. This will trigger
message handlers synchronously so they will execute within the same context.

import diagnostics_channel from 'node:diagnostics_channel';

const channel = diagnostics_channel.channel('my-channel');

channel.publish({
  some: 'message',
});const diagnostics_channel = require('node:diagnostics_channel');

const channel = diagnostics_channel.channel('my-channel');

channel.publish({
  some: 'message',
});copy

channel.subscribe(onMessage)#

Added in: v15.1.0, v14.17.0Deprecated since: v18.7.0, v16.17.0

Stability: 0 - Deprecated: Use diagnostics_channel.subscribe(name, onMessage)

onMessage <Function> The handler to receive channel messages

message <any> The message data
name <string> | <symbol> The name of the channel



Register a message handler to subscribe to this channel. This message handler
will be run synchronously whenever a message is published to the channel. Any
errors thrown in the message handler will trigger an 'uncaughtException'.

import diagnostics_channel from 'node:diagnostics_channel';

const channel = diagnostics_channel.channel('my-channel');

channel.subscribe((message, name) => {
  // Received data
});const diagnostics_channel = require('node:diagnostics_channel');

const channel = diagnostics_channel.channel('my-channel');

channel.subscribe((message, name) => {
  // Received data
});copy

channel.unsubscribe(onMessage)#

History

VersionChanges
v18.7.0, v16.17.0
Deprecated since: v18.7.0, v16.17.0
v17.1.0, v16.14.0, v14.19.0
Added return value. Added to channels without subscribers.
v15.1.0, v14.17.0
Added in: v15.1.0, v14.17.0



Stability: 0 - Deprecated: Use diagnostics_channel.unsubscribe(name, onMessage)

onMessage <Function> The previous subscribed handler to remove
Returns: <boolean> true if the handler was found, false otherwise.

Remove a message handler previously registered to this channel with
channel.subscribe(onMessage).

import diagnostics_channel from 'node:diagnostics_channel';

const channel = diagnostics_channel.channel('my-channel');

function onMessage(message, name) {
  // Received data
}

channel.subscribe(onMessage);

channel.unsubscribe(onMessage);const diagnostics_channel = require('node:diagnostics_channel');

const channel = diagnostics_channel.channel('my-channel');

function onMessage(message, name) {
  // Received data
}

channel.subscribe(onMessage);

channel.unsubscribe(onMessage);copy

channel.bindStore(store[, transform])#

Added in: v19.9.0, v18.19.0

Stability: 1 - Experimental

store <AsyncLocalStorage> The store to which to bind the context data
transform <Function> Transform context data before setting the store context

When channel.runStores(context, ...) is called, the given context data
will be applied to any store bound to the channel. If the store has already been
bound the previous transform function will be replaced with the new one.
The transform function may be omitted to set the given context data as the
context directly.

import diagnostics_channel from 'node:diagnostics_channel';
import { AsyncLocalStorage } from 'node:async_hooks';

const store = new AsyncLocalStorage();

const channel = diagnostics_channel.channel('my-channel');

channel.bindStore(store, (data) => {
  return { data };
});const diagnostics_channel = require('node:diagnostics_channel');
const { AsyncLocalStorage } = require('node:async_hooks');

const store = new AsyncLocalStorage();

const channel = diagnostics_channel.channel('my-channel');

channel.bindStore(store, (data) => {
  return { data };
});copy

channel.unbindStore(store)#

Added in: v19.9.0, v18.19.0

Stability: 1 - Experimental

store <AsyncLocalStorage> The store to unbind from the channel.
Returns: <boolean> true if the store was found, false otherwise.

Remove a message handler previously registered to this channel with
channel.bindStore(store).

import diagnostics_channel from 'node:diagnostics_channel';
import { AsyncLocalStorage } from 'node:async_hooks';

const store = new AsyncLocalStorage();

const channel = diagnostics_channel.channel('my-channel');

channel.bindStore(store);
channel.unbindStore(store);const diagnostics_channel = require('node:diagnostics_channel');
const { AsyncLocalStorage } = require('node:async_hooks');

const store = new AsyncLocalStorage();

const channel = diagnostics_channel.channel('my-channel');

channel.bindStore(store);
channel.unbindStore(store);copy

channel.runStores(context, fn[, thisArg[, ...args]])#

Added in: v19.9.0, v18.19.0

Stability: 1 - Experimental

context <any> Message to send to subscribers and bind to stores
fn <Function> Handler to run within the entered storage context
thisArg <any> The receiver to be used for the function call.
...args <any> Optional arguments to pass to the function.

Applies the given data to any AsyncLocalStorage instances bound to the channel
for the duration of the given function, then publishes to the channel within
the scope of that data is applied to the stores.
If a transform function was given to channel.bindStore(store) it will be
applied to transform the message data before it becomes the context value for
the store. The prior storage context is accessible from within the transform
function in cases where context linking is required.
The context applied to the store should be accessible in any async code which
continues from execution which began during the given function, however
there are some situations in which context loss may occur.

import diagnostics_channel from 'node:diagnostics_channel';
import { AsyncLocalStorage } from 'node:async_hooks';

const store = new AsyncLocalStorage();

const channel = diagnostics_channel.channel('my-channel');

channel.bindStore(store, (message) => {
  const parent = store.getStore();
  return new Span(message, parent);
});
channel.runStores({ some: 'message' }, () => {
  store.getStore(); // Span({ some: 'message' })
});const diagnostics_channel = require('node:diagnostics_channel');
const { AsyncLocalStorage } = require('node:async_hooks');

const store = new AsyncLocalStorage();

const channel = diagnostics_channel.channel('my-channel');

channel.bindStore(store, (message) => {
  const parent = store.getStore();
  return new Span(message, parent);
});
channel.runStores({ some: 'message' }, () => {
  store.getStore(); // Span({ some: 'message' })
});copy

Class: TracingChannel#

Added in: v19.9.0, v18.19.0

Stability: 1 - Experimental
The class TracingChannel is a collection of TracingChannel Channels which
together express a single traceable action. It is used to formalize and
simplify the process of producing events for tracing application flow.
diagnostics_channel.tracingChannel() is used to construct a
TracingChannel. As with Channel it is recommended to create and reuse a
single TracingChannel at the top-level of the file rather than creating them
dynamically.

tracingChannel.subscribe(subscribers)#

Added in: v19.9.0, v18.19.0


subscribers <Object> Set of TracingChannel Channels subscribers

start <Function> The start event subscriber
end <Function> The end event subscriber
asyncStart <Function> The asyncStart event subscriber
asyncEnd <Function> The asyncEnd event subscriber
error <Function> The error event subscriber



Helper to subscribe a collection of functions to the corresponding channels.
This is the same as calling channel.subscribe(onMessage) on each channel
individually.

import diagnostics_channel from 'node:diagnostics_channel';

const channels = diagnostics_channel.tracingChannel('my-channel');

channels.subscribe({
  start(message) {
    // Handle start message
  },
  end(message) {
    // Handle end message
  },
  asyncStart(message) {
    // Handle asyncStart message
  },
  asyncEnd(message) {
    // Handle asyncEnd message
  },
  error(message) {
    // Handle error message
  },
});const diagnostics_channel = require('node:diagnostics_channel');

const channels = diagnostics_channel.tracingChannel('my-channel');

channels.subscribe({
  start(message) {
    // Handle start message
  },
  end(message) {
    // Handle end message
  },
  asyncStart(message) {
    // Handle asyncStart message
  },
  asyncEnd(message) {
    // Handle asyncEnd message
  },
  error(message) {
    // Handle error message
  },
});copy

tracingChannel.unsubscribe(subscribers)#

Added in: v19.9.0, v18.19.0


subscribers <Object> Set of TracingChannel Channels subscribers

start <Function> The start event subscriber
end <Function> The end event subscriber
asyncStart <Function> The asyncStart event subscriber
asyncEnd <Function> The asyncEnd event subscriber
error <Function> The error event subscriber


Returns: <boolean> true if all handlers were successfully unsubscribed,
and false otherwise.

Helper to unsubscribe a collection of functions from the corresponding channels.
This is the same as calling channel.unsubscribe(onMessage) on each channel
individually.

import diagnostics_channel from 'node:diagnostics_channel';

const channels = diagnostics_channel.tracingChannel('my-channel');

channels.unsubscribe({
  start(message) {
    // Handle start message
  },
  end(message) {
    // Handle end message
  },
  asyncStart(message) {
    // Handle asyncStart message
  },
  asyncEnd(message) {
    // Handle asyncEnd message
  },
  error(message) {
    // Handle error message
  },
});const diagnostics_channel = require('node:diagnostics_channel');

const channels = diagnostics_channel.tracingChannel('my-channel');

channels.unsubscribe({
  start(message) {
    // Handle start message
  },
  end(message) {
    // Handle end message
  },
  asyncStart(message) {
    // Handle asyncStart message
  },
  asyncEnd(message) {
    // Handle asyncEnd message
  },
  error(message) {
    // Handle error message
  },
});copy

tracingChannel.traceSync(fn[, context[, thisArg[, ...args]]])#

Added in: v19.9.0, v18.19.0


fn <Function> Function to wrap a trace around
context <Object> Shared object to correlate events through
thisArg <any> The receiver to be used for the function call
...args <any> Optional arguments to pass to the function
Returns: <any> The return value of the given function

Trace a synchronous function call. This will always produce a start event
and end event around the execution and may produce an error event
if the given function throws an error. This will run the given function using
channel.runStores(context, ...) on the start channel which ensures all
events should have any bound stores set to match this trace context.
To ensure only correct trace graphs are formed, events will only be published
if subscribers are present prior to starting the trace. Subscriptions which are
added after the trace begins will not receive future events from that trace,
only future traces will be seen.

import diagnostics_channel from 'node:diagnostics_channel';

const channels = diagnostics_channel.tracingChannel('my-channel');

channels.traceSync(() => {
  // Do something
}, {
  some: 'thing',
});const diagnostics_channel = require('node:diagnostics_channel');

const channels = diagnostics_channel.tracingChannel('my-channel');

channels.traceSync(() => {
  // Do something
}, {
  some: 'thing',
});copy

tracingChannel.tracePromise(fn[, context[, thisArg[, ...args]]])#

Added in: v19.9.0, v18.19.0


fn <Function> Promise-returning function to wrap a trace around
context <Object> Shared object to correlate trace events through
thisArg <any> The receiver to be used for the function call
...args <any> Optional arguments to pass to the function
Returns: <Promise> Chained from promise returned by the given function

Trace a promise-returning function call. This will always produce a
start event and end event around the synchronous portion of the
function execution, and will produce an asyncStart event and
asyncEnd event when a promise continuation is reached. It may also
produce an error event if the given function throws an error or the
returned promise rejects. This will run the given function using
channel.runStores(context, ...) on the start channel which ensures all
events should have any bound stores set to match this trace context.
To ensure only correct trace graphs are formed, events will only be published
if subscribers are present prior to starting the trace. Subscriptions which are
added after the trace begins will not receive future events from that trace,
only future traces will be seen.

import diagnostics_channel from 'node:diagnostics_channel';

const channels = diagnostics_channel.tracingChannel('my-channel');

channels.tracePromise(async () => {
  // Do something
}, {
  some: 'thing',
});const diagnostics_channel = require('node:diagnostics_channel');

const channels = diagnostics_channel.tracingChannel('my-channel');

channels.tracePromise(async () => {
  // Do something
}, {
  some: 'thing',
});copy

tracingChannel.traceCallback(fn[, position[, context[, thisArg[, ...args]]]])#

Added in: v19.9.0, v18.19.0


fn <Function> callback using function to wrap a trace around
position <number> Zero-indexed argument position of expected callback
(defaults to last argument if undefined is passed)
context <Object> Shared object to correlate trace events through (defaults
to {} if undefined is passed)
thisArg <any> The receiver to be used for the function call
...args <any> arguments to pass to the function (must include the callback)
Returns: <any> The return value of the given function

Trace a callback-receiving function call. The callback is expected to follow
the error as first arg convention typically used. This will always produce a
start event and end event around the synchronous portion of the
function execution, and will produce a asyncStart event and
asyncEnd event around the callback execution. It may also produce an
error event if the given function throws or the first argument passed to
the callback is set. This will run the given function using
channel.runStores(context, ...) on the start channel which ensures all
events should have any bound stores set to match this trace context.
To ensure only correct trace graphs are formed, events will only be published
if subscribers are present prior to starting the trace. Subscriptions which are
added after the trace begins will not receive future events from that trace,
only future traces will be seen.

import diagnostics_channel from 'node:diagnostics_channel';

const channels = diagnostics_channel.tracingChannel('my-channel');

channels.traceCallback((arg1, callback) => {
  // Do something
  callback(null, 'result');
}, 1, {
  some: 'thing',
}, thisArg, arg1, callback);const diagnostics_channel = require('node:diagnostics_channel');

const channels = diagnostics_channel.tracingChannel('my-channel');

channels.traceCallback((arg1, callback) => {
  // Do something
  callback(null, 'result');
}, 1, {
  some: 'thing',
}, thisArg, arg1, callback);copy
The callback will also be run with channel.runStores(context, ...) which
enables context loss recovery in some cases.

import diagnostics_channel from 'node:diagnostics_channel';
import { AsyncLocalStorage } from 'node:async_hooks';

const channels = diagnostics_channel.tracingChannel('my-channel');
const myStore = new AsyncLocalStorage();

// The start channel sets the initial store data to something
// and stores that store data value on the trace context object
channels.start.bindStore(myStore, (data) => {
  const span = new Span(data);
  data.span = span;
  return span;
});

// Then asyncStart can restore from that data it stored previously
channels.asyncStart.bindStore(myStore, (data) => {
  return data.span;
});const diagnostics_channel = require('node:diagnostics_channel');
const { AsyncLocalStorage } = require('node:async_hooks');

const channels = diagnostics_channel.tracingChannel('my-channel');
const myStore = new AsyncLocalStorage();

// The start channel sets the initial store data to something
// and stores that store data value on the trace context object
channels.start.bindStore(myStore, (data) => {
  const span = new Span(data);
  data.span = span;
  return span;
});

// Then asyncStart can restore from that data it stored previously
channels.asyncStart.bindStore(myStore, (data) => {
  return data.span;
});copy

tracingChannel.hasSubscribers#

Added in: v22.0.0, v20.13.0


Returns: <boolean> true if any of the individual channels has a subscriber,
false if not.

This is a helper method available on a TracingChannel instance to check if
any of the TracingChannel Channels have subscribers. A true is returned if
any of them have at least one subscriber, a false is returned otherwise.

import diagnostics_channel from 'node:diagnostics_channel';

const channels = diagnostics_channel.tracingChannel('my-channel');

if (channels.hasSubscribers) {
  // Do something
}const diagnostics_channel = require('node:diagnostics_channel');

const channels = diagnostics_channel.tracingChannel('my-channel');

if (channels.hasSubscribers) {
  // Do something
}copy

TracingChannel Channels#
A TracingChannel is a collection of several diagnostics_channels representing
specific points in the execution lifecycle of a single traceable action. The
behavior is split into five diagnostics_channels consisting of start,
end, asyncStart, asyncEnd, and error. A single traceable action will
share the same event object between all events, this can be helpful for
managing correlation through a weakmap.
These event objects will be extended with result or error values when
the task "completes". In the case of a synchronous task the result will be
the return value and the error will be anything thrown from the function.
With callback-based async functions the result will be the second argument
of the callback while the error will either be a thrown error visible in the
end event or the first callback argument in either of the asyncStart or
asyncEnd events.
To ensure only correct trace graphs are formed, events should only be published
if subscribers are present prior to starting the trace. Subscriptions which are
added after the trace begins should not receive future events from that trace,
only future traces will be seen.
Tracing channels should follow a naming pattern of:

tracing:module.class.method:start or tracing:module.function:start
tracing:module.class.method:end or tracing:module.function:end
tracing:module.class.method:asyncStart or tracing:module.function:asyncStart
tracing:module.class.method:asyncEnd or tracing:module.function:asyncEnd
tracing:module.class.method:error or tracing:module.function:error


start(event)#

Name: tracing:${name}:start

The start event represents the point at which a function is called. At this
point the event data may contain function arguments or anything else available
at the very start of the execution of the function.

end(event)#

Name: tracing:${name}:end

The end event represents the point at which a function call returns a value.
In the case of an async function this is when the promise returned not when the
function itself makes a return statement internally. At this point, if the
traced function was synchronous the result field will be set to the return
value of the function. Alternatively, the error field may be present to
represent any thrown errors.
It is recommended to listen specifically to the error event to track errors
as it may be possible for a traceable action to produce multiple errors. For
example, an async task which fails may be started internally before the sync
part of the task then throws an error.

asyncStart(event)#

Name: tracing:${name}:asyncStart

The asyncStart event represents the callback or continuation of a traceable
function being reached. At this point things like callback arguments may be
available, or anything else expressing the "result" of the action.
For callbacks-based functions, the first argument of the callback will be
assigned to the error field, if not undefined or null, and the second
argument will be assigned to the result field.
For promises, the argument to the resolve path will be assigned to result
or the argument to the reject path will be assign to error.
It is recommended to listen specifically to the error event to track errors
as it may be possible for a traceable action to produce multiple errors. For
example, an async task which fails may be started internally before the sync
part of the task then throws an error.

asyncEnd(event)#

Name: tracing:${name}:asyncEnd

The asyncEnd event represents the callback of an asynchronous function
returning. It's not likely event data will change after the asyncStart event,
however it may be useful to see the point where the callback completes.

error(event)#

Name: tracing:${name}:error

The error event represents any error produced by the traceable function
either synchronously or asynchronously. If an error is thrown in the
synchronous portion of the traced function the error will be assigned to the
error field of the event and the error event will be triggered. If an error
is received asynchronously through a callback or promise rejection it will also
be assigned to the error field of the event and trigger the error event.
It is possible for a single traceable function call to produce errors multiple
times so this should be considered when consuming this event. For example, if
another async task is triggered internally which fails and then the sync part
of the function then throws and error two error events will be emitted, one
for the sync error and one for the async error.

Built-in Channels#
Stability: 1 - Experimental
While the diagnostics_channel API is now considered stable, the built-in
channels currently available are not. Each channel must be declared stable
independently.

Console#
console.log

args <any[]>

Emitted when console.log() is called. Receives and array of the arguments
passed to console.log().
console.info

args <any[]>

Emitted when console.info() is called. Receives and array of the arguments
passed to console.info().
console.debug

args <any[]>

Emitted when console.debug() is called. Receives and array of the arguments
passed to console.debug().
console.warn

args <any[]>

Emitted when console.warn() is called. Receives and array of the arguments
passed to console.warn().
console.error

args <any[]>

Emitted when console.error() is called. Receives and array of the arguments
passed to console.error().

HTTP#
http.client.request.created

request <http.ClientRequest>

Emitted when client creates a request object.
Unlike http.client.request.start, this event is emitted before the request has been sent.
http.client.request.start

request <http.ClientRequest>

Emitted when client starts a request.
http.client.request.error

request <http.ClientRequest>
error <Error>

Emitted when an error occurs during a client request.
http.client.response.finish

request <http.ClientRequest>
response <http.IncomingMessage>

Emitted when client receives a response.
http.server.request.start

request <http.IncomingMessage>
response <http.ServerResponse>
socket <net.Socket>
server <http.Server>

Emitted when server receives a request.
http.server.response.created

request <http.IncomingMessage>
response <http.ServerResponse>

Emitted when server creates a response.
The event is emitted before the response is sent.
http.server.response.finish

request <http.IncomingMessage>
response <http.ServerResponse>
socket <net.Socket>
server <http.Server>

Emitted when server sends a response.

Modules#
module.require.start

event <Object> containing the following properties

id - Argument passed to require(). Module name.
parentFilename - Name of the module that attempted to require(id).



Emitted when require() is executed. See start event.
module.require.end

event <Object> containing the following properties

id - Argument passed to require(). Module name.
parentFilename - Name of the module that attempted to require(id).



Emitted when a require() call returns. See end event.
module.require.error

event <Object> containing the following properties

id - Argument passed to require(). Module name.
parentFilename - Name of the module that attempted to require(id).


error <Error>

Emitted when a require() throws an error. See error event.
module.import.asyncStart

event <Object> containing the following properties

id - Argument passed to import(). Module name.
parentURL - URL object of the module that attempted to import(id).



Emitted when import() is invoked. See asyncStart event.
module.import.asyncEnd

event <Object> containing the following properties

id - Argument passed to import(). Module name.
parentURL - URL object of the module that attempted to import(id).



Emitted when import() has completed. See asyncEnd event.
module.import.error

event <Object> containing the following properties

id - Argument passed to import(). Module name.
parentURL - URL object of the module that attempted to import(id).


error <Error>

Emitted when a import() throws an error. See error event.

NET#
net.client.socket

socket <net.Socket>

Emitted when a new TCP or pipe client socket is created.
net.server.socket

socket <net.Socket>

Emitted when a new TCP or pipe connection is received.
tracing:net.server.listen:asyncStart

server <net.Server>
options <Object>

Emitted when net.Server.listen() is invoked, before the port or pipe is actually setup.
tracing:net.server.listen:asyncEnd

server <net.Server>

Emitted when net.Server.listen() has completed and thus the server is ready to accept connection.
tracing:net.server.listen:error

server <net.Server>
error <Error>

Emitted when net.Server.listen() is returning an error.

UDP#
udp.socket

socket <dgram.Socket>

Emitted when a new UDP socket is created.

Process#

Added in: v16.18.0

child_process

process <ChildProcess>

Emitted when a new process is created.
execve

execPath <string>
args <string[]>
env <string[]>

Emitted when process.execve() is invoked.

Worker Thread#

Added in: v16.18.0

worker_threads

worker Worker

Emitted when a new thread is created.\n\n\n\nNode.js
        
      
      
About this documentation
Usage and example



Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Modules: TypeScript
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
Readline
REPL
Report
Single executable applications
SQLite
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker

    

    
      
        
          Node.js v24.0.1 documentation
          
            
            
          
        
        
          
            Node.js v24.0.1
            
    
      
        
        Table of contents
      

      
DNS

Class: dns.Resolver

Resolver([options])
resolver.cancel()
resolver.setLocalAddress([ipv4][, ipv6])


dns.getServers()
dns.lookup(hostname[, options], callback)

Supported getaddrinfo flags


dns.lookupService(address, port, callback)
dns.resolve(hostname[, rrtype], callback)
dns.resolve4(hostname[, options], callback)
dns.resolve6(hostname[, options], callback)
dns.resolveAny(hostname, callback)
dns.resolveCname(hostname, callback)
dns.resolveCaa(hostname, callback)
dns.resolveMx(hostname, callback)
dns.resolveNaptr(hostname, callback)
dns.resolveNs(hostname, callback)
dns.resolvePtr(hostname, callback)
dns.resolveSoa(hostname, callback)
dns.resolveSrv(hostname, callback)
dns.resolveTlsa(hostname, callback)
dns.resolveTxt(hostname, callback)
dns.reverse(ip, callback)
dns.setDefaultResultOrder(order)
dns.getDefaultResultOrder()
dns.setServers(servers)
DNS promises API

Class: dnsPromises.Resolver
resolver.cancel()
dnsPromises.getServers()
dnsPromises.lookup(hostname[, options])
dnsPromises.lookupService(address, port)
dnsPromises.resolve(hostname[, rrtype])
dnsPromises.resolve4(hostname[, options])
dnsPromises.resolve6(hostname[, options])
dnsPromises.resolveAny(hostname)
dnsPromises.resolveCaa(hostname)
dnsPromises.resolveCname(hostname)
dnsPromises.resolveMx(hostname)
dnsPromises.resolveNaptr(hostname)
dnsPromises.resolveNs(hostname)
dnsPromises.resolvePtr(hostname)
dnsPromises.resolveSoa(hostname)
dnsPromises.resolveSrv(hostname)
dnsPromises.resolveTlsa(hostname)
dnsPromises.resolveTxt(hostname)
dnsPromises.reverse(ip)
dnsPromises.setDefaultResultOrder(order)
dnsPromises.getDefaultResultOrder()
dnsPromises.setServers(servers)


Error codes
Implementation considerations

dns.lookup()
dns.resolve(), dns.resolve*(), and dns.reverse()





    
  
            
    
      
        
        Index
      

      
About this documentation
Usage and example

      
        Index
      
    
  


Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Modules: TypeScript
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
Readline
REPL
Report
Single executable applications
SQLite
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker

    
  
            
    
      
        
        Other versions
      
      24.x
23.x
22.x LTS
21.x
20.x LTS
19.x
18.x
17.x
16.x
15.x
14.x
13.x
12.x
11.x
10.x
9.x
8.x
7.x
6.x
5.x
4.x
0.12.x
0.10.x
    
  
            
              
                
                Options
              
        
              
                
                  
                    View on single page
                  
                  
                    View as JSON
                  
                  Edit on GitHub    
                
              
            
          
        
        
      

      Table of contents
DNS

Class: dns.Resolver

Resolver([options])
resolver.cancel()
resolver.setLocalAddress([ipv4][, ipv6])


dns.getServers()
dns.lookup(hostname[, options], callback)

Supported getaddrinfo flags


dns.lookupService(address, port, callback)
dns.resolve(hostname[, rrtype], callback)
dns.resolve4(hostname[, options], callback)
dns.resolve6(hostname[, options], callback)
dns.resolveAny(hostname, callback)
dns.resolveCname(hostname, callback)
dns.resolveCaa(hostname, callback)
dns.resolveMx(hostname, callback)
dns.resolveNaptr(hostname, callback)
dns.resolveNs(hostname, callback)
dns.resolvePtr(hostname, callback)
dns.resolveSoa(hostname, callback)
dns.resolveSrv(hostname, callback)
dns.resolveTlsa(hostname, callback)
dns.resolveTxt(hostname, callback)
dns.reverse(ip, callback)
dns.setDefaultResultOrder(order)
dns.getDefaultResultOrder()
dns.setServers(servers)
DNS promises API

Class: dnsPromises.Resolver
resolver.cancel()
dnsPromises.getServers()
dnsPromises.lookup(hostname[, options])
dnsPromises.lookupService(address, port)
dnsPromises.resolve(hostname[, rrtype])
dnsPromises.resolve4(hostname[, options])
dnsPromises.resolve6(hostname[, options])
dnsPromises.resolveAny(hostname)
dnsPromises.resolveCaa(hostname)
dnsPromises.resolveCname(hostname)
dnsPromises.resolveMx(hostname)
dnsPromises.resolveNaptr(hostname)
dnsPromises.resolveNs(hostname)
dnsPromises.resolvePtr(hostname)
dnsPromises.resolveSoa(hostname)
dnsPromises.resolveSrv(hostname)
dnsPromises.resolveTlsa(hostname)
dnsPromises.resolveTxt(hostname)
dnsPromises.reverse(ip)
dnsPromises.setDefaultResultOrder(order)
dnsPromises.getDefaultResultOrder()
dnsPromises.setServers(servers)


Error codes
Implementation considerations

dns.lookup()
dns.resolve(), dns.resolve*(), and dns.reverse()






      
        DNS#

Stability: 2 - Stable
Source Code: lib/dns.js
The node:dns module enables name resolution. For example, use it to look up IP
addresses of host names.
Although named for the Domain Name System (DNS), it does not always use the
DNS protocol for lookups. dns.lookup() uses the operating system
facilities to perform name resolution. It may not need to perform any network
communication. To perform name resolution the way other applications on the same
system do, use dns.lookup().

import dns from 'node:dns';

dns.lookup('example.org', (err, address, family) => {
  console.log('address: %j family: IPv%s', address, family);
});
// address: "2606:2800:21f:cb07:6820:80da:af6b:8b2c" family: IPv6const dns = require('node:dns');

dns.lookup('example.org', (err, address, family) => {
  console.log('address: %j family: IPv%s', address, family);
});
// address: "2606:2800:21f:cb07:6820:80da:af6b:8b2c" family: IPv6copy
All other functions in the node:dns module connect to an actual DNS server to
perform name resolution. They will always use the network to perform DNS
queries. These functions do not use the same set of configuration files used by
dns.lookup() (e.g. /etc/hosts). Use these functions to always perform
DNS queries, bypassing other name-resolution facilities.

import dns from 'node:dns';

dns.resolve4('archive.org', (err, addresses) => {
  if (err) throw err;

  console.log(`addresses: ${JSON.stringify(addresses)}`);

  addresses.forEach((a) => {
    dns.reverse(a, (err, hostnames) => {
      if (err) {
        throw err;
      }
      console.log(`reverse for ${a}: ${JSON.stringify(hostnames)}`);
    });
  });
});const dns = require('node:dns');

dns.resolve4('archive.org', (err, addresses) => {
  if (err) throw err;

  console.log(`addresses: ${JSON.stringify(addresses)}`);

  addresses.forEach((a) => {
    dns.reverse(a, (err, hostnames) => {
      if (err) {
        throw err;
      }
      console.log(`reverse for ${a}: ${JSON.stringify(hostnames)}`);
    });
  });
});copy
See the Implementation considerations section for more information.
Class: dns.Resolver#

Added in: v8.3.0

An independent resolver for DNS requests.
Creating a new resolver uses the default server settings. Setting
the servers used for a resolver using
resolver.setServers() does not affect
other resolvers:

import { Resolver } from 'node:dns';
const resolver = new Resolver();
resolver.setServers(['4.4.4.4']);

// This request will use the server at 4.4.4.4, independent of global settings.
resolver.resolve4('example.org', (err, addresses) => {
  // ...
});const { Resolver } = require('node:dns');
const resolver = new Resolver();
resolver.setServers(['4.4.4.4']);

// This request will use the server at 4.4.4.4, independent of global settings.
resolver.resolve4('example.org', (err, addresses) => {
  // ...
});copy
The following methods from the node:dns module are available:

resolver.getServers()
resolver.resolve()
resolver.resolve4()
resolver.resolve6()
resolver.resolveAny()
resolver.resolveCaa()
resolver.resolveCname()
resolver.resolveMx()
resolver.resolveNaptr()
resolver.resolveNs()
resolver.resolvePtr()
resolver.resolveSoa()
resolver.resolveSrv()
resolver.resolveTlsa()
resolver.resolveTxt()
resolver.reverse()
resolver.setServers()


Resolver([options])#

History

VersionChanges
v16.7.0, v14.18.0
The options object now accepts a tries option.
v12.18.3
The constructor now accepts an options object. The single supported option is timeout.
v8.3.0
Added in: v8.3.0



Create a new resolver.

options <Object>

timeout <integer> Query timeout in milliseconds, or -1 to use the
default timeout.
tries <integer> The number of tries the resolver will try contacting
each name server before giving up. Default: 4




resolver.cancel()#

Added in: v8.3.0

Cancel all outstanding DNS queries made by this resolver. The corresponding
callbacks will be called with an error with code ECANCELLED.

resolver.setLocalAddress([ipv4][, ipv6])#

Added in: v15.1.0, v14.17.0


ipv4 <string> A string representation of an IPv4 address.
Default: '0.0.0.0'
ipv6 <string> A string representation of an IPv6 address.
Default: '::0'

The resolver instance will send its requests from the specified IP address.
This allows programs to specify outbound interfaces when used on multi-homed
systems.
If a v4 or v6 address is not specified, it is set to the default and the
operating system will choose a local address automatically.
The resolver will use the v4 local address when making requests to IPv4 DNS
servers, and the v6 local address when making requests to IPv6 DNS servers.
The rrtype of resolution requests has no impact on the local address used.

dns.getServers()#

Added in: v0.11.3


Returns: <string[]>

Returns an array of IP address strings, formatted according to RFC 5952,
that are currently configured for DNS resolution. A string will include a port
section if a custom port is used.

[
  '8.8.8.8',
  '2001:4860:4860::8888',
  '8.8.8.8:1053',
  '[2001:4860:4860::8888]:1053',
] copy
dns.lookup(hostname[, options], callback)#

History

VersionChanges
v22.1.0, v20.13.0
The verbatim option is now deprecated in favor of the new order option.
v18.4.0
For compatibility with node:net, when passing an option object the family option can be the string 'IPv4' or the string 'IPv6'.
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v17.0.0
The verbatim options defaults to true now.
v8.5.0
The verbatim option is supported now.
v1.2.0
The all option is supported now.
v0.1.90
Added in: v0.1.90




hostname <string>
options <integer> | <Object>

family <integer> | <string> The record family. Must be 4, 6, or 0. For
backward compatibility reasons,'IPv4' and 'IPv6' are interpreted as 4
and 6 respectively. The value 0 indicates that either an IPv4 or IPv6
address is returned. If the value 0 is used with { all: true } (see
below), either one of or both IPv4 and IPv6 addresses are returned,
depending on the system's DNS resolver. Default: 0.
hints <number> One or more supported getaddrinfo flags. Multiple
flags may be passed by bitwise ORing their values.
all <boolean> When true, the callback returns all resolved addresses in
an array. Otherwise, returns a single address. Default: false.
order <string> When verbatim, the resolved addresses are return
unsorted. When ipv4first, the resolved addresses are sorted by placing
IPv4 addresses before IPv6 addresses. When ipv6first, the resolved
addresses are sorted by placing IPv6 addresses before IPv4 addresses.
Default: verbatim (addresses are not reordered).
Default value is configurable using dns.setDefaultResultOrder() or
--dns-result-order.
verbatim <boolean> When true, the callback receives IPv4 and IPv6
addresses in the order the DNS resolver returned them. When false,
IPv4 addresses are placed before IPv6 addresses.
This option will be deprecated in favor of order. When both are specified,
order has higher precedence. New code should only use order.
Default: true (addresses are not reordered). Default value is
configurable using dns.setDefaultResultOrder() or
--dns-result-order.


callback <Function>

err <Error>
address <string> A string representation of an IPv4 or IPv6 address.
family <integer> 4 or 6, denoting the family of address, or 0 if
the address is not an IPv4 or IPv6 address. 0 is a likely indicator of a
bug in the name resolution service used by the operating system.



Resolves a host name (e.g. 'nodejs.org') into the first found A (IPv4) or
AAAA (IPv6) record. All option properties are optional. If options is an
integer, then it must be 4 or 6 – if options is not provided, then
either IPv4 or IPv6 addresses, or both, are returned if found.
With the all option set to true, the arguments for callback change to
(err, addresses), with addresses being an array of objects with the
properties address and family.
On error, err is an Error object, where err.code is the error code.
Keep in mind that err.code will be set to 'ENOTFOUND' not only when
the host name does not exist but also when the lookup fails in other ways
such as no available file descriptors.
dns.lookup() does not necessarily have anything to do with the DNS protocol.
The implementation uses an operating system facility that can associate names
with addresses and vice versa. This implementation can have subtle but
important consequences on the behavior of any Node.js program. Please take some
time to consult the Implementation considerations section before using
dns.lookup().
Example usage:

import dns from 'node:dns';
const options = {
  family: 6,
  hints: dns.ADDRCONFIG | dns.V4MAPPED,
};
dns.lookup('example.org', options, (err, address, family) =>
  console.log('address: %j family: IPv%s', address, family));
// address: "2606:2800:21f:cb07:6820:80da:af6b:8b2c" family: IPv6

// When options.all is true, the result will be an Array.
options.all = true;
dns.lookup('example.org', options, (err, addresses) =>
  console.log('addresses: %j', addresses));
// addresses: [{"address":"2606:2800:21f:cb07:6820:80da:af6b:8b2c","family":6}]const dns = require('node:dns');
const options = {
  family: 6,
  hints: dns.ADDRCONFIG | dns.V4MAPPED,
};
dns.lookup('example.org', options, (err, address, family) =>
  console.log('address: %j family: IPv%s', address, family));
// address: "2606:2800:21f:cb07:6820:80da:af6b:8b2c" family: IPv6

// When options.all is true, the result will be an Array.
options.all = true;
dns.lookup('example.org', options, (err, addresses) =>
  console.log('addresses: %j', addresses));
// addresses: [{"address":"2606:2800:21f:cb07:6820:80da:af6b:8b2c","family":6}]copy
If this method is invoked as its util.promisify()ed version, and all
is not set to true, it returns a Promise for an Object with address and
family properties.

Supported getaddrinfo flags#

History

VersionChanges
v13.13.0, v12.17.0
Added support for the dns.ALL flag.



The following flags can be passed as hints to dns.lookup().

dns.ADDRCONFIG: Limits returned address types to the types of non-loopback
addresses configured on the system. For example, IPv4 addresses are only
returned if the current system has at least one IPv4 address configured.
dns.V4MAPPED: If the IPv6 family was specified, but no IPv6 addresses were
found, then return IPv4 mapped IPv6 addresses. It is not supported
on some operating systems (e.g. FreeBSD 10.1).
dns.ALL: If dns.V4MAPPED is specified, return resolved IPv6 addresses as
well as IPv4 mapped IPv6 addresses.


dns.lookupService(address, port, callback)#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v0.11.14
Added in: v0.11.14




address <string>
port <number>
callback <Function>

err <Error>
hostname <string> e.g. example.com
service <string> e.g. http



Resolves the given address and port into a host name and service using
the operating system's underlying getnameinfo implementation.
If address is not a valid IP address, a TypeError will be thrown.
The port will be coerced to a number. If it is not a legal port, a TypeError
will be thrown.
On an error, err is an Error object, where err.code is the error code.

import dns from 'node:dns';
dns.lookupService('127.0.0.1', 22, (err, hostname, service) => {
  console.log(hostname, service);
  // Prints: localhost ssh
});const dns = require('node:dns');
dns.lookupService('127.0.0.1', 22, (err, hostname, service) => {
  console.log(hostname, service);
  // Prints: localhost ssh
});copy
If this method is invoked as its util.promisify()ed version, it returns a
Promise for an Object with hostname and service properties.
dns.resolve(hostname[, rrtype], callback)#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v0.1.27
Added in: v0.1.27




hostname <string> Host name to resolve.
rrtype <string> Resource record type. Default: 'A'.
callback <Function>

err <Error>
records <string[]> | <Object[]> | <Object>



Uses the DNS protocol to resolve a host name (e.g. 'nodejs.org') into an array
of the resource records. The callback function has arguments
(err, records). When successful, records will be an array of resource
records. The type and structure of individual results varies based on rrtype:

























































































rrtyperecords containsResult typeShorthand method'A'IPv4 addresses (default)<string>dns.resolve4()'AAAA'IPv6 addresses<string>dns.resolve6()'ANY'any records<Object>dns.resolveAny()'CAA'CA authorization records<Object>dns.resolveCaa()'CNAME'canonical name records<string>dns.resolveCname()'MX'mail exchange records<Object>dns.resolveMx()'NAPTR'name authority pointer records<Object>dns.resolveNaptr()'NS'name server records<string>dns.resolveNs()'PTR'pointer records<string>dns.resolvePtr()'SOA'start of authority records<Object>dns.resolveSoa()'SRV'service records<Object>dns.resolveSrv()'TLSA'certificate associations<Object>dns.resolveTlsa()'TXT'text records<string[]>dns.resolveTxt()
On error, err is an Error object, where err.code is one of the
DNS error codes.
dns.resolve4(hostname[, options], callback)#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v7.2.0
This method now supports passing options, specifically options.ttl.
v0.1.16
Added in: v0.1.16




hostname <string> Host name to resolve.
options <Object>

ttl <boolean> Retrieves the Time-To-Live value (TTL) of each record.
When true, the callback receives an array of
{ address: '1.2.3.4', ttl: 60 } objects rather than an array of strings,
with the TTL expressed in seconds.


callback <Function>

err <Error>
addresses <string[]> | <Object[]>



Uses the DNS protocol to resolve a IPv4 addresses (A records) for the
hostname. The addresses argument passed to the callback function
will contain an array of IPv4 addresses (e.g.
['74.125.79.104', '74.125.79.105', '74.125.79.106']).
dns.resolve6(hostname[, options], callback)#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v7.2.0
This method now supports passing options, specifically options.ttl.
v0.1.16
Added in: v0.1.16




hostname <string> Host name to resolve.
options <Object>

ttl <boolean> Retrieve the Time-To-Live value (TTL) of each record.
When true, the callback receives an array of
{ address: '0:1:2:3:4:5:6:7', ttl: 60 } objects rather than an array of
strings, with the TTL expressed in seconds.


callback <Function>

err <Error>
addresses <string[]> | <Object[]>



Uses the DNS protocol to resolve IPv6 addresses (AAAA records) for the
hostname. The addresses argument passed to the callback function
will contain an array of IPv6 addresses.
dns.resolveAny(hostname, callback)#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.




hostname <string>
callback <Function>

err <Error>
ret <Object[]>



Uses the DNS protocol to resolve all records (also known as ANY or * query).
The ret argument passed to the callback function will be an array containing
various types of records. Each object has a property type that indicates the
type of the current record. And depending on the type, additional properties
will be present on the object:





















































TypeProperties'A'address/ttl'AAAA'address/ttl'CNAME'value'MX'Refer to dns.resolveMx()'NAPTR'Refer to dns.resolveNaptr()'NS'value'PTR'value'SOA'Refer to dns.resolveSoa()'SRV'Refer to dns.resolveSrv()'TLSA'Refer to dns.resolveTlsa()'TXT'This type of record contains an array property called entries which refers to dns.resolveTxt(), e.g. { entries: ['...'], type: 'TXT' }
Here is an example of the ret object passed to the callback:

[ { type: 'A', address: '127.0.0.1', ttl: 299 },
  { type: 'CNAME', value: 'example.com' },
  { type: 'MX', exchange: 'alt4.aspmx.l.example.com', priority: 50 },
  { type: 'NS', value: 'ns1.example.com' },
  { type: 'TXT', entries: [ 'v=spf1 include:_spf.example.com ~all' ] },
  { type: 'SOA',
    nsname: 'ns1.example.com',
    hostmaster: 'admin.example.com',
    serial: 156696742,
    refresh: 900,
    retry: 900,
    expire: 1800,
    minttl: 60 } ] copy
DNS server operators may choose not to respond to ANY
queries. It may be better to call individual methods like dns.resolve4(),
dns.resolveMx(), and so on. For more details, see RFC 8482.
dns.resolveCname(hostname, callback)#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v0.3.2
Added in: v0.3.2




hostname <string>
callback <Function>

err <Error>
addresses <string[]>



Uses the DNS protocol to resolve CNAME records for the hostname. The
addresses argument passed to the callback function
will contain an array of canonical name records available for the hostname
(e.g. ['bar.example.com']).
dns.resolveCaa(hostname, callback)#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v15.0.0, v14.17.0
Added in: v15.0.0, v14.17.0




hostname <string>
callback <Function>

err <Error>
records <Object[]>



Uses the DNS protocol to resolve CAA records for the hostname. The
addresses argument passed to the callback function
will contain an array of certification authority authorization records
available for the hostname (e.g. [{critical: 0, iodef: 'mailto:pki@example.com'}, {critical: 128, issue: 'pki.example.com'}]).
dns.resolveMx(hostname, callback)#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v0.1.27
Added in: v0.1.27




hostname <string>
callback <Function>

err <Error>
addresses <Object[]>



Uses the DNS protocol to resolve mail exchange records (MX records) for the
hostname. The addresses argument passed to the callback function will
contain an array of objects containing both a priority and exchange
property (e.g. [{priority: 10, exchange: 'mx.example.com'}, ...]).
dns.resolveNaptr(hostname, callback)#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v0.9.12
Added in: v0.9.12




hostname <string>
callback <Function>

err <Error>
addresses <Object[]>



Uses the DNS protocol to resolve regular expression-based records (NAPTR
records) for the hostname. The addresses argument passed to the callback
function will contain an array of objects with the following properties:

flags
service
regexp
replacement
order
preference


{
  flags: 's',
  service: 'SIP+D2U',
  regexp: '',
  replacement: '_sip._udp.example.com',
  order: 30,
  preference: 100
} copy
dns.resolveNs(hostname, callback)#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v0.1.90
Added in: v0.1.90




hostname <string>
callback <Function>

err <Error>
addresses <string[]>



Uses the DNS protocol to resolve name server records (NS records) for the
hostname. The addresses argument passed to the callback function will
contain an array of name server records available for hostname
(e.g. ['ns1.example.com', 'ns2.example.com']).
dns.resolvePtr(hostname, callback)#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v6.0.0
Added in: v6.0.0




hostname <string>
callback <Function>

err <Error>
addresses <string[]>



Uses the DNS protocol to resolve pointer records (PTR records) for the
hostname. The addresses argument passed to the callback function will
be an array of strings containing the reply records.
dns.resolveSoa(hostname, callback)#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v0.11.10
Added in: v0.11.10




hostname <string>
callback <Function>

err <Error>
address <Object>



Uses the DNS protocol to resolve a start of authority record (SOA record) for
the hostname. The address argument passed to the callback function will
be an object with the following properties:

nsname
hostmaster
serial
refresh
retry
expire
minttl


{
  nsname: 'ns.example.com',
  hostmaster: 'root.example.com',
  serial: 2013101809,
  refresh: 10000,
  retry: 2400,
  expire: 604800,
  minttl: 3600
} copy
dns.resolveSrv(hostname, callback)#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v0.1.27
Added in: v0.1.27




hostname <string>
callback <Function>

err <Error>
addresses <Object[]>



Uses the DNS protocol to resolve service records (SRV records) for the
hostname. The addresses argument passed to the callback function will
be an array of objects with the following properties:

priority
weight
port
name


{
  priority: 10,
  weight: 5,
  port: 21223,
  name: 'service.example.com'
} copy
dns.resolveTlsa(hostname, callback)#

Added in: v23.9.0, v22.15.0



hostname <string>
callback <Function>

err <Error>
records <Object[]>




Uses the DNS protocol to resolve certificate associations (TLSA records) for
the hostname. The records argument passed to the callback function is an
array of objects with these properties:

certUsage
selector
match
data


{
  certUsage: 3,
  selector: 1,
  match: 1,
  data: [ArrayBuffer]
} copy
dns.resolveTxt(hostname, callback)#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v0.1.27
Added in: v0.1.27





hostname <string>
callback <Function>

err <Error>
records <string[][]>




Uses the DNS protocol to resolve text queries (TXT records) for the
hostname. The records argument passed to the callback function is a
two-dimensional array of the text records available for hostname (e.g.
[ ['v=spf1 ip4:0.0.0.0 ', '~all' ] ]). Each sub-array contains TXT chunks of
one record. Depending on the use case, these could be either joined together or
treated separately.
dns.reverse(ip, callback)#

Added in: v0.1.16


ip <string>
callback <Function>

err <Error>
hostnames <string[]>



Performs a reverse DNS query that resolves an IPv4 or IPv6 address to an
array of host names.
On error, err is an Error object, where err.code is
one of the DNS error codes.
dns.setDefaultResultOrder(order)#

History

VersionChanges
v22.1.0, v20.13.0
The ipv6first value is supported now.
v17.0.0
Changed default value to verbatim.
v16.4.0, v14.18.0
Added in: v16.4.0, v14.18.0




order <string> must be 'ipv4first', 'ipv6first' or 'verbatim'.

Set the default value of order in dns.lookup() and
dnsPromises.lookup(). The value could be:

ipv4first: sets default order to ipv4first.
ipv6first: sets default order to ipv6first.
verbatim: sets default order to verbatim.

The default is verbatim and dns.setDefaultResultOrder() have higher
priority than --dns-result-order. When using worker threads,
dns.setDefaultResultOrder() from the main thread won't affect the default
dns orders in workers.
dns.getDefaultResultOrder()#

History

VersionChanges
v22.1.0, v20.13.0
The ipv6first value is supported now.
v20.1.0, v18.17.0
Added in: v20.1.0, v18.17.0



Get the default value for order in dns.lookup() and
dnsPromises.lookup(). The value could be:

ipv4first: for order defaulting to ipv4first.
ipv6first: for order defaulting to ipv6first.
verbatim: for order defaulting to verbatim.

dns.setServers(servers)#

Added in: v0.11.3


servers <string[]> array of RFC 5952 formatted addresses

Sets the IP address and port of servers to be used when performing DNS
resolution. The servers argument is an array of RFC 5952 formatted
addresses. If the port is the IANA default DNS port (53) it can be omitted.
dns.setServers([
  '8.8.8.8',
  '[2001:4860:4860::8888]',
  '8.8.8.8:1053',
  '[2001:4860:4860::8888]:1053',
]); copy
An error will be thrown if an invalid address is provided.
The dns.setServers() method must not be called while a DNS query is in
progress.
The dns.setServers() method affects only dns.resolve(),
dns.resolve*() and dns.reverse() (and specifically not
dns.lookup()).
This method works much like
resolve.conf.
That is, if attempting to resolve with the first server provided results in a
NOTFOUND error, the resolve() method will not attempt to resolve with
subsequent servers provided. Fallback DNS servers will only be used if the
earlier ones time out or result in some other error.
DNS promises API#

History

VersionChanges
v15.0.0
Exposed as require('dns/promises').
v11.14.0, v10.17.0
This API is no longer experimental.
v10.6.0
Added in: v10.6.0



The dns.promises API provides an alternative set of asynchronous DNS methods
that return Promise objects rather than using callbacks. The API is accessible
via require('node:dns').promises or require('node:dns/promises').

Class: dnsPromises.Resolver#

Added in: v10.6.0

An independent resolver for DNS requests.
Creating a new resolver uses the default server settings. Setting
the servers used for a resolver using
resolver.setServers() does not affect
other resolvers:

import { Resolver } from 'node:dns/promises';
const resolver = new Resolver();
resolver.setServers(['4.4.4.4']);

// This request will use the server at 4.4.4.4, independent of global settings.
const addresses = await resolver.resolve4('example.org');const { Resolver } = require('node:dns').promises;
const resolver = new Resolver();
resolver.setServers(['4.4.4.4']);

// This request will use the server at 4.4.4.4, independent of global settings.
resolver.resolve4('example.org').then((addresses) => {
  // ...
});

// Alternatively, the same code can be written using async-await style.
(async function() {
  const addresses = await resolver.resolve4('example.org');
})();copy
The following methods from the dnsPromises API are available:

resolver.getServers()
resolver.resolve()
resolver.resolve4()
resolver.resolve6()
resolver.resolveAny()
resolver.resolveCaa()
resolver.resolveCname()
resolver.resolveMx()
resolver.resolveNaptr()
resolver.resolveNs()
resolver.resolvePtr()
resolver.resolveSoa()
resolver.resolveSrv()
resolver.resolveTlsa()
resolver.resolveTxt()
resolver.reverse()
resolver.setServers()


resolver.cancel()#

Added in: v15.3.0, v14.17.0

Cancel all outstanding DNS queries made by this resolver. The corresponding
promises will be rejected with an error with the code ECANCELLED.

dnsPromises.getServers()#

Added in: v10.6.0


Returns: <string[]>

Returns an array of IP address strings, formatted according to RFC 5952,
that are currently configured for DNS resolution. A string will include a port
section if a custom port is used.

[
  '8.8.8.8',
  '2001:4860:4860::8888',
  '8.8.8.8:1053',
  '[2001:4860:4860::8888]:1053',
] copy

dnsPromises.lookup(hostname[, options])#

History

VersionChanges
v22.1.0, v20.13.0
The verbatim option is now deprecated in favor of the new order option.
v10.6.0
Added in: v10.6.0




hostname <string>
options <integer> | <Object>

family <integer> The record family. Must be 4, 6, or 0. The value
0 indicates that either an IPv4 or IPv6 address is returned. If the
value 0 is used with { all: true } (see below), either one of or both
IPv4 and IPv6 addresses are returned, depending on the system's DNS
resolver. Default: 0.
hints <number> One or more supported getaddrinfo flags. Multiple
flags may be passed by bitwise ORing their values.
all <boolean> When true, the Promise is resolved with all addresses in
an array. Otherwise, returns a single address. Default: false.
order <string> When verbatim, the Promise is resolved with IPv4 and
IPv6 addresses in the order the DNS resolver returned them. When ipv4first,
IPv4 addresses are placed before IPv6 addresses. When ipv6first,
IPv6 addresses are placed before IPv4 addresses.
Default: verbatim (addresses are not reordered).
Default value is configurable using dns.setDefaultResultOrder() or
--dns-result-order. New code should use { order: 'verbatim' }.
verbatim <boolean> When true, the Promise is resolved with IPv4 and
IPv6 addresses in the order the DNS resolver returned them. When false,
IPv4 addresses are placed before IPv6 addresses.
This option will be deprecated in favor of order. When both are specified,
order has higher precedence. New code should only use order.
Default: currently false (addresses are reordered) but this is
expected to change in the not too distant future. Default value is
configurable using dns.setDefaultResultOrder() or
--dns-result-order.



Resolves a host name (e.g. 'nodejs.org') into the first found A (IPv4) or
AAAA (IPv6) record. All option properties are optional. If options is an
integer, then it must be 4 or 6 – if options is not provided, then
either IPv4 or IPv6 addresses, or both, are returned if found.
With the all option set to true, the Promise is resolved with addresses
being an array of objects with the properties address and family.
On error, the Promise is rejected with an Error object, where err.code
is the error code.
Keep in mind that err.code will be set to 'ENOTFOUND' not only when
the host name does not exist but also when the lookup fails in other ways
such as no available file descriptors.
dnsPromises.lookup() does not necessarily have anything to do with the DNS
protocol. The implementation uses an operating system facility that can
associate names with addresses and vice versa. This implementation can have
subtle but important consequences on the behavior of any Node.js program. Please
take some time to consult the Implementation considerations section before
using dnsPromises.lookup().
Example usage:

import dns from 'node:dns';
const dnsPromises = dns.promises;
const options = {
  family: 6,
  hints: dns.ADDRCONFIG | dns.V4MAPPED,
};

await dnsPromises.lookup('example.org', options).then((result) => {
  console.log('address: %j family: IPv%s', result.address, result.family);
  // address: "2606:2800:21f:cb07:6820:80da:af6b:8b2c" family: IPv6
});

// When options.all is true, the result will be an Array.
options.all = true;
await dnsPromises.lookup('example.org', options).then((result) => {
  console.log('addresses: %j', result);
  // addresses: [{"address":"2606:2800:21f:cb07:6820:80da:af6b:8b2c","family":6}]
});const dns = require('node:dns');
const dnsPromises = dns.promises;
const options = {
  family: 6,
  hints: dns.ADDRCONFIG | dns.V4MAPPED,
};

dnsPromises.lookup('example.org', options).then((result) => {
  console.log('address: %j family: IPv%s', result.address, result.family);
  // address: "2606:2800:21f:cb07:6820:80da:af6b:8b2c" family: IPv6
});

// When options.all is true, the result will be an Array.
options.all = true;
dnsPromises.lookup('example.org', options).then((result) => {
  console.log('addresses: %j', result);
  // addresses: [{"address":"2606:2800:21f:cb07:6820:80da:af6b:8b2c","family":6}]
});copy

dnsPromises.lookupService(address, port)#

Added in: v10.6.0


address <string>
port <number>

Resolves the given address and port into a host name and service using
the operating system's underlying getnameinfo implementation.
If address is not a valid IP address, a TypeError will be thrown.
The port will be coerced to a number. If it is not a legal port, a TypeError
will be thrown.
On error, the Promise is rejected with an Error object, where err.code
is the error code.

import dnsPromises from 'node:dns/promises';
const result = await dnsPromises.lookupService('127.0.0.1', 22);

console.log(result.hostname, result.service); // Prints: localhost sshconst dnsPromises = require('node:dns').promises;
dnsPromises.lookupService('127.0.0.1', 22).then((result) => {
  console.log(result.hostname, result.service);
  // Prints: localhost ssh
});copy

dnsPromises.resolve(hostname[, rrtype])#

Added in: v10.6.0


hostname <string> Host name to resolve.
rrtype <string> Resource record type. Default: 'A'.

Uses the DNS protocol to resolve a host name (e.g. 'nodejs.org') into an array
of the resource records. When successful, the Promise is resolved with an
array of resource records. The type and structure of individual results vary
based on rrtype:

























































































rrtyperecords containsResult typeShorthand method'A'IPv4 addresses (default)<string>dnsPromises.resolve4()'AAAA'IPv6 addresses<string>dnsPromises.resolve6()'ANY'any records<Object>dnsPromises.resolveAny()'CAA'CA authorization records<Object>dnsPromises.resolveCaa()'CNAME'canonical name records<string>dnsPromises.resolveCname()'MX'mail exchange records<Object>dnsPromises.resolveMx()'NAPTR'name authority pointer records<Object>dnsPromises.resolveNaptr()'NS'name server records<string>dnsPromises.resolveNs()'PTR'pointer records<string>dnsPromises.resolvePtr()'SOA'start of authority records<Object>dnsPromises.resolveSoa()'SRV'service records<Object>dnsPromises.resolveSrv()'TLSA'certificate associations<Object>dnsPromises.resolveTlsa()'TXT'text records<string[]>dnsPromises.resolveTxt()
On error, the Promise is rejected with an Error object, where err.code
is one of the DNS error codes.

dnsPromises.resolve4(hostname[, options])#

Added in: v10.6.0


hostname <string> Host name to resolve.
options <Object>

ttl <boolean> Retrieve the Time-To-Live value (TTL) of each record.
When true, the Promise is resolved with an array of
{ address: '1.2.3.4', ttl: 60 } objects rather than an array of strings,
with the TTL expressed in seconds.



Uses the DNS protocol to resolve IPv4 addresses (A records) for the
hostname. On success, the Promise is resolved with an array of IPv4
addresses (e.g. ['74.125.79.104', '74.125.79.105', '74.125.79.106']).

dnsPromises.resolve6(hostname[, options])#

Added in: v10.6.0


hostname <string> Host name to resolve.
options <Object>

ttl <boolean> Retrieve the Time-To-Live value (TTL) of each record.
When true, the Promise is resolved with an array of
{ address: '0:1:2:3:4:5:6:7', ttl: 60 } objects rather than an array of
strings, with the TTL expressed in seconds.



Uses the DNS protocol to resolve IPv6 addresses (AAAA records) for the
hostname. On success, the Promise is resolved with an array of IPv6
addresses.

dnsPromises.resolveAny(hostname)#

Added in: v10.6.0


hostname <string>

Uses the DNS protocol to resolve all records (also known as ANY or * query).
On success, the Promise is resolved with an array containing various types of
records. Each object has a property type that indicates the type of the
current record. And depending on the type, additional properties will be
present on the object:





















































TypeProperties'A'address/ttl'AAAA'address/ttl'CNAME'value'MX'Refer to dnsPromises.resolveMx()'NAPTR'Refer to dnsPromises.resolveNaptr()'NS'value'PTR'value'SOA'Refer to dnsPromises.resolveSoa()'SRV'Refer to dnsPromises.resolveSrv()'TLSA'Refer to dnsPromises.resolveTlsa()'TXT'This type of record contains an array property called entries which refers to dnsPromises.resolveTxt(), e.g. { entries: ['...'], type: 'TXT' }
Here is an example of the result object:

[ { type: 'A', address: '127.0.0.1', ttl: 299 },
  { type: 'CNAME', value: 'example.com' },
  { type: 'MX', exchange: 'alt4.aspmx.l.example.com', priority: 50 },
  { type: 'NS', value: 'ns1.example.com' },
  { type: 'TXT', entries: [ 'v=spf1 include:_spf.example.com ~all' ] },
  { type: 'SOA',
    nsname: 'ns1.example.com',
    hostmaster: 'admin.example.com',
    serial: 156696742,
    refresh: 900,
    retry: 900,
    expire: 1800,
    minttl: 60 } ] copy

dnsPromises.resolveCaa(hostname)#

Added in: v15.0.0, v14.17.0


hostname <string>

Uses the DNS protocol to resolve CAA records for the hostname. On success,
the Promise is resolved with an array of objects containing available
certification authority authorization records available for the hostname
(e.g. [{critical: 0, iodef: 'mailto:pki@example.com'},{critical: 128, issue: 'pki.example.com'}]).

dnsPromises.resolveCname(hostname)#

Added in: v10.6.0


hostname <string>

Uses the DNS protocol to resolve CNAME records for the hostname. On success,
the Promise is resolved with an array of canonical name records available for
the hostname (e.g. ['bar.example.com']).

dnsPromises.resolveMx(hostname)#

Added in: v10.6.0


hostname <string>

Uses the DNS protocol to resolve mail exchange records (MX records) for the
hostname. On success, the Promise is resolved with an array of objects
containing both a priority and exchange property (e.g.
[{priority: 10, exchange: 'mx.example.com'}, ...]).

dnsPromises.resolveNaptr(hostname)#

Added in: v10.6.0


hostname <string>

Uses the DNS protocol to resolve regular expression-based records (NAPTR
records) for the hostname. On success, the Promise is resolved with an array
of objects with the following properties:

flags
service
regexp
replacement
order
preference


{
  flags: 's',
  service: 'SIP+D2U',
  regexp: '',
  replacement: '_sip._udp.example.com',
  order: 30,
  preference: 100
} copy

dnsPromises.resolveNs(hostname)#

Added in: v10.6.0


hostname <string>

Uses the DNS protocol to resolve name server records (NS records) for the
hostname. On success, the Promise is resolved with an array of name server
records available for hostname (e.g.
['ns1.example.com', 'ns2.example.com']).

dnsPromises.resolvePtr(hostname)#

Added in: v10.6.0


hostname <string>

Uses the DNS protocol to resolve pointer records (PTR records) for the
hostname. On success, the Promise is resolved with an array of strings
containing the reply records.

dnsPromises.resolveSoa(hostname)#

Added in: v10.6.0


hostname <string>

Uses the DNS protocol to resolve a start of authority record (SOA record) for
the hostname. On success, the Promise is resolved with an object with the
following properties:

nsname
hostmaster
serial
refresh
retry
expire
minttl


{
  nsname: 'ns.example.com',
  hostmaster: 'root.example.com',
  serial: 2013101809,
  refresh: 10000,
  retry: 2400,
  expire: 604800,
  minttl: 3600
} copy

dnsPromises.resolveSrv(hostname)#

Added in: v10.6.0


hostname <string>

Uses the DNS protocol to resolve service records (SRV records) for the
hostname. On success, the Promise is resolved with an array of objects with
the following properties:

priority
weight
port
name


{
  priority: 10,
  weight: 5,
  port: 21223,
  name: 'service.example.com'
} copy

dnsPromises.resolveTlsa(hostname)#

Added in: v23.9.0, v22.15.0


hostname <string>

Uses the DNS protocol to resolve certificate associations (TLSA records) for
the hostname. On success, the Promise is resolved with an array of objects
with these properties:

certUsage
selector
match
data


{
  certUsage: 3,
  selector: 1,
  match: 1,
  data: [ArrayBuffer]
} copy

dnsPromises.resolveTxt(hostname)#

Added in: v10.6.0


hostname <string>

Uses the DNS protocol to resolve text queries (TXT records) for the
hostname. On success, the Promise is resolved with a two-dimensional array
of the text records available for hostname (e.g.
[ ['v=spf1 ip4:0.0.0.0 ', '~all' ] ]). Each sub-array contains TXT chunks of
one record. Depending on the use case, these could be either joined together or
treated separately.

dnsPromises.reverse(ip)#

Added in: v10.6.0


ip <string>

Performs a reverse DNS query that resolves an IPv4 or IPv6 address to an
array of host names.
On error, the Promise is rejected with an Error object, where err.code
is one of the DNS error codes.

dnsPromises.setDefaultResultOrder(order)#

History

VersionChanges
v22.1.0, v20.13.0
The ipv6first value is supported now.
v17.0.0
Changed default value to verbatim.
v16.4.0, v14.18.0
Added in: v16.4.0, v14.18.0




order <string> must be 'ipv4first', 'ipv6first' or 'verbatim'.

Set the default value of order in dns.lookup() and
dnsPromises.lookup(). The value could be:

ipv4first: sets default order to ipv4first.
ipv6first: sets default order to ipv6first.
verbatim: sets default order to verbatim.

The default is verbatim and dnsPromises.setDefaultResultOrder() have
higher priority than --dns-result-order. When using worker threads,
dnsPromises.setDefaultResultOrder() from the main thread won't affect the
default dns orders in workers.

dnsPromises.getDefaultResultOrder()#

Added in: v20.1.0, v18.17.0

Get the value of dnsOrder.

dnsPromises.setServers(servers)#

Added in: v10.6.0


servers <string[]> array of RFC 5952 formatted addresses

Sets the IP address and port of servers to be used when performing DNS
resolution. The servers argument is an array of RFC 5952 formatted
addresses. If the port is the IANA default DNS port (53) it can be omitted.
dnsPromises.setServers([
  '8.8.8.8',
  '[2001:4860:4860::8888]',
  '8.8.8.8:1053',
  '[2001:4860:4860::8888]:1053',
]); copy
An error will be thrown if an invalid address is provided.
The dnsPromises.setServers() method must not be called while a DNS query is in
progress.
This method works much like
resolve.conf.
That is, if attempting to resolve with the first server provided results in a
NOTFOUND error, the resolve() method will not attempt to resolve with
subsequent servers provided. Fallback DNS servers will only be used if the
earlier ones time out or result in some other error.

Error codes#
Each DNS query can return one of the following error codes:

dns.NODATA: DNS server returned an answer with no data.
dns.FORMERR: DNS server claims query was misformatted.
dns.SERVFAIL: DNS server returned general failure.
dns.NOTFOUND: Domain name not found.
dns.NOTIMP: DNS server does not implement the requested operation.
dns.REFUSED: DNS server refused query.
dns.BADQUERY: Misformatted DNS query.
dns.BADNAME: Misformatted host name.
dns.BADFAMILY: Unsupported address family.
dns.BADRESP: Misformatted DNS reply.
dns.CONNREFUSED: Could not contact DNS servers.
dns.TIMEOUT: Timeout while contacting DNS servers.
dns.EOF: End of file.
dns.FILE: Error reading file.
dns.NOMEM: Out of memory.
dns.DESTRUCTION: Channel is being destroyed.
dns.BADSTR: Misformatted string.
dns.BADFLAGS: Illegal flags specified.
dns.NONAME: Given host name is not numeric.
dns.BADHINTS: Illegal hints flags specified.
dns.NOTINITIALIZED: c-ares library initialization not yet performed.
dns.LOADIPHLPAPI: Error loading iphlpapi.dll.
dns.ADDRGETNETWORKPARAMS: Could not find GetNetworkParams function.
dns.CANCELLED: DNS query cancelled.

The dnsPromises API also exports the above error codes, e.g., dnsPromises.NODATA.
Implementation considerations#
Although dns.lookup() and the various dns.resolve*()/dns.reverse()
functions have the same goal of associating a network name with a network
address (or vice versa), their behavior is quite different. These differences
can have subtle but significant consequences on the behavior of Node.js
programs.

dns.lookup()#
Under the hood, dns.lookup() uses the same operating system facilities
as most other programs. For instance, dns.lookup() will almost always
resolve a given name the same way as the ping command. On most POSIX-like
operating systems, the behavior of the dns.lookup() function can be
modified by changing settings in nsswitch.conf(5) and/or resolv.conf(5),
but changing these files will change the behavior of all other
programs running on the same operating system.
Though the call to dns.lookup() will be asynchronous from JavaScript's
perspective, it is implemented as a synchronous call to getaddrinfo(3) that runs
on libuv's threadpool. This can have surprising negative performance
implications for some applications, see the UV_THREADPOOL_SIZE
documentation for more information.
Various networking APIs will call dns.lookup() internally to resolve
host names. If that is an issue, consider resolving the host name to an address
using dns.resolve() and using the address instead of a host name. Also, some
networking APIs (such as socket.connect() and dgram.createSocket())
allow the default resolver, dns.lookup(), to be replaced.

dns.resolve(), dns.resolve*(), and dns.reverse()#
These functions are implemented quite differently than dns.lookup(). They
do not use getaddrinfo(3) and they always perform a DNS query on the
network. This network communication is always done asynchronously and does not
use libuv's threadpool.
As a result, these functions cannot have the same negative impact on other
processing that happens on libuv's threadpool that dns.lookup() can have.
They do not use the same set of configuration files that dns.lookup()
uses. For instance, they do not use the configuration from /etc/hosts.\n\n\n\nNode.js
        
      
      
About this documentation
Usage and example



Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Modules: TypeScript
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
Readline
REPL
Report
Single executable applications
SQLite
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker

    

    
      
        
          Node.js v24.0.1 documentation
          
            
            
          
        
        
          
            Node.js v24.0.1
            
    
      
        
        Table of contents
      

      
Domain

Warning: Don't ignore errors!
Additions to Error objects
Implicit binding
Explicit binding
domain.create()
Class: Domain

domain.members
domain.add(emitter)
domain.bind(callback)
domain.enter()
domain.exit()
domain.intercept(callback)
domain.remove(emitter)
domain.run(fn[, ...args])


Domains and promises



    
  
            
    
      
        
        Index
      

      
About this documentation
Usage and example

      
        Index
      
    
  


Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Modules: TypeScript
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
Readline
REPL
Report
Single executable applications
SQLite
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker

    
  
            
    
      
        
        Other versions
      
      24.x
23.x
22.x LTS
21.x
20.x LTS
19.x
18.x
17.x
16.x
15.x
14.x
13.x
12.x
11.x
10.x
9.x
8.x
7.x
6.x
5.x
4.x
0.12.x
0.10.x
    
  
            
              
                
                Options
              
        
              
                
                  
                    View on single page
                  
                  
                    View as JSON
                  
                  Edit on GitHub    
                
              
            
          
        
        
      

      Table of contents
Domain

Warning: Don't ignore errors!
Additions to Error objects
Implicit binding
Explicit binding
domain.create()
Class: Domain

domain.members
domain.add(emitter)
domain.bind(callback)
domain.enter()
domain.exit()
domain.intercept(callback)
domain.remove(emitter)
domain.run(fn[, ...args])


Domains and promises




      
        Domain#

History

VersionChanges
v8.8.0
Any Promises created in VM contexts no longer have a .domain property. Their handlers are still executed in the proper domain, however, and Promises created in the main context still possess a .domain property.
v8.0.0
Handlers for Promises are now invoked in the domain in which the first promise of a chain was created.
v1.4.2
Deprecated since: v1.4.2




Stability: 0 - Deprecated
Source Code: lib/domain.js
This module is pending deprecation. Once a replacement API has been
finalized, this module will be fully deprecated. Most developers should
not have cause to use this module. Users who absolutely must have
the functionality that domains provide may rely on it for the time being
but should expect to have to migrate to a different solution
in the future.
Domains provide a way to handle multiple different IO operations as a
single group. If any of the event emitters or callbacks registered to a
domain emit an 'error' event, or throw an error, then the domain object
will be notified, rather than losing the context of the error in the
process.on('uncaughtException') handler, or causing the program to
exit immediately with an error code.
Warning: Don't ignore errors!#

Domain error handlers are not a substitute for closing down a
process when an error occurs.
By the very nature of how throw works in JavaScript, there is almost
never any way to safely "pick up where it left off", without leaking
references, or creating some other sort of undefined brittle state.
The safest way to respond to a thrown error is to shut down the
process. Of course, in a normal web server, there may be many
open connections, and it is not reasonable to abruptly shut those down
because an error was triggered by someone else.
The better approach is to send an error response to the request that
triggered the error, while letting the others finish in their normal
time, and stop listening for new requests in that worker.
In this way, domain usage goes hand-in-hand with the cluster module,
since the primary process can fork a new worker when a worker
encounters an error. For Node.js programs that scale to multiple
machines, the terminating proxy or service registry can take note of
the failure, and react accordingly.
For example, this is not a good idea:
// XXX WARNING! BAD IDEA!

const d = require('node:domain').create();
d.on('error', (er) => {
  // The error won't crash the process, but what it does is worse!
  // Though we've prevented abrupt process restarting, we are leaking
  // a lot of resources if this ever happens.
  // This is no better than process.on('uncaughtException')!
  console.log(`error, but oh well ${er.message}`);
});
d.run(() => {
  require('node:http').createServer((req, res) => {
    handleRequest(req, res);
  }).listen(PORT);
}); copy
By using the context of a domain, and the resilience of separating our
program into multiple worker processes, we can react more
appropriately, and handle errors with much greater safety.
// Much better!

const cluster = require('node:cluster');
const PORT = +process.env.PORT || 1337;

if (cluster.isPrimary) {
  // A more realistic scenario would have more than 2 workers,
  // and perhaps not put the primary and worker in the same file.
  //
  // It is also possible to get a bit fancier about logging, and
  // implement whatever custom logic is needed to prevent DoS
  // attacks and other bad behavior.
  //
  // See the options in the cluster documentation.
  //
  // The important thing is that the primary does very little,
  // increasing our resilience to unexpected errors.

  cluster.fork();
  cluster.fork();

  cluster.on('disconnect', (worker) => {
    console.error('disconnect!');
    cluster.fork();
  });

} else {
  // the worker
  //
  // This is where we put our bugs!

  const domain = require('node:domain');

  // See the cluster documentation for more details about using
  // worker processes to serve requests. How it works, caveats, etc.

  const server = require('node:http').createServer((req, res) => {
    const d = domain.create();
    d.on('error', (er) => {
      console.error(`error ${er.stack}`);

      // We're in dangerous territory!
      // By definition, something unexpected occurred,
      // which we probably didn't want.
      // Anything can happen now! Be very careful!

      try {
        // Make sure we close down within 30 seconds
        const killtimer = setTimeout(() => {
          process.exit(1);
        }, 30000);
        // But don't keep the process open just for that!
        killtimer.unref();

        // Stop taking new requests.
        server.close();

        // Let the primary know we're dead. This will trigger a
        // 'disconnect' in the cluster primary, and then it will fork
        // a new worker.
        cluster.worker.disconnect();

        // Try to send an error to the request that triggered the problem
        res.statusCode = 500;
        res.setHeader('content-type', 'text/plain');
        res.end('Oops, there was a problem!\n');
      } catch (er2) {
        // Oh well, not much we can do at this point.
        console.error(`Error sending 500! ${er2.stack}`);
      }
    });

    // Because req and res were created before this domain existed,
    // we need to explicitly add them.
    // See the explanation of implicit vs explicit binding below.
    d.add(req);
    d.add(res);

    // Now run the handler function in the domain.
    d.run(() => {
      handleRequest(req, res);
    });
  });
  server.listen(PORT);
}

// This part is not important. Just an example routing thing.
// Put fancy application logic here.
function handleRequest(req, res) {
  switch (req.url) {
    case '/error':
      // We do some async stuff, and then...
      setTimeout(() => {
        // Whoops!
        flerb.bark();
      }, timeout);
      break;
    default:
      res.end('ok');
  }
} copy
Additions to Error objects#

Any time an Error object is routed through a domain, a few extra fields
are added to it.

error.domain The domain that first handled the error.
error.domainEmitter The event emitter that emitted an 'error' event
with the error object.
error.domainBound The callback function which was bound to the
domain, and passed an error as its first argument.
error.domainThrown A boolean indicating whether the error was
thrown, emitted, or passed to a bound callback function.

Implicit binding#

If domains are in use, then all new EventEmitter objects (including
Stream objects, requests, responses, etc.) will be implicitly bound to
the active domain at the time of their creation.
Additionally, callbacks passed to low-level event loop requests (such as
to fs.open(), or other callback-taking methods) will automatically be
bound to the active domain. If they throw, then the domain will catch
the error.
In order to prevent excessive memory usage, Domain objects themselves
are not implicitly added as children of the active domain. If they
were, then it would be too easy to prevent request and response objects
from being properly garbage collected.
To nest Domain objects as children of a parent Domain they must be
explicitly added.
Implicit binding routes thrown errors and 'error' events to the
Domain's 'error' event, but does not register the EventEmitter on the
Domain.
Implicit binding only takes care of thrown errors and 'error' events.
Explicit binding#

Sometimes, the domain in use is not the one that ought to be used for a
specific event emitter. Or, the event emitter could have been created
in the context of one domain, but ought to instead be bound to some
other domain.
For example, there could be one domain in use for an HTTP server, but
perhaps we would like to have a separate domain to use for each request.
That is possible via explicit binding.
// Create a top-level domain for the server
const domain = require('node:domain');
const http = require('node:http');
const serverDomain = domain.create();

serverDomain.run(() => {
  // Server is created in the scope of serverDomain
  http.createServer((req, res) => {
    // Req and res are also created in the scope of serverDomain
    // however, we'd prefer to have a separate domain for each request.
    // create it first thing, and add req and res to it.
    const reqd = domain.create();
    reqd.add(req);
    reqd.add(res);
    reqd.on('error', (er) => {
      console.error('Error', er, req.url);
      try {
        res.writeHead(500);
        res.end('Error occurred, sorry.');
      } catch (er2) {
        console.error('Error sending 500', er2, req.url);
      }
    });
  }).listen(1337);
}); copy
domain.create()#

Returns: <Domain>

Class: Domain#

Extends: <EventEmitter>

The Domain class encapsulates the functionality of routing errors and
uncaught exceptions to the active Domain object.
To handle the errors that it catches, listen to its 'error' event.

domain.members#

<Array>

An array of timers and event emitters that have been explicitly added
to the domain.

domain.add(emitter)#

emitter <EventEmitter> | <Timer> emitter or timer to be added to the domain

Explicitly adds an emitter to the domain. If any event handlers called by
the emitter throw an error, or if the emitter emits an 'error' event, it
will be routed to the domain's 'error' event, just like with implicit
binding.
This also works with timers that are returned from setInterval() and
setTimeout(). If their callback function throws, it will be caught by
the domain 'error' handler.
If the Timer or EventEmitter was already bound to a domain, it is removed
from that one, and bound to this one instead.

domain.bind(callback)#

callback <Function> The callback function
Returns: <Function> The bound function

The returned function will be a wrapper around the supplied callback
function. When the returned function is called, any errors that are
thrown will be routed to the domain's 'error' event.
const d = domain.create();

function readSomeFile(filename, cb) {
  fs.readFile(filename, 'utf8', d.bind((er, data) => {
    // If this throws, it will also be passed to the domain.
    return cb(er, data ? JSON.parse(data) : null);
  }));
}

d.on('error', (er) => {
  // An error occurred somewhere. If we throw it now, it will crash the program
  // with the normal line number and stack message.
}); copy

domain.enter()#
The enter() method is plumbing used by the run(), bind(), and
intercept() methods to set the active domain. It sets domain.active and
process.domain to the domain, and implicitly pushes the domain onto the domain
stack managed by the domain module (see domain.exit() for details on the
domain stack). The call to enter() delimits the beginning of a chain of
asynchronous calls and I/O operations bound to a domain.
Calling enter() changes only the active domain, and does not alter the domain
itself. enter() and exit() can be called an arbitrary number of times on a
single domain.

domain.exit()#
The exit() method exits the current domain, popping it off the domain stack.
Any time execution is going to switch to the context of a different chain of
asynchronous calls, it's important to ensure that the current domain is exited.
The call to exit() delimits either the end of or an interruption to the chain
of asynchronous calls and I/O operations bound to a domain.
If there are multiple, nested domains bound to the current execution context,
exit() will exit any domains nested within this domain.
Calling exit() changes only the active domain, and does not alter the domain
itself. enter() and exit() can be called an arbitrary number of times on a
single domain.

domain.intercept(callback)#

callback <Function> The callback function
Returns: <Function> The intercepted function

This method is almost identical to domain.bind(callback). However, in
addition to catching thrown errors, it will also intercept Error
objects sent as the first argument to the function.
In this way, the common if (err) return callback(err); pattern can be replaced
with a single error handler in a single place.
const d = domain.create();

function readSomeFile(filename, cb) {
  fs.readFile(filename, 'utf8', d.intercept((data) => {
    // Note, the first argument is never passed to the
    // callback since it is assumed to be the 'Error' argument
    // and thus intercepted by the domain.

    // If this throws, it will also be passed to the domain
    // so the error-handling logic can be moved to the 'error'
    // event on the domain instead of being repeated throughout
    // the program.
    return cb(null, JSON.parse(data));
  }));
}

d.on('error', (er) => {
  // An error occurred somewhere. If we throw it now, it will crash the program
  // with the normal line number and stack message.
}); copy

domain.remove(emitter)#

emitter <EventEmitter> | <Timer> emitter or timer to be removed from the domain

The opposite of domain.add(emitter). Removes domain handling from the
specified emitter.

domain.run(fn[, ...args])#

fn <Function>
...args <any>

Run the supplied function in the context of the domain, implicitly
binding all event emitters, timers, and low-level requests that are
created in that context. Optionally, arguments can be passed to
the function.
This is the most basic way to use a domain.
const domain = require('node:domain');
const fs = require('node:fs');
const d = domain.create();
d.on('error', (er) => {
  console.error('Caught error!', er);
});
d.run(() => {
  process.nextTick(() => {
    setTimeout(() => { // Simulating some various async stuff
      fs.open('non-existent file', 'r', (er, fd) => {
        if (er) throw er;
        // proceed...
      });
    }, 100);
  });
}); copy
In this example, the d.on('error') handler will be triggered, rather
than crashing the program.

Domains and promises#
As of Node.js 8.0.0, the handlers of promises are run inside the domain in
which the call to .then() or .catch() itself was made:
const d1 = domain.create();
const d2 = domain.create();

let p;
d1.run(() => {
  p = Promise.resolve(42);
});

d2.run(() => {
  p.then((v) => {
    // running in d2
  });
}); copy
A callback may be bound to a specific domain using domain.bind(callback):
const d1 = domain.create();
const d2 = domain.create();

let p;
d1.run(() => {
  p = Promise.resolve(42);
});

d2.run(() => {
  p.then(p.domain.bind((v) => {
    // running in d1
  }));
}); copy
Domains will not interfere with the error handling mechanisms for
promises. In other words, no 'error' event will be emitted for unhandled
Promise rejections.\n\n\n\nNode.js
        
      
      
About this documentation
Usage and example



Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Modules: TypeScript
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
Readline
REPL
Report
Single executable applications
SQLite
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker

    

    
      
        
          Node.js v24.0.1 documentation
          
            
            
          
        
        
          
            Node.js v24.0.1
            
    
      
        
        Table of contents
      

      
Errors

Error propagation and interception
Class: Error

new Error(message[, options])
Error.captureStackTrace(targetObject[, constructorOpt])
Error.stackTraceLimit
error.cause
error.code
error.message
error.stack


Class: AssertionError
Class: RangeError
Class: ReferenceError
Class: SyntaxError
Class: SystemError

error.address
error.code
error.dest
error.errno
error.info
error.message
error.path
error.port
error.syscall
Common system errors


Class: TypeError
Exceptions vs. errors
OpenSSL errors

error.opensslErrorStack
error.function
error.library
error.reason


Node.js error codes

ABORT_ERR
ERR_ACCESS_DENIED
ERR_AMBIGUOUS_ARGUMENT
ERR_ARG_NOT_ITERABLE
ERR_ASSERTION
ERR_ASYNC_CALLBACK
ERR_ASYNC_TYPE
ERR_BROTLI_COMPRESSION_FAILED
ERR_BROTLI_INVALID_PARAM
ERR_BUFFER_CONTEXT_NOT_AVAILABLE
ERR_BUFFER_OUT_OF_BOUNDS
ERR_BUFFER_TOO_LARGE
ERR_CANNOT_WATCH_SIGINT
ERR_CHILD_CLOSED_BEFORE_REPLY
ERR_CHILD_PROCESS_IPC_REQUIRED
ERR_CHILD_PROCESS_STDIO_MAXBUFFER
ERR_CLOSED_MESSAGE_PORT
ERR_CONSOLE_WRITABLE_STREAM
ERR_CONSTRUCT_CALL_INVALID
ERR_CONSTRUCT_CALL_REQUIRED
ERR_CONTEXT_NOT_INITIALIZED
ERR_CRYPTO_CUSTOM_ENGINE_NOT_SUPPORTED
ERR_CRYPTO_ECDH_INVALID_FORMAT
ERR_CRYPTO_ECDH_INVALID_PUBLIC_KEY
ERR_CRYPTO_ENGINE_UNKNOWN
ERR_CRYPTO_FIPS_FORCED
ERR_CRYPTO_FIPS_UNAVAILABLE
ERR_CRYPTO_HASH_FINALIZED
ERR_CRYPTO_HASH_UPDATE_FAILED
ERR_CRYPTO_INCOMPATIBLE_KEY
ERR_CRYPTO_INCOMPATIBLE_KEY_OPTIONS
ERR_CRYPTO_INITIALIZATION_FAILED
ERR_CRYPTO_INVALID_AUTH_TAG
ERR_CRYPTO_INVALID_COUNTER
ERR_CRYPTO_INVALID_CURVE
ERR_CRYPTO_INVALID_DIGEST
ERR_CRYPTO_INVALID_IV
ERR_CRYPTO_INVALID_JWK
ERR_CRYPTO_INVALID_KEYLEN
ERR_CRYPTO_INVALID_KEYPAIR
ERR_CRYPTO_INVALID_KEYTYPE
ERR_CRYPTO_INVALID_KEY_OBJECT_TYPE
ERR_CRYPTO_INVALID_MESSAGELEN
ERR_CRYPTO_INVALID_SCRYPT_PARAMS
ERR_CRYPTO_INVALID_STATE
ERR_CRYPTO_INVALID_TAG_LENGTH
ERR_CRYPTO_JOB_INIT_FAILED
ERR_CRYPTO_JWK_UNSUPPORTED_CURVE
ERR_CRYPTO_JWK_UNSUPPORTED_KEY_TYPE
ERR_CRYPTO_OPERATION_FAILED
ERR_CRYPTO_PBKDF2_ERROR
ERR_CRYPTO_SCRYPT_NOT_SUPPORTED
ERR_CRYPTO_SIGN_KEY_REQUIRED
ERR_CRYPTO_TIMING_SAFE_EQUAL_LENGTH
ERR_CRYPTO_UNKNOWN_CIPHER
ERR_CRYPTO_UNKNOWN_DH_GROUP
ERR_CRYPTO_UNSUPPORTED_OPERATION
ERR_DEBUGGER_ERROR
ERR_DEBUGGER_STARTUP_ERROR
ERR_DIR_CLOSED
ERR_DIR_CONCURRENT_OPERATION
ERR_DLOPEN_DISABLED
ERR_DLOPEN_FAILED
ERR_DNS_SET_SERVERS_FAILED
ERR_DOMAIN_CALLBACK_NOT_AVAILABLE
ERR_DOMAIN_CANNOT_SET_UNCAUGHT_EXCEPTION_CAPTURE
ERR_DUPLICATE_STARTUP_SNAPSHOT_MAIN_FUNCTION
ERR_ENCODING_INVALID_ENCODED_DATA
ERR_ENCODING_NOT_SUPPORTED
ERR_EVAL_ESM_CANNOT_PRINT
ERR_EVENT_RECURSION
ERR_EXECUTION_ENVIRONMENT_NOT_AVAILABLE
ERR_FALSY_VALUE_REJECTION
ERR_FEATURE_UNAVAILABLE_ON_PLATFORM
ERR_FS_CP_DIR_TO_NON_DIR
ERR_FS_CP_EEXIST
ERR_FS_CP_EINVAL
ERR_FS_CP_FIFO_PIPE
ERR_FS_CP_NON_DIR_TO_DIR
ERR_FS_CP_SOCKET
ERR_FS_CP_SYMLINK_TO_SUBDIRECTORY
ERR_FS_CP_UNKNOWN
ERR_FS_EISDIR
ERR_FS_FILE_TOO_LARGE
ERR_HTTP2_ALTSVC_INVALID_ORIGIN
ERR_HTTP2_ALTSVC_LENGTH
ERR_HTTP2_CONNECT_AUTHORITY
ERR_HTTP2_CONNECT_PATH
ERR_HTTP2_CONNECT_SCHEME
ERR_HTTP2_ERROR
ERR_HTTP2_GOAWAY_SESSION
ERR_HTTP2_HEADERS_AFTER_RESPOND
ERR_HTTP2_HEADERS_SENT
ERR_HTTP2_HEADER_SINGLE_VALUE
ERR_HTTP2_INFO_STATUS_NOT_ALLOWED
ERR_HTTP2_INVALID_CONNECTION_HEADERS
ERR_HTTP2_INVALID_HEADER_VALUE
ERR_HTTP2_INVALID_INFO_STATUS
ERR_HTTP2_INVALID_ORIGIN
ERR_HTTP2_INVALID_PACKED_SETTINGS_LENGTH
ERR_HTTP2_INVALID_PSEUDOHEADER
ERR_HTTP2_INVALID_SESSION
ERR_HTTP2_INVALID_SETTING_VALUE
ERR_HTTP2_INVALID_STREAM
ERR_HTTP2_MAX_PENDING_SETTINGS_ACK
ERR_HTTP2_NESTED_PUSH
ERR_HTTP2_NO_MEM
ERR_HTTP2_NO_SOCKET_MANIPULATION
ERR_HTTP2_ORIGIN_LENGTH
ERR_HTTP2_OUT_OF_STREAMS
ERR_HTTP2_PAYLOAD_FORBIDDEN
ERR_HTTP2_PING_CANCEL
ERR_HTTP2_PING_LENGTH
ERR_HTTP2_PSEUDOHEADER_NOT_ALLOWED
ERR_HTTP2_PUSH_DISABLED
ERR_HTTP2_SEND_FILE
ERR_HTTP2_SEND_FILE_NOSEEK
ERR_HTTP2_SESSION_ERROR
ERR_HTTP2_SETTINGS_CANCEL
ERR_HTTP2_SOCKET_BOUND
ERR_HTTP2_SOCKET_UNBOUND
ERR_HTTP2_STATUS_101
ERR_HTTP2_STATUS_INVALID
ERR_HTTP2_STREAM_CANCEL
ERR_HTTP2_STREAM_ERROR
ERR_HTTP2_STREAM_SELF_DEPENDENCY
ERR_HTTP2_TOO_MANY_CUSTOM_SETTINGS
ERR_HTTP2_TOO_MANY_INVALID_FRAMES
ERR_HTTP2_TRAILERS_ALREADY_SENT
ERR_HTTP2_TRAILERS_NOT_READY
ERR_HTTP2_UNSUPPORTED_PROTOCOL
ERR_HTTP_BODY_NOT_ALLOWED
ERR_HTTP_CONTENT_LENGTH_MISMATCH
ERR_HTTP_HEADERS_SENT
ERR_HTTP_INVALID_HEADER_VALUE
ERR_HTTP_INVALID_STATUS_CODE
ERR_HTTP_REQUEST_TIMEOUT
ERR_HTTP_SOCKET_ASSIGNED
ERR_HTTP_SOCKET_ENCODING
ERR_HTTP_TRAILER_INVALID
ERR_ILLEGAL_CONSTRUCTOR
ERR_IMPORT_ATTRIBUTE_MISSING
ERR_IMPORT_ATTRIBUTE_TYPE_INCOMPATIBLE
ERR_IMPORT_ATTRIBUTE_UNSUPPORTED
ERR_INCOMPATIBLE_OPTION_PAIR
ERR_INPUT_TYPE_NOT_ALLOWED
ERR_INSPECTOR_ALREADY_ACTIVATED
ERR_INSPECTOR_ALREADY_CONNECTED
ERR_INSPECTOR_CLOSED
ERR_INSPECTOR_COMMAND
ERR_INSPECTOR_NOT_ACTIVE
ERR_INSPECTOR_NOT_AVAILABLE
ERR_INSPECTOR_NOT_CONNECTED
ERR_INSPECTOR_NOT_WORKER
ERR_INTERNAL_ASSERTION
ERR_INVALID_ADDRESS
ERR_INVALID_ADDRESS_FAMILY
ERR_INVALID_ARG_TYPE
ERR_INVALID_ARG_VALUE
ERR_INVALID_ASYNC_ID
ERR_INVALID_BUFFER_SIZE
ERR_INVALID_CHAR
ERR_INVALID_CURSOR_POS
ERR_INVALID_FD
ERR_INVALID_FD_TYPE
ERR_INVALID_FILE_URL_HOST
ERR_INVALID_FILE_URL_PATH
ERR_INVALID_HANDLE_TYPE
ERR_INVALID_HTTP_TOKEN
ERR_INVALID_IP_ADDRESS
ERR_INVALID_MIME_SYNTAX
ERR_INVALID_MODULE
ERR_INVALID_MODULE_SPECIFIER
ERR_INVALID_OBJECT_DEFINE_PROPERTY
ERR_INVALID_PACKAGE_CONFIG
ERR_INVALID_PACKAGE_TARGET
ERR_INVALID_PROTOCOL
ERR_INVALID_REPL_EVAL_CONFIG
ERR_INVALID_REPL_INPUT
ERR_INVALID_RETURN_PROPERTY
ERR_INVALID_RETURN_PROPERTY_VALUE
ERR_INVALID_RETURN_VALUE
ERR_INVALID_STATE
ERR_INVALID_SYNC_FORK_INPUT
ERR_INVALID_THIS
ERR_INVALID_TUPLE
ERR_INVALID_TYPESCRIPT_SYNTAX
ERR_INVALID_URI
ERR_INVALID_URL
ERR_INVALID_URL_PATTERN
ERR_INVALID_URL_SCHEME
ERR_IPC_CHANNEL_CLOSED
ERR_IPC_DISCONNECTED
ERR_IPC_ONE_PIPE
ERR_IPC_SYNC_FORK
ERR_IP_BLOCKED
ERR_LOADER_CHAIN_INCOMPLETE
ERR_LOAD_SQLITE_EXTENSION
ERR_MEMORY_ALLOCATION_FAILED
ERR_MESSAGE_TARGET_CONTEXT_UNAVAILABLE
ERR_METHOD_NOT_IMPLEMENTED
ERR_MISSING_ARGS
ERR_MISSING_OPTION
ERR_MISSING_PASSPHRASE
ERR_MISSING_PLATFORM_FOR_WORKER
ERR_MODULE_NOT_FOUND
ERR_MULTIPLE_CALLBACK
ERR_NAPI_CONS_FUNCTION
ERR_NAPI_INVALID_DATAVIEW_ARGS
ERR_NAPI_INVALID_TYPEDARRAY_ALIGNMENT
ERR_NAPI_INVALID_TYPEDARRAY_LENGTH
ERR_NAPI_TSFN_CALL_JS
ERR_NAPI_TSFN_GET_UNDEFINED
ERR_NON_CONTEXT_AWARE_DISABLED
ERR_NOT_BUILDING_SNAPSHOT
ERR_NOT_IN_SINGLE_EXECUTABLE_APPLICATION
ERR_NOT_SUPPORTED_IN_SNAPSHOT
ERR_NO_CRYPTO
ERR_NO_ICU
ERR_NO_TYPESCRIPT
ERR_OPERATION_FAILED
ERR_OPTIONS_BEFORE_BOOTSTRAPPING
ERR_OUT_OF_RANGE
ERR_PACKAGE_IMPORT_NOT_DEFINED
ERR_PACKAGE_PATH_NOT_EXPORTED
ERR_PARSE_ARGS_INVALID_OPTION_VALUE
ERR_PARSE_ARGS_UNEXPECTED_POSITIONAL
ERR_PARSE_ARGS_UNKNOWN_OPTION
ERR_PERFORMANCE_INVALID_TIMESTAMP
ERR_PERFORMANCE_MEASURE_INVALID_OPTIONS
ERR_PROTO_ACCESS
ERR_QUIC_APPLICATION_ERROR
ERR_QUIC_CONNECTION_FAILED
ERR_QUIC_ENDPOINT_CLOSED
ERR_QUIC_OPEN_STREAM_FAILED
ERR_QUIC_TRANSPORT_ERROR
ERR_QUIC_VERSION_NEGOTIATION_ERROR
ERR_REQUIRE_ASYNC_MODULE
ERR_REQUIRE_CYCLE_MODULE
ERR_REQUIRE_ESM
ERR_SCRIPT_EXECUTION_INTERRUPTED
ERR_SCRIPT_EXECUTION_TIMEOUT
ERR_SERVER_ALREADY_LISTEN
ERR_SERVER_NOT_RUNNING
ERR_SINGLE_EXECUTABLE_APPLICATION_ASSET_NOT_FOUND
ERR_SOCKET_ALREADY_BOUND
ERR_SOCKET_BAD_BUFFER_SIZE
ERR_SOCKET_BAD_PORT
ERR_SOCKET_BAD_TYPE
ERR_SOCKET_BUFFER_SIZE
ERR_SOCKET_CLOSED
ERR_SOCKET_CLOSED_BEFORE_CONNECTION
ERR_SOCKET_CONNECTION_TIMEOUT
ERR_SOCKET_DGRAM_IS_CONNECTED
ERR_SOCKET_DGRAM_NOT_CONNECTED
ERR_SOCKET_DGRAM_NOT_RUNNING
ERR_SOURCE_MAP_CORRUPT
ERR_SOURCE_MAP_MISSING_SOURCE
ERR_SOURCE_PHASE_NOT_DEFINED
ERR_SQLITE_ERROR
ERR_SRI_PARSE
ERR_STREAM_ALREADY_FINISHED
ERR_STREAM_CANNOT_PIPE
ERR_STREAM_DESTROYED
ERR_STREAM_NULL_VALUES
ERR_STREAM_PREMATURE_CLOSE
ERR_STREAM_PUSH_AFTER_EOF
ERR_STREAM_UNABLE_TO_PIPE
ERR_STREAM_UNSHIFT_AFTER_END_EVENT
ERR_STREAM_WRAP
ERR_STREAM_WRITE_AFTER_END
ERR_STRING_TOO_LONG
ERR_SYNTHETIC
ERR_SYSTEM_ERROR
ERR_TEST_FAILURE
ERR_TLS_ALPN_CALLBACK_INVALID_RESULT
ERR_TLS_ALPN_CALLBACK_WITH_PROTOCOLS
ERR_TLS_CERT_ALTNAME_FORMAT
ERR_TLS_CERT_ALTNAME_INVALID
ERR_TLS_DH_PARAM_SIZE
ERR_TLS_HANDSHAKE_TIMEOUT
ERR_TLS_INVALID_CONTEXT
ERR_TLS_INVALID_PROTOCOL_METHOD
ERR_TLS_INVALID_PROTOCOL_VERSION
ERR_TLS_INVALID_STATE
ERR_TLS_PROTOCOL_VERSION_CONFLICT
ERR_TLS_PSK_SET_IDENTITY_HINT_FAILED
ERR_TLS_RENEGOTIATION_DISABLED
ERR_TLS_REQUIRED_SERVER_NAME
ERR_TLS_SESSION_ATTACK
ERR_TLS_SNI_FROM_SERVER
ERR_TRACE_EVENTS_CATEGORY_REQUIRED
ERR_TRACE_EVENTS_UNAVAILABLE
ERR_TRANSFORM_ALREADY_TRANSFORMING
ERR_TRANSFORM_WITH_LENGTH_0
ERR_TTY_INIT_FAILED
ERR_UNAVAILABLE_DURING_EXIT
ERR_UNCAUGHT_EXCEPTION_CAPTURE_ALREADY_SET
ERR_UNESCAPED_CHARACTERS
ERR_UNHANDLED_ERROR
ERR_UNKNOWN_BUILTIN_MODULE
ERR_UNKNOWN_CREDENTIAL
ERR_UNKNOWN_ENCODING
ERR_UNKNOWN_FILE_EXTENSION
ERR_UNKNOWN_MODULE_FORMAT
ERR_UNKNOWN_SIGNAL
ERR_UNSUPPORTED_DIR_IMPORT
ERR_UNSUPPORTED_ESM_URL_SCHEME
ERR_UNSUPPORTED_NODE_MODULES_TYPE_STRIPPING
ERR_UNSUPPORTED_RESOLVE_REQUEST
ERR_UNSUPPORTED_TYPESCRIPT_SYNTAX
ERR_USE_AFTER_CLOSE
ERR_VALID_PERFORMANCE_ENTRY_TYPE
ERR_VM_DYNAMIC_IMPORT_CALLBACK_MISSING
ERR_VM_DYNAMIC_IMPORT_CALLBACK_MISSING_FLAG
ERR_VM_MODULE_ALREADY_LINKED
ERR_VM_MODULE_CACHED_DATA_REJECTED
ERR_VM_MODULE_CANNOT_CREATE_CACHED_DATA
ERR_VM_MODULE_DIFFERENT_CONTEXT
ERR_VM_MODULE_LINK_FAILURE
ERR_VM_MODULE_NOT_MODULE
ERR_VM_MODULE_STATUS
ERR_WASI_ALREADY_STARTED
ERR_WASI_NOT_STARTED
ERR_WEBASSEMBLY_RESPONSE
ERR_WORKER_INIT_FAILED
ERR_WORKER_INVALID_EXEC_ARGV
ERR_WORKER_MESSAGING_ERRORED
ERR_WORKER_MESSAGING_FAILED
ERR_WORKER_MESSAGING_SAME_THREAD
ERR_WORKER_MESSAGING_TIMEOUT
ERR_WORKER_NOT_RUNNING
ERR_WORKER_OUT_OF_MEMORY
ERR_WORKER_PATH
ERR_WORKER_UNSERIALIZABLE_ERROR
ERR_WORKER_UNSUPPORTED_OPERATION
ERR_ZLIB_INITIALIZATION_FAILED
ERR_ZSTD_INVALID_PARAM
HPE_CHUNK_EXTENSIONS_OVERFLOW
HPE_HEADER_OVERFLOW
HPE_UNEXPECTED_CONTENT_LENGTH
MODULE_NOT_FOUND


Legacy Node.js error codes

ERR_CANNOT_TRANSFER_OBJECT
ERR_CPU_USAGE
ERR_CRYPTO_HASH_DIGEST_NO_UTF16
ERR_CRYPTO_SCRYPT_INVALID_PARAMETER
ERR_FS_INVALID_SYMLINK_TYPE
ERR_HTTP2_FRAME_ERROR
ERR_HTTP2_HEADERS_OBJECT
ERR_HTTP2_HEADER_REQUIRED
ERR_HTTP2_INFO_HEADERS_AFTER_RESPOND
ERR_HTTP2_STREAM_CLOSED
ERR_HTTP_INVALID_CHAR
ERR_IMPORT_ASSERTION_TYPE_FAILED
ERR_IMPORT_ASSERTION_TYPE_MISSING
ERR_IMPORT_ASSERTION_TYPE_UNSUPPORTED
ERR_INDEX_OUT_OF_RANGE
ERR_INVALID_OPT_VALUE
ERR_INVALID_OPT_VALUE_ENCODING
ERR_INVALID_PERFORMANCE_MARK
ERR_INVALID_TRANSFER_OBJECT
ERR_MANIFEST_ASSERT_INTEGRITY
ERR_MANIFEST_DEPENDENCY_MISSING
ERR_MANIFEST_INTEGRITY_MISMATCH
ERR_MANIFEST_INVALID_RESOURCE_FIELD
ERR_MANIFEST_INVALID_SPECIFIER
ERR_MANIFEST_PARSE_POLICY
ERR_MANIFEST_TDZ
ERR_MANIFEST_UNKNOWN_ONERROR
ERR_MISSING_MESSAGE_PORT_IN_TRANSFER_LIST
ERR_MISSING_TRANSFERABLE_IN_TRANSFER_LIST
ERR_NAPI_CONS_PROTOTYPE_OBJECT
ERR_NAPI_TSFN_START_IDLE_LOOP
ERR_NAPI_TSFN_STOP_IDLE_LOOP
ERR_NO_LONGER_SUPPORTED
ERR_OUTOFMEMORY
ERR_PARSE_HISTORY_DATA
ERR_SOCKET_CANNOT_SEND
ERR_STDERR_CLOSE
ERR_STDOUT_CLOSE
ERR_STREAM_READ_NOT_IMPLEMENTED
ERR_TAP_LEXER_ERROR
ERR_TAP_PARSER_ERROR
ERR_TAP_VALIDATION_ERROR
ERR_TLS_RENEGOTIATION_FAILED
ERR_TRANSFERRING_EXTERNALIZED_SHAREDARRAYBUFFER
ERR_UNKNOWN_STDIN_TYPE
ERR_UNKNOWN_STREAM_TYPE
ERR_V8BREAKITERATOR
ERR_VALUE_OUT_OF_RANGE
ERR_VM_MODULE_LINKING_ERRORED
ERR_VM_MODULE_NOT_LINKED
ERR_WORKER_UNSUPPORTED_EXTENSION
ERR_ZLIB_BINDING_CLOSED


OpenSSL Error Codes

Time Validity Errors

CERT_NOT_YET_VALID
CERT_HAS_EXPIRED
CRL_NOT_YET_VALID
CRL_HAS_EXPIRED
CERT_REVOKED


Trust or Chain Related Errors

UNABLE_TO_GET_ISSUER_CERT
UNABLE_TO_GET_ISSUER_CERT_LOCALLY
DEPTH_ZERO_SELF_SIGNED_CERT
SELF_SIGNED_CERT_IN_CHAIN
CERT_CHAIN_TOO_LONG
UNABLE_TO_GET_CRL
UNABLE_TO_VERIFY_LEAF_SIGNATURE
CERT_UNTRUSTED


Basic Extension Errors

INVALID_CA
PATH_LENGTH_EXCEEDED


Name Related Errors

HOSTNAME_MISMATCH


Usage and Policy Errors

INVALID_PURPOSE
CERT_REJECTED


Formatting Errors

CERT_SIGNATURE_FAILURE
CRL_SIGNATURE_FAILURE
ERROR_IN_CERT_NOT_BEFORE_FIELD
ERROR_IN_CERT_NOT_AFTER_FIELD
ERROR_IN_CRL_LAST_UPDATE_FIELD
ERROR_IN_CRL_NEXT_UPDATE_FIELD
UNABLE_TO_DECRYPT_CERT_SIGNATURE
UNABLE_TO_DECRYPT_CRL_SIGNATURE
UNABLE_TO_DECODE_ISSUER_PUBLIC_KEY


Other OpenSSL Errors

OUT_OF_MEM







    
  
            
    
      
        
        Index
      

      
About this documentation
Usage and example

      
        Index
      
    
  


Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Modules: TypeScript
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
Readline
REPL
Report
Single executable applications
SQLite
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker

    
  
            
    
      
        
        Other versions
      
      24.x
23.x
22.x LTS
21.x
20.x LTS
19.x
18.x
17.x
16.x
15.x
14.x
13.x
12.x
11.x
10.x
9.x
8.x
7.x
6.x
5.x
4.x
    
  
            
              
                
                Options
              
        
              
                
                  
                    View on single page
                  
                  
                    View as JSON
                  
                  Edit on GitHub    
                
              
            
          
        
        
      

      Table of contents
Errors

Error propagation and interception
Class: Error

new Error(message[, options])
Error.captureStackTrace(targetObject[, constructorOpt])
Error.stackTraceLimit
error.cause
error.code
error.message
error.stack


Class: AssertionError
Class: RangeError
Class: ReferenceError
Class: SyntaxError
Class: SystemError

error.address
error.code
error.dest
error.errno
error.info
error.message
error.path
error.port
error.syscall
Common system errors


Class: TypeError
Exceptions vs. errors
OpenSSL errors

error.opensslErrorStack
error.function
error.library
error.reason


Node.js error codes

ABORT_ERR
ERR_ACCESS_DENIED
ERR_AMBIGUOUS_ARGUMENT
ERR_ARG_NOT_ITERABLE
ERR_ASSERTION
ERR_ASYNC_CALLBACK
ERR_ASYNC_TYPE
ERR_BROTLI_COMPRESSION_FAILED
ERR_BROTLI_INVALID_PARAM
ERR_BUFFER_CONTEXT_NOT_AVAILABLE
ERR_BUFFER_OUT_OF_BOUNDS
ERR_BUFFER_TOO_LARGE
ERR_CANNOT_WATCH_SIGINT
ERR_CHILD_CLOSED_BEFORE_REPLY
ERR_CHILD_PROCESS_IPC_REQUIRED
ERR_CHILD_PROCESS_STDIO_MAXBUFFER
ERR_CLOSED_MESSAGE_PORT
ERR_CONSOLE_WRITABLE_STREAM
ERR_CONSTRUCT_CALL_INVALID
ERR_CONSTRUCT_CALL_REQUIRED
ERR_CONTEXT_NOT_INITIALIZED
ERR_CRYPTO_CUSTOM_ENGINE_NOT_SUPPORTED
ERR_CRYPTO_ECDH_INVALID_FORMAT
ERR_CRYPTO_ECDH_INVALID_PUBLIC_KEY
ERR_CRYPTO_ENGINE_UNKNOWN
ERR_CRYPTO_FIPS_FORCED
ERR_CRYPTO_FIPS_UNAVAILABLE
ERR_CRYPTO_HASH_FINALIZED
ERR_CRYPTO_HASH_UPDATE_FAILED
ERR_CRYPTO_INCOMPATIBLE_KEY
ERR_CRYPTO_INCOMPATIBLE_KEY_OPTIONS
ERR_CRYPTO_INITIALIZATION_FAILED
ERR_CRYPTO_INVALID_AUTH_TAG
ERR_CRYPTO_INVALID_COUNTER
ERR_CRYPTO_INVALID_CURVE
ERR_CRYPTO_INVALID_DIGEST
ERR_CRYPTO_INVALID_IV
ERR_CRYPTO_INVALID_JWK
ERR_CRYPTO_INVALID_KEYLEN
ERR_CRYPTO_INVALID_KEYPAIR
ERR_CRYPTO_INVALID_KEYTYPE
ERR_CRYPTO_INVALID_KEY_OBJECT_TYPE
ERR_CRYPTO_INVALID_MESSAGELEN
ERR_CRYPTO_INVALID_SCRYPT_PARAMS
ERR_CRYPTO_INVALID_STATE
ERR_CRYPTO_INVALID_TAG_LENGTH
ERR_CRYPTO_JOB_INIT_FAILED
ERR_CRYPTO_JWK_UNSUPPORTED_CURVE
ERR_CRYPTO_JWK_UNSUPPORTED_KEY_TYPE
ERR_CRYPTO_OPERATION_FAILED
ERR_CRYPTO_PBKDF2_ERROR
ERR_CRYPTO_SCRYPT_NOT_SUPPORTED
ERR_CRYPTO_SIGN_KEY_REQUIRED
ERR_CRYPTO_TIMING_SAFE_EQUAL_LENGTH
ERR_CRYPTO_UNKNOWN_CIPHER
ERR_CRYPTO_UNKNOWN_DH_GROUP
ERR_CRYPTO_UNSUPPORTED_OPERATION
ERR_DEBUGGER_ERROR
ERR_DEBUGGER_STARTUP_ERROR
ERR_DIR_CLOSED
ERR_DIR_CONCURRENT_OPERATION
ERR_DLOPEN_DISABLED
ERR_DLOPEN_FAILED
ERR_DNS_SET_SERVERS_FAILED
ERR_DOMAIN_CALLBACK_NOT_AVAILABLE
ERR_DOMAIN_CANNOT_SET_UNCAUGHT_EXCEPTION_CAPTURE
ERR_DUPLICATE_STARTUP_SNAPSHOT_MAIN_FUNCTION
ERR_ENCODING_INVALID_ENCODED_DATA
ERR_ENCODING_NOT_SUPPORTED
ERR_EVAL_ESM_CANNOT_PRINT
ERR_EVENT_RECURSION
ERR_EXECUTION_ENVIRONMENT_NOT_AVAILABLE
ERR_FALSY_VALUE_REJECTION
ERR_FEATURE_UNAVAILABLE_ON_PLATFORM
ERR_FS_CP_DIR_TO_NON_DIR
ERR_FS_CP_EEXIST
ERR_FS_CP_EINVAL
ERR_FS_CP_FIFO_PIPE
ERR_FS_CP_NON_DIR_TO_DIR
ERR_FS_CP_SOCKET
ERR_FS_CP_SYMLINK_TO_SUBDIRECTORY
ERR_FS_CP_UNKNOWN
ERR_FS_EISDIR
ERR_FS_FILE_TOO_LARGE
ERR_HTTP2_ALTSVC_INVALID_ORIGIN
ERR_HTTP2_ALTSVC_LENGTH
ERR_HTTP2_CONNECT_AUTHORITY
ERR_HTTP2_CONNECT_PATH
ERR_HTTP2_CONNECT_SCHEME
ERR_HTTP2_ERROR
ERR_HTTP2_GOAWAY_SESSION
ERR_HTTP2_HEADERS_AFTER_RESPOND
ERR_HTTP2_HEADERS_SENT
ERR_HTTP2_HEADER_SINGLE_VALUE
ERR_HTTP2_INFO_STATUS_NOT_ALLOWED
ERR_HTTP2_INVALID_CONNECTION_HEADERS
ERR_HTTP2_INVALID_HEADER_VALUE
ERR_HTTP2_INVALID_INFO_STATUS
ERR_HTTP2_INVALID_ORIGIN
ERR_HTTP2_INVALID_PACKED_SETTINGS_LENGTH
ERR_HTTP2_INVALID_PSEUDOHEADER
ERR_HTTP2_INVALID_SESSION
ERR_HTTP2_INVALID_SETTING_VALUE
ERR_HTTP2_INVALID_STREAM
ERR_HTTP2_MAX_PENDING_SETTINGS_ACK
ERR_HTTP2_NESTED_PUSH
ERR_HTTP2_NO_MEM
ERR_HTTP2_NO_SOCKET_MANIPULATION
ERR_HTTP2_ORIGIN_LENGTH
ERR_HTTP2_OUT_OF_STREAMS
ERR_HTTP2_PAYLOAD_FORBIDDEN
ERR_HTTP2_PING_CANCEL
ERR_HTTP2_PING_LENGTH
ERR_HTTP2_PSEUDOHEADER_NOT_ALLOWED
ERR_HTTP2_PUSH_DISABLED
ERR_HTTP2_SEND_FILE
ERR_HTTP2_SEND_FILE_NOSEEK
ERR_HTTP2_SESSION_ERROR
ERR_HTTP2_SETTINGS_CANCEL
ERR_HTTP2_SOCKET_BOUND
ERR_HTTP2_SOCKET_UNBOUND
ERR_HTTP2_STATUS_101
ERR_HTTP2_STATUS_INVALID
ERR_HTTP2_STREAM_CANCEL
ERR_HTTP2_STREAM_ERROR
ERR_HTTP2_STREAM_SELF_DEPENDENCY
ERR_HTTP2_TOO_MANY_CUSTOM_SETTINGS
ERR_HTTP2_TOO_MANY_INVALID_FRAMES
ERR_HTTP2_TRAILERS_ALREADY_SENT
ERR_HTTP2_TRAILERS_NOT_READY
ERR_HTTP2_UNSUPPORTED_PROTOCOL
ERR_HTTP_BODY_NOT_ALLOWED
ERR_HTTP_CONTENT_LENGTH_MISMATCH
ERR_HTTP_HEADERS_SENT
ERR_HTTP_INVALID_HEADER_VALUE
ERR_HTTP_INVALID_STATUS_CODE
ERR_HTTP_REQUEST_TIMEOUT
ERR_HTTP_SOCKET_ASSIGNED
ERR_HTTP_SOCKET_ENCODING
ERR_HTTP_TRAILER_INVALID
ERR_ILLEGAL_CONSTRUCTOR
ERR_IMPORT_ATTRIBUTE_MISSING
ERR_IMPORT_ATTRIBUTE_TYPE_INCOMPATIBLE
ERR_IMPORT_ATTRIBUTE_UNSUPPORTED
ERR_INCOMPATIBLE_OPTION_PAIR
ERR_INPUT_TYPE_NOT_ALLOWED
ERR_INSPECTOR_ALREADY_ACTIVATED
ERR_INSPECTOR_ALREADY_CONNECTED
ERR_INSPECTOR_CLOSED
ERR_INSPECTOR_COMMAND
ERR_INSPECTOR_NOT_ACTIVE
ERR_INSPECTOR_NOT_AVAILABLE
ERR_INSPECTOR_NOT_CONNECTED
ERR_INSPECTOR_NOT_WORKER
ERR_INTERNAL_ASSERTION
ERR_INVALID_ADDRESS
ERR_INVALID_ADDRESS_FAMILY
ERR_INVALID_ARG_TYPE
ERR_INVALID_ARG_VALUE
ERR_INVALID_ASYNC_ID
ERR_INVALID_BUFFER_SIZE
ERR_INVALID_CHAR
ERR_INVALID_CURSOR_POS
ERR_INVALID_FD
ERR_INVALID_FD_TYPE
ERR_INVALID_FILE_URL_HOST
ERR_INVALID_FILE_URL_PATH
ERR_INVALID_HANDLE_TYPE
ERR_INVALID_HTTP_TOKEN
ERR_INVALID_IP_ADDRESS
ERR_INVALID_MIME_SYNTAX
ERR_INVALID_MODULE
ERR_INVALID_MODULE_SPECIFIER
ERR_INVALID_OBJECT_DEFINE_PROPERTY
ERR_INVALID_PACKAGE_CONFIG
ERR_INVALID_PACKAGE_TARGET
ERR_INVALID_PROTOCOL
ERR_INVALID_REPL_EVAL_CONFIG
ERR_INVALID_REPL_INPUT
ERR_INVALID_RETURN_PROPERTY
ERR_INVALID_RETURN_PROPERTY_VALUE
ERR_INVALID_RETURN_VALUE
ERR_INVALID_STATE
ERR_INVALID_SYNC_FORK_INPUT
ERR_INVALID_THIS
ERR_INVALID_TUPLE
ERR_INVALID_TYPESCRIPT_SYNTAX
ERR_INVALID_URI
ERR_INVALID_URL
ERR_INVALID_URL_PATTERN
ERR_INVALID_URL_SCHEME
ERR_IPC_CHANNEL_CLOSED
ERR_IPC_DISCONNECTED
ERR_IPC_ONE_PIPE
ERR_IPC_SYNC_FORK
ERR_IP_BLOCKED
ERR_LOADER_CHAIN_INCOMPLETE
ERR_LOAD_SQLITE_EXTENSION
ERR_MEMORY_ALLOCATION_FAILED
ERR_MESSAGE_TARGET_CONTEXT_UNAVAILABLE
ERR_METHOD_NOT_IMPLEMENTED
ERR_MISSING_ARGS
ERR_MISSING_OPTION
ERR_MISSING_PASSPHRASE
ERR_MISSING_PLATFORM_FOR_WORKER
ERR_MODULE_NOT_FOUND
ERR_MULTIPLE_CALLBACK
ERR_NAPI_CONS_FUNCTION
ERR_NAPI_INVALID_DATAVIEW_ARGS
ERR_NAPI_INVALID_TYPEDARRAY_ALIGNMENT
ERR_NAPI_INVALID_TYPEDARRAY_LENGTH
ERR_NAPI_TSFN_CALL_JS
ERR_NAPI_TSFN_GET_UNDEFINED
ERR_NON_CONTEXT_AWARE_DISABLED
ERR_NOT_BUILDING_SNAPSHOT
ERR_NOT_IN_SINGLE_EXECUTABLE_APPLICATION
ERR_NOT_SUPPORTED_IN_SNAPSHOT
ERR_NO_CRYPTO
ERR_NO_ICU
ERR_NO_TYPESCRIPT
ERR_OPERATION_FAILED
ERR_OPTIONS_BEFORE_BOOTSTRAPPING
ERR_OUT_OF_RANGE
ERR_PACKAGE_IMPORT_NOT_DEFINED
ERR_PACKAGE_PATH_NOT_EXPORTED
ERR_PARSE_ARGS_INVALID_OPTION_VALUE
ERR_PARSE_ARGS_UNEXPECTED_POSITIONAL
ERR_PARSE_ARGS_UNKNOWN_OPTION
ERR_PERFORMANCE_INVALID_TIMESTAMP
ERR_PERFORMANCE_MEASURE_INVALID_OPTIONS
ERR_PROTO_ACCESS
ERR_QUIC_APPLICATION_ERROR
ERR_QUIC_CONNECTION_FAILED
ERR_QUIC_ENDPOINT_CLOSED
ERR_QUIC_OPEN_STREAM_FAILED
ERR_QUIC_TRANSPORT_ERROR
ERR_QUIC_VERSION_NEGOTIATION_ERROR
ERR_REQUIRE_ASYNC_MODULE
ERR_REQUIRE_CYCLE_MODULE
ERR_REQUIRE_ESM
ERR_SCRIPT_EXECUTION_INTERRUPTED
ERR_SCRIPT_EXECUTION_TIMEOUT
ERR_SERVER_ALREADY_LISTEN
ERR_SERVER_NOT_RUNNING
ERR_SINGLE_EXECUTABLE_APPLICATION_ASSET_NOT_FOUND
ERR_SOCKET_ALREADY_BOUND
ERR_SOCKET_BAD_BUFFER_SIZE
ERR_SOCKET_BAD_PORT
ERR_SOCKET_BAD_TYPE
ERR_SOCKET_BUFFER_SIZE
ERR_SOCKET_CLOSED
ERR_SOCKET_CLOSED_BEFORE_CONNECTION
ERR_SOCKET_CONNECTION_TIMEOUT
ERR_SOCKET_DGRAM_IS_CONNECTED
ERR_SOCKET_DGRAM_NOT_CONNECTED
ERR_SOCKET_DGRAM_NOT_RUNNING
ERR_SOURCE_MAP_CORRUPT
ERR_SOURCE_MAP_MISSING_SOURCE
ERR_SOURCE_PHASE_NOT_DEFINED
ERR_SQLITE_ERROR
ERR_SRI_PARSE
ERR_STREAM_ALREADY_FINISHED
ERR_STREAM_CANNOT_PIPE
ERR_STREAM_DESTROYED
ERR_STREAM_NULL_VALUES
ERR_STREAM_PREMATURE_CLOSE
ERR_STREAM_PUSH_AFTER_EOF
ERR_STREAM_UNABLE_TO_PIPE
ERR_STREAM_UNSHIFT_AFTER_END_EVENT
ERR_STREAM_WRAP
ERR_STREAM_WRITE_AFTER_END
ERR_STRING_TOO_LONG
ERR_SYNTHETIC
ERR_SYSTEM_ERROR
ERR_TEST_FAILURE
ERR_TLS_ALPN_CALLBACK_INVALID_RESULT
ERR_TLS_ALPN_CALLBACK_WITH_PROTOCOLS
ERR_TLS_CERT_ALTNAME_FORMAT
ERR_TLS_CERT_ALTNAME_INVALID
ERR_TLS_DH_PARAM_SIZE
ERR_TLS_HANDSHAKE_TIMEOUT
ERR_TLS_INVALID_CONTEXT
ERR_TLS_INVALID_PROTOCOL_METHOD
ERR_TLS_INVALID_PROTOCOL_VERSION
ERR_TLS_INVALID_STATE
ERR_TLS_PROTOCOL_VERSION_CONFLICT
ERR_TLS_PSK_SET_IDENTITY_HINT_FAILED
ERR_TLS_RENEGOTIATION_DISABLED
ERR_TLS_REQUIRED_SERVER_NAME
ERR_TLS_SESSION_ATTACK
ERR_TLS_SNI_FROM_SERVER
ERR_TRACE_EVENTS_CATEGORY_REQUIRED
ERR_TRACE_EVENTS_UNAVAILABLE
ERR_TRANSFORM_ALREADY_TRANSFORMING
ERR_TRANSFORM_WITH_LENGTH_0
ERR_TTY_INIT_FAILED
ERR_UNAVAILABLE_DURING_EXIT
ERR_UNCAUGHT_EXCEPTION_CAPTURE_ALREADY_SET
ERR_UNESCAPED_CHARACTERS
ERR_UNHANDLED_ERROR
ERR_UNKNOWN_BUILTIN_MODULE
ERR_UNKNOWN_CREDENTIAL
ERR_UNKNOWN_ENCODING
ERR_UNKNOWN_FILE_EXTENSION
ERR_UNKNOWN_MODULE_FORMAT
ERR_UNKNOWN_SIGNAL
ERR_UNSUPPORTED_DIR_IMPORT
ERR_UNSUPPORTED_ESM_URL_SCHEME
ERR_UNSUPPORTED_NODE_MODULES_TYPE_STRIPPING
ERR_UNSUPPORTED_RESOLVE_REQUEST
ERR_UNSUPPORTED_TYPESCRIPT_SYNTAX
ERR_USE_AFTER_CLOSE
ERR_VALID_PERFORMANCE_ENTRY_TYPE
ERR_VM_DYNAMIC_IMPORT_CALLBACK_MISSING
ERR_VM_DYNAMIC_IMPORT_CALLBACK_MISSING_FLAG
ERR_VM_MODULE_ALREADY_LINKED
ERR_VM_MODULE_CACHED_DATA_REJECTED
ERR_VM_MODULE_CANNOT_CREATE_CACHED_DATA
ERR_VM_MODULE_DIFFERENT_CONTEXT
ERR_VM_MODULE_LINK_FAILURE
ERR_VM_MODULE_NOT_MODULE
ERR_VM_MODULE_STATUS
ERR_WASI_ALREADY_STARTED
ERR_WASI_NOT_STARTED
ERR_WEBASSEMBLY_RESPONSE
ERR_WORKER_INIT_FAILED
ERR_WORKER_INVALID_EXEC_ARGV
ERR_WORKER_MESSAGING_ERRORED
ERR_WORKER_MESSAGING_FAILED
ERR_WORKER_MESSAGING_SAME_THREAD
ERR_WORKER_MESSAGING_TIMEOUT
ERR_WORKER_NOT_RUNNING
ERR_WORKER_OUT_OF_MEMORY
ERR_WORKER_PATH
ERR_WORKER_UNSERIALIZABLE_ERROR
ERR_WORKER_UNSUPPORTED_OPERATION
ERR_ZLIB_INITIALIZATION_FAILED
ERR_ZSTD_INVALID_PARAM
HPE_CHUNK_EXTENSIONS_OVERFLOW
HPE_HEADER_OVERFLOW
HPE_UNEXPECTED_CONTENT_LENGTH
MODULE_NOT_FOUND


Legacy Node.js error codes

ERR_CANNOT_TRANSFER_OBJECT
ERR_CPU_USAGE
ERR_CRYPTO_HASH_DIGEST_NO_UTF16
ERR_CRYPTO_SCRYPT_INVALID_PARAMETER
ERR_FS_INVALID_SYMLINK_TYPE
ERR_HTTP2_FRAME_ERROR
ERR_HTTP2_HEADERS_OBJECT
ERR_HTTP2_HEADER_REQUIRED
ERR_HTTP2_INFO_HEADERS_AFTER_RESPOND
ERR_HTTP2_STREAM_CLOSED
ERR_HTTP_INVALID_CHAR
ERR_IMPORT_ASSERTION_TYPE_FAILED
ERR_IMPORT_ASSERTION_TYPE_MISSING
ERR_IMPORT_ASSERTION_TYPE_UNSUPPORTED
ERR_INDEX_OUT_OF_RANGE
ERR_INVALID_OPT_VALUE
ERR_INVALID_OPT_VALUE_ENCODING
ERR_INVALID_PERFORMANCE_MARK
ERR_INVALID_TRANSFER_OBJECT
ERR_MANIFEST_ASSERT_INTEGRITY
ERR_MANIFEST_DEPENDENCY_MISSING
ERR_MANIFEST_INTEGRITY_MISMATCH
ERR_MANIFEST_INVALID_RESOURCE_FIELD
ERR_MANIFEST_INVALID_SPECIFIER
ERR_MANIFEST_PARSE_POLICY
ERR_MANIFEST_TDZ
ERR_MANIFEST_UNKNOWN_ONERROR
ERR_MISSING_MESSAGE_PORT_IN_TRANSFER_LIST
ERR_MISSING_TRANSFERABLE_IN_TRANSFER_LIST
ERR_NAPI_CONS_PROTOTYPE_OBJECT
ERR_NAPI_TSFN_START_IDLE_LOOP
ERR_NAPI_TSFN_STOP_IDLE_LOOP
ERR_NO_LONGER_SUPPORTED
ERR_OUTOFMEMORY
ERR_PARSE_HISTORY_DATA
ERR_SOCKET_CANNOT_SEND
ERR_STDERR_CLOSE
ERR_STDOUT_CLOSE
ERR_STREAM_READ_NOT_IMPLEMENTED
ERR_TAP_LEXER_ERROR
ERR_TAP_PARSER_ERROR
ERR_TAP_VALIDATION_ERROR
ERR_TLS_RENEGOTIATION_FAILED
ERR_TRANSFERRING_EXTERNALIZED_SHAREDARRAYBUFFER
ERR_UNKNOWN_STDIN_TYPE
ERR_UNKNOWN_STREAM_TYPE
ERR_V8BREAKITERATOR
ERR_VALUE_OUT_OF_RANGE
ERR_VM_MODULE_LINKING_ERRORED
ERR_VM_MODULE_NOT_LINKED
ERR_WORKER_UNSUPPORTED_EXTENSION
ERR_ZLIB_BINDING_CLOSED


OpenSSL Error Codes

Time Validity Errors

CERT_NOT_YET_VALID
CERT_HAS_EXPIRED
CRL_NOT_YET_VALID
CRL_HAS_EXPIRED
CERT_REVOKED


Trust or Chain Related Errors

UNABLE_TO_GET_ISSUER_CERT
UNABLE_TO_GET_ISSUER_CERT_LOCALLY
DEPTH_ZERO_SELF_SIGNED_CERT
SELF_SIGNED_CERT_IN_CHAIN
CERT_CHAIN_TOO_LONG
UNABLE_TO_GET_CRL
UNABLE_TO_VERIFY_LEAF_SIGNATURE
CERT_UNTRUSTED


Basic Extension Errors

INVALID_CA
PATH_LENGTH_EXCEEDED


Name Related Errors

HOSTNAME_MISMATCH


Usage and Policy Errors

INVALID_PURPOSE
CERT_REJECTED


Formatting Errors

CERT_SIGNATURE_FAILURE
CRL_SIGNATURE_FAILURE
ERROR_IN_CERT_NOT_BEFORE_FIELD
ERROR_IN_CERT_NOT_AFTER_FIELD
ERROR_IN_CRL_LAST_UPDATE_FIELD
ERROR_IN_CRL_NEXT_UPDATE_FIELD
UNABLE_TO_DECRYPT_CERT_SIGNATURE
UNABLE_TO_DECRYPT_CRL_SIGNATURE
UNABLE_TO_DECODE_ISSUER_PUBLIC_KEY


Other OpenSSL Errors

OUT_OF_MEM








      
        Errors#


Applications running in Node.js will generally experience the following
categories of errors:

Standard JavaScript errors such as <EvalError>, <SyntaxError>, <RangeError>,
<ReferenceError>, <TypeError>, and <URIError>.
Standard DOMExceptions.
System errors triggered by underlying operating system constraints such
as attempting to open a file that does not exist or attempting to send data
over a closed socket.
AssertionErrors are a special class of error that can be triggered when
Node.js detects an exceptional logic violation that should never occur. These
are raised typically by the node:assert module.
User-specified errors triggered by application code.

All JavaScript and system errors raised by Node.js inherit from, or are
instances of, the standard JavaScript <Error> class and are guaranteed
to provide at least the properties available on that class.
The error.message property of errors raised by Node.js may be changed in
any versions. Use error.code to identify an error instead. For a
DOMException, use domException.name to identify its type.
Error propagation and interception#

Node.js supports several mechanisms for propagating and handling errors that
occur while an application is running. How these errors are reported and
handled depends entirely on the type of Error and the style of the API that is
called.
All JavaScript errors are handled as exceptions that immediately generate
and throw an error using the standard JavaScript throw mechanism. These
are handled using the try…catch construct provided by the
JavaScript language.
// Throws with a ReferenceError because z is not defined.
try {
  const m = 1;
  const n = m + z;
} catch (err) {
  // Handle the error here.
} copy
Any use of the JavaScript throw mechanism will raise an exception that
must be handled or the Node.js process will exit immediately.
With few exceptions, Synchronous APIs (any blocking method that does not
return a <Promise> nor accept a callback function, such as
fs.readFileSync), will use throw to report errors.
Errors that occur within Asynchronous APIs may be reported in multiple ways:


Some asynchronous methods returns a <Promise>, you should always take into
account that it might be rejected. See --unhandled-rejections flag for
how the process will react to an unhandled promise rejection.

const fs = require('node:fs/promises');

(async () => {
  let data;
  try {
    data = await fs.readFile('a file that does not exist');
  } catch (err) {
    console.error('There was an error reading the file!', err);
    return;
  }
  // Otherwise handle the data
})(); copy


Most asynchronous methods that accept a callback function will accept an
Error object passed as the first argument to that function. If that first
argument is not null and is an instance of Error, then an error occurred
that should be handled.

const fs = require('node:fs');
fs.readFile('a file that does not exist', (err, data) => {
  if (err) {
    console.error('There was an error reading the file!', err);
    return;
  }
  // Otherwise handle the data
}); copy


When an asynchronous method is called on an object that is an
EventEmitter, errors can be routed to that object's 'error' event.
const net = require('node:net');
const connection = net.connect('localhost');

// Adding an 'error' event handler to a stream:
connection.on('error', (err) => {
  // If the connection is reset by the server, or if it can't
  // connect at all, or on any sort of error encountered by
  // the connection, the error will be sent here.
  console.error(err);
});

connection.pipe(process.stdout); copy


A handful of typically asynchronous methods in the Node.js API may still
use the throw mechanism to raise exceptions that must be handled using
try…catch. There is no comprehensive list of such methods; please
refer to the documentation of each method to determine the appropriate
error handling mechanism required.


The use of the 'error' event mechanism is most common for stream-based
and event emitter-based APIs, which themselves represent a series of
asynchronous operations over time (as opposed to a single operation that may
pass or fail).
For all EventEmitter objects, if an 'error' event handler is not
provided, the error will be thrown, causing the Node.js process to report an
uncaught exception and crash unless either: a handler has been registered for
the 'uncaughtException' event, or the deprecated node:domain
module is used.
const EventEmitter = require('node:events');
const ee = new EventEmitter();

setImmediate(() => {
  // This will crash the process because no 'error' event
  // handler has been added.
  ee.emit('error', new Error('This will crash'));
}); copy
Errors generated in this way cannot be intercepted using try…catch as
they are thrown after the calling code has already exited.
Developers must refer to the documentation for each method to determine
exactly how errors raised by those methods are propagated.
Class: Error#

A generic JavaScript <Error> object that does not denote any specific
circumstance of why the error occurred. Error objects capture a "stack trace"
detailing the point in the code at which the Error was instantiated, and may
provide a text description of the error.
All errors generated by Node.js, including all system and JavaScript errors,
will either be instances of, or inherit from, the Error class.

new Error(message[, options])#

message <string>
options <Object>

cause <any> The error that caused the newly created error.



Creates a new Error object and sets the error.message property to the
provided text message. If an object is passed as message, the text message
is generated by calling String(message). If the cause option is provided,
it is assigned to the error.cause property. The error.stack property will
represent the point in the code at which new Error() was called. Stack traces
are dependent on V8's stack trace API. Stack traces extend only to either
(a) the beginning of synchronous code execution, or (b) the number of frames
given by the property Error.stackTraceLimit, whichever is smaller.

Error.captureStackTrace(targetObject[, constructorOpt])#

targetObject <Object>
constructorOpt <Function>

Creates a .stack property on targetObject, which when accessed returns
a string representing the location in the code at which
Error.captureStackTrace() was called.
const myObject = {};
Error.captureStackTrace(myObject);
myObject.stack;  // Similar to `new Error().stack` copy
The first line of the trace will be prefixed with
${myObject.name}: ${myObject.message}.
The optional constructorOpt argument accepts a function. If given, all frames
above constructorOpt, including constructorOpt, will be omitted from the
generated stack trace.
The constructorOpt argument is useful for hiding implementation
details of error generation from the user. For instance:
function a() {
  b();
}

function b() {
  c();
}

function c() {
  // Create an error without stack trace to avoid calculating the stack trace twice.
  const { stackTraceLimit } = Error;
  Error.stackTraceLimit = 0;
  const error = new Error();
  Error.stackTraceLimit = stackTraceLimit;

  // Capture the stack trace above function b
  Error.captureStackTrace(error, b); // Neither function c, nor b is included in the stack trace
  throw error;
}

a(); copy

Error.stackTraceLimit#

<number>

The Error.stackTraceLimit property specifies the number of stack frames
collected by a stack trace (whether generated by new Error().stack or
Error.captureStackTrace(obj)).
The default value is 10 but may be set to any valid JavaScript number. Changes
will affect any stack trace captured after the value has been changed.
If set to a non-number value, or set to a negative number, stack traces will
not capture any frames.

error.cause#

Added in: v16.9.0


<any>

If present, the error.cause property is the underlying cause of the Error.
It is used when catching an error and throwing a new one with a different
message or code in order to still have access to the original error.
The error.cause property is typically set by calling
new Error(message, { cause }). It is not set by the constructor if the
cause option is not provided.
This property allows errors to be chained. When serializing Error objects,
util.inspect() recursively serializes error.cause if it is set.
const cause = new Error('The remote HTTP server responded with a 500 status');
const symptom = new Error('The message failed to send', { cause });

console.log(symptom);
// Prints:
//   Error: The message failed to send
//       at REPL2:1:17
//       at Script.runInThisContext (node:vm:130:12)
//       ... 7 lines matching cause stack trace ...
//       at [_line] [as _line] (node:internal/readline/interface:886:18) {
//     [cause]: Error: The remote HTTP server responded with a 500 status
//         at REPL1:1:15
//         at Script.runInThisContext (node:vm:130:12)
//         at REPLServer.defaultEval (node:repl:574:29)
//         at bound (node:domain:426:15)
//         at REPLServer.runBound [as eval] (node:domain:437:12)
//         at REPLServer.onLine (node:repl:902:10)
//         at REPLServer.emit (node:events:549:35)
//         at REPLServer.emit (node:domain:482:12)
//         at [_onLine] [as _onLine] (node:internal/readline/interface:425:12)
//         at [_line] [as _line] (node:internal/readline/interface:886:18) copy

error.code#

<string>

The error.code property is a string label that identifies the kind of error.
error.code is the most stable way to identify an error. It will only change
between major versions of Node.js. In contrast, error.message strings may
change between any versions of Node.js. See Node.js error codes for details
about specific codes.

error.message#

<string>

The error.message property is the string description of the error as set by
calling new Error(message). The message passed to the constructor will also
appear in the first line of the stack trace of the Error, however changing
this property after the Error object is created may not change the first
line of the stack trace (for example, when error.stack is read before this
property is changed).
const err = new Error('The message');
console.error(err.message);
// Prints: The message copy

error.stack#

<string>

The error.stack property is a string describing the point in the code at which
the Error was instantiated.
Error: Things keep happening!
   at /home/gbusey/file.js:525:2
   at Frobnicator.refrobulate (/home/gbusey/business-logic.js:424:21)
   at Actor.<anonymous> (/home/gbusey/actors.js:400:8)
   at increaseSynergy (/home/gbusey/actors.js:701:6) copy
The first line is formatted as <error class name>: <error message>, and
is followed by a series of stack frames (each line beginning with "at ").
Each frame describes a call site within the code that lead to the error being
generated. V8 attempts to display a name for each function (by variable name,
function name, or object method name), but occasionally it will not be able to
find a suitable name. If V8 cannot determine a name for the function, only
location information will be displayed for that frame. Otherwise, the
determined function name will be displayed with location information appended
in parentheses.
Frames are only generated for JavaScript functions. If, for example, execution
synchronously passes through a C++ addon function called cheetahify which
itself calls a JavaScript function, the frame representing the cheetahify call
will not be present in the stack traces:
const cheetahify = require('./native-binding.node');

function makeFaster() {
  // `cheetahify()` *synchronously* calls speedy.
  cheetahify(function speedy() {
    throw new Error('oh no!');
  });
}

makeFaster();
// will throw:
//   /home/gbusey/file.js:6
//       throw new Error('oh no!');
//           ^
//   Error: oh no!
//       at speedy (/home/gbusey/file.js:6:11)
//       at makeFaster (/home/gbusey/file.js:5:3)
//       at Object.<anonymous> (/home/gbusey/file.js:10:1)
//       at Module._compile (module.js:456:26)
//       at Object.Module._extensions..js (module.js:474:10)
//       at Module.load (module.js:356:32)
//       at Function.Module._load (module.js:312:12)
//       at Function.Module.runMain (module.js:497:10)
//       at startup (node.js:119:16)
//       at node.js:906:3 copy
The location information will be one of:

native, if the frame represents a call internal to V8 (as in [].forEach).
plain-filename.js:line:column, if the frame represents a call internal
to Node.js.
/absolute/path/to/file.js:line:column, if the frame represents a call in
a user program (using CommonJS module system), or its dependencies.
<transport-protocol>:///url/to/module/file.mjs:line:column, if the frame
represents a call in a user program (using ES module system), or
its dependencies.

The string representing the stack trace is lazily generated when the
error.stack property is accessed.
The number of frames captured by the stack trace is bounded by the smaller of
Error.stackTraceLimit or the number of available frames on the current event
loop tick.

Class: AssertionError#

Extends: <errors.Error>

Indicates the failure of an assertion. For details, see
Class: assert.AssertionError.
Class: RangeError#

Extends: <errors.Error>

Indicates that a provided argument was not within the set or range of
acceptable values for a function; whether that is a numeric range, or
outside the set of options for a given function parameter.
require('node:net').connect(-1);
// Throws "RangeError: "port" option should be >= 0 and < 65536: -1" copy
Node.js will generate and throw RangeError instances immediately as a form
of argument validation.
Class: ReferenceError#

Extends: <errors.Error>

Indicates that an attempt is being made to access a variable that is not
defined. Such errors commonly indicate typos in code, or an otherwise broken
program.
While client code may generate and propagate these errors, in practice, only V8
will do so.
doesNotExist;
// Throws ReferenceError, doesNotExist is not a variable in this program. copy
Unless an application is dynamically generating and running code,
ReferenceError instances indicate a bug in the code or its dependencies.
Class: SyntaxError#

Extends: <errors.Error>

Indicates that a program is not valid JavaScript. These errors may only be
generated and propagated as a result of code evaluation. Code evaluation may
happen as a result of eval, Function, require, or vm. These errors
are almost always indicative of a broken program.
try {
  require('node:vm').runInThisContext('binary ! isNotOk');
} catch (err) {
  // 'err' will be a SyntaxError.
} copy
SyntaxError instances are unrecoverable in the context that created them –
they may only be caught by other contexts.
Class: SystemError#

Extends: <errors.Error>

Node.js generates system errors when exceptions occur within its runtime
environment. These usually occur when an application violates an operating
system constraint. For example, a system error will occur if an application
attempts to read a file that does not exist.

address <string> If present, the address to which a network connection
failed
code <string> The string error code
dest <string> If present, the file path destination when reporting a file
system error
errno <number> The system-provided error number
info <Object> If present, extra details about the error condition
message <string> A system-provided human-readable description of the error
path <string> If present, the file path when reporting a file system error
port <number> If present, the network connection port that is not available
syscall <string> The name of the system call that triggered the error


error.address#

<string>

If present, error.address is a string describing the address to which a
network connection failed.

error.code#

<string>

The error.code property is a string representing the error code.

error.dest#

<string>

If present, error.dest is the file path destination when reporting a file
system error.

error.errno#

<number>

The error.errno property is a negative number which corresponds
to the error code defined in libuv Error handling.
On Windows the error number provided by the system will be normalized by libuv.
To get the string representation of the error code, use
util.getSystemErrorName(error.errno).

error.info#

<Object>

If present, error.info is an object with details about the error condition.

error.message#

<string>

error.message is a system-provided human-readable description of the error.

error.path#

<string>

If present, error.path is a string containing a relevant invalid pathname.

error.port#

<number>

If present, error.port is the network connection port that is not available.

error.syscall#

<string>

The error.syscall property is a string describing the syscall that failed.

Common system errors#
This is a list of system errors commonly-encountered when writing a Node.js
program. For a comprehensive list, see the errno(3) man page.


EACCES (Permission denied): An attempt was made to access a file in a way
forbidden by its file access permissions.


EADDRINUSE (Address already in use): An attempt to bind a server
(net, http, or https) to a local address failed due to
another server on the local system already occupying that address.


ECONNREFUSED (Connection refused): No connection could be made because the
target machine actively refused it. This usually results from trying to
connect to a service that is inactive on the foreign host.


ECONNRESET (Connection reset by peer): A connection was forcibly closed by
a peer. This normally results from a loss of the connection on the remote
socket due to a timeout or reboot. Commonly encountered via the http
and net modules.


EEXIST (File exists): An existing file was the target of an operation that
required that the target not exist.


EISDIR (Is a directory): An operation expected a file, but the given
pathname was a directory.


EMFILE (Too many open files in system): Maximum number of
file descriptors allowable on the system has been reached, and
requests for another descriptor cannot be fulfilled until at least one
has been closed. This is encountered when opening many files at once in
parallel, especially on systems (in particular, macOS) where there is a low
file descriptor limit for processes. To remedy a low limit, run
ulimit -n 2048 in the same shell that will run the Node.js process.


ENOENT (No such file or directory): Commonly raised by fs operations
to indicate that a component of the specified pathname does not exist. No
entity (file or directory) could be found by the given path.


ENOTDIR (Not a directory): A component of the given pathname existed, but
was not a directory as expected. Commonly raised by fs.readdir.


ENOTEMPTY (Directory not empty): A directory with entries was the target
of an operation that requires an empty directory, usually fs.unlink.


ENOTFOUND (DNS lookup failed): Indicates a DNS failure of either
EAI_NODATA or EAI_NONAME. This is not a standard POSIX error.


EPERM (Operation not permitted): An attempt was made to perform an
operation that requires elevated privileges.


EPIPE (Broken pipe): A write on a pipe, socket, or FIFO for which there is
no process to read the data. Commonly encountered at the net and
http layers, indicative that the remote side of the stream being
written to has been closed.


ETIMEDOUT (Operation timed out): A connect or send request failed because
the connected party did not properly respond after a period of time. Usually
encountered by http or net. Often a sign that a socket.end()
was not properly called.



Class: TypeError#

Extends <errors.Error>

Indicates that a provided argument is not an allowable type. For example,
passing a function to a parameter which expects a string would be a TypeError.
require('node:url').parse(() => { });
// Throws TypeError, since it expected a string. copy
Node.js will generate and throw TypeError instances immediately as a form
of argument validation.
Exceptions vs. errors#

A JavaScript exception is a value that is thrown as a result of an invalid
operation or as the target of a throw statement. While it is not required
that these values are instances of Error or classes which inherit from
Error, all exceptions thrown by Node.js or the JavaScript runtime will be
instances of Error.
Some exceptions are unrecoverable at the JavaScript layer. Such exceptions
will always cause the Node.js process to crash. Examples include assert()
checks or abort() calls in the C++ layer.
OpenSSL errors#
Errors originating in crypto or tls are of class Error, and in addition to
the standard .code and .message properties, may have some additional
OpenSSL-specific properties.

error.opensslErrorStack#
An array of errors that can give context to where in the OpenSSL library an
error originates from.

error.function#
The OpenSSL function the error originates in.

error.library#
The OpenSSL library the error originates in.

error.reason#
A human-readable string describing the reason for the error.


Node.js error codes#


ABORT_ERR#

Added in: v15.0.0

Used when an operation has been aborted (typically using an AbortController).
APIs not using AbortSignals typically do not raise an error with this code.
This code does not use the regular ERR_* convention Node.js errors use in
order to be compatible with the web platform's AbortError.


ERR_ACCESS_DENIED#
A special type of error that is triggered whenever Node.js tries to get access
to a resource restricted by the Permission Model.


ERR_AMBIGUOUS_ARGUMENT#
A function argument is being used in a way that suggests that the function
signature may be misunderstood. This is thrown by the node:assert module when
the message parameter in assert.throws(block, message) matches the error
message thrown by block because that usage suggests that the user believes
message is the expected message rather than the message the AssertionError
will display if block does not throw.


ERR_ARG_NOT_ITERABLE#
An iterable argument (i.e. a value that works with for...of loops) was
required, but not provided to a Node.js API.


ERR_ASSERTION#
A special type of error that can be triggered whenever Node.js detects an
exceptional logic violation that should never occur. These are raised typically
by the node:assert module.


ERR_ASYNC_CALLBACK#
An attempt was made to register something that is not a function as an
AsyncHooks callback.


ERR_ASYNC_TYPE#
The type of an asynchronous resource was invalid. Users are also able
to define their own types if using the public embedder API.


ERR_BROTLI_COMPRESSION_FAILED#
Data passed to a Brotli stream was not successfully compressed.


ERR_BROTLI_INVALID_PARAM#
An invalid parameter key was passed during construction of a Brotli stream.


ERR_BUFFER_CONTEXT_NOT_AVAILABLE#
An attempt was made to create a Node.js Buffer instance from addon or embedder
code, while in a JS engine Context that is not associated with a Node.js
instance. The data passed to the Buffer method will have been released
by the time the method returns.
When encountering this error, a possible alternative to creating a Buffer
instance is to create a normal Uint8Array, which only differs in the
prototype of the resulting object. Uint8Arrays are generally accepted in all
Node.js core APIs where Buffers are; they are available in all Contexts.


ERR_BUFFER_OUT_OF_BOUNDS#
An operation outside the bounds of a Buffer was attempted.


ERR_BUFFER_TOO_LARGE#
An attempt has been made to create a Buffer larger than the maximum allowed
size.


ERR_CANNOT_WATCH_SIGINT#
Node.js was unable to watch for the SIGINT signal.


ERR_CHILD_CLOSED_BEFORE_REPLY#
A child process was closed before the parent received a reply.


ERR_CHILD_PROCESS_IPC_REQUIRED#
Used when a child process is being forked without specifying an IPC channel.


ERR_CHILD_PROCESS_STDIO_MAXBUFFER#
Used when the main process is trying to read data from the child process's
STDERR/STDOUT, and the data's length is longer than the maxBuffer option.


ERR_CLOSED_MESSAGE_PORT#

History

VersionChanges
v16.2.0, v14.17.1
The error message was reintroduced.
v11.12.0
The error message was removed.
v10.5.0
Added in: v10.5.0



There was an attempt to use a MessagePort instance in a closed
state, usually after .close() has been called.


ERR_CONSOLE_WRITABLE_STREAM#
Console was instantiated without stdout stream, or Console has a
non-writable stdout or stderr stream.


ERR_CONSTRUCT_CALL_INVALID#

Added in: v12.5.0

A class constructor was called that is not callable.


ERR_CONSTRUCT_CALL_REQUIRED#
A constructor for a class was called without new.


ERR_CONTEXT_NOT_INITIALIZED#
The vm context passed into the API is not yet initialized. This could happen
when an error occurs (and is caught) during the creation of the
context, for example, when the allocation fails or the maximum call stack
size is reached when the context is created.


ERR_CRYPTO_CUSTOM_ENGINE_NOT_SUPPORTED#
An OpenSSL engine was requested (for example, through the clientCertEngine or
privateKeyEngine TLS options) that is not supported by the version of OpenSSL
being used, likely due to the compile-time flag OPENSSL_NO_ENGINE.


ERR_CRYPTO_ECDH_INVALID_FORMAT#
An invalid value for the format argument was passed to the crypto.ECDH()
class getPublicKey() method.


ERR_CRYPTO_ECDH_INVALID_PUBLIC_KEY#
An invalid value for the key argument has been passed to the
crypto.ECDH() class computeSecret() method. It means that the public
key lies outside of the elliptic curve.


ERR_CRYPTO_ENGINE_UNKNOWN#
An invalid crypto engine identifier was passed to
require('node:crypto').setEngine().


ERR_CRYPTO_FIPS_FORCED#
The --force-fips command-line argument was used but there was an attempt
to enable or disable FIPS mode in the node:crypto module.


ERR_CRYPTO_FIPS_UNAVAILABLE#
An attempt was made to enable or disable FIPS mode, but FIPS mode was not
available.


ERR_CRYPTO_HASH_FINALIZED#
hash.digest() was called multiple times. The hash.digest() method must
be called no more than one time per instance of a Hash object.


ERR_CRYPTO_HASH_UPDATE_FAILED#
hash.update() failed for any reason. This should rarely, if ever, happen.


ERR_CRYPTO_INCOMPATIBLE_KEY#
The given crypto keys are incompatible with the attempted operation.


ERR_CRYPTO_INCOMPATIBLE_KEY_OPTIONS#
The selected public or private key encoding is incompatible with other options.


ERR_CRYPTO_INITIALIZATION_FAILED#

Added in: v15.0.0

Initialization of the crypto subsystem failed.


ERR_CRYPTO_INVALID_AUTH_TAG#

Added in: v15.0.0

An invalid authentication tag was provided.


ERR_CRYPTO_INVALID_COUNTER#

Added in: v15.0.0

An invalid counter was provided for a counter-mode cipher.


ERR_CRYPTO_INVALID_CURVE#

Added in: v15.0.0

An invalid elliptic-curve was provided.


ERR_CRYPTO_INVALID_DIGEST#
An invalid crypto digest algorithm was specified.


ERR_CRYPTO_INVALID_IV#

Added in: v15.0.0

An invalid initialization vector was provided.


ERR_CRYPTO_INVALID_JWK#

Added in: v15.0.0

An invalid JSON Web Key was provided.


ERR_CRYPTO_INVALID_KEYLEN#

Added in: v15.0.0

An invalid key length was provided.


ERR_CRYPTO_INVALID_KEYPAIR#

Added in: v15.0.0

An invalid key pair was provided.


ERR_CRYPTO_INVALID_KEYTYPE#

Added in: v15.0.0

An invalid key type was provided.


ERR_CRYPTO_INVALID_KEY_OBJECT_TYPE#
The given crypto key object's type is invalid for the attempted operation.


ERR_CRYPTO_INVALID_MESSAGELEN#

Added in: v15.0.0

An invalid message length was provided.


ERR_CRYPTO_INVALID_SCRYPT_PARAMS#

Added in: v15.0.0

One or more crypto.scrypt() or crypto.scryptSync() parameters are
outside their legal range.


ERR_CRYPTO_INVALID_STATE#
A crypto method was used on an object that was in an invalid state. For
instance, calling cipher.getAuthTag() before calling cipher.final().


ERR_CRYPTO_INVALID_TAG_LENGTH#

Added in: v15.0.0

An invalid authentication tag length was provided.


ERR_CRYPTO_JOB_INIT_FAILED#

Added in: v15.0.0

Initialization of an asynchronous crypto operation failed.


ERR_CRYPTO_JWK_UNSUPPORTED_CURVE#
Key's Elliptic Curve is not registered for use in the
JSON Web Key Elliptic Curve Registry.


ERR_CRYPTO_JWK_UNSUPPORTED_KEY_TYPE#
Key's Asymmetric Key Type is not registered for use in the
JSON Web Key Types Registry.


ERR_CRYPTO_OPERATION_FAILED#

Added in: v15.0.0

A crypto operation failed for an otherwise unspecified reason.


ERR_CRYPTO_PBKDF2_ERROR#
The PBKDF2 algorithm failed for unspecified reasons. OpenSSL does not provide
more details and therefore neither does Node.js.


ERR_CRYPTO_SCRYPT_NOT_SUPPORTED#
Node.js was compiled without scrypt support. Not possible with the official
release binaries but can happen with custom builds, including distro builds.


ERR_CRYPTO_SIGN_KEY_REQUIRED#
A signing key was not provided to the sign.sign() method.


ERR_CRYPTO_TIMING_SAFE_EQUAL_LENGTH#
crypto.timingSafeEqual() was called with Buffer, TypedArray, or
DataView arguments of different lengths.


ERR_CRYPTO_UNKNOWN_CIPHER#
An unknown cipher was specified.


ERR_CRYPTO_UNKNOWN_DH_GROUP#
An unknown Diffie-Hellman group name was given. See
crypto.getDiffieHellman() for a list of valid group names.


ERR_CRYPTO_UNSUPPORTED_OPERATION#

Added in: v15.0.0, v14.18.0

An attempt to invoke an unsupported crypto operation was made.


ERR_DEBUGGER_ERROR#

Added in: v16.4.0, v14.17.4

An error occurred with the debugger.


ERR_DEBUGGER_STARTUP_ERROR#

Added in: v16.4.0, v14.17.4

The debugger timed out waiting for the required host/port to be free.


ERR_DIR_CLOSED#
The fs.Dir was previously closed.


ERR_DIR_CONCURRENT_OPERATION#

Added in: v14.3.0

A synchronous read or close call was attempted on an fs.Dir which has
ongoing asynchronous operations.


ERR_DLOPEN_DISABLED#

Added in: v16.10.0, v14.19.0

Loading native addons has been disabled using --no-addons.


ERR_DLOPEN_FAILED#

Added in: v15.0.0

A call to process.dlopen() failed.


ERR_DNS_SET_SERVERS_FAILED#
c-ares failed to set the DNS server.


ERR_DOMAIN_CALLBACK_NOT_AVAILABLE#
The node:domain module was not usable since it could not establish the
required error handling hooks, because
process.setUncaughtExceptionCaptureCallback() had been called at an
earlier point in time.


ERR_DOMAIN_CANNOT_SET_UNCAUGHT_EXCEPTION_CAPTURE#
process.setUncaughtExceptionCaptureCallback() could not be called
because the node:domain module has been loaded at an earlier point in time.
The stack trace is extended to include the point in time at which the
node:domain module had been loaded.


ERR_DUPLICATE_STARTUP_SNAPSHOT_MAIN_FUNCTION#
v8.startupSnapshot.setDeserializeMainFunction() could not be called
because it had already been called before.


ERR_ENCODING_INVALID_ENCODED_DATA#
Data provided to TextDecoder() API was invalid according to the encoding
provided.


ERR_ENCODING_NOT_SUPPORTED#
Encoding provided to TextDecoder() API was not one of the
WHATWG Supported Encodings.


ERR_EVAL_ESM_CANNOT_PRINT#
--print cannot be used with ESM input.


ERR_EVENT_RECURSION#
Thrown when an attempt is made to recursively dispatch an event on EventTarget.


ERR_EXECUTION_ENVIRONMENT_NOT_AVAILABLE#
The JS execution context is not associated with a Node.js environment.
This may occur when Node.js is used as an embedded library and some hooks
for the JS engine are not set up properly.


ERR_FALSY_VALUE_REJECTION#
A Promise that was callbackified via util.callbackify() was rejected with a
falsy value.


ERR_FEATURE_UNAVAILABLE_ON_PLATFORM#

Added in: v14.0.0

Used when a feature that is not available
to the current platform which is running Node.js is used.


ERR_FS_CP_DIR_TO_NON_DIR#

Added in: v16.7.0

An attempt was made to copy a directory to a non-directory (file, symlink,
etc.) using fs.cp().


ERR_FS_CP_EEXIST#

Added in: v16.7.0

An attempt was made to copy over a file that already existed with
fs.cp(), with the force and errorOnExist set to true.


ERR_FS_CP_EINVAL#

Added in: v16.7.0

When using fs.cp(), src or dest pointed to an invalid path.


ERR_FS_CP_FIFO_PIPE#

Added in: v16.7.0

An attempt was made to copy a named pipe with fs.cp().


ERR_FS_CP_NON_DIR_TO_DIR#

Added in: v16.7.0

An attempt was made to copy a non-directory (file, symlink, etc.) to a directory
using fs.cp().


ERR_FS_CP_SOCKET#

Added in: v16.7.0

An attempt was made to copy to a socket with fs.cp().


ERR_FS_CP_SYMLINK_TO_SUBDIRECTORY#

Added in: v16.7.0

When using fs.cp(), a symlink in dest pointed to a subdirectory
of src.


ERR_FS_CP_UNKNOWN#

Added in: v16.7.0

An attempt was made to copy to an unknown file type with fs.cp().


ERR_FS_EISDIR#
Path is a directory.


ERR_FS_FILE_TOO_LARGE#
An attempt has been made to read a file whose size is larger than the maximum
allowed size for a Buffer.


ERR_HTTP2_ALTSVC_INVALID_ORIGIN#
HTTP/2 ALTSVC frames require a valid origin.


ERR_HTTP2_ALTSVC_LENGTH#
HTTP/2 ALTSVC frames are limited to a maximum of 16,382 payload bytes.


ERR_HTTP2_CONNECT_AUTHORITY#
For HTTP/2 requests using the CONNECT method, the :authority pseudo-header
is required.


ERR_HTTP2_CONNECT_PATH#
For HTTP/2 requests using the CONNECT method, the :path pseudo-header is
forbidden.


ERR_HTTP2_CONNECT_SCHEME#
For HTTP/2 requests using the CONNECT method, the :scheme pseudo-header is
forbidden.


ERR_HTTP2_ERROR#
A non-specific HTTP/2 error has occurred.


ERR_HTTP2_GOAWAY_SESSION#
New HTTP/2 Streams may not be opened after the Http2Session has received a
GOAWAY frame from the connected peer.


ERR_HTTP2_HEADERS_AFTER_RESPOND#
An additional headers was specified after an HTTP/2 response was initiated.


ERR_HTTP2_HEADERS_SENT#
An attempt was made to send multiple response headers.


ERR_HTTP2_HEADER_SINGLE_VALUE#
Multiple values were provided for an HTTP/2 header field that was required to
have only a single value.


ERR_HTTP2_INFO_STATUS_NOT_ALLOWED#
Informational HTTP status codes (1xx) may not be set as the response status
code on HTTP/2 responses.


ERR_HTTP2_INVALID_CONNECTION_HEADERS#
HTTP/1 connection specific headers are forbidden to be used in HTTP/2
requests and responses.


ERR_HTTP2_INVALID_HEADER_VALUE#
An invalid HTTP/2 header value was specified.


ERR_HTTP2_INVALID_INFO_STATUS#
An invalid HTTP informational status code has been specified. Informational
status codes must be an integer between 100 and 199 (inclusive).


ERR_HTTP2_INVALID_ORIGIN#
HTTP/2 ORIGIN frames require a valid origin.


ERR_HTTP2_INVALID_PACKED_SETTINGS_LENGTH#
Input Buffer and Uint8Array instances passed to the
http2.getUnpackedSettings() API must have a length that is a multiple of
six.


ERR_HTTP2_INVALID_PSEUDOHEADER#
Only valid HTTP/2 pseudoheaders (:status, :path, :authority, :scheme,
and :method) may be used.


ERR_HTTP2_INVALID_SESSION#
An action was performed on an Http2Session object that had already been
destroyed.


ERR_HTTP2_INVALID_SETTING_VALUE#
An invalid value has been specified for an HTTP/2 setting.


ERR_HTTP2_INVALID_STREAM#
An operation was performed on a stream that had already been destroyed.


ERR_HTTP2_MAX_PENDING_SETTINGS_ACK#
Whenever an HTTP/2 SETTINGS frame is sent to a connected peer, the peer is
required to send an acknowledgment that it has received and applied the new
SETTINGS. By default, a maximum number of unacknowledged SETTINGS frames may
be sent at any given time. This error code is used when that limit has been
reached.


ERR_HTTP2_NESTED_PUSH#
An attempt was made to initiate a new push stream from within a push stream.
Nested push streams are not permitted.


ERR_HTTP2_NO_MEM#
Out of memory when using the http2session.setLocalWindowSize(windowSize) API.


ERR_HTTP2_NO_SOCKET_MANIPULATION#
An attempt was made to directly manipulate (read, write, pause, resume, etc.) a
socket attached to an Http2Session.


ERR_HTTP2_ORIGIN_LENGTH#
HTTP/2 ORIGIN frames are limited to a length of 16382 bytes.


ERR_HTTP2_OUT_OF_STREAMS#
The number of streams created on a single HTTP/2 session reached the maximum
limit.


ERR_HTTP2_PAYLOAD_FORBIDDEN#
A message payload was specified for an HTTP response code for which a payload is
forbidden.


ERR_HTTP2_PING_CANCEL#
An HTTP/2 ping was canceled.


ERR_HTTP2_PING_LENGTH#
HTTP/2 ping payloads must be exactly 8 bytes in length.


ERR_HTTP2_PSEUDOHEADER_NOT_ALLOWED#
An HTTP/2 pseudo-header has been used inappropriately. Pseudo-headers are header
key names that begin with the : prefix.


ERR_HTTP2_PUSH_DISABLED#
An attempt was made to create a push stream, which had been disabled by the
client.


ERR_HTTP2_SEND_FILE#
An attempt was made to use the Http2Stream.prototype.responseWithFile() API to
send a directory.


ERR_HTTP2_SEND_FILE_NOSEEK#
An attempt was made to use the Http2Stream.prototype.responseWithFile() API to
send something other than a regular file, but offset or length options were
provided.


ERR_HTTP2_SESSION_ERROR#
The Http2Session closed with a non-zero error code.


ERR_HTTP2_SETTINGS_CANCEL#
The Http2Session settings canceled.


ERR_HTTP2_SOCKET_BOUND#
An attempt was made to connect a Http2Session object to a net.Socket or
tls.TLSSocket that had already been bound to another Http2Session object.


ERR_HTTP2_SOCKET_UNBOUND#
An attempt was made to use the socket property of an Http2Session that
has already been closed.


ERR_HTTP2_STATUS_101#
Use of the 101 Informational status code is forbidden in HTTP/2.


ERR_HTTP2_STATUS_INVALID#
An invalid HTTP status code has been specified. Status codes must be an integer
between 100 and 599 (inclusive).


ERR_HTTP2_STREAM_CANCEL#
An Http2Stream was destroyed before any data was transmitted to the connected
peer.


ERR_HTTP2_STREAM_ERROR#
A non-zero error code was been specified in an RST_STREAM frame.


ERR_HTTP2_STREAM_SELF_DEPENDENCY#
When setting the priority for an HTTP/2 stream, the stream may be marked as
a dependency for a parent stream. This error code is used when an attempt is
made to mark a stream and dependent of itself.


ERR_HTTP2_TOO_MANY_CUSTOM_SETTINGS#
The number of supported custom settings (10) has been exceeded.


ERR_HTTP2_TOO_MANY_INVALID_FRAMES#

Added in: v15.14.0

The limit of acceptable invalid HTTP/2 protocol frames sent by the peer,
as specified through the maxSessionInvalidFrames option, has been exceeded.


ERR_HTTP2_TRAILERS_ALREADY_SENT#
Trailing headers have already been sent on the Http2Stream.


ERR_HTTP2_TRAILERS_NOT_READY#
The http2stream.sendTrailers() method cannot be called until after the
'wantTrailers' event is emitted on an Http2Stream object. The
'wantTrailers' event will only be emitted if the waitForTrailers option
is set for the Http2Stream.


ERR_HTTP2_UNSUPPORTED_PROTOCOL#
http2.connect() was passed a URL that uses any protocol other than http: or
https:.


ERR_HTTP_BODY_NOT_ALLOWED#
An error is thrown when writing to an HTTP response which does not allow
contents.


ERR_HTTP_CONTENT_LENGTH_MISMATCH#
Response body size doesn't match with the specified content-length header value.


ERR_HTTP_HEADERS_SENT#
An attempt was made to add more headers after the headers had already been sent.


ERR_HTTP_INVALID_HEADER_VALUE#
An invalid HTTP header value was specified.


ERR_HTTP_INVALID_STATUS_CODE#
Status code was outside the regular status code range (100-999).


ERR_HTTP_REQUEST_TIMEOUT#
The client has not sent the entire request within the allowed time.


ERR_HTTP_SOCKET_ASSIGNED#
The given ServerResponse was already assigned a socket.


ERR_HTTP_SOCKET_ENCODING#
Changing the socket encoding is not allowed per RFC 7230 Section 3.


ERR_HTTP_TRAILER_INVALID#
The Trailer header was set even though the transfer encoding does not support
that.


ERR_ILLEGAL_CONSTRUCTOR#
An attempt was made to construct an object using a non-public constructor.


ERR_IMPORT_ATTRIBUTE_MISSING#

Added in: v21.1.0

An import attribute is missing, preventing the specified module to be imported.


ERR_IMPORT_ATTRIBUTE_TYPE_INCOMPATIBLE#

Added in: v21.1.0

An import type attribute was provided, but the specified module is of a
different type.


ERR_IMPORT_ATTRIBUTE_UNSUPPORTED#

Added in: v21.0.0, v20.10.0, v18.19.0

An import attribute is not supported by this version of Node.js.


ERR_INCOMPATIBLE_OPTION_PAIR#
An option pair is incompatible with each other and cannot be used at the same
time.


ERR_INPUT_TYPE_NOT_ALLOWED#
Stability: 1 - Experimental
The --input-type flag was used to attempt to execute a file. This flag can
only be used with input via --eval, --print, or STDIN.


ERR_INSPECTOR_ALREADY_ACTIVATED#
While using the node:inspector module, an attempt was made to activate the
inspector when it already started to listen on a port. Use inspector.close()
before activating it on a different address.


ERR_INSPECTOR_ALREADY_CONNECTED#
While using the node:inspector module, an attempt was made to connect when the
inspector was already connected.


ERR_INSPECTOR_CLOSED#
While using the node:inspector module, an attempt was made to use the
inspector after the session had already closed.


ERR_INSPECTOR_COMMAND#
An error occurred while issuing a command via the node:inspector module.


ERR_INSPECTOR_NOT_ACTIVE#
The inspector is not active when inspector.waitForDebugger() is called.


ERR_INSPECTOR_NOT_AVAILABLE#
The node:inspector module is not available for use.


ERR_INSPECTOR_NOT_CONNECTED#
While using the node:inspector module, an attempt was made to use the
inspector before it was connected.


ERR_INSPECTOR_NOT_WORKER#
An API was called on the main thread that can only be used from
the worker thread.


ERR_INTERNAL_ASSERTION#
There was a bug in Node.js or incorrect usage of Node.js internals.
To fix the error, open an issue at https://github.com/nodejs/node/issues.


ERR_INVALID_ADDRESS#
The provided address is not understood by the Node.js API.


ERR_INVALID_ADDRESS_FAMILY#
The provided address family is not understood by the Node.js API.


ERR_INVALID_ARG_TYPE#
An argument of the wrong type was passed to a Node.js API.


ERR_INVALID_ARG_VALUE#
An invalid or unsupported value was passed for a given argument.


ERR_INVALID_ASYNC_ID#
An invalid asyncId or triggerAsyncId was passed using AsyncHooks. An id
less than -1 should never happen.


ERR_INVALID_BUFFER_SIZE#
A swap was performed on a Buffer but its size was not compatible with the
operation.


ERR_INVALID_CHAR#
Invalid characters were detected in headers.


ERR_INVALID_CURSOR_POS#
A cursor on a given stream cannot be moved to a specified row without a
specified column.


ERR_INVALID_FD#
A file descriptor ('fd') was not valid (e.g. it was a negative value).


ERR_INVALID_FD_TYPE#
A file descriptor ('fd') type was not valid.


ERR_INVALID_FILE_URL_HOST#
A Node.js API that consumes file: URLs (such as certain functions in the
fs module) encountered a file URL with an incompatible host. This
situation can only occur on Unix-like systems where only localhost or an empty
host is supported.


ERR_INVALID_FILE_URL_PATH#
A Node.js API that consumes file: URLs (such as certain functions in the
fs module) encountered a file URL with an incompatible path. The exact
semantics for determining whether a path can be used is platform-dependent.


ERR_INVALID_HANDLE_TYPE#
An attempt was made to send an unsupported "handle" over an IPC communication
channel to a child process. See subprocess.send() and process.send()
for more information.


ERR_INVALID_HTTP_TOKEN#
An invalid HTTP token was supplied.


ERR_INVALID_IP_ADDRESS#
An IP address is not valid.


ERR_INVALID_MIME_SYNTAX#
The syntax of a MIME is not valid.


ERR_INVALID_MODULE#

Added in: v15.0.0, v14.18.0

An attempt was made to load a module that does not exist or was otherwise not
valid.


ERR_INVALID_MODULE_SPECIFIER#
The imported module string is an invalid URL, package name, or package subpath
specifier.


ERR_INVALID_OBJECT_DEFINE_PROPERTY#
An error occurred while setting an invalid attribute on the property of
an object.


ERR_INVALID_PACKAGE_CONFIG#
An invalid package.json file failed parsing.


ERR_INVALID_PACKAGE_TARGET#
The package.json "exports" field contains an invalid target mapping
value for the attempted module resolution.


ERR_INVALID_PROTOCOL#
An invalid options.protocol was passed to http.request().


ERR_INVALID_REPL_EVAL_CONFIG#
Both breakEvalOnSigint and eval options were set in the REPL config,
which is not supported.


ERR_INVALID_REPL_INPUT#
The input may not be used in the REPL. The conditions under which this
error is used are described in the REPL documentation.


ERR_INVALID_RETURN_PROPERTY#
Thrown in case a function option does not provide a valid value for one of its
returned object properties on execution.


ERR_INVALID_RETURN_PROPERTY_VALUE#
Thrown in case a function option does not provide an expected value
type for one of its returned object properties on execution.


ERR_INVALID_RETURN_VALUE#
Thrown in case a function option does not return an expected value
type on execution, such as when a function is expected to return a promise.


ERR_INVALID_STATE#

Added in: v15.0.0

Indicates that an operation cannot be completed due to an invalid state.
For instance, an object may have already been destroyed, or may be
performing another operation.


ERR_INVALID_SYNC_FORK_INPUT#
A Buffer, TypedArray, DataView, or string was provided as stdio input to
an asynchronous fork. See the documentation for the child_process module
for more information.


ERR_INVALID_THIS#
A Node.js API function was called with an incompatible this value.
const urlSearchParams = new URLSearchParams('foo=bar&baz=new');

const buf = Buffer.alloc(1);
urlSearchParams.has.call(buf, 'foo');
// Throws a TypeError with code 'ERR_INVALID_THIS' copy


ERR_INVALID_TUPLE#
An element in the iterable provided to the WHATWG
URLSearchParams constructor did not
represent a [name, value] tuple – that is, if an element is not iterable, or
does not consist of exactly two elements.


ERR_INVALID_TYPESCRIPT_SYNTAX#

History

VersionChanges
v23.7.0, v22.14.0
This error is no longer thrown on valid yet unsupported syntax.
v23.0.0, v22.10.0
Added in: v23.0.0, v22.10.0



The provided TypeScript syntax is not valid.


ERR_INVALID_URI#
An invalid URI was passed.


ERR_INVALID_URL#
An invalid URL was passed to the WHATWG URL
constructor or the legacy url.parse() to be parsed.
The thrown error object typically has an additional property 'input' that
contains the URL that failed to parse.


ERR_INVALID_URL_PATTERN#
An invalid URLPattern was passed to the WHATWG [URLPattern
constructor][new URLPattern(input)] to be parsed.


ERR_INVALID_URL_SCHEME#
An attempt was made to use a URL of an incompatible scheme (protocol) for a
specific purpose. It is only used in the WHATWG URL API support in the
fs module (which only accepts URLs with 'file' scheme), but may be used
in other Node.js APIs as well in the future.


ERR_IPC_CHANNEL_CLOSED#
An attempt was made to use an IPC communication channel that was already closed.


ERR_IPC_DISCONNECTED#
An attempt was made to disconnect an IPC communication channel that was already
disconnected. See the documentation for the child_process module
for more information.


ERR_IPC_ONE_PIPE#
An attempt was made to create a child Node.js process using more than one IPC
communication channel. See the documentation for the child_process module
for more information.


ERR_IPC_SYNC_FORK#
An attempt was made to open an IPC communication channel with a synchronously
forked Node.js process. See the documentation for the child_process module
for more information.


ERR_IP_BLOCKED#
IP is blocked by net.BlockList.


ERR_LOADER_CHAIN_INCOMPLETE#

Added in: v18.6.0, v16.17.0

An ESM loader hook returned without calling next() and without explicitly
signaling a short circuit.


ERR_LOAD_SQLITE_EXTENSION#

Added in: v23.5.0, v22.13.0

An error occurred while loading a SQLite extension.


ERR_MEMORY_ALLOCATION_FAILED#
An attempt was made to allocate memory (usually in the C++ layer) but it
failed.


ERR_MESSAGE_TARGET_CONTEXT_UNAVAILABLE#

Added in: v14.5.0, v12.19.0

A message posted to a MessagePort could not be deserialized in the target
vm Context. Not all Node.js objects can be successfully instantiated in
any context at this time, and attempting to transfer them using postMessage()
can fail on the receiving side in that case.


ERR_METHOD_NOT_IMPLEMENTED#
A method is required but not implemented.


ERR_MISSING_ARGS#
A required argument of a Node.js API was not passed. This is only used for
strict compliance with the API specification (which in some cases may accept
func(undefined) but not func()). In most native Node.js APIs,
func(undefined) and func() are treated identically, and the
ERR_INVALID_ARG_TYPE error code may be used instead.


ERR_MISSING_OPTION#
For APIs that accept options objects, some options might be mandatory. This code
is thrown if a required option is missing.


ERR_MISSING_PASSPHRASE#
An attempt was made to read an encrypted key without specifying a passphrase.


ERR_MISSING_PLATFORM_FOR_WORKER#
The V8 platform used by this instance of Node.js does not support creating
Workers. This is caused by lack of embedder support for Workers. In particular,
this error will not occur with standard builds of Node.js.


ERR_MODULE_NOT_FOUND#
A module file could not be resolved by the ECMAScript modules loader while
attempting an import operation or when loading the program entry point.


ERR_MULTIPLE_CALLBACK#
A callback was called more than once.
A callback is almost always meant to only be called once as the query
can either be fulfilled or rejected but not both at the same time. The latter
would be possible by calling a callback more than once.


ERR_NAPI_CONS_FUNCTION#
While using Node-API, a constructor passed was not a function.


ERR_NAPI_INVALID_DATAVIEW_ARGS#
While calling napi_create_dataview(), a given offset was outside the bounds
of the dataview or offset + length was larger than a length of given buffer.


ERR_NAPI_INVALID_TYPEDARRAY_ALIGNMENT#
While calling napi_create_typedarray(), the provided offset was not a
multiple of the element size.


ERR_NAPI_INVALID_TYPEDARRAY_LENGTH#
While calling napi_create_typedarray(), (length * size_of_element) + byte_offset was larger than the length of given buffer.


ERR_NAPI_TSFN_CALL_JS#
An error occurred while invoking the JavaScript portion of the thread-safe
function.


ERR_NAPI_TSFN_GET_UNDEFINED#
An error occurred while attempting to retrieve the JavaScript undefined
value.


ERR_NON_CONTEXT_AWARE_DISABLED#
A non-context-aware native addon was loaded in a process that disallows them.


ERR_NOT_BUILDING_SNAPSHOT#
An attempt was made to use operations that can only be used when building
V8 startup snapshot even though Node.js isn't building one.


ERR_NOT_IN_SINGLE_EXECUTABLE_APPLICATION#

Added in: v21.7.0, v20.12.0

The operation cannot be performed when it's not in a single-executable
application.


ERR_NOT_SUPPORTED_IN_SNAPSHOT#
An attempt was made to perform operations that are not supported when
building a startup snapshot.


ERR_NO_CRYPTO#
An attempt was made to use crypto features while Node.js was not compiled with
OpenSSL crypto support.


ERR_NO_ICU#
An attempt was made to use features that require ICU, but Node.js was not
compiled with ICU support.


ERR_NO_TYPESCRIPT#

Added in: v23.0.0, v22.12.0

An attempt was made to use features that require Native TypeScript support, but Node.js was not
compiled with TypeScript support.


ERR_OPERATION_FAILED#

Added in: v15.0.0

An operation failed. This is typically used to signal the general failure
of an asynchronous operation.


ERR_OPTIONS_BEFORE_BOOTSTRAPPING#

Added in: v23.10.0

An attempt was made to get options before the bootstrapping was completed.


ERR_OUT_OF_RANGE#
A given value is out of the accepted range.


ERR_PACKAGE_IMPORT_NOT_DEFINED#
The package.json "imports" field does not define the given internal
package specifier mapping.


ERR_PACKAGE_PATH_NOT_EXPORTED#
The package.json "exports" field does not export the requested subpath.
Because exports are encapsulated, private internal modules that are not exported
cannot be imported through the package resolution, unless using an absolute URL.


ERR_PARSE_ARGS_INVALID_OPTION_VALUE#

Added in: v18.3.0, v16.17.0

When strict set to true, thrown by util.parseArgs() if a <boolean>
value is provided for an option of type <string>, or if a <string>
value is provided for an option of type <boolean>.


ERR_PARSE_ARGS_UNEXPECTED_POSITIONAL#

Added in: v18.3.0, v16.17.0

Thrown by util.parseArgs(), when a positional argument is provided and
allowPositionals is set to false.


ERR_PARSE_ARGS_UNKNOWN_OPTION#

Added in: v18.3.0, v16.17.0

When strict set to true, thrown by util.parseArgs() if an argument
is not configured in options.


ERR_PERFORMANCE_INVALID_TIMESTAMP#
An invalid timestamp value was provided for a performance mark or measure.


ERR_PERFORMANCE_MEASURE_INVALID_OPTIONS#
Invalid options were provided for a performance measure.


ERR_PROTO_ACCESS#
Accessing Object.prototype.__proto__ has been forbidden using
--disable-proto=throw. Object.getPrototypeOf and
Object.setPrototypeOf should be used to get and set the prototype of an
object.


ERR_QUIC_APPLICATION_ERROR#

Added in: v23.4.0, v22.13.0

Stability: 1 - Experimental
A QUIC application error occurred.


ERR_QUIC_CONNECTION_FAILED#

Added in: v23.0.0, v22.10.0

Stability: 1 - Experimental
Establishing a QUIC connection failed.


ERR_QUIC_ENDPOINT_CLOSED#

Added in: v23.0.0, v22.10.0

Stability: 1 - Experimental
A QUIC Endpoint closed with an error.


ERR_QUIC_OPEN_STREAM_FAILED#

Added in: v23.0.0, v22.10.0

Stability: 1 - Experimental
Opening a QUIC stream failed.


ERR_QUIC_TRANSPORT_ERROR#

Added in: v23.4.0, v22.13.0

Stability: 1 - Experimental
A QUIC transport error occurred.


ERR_QUIC_VERSION_NEGOTIATION_ERROR#

Added in: v23.4.0, v22.13.0

Stability: 1 - Experimental
A QUIC session failed because version negotiation is required.


ERR_REQUIRE_ASYNC_MODULE#
Stability: 1 - Experimental
When trying to require() a ES Module, the module turns out to be asynchronous.
That is, it contains top-level await.
To see where the top-level await is, use
--experimental-print-required-tla (this would execute the modules
before looking for the top-level awaits).


ERR_REQUIRE_CYCLE_MODULE#
Stability: 1 - Experimental
When trying to require() a ES Module, a CommonJS to ESM or ESM to CommonJS edge
participates in an immediate cycle.
This is not allowed because ES Modules cannot be evaluated while they are
already being evaluated.
To avoid the cycle, the require() call involved in a cycle should not happen
at the top-level of either an ES Module (via createRequire()) or a CommonJS
module, and should be done lazily in an inner function.


ERR_REQUIRE_ESM#

History

VersionChanges
v23.0.0, v22.12.0, v20.19.0
require() now supports loading synchronous ES modules by default.



Stability: 0 - Deprecated
An attempt was made to require() an ES Module.
This error has been deprecated since require() now supports loading synchronous
ES modules. When require() encounters an ES module that contains top-level
await, it will throw ERR_REQUIRE_ASYNC_MODULE instead.


ERR_SCRIPT_EXECUTION_INTERRUPTED#
Script execution was interrupted by SIGINT (For
example, Ctrl+C was pressed.)


ERR_SCRIPT_EXECUTION_TIMEOUT#
Script execution timed out, possibly due to bugs in the script being executed.


ERR_SERVER_ALREADY_LISTEN#
The server.listen() method was called while a net.Server was already
listening. This applies to all instances of net.Server, including HTTP, HTTPS,
and HTTP/2 Server instances.


ERR_SERVER_NOT_RUNNING#
The server.close() method was called when a net.Server was not
running. This applies to all instances of net.Server, including HTTP, HTTPS,
and HTTP/2 Server instances.


ERR_SINGLE_EXECUTABLE_APPLICATION_ASSET_NOT_FOUND#

Added in: v21.7.0, v20.12.0

A key was passed to single executable application APIs to identify an asset,
but no match could be found.


ERR_SOCKET_ALREADY_BOUND#
An attempt was made to bind a socket that has already been bound.


ERR_SOCKET_BAD_BUFFER_SIZE#
An invalid (negative) size was passed for either the recvBufferSize or
sendBufferSize options in dgram.createSocket().


ERR_SOCKET_BAD_PORT#
An API function expecting a port >= 0 and < 65536 received an invalid value.


ERR_SOCKET_BAD_TYPE#
An API function expecting a socket type (udp4 or udp6) received an invalid
value.


ERR_SOCKET_BUFFER_SIZE#
While using dgram.createSocket(), the size of the receive or send Buffer
could not be determined.


ERR_SOCKET_CLOSED#
An attempt was made to operate on an already closed socket.


ERR_SOCKET_CLOSED_BEFORE_CONNECTION#
When calling net.Socket.write() on a connecting socket and the socket was
closed before the connection was established.


ERR_SOCKET_CONNECTION_TIMEOUT#
The socket was unable to connect to any address returned by the DNS within the
allowed timeout when using the family autoselection algorithm.


ERR_SOCKET_DGRAM_IS_CONNECTED#
A dgram.connect() call was made on an already connected socket.


ERR_SOCKET_DGRAM_NOT_CONNECTED#
A dgram.disconnect() or dgram.remoteAddress() call was made on a
disconnected socket.


ERR_SOCKET_DGRAM_NOT_RUNNING#
A call was made and the UDP subsystem was not running.


ERR_SOURCE_MAP_CORRUPT#
The source map could not be parsed because it does not exist, or is corrupt.


ERR_SOURCE_MAP_MISSING_SOURCE#
A file imported from a source map was not found.


ERR_SOURCE_PHASE_NOT_DEFINED#

Added in: v24.0.0

The provided module import does not provide a source phase imports representation for source phase
import syntax import source x from 'x' or import.source(x).


ERR_SQLITE_ERROR#

Added in: v22.5.0

An error was returned from SQLite.


ERR_SRI_PARSE#
A string was provided for a Subresource Integrity check, but was unable to be
parsed. Check the format of integrity attributes by looking at the
Subresource Integrity specification.


ERR_STREAM_ALREADY_FINISHED#
A stream method was called that cannot complete because the stream was
finished.


ERR_STREAM_CANNOT_PIPE#
An attempt was made to call stream.pipe() on a Writable stream.


ERR_STREAM_DESTROYED#
A stream method was called that cannot complete because the stream was
destroyed using stream.destroy().


ERR_STREAM_NULL_VALUES#
An attempt was made to call stream.write() with a null chunk.


ERR_STREAM_PREMATURE_CLOSE#
An error returned by stream.finished() and stream.pipeline(), when a stream
or a pipeline ends non gracefully with no explicit error.


ERR_STREAM_PUSH_AFTER_EOF#
An attempt was made to call stream.push() after a null(EOF) had been
pushed to the stream.


ERR_STREAM_UNABLE_TO_PIPE#
An attempt was made to pipe to a closed or destroyed stream in a pipeline.


ERR_STREAM_UNSHIFT_AFTER_END_EVENT#
An attempt was made to call stream.unshift() after the 'end' event was
emitted.


ERR_STREAM_WRAP#
Prevents an abort if a string decoder was set on the Socket or if the decoder
is in objectMode.
const Socket = require('node:net').Socket;
const instance = new Socket();

instance.setEncoding('utf8'); copy


ERR_STREAM_WRITE_AFTER_END#
An attempt was made to call stream.write() after stream.end() has been
called.


ERR_STRING_TOO_LONG#
An attempt has been made to create a string longer than the maximum allowed
length.


ERR_SYNTHETIC#
An artificial error object used to capture the call stack for diagnostic
reports.


ERR_SYSTEM_ERROR#
An unspecified or non-specific system error has occurred within the Node.js
process. The error object will have an err.info object property with
additional details.


ERR_TEST_FAILURE#
This error represents a failed test. Additional information about the failure
is available via the cause property. The failureType property specifies
what the test was doing when the failure occurred.


ERR_TLS_ALPN_CALLBACK_INVALID_RESULT#
This error is thrown when an ALPNCallback returns a value that is not in the
list of ALPN protocols offered by the client.


ERR_TLS_ALPN_CALLBACK_WITH_PROTOCOLS#
This error is thrown when creating a TLSServer if the TLS options include
both ALPNProtocols and ALPNCallback. These options are mutually exclusive.


ERR_TLS_CERT_ALTNAME_FORMAT#
This error is thrown by checkServerIdentity if a user-supplied
subjectaltname property violates encoding rules. Certificate objects produced
by Node.js itself always comply with encoding rules and will never cause
this error.


ERR_TLS_CERT_ALTNAME_INVALID#
While using TLS, the host name/IP of the peer did not match any of the
subjectAltNames in its certificate.


ERR_TLS_DH_PARAM_SIZE#
While using TLS, the parameter offered for the Diffie-Hellman (DH)
key-agreement protocol is too small. By default, the key length must be greater
than or equal to 1024 bits to avoid vulnerabilities, even though it is strongly
recommended to use 2048 bits or larger for stronger security.


ERR_TLS_HANDSHAKE_TIMEOUT#
A TLS/SSL handshake timed out. In this case, the server must also abort the
connection.


ERR_TLS_INVALID_CONTEXT#

Added in: v13.3.0

The context must be a SecureContext.


ERR_TLS_INVALID_PROTOCOL_METHOD#
The specified  secureProtocol method is invalid. It is  either unknown, or
disabled because it is insecure.


ERR_TLS_INVALID_PROTOCOL_VERSION#
Valid TLS protocol versions are 'TLSv1', 'TLSv1.1', or 'TLSv1.2'.


ERR_TLS_INVALID_STATE#

Added in: v13.10.0, v12.17.0

The TLS socket must be connected and securely established. Ensure the 'secure'
event is emitted before continuing.


ERR_TLS_PROTOCOL_VERSION_CONFLICT#
Attempting to set a TLS protocol minVersion or maxVersion conflicts with an
attempt to set the secureProtocol explicitly. Use one mechanism or the other.


ERR_TLS_PSK_SET_IDENTITY_HINT_FAILED#
Failed to set PSK identity hint. Hint may be too long.


ERR_TLS_RENEGOTIATION_DISABLED#
An attempt was made to renegotiate TLS on a socket instance with renegotiation
disabled.


ERR_TLS_REQUIRED_SERVER_NAME#
While using TLS, the server.addContext() method was called without providing
a host name in the first parameter.


ERR_TLS_SESSION_ATTACK#
An excessive amount of TLS renegotiations is detected, which is a potential
vector for denial-of-service attacks.


ERR_TLS_SNI_FROM_SERVER#
An attempt was made to issue Server Name Indication from a TLS server-side
socket, which is only valid from a client.


ERR_TRACE_EVENTS_CATEGORY_REQUIRED#
The trace_events.createTracing() method requires at least one trace event
category.


ERR_TRACE_EVENTS_UNAVAILABLE#
The node:trace_events module could not be loaded because Node.js was compiled
with the --without-v8-platform flag.


ERR_TRANSFORM_ALREADY_TRANSFORMING#
A Transform stream finished while it was still transforming.


ERR_TRANSFORM_WITH_LENGTH_0#
A Transform stream finished with data still in the write buffer.


ERR_TTY_INIT_FAILED#
The initialization of a TTY failed due to a system error.


ERR_UNAVAILABLE_DURING_EXIT#
Function was called within a process.on('exit') handler that shouldn't be
called within process.on('exit') handler.


ERR_UNCAUGHT_EXCEPTION_CAPTURE_ALREADY_SET#
process.setUncaughtExceptionCaptureCallback() was called twice,
without first resetting the callback to null.
This error is designed to prevent accidentally overwriting a callback registered
from another module.


ERR_UNESCAPED_CHARACTERS#
A string that contained unescaped characters was received.


ERR_UNHANDLED_ERROR#
An unhandled error occurred (for instance, when an 'error' event is emitted
by an EventEmitter but an 'error' handler is not registered).


ERR_UNKNOWN_BUILTIN_MODULE#
Used to identify a specific kind of internal Node.js error that should not
typically be triggered by user code. Instances of this error point to an
internal bug within the Node.js binary itself.


ERR_UNKNOWN_CREDENTIAL#
A Unix group or user identifier that does not exist was passed.


ERR_UNKNOWN_ENCODING#
An invalid or unknown encoding option was passed to an API.


ERR_UNKNOWN_FILE_EXTENSION#
Stability: 1 - Experimental
An attempt was made to load a module with an unknown or unsupported file
extension.


ERR_UNKNOWN_MODULE_FORMAT#
Stability: 1 - Experimental
An attempt was made to load a module with an unknown or unsupported format.


ERR_UNKNOWN_SIGNAL#
An invalid or unknown process signal was passed to an API expecting a valid
signal (such as subprocess.kill()).


ERR_UNSUPPORTED_DIR_IMPORT#
import a directory URL is unsupported. Instead,
self-reference a package using its name and define a custom subpath in
the "exports" field of the package.json file.
import './'; // unsupported
import './index.js'; // supported
import 'package-name'; // supported copy


ERR_UNSUPPORTED_ESM_URL_SCHEME#
import with URL schemes other than file and data is unsupported.


ERR_UNSUPPORTED_NODE_MODULES_TYPE_STRIPPING#

Added in: v22.6.0

Type stripping is not supported for files descendent of a node_modules directory.


ERR_UNSUPPORTED_RESOLVE_REQUEST#
An attempt was made to resolve an invalid module referrer. This can happen when
importing or calling import.meta.resolve() with either:

a bare specifier that is not a builtin module from a module whose URL scheme
is not file.
a relative URL from a module whose URL scheme is not a special scheme.

try {
  // Trying to import the package 'bare-specifier' from a `data:` URL module:
  await import('data:text/javascript,import "bare-specifier"');
} catch (e) {
  console.log(e.code); // ERR_UNSUPPORTED_RESOLVE_REQUEST
} copy


ERR_UNSUPPORTED_TYPESCRIPT_SYNTAX#

Added in: v23.7.0, v22.14.0

The provided TypeScript syntax is unsupported.
This could happen when using TypeScript syntax that requires
transformation with type-stripping.


ERR_USE_AFTER_CLOSE#
Stability: 1 - Experimental
An attempt was made to use something that was already closed.


ERR_VALID_PERFORMANCE_ENTRY_TYPE#
While using the Performance Timing API (perf_hooks), no valid performance
entry types are found.


ERR_VM_DYNAMIC_IMPORT_CALLBACK_MISSING#
A dynamic import callback was not specified.


ERR_VM_DYNAMIC_IMPORT_CALLBACK_MISSING_FLAG#
A dynamic import callback was invoked without --experimental-vm-modules.


ERR_VM_MODULE_ALREADY_LINKED#
The module attempted to be linked is not eligible for linking, because of one of
the following reasons:

It has already been linked (linkingStatus is 'linked')
It is being linked (linkingStatus is 'linking')
Linking has failed for this module (linkingStatus is 'errored')



ERR_VM_MODULE_CACHED_DATA_REJECTED#
The cachedData option passed to a module constructor is invalid.


ERR_VM_MODULE_CANNOT_CREATE_CACHED_DATA#
Cached data cannot be created for modules which have already been evaluated.


ERR_VM_MODULE_DIFFERENT_CONTEXT#
The module being returned from the linker function is from a different context
than the parent module. Linked modules must share the same context.


ERR_VM_MODULE_LINK_FAILURE#
The module was unable to be linked due to a failure.


ERR_VM_MODULE_NOT_MODULE#
The fulfilled value of a linking promise is not a vm.Module object.


ERR_VM_MODULE_STATUS#
The current module's status does not allow for this operation. The specific
meaning of the error depends on the specific function.


ERR_WASI_ALREADY_STARTED#
The WASI instance has already started.


ERR_WASI_NOT_STARTED#
The WASI instance has not been started.


ERR_WEBASSEMBLY_RESPONSE#

Added in: v18.1.0

The Response that has been passed to WebAssembly.compileStreaming or to
WebAssembly.instantiateStreaming is not a valid WebAssembly response.


ERR_WORKER_INIT_FAILED#
The Worker initialization failed.


ERR_WORKER_INVALID_EXEC_ARGV#
The execArgv option passed to the Worker constructor contains
invalid flags.


ERR_WORKER_MESSAGING_ERRORED#

Added in: v22.5.0

Stability: 1.1 - Active development
The destination thread threw an error while processing a message sent via postMessageToThread().


ERR_WORKER_MESSAGING_FAILED#

Added in: v22.5.0

Stability: 1.1 - Active development
The thread requested in postMessageToThread() is invalid or has no workerMessage listener.


ERR_WORKER_MESSAGING_SAME_THREAD#

Added in: v22.5.0

Stability: 1.1 - Active development
The thread id requested in postMessageToThread() is the current thread id.


ERR_WORKER_MESSAGING_TIMEOUT#

Added in: v22.5.0

Stability: 1.1 - Active development
Sending a message via postMessageToThread() timed out.


ERR_WORKER_NOT_RUNNING#
An operation failed because the Worker instance is not currently running.


ERR_WORKER_OUT_OF_MEMORY#
The Worker instance terminated because it reached its memory limit.


ERR_WORKER_PATH#
The path for the main script of a worker is neither an absolute path
nor a relative path starting with ./ or ../.


ERR_WORKER_UNSERIALIZABLE_ERROR#
All attempts at serializing an uncaught exception from a worker thread failed.


ERR_WORKER_UNSUPPORTED_OPERATION#
The requested functionality is not supported in worker threads.


ERR_ZLIB_INITIALIZATION_FAILED#
Creation of a zlib object failed due to incorrect configuration.


ERR_ZSTD_INVALID_PARAM#
An invalid parameter key was passed during construction of a Zstd stream.


HPE_CHUNK_EXTENSIONS_OVERFLOW#

Added in: v21.6.2, v20.11.1, v18.19.1

Too much data was received for a chunk extensions. In order to protect against
malicious or malconfigured clients, if more than 16 KiB of data is received
then an Error with this code will be emitted.


HPE_HEADER_OVERFLOW#

History

VersionChanges
v11.4.0, v10.15.0
Max header size in http_parser was set to 8 KiB.



Too much HTTP header data was received. In order to protect against malicious or
malconfigured clients, if more than maxHeaderSize of HTTP header data is received then
HTTP parsing will abort without a request or response object being created, and
an Error with this code will be emitted.


HPE_UNEXPECTED_CONTENT_LENGTH#
Server is sending both a Content-Length header and Transfer-Encoding: chunked.
Transfer-Encoding: chunked allows the server to maintain an HTTP persistent
connection for dynamically generated content.
In this case, the Content-Length HTTP header cannot be used.
Use Content-Length or Transfer-Encoding: chunked.


MODULE_NOT_FOUND#

History

VersionChanges
v12.0.0
Added requireStack property.



A module file could not be resolved by the CommonJS modules loader while
attempting a require() operation or when loading the program entry point.

Legacy Node.js error codes#
Stability: 0 - Deprecated. These error codes are either inconsistent, or have
been removed.


ERR_CANNOT_TRANSFER_OBJECT#

Added in: v10.5.0Removed in: v12.5.0

The value passed to postMessage() contained an object that is not supported
for transferring.


ERR_CPU_USAGE#

Removed in: v15.0.0

The native call from process.cpuUsage could not be processed.


ERR_CRYPTO_HASH_DIGEST_NO_UTF16#

Added in: v9.0.0Removed in: v12.12.0

The UTF-16 encoding was used with hash.digest(). While the
hash.digest() method does allow an encoding argument to be passed in,
causing the method to return a string rather than a Buffer, the UTF-16
encoding (e.g. ucs or utf16le) is not supported.


ERR_CRYPTO_SCRYPT_INVALID_PARAMETER#

Removed in: v23.0.0

An incompatible combination of options was passed to crypto.scrypt() or
crypto.scryptSync(). New versions of Node.js use the error code
ERR_INCOMPATIBLE_OPTION_PAIR instead, which is consistent with other APIs.


ERR_FS_INVALID_SYMLINK_TYPE#

Removed in: v23.0.0

An invalid symlink type was passed to the fs.symlink() or
fs.symlinkSync() methods.


ERR_HTTP2_FRAME_ERROR#

Added in: v9.0.0Removed in: v10.0.0

Used when a failure occurs sending an individual frame on the HTTP/2
session.


ERR_HTTP2_HEADERS_OBJECT#

Added in: v9.0.0Removed in: v10.0.0

Used when an HTTP/2 Headers Object is expected.


ERR_HTTP2_HEADER_REQUIRED#

Added in: v9.0.0Removed in: v10.0.0

Used when a required header is missing in an HTTP/2 message.


ERR_HTTP2_INFO_HEADERS_AFTER_RESPOND#

Added in: v9.0.0Removed in: v10.0.0

HTTP/2 informational headers must only be sent prior to calling the
Http2Stream.prototype.respond() method.


ERR_HTTP2_STREAM_CLOSED#

Added in: v9.0.0Removed in: v10.0.0

Used when an action has been performed on an HTTP/2 Stream that has already
been closed.


ERR_HTTP_INVALID_CHAR#

Added in: v9.0.0Removed in: v10.0.0

Used when an invalid character is found in an HTTP response status message
(reason phrase).


ERR_IMPORT_ASSERTION_TYPE_FAILED#

Added in: v17.1.0, v16.14.0Removed in: v21.1.0

An import assertion has failed, preventing the specified module to be imported.


ERR_IMPORT_ASSERTION_TYPE_MISSING#

Added in: v17.1.0, v16.14.0Removed in: v21.1.0

An import assertion is missing, preventing the specified module to be imported.


ERR_IMPORT_ASSERTION_TYPE_UNSUPPORTED#

Added in: v17.1.0, v16.14.0Removed in: v21.1.0

An import attribute is not supported by this version of Node.js.


ERR_INDEX_OUT_OF_RANGE#

Added in: v10.0.0Removed in: v11.0.0

A given index was out of the accepted range (e.g. negative offsets).


ERR_INVALID_OPT_VALUE#

Added in: v8.0.0Removed in: v15.0.0

An invalid or unexpected value was passed in an options object.


ERR_INVALID_OPT_VALUE_ENCODING#

Added in: v9.0.0Removed in: v15.0.0

An invalid or unknown file encoding was passed.


ERR_INVALID_PERFORMANCE_MARK#

Added in: v8.5.0Removed in: v16.7.0

While using the Performance Timing API (perf_hooks), a performance mark is
invalid.


ERR_INVALID_TRANSFER_OBJECT#

History

VersionChanges
v21.0.0
A DOMException is thrown instead.
v21.0.0
Removed in: v21.0.0



An invalid transfer object was passed to postMessage().


ERR_MANIFEST_ASSERT_INTEGRITY#

Removed in: v22.2.0

An attempt was made to load a resource, but the resource did not match the
integrity defined by the policy manifest. See the documentation for policy
manifests for more information.


ERR_MANIFEST_DEPENDENCY_MISSING#

Removed in: v22.2.0

An attempt was made to load a resource, but the resource was not listed as a
dependency from the location that attempted to load it. See the documentation
for policy manifests for more information.


ERR_MANIFEST_INTEGRITY_MISMATCH#

Removed in: v22.2.0

An attempt was made to load a policy manifest, but the manifest had multiple
entries for a resource which did not match each other. Update the manifest
entries to match in order to resolve this error. See the documentation for
policy manifests for more information.


ERR_MANIFEST_INVALID_RESOURCE_FIELD#

Removed in: v22.2.0

A policy manifest resource had an invalid value for one of its fields. Update
the manifest entry to match in order to resolve this error. See the
documentation for policy manifests for more information.


ERR_MANIFEST_INVALID_SPECIFIER#

Removed in: v22.2.0

A policy manifest resource had an invalid value for one of its dependency
mappings. Update the manifest entry to match to resolve this error. See the
documentation for policy manifests for more information.


ERR_MANIFEST_PARSE_POLICY#

Removed in: v22.2.0

An attempt was made to load a policy manifest, but the manifest was unable to
be parsed. See the documentation for policy manifests for more information.


ERR_MANIFEST_TDZ#

Removed in: v22.2.0

An attempt was made to read from a policy manifest, but the manifest
initialization has not yet taken place. This is likely a bug in Node.js.


ERR_MANIFEST_UNKNOWN_ONERROR#

Removed in: v22.2.0

A policy manifest was loaded, but had an unknown value for its "onerror"
behavior. See the documentation for policy manifests for more information.


ERR_MISSING_MESSAGE_PORT_IN_TRANSFER_LIST#

Removed in: v15.0.0

This error code was replaced by ERR_MISSING_TRANSFERABLE_IN_TRANSFER_LIST
in Node.js v15.0.0, because it is no longer accurate as other types of
transferable objects also exist now.


ERR_MISSING_TRANSFERABLE_IN_TRANSFER_LIST#

History

VersionChanges
v21.0.0
A DOMException is thrown instead.
v21.0.0
Removed in: v21.0.0
v15.0.0
Added in: v15.0.0



An object that needs to be explicitly listed in the transferList argument
is in the object passed to a postMessage() call, but is not provided
in the transferList for that call. Usually, this is a MessagePort.
In Node.js versions prior to v15.0.0, the error code being used here was
ERR_MISSING_MESSAGE_PORT_IN_TRANSFER_LIST. However, the set of
transferable object types has been expanded to cover more types than
MessagePort.


ERR_NAPI_CONS_PROTOTYPE_OBJECT#

Added in: v9.0.0Removed in: v10.0.0

Used by the Node-API when Constructor.prototype is not an object.


ERR_NAPI_TSFN_START_IDLE_LOOP#

Added in: v10.6.0, v8.16.0Removed in: v14.2.0, v12.17.0

On the main thread, values are removed from the queue associated with the
thread-safe function in an idle loop. This error indicates that an error
has occurred when attempting to start the loop.


ERR_NAPI_TSFN_STOP_IDLE_LOOP#

Added in: v10.6.0, v8.16.0Removed in: v14.2.0, v12.17.0

Once no more items are left in the queue, the idle loop must be suspended. This
error indicates that the idle loop has failed to stop.


ERR_NO_LONGER_SUPPORTED#
A Node.js API was called in an unsupported manner, such as
Buffer.write(string, encoding, offset[, length]).


ERR_OUTOFMEMORY#

Added in: v9.0.0Removed in: v10.0.0

Used generically to identify that an operation caused an out of memory
condition.


ERR_PARSE_HISTORY_DATA#

Added in: v9.0.0Removed in: v10.0.0

The node:repl module was unable to parse data from the REPL history file.


ERR_SOCKET_CANNOT_SEND#

Added in: v9.0.0Removed in: v14.0.0

Data could not be sent on a socket.


ERR_STDERR_CLOSE#

History

VersionChanges
v10.12.0
Rather than emitting an error, process.stderr.end() now only closes the stream side but not the underlying resource, making this error obsolete.
v10.12.0
Removed in: v10.12.0



An attempt was made to close the process.stderr stream. By design, Node.js
does not allow stdout or stderr streams to be closed by user code.


ERR_STDOUT_CLOSE#

History

VersionChanges
v10.12.0
Rather than emitting an error, process.stderr.end() now only closes the stream side but not the underlying resource, making this error obsolete.
v10.12.0
Removed in: v10.12.0



An attempt was made to close the process.stdout stream. By design, Node.js
does not allow stdout or stderr streams to be closed by user code.


ERR_STREAM_READ_NOT_IMPLEMENTED#

Added in: v9.0.0Removed in: v10.0.0

Used when an attempt is made to use a readable stream that has not implemented
readable._read().


ERR_TAP_LEXER_ERROR#
An error representing a failing lexer state.


ERR_TAP_PARSER_ERROR#
An error representing a failing parser state. Additional information about
the token causing the error is available via the cause property.


ERR_TAP_VALIDATION_ERROR#
This error represents a failed TAP validation.


ERR_TLS_RENEGOTIATION_FAILED#

Added in: v9.0.0Removed in: v10.0.0

Used when a TLS renegotiation request has failed in a non-specific way.


ERR_TRANSFERRING_EXTERNALIZED_SHAREDARRAYBUFFER#

Added in: v10.5.0Removed in: v14.0.0

A SharedArrayBuffer whose memory is not managed by the JavaScript engine
or by Node.js was encountered during serialization. Such a SharedArrayBuffer
cannot be serialized.
This can only happen when native addons create SharedArrayBuffers in
"externalized" mode, or put existing SharedArrayBuffer into externalized mode.


ERR_UNKNOWN_STDIN_TYPE#

Added in: v8.0.0Removed in: v11.7.0

An attempt was made to launch a Node.js process with an unknown stdin file
type. This error is usually an indication of a bug within Node.js itself,
although it is possible for user code to trigger it.


ERR_UNKNOWN_STREAM_TYPE#

Added in: v8.0.0Removed in: v11.7.0

An attempt was made to launch a Node.js process with an unknown stdout or
stderr file type. This error is usually an indication of a bug within Node.js
itself, although it is possible for user code to trigger it.


ERR_V8BREAKITERATOR#
The V8 BreakIterator API was used but the full ICU data set is not installed.


ERR_VALUE_OUT_OF_RANGE#

Added in: v9.0.0Removed in: v10.0.0

Used when a given value is out of the accepted range.


ERR_VM_MODULE_LINKING_ERRORED#

Added in: v10.0.0Removed in: v18.1.0, v16.17.0

The linker function returned a module for which linking has failed.


ERR_VM_MODULE_NOT_LINKED#
The module must be successfully linked before instantiation.


ERR_WORKER_UNSUPPORTED_EXTENSION#

Added in: v11.0.0Removed in: v16.9.0

The pathname used for the main script of a worker has an
unknown file extension.


ERR_ZLIB_BINDING_CLOSED#

Added in: v9.0.0Removed in: v10.0.0

Used when an attempt is made to use a zlib object after it has already been
closed.


OpenSSL Error Codes#


Time Validity Errors#


CERT_NOT_YET_VALID#
The certificate is not yet valid: the notBefore date is after the current time.


CERT_HAS_EXPIRED#
The certificate has expired: the notAfter date is before the current time.


CRL_NOT_YET_VALID#
The certificate revocation list (CRL) has a future issue date.


CRL_HAS_EXPIRED#
The certificate revocation list (CRL) has expired.


CERT_REVOKED#
The certificate has been revoked; it is on a certificate revocation list (CRL).


Trust or Chain Related Errors#


UNABLE_TO_GET_ISSUER_CERT#
The issuer certificate of a looked up certificate could not be found. This
normally means the list of trusted certificates is not complete.


UNABLE_TO_GET_ISSUER_CERT_LOCALLY#
The certificate’s issuer is not known. This is the case if the issuer is not
included in the trusted certificate list.


DEPTH_ZERO_SELF_SIGNED_CERT#
The passed certificate is self-signed and the same certificate cannot be found
in the list of trusted certificates.


SELF_SIGNED_CERT_IN_CHAIN#
The certificate’s issuer is not known. This is the case if the issuer is not
included in the trusted certificate list.


CERT_CHAIN_TOO_LONG#
The certificate chain length is greater than the maximum depth.


UNABLE_TO_GET_CRL#
The CRL reference by the certificate could not be found.


UNABLE_TO_VERIFY_LEAF_SIGNATURE#
No signatures could be verified because the chain contains only one certificate
and it is not self signed.


CERT_UNTRUSTED#
The root certificate authority (CA) is not marked as trusted for the specified
purpose.


Basic Extension Errors#


INVALID_CA#
A CA certificate is invalid. Either it is not a CA or its extensions are not
consistent with the supplied purpose.


PATH_LENGTH_EXCEEDED#
The basicConstraints pathlength parameter has been exceeded.


Name Related Errors#


HOSTNAME_MISMATCH#
Certificate does not match provided name.


Usage and Policy Errors#


INVALID_PURPOSE#
The supplied certificate cannot be used for the specified purpose.


CERT_REJECTED#
The root CA is marked to reject the specified purpose.


Formatting Errors#


CERT_SIGNATURE_FAILURE#
The signature of the certificate is invalid.


CRL_SIGNATURE_FAILURE#
The signature of the certificate revocation list (CRL) is invalid.


ERROR_IN_CERT_NOT_BEFORE_FIELD#
The certificate notBefore field contains an invalid time.


ERROR_IN_CERT_NOT_AFTER_FIELD#
The certificate notAfter field contains an invalid time.


ERROR_IN_CRL_LAST_UPDATE_FIELD#
The CRL lastUpdate field contains an invalid time.


ERROR_IN_CRL_NEXT_UPDATE_FIELD#
The CRL nextUpdate field contains an invalid time.


UNABLE_TO_DECRYPT_CERT_SIGNATURE#
The certificate signature could not be decrypted. This means that the actual
signature value could not be determined rather than it not matching the expected
value, this is only meaningful for RSA keys.


UNABLE_TO_DECRYPT_CRL_SIGNATURE#
The certificate revocation list (CRL) signature could not be decrypted: this
means that the actual signature value could not be determined rather than it not
matching the expected value.


UNABLE_TO_DECODE_ISSUER_PUBLIC_KEY#
The public key in the certificate SubjectPublicKeyInfo could not be read.


Other OpenSSL Errors#


OUT_OF_MEM#
An error occurred trying to allocate memory. This should never happen.\n\n\n\nNode.js
        
      
      
About this documentation
Usage and example



Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Modules: TypeScript
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
Readline
REPL
Report
Single executable applications
SQLite
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker

    

    
      
        
          Node.js v24.0.1 documentation
          
            
            
          
        
        
          
            Node.js v24.0.1
            
    
      
        
        Table of contents
      

      
Events

Passing arguments and this to listeners
Asynchronous vs. synchronous
Handling events only once
Error events
Capture rejections of promises
Class: EventEmitter

Event: 'newListener'
Event: 'removeListener'
emitter.addListener(eventName, listener)
emitter.emit(eventName[, ...args])
emitter.eventNames()
emitter.getMaxListeners()
emitter.listenerCount(eventName[, listener])
emitter.listeners(eventName)
emitter.off(eventName, listener)
emitter.on(eventName, listener)
emitter.once(eventName, listener)
emitter.prependListener(eventName, listener)
emitter.prependOnceListener(eventName, listener)
emitter.removeAllListeners([eventName])
emitter.removeListener(eventName, listener)
emitter.setMaxListeners(n)
emitter.rawListeners(eventName)
emitter[Symbol.for('nodejs.rejection')](err, eventName[, ...args])


events.defaultMaxListeners
events.errorMonitor
events.getEventListeners(emitterOrTarget, eventName)
events.getMaxListeners(emitterOrTarget)
events.once(emitter, name[, options])

Awaiting multiple events emitted on process.nextTick()


events.captureRejections
events.captureRejectionSymbol
events.listenerCount(emitter, eventName)
events.on(emitter, eventName[, options])
events.setMaxListeners(n[, ...eventTargets])
events.addAbortListener(signal, listener)
Class: events.EventEmitterAsyncResource extends EventEmitter

new events.EventEmitterAsyncResource([options])
eventemitterasyncresource.asyncId
eventemitterasyncresource.asyncResource
eventemitterasyncresource.emitDestroy()
eventemitterasyncresource.triggerAsyncId


EventTarget and Event API

Node.js EventTarget vs. DOM EventTarget
NodeEventTarget vs. EventEmitter
Event listener
EventTarget error handling
Class: Event

event.bubbles
event.cancelBubble
event.cancelable
event.composed
event.composedPath()
event.currentTarget
event.defaultPrevented
event.eventPhase
event.initEvent(type[, bubbles[, cancelable]])
event.isTrusted
event.preventDefault()
event.returnValue
event.srcElement
event.stopImmediatePropagation()
event.stopPropagation()
event.target
event.timeStamp
event.type


Class: EventTarget

eventTarget.addEventListener(type, listener[, options])
eventTarget.dispatchEvent(event)
eventTarget.removeEventListener(type, listener[, options])


Class: CustomEvent

event.detail


Class: NodeEventTarget

nodeEventTarget.addListener(type, listener)
nodeEventTarget.emit(type, arg)
nodeEventTarget.eventNames()
nodeEventTarget.listenerCount(type)
nodeEventTarget.setMaxListeners(n)
nodeEventTarget.getMaxListeners()
nodeEventTarget.off(type, listener[, options])
nodeEventTarget.on(type, listener)
nodeEventTarget.once(type, listener)
nodeEventTarget.removeAllListeners([type])
nodeEventTarget.removeListener(type, listener[, options])







    
  
            
    
      
        
        Index
      

      
About this documentation
Usage and example

      
        Index
      
    
  


Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Modules: TypeScript
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
Readline
REPL
Report
Single executable applications
SQLite
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker

    
  
            
    
      
        
        Other versions
      
      24.x
23.x
22.x LTS
21.x
20.x LTS
19.x
18.x
17.x
16.x
15.x
14.x
13.x
12.x
11.x
10.x
9.x
8.x
7.x
6.x
5.x
4.x
0.12.x
0.10.x
    
  
            
              
                
                Options
              
        
              
                
                  
                    View on single page
                  
                  
                    View as JSON
                  
                  Edit on GitHub    
                
              
            
          
        
        
      

      Table of contents
Events

Passing arguments and this to listeners
Asynchronous vs. synchronous
Handling events only once
Error events
Capture rejections of promises
Class: EventEmitter

Event: 'newListener'
Event: 'removeListener'
emitter.addListener(eventName, listener)
emitter.emit(eventName[, ...args])
emitter.eventNames()
emitter.getMaxListeners()
emitter.listenerCount(eventName[, listener])
emitter.listeners(eventName)
emitter.off(eventName, listener)
emitter.on(eventName, listener)
emitter.once(eventName, listener)
emitter.prependListener(eventName, listener)
emitter.prependOnceListener(eventName, listener)
emitter.removeAllListeners([eventName])
emitter.removeListener(eventName, listener)
emitter.setMaxListeners(n)
emitter.rawListeners(eventName)
emitter[Symbol.for('nodejs.rejection')](err, eventName[, ...args])


events.defaultMaxListeners
events.errorMonitor
events.getEventListeners(emitterOrTarget, eventName)
events.getMaxListeners(emitterOrTarget)
events.once(emitter, name[, options])

Awaiting multiple events emitted on process.nextTick()


events.captureRejections
events.captureRejectionSymbol
events.listenerCount(emitter, eventName)
events.on(emitter, eventName[, options])
events.setMaxListeners(n[, ...eventTargets])
events.addAbortListener(signal, listener)
Class: events.EventEmitterAsyncResource extends EventEmitter

new events.EventEmitterAsyncResource([options])
eventemitterasyncresource.asyncId
eventemitterasyncresource.asyncResource
eventemitterasyncresource.emitDestroy()
eventemitterasyncresource.triggerAsyncId


EventTarget and Event API

Node.js EventTarget vs. DOM EventTarget
NodeEventTarget vs. EventEmitter
Event listener
EventTarget error handling
Class: Event

event.bubbles
event.cancelBubble
event.cancelable
event.composed
event.composedPath()
event.currentTarget
event.defaultPrevented
event.eventPhase
event.initEvent(type[, bubbles[, cancelable]])
event.isTrusted
event.preventDefault()
event.returnValue
event.srcElement
event.stopImmediatePropagation()
event.stopPropagation()
event.target
event.timeStamp
event.type


Class: EventTarget

eventTarget.addEventListener(type, listener[, options])
eventTarget.dispatchEvent(event)
eventTarget.removeEventListener(type, listener[, options])


Class: CustomEvent

event.detail


Class: NodeEventTarget

nodeEventTarget.addListener(type, listener)
nodeEventTarget.emit(type, arg)
nodeEventTarget.eventNames()
nodeEventTarget.listenerCount(type)
nodeEventTarget.setMaxListeners(n)
nodeEventTarget.getMaxListeners()
nodeEventTarget.off(type, listener[, options])
nodeEventTarget.on(type, listener)
nodeEventTarget.once(type, listener)
nodeEventTarget.removeAllListeners([type])
nodeEventTarget.removeListener(type, listener[, options])








      
        Events#

Stability: 2 - Stable

Source Code: lib/events.js
Much of the Node.js core API is built around an idiomatic asynchronous
event-driven architecture in which certain kinds of objects (called "emitters")
emit named events that cause Function objects ("listeners") to be called.
For instance: a net.Server object emits an event each time a peer
connects to it; a fs.ReadStream emits an event when the file is opened;
a stream emits an event whenever data is available to be read.
All objects that emit events are instances of the EventEmitter class. These
objects expose an eventEmitter.on() function that allows one or more
functions to be attached to named events emitted by the object. Typically,
event names are camel-cased strings but any valid JavaScript property key
can be used.
When the EventEmitter object emits an event, all of the functions attached
to that specific event are called synchronously. Any values returned by the
called listeners are ignored and discarded.
The following example shows a simple EventEmitter instance with a single
listener. The eventEmitter.on() method is used to register listeners, while
the eventEmitter.emit() method is used to trigger the event.

import { EventEmitter } from 'node:events';

class MyEmitter extends EventEmitter {}

const myEmitter = new MyEmitter();
myEmitter.on('event', () => {
  console.log('an event occurred!');
});
myEmitter.emit('event');const EventEmitter = require('node:events');

class MyEmitter extends EventEmitter {}

const myEmitter = new MyEmitter();
myEmitter.on('event', () => {
  console.log('an event occurred!');
});
myEmitter.emit('event');copy
Passing arguments and this to listeners#
The eventEmitter.emit() method allows an arbitrary set of arguments to be
passed to the listener functions. Keep in mind that when
an ordinary listener function is called, the standard this keyword
is intentionally set to reference the EventEmitter instance to which the
listener is attached.

import { EventEmitter } from 'node:events';
class MyEmitter extends EventEmitter {}
const myEmitter = new MyEmitter();
myEmitter.on('event', function(a, b) {
  console.log(a, b, this, this === myEmitter);
  // Prints:
  //   a b MyEmitter {
  //     _events: [Object: null prototype] { event: [Function (anonymous)] },
  //     _eventsCount: 1,
  //     _maxListeners: undefined,
  //     Symbol(shapeMode): false,
  //     Symbol(kCapture): false
  //   } true
});
myEmitter.emit('event', 'a', 'b');const EventEmitter = require('node:events');
class MyEmitter extends EventEmitter {}
const myEmitter = new MyEmitter();
myEmitter.on('event', function(a, b) {
  console.log(a, b, this, this === myEmitter);
  // Prints:
  //   a b MyEmitter {
  //     _events: [Object: null prototype] { event: [Function (anonymous)] },
  //     _eventsCount: 1,
  //     _maxListeners: undefined,
  //     Symbol(shapeMode): false,
  //     Symbol(kCapture): false
  //   } true
});
myEmitter.emit('event', 'a', 'b');copy
It is possible to use ES6 Arrow Functions as listeners, however, when doing so,
the this keyword will no longer reference the EventEmitter instance:

import { EventEmitter } from 'node:events';
class MyEmitter extends EventEmitter {}
const myEmitter = new MyEmitter();
myEmitter.on('event', (a, b) => {
  console.log(a, b, this);
  // Prints: a b undefined
});
myEmitter.emit('event', 'a', 'b');const EventEmitter = require('node:events');
class MyEmitter extends EventEmitter {}
const myEmitter = new MyEmitter();
myEmitter.on('event', (a, b) => {
  console.log(a, b, this);
  // Prints: a b {}
});
myEmitter.emit('event', 'a', 'b');copy
Asynchronous vs. synchronous#
The EventEmitter calls all listeners synchronously in the order in which
they were registered. This ensures the proper sequencing of
events and helps avoid race conditions and logic errors. When appropriate,
listener functions can switch to an asynchronous mode of operation using
the setImmediate() or process.nextTick() methods:

import { EventEmitter } from 'node:events';
class MyEmitter extends EventEmitter {}
const myEmitter = new MyEmitter();
myEmitter.on('event', (a, b) => {
  setImmediate(() => {
    console.log('this happens asynchronously');
  });
});
myEmitter.emit('event', 'a', 'b');const EventEmitter = require('node:events');
class MyEmitter extends EventEmitter {}
const myEmitter = new MyEmitter();
myEmitter.on('event', (a, b) => {
  setImmediate(() => {
    console.log('this happens asynchronously');
  });
});
myEmitter.emit('event', 'a', 'b');copy
Handling events only once#
When a listener is registered using the eventEmitter.on() method, that
listener is invoked every time the named event is emitted.

import { EventEmitter } from 'node:events';
class MyEmitter extends EventEmitter {}
const myEmitter = new MyEmitter();
let m = 0;
myEmitter.on('event', () => {
  console.log(++m);
});
myEmitter.emit('event');
// Prints: 1
myEmitter.emit('event');
// Prints: 2const EventEmitter = require('node:events');
class MyEmitter extends EventEmitter {}
const myEmitter = new MyEmitter();
let m = 0;
myEmitter.on('event', () => {
  console.log(++m);
});
myEmitter.emit('event');
// Prints: 1
myEmitter.emit('event');
// Prints: 2copy
Using the eventEmitter.once() method, it is possible to register a listener
that is called at most once for a particular event. Once the event is emitted,
the listener is unregistered and then called.

import { EventEmitter } from 'node:events';
class MyEmitter extends EventEmitter {}
const myEmitter = new MyEmitter();
let m = 0;
myEmitter.once('event', () => {
  console.log(++m);
});
myEmitter.emit('event');
// Prints: 1
myEmitter.emit('event');
// Ignoredconst EventEmitter = require('node:events');
class MyEmitter extends EventEmitter {}
const myEmitter = new MyEmitter();
let m = 0;
myEmitter.once('event', () => {
  console.log(++m);
});
myEmitter.emit('event');
// Prints: 1
myEmitter.emit('event');
// Ignoredcopy
Error events#
When an error occurs within an EventEmitter instance, the typical action is
for an 'error' event to be emitted. These are treated as special cases
within Node.js.
If an EventEmitter does not have at least one listener registered for the
'error' event, and an 'error' event is emitted, the error is thrown, a
stack trace is printed, and the Node.js process exits.

import { EventEmitter } from 'node:events';
class MyEmitter extends EventEmitter {}
const myEmitter = new MyEmitter();
myEmitter.emit('error', new Error('whoops!'));
// Throws and crashes Node.jsconst EventEmitter = require('node:events');
class MyEmitter extends EventEmitter {}
const myEmitter = new MyEmitter();
myEmitter.emit('error', new Error('whoops!'));
// Throws and crashes Node.jscopy
To guard against crashing the Node.js process the domain module can be
used. (Note, however, that the node:domain module is deprecated.)
As a best practice, listeners should always be added for the 'error' events.

import { EventEmitter } from 'node:events';
class MyEmitter extends EventEmitter {}
const myEmitter = new MyEmitter();
myEmitter.on('error', (err) => {
  console.error('whoops! there was an error');
});
myEmitter.emit('error', new Error('whoops!'));
// Prints: whoops! there was an errorconst EventEmitter = require('node:events');
class MyEmitter extends EventEmitter {}
const myEmitter = new MyEmitter();
myEmitter.on('error', (err) => {
  console.error('whoops! there was an error');
});
myEmitter.emit('error', new Error('whoops!'));
// Prints: whoops! there was an errorcopy
It is possible to monitor 'error' events without consuming the emitted error
by installing a listener using the symbol events.errorMonitor.

import { EventEmitter, errorMonitor } from 'node:events';

const myEmitter = new EventEmitter();
myEmitter.on(errorMonitor, (err) => {
  MyMonitoringTool.log(err);
});
myEmitter.emit('error', new Error('whoops!'));
// Still throws and crashes Node.jsconst { EventEmitter, errorMonitor } = require('node:events');

const myEmitter = new EventEmitter();
myEmitter.on(errorMonitor, (err) => {
  MyMonitoringTool.log(err);
});
myEmitter.emit('error', new Error('whoops!'));
// Still throws and crashes Node.jscopy
Capture rejections of promises#
Using async functions with event handlers is problematic, because it
can lead to an unhandled rejection in case of a thrown exception:

import { EventEmitter } from 'node:events';
const ee = new EventEmitter();
ee.on('something', async (value) => {
  throw new Error('kaboom');
});const EventEmitter = require('node:events');
const ee = new EventEmitter();
ee.on('something', async (value) => {
  throw new Error('kaboom');
});copy
The captureRejections option in the EventEmitter constructor or the global
setting change this behavior, installing a .then(undefined, handler)
handler on the Promise. This handler routes the exception
asynchronously to the Symbol.for('nodejs.rejection') method
if there is one, or to 'error' event handler if there is none.

import { EventEmitter } from 'node:events';
const ee1 = new EventEmitter({ captureRejections: true });
ee1.on('something', async (value) => {
  throw new Error('kaboom');
});

ee1.on('error', console.log);

const ee2 = new EventEmitter({ captureRejections: true });
ee2.on('something', async (value) => {
  throw new Error('kaboom');
});

ee2[Symbol.for('nodejs.rejection')] = console.log;const EventEmitter = require('node:events');
const ee1 = new EventEmitter({ captureRejections: true });
ee1.on('something', async (value) => {
  throw new Error('kaboom');
});

ee1.on('error', console.log);

const ee2 = new EventEmitter({ captureRejections: true });
ee2.on('something', async (value) => {
  throw new Error('kaboom');
});

ee2[Symbol.for('nodejs.rejection')] = console.log;copy
Setting events.captureRejections = true will change the default for all
new instances of EventEmitter.

import { EventEmitter } from 'node:events';

EventEmitter.captureRejections = true;
const ee1 = new EventEmitter();
ee1.on('something', async (value) => {
  throw new Error('kaboom');
});

ee1.on('error', console.log);const events = require('node:events');
events.captureRejections = true;
const ee1 = new events.EventEmitter();
ee1.on('something', async (value) => {
  throw new Error('kaboom');
});

ee1.on('error', console.log);copy
The 'error' events that are generated by the captureRejections behavior
do not have a catch handler to avoid infinite error loops: the
recommendation is to not use async functions as 'error' event handlers.
Class: EventEmitter#

History

VersionChanges
v13.4.0, v12.16.0
Added captureRejections option.
v0.1.26
Added in: v0.1.26



The EventEmitter class is defined and exposed by the node:events module:

import { EventEmitter } from 'node:events';const EventEmitter = require('node:events');copy
All EventEmitters emit the event 'newListener' when new listeners are
added and 'removeListener' when existing listeners are removed.
It supports the following option:

captureRejections <boolean> It enables
automatic capturing of promise rejection.
Default: false.


Event: 'newListener'#

Added in: v0.1.26


eventName <string> | <symbol> The name of the event being listened for
listener <Function> The event handler function

The EventEmitter instance will emit its own 'newListener' event before
a listener is added to its internal array of listeners.
Listeners registered for the 'newListener' event are passed the event
name and a reference to the listener being added.
The fact that the event is triggered before adding the listener has a subtle
but important side effect: any additional listeners registered to the same
name within the 'newListener' callback are inserted before the
listener that is in the process of being added.

import { EventEmitter } from 'node:events';
class MyEmitter extends EventEmitter {}

const myEmitter = new MyEmitter();
// Only do this once so we don't loop forever
myEmitter.once('newListener', (event, listener) => {
  if (event === 'event') {
    // Insert a new listener in front
    myEmitter.on('event', () => {
      console.log('B');
    });
  }
});
myEmitter.on('event', () => {
  console.log('A');
});
myEmitter.emit('event');
// Prints:
//   B
//   Aconst EventEmitter = require('node:events');
class MyEmitter extends EventEmitter {}

const myEmitter = new MyEmitter();
// Only do this once so we don't loop forever
myEmitter.once('newListener', (event, listener) => {
  if (event === 'event') {
    // Insert a new listener in front
    myEmitter.on('event', () => {
      console.log('B');
    });
  }
});
myEmitter.on('event', () => {
  console.log('A');
});
myEmitter.emit('event');
// Prints:
//   B
//   Acopy

Event: 'removeListener'#

History

VersionChanges
v6.1.0, v4.7.0
For listeners attached using .once(), the listener argument now yields the original listener function.
v0.9.3
Added in: v0.9.3




eventName <string> | <symbol> The event name
listener <Function> The event handler function

The 'removeListener' event is emitted after the listener is removed.

emitter.addListener(eventName, listener)#

Added in: v0.1.26


eventName <string> | <symbol>
listener <Function>

Alias for emitter.on(eventName, listener).

emitter.emit(eventName[, ...args])#

Added in: v0.1.26


eventName <string> | <symbol>
...args <any>
Returns: <boolean>

Synchronously calls each of the listeners registered for the event named
eventName, in the order they were registered, passing the supplied arguments
to each.
Returns true if the event had listeners, false otherwise.

import { EventEmitter } from 'node:events';
const myEmitter = new EventEmitter();

// First listener
myEmitter.on('event', function firstListener() {
  console.log('Helloooo! first listener');
});
// Second listener
myEmitter.on('event', function secondListener(arg1, arg2) {
  console.log(`event with parameters ${arg1}, ${arg2} in second listener`);
});
// Third listener
myEmitter.on('event', function thirdListener(...args) {
  const parameters = args.join(', ');
  console.log(`event with parameters ${parameters} in third listener`);
});

console.log(myEmitter.listeners('event'));

myEmitter.emit('event', 1, 2, 3, 4, 5);

// Prints:
// [
//   [Function: firstListener],
//   [Function: secondListener],
//   [Function: thirdListener]
// ]
// Helloooo! first listener
// event with parameters 1, 2 in second listener
// event with parameters 1, 2, 3, 4, 5 in third listenerconst EventEmitter = require('node:events');
const myEmitter = new EventEmitter();

// First listener
myEmitter.on('event', function firstListener() {
  console.log('Helloooo! first listener');
});
// Second listener
myEmitter.on('event', function secondListener(arg1, arg2) {
  console.log(`event with parameters ${arg1}, ${arg2} in second listener`);
});
// Third listener
myEmitter.on('event', function thirdListener(...args) {
  const parameters = args.join(', ');
  console.log(`event with parameters ${parameters} in third listener`);
});

console.log(myEmitter.listeners('event'));

myEmitter.emit('event', 1, 2, 3, 4, 5);

// Prints:
// [
//   [Function: firstListener],
//   [Function: secondListener],
//   [Function: thirdListener]
// ]
// Helloooo! first listener
// event with parameters 1, 2 in second listener
// event with parameters 1, 2, 3, 4, 5 in third listenercopy

emitter.eventNames()#

Added in: v6.0.0


Returns: <Array>

Returns an array listing the events for which the emitter has registered
listeners. The values in the array are strings or Symbols.

import { EventEmitter } from 'node:events';

const myEE = new EventEmitter();
myEE.on('foo', () => {});
myEE.on('bar', () => {});

const sym = Symbol('symbol');
myEE.on(sym, () => {});

console.log(myEE.eventNames());
// Prints: [ 'foo', 'bar', Symbol(symbol) ]const EventEmitter = require('node:events');

const myEE = new EventEmitter();
myEE.on('foo', () => {});
myEE.on('bar', () => {});

const sym = Symbol('symbol');
myEE.on(sym, () => {});

console.log(myEE.eventNames());
// Prints: [ 'foo', 'bar', Symbol(symbol) ]copy

emitter.getMaxListeners()#

Added in: v1.0.0


Returns: <integer>

Returns the current max listener value for the EventEmitter which is either
set by emitter.setMaxListeners(n) or defaults to
events.defaultMaxListeners.

emitter.listenerCount(eventName[, listener])#

History

VersionChanges
v19.8.0, v18.16.0
Added the listener argument.
v3.2.0
Added in: v3.2.0




eventName <string> | <symbol> The name of the event being listened for
listener <Function> The event handler function
Returns: <integer>

Returns the number of listeners listening for the event named eventName.
If listener is provided, it will return how many times the listener is found
in the list of the listeners of the event.

emitter.listeners(eventName)#

History

VersionChanges
v7.0.0
For listeners attached using .once() this returns the original listeners instead of wrapper functions now.
v0.1.26
Added in: v0.1.26




eventName <string> | <symbol>
Returns: <Function[]>

Returns a copy of the array of listeners for the event named eventName.
server.on('connection', (stream) => {
  console.log('someone connected!');
});
console.log(util.inspect(server.listeners('connection')));
// Prints: [ [Function] ] copy

emitter.off(eventName, listener)#

Added in: v10.0.0


eventName <string> | <symbol>
listener <Function>
Returns: <EventEmitter>

Alias for emitter.removeListener().

emitter.on(eventName, listener)#

Added in: v0.1.101


eventName <string> | <symbol> The name of the event.
listener <Function> The callback function
Returns: <EventEmitter>

Adds the listener function to the end of the listeners array for the
event named eventName. No checks are made to see if the listener has
already been added. Multiple calls passing the same combination of eventName
and listener will result in the listener being added, and called, multiple
times.
server.on('connection', (stream) => {
  console.log('someone connected!');
}); copy
Returns a reference to the EventEmitter, so that calls can be chained.
By default, event listeners are invoked in the order they are added. The
emitter.prependListener() method can be used as an alternative to add the
event listener to the beginning of the listeners array.

import { EventEmitter } from 'node:events';
const myEE = new EventEmitter();
myEE.on('foo', () => console.log('a'));
myEE.prependListener('foo', () => console.log('b'));
myEE.emit('foo');
// Prints:
//   b
//   aconst EventEmitter = require('node:events');
const myEE = new EventEmitter();
myEE.on('foo', () => console.log('a'));
myEE.prependListener('foo', () => console.log('b'));
myEE.emit('foo');
// Prints:
//   b
//   acopy

emitter.once(eventName, listener)#

Added in: v0.3.0


eventName <string> | <symbol> The name of the event.
listener <Function> The callback function
Returns: <EventEmitter>

Adds a one-time listener function for the event named eventName. The
next time eventName is triggered, this listener is removed and then invoked.
server.once('connection', (stream) => {
  console.log('Ah, we have our first user!');
}); copy
Returns a reference to the EventEmitter, so that calls can be chained.
By default, event listeners are invoked in the order they are added. The
emitter.prependOnceListener() method can be used as an alternative to add the
event listener to the beginning of the listeners array.

import { EventEmitter } from 'node:events';
const myEE = new EventEmitter();
myEE.once('foo', () => console.log('a'));
myEE.prependOnceListener('foo', () => console.log('b'));
myEE.emit('foo');
// Prints:
//   b
//   aconst EventEmitter = require('node:events');
const myEE = new EventEmitter();
myEE.once('foo', () => console.log('a'));
myEE.prependOnceListener('foo', () => console.log('b'));
myEE.emit('foo');
// Prints:
//   b
//   acopy

emitter.prependListener(eventName, listener)#

Added in: v6.0.0


eventName <string> | <symbol> The name of the event.
listener <Function> The callback function
Returns: <EventEmitter>

Adds the listener function to the beginning of the listeners array for the
event named eventName. No checks are made to see if the listener has
already been added. Multiple calls passing the same combination of eventName
and listener will result in the listener being added, and called, multiple
times.
server.prependListener('connection', (stream) => {
  console.log('someone connected!');
}); copy
Returns a reference to the EventEmitter, so that calls can be chained.

emitter.prependOnceListener(eventName, listener)#

Added in: v6.0.0


eventName <string> | <symbol> The name of the event.
listener <Function> The callback function
Returns: <EventEmitter>

Adds a one-time listener function for the event named eventName to the
beginning of the listeners array. The next time eventName is triggered, this
listener is removed, and then invoked.
server.prependOnceListener('connection', (stream) => {
  console.log('Ah, we have our first user!');
}); copy
Returns a reference to the EventEmitter, so that calls can be chained.

emitter.removeAllListeners([eventName])#

Added in: v0.1.26


eventName <string> | <symbol>
Returns: <EventEmitter>

Removes all listeners, or those of the specified eventName.
It is bad practice to remove listeners added elsewhere in the code,
particularly when the EventEmitter instance was created by some other
component or module (e.g. sockets or file streams).
Returns a reference to the EventEmitter, so that calls can be chained.

emitter.removeListener(eventName, listener)#

Added in: v0.1.26


eventName <string> | <symbol>
listener <Function>
Returns: <EventEmitter>

Removes the specified listener from the listener array for the event named
eventName.
const callback = (stream) => {
  console.log('someone connected!');
};
server.on('connection', callback);
// ...
server.removeListener('connection', callback); copy
removeListener() will remove, at most, one instance of a listener from the
listener array. If any single listener has been added multiple times to the
listener array for the specified eventName, then removeListener() must be
called multiple times to remove each instance.
Once an event is emitted, all listeners attached to it at the
time of emitting are called in order. This implies that any
removeListener() or removeAllListeners() calls after emitting and
before the last listener finishes execution will not remove them from
emit() in progress. Subsequent events behave as expected.

import { EventEmitter } from 'node:events';
class MyEmitter extends EventEmitter {}
const myEmitter = new MyEmitter();

const callbackA = () => {
  console.log('A');
  myEmitter.removeListener('event', callbackB);
};

const callbackB = () => {
  console.log('B');
};

myEmitter.on('event', callbackA);

myEmitter.on('event', callbackB);

// callbackA removes listener callbackB but it will still be called.
// Internal listener array at time of emit [callbackA, callbackB]
myEmitter.emit('event');
// Prints:
//   A
//   B

// callbackB is now removed.
// Internal listener array [callbackA]
myEmitter.emit('event');
// Prints:
//   Aconst EventEmitter = require('node:events');
class MyEmitter extends EventEmitter {}
const myEmitter = new MyEmitter();

const callbackA = () => {
  console.log('A');
  myEmitter.removeListener('event', callbackB);
};

const callbackB = () => {
  console.log('B');
};

myEmitter.on('event', callbackA);

myEmitter.on('event', callbackB);

// callbackA removes listener callbackB but it will still be called.
// Internal listener array at time of emit [callbackA, callbackB]
myEmitter.emit('event');
// Prints:
//   A
//   B

// callbackB is now removed.
// Internal listener array [callbackA]
myEmitter.emit('event');
// Prints:
//   Acopy
Because listeners are managed using an internal array, calling this will
change the position indexes of any listener registered after the listener
being removed. This will not impact the order in which listeners are called,
but it means that any copies of the listener array as returned by
the emitter.listeners() method will need to be recreated.
When a single function has been added as a handler multiple times for a single
event (as in the example below), removeListener() will remove the most
recently added instance. In the example the once('ping')
listener is removed:

import { EventEmitter } from 'node:events';
const ee = new EventEmitter();

function pong() {
  console.log('pong');
}

ee.on('ping', pong);
ee.once('ping', pong);
ee.removeListener('ping', pong);

ee.emit('ping');
ee.emit('ping');const EventEmitter = require('node:events');
const ee = new EventEmitter();

function pong() {
  console.log('pong');
}

ee.on('ping', pong);
ee.once('ping', pong);
ee.removeListener('ping', pong);

ee.emit('ping');
ee.emit('ping');copy
Returns a reference to the EventEmitter, so that calls can be chained.

emitter.setMaxListeners(n)#

Added in: v0.3.5


n <integer>
Returns: <EventEmitter>

By default EventEmitters will print a warning if more than 10 listeners are
added for a particular event. This is a useful default that helps finding
memory leaks. The emitter.setMaxListeners() method allows the limit to be
modified for this specific EventEmitter instance. The value can be set to
Infinity (or 0) to indicate an unlimited number of listeners.
Returns a reference to the EventEmitter, so that calls can be chained.

emitter.rawListeners(eventName)#

Added in: v9.4.0


eventName <string> | <symbol>
Returns: <Function[]>

Returns a copy of the array of listeners for the event named eventName,
including any wrappers (such as those created by .once()).

import { EventEmitter } from 'node:events';
const emitter = new EventEmitter();
emitter.once('log', () => console.log('log once'));

// Returns a new Array with a function `onceWrapper` which has a property
// `listener` which contains the original listener bound above
const listeners = emitter.rawListeners('log');
const logFnWrapper = listeners[0];

// Logs "log once" to the console and does not unbind the `once` event
logFnWrapper.listener();

// Logs "log once" to the console and removes the listener
logFnWrapper();

emitter.on('log', () => console.log('log persistently'));
// Will return a new Array with a single function bound by `.on()` above
const newListeners = emitter.rawListeners('log');

// Logs "log persistently" twice
newListeners[0]();
emitter.emit('log');const EventEmitter = require('node:events');
const emitter = new EventEmitter();
emitter.once('log', () => console.log('log once'));

// Returns a new Array with a function `onceWrapper` which has a property
// `listener` which contains the original listener bound above
const listeners = emitter.rawListeners('log');
const logFnWrapper = listeners[0];

// Logs "log once" to the console and does not unbind the `once` event
logFnWrapper.listener();

// Logs "log once" to the console and removes the listener
logFnWrapper();

emitter.on('log', () => console.log('log persistently'));
// Will return a new Array with a single function bound by `.on()` above
const newListeners = emitter.rawListeners('log');

// Logs "log persistently" twice
newListeners[0]();
emitter.emit('log');copy

emitter[Symbol.for('nodejs.rejection')](err, eventName[, ...args])#

History

VersionChanges
v17.4.0, v16.14.0
No longer experimental.
v13.4.0, v12.16.0
Added in: v13.4.0, v12.16.0




err Error
eventName <string> | <symbol>
...args <any>

The Symbol.for('nodejs.rejection') method is called in case a
promise rejection happens when emitting an event and
captureRejections is enabled on the emitter.
It is possible to use events.captureRejectionSymbol in
place of Symbol.for('nodejs.rejection').

import { EventEmitter, captureRejectionSymbol } from 'node:events';

class MyClass extends EventEmitter {
  constructor() {
    super({ captureRejections: true });
  }

  [captureRejectionSymbol](err, event, ...args) {
    console.log('rejection happened for', event, 'with', err, ...args);
    this.destroy(err);
  }

  destroy(err) {
    // Tear the resource down here.
  }
}const { EventEmitter, captureRejectionSymbol } = require('node:events');

class MyClass extends EventEmitter {
  constructor() {
    super({ captureRejections: true });
  }

  [captureRejectionSymbol](err, event, ...args) {
    console.log('rejection happened for', event, 'with', err, ...args);
    this.destroy(err);
  }

  destroy(err) {
    // Tear the resource down here.
  }
}copy

events.defaultMaxListeners#

Added in: v0.11.2

By default, a maximum of 10 listeners can be registered for any single
event. This limit can be changed for individual EventEmitter instances
using the emitter.setMaxListeners(n) method. To change the default
for all EventEmitter instances, the events.defaultMaxListeners
property can be used. If this value is not a positive number, a RangeError
is thrown.
Take caution when setting the events.defaultMaxListeners because the
change affects all EventEmitter instances, including those created before
the change is made. However, calling emitter.setMaxListeners(n) still has
precedence over events.defaultMaxListeners.
This is not a hard limit. The EventEmitter instance will allow
more listeners to be added but will output a trace warning to stderr indicating
that a "possible EventEmitter memory leak" has been detected. For any single
EventEmitter, the emitter.getMaxListeners() and emitter.setMaxListeners()
methods can be used to temporarily avoid this warning:
defaultMaxListeners has no effect on AbortSignal instances. While it is
still possible to use emitter.setMaxListeners(n) to set a warning limit
for individual AbortSignal instances, per default AbortSignal instances will not warn.

import { EventEmitter } from 'node:events';
const emitter = new EventEmitter();
emitter.setMaxListeners(emitter.getMaxListeners() + 1);
emitter.once('event', () => {
  // do stuff
  emitter.setMaxListeners(Math.max(emitter.getMaxListeners() - 1, 0));
});const EventEmitter = require('node:events');
const emitter = new EventEmitter();
emitter.setMaxListeners(emitter.getMaxListeners() + 1);
emitter.once('event', () => {
  // do stuff
  emitter.setMaxListeners(Math.max(emitter.getMaxListeners() - 1, 0));
});copy
The --trace-warnings command-line flag can be used to display the
stack trace for such warnings.
The emitted warning can be inspected with process.on('warning') and will
have the additional emitter, type, and count properties, referring to
the event emitter instance, the event's name and the number of attached
listeners, respectively.
Its name property is set to 'MaxListenersExceededWarning'.
events.errorMonitor#

Added in: v13.6.0, v12.17.0

This symbol shall be used to install a listener for only monitoring 'error'
events. Listeners installed using this symbol are called before the regular
'error' listeners are called.
Installing a listener using this symbol does not change the behavior once an
'error' event is emitted. Therefore, the process will still crash if no
regular 'error' listener is installed.
events.getEventListeners(emitterOrTarget, eventName)#

Added in: v15.2.0, v14.17.0


emitterOrTarget <EventEmitter> | <EventTarget>
eventName <string> | <symbol>
Returns: <Function[]>

Returns a copy of the array of listeners for the event named eventName.
For EventEmitters this behaves exactly the same as calling .listeners on
the emitter.
For EventTargets this is the only way to get the event listeners for the
event target. This is useful for debugging and diagnostic purposes.

import { getEventListeners, EventEmitter } from 'node:events';

{
  const ee = new EventEmitter();
  const listener = () => console.log('Events are fun');
  ee.on('foo', listener);
  console.log(getEventListeners(ee, 'foo')); // [ [Function: listener] ]
}
{
  const et = new EventTarget();
  const listener = () => console.log('Events are fun');
  et.addEventListener('foo', listener);
  console.log(getEventListeners(et, 'foo')); // [ [Function: listener] ]
}const { getEventListeners, EventEmitter } = require('node:events');

{
  const ee = new EventEmitter();
  const listener = () => console.log('Events are fun');
  ee.on('foo', listener);
  console.log(getEventListeners(ee, 'foo')); // [ [Function: listener] ]
}
{
  const et = new EventTarget();
  const listener = () => console.log('Events are fun');
  et.addEventListener('foo', listener);
  console.log(getEventListeners(et, 'foo')); // [ [Function: listener] ]
}copy
events.getMaxListeners(emitterOrTarget)#

Added in: v19.9.0, v18.17.0


emitterOrTarget <EventEmitter> | <EventTarget>
Returns: <number>

Returns the currently set max amount of listeners.
For EventEmitters this behaves exactly the same as calling .getMaxListeners on
the emitter.
For EventTargets this is the only way to get the max event listeners for the
event target. If the number of event handlers on a single EventTarget exceeds
the max set, the EventTarget will print a warning.

import { getMaxListeners, setMaxListeners, EventEmitter } from 'node:events';

{
  const ee = new EventEmitter();
  console.log(getMaxListeners(ee)); // 10
  setMaxListeners(11, ee);
  console.log(getMaxListeners(ee)); // 11
}
{
  const et = new EventTarget();
  console.log(getMaxListeners(et)); // 10
  setMaxListeners(11, et);
  console.log(getMaxListeners(et)); // 11
}const { getMaxListeners, setMaxListeners, EventEmitter } = require('node:events');

{
  const ee = new EventEmitter();
  console.log(getMaxListeners(ee)); // 10
  setMaxListeners(11, ee);
  console.log(getMaxListeners(ee)); // 11
}
{
  const et = new EventTarget();
  console.log(getMaxListeners(et)); // 10
  setMaxListeners(11, et);
  console.log(getMaxListeners(et)); // 11
}copy
events.once(emitter, name[, options])#

History

VersionChanges
v15.0.0
The signal option is supported now.
v11.13.0, v10.16.0
Added in: v11.13.0, v10.16.0




emitter <EventEmitter>
name <string> | <symbol>
options <Object>

signal <AbortSignal> Can be used to cancel waiting for the event.


Returns: <Promise>

Creates a Promise that is fulfilled when the EventEmitter emits the given
event or that is rejected if the EventEmitter emits 'error' while waiting.
The Promise will resolve with an array of all the arguments emitted to the
given event.
This method is intentionally generic and works with the web platform
EventTarget interface, which has no special
'error' event semantics and does not listen to the 'error' event.

import { once, EventEmitter } from 'node:events';
import process from 'node:process';

const ee = new EventEmitter();

process.nextTick(() => {
  ee.emit('myevent', 42);
});

const [value] = await once(ee, 'myevent');
console.log(value);

const err = new Error('kaboom');
process.nextTick(() => {
  ee.emit('error', err);
});

try {
  await once(ee, 'myevent');
} catch (err) {
  console.error('error happened', err);
}const { once, EventEmitter } = require('node:events');

async function run() {
  const ee = new EventEmitter();

  process.nextTick(() => {
    ee.emit('myevent', 42);
  });

  const [value] = await once(ee, 'myevent');
  console.log(value);

  const err = new Error('kaboom');
  process.nextTick(() => {
    ee.emit('error', err);
  });

  try {
    await once(ee, 'myevent');
  } catch (err) {
    console.error('error happened', err);
  }
}

run();copy
The special handling of the 'error' event is only used when events.once()
is used to wait for another event. If events.once() is used to wait for the
'error' event itself, then it is treated as any other kind of event without
special handling:

import { EventEmitter, once } from 'node:events';

const ee = new EventEmitter();

once(ee, 'error')
  .then(([err]) => console.log('ok', err.message))
  .catch((err) => console.error('error', err.message));

ee.emit('error', new Error('boom'));

// Prints: ok boomconst { EventEmitter, once } = require('node:events');

const ee = new EventEmitter();

once(ee, 'error')
  .then(([err]) => console.log('ok', err.message))
  .catch((err) => console.error('error', err.message));

ee.emit('error', new Error('boom'));

// Prints: ok boomcopy
An <AbortSignal> can be used to cancel waiting for the event:

import { EventEmitter, once } from 'node:events';

const ee = new EventEmitter();
const ac = new AbortController();

async function foo(emitter, event, signal) {
  try {
    await once(emitter, event, { signal });
    console.log('event emitted!');
  } catch (error) {
    if (error.name === 'AbortError') {
      console.error('Waiting for the event was canceled!');
    } else {
      console.error('There was an error', error.message);
    }
  }
}

foo(ee, 'foo', ac.signal);
ac.abort(); // Prints: Waiting for the event was canceled!const { EventEmitter, once } = require('node:events');

const ee = new EventEmitter();
const ac = new AbortController();

async function foo(emitter, event, signal) {
  try {
    await once(emitter, event, { signal });
    console.log('event emitted!');
  } catch (error) {
    if (error.name === 'AbortError') {
      console.error('Waiting for the event was canceled!');
    } else {
      console.error('There was an error', error.message);
    }
  }
}

foo(ee, 'foo', ac.signal);
ac.abort(); // Prints: Waiting for the event was canceled!copy

Awaiting multiple events emitted on process.nextTick()#
There is an edge case worth noting when using the events.once() function
to await multiple events emitted on in the same batch of process.nextTick()
operations, or whenever multiple events are emitted synchronously. Specifically,
because the process.nextTick() queue is drained before the Promise microtask
queue, and because EventEmitter emits all events synchronously, it is possible
for events.once() to miss an event.

import { EventEmitter, once } from 'node:events';
import process from 'node:process';

const myEE = new EventEmitter();

async function foo() {
  await once(myEE, 'bar');
  console.log('bar');

  // This Promise will never resolve because the 'foo' event will
  // have already been emitted before the Promise is created.
  await once(myEE, 'foo');
  console.log('foo');
}

process.nextTick(() => {
  myEE.emit('bar');
  myEE.emit('foo');
});

foo().then(() => console.log('done'));const { EventEmitter, once } = require('node:events');

const myEE = new EventEmitter();

async function foo() {
  await once(myEE, 'bar');
  console.log('bar');

  // This Promise will never resolve because the 'foo' event will
  // have already been emitted before the Promise is created.
  await once(myEE, 'foo');
  console.log('foo');
}

process.nextTick(() => {
  myEE.emit('bar');
  myEE.emit('foo');
});

foo().then(() => console.log('done'));copy
To catch both events, create each of the Promises before awaiting either
of them, then it becomes possible to use Promise.all(), Promise.race(),
or Promise.allSettled():

import { EventEmitter, once } from 'node:events';
import process from 'node:process';

const myEE = new EventEmitter();

async function foo() {
  await Promise.all([once(myEE, 'bar'), once(myEE, 'foo')]);
  console.log('foo', 'bar');
}

process.nextTick(() => {
  myEE.emit('bar');
  myEE.emit('foo');
});

foo().then(() => console.log('done'));const { EventEmitter, once } = require('node:events');

const myEE = new EventEmitter();

async function foo() {
  await Promise.all([once(myEE, 'bar'), once(myEE, 'foo')]);
  console.log('foo', 'bar');
}

process.nextTick(() => {
  myEE.emit('bar');
  myEE.emit('foo');
});

foo().then(() => console.log('done'));copy

events.captureRejections#

History

VersionChanges
v17.4.0, v16.14.0
No longer experimental.
v13.4.0, v12.16.0
Added in: v13.4.0, v12.16.0



Value: <boolean>
Change the default captureRejections option on all new EventEmitter objects.
events.captureRejectionSymbol#

History

VersionChanges
v17.4.0, v16.14.0
No longer experimental.
v13.4.0, v12.16.0
Added in: v13.4.0, v12.16.0



Value: Symbol.for('nodejs.rejection')
See how to write a custom rejection handler.
events.listenerCount(emitter, eventName)#

Added in: v0.9.12Deprecated since: v3.2.0

Stability: 0 - Deprecated: Use emitter.listenerCount() instead.

emitter <EventEmitter> The emitter to query
eventName <string> | <symbol> The event name

A class method that returns the number of listeners for the given eventName
registered on the given emitter.

import { EventEmitter, listenerCount } from 'node:events';

const myEmitter = new EventEmitter();
myEmitter.on('event', () => {});
myEmitter.on('event', () => {});
console.log(listenerCount(myEmitter, 'event'));
// Prints: 2const { EventEmitter, listenerCount } = require('node:events');

const myEmitter = new EventEmitter();
myEmitter.on('event', () => {});
myEmitter.on('event', () => {});
console.log(listenerCount(myEmitter, 'event'));
// Prints: 2copy
events.on(emitter, eventName[, options])#

History

VersionChanges
v22.0.0, v20.13.0
Support highWaterMark and lowWaterMark options, For consistency. Old options are still supported.
v20.0.0
The close, highWatermark, and lowWatermark options are supported now.
v13.6.0, v12.16.0
Added in: v13.6.0, v12.16.0




emitter <EventEmitter>
eventName <string> | <symbol> The name of the event being listened for
options <Object>

signal <AbortSignal> Can be used to cancel awaiting events.
close - <string[]> Names of events that will end the iteration.
highWaterMark - <integer> Default: Number.MAX_SAFE_INTEGER
The high watermark. The emitter is paused every time the size of events
being buffered is higher than it. Supported only on emitters implementing
pause() and resume() methods.
lowWaterMark - <integer> Default: 1
The low watermark. The emitter is resumed every time the size of events
being buffered is lower than it. Supported only on emitters implementing
pause() and resume() methods.


Returns: <AsyncIterator> that iterates eventName events emitted by the emitter


import { on, EventEmitter } from 'node:events';
import process from 'node:process';

const ee = new EventEmitter();

// Emit later on
process.nextTick(() => {
  ee.emit('foo', 'bar');
  ee.emit('foo', 42);
});

for await (const event of on(ee, 'foo')) {
  // The execution of this inner block is synchronous and it
  // processes one event at a time (even with await). Do not use
  // if concurrent execution is required.
  console.log(event); // prints ['bar'] [42]
}
// Unreachable hereconst { on, EventEmitter } = require('node:events');

(async () => {
  const ee = new EventEmitter();

  // Emit later on
  process.nextTick(() => {
    ee.emit('foo', 'bar');
    ee.emit('foo', 42);
  });

  for await (const event of on(ee, 'foo')) {
    // The execution of this inner block is synchronous and it
    // processes one event at a time (even with await). Do not use
    // if concurrent execution is required.
    console.log(event); // prints ['bar'] [42]
  }
  // Unreachable here
})();copy
Returns an AsyncIterator that iterates eventName events. It will throw
if the EventEmitter emits 'error'. It removes all listeners when
exiting the loop. The value returned by each iteration is an array
composed of the emitted event arguments.
An <AbortSignal> can be used to cancel waiting on events:

import { on, EventEmitter } from 'node:events';
import process from 'node:process';

const ac = new AbortController();

(async () => {
  const ee = new EventEmitter();

  // Emit later on
  process.nextTick(() => {
    ee.emit('foo', 'bar');
    ee.emit('foo', 42);
  });

  for await (const event of on(ee, 'foo', { signal: ac.signal })) {
    // The execution of this inner block is synchronous and it
    // processes one event at a time (even with await). Do not use
    // if concurrent execution is required.
    console.log(event); // prints ['bar'] [42]
  }
  // Unreachable here
})();

process.nextTick(() => ac.abort());const { on, EventEmitter } = require('node:events');

const ac = new AbortController();

(async () => {
  const ee = new EventEmitter();

  // Emit later on
  process.nextTick(() => {
    ee.emit('foo', 'bar');
    ee.emit('foo', 42);
  });

  for await (const event of on(ee, 'foo', { signal: ac.signal })) {
    // The execution of this inner block is synchronous and it
    // processes one event at a time (even with await). Do not use
    // if concurrent execution is required.
    console.log(event); // prints ['bar'] [42]
  }
  // Unreachable here
})();

process.nextTick(() => ac.abort());copy
events.setMaxListeners(n[, ...eventTargets])#

Added in: v15.4.0


n <number> A non-negative number. The maximum number of listeners per
EventTarget event.
...eventsTargets <EventTarget[]> | <EventEmitter[]> Zero or more <EventTarget>
or <EventEmitter> instances. If none are specified, n is set as the default
max for all newly created <EventTarget> and <EventEmitter> objects.


import { setMaxListeners, EventEmitter } from 'node:events';

const target = new EventTarget();
const emitter = new EventEmitter();

setMaxListeners(5, target, emitter);const {
  setMaxListeners,
  EventEmitter,
} = require('node:events');

const target = new EventTarget();
const emitter = new EventEmitter();

setMaxListeners(5, target, emitter);copy
events.addAbortListener(signal, listener)#

History

VersionChanges
v24.0.0
Change stability index for this feature from Experimental to Stable.
v20.5.0, v18.18.0
Added in: v20.5.0, v18.18.0




signal <AbortSignal>
listener <Function> | <EventListener>
Returns: <Disposable> A Disposable that removes the abort listener.

Listens once to the abort event on the provided signal.
Listening to the abort event on abort signals is unsafe and may
lead to resource leaks since another third party with the signal can
call e.stopImmediatePropagation(). Unfortunately Node.js cannot change
this since it would violate the web standard. Additionally, the original
API makes it easy to forget to remove listeners.
This API allows safely using AbortSignals in Node.js APIs by solving these
two issues by listening to the event such that stopImmediatePropagation does
not prevent the listener from running.
Returns a disposable so that it may be unsubscribed from more easily.

const { addAbortListener } = require('node:events');

function example(signal) {
  let disposable;
  try {
    signal.addEventListener('abort', (e) => e.stopImmediatePropagation());
    disposable = addAbortListener(signal, (e) => {
      // Do something when signal is aborted.
    });
  } finally {
    disposable?.[Symbol.dispose]();
  }
}import { addAbortListener } from 'node:events';

function example(signal) {
  let disposable;
  try {
    signal.addEventListener('abort', (e) => e.stopImmediatePropagation());
    disposable = addAbortListener(signal, (e) => {
      // Do something when signal is aborted.
    });
  } finally {
    disposable?.[Symbol.dispose]();
  }
}copy
Class: events.EventEmitterAsyncResource extends EventEmitter#

Added in: v17.4.0, v16.14.0

Integrates EventEmitter with <AsyncResource> for EventEmitters that
require manual async tracking. Specifically, all events emitted by instances
of events.EventEmitterAsyncResource will run within its async context.

import { EventEmitterAsyncResource, EventEmitter } from 'node:events';
import { notStrictEqual, strictEqual } from 'node:assert';
import { executionAsyncId, triggerAsyncId } from 'node:async_hooks';

// Async tracking tooling will identify this as 'Q'.
const ee1 = new EventEmitterAsyncResource({ name: 'Q' });

// 'foo' listeners will run in the EventEmitters async context.
ee1.on('foo', () => {
  strictEqual(executionAsyncId(), ee1.asyncId);
  strictEqual(triggerAsyncId(), ee1.triggerAsyncId);
});

const ee2 = new EventEmitter();

// 'foo' listeners on ordinary EventEmitters that do not track async
// context, however, run in the same async context as the emit().
ee2.on('foo', () => {
  notStrictEqual(executionAsyncId(), ee2.asyncId);
  notStrictEqual(triggerAsyncId(), ee2.triggerAsyncId);
});

Promise.resolve().then(() => {
  ee1.emit('foo');
  ee2.emit('foo');
});const { EventEmitterAsyncResource, EventEmitter } = require('node:events');
const { notStrictEqual, strictEqual } = require('node:assert');
const { executionAsyncId, triggerAsyncId } = require('node:async_hooks');

// Async tracking tooling will identify this as 'Q'.
const ee1 = new EventEmitterAsyncResource({ name: 'Q' });

// 'foo' listeners will run in the EventEmitters async context.
ee1.on('foo', () => {
  strictEqual(executionAsyncId(), ee1.asyncId);
  strictEqual(triggerAsyncId(), ee1.triggerAsyncId);
});

const ee2 = new EventEmitter();

// 'foo' listeners on ordinary EventEmitters that do not track async
// context, however, run in the same async context as the emit().
ee2.on('foo', () => {
  notStrictEqual(executionAsyncId(), ee2.asyncId);
  notStrictEqual(triggerAsyncId(), ee2.triggerAsyncId);
});

Promise.resolve().then(() => {
  ee1.emit('foo');
  ee2.emit('foo');
});copy
The EventEmitterAsyncResource class has the same methods and takes the
same options as EventEmitter and AsyncResource themselves.

new events.EventEmitterAsyncResource([options])#

options <Object>

captureRejections <boolean> It enables
automatic capturing of promise rejection.
Default: false.
name <string> The type of async event. Default: new.target.name.
triggerAsyncId <number> The ID of the execution context that created this
async event. Default: executionAsyncId().
requireManualDestroy <boolean> If set to true, disables emitDestroy
when the object is garbage collected. This usually does not need to be set
(even if emitDestroy is called manually), unless the resource's asyncId
is retrieved and the sensitive API's emitDestroy is called with it.
When set to false, the emitDestroy call on garbage collection
will only take place if there is at least one active destroy hook.
Default: false.




eventemitterasyncresource.asyncId#

Type: <number> The unique asyncId assigned to the resource.


eventemitterasyncresource.asyncResource#

Type: The underlying <AsyncResource>.

The returned AsyncResource object has an additional eventEmitter property
that provides a reference to this EventEmitterAsyncResource.

eventemitterasyncresource.emitDestroy()#
Call all destroy hooks. This should only ever be called once. An error will
be thrown if it is called more than once. This must be manually called. If
the resource is left to be collected by the GC then the destroy hooks will
never be called.

eventemitterasyncresource.triggerAsyncId#

Type: <number> The same triggerAsyncId that is passed to the
AsyncResource constructor.



EventTarget and Event API#

History

VersionChanges
v16.0.0
changed EventTarget error handling.
v15.4.0
No longer experimental.
v15.0.0
The EventTarget and Event classes are now available as globals.
v14.5.0
Added in: v14.5.0



The EventTarget and Event objects are a Node.js-specific implementation
of the EventTarget Web API that are exposed by some Node.js core APIs.
const target = new EventTarget();

target.addEventListener('foo', (event) => {
  console.log('foo event happened!');
}); copy

Node.js EventTarget vs. DOM EventTarget#
There are two key differences between the Node.js EventTarget and the
EventTarget Web API:

Whereas DOM EventTarget instances may be hierarchical, there is no
concept of hierarchy and event propagation in Node.js. That is, an event
dispatched to an EventTarget does not propagate through a hierarchy of
nested target objects that may each have their own set of handlers for the
event.
In the Node.js EventTarget, if an event listener is an async function
or returns a Promise, and the returned Promise rejects, the rejection
is automatically captured and handled the same way as a listener that
throws synchronously (see EventTarget error handling for details).


NodeEventTarget vs. EventEmitter#
The NodeEventTarget object implements a modified subset of the
EventEmitter API that allows it to closely emulate an EventEmitter in
certain situations. A NodeEventTarget is not an instance of EventEmitter
and cannot be used in place of an EventEmitter in most cases.

Unlike EventEmitter, any given listener can be registered at most once
per event type. Attempts to register a listener multiple times are
ignored.
The NodeEventTarget does not emulate the full EventEmitter API.
Specifically the prependListener(), prependOnceListener(),
rawListeners(), and errorMonitor APIs are not emulated.
The 'newListener' and 'removeListener' events will also not be emitted.
The NodeEventTarget does not implement any special default behavior
for events with type 'error'.
The NodeEventTarget supports EventListener objects as well as
functions as handlers for all event types.


Event listener#
Event listeners registered for an event type may either be JavaScript
functions or objects with a handleEvent property whose value is a function.
In either case, the handler function is invoked with the event argument
passed to the eventTarget.dispatchEvent() function.
Async functions may be used as event listeners. If an async handler function
rejects, the rejection is captured and handled as described in
EventTarget error handling.
An error thrown by one handler function does not prevent the other handlers
from being invoked.
The return value of a handler function is ignored.
Handlers are always invoked in the order they were added.
Handler functions may mutate the event object.
function handler1(event) {
  console.log(event.type);  // Prints 'foo'
  event.a = 1;
}

async function handler2(event) {
  console.log(event.type);  // Prints 'foo'
  console.log(event.a);  // Prints 1
}

const handler3 = {
  handleEvent(event) {
    console.log(event.type);  // Prints 'foo'
  },
};

const handler4 = {
  async handleEvent(event) {
    console.log(event.type);  // Prints 'foo'
  },
};

const target = new EventTarget();

target.addEventListener('foo', handler1);
target.addEventListener('foo', handler2);
target.addEventListener('foo', handler3);
target.addEventListener('foo', handler4, { once: true }); copy

EventTarget error handling#
When a registered event listener throws (or returns a Promise that rejects),
by default the error is treated as an uncaught exception on
process.nextTick(). This means uncaught exceptions in EventTargets will
terminate the Node.js process by default.
Throwing within an event listener will not stop the other registered handlers
from being invoked.
The EventTarget does not implement any special default handling for 'error'
type events like EventEmitter.
Currently errors are first forwarded to the process.on('error') event
before reaching process.on('uncaughtException'). This behavior is
deprecated and will change in a future release to align EventTarget with
other Node.js APIs. Any code relying on the process.on('error') event should
be aligned with the new behavior.

Class: Event#

History

VersionChanges
v15.0.0
The Event class is now available through the global object.
v14.5.0
Added in: v14.5.0



The Event object is an adaptation of the Event Web API. Instances
are created internally by Node.js.

event.bubbles#

Added in: v14.5.0


Type: <boolean> Always returns false.

This is not used in Node.js and is provided purely for completeness.

event.cancelBubble#

Added in: v14.5.0

Stability: 3 - Legacy: Use event.stopPropagation() instead.

Type: <boolean>

Alias for event.stopPropagation() if set to true. This is not used
in Node.js and is provided purely for completeness.

event.cancelable#

Added in: v14.5.0


Type: <boolean> True if the event was created with the cancelable option.


event.composed#

Added in: v14.5.0


Type: <boolean> Always returns false.

This is not used in Node.js and is provided purely for completeness.

event.composedPath()#

Added in: v14.5.0

Returns an array containing the current EventTarget as the only entry or
empty if the event is not being dispatched. This is not used in
Node.js and is provided purely for completeness.

event.currentTarget#

Added in: v14.5.0


Type: <EventTarget> The EventTarget dispatching the event.

Alias for event.target.

event.defaultPrevented#

Added in: v14.5.0


Type: <boolean>

Is true if cancelable is true and event.preventDefault() has been
called.

event.eventPhase#

Added in: v14.5.0


Type: <number> Returns 0 while an event is not being dispatched, 2 while
it is being dispatched.

This is not used in Node.js and is provided purely for completeness.

event.initEvent(type[, bubbles[, cancelable]])#

Added in: v19.5.0

Stability: 3 - Legacy: The WHATWG spec considers it deprecated and users
shouldn't use it at all.

type <string>
bubbles <boolean>
cancelable <boolean>

Redundant with event constructors and incapable of setting composed.
This is not used in Node.js and is provided purely for completeness.

event.isTrusted#

Added in: v14.5.0


Type: <boolean>

The <AbortSignal> "abort" event is emitted with isTrusted set to true. The
value is false in all other cases.

event.preventDefault()#

Added in: v14.5.0

Sets the defaultPrevented property to true if cancelable is true.

event.returnValue#

Added in: v14.5.0

Stability: 3 - Legacy: Use event.defaultPrevented instead.

Type: <boolean> True if the event has not been canceled.

The value of event.returnValue is always the opposite of event.defaultPrevented.
This is not used in Node.js and is provided purely for completeness.

event.srcElement#

Added in: v14.5.0

Stability: 3 - Legacy: Use event.target instead.

Type: <EventTarget> The EventTarget dispatching the event.

Alias for event.target.

event.stopImmediatePropagation()#

Added in: v14.5.0

Stops the invocation of event listeners after the current one completes.

event.stopPropagation()#

Added in: v14.5.0

This is not used in Node.js and is provided purely for completeness.

event.target#

Added in: v14.5.0


Type: <EventTarget> The EventTarget dispatching the event.


event.timeStamp#

Added in: v14.5.0


Type: <number>

The millisecond timestamp when the Event object was created.

event.type#

Added in: v14.5.0


Type: <string>

The event type identifier.

Class: EventTarget#

History

VersionChanges
v15.0.0
The EventTarget class is now available through the global object.
v14.5.0
Added in: v14.5.0




eventTarget.addEventListener(type, listener[, options])#

History

VersionChanges
v15.4.0
add support for signal option.
v14.5.0
Added in: v14.5.0




type <string>
listener <Function> | <EventListener>
options <Object>

once <boolean> When true, the listener is automatically removed
when it is first invoked. Default: false.
passive <boolean> When true, serves as a hint that the listener will
not call the Event object's preventDefault() method.
Default: false.
capture <boolean> Not directly used by Node.js. Added for API
completeness. Default: false.
signal <AbortSignal> The listener will be removed when the given
AbortSignal object's abort() method is called.



Adds a new handler for the type event. Any given listener is added
only once per type and per capture option value.
If the once option is true, the listener is removed after the
next time a type event is dispatched.
The capture option is not used by Node.js in any functional way other than
tracking registered event listeners per the EventTarget specification.
Specifically, the capture option is used as part of the key when registering
a listener. Any individual listener may be added once with
capture = false, and once with capture = true.
function handler(event) {}

const target = new EventTarget();
target.addEventListener('foo', handler, { capture: true });  // first
target.addEventListener('foo', handler, { capture: false }); // second

// Removes the second instance of handler
target.removeEventListener('foo', handler);

// Removes the first instance of handler
target.removeEventListener('foo', handler, { capture: true }); copy

eventTarget.dispatchEvent(event)#

Added in: v14.5.0


event <Event>
Returns: <boolean> true if either event's cancelable attribute value is
false or its preventDefault() method was not invoked, otherwise false.

Dispatches the event to the list of handlers for event.type.
The registered event listeners is synchronously invoked in the order they
were registered.

eventTarget.removeEventListener(type, listener[, options])#

Added in: v14.5.0


type <string>
listener <Function> | <EventListener>
options <Object>

capture <boolean>



Removes the listener from the list of handlers for event type.

Class: CustomEvent#

History

VersionChanges
v23.0.0
No longer experimental.
v22.1.0, v20.13.0
CustomEvent is now stable.
v19.0.0
No longer behind --experimental-global-customevent CLI flag.
v18.7.0, v16.17.0
Added in: v18.7.0, v16.17.0




Extends: <Event>

The CustomEvent object is an adaptation of the CustomEvent Web API.
Instances are created internally by Node.js.

event.detail#

History

VersionChanges
v22.1.0, v20.13.0
CustomEvent is now stable.
v18.7.0, v16.17.0
Added in: v18.7.0, v16.17.0




Type: <any> Returns custom data passed when initializing.

Read-only.

Class: NodeEventTarget#

Added in: v14.5.0


Extends: <EventTarget>

The NodeEventTarget is a Node.js-specific extension to EventTarget
that emulates a subset of the EventEmitter API.

nodeEventTarget.addListener(type, listener)#

Added in: v14.5.0



type <string>


listener <Function> | <EventListener>


Returns: <EventTarget> this


Node.js-specific extension to the EventTarget class that emulates the
equivalent EventEmitter API. The only difference between addListener() and
addEventListener() is that addListener() will return a reference to the
EventTarget.

nodeEventTarget.emit(type, arg)#

Added in: v15.2.0


type <string>
arg <any>
Returns: <boolean> true if event listeners registered for the type exist,
otherwise false.

Node.js-specific extension to the EventTarget class that dispatches the
arg to the list of handlers for type.

nodeEventTarget.eventNames()#

Added in: v14.5.0


Returns: <string[]>

Node.js-specific extension to the EventTarget class that returns an array
of event type names for which event listeners are registered.

nodeEventTarget.listenerCount(type)#

Added in: v14.5.0



type <string>


Returns: <number>


Node.js-specific extension to the EventTarget class that returns the number
of event listeners registered for the type.

nodeEventTarget.setMaxListeners(n)#

Added in: v14.5.0


n <number>

Node.js-specific extension to the EventTarget class that sets the number
of max event listeners as n.

nodeEventTarget.getMaxListeners()#

Added in: v14.5.0


Returns: <number>

Node.js-specific extension to the EventTarget class that returns the number
of max event listeners.

nodeEventTarget.off(type, listener[, options])#

Added in: v14.5.0



type <string>


listener <Function> | <EventListener>


options <Object>

capture <boolean>



Returns: <EventTarget> this


Node.js-specific alias for eventTarget.removeEventListener().

nodeEventTarget.on(type, listener)#

Added in: v14.5.0



type <string>


listener <Function> | <EventListener>


Returns: <EventTarget> this


Node.js-specific alias for eventTarget.addEventListener().

nodeEventTarget.once(type, listener)#

Added in: v14.5.0



type <string>


listener <Function> | <EventListener>


Returns: <EventTarget> this


Node.js-specific extension to the EventTarget class that adds a once
listener for the given event type. This is equivalent to calling on
with the once option set to true.

nodeEventTarget.removeAllListeners([type])#

Added in: v14.5.0



type <string>


Returns: <EventTarget> this


Node.js-specific extension to the EventTarget class. If type is specified,
removes all registered listeners for type, otherwise removes all registered
listeners.

nodeEventTarget.removeListener(type, listener[, options])#

Added in: v14.5.0



type <string>


listener <Function> | <EventListener>


options <Object>

capture <boolean>



Returns: <EventTarget> this


Node.js-specific extension to the EventTarget class that removes the
listener for the given type. The only difference between removeListener()
and removeEventListener() is that removeListener() will return a reference
to the EventTarget.\n\n\n\nNode.js
        
      
      
About this documentation
Usage and example



Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Modules: TypeScript
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
Readline
REPL
Report
Single executable applications
SQLite
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker

    

    
      
        
          Node.js v24.0.1 documentation
          
            
            
          
        
        
          
            Node.js v24.0.1
            
    
      
        
        Table of contents
      

      
File system

Promise example
Callback example
Synchronous example
Promises API

Class: FileHandle

Event: 'close'
filehandle.appendFile(data[, options])
filehandle.chmod(mode)
filehandle.chown(uid, gid)
filehandle.close()
filehandle.createReadStream([options])
filehandle.createWriteStream([options])
filehandle.datasync()
filehandle.fd
filehandle.read(buffer, offset, length, position)
filehandle.read([options])
filehandle.read(buffer[, options])
filehandle.readableWebStream()
filehandle.readFile(options)
filehandle.readLines([options])
filehandle.readv(buffers[, position])
filehandle.stat([options])
filehandle.sync()
filehandle.truncate(len)
filehandle.utimes(atime, mtime)
filehandle.write(buffer, offset[, length[, position]])
filehandle.write(buffer[, options])
filehandle.write(string[, position[, encoding]])
filehandle.writeFile(data, options)
filehandle.writev(buffers[, position])
filehandle[Symbol.asyncDispose]()


fsPromises.access(path[, mode])
fsPromises.appendFile(path, data[, options])
fsPromises.chmod(path, mode)
fsPromises.chown(path, uid, gid)
fsPromises.copyFile(src, dest[, mode])
fsPromises.cp(src, dest[, options])
fsPromises.glob(pattern[, options])
fsPromises.lchmod(path, mode)
fsPromises.lchown(path, uid, gid)
fsPromises.lutimes(path, atime, mtime)
fsPromises.link(existingPath, newPath)
fsPromises.lstat(path[, options])
fsPromises.mkdir(path[, options])
fsPromises.mkdtemp(prefix[, options])
fsPromises.open(path, flags[, mode])
fsPromises.opendir(path[, options])
fsPromises.readdir(path[, options])
fsPromises.readFile(path[, options])
fsPromises.readlink(path[, options])
fsPromises.realpath(path[, options])
fsPromises.rename(oldPath, newPath)
fsPromises.rmdir(path[, options])
fsPromises.rm(path[, options])
fsPromises.stat(path[, options])
fsPromises.statfs(path[, options])
fsPromises.symlink(target, path[, type])
fsPromises.truncate(path[, len])
fsPromises.unlink(path)
fsPromises.utimes(path, atime, mtime)
fsPromises.watch(filename[, options])
fsPromises.writeFile(file, data[, options])
fsPromises.constants


Callback API

fs.access(path[, mode], callback)
fs.appendFile(path, data[, options], callback)
fs.chmod(path, mode, callback)

File modes


fs.chown(path, uid, gid, callback)
fs.close(fd[, callback])
fs.copyFile(src, dest[, mode], callback)
fs.cp(src, dest[, options], callback)
fs.createReadStream(path[, options])
fs.createWriteStream(path[, options])
fs.exists(path, callback)
fs.fchmod(fd, mode, callback)
fs.fchown(fd, uid, gid, callback)
fs.fdatasync(fd, callback)
fs.fstat(fd[, options], callback)
fs.fsync(fd, callback)
fs.ftruncate(fd[, len], callback)
fs.futimes(fd, atime, mtime, callback)
fs.glob(pattern[, options], callback)
fs.lchmod(path, mode, callback)
fs.lchown(path, uid, gid, callback)
fs.lutimes(path, atime, mtime, callback)
fs.link(existingPath, newPath, callback)
fs.lstat(path[, options], callback)
fs.mkdir(path[, options], callback)
fs.mkdtemp(prefix[, options], callback)
fs.open(path[, flags[, mode]], callback)
fs.openAsBlob(path[, options])
fs.opendir(path[, options], callback)
fs.read(fd, buffer, offset, length, position, callback)
fs.read(fd[, options], callback)
fs.read(fd, buffer[, options], callback)
fs.readdir(path[, options], callback)
fs.readFile(path[, options], callback)

File descriptors
Performance Considerations


fs.readlink(path[, options], callback)
fs.readv(fd, buffers[, position], callback)
fs.realpath(path[, options], callback)
fs.realpath.native(path[, options], callback)
fs.rename(oldPath, newPath, callback)
fs.rmdir(path[, options], callback)
fs.rm(path[, options], callback)
fs.stat(path[, options], callback)
fs.statfs(path[, options], callback)
fs.symlink(target, path[, type], callback)
fs.truncate(path[, len], callback)
fs.unlink(path, callback)
fs.unwatchFile(filename[, listener])
fs.utimes(path, atime, mtime, callback)
fs.watch(filename[, options][, listener])

Caveats

Availability
Inodes
Filename argument




fs.watchFile(filename[, options], listener)
fs.write(fd, buffer, offset[, length[, position]], callback)
fs.write(fd, buffer[, options], callback)
fs.write(fd, string[, position[, encoding]], callback)
fs.writeFile(file, data[, options], callback)

Using fs.writeFile() with file descriptors


fs.writev(fd, buffers[, position], callback)


Synchronous API

fs.accessSync(path[, mode])
fs.appendFileSync(path, data[, options])
fs.chmodSync(path, mode)
fs.chownSync(path, uid, gid)
fs.closeSync(fd)
fs.copyFileSync(src, dest[, mode])
fs.cpSync(src, dest[, options])
fs.existsSync(path)
fs.fchmodSync(fd, mode)
fs.fchownSync(fd, uid, gid)
fs.fdatasyncSync(fd)
fs.fstatSync(fd[, options])
fs.fsyncSync(fd)
fs.ftruncateSync(fd[, len])
fs.futimesSync(fd, atime, mtime)
fs.globSync(pattern[, options])
fs.lchmodSync(path, mode)
fs.lchownSync(path, uid, gid)
fs.lutimesSync(path, atime, mtime)
fs.linkSync(existingPath, newPath)
fs.lstatSync(path[, options])
fs.mkdirSync(path[, options])
fs.mkdtempSync(prefix[, options])
fs.opendirSync(path[, options])
fs.openSync(path[, flags[, mode]])
fs.readdirSync(path[, options])
fs.readFileSync(path[, options])
fs.readlinkSync(path[, options])
fs.readSync(fd, buffer, offset, length[, position])
fs.readSync(fd, buffer[, options])
fs.readvSync(fd, buffers[, position])
fs.realpathSync(path[, options])
fs.realpathSync.native(path[, options])
fs.renameSync(oldPath, newPath)
fs.rmdirSync(path[, options])
fs.rmSync(path[, options])
fs.statSync(path[, options])
fs.statfsSync(path[, options])
fs.symlinkSync(target, path[, type])
fs.truncateSync(path[, len])
fs.unlinkSync(path)
fs.utimesSync(path, atime, mtime)
fs.writeFileSync(file, data[, options])
fs.writeSync(fd, buffer, offset[, length[, position]])
fs.writeSync(fd, buffer[, options])
fs.writeSync(fd, string[, position[, encoding]])
fs.writevSync(fd, buffers[, position])


Common Objects

Class: fs.Dir

dir.close()
dir.close(callback)
dir.closeSync()
dir.path
dir.read()
dir.read(callback)
dir.readSync()
dir[Symbol.asyncIterator]()


Class: fs.Dirent

dirent.isBlockDevice()
dirent.isCharacterDevice()
dirent.isDirectory()
dirent.isFIFO()
dirent.isFile()
dirent.isSocket()
dirent.isSymbolicLink()
dirent.name
dirent.parentPath


Class: fs.FSWatcher

Event: 'change'
Event: 'close'
Event: 'error'
watcher.close()
watcher.ref()
watcher.unref()


Class: fs.StatWatcher

watcher.ref()
watcher.unref()


Class: fs.ReadStream

Event: 'close'
Event: 'open'
Event: 'ready'
readStream.bytesRead
readStream.path
readStream.pending


Class: fs.Stats

stats.isBlockDevice()
stats.isCharacterDevice()
stats.isDirectory()
stats.isFIFO()
stats.isFile()
stats.isSocket()
stats.isSymbolicLink()
stats.dev
stats.ino
stats.mode
stats.nlink
stats.uid
stats.gid
stats.rdev
stats.size
stats.blksize
stats.blocks
stats.atimeMs
stats.mtimeMs
stats.ctimeMs
stats.birthtimeMs
stats.atimeNs
stats.mtimeNs
stats.ctimeNs
stats.birthtimeNs
stats.atime
stats.mtime
stats.ctime
stats.birthtime
Stat time values


Class: fs.StatFs

statfs.bavail
statfs.bfree
statfs.blocks
statfs.bsize
statfs.ffree
statfs.files
statfs.type


Class: fs.WriteStream

Event: 'close'
Event: 'open'
Event: 'ready'
writeStream.bytesWritten
writeStream.close([callback])
writeStream.path
writeStream.pending


fs.constants

FS constants

File access constants
File copy constants
File open constants
File type constants
File mode constants






Notes

Ordering of callback and promise-based operations
File paths

String paths
File URL paths

Platform-specific considerations


Buffer paths
Per-drive working directories on Windows


File descriptors
Threadpool usage
File system flags





    
  
            
    
      
        
        Index
      

      
About this documentation
Usage and example

      
        Index
      
    
  


Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Modules: TypeScript
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
Readline
REPL
Report
Single executable applications
SQLite
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker

    
  
            
    
      
        
        Other versions
      
      24.x
23.x
22.x LTS
21.x
20.x LTS
19.x
18.x
17.x
16.x
15.x
14.x
13.x
12.x
11.x
10.x
9.x
8.x
7.x
6.x
5.x
4.x
0.12.x
0.10.x
    
  
            
              
                
                Options
              
        
              
                
                  
                    View on single page
                  
                  
                    View as JSON
                  
                  Edit on GitHub    
                
              
            
          
        
        
      

      Table of contents
File system

Promise example
Callback example
Synchronous example
Promises API

Class: FileHandle

Event: 'close'
filehandle.appendFile(data[, options])
filehandle.chmod(mode)
filehandle.chown(uid, gid)
filehandle.close()
filehandle.createReadStream([options])
filehandle.createWriteStream([options])
filehandle.datasync()
filehandle.fd
filehandle.read(buffer, offset, length, position)
filehandle.read([options])
filehandle.read(buffer[, options])
filehandle.readableWebStream()
filehandle.readFile(options)
filehandle.readLines([options])
filehandle.readv(buffers[, position])
filehandle.stat([options])
filehandle.sync()
filehandle.truncate(len)
filehandle.utimes(atime, mtime)
filehandle.write(buffer, offset[, length[, position]])
filehandle.write(buffer[, options])
filehandle.write(string[, position[, encoding]])
filehandle.writeFile(data, options)
filehandle.writev(buffers[, position])
filehandle[Symbol.asyncDispose]()


fsPromises.access(path[, mode])
fsPromises.appendFile(path, data[, options])
fsPromises.chmod(path, mode)
fsPromises.chown(path, uid, gid)
fsPromises.copyFile(src, dest[, mode])
fsPromises.cp(src, dest[, options])
fsPromises.glob(pattern[, options])
fsPromises.lchmod(path, mode)
fsPromises.lchown(path, uid, gid)
fsPromises.lutimes(path, atime, mtime)
fsPromises.link(existingPath, newPath)
fsPromises.lstat(path[, options])
fsPromises.mkdir(path[, options])
fsPromises.mkdtemp(prefix[, options])
fsPromises.open(path, flags[, mode])
fsPromises.opendir(path[, options])
fsPromises.readdir(path[, options])
fsPromises.readFile(path[, options])
fsPromises.readlink(path[, options])
fsPromises.realpath(path[, options])
fsPromises.rename(oldPath, newPath)
fsPromises.rmdir(path[, options])
fsPromises.rm(path[, options])
fsPromises.stat(path[, options])
fsPromises.statfs(path[, options])
fsPromises.symlink(target, path[, type])
fsPromises.truncate(path[, len])
fsPromises.unlink(path)
fsPromises.utimes(path, atime, mtime)
fsPromises.watch(filename[, options])
fsPromises.writeFile(file, data[, options])
fsPromises.constants


Callback API

fs.access(path[, mode], callback)
fs.appendFile(path, data[, options], callback)
fs.chmod(path, mode, callback)

File modes


fs.chown(path, uid, gid, callback)
fs.close(fd[, callback])
fs.copyFile(src, dest[, mode], callback)
fs.cp(src, dest[, options], callback)
fs.createReadStream(path[, options])
fs.createWriteStream(path[, options])
fs.exists(path, callback)
fs.fchmod(fd, mode, callback)
fs.fchown(fd, uid, gid, callback)
fs.fdatasync(fd, callback)
fs.fstat(fd[, options], callback)
fs.fsync(fd, callback)
fs.ftruncate(fd[, len], callback)
fs.futimes(fd, atime, mtime, callback)
fs.glob(pattern[, options], callback)
fs.lchmod(path, mode, callback)
fs.lchown(path, uid, gid, callback)
fs.lutimes(path, atime, mtime, callback)
fs.link(existingPath, newPath, callback)
fs.lstat(path[, options], callback)
fs.mkdir(path[, options], callback)
fs.mkdtemp(prefix[, options], callback)
fs.open(path[, flags[, mode]], callback)
fs.openAsBlob(path[, options])
fs.opendir(path[, options], callback)
fs.read(fd, buffer, offset, length, position, callback)
fs.read(fd[, options], callback)
fs.read(fd, buffer[, options], callback)
fs.readdir(path[, options], callback)
fs.readFile(path[, options], callback)

File descriptors
Performance Considerations


fs.readlink(path[, options], callback)
fs.readv(fd, buffers[, position], callback)
fs.realpath(path[, options], callback)
fs.realpath.native(path[, options], callback)
fs.rename(oldPath, newPath, callback)
fs.rmdir(path[, options], callback)
fs.rm(path[, options], callback)
fs.stat(path[, options], callback)
fs.statfs(path[, options], callback)
fs.symlink(target, path[, type], callback)
fs.truncate(path[, len], callback)
fs.unlink(path, callback)
fs.unwatchFile(filename[, listener])
fs.utimes(path, atime, mtime, callback)
fs.watch(filename[, options][, listener])

Caveats

Availability
Inodes
Filename argument




fs.watchFile(filename[, options], listener)
fs.write(fd, buffer, offset[, length[, position]], callback)
fs.write(fd, buffer[, options], callback)
fs.write(fd, string[, position[, encoding]], callback)
fs.writeFile(file, data[, options], callback)

Using fs.writeFile() with file descriptors


fs.writev(fd, buffers[, position], callback)


Synchronous API

fs.accessSync(path[, mode])
fs.appendFileSync(path, data[, options])
fs.chmodSync(path, mode)
fs.chownSync(path, uid, gid)
fs.closeSync(fd)
fs.copyFileSync(src, dest[, mode])
fs.cpSync(src, dest[, options])
fs.existsSync(path)
fs.fchmodSync(fd, mode)
fs.fchownSync(fd, uid, gid)
fs.fdatasyncSync(fd)
fs.fstatSync(fd[, options])
fs.fsyncSync(fd)
fs.ftruncateSync(fd[, len])
fs.futimesSync(fd, atime, mtime)
fs.globSync(pattern[, options])
fs.lchmodSync(path, mode)
fs.lchownSync(path, uid, gid)
fs.lutimesSync(path, atime, mtime)
fs.linkSync(existingPath, newPath)
fs.lstatSync(path[, options])
fs.mkdirSync(path[, options])
fs.mkdtempSync(prefix[, options])
fs.opendirSync(path[, options])
fs.openSync(path[, flags[, mode]])
fs.readdirSync(path[, options])
fs.readFileSync(path[, options])
fs.readlinkSync(path[, options])
fs.readSync(fd, buffer, offset, length[, position])
fs.readSync(fd, buffer[, options])
fs.readvSync(fd, buffers[, position])
fs.realpathSync(path[, options])
fs.realpathSync.native(path[, options])
fs.renameSync(oldPath, newPath)
fs.rmdirSync(path[, options])
fs.rmSync(path[, options])
fs.statSync(path[, options])
fs.statfsSync(path[, options])
fs.symlinkSync(target, path[, type])
fs.truncateSync(path[, len])
fs.unlinkSync(path)
fs.utimesSync(path, atime, mtime)
fs.writeFileSync(file, data[, options])
fs.writeSync(fd, buffer, offset[, length[, position]])
fs.writeSync(fd, buffer[, options])
fs.writeSync(fd, string[, position[, encoding]])
fs.writevSync(fd, buffers[, position])


Common Objects

Class: fs.Dir

dir.close()
dir.close(callback)
dir.closeSync()
dir.path
dir.read()
dir.read(callback)
dir.readSync()
dir[Symbol.asyncIterator]()


Class: fs.Dirent

dirent.isBlockDevice()
dirent.isCharacterDevice()
dirent.isDirectory()
dirent.isFIFO()
dirent.isFile()
dirent.isSocket()
dirent.isSymbolicLink()
dirent.name
dirent.parentPath


Class: fs.FSWatcher

Event: 'change'
Event: 'close'
Event: 'error'
watcher.close()
watcher.ref()
watcher.unref()


Class: fs.StatWatcher

watcher.ref()
watcher.unref()


Class: fs.ReadStream

Event: 'close'
Event: 'open'
Event: 'ready'
readStream.bytesRead
readStream.path
readStream.pending


Class: fs.Stats

stats.isBlockDevice()
stats.isCharacterDevice()
stats.isDirectory()
stats.isFIFO()
stats.isFile()
stats.isSocket()
stats.isSymbolicLink()
stats.dev
stats.ino
stats.mode
stats.nlink
stats.uid
stats.gid
stats.rdev
stats.size
stats.blksize
stats.blocks
stats.atimeMs
stats.mtimeMs
stats.ctimeMs
stats.birthtimeMs
stats.atimeNs
stats.mtimeNs
stats.ctimeNs
stats.birthtimeNs
stats.atime
stats.mtime
stats.ctime
stats.birthtime
Stat time values


Class: fs.StatFs

statfs.bavail
statfs.bfree
statfs.blocks
statfs.bsize
statfs.ffree
statfs.files
statfs.type


Class: fs.WriteStream

Event: 'close'
Event: 'open'
Event: 'ready'
writeStream.bytesWritten
writeStream.close([callback])
writeStream.path
writeStream.pending


fs.constants

FS constants

File access constants
File copy constants
File open constants
File type constants
File mode constants






Notes

Ordering of callback and promise-based operations
File paths

String paths
File URL paths

Platform-specific considerations


Buffer paths
Per-drive working directories on Windows


File descriptors
Threadpool usage
File system flags






      
        File system#

Stability: 2 - Stable

Source Code: lib/fs.js
The node:fs module enables interacting with the file system in a
way modeled on standard POSIX functions.
To use the promise-based APIs:

import * as fs from 'node:fs/promises';const fs = require('node:fs/promises');copy
To use the callback and sync APIs:

import * as fs from 'node:fs';const fs = require('node:fs');copy
All file system operations have synchronous, callback, and promise-based
forms, and are accessible using both CommonJS syntax and ES6 Modules (ESM).
Promise example#
Promise-based operations return a promise that is fulfilled when the
asynchronous operation is complete.

import { unlink } from 'node:fs/promises';

try {
  await unlink('/tmp/hello');
  console.log('successfully deleted /tmp/hello');
} catch (error) {
  console.error('there was an error:', error.message);
}const { unlink } = require('node:fs/promises');

(async function(path) {
  try {
    await unlink(path);
    console.log(`successfully deleted ${path}`);
  } catch (error) {
    console.error('there was an error:', error.message);
  }
})('/tmp/hello');copy
Callback example#
The callback form takes a completion callback function as its last
argument and invokes the operation asynchronously. The arguments passed to
the completion callback depend on the method, but the first argument is always
reserved for an exception. If the operation is completed successfully, then
the first argument is null or undefined.

import { unlink } from 'node:fs';

unlink('/tmp/hello', (err) => {
  if (err) throw err;
  console.log('successfully deleted /tmp/hello');
});const { unlink } = require('node:fs');

unlink('/tmp/hello', (err) => {
  if (err) throw err;
  console.log('successfully deleted /tmp/hello');
});copy
The callback-based versions of the node:fs module APIs are preferable over
the use of the promise APIs when maximal performance (both in terms of
execution time and memory allocation) is required.
Synchronous example#
The synchronous APIs block the Node.js event loop and further JavaScript
execution until the operation is complete. Exceptions are thrown immediately
and can be handled using try…catch, or can be allowed to bubble up.

import { unlinkSync } from 'node:fs';

try {
  unlinkSync('/tmp/hello');
  console.log('successfully deleted /tmp/hello');
} catch (err) {
  // handle the error
}const { unlinkSync } = require('node:fs');

try {
  unlinkSync('/tmp/hello');
  console.log('successfully deleted /tmp/hello');
} catch (err) {
  // handle the error
}copy
Promises API#

History

VersionChanges
v14.0.0
Exposed as require('fs/promises').
v11.14.0, v10.17.0
This API is no longer experimental.
v10.1.0
The API is accessible via require('fs').promises only.
v10.0.0
Added in: v10.0.0



The fs/promises API provides asynchronous file system methods that return
promises.
The promise APIs use the underlying Node.js threadpool to perform file
system operations off the event loop thread. These operations are not
synchronized or threadsafe. Care must be taken when performing multiple
concurrent modifications on the same file or data corruption may occur.

Class: FileHandle#

Added in: v10.0.0

A <FileHandle> object is an object wrapper for a numeric file descriptor.
Instances of the <FileHandle> object are created by the fsPromises.open()
method.
All <FileHandle> objects are <EventEmitter>s.
If a <FileHandle> is not closed using the filehandle.close() method, it will
try to automatically close the file descriptor and emit a process warning,
helping to prevent memory leaks. Please do not rely on this behavior because
it can be unreliable and the file may not be closed. Instead, always explicitly
close <FileHandle>s. Node.js may change this behavior in the future.

Event: 'close'#

Added in: v15.4.0

The 'close' event is emitted when the <FileHandle> has been closed and can no
longer be used.

filehandle.appendFile(data[, options])#

History

VersionChanges
v21.1.0, v20.10.0
The flush option is now supported.
v15.14.0, v14.18.0
The data argument supports AsyncIterable, Iterable, and Stream.
v14.0.0
The data parameter won't coerce unsupported input to strings anymore.
v10.0.0
Added in: v10.0.0




data <string> | <Buffer> | <TypedArray> | <DataView> | <AsyncIterable> | <Iterable> | <Stream>
options <Object> | <string>

encoding <string> | <null> Default: 'utf8'
signal <AbortSignal> | <undefined> allows aborting an in-progress writeFile. Default: undefined


Returns: <Promise> Fulfills with undefined upon success.

Alias of filehandle.writeFile().
When operating on file handles, the mode cannot be changed from what it was set
to with fsPromises.open(). Therefore, this is equivalent to
filehandle.writeFile().

filehandle.chmod(mode)#

Added in: v10.0.0


mode <integer> the file mode bit mask.
Returns: <Promise> Fulfills with undefined upon success.

Modifies the permissions on the file. See chmod(2).

filehandle.chown(uid, gid)#

Added in: v10.0.0


uid <integer> The file's new owner's user id.
gid <integer> The file's new group's group id.
Returns: <Promise> Fulfills with undefined upon success.

Changes the ownership of the file. A wrapper for chown(2).

filehandle.close()#

Added in: v10.0.0


Returns: <Promise> Fulfills with undefined upon success.

Closes the file handle after waiting for any pending operation on the handle to
complete.
import { open } from 'node:fs/promises';

let filehandle;
try {
  filehandle = await open('thefile.txt', 'r');
} finally {
  await filehandle?.close();
} copy

filehandle.createReadStream([options])#

Added in: v16.11.0


options <Object>

encoding <string> Default: null
autoClose <boolean> Default: true
emitClose <boolean> Default: true
start <integer>
end <integer> Default: Infinity
highWaterMark <integer> Default: 64 * 1024
signal <AbortSignal> | <undefined> Default: undefined


Returns: <fs.ReadStream>

options can include start and end values to read a range of bytes from
the file instead of the entire file. Both start and end are inclusive and
start counting at 0, allowed values are in the
[0, Number.MAX_SAFE_INTEGER] range. If start is
omitted or undefined, filehandle.createReadStream() reads sequentially from
the current file position. The encoding can be any one of those accepted by
<Buffer>.
If the FileHandle points to a character device that only supports blocking
reads (such as keyboard or sound card), read operations do not finish until data
is available. This can prevent the process from exiting and the stream from
closing naturally.
By default, the stream will emit a 'close' event after it has been
destroyed.  Set the emitClose option to false to change this behavior.
import { open } from 'node:fs/promises';

const fd = await open('/dev/input/event0');
// Create a stream from some character device.
const stream = fd.createReadStream();
setTimeout(() => {
  stream.close(); // This may not close the stream.
  // Artificially marking end-of-stream, as if the underlying resource had
  // indicated end-of-file by itself, allows the stream to close.
  // This does not cancel pending read operations, and if there is such an
  // operation, the process may still not be able to exit successfully
  // until it finishes.
  stream.push(null);
  stream.read(0);
}, 100); copy
If autoClose is false, then the file descriptor won't be closed, even if
there's an error. It is the application's responsibility to close it and make
sure there's no file descriptor leak. If autoClose is set to true (default
behavior), on 'error' or 'end' the file descriptor will be closed
automatically.
An example to read the last 10 bytes of a file which is 100 bytes long:
import { open } from 'node:fs/promises';

const fd = await open('sample.txt');
fd.createReadStream({ start: 90, end: 99 }); copy

filehandle.createWriteStream([options])#

History

VersionChanges
v21.0.0, v20.10.0
The flush option is now supported.
v16.11.0
Added in: v16.11.0




options <Object>

encoding <string> Default: 'utf8'
autoClose <boolean> Default: true
emitClose <boolean> Default: true
start <integer>
highWaterMark <number> Default: 16384
flush <boolean> If true, the underlying file descriptor is flushed
prior to closing it. Default: false.


Returns: <fs.WriteStream>

options may also include a start option to allow writing data at some
position past the beginning of the file, allowed values are in the
[0, Number.MAX_SAFE_INTEGER] range. Modifying a file rather than
replacing it may require the flags open option to be set to r+ rather than
the default r. The encoding can be any one of those accepted by <Buffer>.
If autoClose is set to true (default behavior) on 'error' or 'finish'
the file descriptor will be closed automatically. If autoClose is false,
then the file descriptor won't be closed, even if there's an error.
It is the application's responsibility to close it and make sure there's no
file descriptor leak.
By default, the stream will emit a 'close' event after it has been
destroyed.  Set the emitClose option to false to change this behavior.

filehandle.datasync()#

Added in: v10.0.0


Returns: <Promise> Fulfills with undefined upon success.

Forces all currently queued I/O operations associated with the file to the
operating system's synchronized I/O completion state. Refer to the POSIX
fdatasync(2) documentation for details.
Unlike filehandle.sync this method does not flush modified metadata.

filehandle.fd#

Added in: v10.0.0


<number> The numeric file descriptor managed by the <FileHandle> object.


filehandle.read(buffer, offset, length, position)#

History

VersionChanges
v21.0.0
Accepts bigint values as position.
v10.0.0
Added in: v10.0.0




buffer <Buffer> | <TypedArray> | <DataView> A buffer that will be filled with the
file data read.
offset <integer> The location in the buffer at which to start filling.
Default: 0
length <integer> The number of bytes to read. Default:
buffer.byteLength - offset
position <integer> | <bigint> | <null> The location where to begin reading data
from the file. If null or -1, data will be read from the current file
position, and the position will be updated. If position is a non-negative
integer, the current file position will remain unchanged.
Default:: null
Returns: <Promise> Fulfills upon success with an object with two properties:

bytesRead <integer> The number of bytes read
buffer <Buffer> | <TypedArray> | <DataView> A reference to the passed in buffer
argument.



Reads data from the file and stores that in the given buffer.
If the file is not modified concurrently, the end-of-file is reached when the
number of bytes read is zero.

filehandle.read([options])#

History

VersionChanges
v21.0.0
Accepts bigint values as position.
v13.11.0, v12.17.0
Added in: v13.11.0, v12.17.0




options <Object>

buffer <Buffer> | <TypedArray> | <DataView> A buffer that will be filled with the
file data read. Default: Buffer.alloc(16384)
offset <integer> The location in the buffer at which to start filling.
Default: 0
length <integer> The number of bytes to read. Default:
buffer.byteLength - offset
position <integer> | <bigint> | <null> The location where to begin reading data
from the file. If null or -1, data will be read from the current file
position, and the position will be updated. If position is a non-negative
integer, the current file position will remain unchanged.
Default:: null


Returns: <Promise> Fulfills upon success with an object with two properties:

bytesRead <integer> The number of bytes read
buffer <Buffer> | <TypedArray> | <DataView> A reference to the passed in buffer
argument.



Reads data from the file and stores that in the given buffer.
If the file is not modified concurrently, the end-of-file is reached when the
number of bytes read is zero.

filehandle.read(buffer[, options])#

History

VersionChanges
v21.0.0
Accepts bigint values as position.
v18.2.0, v16.17.0
Added in: v18.2.0, v16.17.0




buffer <Buffer> | <TypedArray> | <DataView> A buffer that will be filled with the
file data read.
options <Object>

offset <integer> The location in the buffer at which to start filling.
Default: 0
length <integer> The number of bytes to read. Default:
buffer.byteLength - offset
position <integer> | <bigint> | <null> The location where to begin reading data
from the file. If null or -1, data will be read from the current file
position, and the position will be updated. If position is a non-negative
integer, the current file position will remain unchanged.
Default:: null


Returns: <Promise> Fulfills upon success with an object with two properties:

bytesRead <integer> The number of bytes read
buffer <Buffer> | <TypedArray> | <DataView> A reference to the passed in buffer
argument.



Reads data from the file and stores that in the given buffer.
If the file is not modified concurrently, the end-of-file is reached when the
number of bytes read is zero.

filehandle.readableWebStream()#

History

VersionChanges
v24.0.0
Marking the API stable.
v23.8.0, v22.15.0
Removed option to create a 'bytes' stream. Streams are now always 'bytes' streams.
v20.0.0, v18.17.0
Added option to create a 'bytes' stream.
v17.0.0
Added in: v17.0.0




Returns: <ReadableStream>

Returns a byte-oriented ReadableStream that may be used to read the file's
contents.
An error will be thrown if this method is called more than once or is called
after the FileHandle is closed or closing.

import {
  open,
} from 'node:fs/promises';

const file = await open('./some/file/to/read');

for await (const chunk of file.readableWebStream())
  console.log(chunk);

await file.close();const {
  open,
} = require('node:fs/promises');

(async () => {
  const file = await open('./some/file/to/read');

  for await (const chunk of file.readableWebStream())
    console.log(chunk);

  await file.close();
})();copy
While the ReadableStream will read the file to completion, it will not
close the FileHandle automatically. User code must still call the
fileHandle.close() method.

filehandle.readFile(options)#

Added in: v10.0.0


options <Object> | <string>

encoding <string> | <null> Default: null
signal <AbortSignal> allows aborting an in-progress readFile


Returns: <Promise> Fulfills upon a successful read with the contents of the
file. If no encoding is specified (using options.encoding), the data is
returned as a <Buffer> object. Otherwise, the data will be a string.

Asynchronously reads the entire contents of a file.
If options is a string, then it specifies the encoding.
The <FileHandle> has to support reading.
If one or more filehandle.read() calls are made on a file handle and then a
filehandle.readFile() call is made, the data will be read from the current
position till the end of the file. It doesn't always read from the beginning
of the file.

filehandle.readLines([options])#

Added in: v18.11.0


options <Object>

encoding <string> Default: null
autoClose <boolean> Default: true
emitClose <boolean> Default: true
start <integer>
end <integer> Default: Infinity
highWaterMark <integer> Default: 64 * 1024


Returns: <readline.InterfaceConstructor>

Convenience method to create a readline interface and stream over the file.
See filehandle.createReadStream() for the options.

import { open } from 'node:fs/promises';

const file = await open('./some/file/to/read');

for await (const line of file.readLines()) {
  console.log(line);
}const { open } = require('node:fs/promises');

(async () => {
  const file = await open('./some/file/to/read');

  for await (const line of file.readLines()) {
    console.log(line);
  }
})();copy

filehandle.readv(buffers[, position])#

Added in: v13.13.0, v12.17.0


buffers <Buffer[]> | <TypedArray[]> | <DataView[]>
position <integer> | <null> The offset from the beginning of the file where
the data should be read from. If position is not a number, the data will
be read from the current position. Default: null
Returns: <Promise> Fulfills upon success an object containing two properties:

bytesRead <integer> the number of bytes read
buffers <Buffer[]> | <TypedArray[]> | <DataView[]> property containing
a reference to the buffers input.



Read from a file and write to an array of <ArrayBufferView>s

filehandle.stat([options])#

History

VersionChanges
v10.5.0
Accepts an additional options object to specify whether the numeric values returned should be bigint.
v10.0.0
Added in: v10.0.0




options <Object>

bigint <boolean> Whether the numeric values in the returned
<fs.Stats> object should be bigint. Default: false.


Returns: <Promise> Fulfills with an <fs.Stats> for the file.


filehandle.sync()#

Added in: v10.0.0


Returns: <Promise> Fulfills with undefined upon success.

Request that all data for the open file descriptor is flushed to the storage
device. The specific implementation is operating system and device specific.
Refer to the POSIX fsync(2) documentation for more detail.

filehandle.truncate(len)#

Added in: v10.0.0


len <integer> Default: 0
Returns: <Promise> Fulfills with undefined upon success.

Truncates the file.
If the file was larger than len bytes, only the first len bytes will be
retained in the file.
The following example retains only the first four bytes of the file:
import { open } from 'node:fs/promises';

let filehandle = null;
try {
  filehandle = await open('temp.txt', 'r+');
  await filehandle.truncate(4);
} finally {
  await filehandle?.close();
} copy
If the file previously was shorter than len bytes, it is extended, and the
extended part is filled with null bytes ('\0'):
If len is negative then 0 will be used.

filehandle.utimes(atime, mtime)#

Added in: v10.0.0


atime <number> | <string> | <Date>
mtime <number> | <string> | <Date>
Returns: <Promise>

Change the file system timestamps of the object referenced by the <FileHandle>
then fulfills the promise with no arguments upon success.

filehandle.write(buffer, offset[, length[, position]])#

History

VersionChanges
v14.0.0
The buffer parameter won't coerce unsupported input to buffers anymore.
v10.0.0
Added in: v10.0.0




buffer <Buffer> | <TypedArray> | <DataView>
offset <integer> The start position from within buffer where the data
to write begins.
length <integer> The number of bytes from buffer to write. Default:
buffer.byteLength - offset
position <integer> | <null> The offset from the beginning of the file where the
data from buffer should be written. If position is not a number,
the data will be written at the current position. See the POSIX pwrite(2)
documentation for more detail. Default: null
Returns: <Promise>

Write buffer to the file.
The promise is fulfilled with an object containing two properties:

bytesWritten <integer> the number of bytes written
buffer <Buffer> | <TypedArray> | <DataView> a reference to the
buffer written.

It is unsafe to use filehandle.write() multiple times on the same file
without waiting for the promise to be fulfilled (or rejected). For this
scenario, use filehandle.createWriteStream().
On Linux, positional writes do not work when the file is opened in append mode.
The kernel ignores the position argument and always appends the data to
the end of the file.

filehandle.write(buffer[, options])#

Added in: v18.3.0, v16.17.0


buffer <Buffer> | <TypedArray> | <DataView>
options <Object>

offset <integer> Default: 0
length <integer> Default: buffer.byteLength - offset
position <integer> | <null> Default: null


Returns: <Promise>

Write buffer to the file.
Similar to the above filehandle.write function, this version takes an
optional options object. If no options object is specified, it will
default with the above values.

filehandle.write(string[, position[, encoding]])#

History

VersionChanges
v14.0.0
The string parameter won't coerce unsupported input to strings anymore.
v10.0.0
Added in: v10.0.0




string <string>
position <integer> | <null> The offset from the beginning of the file where the
data from string should be written. If position is not a number the
data will be written at the current position. See the POSIX pwrite(2)
documentation for more detail. Default: null
encoding <string> The expected string encoding. Default: 'utf8'
Returns: <Promise>

Write string to the file. If string is not a string, the promise is
rejected with an error.
The promise is fulfilled with an object containing two properties:

bytesWritten <integer> the number of bytes written
buffer <string> a reference to the string written.

It is unsafe to use filehandle.write() multiple times on the same file
without waiting for the promise to be fulfilled (or rejected). For this
scenario, use filehandle.createWriteStream().
On Linux, positional writes do not work when the file is opened in append mode.
The kernel ignores the position argument and always appends the data to
the end of the file.

filehandle.writeFile(data, options)#

History

VersionChanges
v15.14.0, v14.18.0
The data argument supports AsyncIterable, Iterable, and Stream.
v14.0.0
The data parameter won't coerce unsupported input to strings anymore.
v10.0.0
Added in: v10.0.0




data <string> | <Buffer> | <TypedArray> | <DataView> | <AsyncIterable> | <Iterable> | <Stream>
options <Object> | <string>

encoding <string> | <null> The expected character encoding when data is a
string. Default: 'utf8'
signal <AbortSignal> | <undefined> allows aborting an in-progress writeFile. Default: undefined


Returns: <Promise>

Asynchronously writes data to a file, replacing the file if it already exists.
data can be a string, a buffer, an <AsyncIterable>, or an <Iterable> object.
The promise is fulfilled with no arguments upon success.
If options is a string, then it specifies the encoding.
The <FileHandle> has to support writing.
It is unsafe to use filehandle.writeFile() multiple times on the same file
without waiting for the promise to be fulfilled (or rejected).
If one or more filehandle.write() calls are made on a file handle and then a
filehandle.writeFile() call is made, the data will be written from the
current position till the end of the file. It doesn't always write from the
beginning of the file.

filehandle.writev(buffers[, position])#

Added in: v12.9.0


buffers <Buffer[]> | <TypedArray[]> | <DataView[]>
position <integer> | <null> The offset from the beginning of the file where the
data from buffers should be written. If position is not a number,
the data will be written at the current position. Default: null
Returns: <Promise>

Write an array of <ArrayBufferView>s to the file.
The promise is fulfilled with an object containing a two properties:

bytesWritten <integer> the number of bytes written
buffers <Buffer[]> | <TypedArray[]> | <DataView[]> a reference to the buffers
input.

It is unsafe to call writev() multiple times on the same file without waiting
for the promise to be fulfilled (or rejected).
On Linux, positional writes don't work when the file is opened in append mode.
The kernel ignores the position argument and always appends the data to
the end of the file.

filehandle[Symbol.asyncDispose]()#

Added in: v20.4.0, v18.18.0

Stability: 1 - Experimental
An alias for filehandle.close().

fsPromises.access(path[, mode])#

Added in: v10.0.0


path <string> | <Buffer> | <URL>
mode <integer> Default: fs.constants.F_OK
Returns: <Promise> Fulfills with undefined upon success.

Tests a user's permissions for the file or directory specified by path.
The mode argument is an optional integer that specifies the accessibility
checks to be performed. mode should be either the value fs.constants.F_OK
or a mask consisting of the bitwise OR of any of fs.constants.R_OK,
fs.constants.W_OK, and fs.constants.X_OK (e.g.
fs.constants.W_OK | fs.constants.R_OK). Check File access constants for
possible values of mode.
If the accessibility check is successful, the promise is fulfilled with no
value. If any of the accessibility checks fail, the promise is rejected
with an <Error> object. The following example checks if the file
/etc/passwd can be read and written by the current process.
import { access, constants } from 'node:fs/promises';

try {
  await access('/etc/passwd', constants.R_OK | constants.W_OK);
  console.log('can access');
} catch {
  console.error('cannot access');
} copy
Using fsPromises.access() to check for the accessibility of a file before
calling fsPromises.open() is not recommended. Doing so introduces a race
condition, since other processes may change the file's state between the two
calls. Instead, user code should open/read/write the file directly and handle
the error raised if the file is not accessible.

fsPromises.appendFile(path, data[, options])#

History

VersionChanges
v21.1.0, v20.10.0
The flush option is now supported.
v10.0.0
Added in: v10.0.0




path <string> | <Buffer> | <URL> | <FileHandle> filename or <FileHandle>
data <string> | <Buffer>
options <Object> | <string>

encoding <string> | <null> Default: 'utf8'
mode <integer> Default: 0o666
flag <string> See support of file system flags. Default: 'a'.
flush <boolean> If true, the underlying file descriptor is flushed
prior to closing it. Default: false.


Returns: <Promise> Fulfills with undefined upon success.

Asynchronously append data to a file, creating the file if it does not yet
exist. data can be a string or a <Buffer>.
If options is a string, then it specifies the encoding.
The mode option only affects the newly created file. See fs.open()
for more details.
The path may be specified as a <FileHandle> that has been opened
for appending (using fsPromises.open()).

fsPromises.chmod(path, mode)#

Added in: v10.0.0


path <string> | <Buffer> | <URL>
mode <string> | <integer>
Returns: <Promise> Fulfills with undefined upon success.

Changes the permissions of a file.

fsPromises.chown(path, uid, gid)#

Added in: v10.0.0


path <string> | <Buffer> | <URL>
uid <integer>
gid <integer>
Returns: <Promise> Fulfills with undefined upon success.

Changes the ownership of a file.

fsPromises.copyFile(src, dest[, mode])#

History

VersionChanges
v14.0.0
Changed flags argument to mode and imposed stricter type validation.
v10.0.0
Added in: v10.0.0




src <string> | <Buffer> | <URL> source filename to copy
dest <string> | <Buffer> | <URL> destination filename of the copy operation
mode <integer> Optional modifiers that specify the behavior of the copy
operation. It is possible to create a mask consisting of the bitwise OR of
two or more values (e.g.
fs.constants.COPYFILE_EXCL | fs.constants.COPYFILE_FICLONE)
Default: 0.

fs.constants.COPYFILE_EXCL: The copy operation will fail if dest
already exists.
fs.constants.COPYFILE_FICLONE: The copy operation will attempt to create
a copy-on-write reflink. If the platform does not support copy-on-write,
then a fallback copy mechanism is used.
fs.constants.COPYFILE_FICLONE_FORCE: The copy operation will attempt to
create a copy-on-write reflink. If the platform does not support
copy-on-write, then the operation will fail.


Returns: <Promise> Fulfills with undefined upon success.

Asynchronously copies src to dest. By default, dest is overwritten if it
already exists.
No guarantees are made about the atomicity of the copy operation. If an
error occurs after the destination file has been opened for writing, an attempt
will be made to remove the destination.
import { copyFile, constants } from 'node:fs/promises';

try {
  await copyFile('source.txt', 'destination.txt');
  console.log('source.txt was copied to destination.txt');
} catch {
  console.error('The file could not be copied');
}

// By using COPYFILE_EXCL, the operation will fail if destination.txt exists.
try {
  await copyFile('source.txt', 'destination.txt', constants.COPYFILE_EXCL);
  console.log('source.txt was copied to destination.txt');
} catch {
  console.error('The file could not be copied');
} copy

fsPromises.cp(src, dest[, options])#

History

VersionChanges
v22.3.0
This API is no longer experimental.
v20.1.0, v18.17.0
Accept an additional mode option to specify the copy behavior as the mode argument of fs.copyFile().
v17.6.0, v16.15.0
Accepts an additional verbatimSymlinks option to specify whether to perform path resolution for symlinks.
v16.7.0
Added in: v16.7.0




src <string> | <URL> source path to copy.
dest <string> | <URL> destination path to copy to.
options <Object>

dereference <boolean> dereference symlinks. Default: false.
errorOnExist <boolean> when force is false, and the destination
exists, throw an error. Default: false.
filter <Function> Function to filter copied files/directories. Return
true to copy the item, false to ignore it. When ignoring a directory,
all of its contents will be skipped as well. Can also return a Promise
that resolves to true or false Default: undefined.

src <string> source path to copy.
dest <string> destination path to copy to.
Returns: <boolean> | <Promise> A value that is coercible to boolean or
a Promise that fulfils with such value.


force <boolean> overwrite existing file or directory. The copy
operation will ignore errors if you set this to false and the destination
exists. Use the errorOnExist option to change this behavior.
Default: true.
mode <integer> modifiers for copy operation. Default: 0.
See mode flag of fsPromises.copyFile().
preserveTimestamps <boolean> When true timestamps from src will
be preserved. Default: false.
recursive <boolean> copy directories recursively Default: false
verbatimSymlinks <boolean> When true, path resolution for symlinks will
be skipped. Default: false


Returns: <Promise> Fulfills with undefined upon success.

Asynchronously copies the entire directory structure from src to dest,
including subdirectories and files.
When copying a directory to another directory, globs are not supported and
behavior is similar to cp dir1/ dir2/.

fsPromises.glob(pattern[, options])#

History

VersionChanges
v24.0.0
Marking the API stable.
v23.7.0, v22.14.0
Add support for exclude option to accept glob patterns.
v22.2.0
Add support for withFileTypes as an option.
v22.0.0
Added in: v22.0.0




pattern <string> | <string[]>
options <Object>

cwd <string> current working directory. Default: process.cwd()
exclude <Function> | <string[]> Function to filter out files/directories or a
list of glob patterns to be excluded. If a function is provided, return
true to exclude the item, false to include it. Default: undefined.
withFileTypes <boolean> true if the glob should return paths as Dirents,
false otherwise. Default: false.


Returns: <AsyncIterator> An AsyncIterator that yields the paths of files
that match the pattern.


import { glob } from 'node:fs/promises';

for await (const entry of glob('**/*.js'))
  console.log(entry);const { glob } = require('node:fs/promises');

(async () => {
  for await (const entry of glob('**/*.js'))
    console.log(entry);
})();copy

fsPromises.lchmod(path, mode)#

Deprecated since: v10.0.0

Stability: 0 - Deprecated

path <string> | <Buffer> | <URL>
mode <integer>
Returns: <Promise> Fulfills with undefined upon success.

Changes the permissions on a symbolic link.
This method is only implemented on macOS.

fsPromises.lchown(path, uid, gid)#

History

VersionChanges
v10.6.0
This API is no longer deprecated.
v10.0.0
Added in: v10.0.0




path <string> | <Buffer> | <URL>
uid <integer>
gid <integer>
Returns: <Promise>  Fulfills with undefined upon success.

Changes the ownership on a symbolic link.

fsPromises.lutimes(path, atime, mtime)#

Added in: v14.5.0, v12.19.0


path <string> | <Buffer> | <URL>
atime <number> | <string> | <Date>
mtime <number> | <string> | <Date>
Returns: <Promise>  Fulfills with undefined upon success.

Changes the access and modification times of a file in the same way as
fsPromises.utimes(), with the difference that if the path refers to a
symbolic link, then the link is not dereferenced: instead, the timestamps of
the symbolic link itself are changed.

fsPromises.link(existingPath, newPath)#

Added in: v10.0.0


existingPath <string> | <Buffer> | <URL>
newPath <string> | <Buffer> | <URL>
Returns: <Promise>  Fulfills with undefined upon success.

Creates a new link from the existingPath to the newPath. See the POSIX
link(2) documentation for more detail.

fsPromises.lstat(path[, options])#

History

VersionChanges
v10.5.0
Accepts an additional options object to specify whether the numeric values returned should be bigint.
v10.0.0
Added in: v10.0.0




path <string> | <Buffer> | <URL>
options <Object>

bigint <boolean> Whether the numeric values in the returned
<fs.Stats> object should be bigint. Default: false.


Returns: <Promise>  Fulfills with the <fs.Stats> object for the given
symbolic link path.

Equivalent to fsPromises.stat() unless path refers to a symbolic link,
in which case the link itself is stat-ed, not the file that it refers to.
Refer to the POSIX lstat(2) document for more detail.

fsPromises.mkdir(path[, options])#

Added in: v10.0.0


path <string> | <Buffer> | <URL>
options <Object> | <integer>

recursive <boolean> Default: false
mode <string> | <integer> Not supported on Windows. Default: 0o777.


Returns: <Promise> Upon success, fulfills with undefined if recursive
is false, or the first directory path created if recursive is true.

Asynchronously creates a directory.
The optional options argument can be an integer specifying mode (permission
and sticky bits), or an object with a mode property and a recursive
property indicating whether parent directories should be created. Calling
fsPromises.mkdir() when path is a directory that exists results in a
rejection only when recursive is false.

import { mkdir } from 'node:fs/promises';

try {
  const projectFolder = new URL('./test/project/', import.meta.url);
  const createDir = await mkdir(projectFolder, { recursive: true });

  console.log(`created ${createDir}`);
} catch (err) {
  console.error(err.message);
}const { mkdir } = require('node:fs/promises');
const { join } = require('node:path');

async function makeDirectory() {
  const projectFolder = join(__dirname, 'test', 'project');
  const dirCreation = await mkdir(projectFolder, { recursive: true });

  console.log(dirCreation);
  return dirCreation;
}

makeDirectory().catch(console.error);copy

fsPromises.mkdtemp(prefix[, options])#

History

VersionChanges
v20.6.0, v18.19.0
The prefix parameter now accepts buffers and URL.
v16.5.0, v14.18.0
The prefix parameter now accepts an empty string.
v10.0.0
Added in: v10.0.0




prefix <string> | <Buffer> | <URL>
options <string> | <Object>

encoding <string> Default: 'utf8'


Returns: <Promise>  Fulfills with a string containing the file system path
of the newly created temporary directory.

Creates a unique temporary directory. A unique directory name is generated by
appending six random characters to the end of the provided prefix. Due to
platform inconsistencies, avoid trailing X characters in prefix. Some
platforms, notably the BSDs, can return more than six random characters, and
replace trailing X characters in prefix with random characters.
The optional options argument can be a string specifying an encoding, or an
object with an encoding property specifying the character encoding to use.
import { mkdtemp } from 'node:fs/promises';
import { join } from 'node:path';
import { tmpdir } from 'node:os';

try {
  await mkdtemp(join(tmpdir(), 'foo-'));
} catch (err) {
  console.error(err);
} copy
The fsPromises.mkdtemp() method will append the six randomly selected
characters directly to the prefix string. For instance, given a directory
/tmp, if the intention is to create a temporary directory within /tmp, the
prefix must end with a trailing platform-specific path separator
(require('node:path').sep).

fsPromises.open(path, flags[, mode])#

History

VersionChanges
v11.1.0
The flags argument is now optional and defaults to 'r'.
v10.0.0
Added in: v10.0.0




path <string> | <Buffer> | <URL>
flags <string> | <number> See support of file system flags.
Default: 'r'.
mode <string> | <integer> Sets the file mode (permission and sticky bits)
if the file is created. Default: 0o666 (readable and writable)
Returns: <Promise> Fulfills with a <FileHandle> object.

Opens a <FileHandle>.
Refer to the POSIX open(2) documentation for more detail.
Some characters (< > : " / \ | ? *) are reserved under Windows as documented
by Naming Files, Paths, and Namespaces. Under NTFS, if the filename contains
a colon, Node.js will open a file system stream, as described by
this MSDN page.

fsPromises.opendir(path[, options])#

History

VersionChanges
v20.1.0, v18.17.0
Added recursive option.
v13.1.0, v12.16.0
The bufferSize option was introduced.
v12.12.0
Added in: v12.12.0




path <string> | <Buffer> | <URL>
options <Object>

encoding <string> | <null> Default: 'utf8'
bufferSize <number> Number of directory entries that are buffered
internally when reading from the directory. Higher values lead to better
performance but higher memory usage. Default: 32
recursive <boolean> Resolved Dir will be an <AsyncIterable>
containing all sub files and directories. Default: false


Returns: <Promise>  Fulfills with an <fs.Dir>.

Asynchronously open a directory for iterative scanning. See the POSIX
opendir(3) documentation for more detail.
Creates an <fs.Dir>, which contains all further functions for reading from
and cleaning up the directory.
The encoding option sets the encoding for the path while opening the
directory and subsequent read operations.
Example using async iteration:
import { opendir } from 'node:fs/promises';

try {
  const dir = await opendir('./');
  for await (const dirent of dir)
    console.log(dirent.name);
} catch (err) {
  console.error(err);
} copy
When using the async iterator, the <fs.Dir> object will be automatically
closed after the iterator exits.

fsPromises.readdir(path[, options])#

History

VersionChanges
v20.1.0, v18.17.0
Added recursive option.
v10.11.0
New option withFileTypes was added.
v10.0.0
Added in: v10.0.0




path <string> | <Buffer> | <URL>
options <string> | <Object>

encoding <string> Default: 'utf8'
withFileTypes <boolean> Default: false
recursive <boolean> If true, reads the contents of a directory
recursively. In recursive mode, it will list all files, sub files, and
directories. Default: false.


Returns: <Promise>  Fulfills with an array of the names of the files in
the directory excluding '.' and '..'.

Reads the contents of a directory.
The optional options argument can be a string specifying an encoding, or an
object with an encoding property specifying the character encoding to use for
the filenames. If the encoding is set to 'buffer', the filenames returned
will be passed as <Buffer> objects.
If options.withFileTypes is set to true, the returned array will contain
<fs.Dirent> objects.
import { readdir } from 'node:fs/promises';

try {
  const files = await readdir(path);
  for (const file of files)
    console.log(file);
} catch (err) {
  console.error(err);
} copy

fsPromises.readFile(path[, options])#

History

VersionChanges
v15.2.0, v14.17.0
The options argument may include an AbortSignal to abort an ongoing readFile request.
v10.0.0
Added in: v10.0.0




path <string> | <Buffer> | <URL> | <FileHandle> filename or FileHandle
options <Object> | <string>

encoding <string> | <null> Default: null
flag <string> See support of file system flags. Default: 'r'.
signal <AbortSignal> allows aborting an in-progress readFile


Returns: <Promise>  Fulfills with the contents of the file.

Asynchronously reads the entire contents of a file.
If no encoding is specified (using options.encoding), the data is returned
as a <Buffer> object. Otherwise, the data will be a string.
If options is a string, then it specifies the encoding.
When the path is a directory, the behavior of fsPromises.readFile() is
platform-specific. On macOS, Linux, and Windows, the promise will be rejected
with an error. On FreeBSD, a representation of the directory's contents will be
returned.
An example of reading a package.json file located in the same directory of the
running code:

import { readFile } from 'node:fs/promises';
try {
  const filePath = new URL('./package.json', import.meta.url);
  const contents = await readFile(filePath, { encoding: 'utf8' });
  console.log(contents);
} catch (err) {
  console.error(err.message);
}const { readFile } = require('node:fs/promises');
const { resolve } = require('node:path');
async function logFile() {
  try {
    const filePath = resolve('./package.json');
    const contents = await readFile(filePath, { encoding: 'utf8' });
    console.log(contents);
  } catch (err) {
    console.error(err.message);
  }
}
logFile();copy
It is possible to abort an ongoing readFile using an <AbortSignal>. If a
request is aborted the promise returned is rejected with an AbortError:
import { readFile } from 'node:fs/promises';

try {
  const controller = new AbortController();
  const { signal } = controller;
  const promise = readFile(fileName, { signal });

  // Abort the request before the promise settles.
  controller.abort();

  await promise;
} catch (err) {
  // When a request is aborted - err is an AbortError
  console.error(err);
} copy
Aborting an ongoing request does not abort individual operating
system requests but rather the internal buffering fs.readFile performs.
Any specified <FileHandle> has to support reading.

fsPromises.readlink(path[, options])#

Added in: v10.0.0


path <string> | <Buffer> | <URL>
options <string> | <Object>

encoding <string> Default: 'utf8'


Returns: <Promise> Fulfills with the linkString upon success.

Reads the contents of the symbolic link referred to by path. See the POSIX
readlink(2) documentation for more detail. The promise is fulfilled with the
linkString upon success.
The optional options argument can be a string specifying an encoding, or an
object with an encoding property specifying the character encoding to use for
the link path returned. If the encoding is set to 'buffer', the link path
returned will be passed as a <Buffer> object.

fsPromises.realpath(path[, options])#

Added in: v10.0.0


path <string> | <Buffer> | <URL>
options <string> | <Object>

encoding <string> Default: 'utf8'


Returns: <Promise>  Fulfills with the resolved path upon success.

Determines the actual location of path using the same semantics as the
fs.realpath.native() function.
Only paths that can be converted to UTF8 strings are supported.
The optional options argument can be a string specifying an encoding, or an
object with an encoding property specifying the character encoding to use for
the path. If the encoding is set to 'buffer', the path returned will be
passed as a <Buffer> object.
On Linux, when Node.js is linked against musl libc, the procfs file system must
be mounted on /proc in order for this function to work. Glibc does not have
this restriction.

fsPromises.rename(oldPath, newPath)#

Added in: v10.0.0


oldPath <string> | <Buffer> | <URL>
newPath <string> | <Buffer> | <URL>
Returns: <Promise> Fulfills with undefined upon success.

Renames oldPath to newPath.

fsPromises.rmdir(path[, options])#

History

VersionChanges
v16.0.0
Using fsPromises.rmdir(path, { recursive: true }) on a path that is a file is no longer permitted and results in an ENOENT error on Windows and an ENOTDIR error on POSIX.
v16.0.0
Using fsPromises.rmdir(path, { recursive: true }) on a path that does not exist is no longer permitted and results in a ENOENT error.
v16.0.0
The recursive option is deprecated, using it triggers a deprecation warning.
v14.14.0
The recursive option is deprecated, use fsPromises.rm instead.
v13.3.0, v12.16.0
The maxBusyTries option is renamed to maxRetries, and its default is 0. The emfileWait option has been removed, and EMFILE errors use the same retry logic as other errors. The retryDelay option is now supported. ENFILE errors are now retried.
v12.10.0
The recursive, maxBusyTries, and emfileWait options are now supported.
v10.0.0
Added in: v10.0.0




path <string> | <Buffer> | <URL>
options <Object>

maxRetries <integer> If an EBUSY, EMFILE, ENFILE, ENOTEMPTY, or
EPERM error is encountered, Node.js retries the operation with a linear
backoff wait of retryDelay milliseconds longer on each try. This option
represents the number of retries. This option is ignored if the recursive
option is not true. Default: 0.
recursive <boolean> If true, perform a recursive directory removal. In
recursive mode, operations are retried on failure. Default: false.
Deprecated.
retryDelay <integer> The amount of time in milliseconds to wait between
retries. This option is ignored if the recursive option is not true.
Default: 100.


Returns: <Promise> Fulfills with undefined upon success.

Removes the directory identified by path.
Using fsPromises.rmdir() on a file (not a directory) results in the
promise being rejected with an ENOENT error on Windows and an ENOTDIR
error on POSIX.
To get a behavior similar to the rm -rf Unix command, use
fsPromises.rm() with options { recursive: true, force: true }.

fsPromises.rm(path[, options])#

Added in: v14.14.0


path <string> | <Buffer> | <URL>
options <Object>

force <boolean> When true, exceptions will be ignored if path does
not exist. Default: false.
maxRetries <integer> If an EBUSY, EMFILE, ENFILE, ENOTEMPTY, or
EPERM error is encountered, Node.js will retry the operation with a linear
backoff wait of retryDelay milliseconds longer on each try. This option
represents the number of retries. This option is ignored if the recursive
option is not true. Default: 0.
recursive <boolean> If true, perform a recursive directory removal. In
recursive mode operations are retried on failure. Default: false.
retryDelay <integer> The amount of time in milliseconds to wait between
retries. This option is ignored if the recursive option is not true.
Default: 100.


Returns: <Promise> Fulfills with undefined upon success.

Removes files and directories (modeled on the standard POSIX rm utility).

fsPromises.stat(path[, options])#

History

VersionChanges
v10.5.0
Accepts an additional options object to specify whether the numeric values returned should be bigint.
v10.0.0
Added in: v10.0.0




path <string> | <Buffer> | <URL>
options <Object>

bigint <boolean> Whether the numeric values in the returned
<fs.Stats> object should be bigint. Default: false.


Returns: <Promise>  Fulfills with the <fs.Stats> object for the
given path.


fsPromises.statfs(path[, options])#

Added in: v19.6.0, v18.15.0


path <string> | <Buffer> | <URL>
options <Object>

bigint <boolean> Whether the numeric values in the returned
<fs.StatFs> object should be bigint. Default: false.


Returns: <Promise> Fulfills with the <fs.StatFs> object for the
given path.


fsPromises.symlink(target, path[, type])#

History

VersionChanges
v19.0.0
If the type argument is null or omitted, Node.js will autodetect target type and automatically select dir or file.
v10.0.0
Added in: v10.0.0




target <string> | <Buffer> | <URL>
path <string> | <Buffer> | <URL>
type <string> | <null> Default: null
Returns: <Promise> Fulfills with undefined upon success.

Creates a symbolic link.
The type argument is only used on Windows platforms and can be one of 'dir',
'file', or 'junction'. If the type argument is null, Node.js will
autodetect target type and use 'file' or 'dir'. If the target does not
exist, 'file' will be used. Windows junction points require the destination
path to be absolute. When using 'junction', the target argument will
automatically be normalized to absolute path. Junction points on NTFS volumes
can only point to directories.

fsPromises.truncate(path[, len])#

Added in: v10.0.0


path <string> | <Buffer> | <URL>
len <integer> Default: 0
Returns: <Promise> Fulfills with undefined upon success.

Truncates (shortens or extends the length) of the content at path to len
bytes.

fsPromises.unlink(path)#

Added in: v10.0.0


path <string> | <Buffer> | <URL>
Returns: <Promise> Fulfills with undefined upon success.

If path refers to a symbolic link, then the link is removed without affecting
the file or directory to which that link refers. If the path refers to a file
path that is not a symbolic link, the file is deleted. See the POSIX unlink(2)
documentation for more detail.

fsPromises.utimes(path, atime, mtime)#

Added in: v10.0.0


path <string> | <Buffer> | <URL>
atime <number> | <string> | <Date>
mtime <number> | <string> | <Date>
Returns: <Promise> Fulfills with undefined upon success.

Change the file system timestamps of the object referenced by path.
The atime and mtime arguments follow these rules:

Values can be either numbers representing Unix epoch time, Dates, or a
numeric string like '123456789.0'.
If the value can not be converted to a number, or is NaN, Infinity, or
-Infinity, an Error will be thrown.


fsPromises.watch(filename[, options])#

Added in: v15.9.0, v14.18.0


filename <string> | <Buffer> | <URL>
options <string> | <Object>

persistent <boolean> Indicates whether the process should continue to run
as long as files are being watched. Default: true.
recursive <boolean> Indicates whether all subdirectories should be
watched, or only the current directory. This applies when a directory is
specified, and only on supported platforms (See caveats). Default:
false.
encoding <string> Specifies the character encoding to be used for the
filename passed to the listener. Default: 'utf8'.
signal <AbortSignal> An <AbortSignal> used to signal when the watcher
should stop.


Returns: <AsyncIterator> of objects with the properties:

eventType <string> The type of change
filename <string> | <Buffer> | <null> The name of the file changed.



Returns an async iterator that watches for changes on filename, where filename
is either a file or a directory.
const { watch } = require('node:fs/promises');

const ac = new AbortController();
const { signal } = ac;
setTimeout(() => ac.abort(), 10000);

(async () => {
  try {
    const watcher = watch(__filename, { signal });
    for await (const event of watcher)
      console.log(event);
  } catch (err) {
    if (err.name === 'AbortError')
      return;
    throw err;
  }
})(); copy
On most platforms, 'rename' is emitted whenever a filename appears or
disappears in the directory.
All the caveats for fs.watch() also apply to fsPromises.watch().

fsPromises.writeFile(file, data[, options])#

History

VersionChanges
v21.0.0, v20.10.0
The flush option is now supported.
v15.14.0, v14.18.0
The data argument supports AsyncIterable, Iterable, and Stream.
v15.2.0, v14.17.0
The options argument may include an AbortSignal to abort an ongoing writeFile request.
v14.0.0
The data parameter won't coerce unsupported input to strings anymore.
v10.0.0
Added in: v10.0.0




file <string> | <Buffer> | <URL> | <FileHandle> filename or FileHandle
data <string> | <Buffer> | <TypedArray> | <DataView> | <AsyncIterable> | <Iterable> | <Stream>
options <Object> | <string>

encoding <string> | <null> Default: 'utf8'
mode <integer> Default: 0o666
flag <string> See support of file system flags. Default: 'w'.
flush <boolean> If all data is successfully written to the file, and
flush is true, filehandle.sync() is used to flush the data.
Default: false.
signal <AbortSignal> allows aborting an in-progress writeFile


Returns: <Promise> Fulfills with undefined upon success.

Asynchronously writes data to a file, replacing the file if it already exists.
data can be a string, a buffer, an <AsyncIterable>, or an <Iterable> object.
The encoding option is ignored if data is a buffer.
If options is a string, then it specifies the encoding.
The mode option only affects the newly created file. See fs.open()
for more details.
Any specified <FileHandle> has to support writing.
It is unsafe to use fsPromises.writeFile() multiple times on the same file
without waiting for the promise to be settled.
Similarly to fsPromises.readFile - fsPromises.writeFile is a convenience
method that performs multiple write calls internally to write the buffer
passed to it. For performance sensitive code consider using
fs.createWriteStream() or filehandle.createWriteStream().
It is possible to use an <AbortSignal> to cancel an fsPromises.writeFile().
Cancelation is "best effort", and some amount of data is likely still
to be written.
import { writeFile } from 'node:fs/promises';
import { Buffer } from 'node:buffer';

try {
  const controller = new AbortController();
  const { signal } = controller;
  const data = new Uint8Array(Buffer.from('Hello Node.js'));
  const promise = writeFile('message.txt', data, { signal });

  // Abort the request before the promise settles.
  controller.abort();

  await promise;
} catch (err) {
  // When a request is aborted - err is an AbortError
  console.error(err);
} copy
Aborting an ongoing request does not abort individual operating
system requests but rather the internal buffering fs.writeFile performs.

fsPromises.constants#

Added in: v18.4.0, v16.17.0


<Object>

Returns an object containing commonly used constants for file system
operations. The object is the same as fs.constants. See FS constants
for more details.

Callback API#
The callback APIs perform all operations asynchronously, without blocking the
event loop, then invoke a callback function upon completion or error.
The callback APIs use the underlying Node.js threadpool to perform file
system operations off the event loop thread. These operations are not
synchronized or threadsafe. Care must be taken when performing multiple
concurrent modifications on the same file or data corruption may occur.

fs.access(path[, mode], callback)#

History

VersionChanges
v20.8.0
The constants fs.F_OK, fs.R_OK, fs.W_OK and fs.X_OK which were present directly on fs are deprecated.
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v7.6.0
The path parameter can be a WHATWG URL object using file: protocol.
v6.3.0
The constants like fs.R_OK, etc which were present directly on fs were moved into fs.constants as a soft deprecation. Thus for Node.js < v6.3.0 use fs to access those constants, or do something like (fs.constants || fs).R_OK to work with all versions.
v0.11.15
Added in: v0.11.15




path <string> | <Buffer> | <URL>
mode <integer> Default: fs.constants.F_OK
callback <Function>

err <Error>



Tests a user's permissions for the file or directory specified by path.
The mode argument is an optional integer that specifies the accessibility
checks to be performed. mode should be either the value fs.constants.F_OK
or a mask consisting of the bitwise OR of any of fs.constants.R_OK,
fs.constants.W_OK, and fs.constants.X_OK (e.g.
fs.constants.W_OK | fs.constants.R_OK). Check File access constants for
possible values of mode.
The final argument, callback, is a callback function that is invoked with
a possible error argument. If any of the accessibility checks fail, the error
argument will be an Error object. The following examples check if
package.json exists, and if it is readable or writable.
import { access, constants } from 'node:fs';

const file = 'package.json';

// Check if the file exists in the current directory.
access(file, constants.F_OK, (err) => {
  console.log(`${file} ${err ? 'does not exist' : 'exists'}`);
});

// Check if the file is readable.
access(file, constants.R_OK, (err) => {
  console.log(`${file} ${err ? 'is not readable' : 'is readable'}`);
});

// Check if the file is writable.
access(file, constants.W_OK, (err) => {
  console.log(`${file} ${err ? 'is not writable' : 'is writable'}`);
});

// Check if the file is readable and writable.
access(file, constants.R_OK | constants.W_OK, (err) => {
  console.log(`${file} ${err ? 'is not' : 'is'} readable and writable`);
}); copy
Do not use fs.access() to check for the accessibility of a file before calling
fs.open(), fs.readFile(), or fs.writeFile(). Doing
so introduces a race condition, since other processes may change the file's
state between the two calls. Instead, user code should open/read/write the
file directly and handle the error raised if the file is not accessible.
write (NOT RECOMMENDED)
import { access, open, close } from 'node:fs';

access('myfile', (err) => {
  if (!err) {
    console.error('myfile already exists');
    return;
  }

  open('myfile', 'wx', (err, fd) => {
    if (err) throw err;

    try {
      writeMyData(fd);
    } finally {
      close(fd, (err) => {
        if (err) throw err;
      });
    }
  });
}); copy
write (RECOMMENDED)
import { open, close } from 'node:fs';

open('myfile', 'wx', (err, fd) => {
  if (err) {
    if (err.code === 'EEXIST') {
      console.error('myfile already exists');
      return;
    }

    throw err;
  }

  try {
    writeMyData(fd);
  } finally {
    close(fd, (err) => {
      if (err) throw err;
    });
  }
}); copy
read (NOT RECOMMENDED)
import { access, open, close } from 'node:fs';
access('myfile', (err) => {
  if (err) {
    if (err.code === 'ENOENT') {
      console.error('myfile does not exist');
      return;
    }

    throw err;
  }

  open('myfile', 'r', (err, fd) => {
    if (err) throw err;

    try {
      readMyData(fd);
    } finally {
      close(fd, (err) => {
        if (err) throw err;
      });
    }
  });
}); copy
read (RECOMMENDED)
import { open, close } from 'node:fs';

open('myfile', 'r', (err, fd) => {
  if (err) {
    if (err.code === 'ENOENT') {
      console.error('myfile does not exist');
      return;
    }

    throw err;
  }

  try {
    readMyData(fd);
  } finally {
    close(fd, (err) => {
      if (err) throw err;
    });
  }
}); copy
The "not recommended" examples above check for accessibility and then use the
file; the "recommended" examples are better because they use the file directly
and handle the error, if any.
In general, check for the accessibility of a file only if the file will not be
used directly, for example when its accessibility is a signal from another
process.
On Windows, access-control policies (ACLs) on a directory may limit access to
a file or directory. The fs.access() function, however, does not check the
ACL and therefore may report that a path is accessible even if the ACL restricts
the user from reading or writing to it.

fs.appendFile(path, data[, options], callback)#

History

VersionChanges
v21.1.0, v20.10.0
The flush option is now supported.
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v10.0.0
The callback parameter is no longer optional. Not passing it will throw a TypeError at runtime.
v7.0.0
The callback parameter is no longer optional. Not passing it will emit a deprecation warning with id DEP0013.
v7.0.0
The passed options object will never be modified.
v5.0.0
The file parameter can be a file descriptor now.
v0.6.7
Added in: v0.6.7




path <string> | <Buffer> | <URL> | <number> filename or file descriptor
data <string> | <Buffer>
options <Object> | <string>

encoding <string> | <null> Default: 'utf8'
mode <integer> Default: 0o666
flag <string> See support of file system flags. Default: 'a'.
flush <boolean> If true, the underlying file descriptor is flushed
prior to closing it. Default: false.


callback <Function>

err <Error>



Asynchronously append data to a file, creating the file if it does not yet
exist. data can be a string or a <Buffer>.
The mode option only affects the newly created file. See fs.open()
for more details.
import { appendFile } from 'node:fs';

appendFile('message.txt', 'data to append', (err) => {
  if (err) throw err;
  console.log('The "data to append" was appended to file!');
}); copy
If options is a string, then it specifies the encoding:
import { appendFile } from 'node:fs';

appendFile('message.txt', 'data to append', 'utf8', callback); copy
The path may be specified as a numeric file descriptor that has been opened
for appending (using fs.open() or fs.openSync()). The file descriptor will
not be closed automatically.
import { open, close, appendFile } from 'node:fs';

function closeFd(fd) {
  close(fd, (err) => {
    if (err) throw err;
  });
}

open('message.txt', 'a', (err, fd) => {
  if (err) throw err;

  try {
    appendFile(fd, 'data to append', 'utf8', (err) => {
      closeFd(fd);
      if (err) throw err;
    });
  } catch (err) {
    closeFd(fd);
    throw err;
  }
}); copy

fs.chmod(path, mode, callback)#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v10.0.0
The callback parameter is no longer optional. Not passing it will throw a TypeError at runtime.
v7.6.0
The path parameter can be a WHATWG URL object using file: protocol.
v7.0.0
The callback parameter is no longer optional. Not passing it will emit a deprecation warning with id DEP0013.
v0.1.30
Added in: v0.1.30




path <string> | <Buffer> | <URL>
mode <string> | <integer>
callback <Function>

err <Error>



Asynchronously changes the permissions of a file. No arguments other than a
possible exception are given to the completion callback.
See the POSIX chmod(2) documentation for more detail.
import { chmod } from 'node:fs';

chmod('my_file.txt', 0o775, (err) => {
  if (err) throw err;
  console.log('The permissions for file "my_file.txt" have been changed!');
}); copy

File modes#
The mode argument used in both the fs.chmod() and fs.chmodSync()
methods is a numeric bitmask created using a logical OR of the following
constants:























































ConstantOctalDescriptionfs.constants.S_IRUSR0o400read by ownerfs.constants.S_IWUSR0o200write by ownerfs.constants.S_IXUSR0o100execute/search by ownerfs.constants.S_IRGRP0o40read by groupfs.constants.S_IWGRP0o20write by groupfs.constants.S_IXGRP0o10execute/search by groupfs.constants.S_IROTH0o4read by othersfs.constants.S_IWOTH0o2write by othersfs.constants.S_IXOTH0o1execute/search by others
An easier method of constructing the mode is to use a sequence of three
octal digits (e.g. 765). The left-most digit (7 in the example), specifies
the permissions for the file owner. The middle digit (6 in the example),
specifies permissions for the group. The right-most digit (5 in the example),
specifies the permissions for others.









































NumberDescription7read, write, and execute6read and write5read and execute4read only3write and execute2write only1execute only0no permission
For example, the octal value 0o765 means:

The owner may read, write, and execute the file.
The group may read and write the file.
Others may read and execute the file.

When using raw numbers where file modes are expected, any value larger than
0o777 may result in platform-specific behaviors that are not supported to work
consistently. Therefore constants like S_ISVTX, S_ISGID, or S_ISUID are
not exposed in fs.constants.
Caveats: on Windows only the write permission can be changed, and the
distinction among the permissions of group, owner, or others is not
implemented.

fs.chown(path, uid, gid, callback)#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v10.0.0
The callback parameter is no longer optional. Not passing it will throw a TypeError at runtime.
v7.6.0
The path parameter can be a WHATWG URL object using file: protocol.
v7.0.0
The callback parameter is no longer optional. Not passing it will emit a deprecation warning with id DEP0013.
v0.1.97
Added in: v0.1.97




path <string> | <Buffer> | <URL>
uid <integer>
gid <integer>
callback <Function>

err <Error>



Asynchronously changes owner and group of a file. No arguments other than a
possible exception are given to the completion callback.
See the POSIX chown(2) documentation for more detail.

fs.close(fd[, callback])#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v15.9.0, v14.17.0
A default callback is now used if one is not provided.
v10.0.0
The callback parameter is no longer optional. Not passing it will throw a TypeError at runtime.
v7.0.0
The callback parameter is no longer optional. Not passing it will emit a deprecation warning with id DEP0013.
v0.0.2
Added in: v0.0.2




fd <integer>
callback <Function>

err <Error>



Closes the file descriptor. No arguments other than a possible exception are
given to the completion callback.
Calling fs.close() on any file descriptor (fd) that is currently in use
through any other fs operation may lead to undefined behavior.
See the POSIX close(2) documentation for more detail.

fs.copyFile(src, dest[, mode], callback)#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v14.0.0
Changed flags argument to mode and imposed stricter type validation.
v8.5.0
Added in: v8.5.0




src <string> | <Buffer> | <URL> source filename to copy
dest <string> | <Buffer> | <URL> destination filename of the copy operation
mode <integer> modifiers for copy operation. Default: 0.
callback <Function>

err <Error>



Asynchronously copies src to dest. By default, dest is overwritten if it
already exists. No arguments other than a possible exception are given to the
callback function. Node.js makes no guarantees about the atomicity of the copy
operation. If an error occurs after the destination file has been opened for
writing, Node.js will attempt to remove the destination.
mode is an optional integer that specifies the behavior
of the copy operation. It is possible to create a mask consisting of the bitwise
OR of two or more values (e.g.
fs.constants.COPYFILE_EXCL | fs.constants.COPYFILE_FICLONE).

fs.constants.COPYFILE_EXCL: The copy operation will fail if dest already
exists.
fs.constants.COPYFILE_FICLONE: The copy operation will attempt to create a
copy-on-write reflink. If the platform does not support copy-on-write, then a
fallback copy mechanism is used.
fs.constants.COPYFILE_FICLONE_FORCE: The copy operation will attempt to
create a copy-on-write reflink. If the platform does not support
copy-on-write, then the operation will fail.

import { copyFile, constants } from 'node:fs';

function callback(err) {
  if (err) throw err;
  console.log('source.txt was copied to destination.txt');
}

// destination.txt will be created or overwritten by default.
copyFile('source.txt', 'destination.txt', callback);

// By using COPYFILE_EXCL, the operation will fail if destination.txt exists.
copyFile('source.txt', 'destination.txt', constants.COPYFILE_EXCL, callback); copy

fs.cp(src, dest[, options], callback)#

History

VersionChanges
v22.3.0
This API is no longer experimental.
v20.1.0, v18.17.0
Accept an additional mode option to specify the copy behavior as the mode argument of fs.copyFile().
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v17.6.0, v16.15.0
Accepts an additional verbatimSymlinks option to specify whether to perform path resolution for symlinks.
v16.7.0
Added in: v16.7.0




src <string> | <URL> source path to copy.
dest <string> | <URL> destination path to copy to.
options <Object>

dereference <boolean> dereference symlinks. Default: false.
errorOnExist <boolean> when force is false, and the destination
exists, throw an error. Default: false.
filter <Function> Function to filter copied files/directories. Return
true to copy the item, false to ignore it. When ignoring a directory,
all of its contents will be skipped as well. Can also return a Promise
that resolves to true or false Default: undefined.

src <string> source path to copy.
dest <string> destination path to copy to.
Returns: <boolean> | <Promise> A value that is coercible to boolean or
a Promise that fulfils with such value.


force <boolean> overwrite existing file or directory. The copy
operation will ignore errors if you set this to false and the destination
exists. Use the errorOnExist option to change this behavior.
Default: true.
mode <integer> modifiers for copy operation. Default: 0.
See mode flag of fs.copyFile().
preserveTimestamps <boolean> When true timestamps from src will
be preserved. Default: false.
recursive <boolean> copy directories recursively Default: false
verbatimSymlinks <boolean> When true, path resolution for symlinks will
be skipped. Default: false


callback <Function>

err <Error>



Asynchronously copies the entire directory structure from src to dest,
including subdirectories and files.
When copying a directory to another directory, globs are not supported and
behavior is similar to cp dir1/ dir2/.

fs.createReadStream(path[, options])#

History

VersionChanges
v16.10.0
The fs option does not need open method if an fd was provided.
v16.10.0
The fs option does not need close method if autoClose is false.
v15.5.0
Add support for AbortSignal.
v15.4.0
The fd option accepts FileHandle arguments.
v14.0.0
Change emitClose default to true.
v13.6.0, v12.17.0
The fs options allow overriding the used fs implementation.
v12.10.0
Enable emitClose option.
v11.0.0
Impose new restrictions on start and end, throwing more appropriate errors in cases when we cannot reasonably handle the input values.
v7.6.0
The path parameter can be a WHATWG URL object using file: protocol.
v7.0.0
The passed options object will never be modified.
v2.3.0
The passed options object can be a string now.
v0.1.31
Added in: v0.1.31




path <string> | <Buffer> | <URL>
options <string> | <Object>

flags <string> See support of file system flags. Default:
'r'.
encoding <string> Default: null
fd <integer> | <FileHandle> Default: null
mode <integer> Default: 0o666
autoClose <boolean> Default: true
emitClose <boolean> Default: true
start <integer>
end <integer> Default: Infinity
highWaterMark <integer> Default: 64 * 1024
fs <Object> | <null> Default: null
signal <AbortSignal> | <null> Default: null


Returns: <fs.ReadStream>

options can include start and end values to read a range of bytes from
the file instead of the entire file. Both start and end are inclusive and
start counting at 0, allowed values are in the
[0, Number.MAX_SAFE_INTEGER] range. If fd is specified and start is
omitted or undefined, fs.createReadStream() reads sequentially from the
current file position. The encoding can be any one of those accepted by
<Buffer>.
If fd is specified, ReadStream will ignore the path argument and will use
the specified file descriptor. This means that no 'open' event will be
emitted. fd should be blocking; non-blocking fds should be passed to
<net.Socket>.
If fd points to a character device that only supports blocking reads
(such as keyboard or sound card), read operations do not finish until data is
available. This can prevent the process from exiting and the stream from
closing naturally.
By default, the stream will emit a 'close' event after it has been
destroyed.  Set the emitClose option to false to change this behavior.
By providing the fs option, it is possible to override the corresponding fs
implementations for open, read, and close. When providing the fs option,
an override for read is required. If no fd is provided, an override for
open is also required. If autoClose is true, an override for close is
also required.
import { createReadStream } from 'node:fs';

// Create a stream from some character device.
const stream = createReadStream('/dev/input/event0');
setTimeout(() => {
  stream.close(); // This may not close the stream.
  // Artificially marking end-of-stream, as if the underlying resource had
  // indicated end-of-file by itself, allows the stream to close.
  // This does not cancel pending read operations, and if there is such an
  // operation, the process may still not be able to exit successfully
  // until it finishes.
  stream.push(null);
  stream.read(0);
}, 100); copy
If autoClose is false, then the file descriptor won't be closed, even if
there's an error. It is the application's responsibility to close it and make
sure there's no file descriptor leak. If autoClose is set to true (default
behavior), on 'error' or 'end' the file descriptor will be closed
automatically.
mode sets the file mode (permission and sticky bits), but only if the
file was created.
An example to read the last 10 bytes of a file which is 100 bytes long:
import { createReadStream } from 'node:fs';

createReadStream('sample.txt', { start: 90, end: 99 }); copy
If options is a string, then it specifies the encoding.

fs.createWriteStream(path[, options])#

History

VersionChanges
v21.0.0, v20.10.0
The flush option is now supported.
v16.10.0
The fs option does not need open method if an fd was provided.
v16.10.0
The fs option does not need close method if autoClose is false.
v15.5.0
Add support for AbortSignal.
v15.4.0
The fd option accepts FileHandle arguments.
v14.0.0
Change emitClose default to true.
v13.6.0, v12.17.0
The fs options allow overriding the used fs implementation.
v12.10.0
Enable emitClose option.
v7.6.0
The path parameter can be a WHATWG URL object using file: protocol.
v7.0.0
The passed options object will never be modified.
v5.5.0
The autoClose option is supported now.
v2.3.0
The passed options object can be a string now.
v0.1.31
Added in: v0.1.31




path <string> | <Buffer> | <URL>
options <string> | <Object>

flags <string> See support of file system flags. Default:
'w'.
encoding <string> Default: 'utf8'
fd <integer> | <FileHandle> Default: null
mode <integer> Default: 0o666
autoClose <boolean> Default: true
emitClose <boolean> Default: true
start <integer>
fs <Object> | <null> Default: null
signal <AbortSignal> | <null> Default: null
highWaterMark <number> Default: 16384
flush <boolean> If true, the underlying file descriptor is flushed
prior to closing it. Default: false.


Returns: <fs.WriteStream>

options may also include a start option to allow writing data at some
position past the beginning of the file, allowed values are in the
[0, Number.MAX_SAFE_INTEGER] range. Modifying a file rather than
replacing it may require the flags option to be set to r+ rather than the
default w. The encoding can be any one of those accepted by <Buffer>.
If autoClose is set to true (default behavior) on 'error' or 'finish'
the file descriptor will be closed automatically. If autoClose is false,
then the file descriptor won't be closed, even if there's an error.
It is the application's responsibility to close it and make sure there's no
file descriptor leak.
By default, the stream will emit a 'close' event after it has been
destroyed.  Set the emitClose option to false to change this behavior.
By providing the fs option it is possible to override the corresponding fs
implementations for open, write, writev, and close. Overriding write()
without writev() can reduce performance as some optimizations (_writev())
will be disabled. When providing the fs option, overrides for at least one of
write and writev are required. If no fd option is supplied, an override
for open is also required. If autoClose is true, an override for close
is also required.
Like <fs.ReadStream>, if fd is specified, <fs.WriteStream> will ignore the
path argument and will use the specified file descriptor. This means that no
'open' event will be emitted. fd should be blocking; non-blocking fds
should be passed to <net.Socket>.
If options is a string, then it specifies the encoding.

fs.exists(path, callback)#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v7.6.0
The path parameter can be a WHATWG URL object using file: protocol.
v1.0.0
Deprecated since: v1.0.0
v0.0.2
Added in: v0.0.2



Stability: 0 - Deprecated: Use fs.stat() or fs.access() instead.

path <string> | <Buffer> | <URL>
callback <Function>

exists <boolean>



Test whether or not the element at the given path exists by checking with the file system.
Then call the callback argument with either true or false:
import { exists } from 'node:fs';

exists('/etc/passwd', (e) => {
  console.log(e ? 'it exists' : 'no passwd!');
}); copy
The parameters for this callback are not consistent with other Node.js
callbacks. Normally, the first parameter to a Node.js callback is an err
parameter, optionally followed by other parameters. The fs.exists() callback
has only one boolean parameter. This is one reason fs.access() is recommended
instead of fs.exists().
If path is a symbolic link, it is followed. Thus, if path exists but points
to a non-existent element, the callback will receive the value false.
Using fs.exists() to check for the existence of a file before calling
fs.open(), fs.readFile(), or fs.writeFile() is not recommended. Doing
so introduces a race condition, since other processes may change the file's
state between the two calls. Instead, user code should open/read/write the
file directly and handle the error raised if the file does not exist.
write (NOT RECOMMENDED)
import { exists, open, close } from 'node:fs';

exists('myfile', (e) => {
  if (e) {
    console.error('myfile already exists');
  } else {
    open('myfile', 'wx', (err, fd) => {
      if (err) throw err;

      try {
        writeMyData(fd);
      } finally {
        close(fd, (err) => {
          if (err) throw err;
        });
      }
    });
  }
}); copy
write (RECOMMENDED)
import { open, close } from 'node:fs';
open('myfile', 'wx', (err, fd) => {
  if (err) {
    if (err.code === 'EEXIST') {
      console.error('myfile already exists');
      return;
    }

    throw err;
  }

  try {
    writeMyData(fd);
  } finally {
    close(fd, (err) => {
      if (err) throw err;
    });
  }
}); copy
read (NOT RECOMMENDED)
import { open, close, exists } from 'node:fs';

exists('myfile', (e) => {
  if (e) {
    open('myfile', 'r', (err, fd) => {
      if (err) throw err;

      try {
        readMyData(fd);
      } finally {
        close(fd, (err) => {
          if (err) throw err;
        });
      }
    });
  } else {
    console.error('myfile does not exist');
  }
}); copy
read (RECOMMENDED)
import { open, close } from 'node:fs';

open('myfile', 'r', (err, fd) => {
  if (err) {
    if (err.code === 'ENOENT') {
      console.error('myfile does not exist');
      return;
    }

    throw err;
  }

  try {
    readMyData(fd);
  } finally {
    close(fd, (err) => {
      if (err) throw err;
    });
  }
}); copy
The "not recommended" examples above check for existence and then use the
file; the "recommended" examples are better because they use the file directly
and handle the error, if any.
In general, check for the existence of a file only if the file won't be
used directly, for example when its existence is a signal from another
process.

fs.fchmod(fd, mode, callback)#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v10.0.0
The callback parameter is no longer optional. Not passing it will throw a TypeError at runtime.
v7.0.0
The callback parameter is no longer optional. Not passing it will emit a deprecation warning with id DEP0013.
v0.4.7
Added in: v0.4.7




fd <integer>
mode <string> | <integer>
callback <Function>

err <Error>



Sets the permissions on the file. No arguments other than a possible exception
are given to the completion callback.
See the POSIX fchmod(2) documentation for more detail.

fs.fchown(fd, uid, gid, callback)#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v10.0.0
The callback parameter is no longer optional. Not passing it will throw a TypeError at runtime.
v7.0.0
The callback parameter is no longer optional. Not passing it will emit a deprecation warning with id DEP0013.
v0.4.7
Added in: v0.4.7




fd <integer>
uid <integer>
gid <integer>
callback <Function>

err <Error>



Sets the owner of the file. No arguments other than a possible exception are
given to the completion callback.
See the POSIX fchown(2) documentation for more detail.

fs.fdatasync(fd, callback)#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v10.0.0
The callback parameter is no longer optional. Not passing it will throw a TypeError at runtime.
v7.0.0
The callback parameter is no longer optional. Not passing it will emit a deprecation warning with id DEP0013.
v0.1.96
Added in: v0.1.96




fd <integer>
callback <Function>

err <Error>



Forces all currently queued I/O operations associated with the file to the
operating system's synchronized I/O completion state. Refer to the POSIX
fdatasync(2) documentation for details. No arguments other than a possible
exception are given to the completion callback.

fs.fstat(fd[, options], callback)#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v10.5.0
Accepts an additional options object to specify whether the numeric values returned should be bigint.
v10.0.0
The callback parameter is no longer optional. Not passing it will throw a TypeError at runtime.
v7.0.0
The callback parameter is no longer optional. Not passing it will emit a deprecation warning with id DEP0013.
v0.1.95
Added in: v0.1.95




fd <integer>
options <Object>

bigint <boolean> Whether the numeric values in the returned
<fs.Stats> object should be bigint. Default: false.


callback <Function>

err <Error>
stats <fs.Stats>



Invokes the callback with the <fs.Stats> for the file descriptor.
See the POSIX fstat(2) documentation for more detail.

fs.fsync(fd, callback)#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v10.0.0
The callback parameter is no longer optional. Not passing it will throw a TypeError at runtime.
v7.0.0
The callback parameter is no longer optional. Not passing it will emit a deprecation warning with id DEP0013.
v0.1.96
Added in: v0.1.96




fd <integer>
callback <Function>

err <Error>



Request that all data for the open file descriptor is flushed to the storage
device. The specific implementation is operating system and device specific.
Refer to the POSIX fsync(2) documentation for more detail. No arguments other
than a possible exception are given to the completion callback.

fs.ftruncate(fd[, len], callback)#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v10.0.0
The callback parameter is no longer optional. Not passing it will throw a TypeError at runtime.
v7.0.0
The callback parameter is no longer optional. Not passing it will emit a deprecation warning with id DEP0013.
v0.8.6
Added in: v0.8.6




fd <integer>
len <integer> Default: 0
callback <Function>

err <Error>



Truncates the file descriptor. No arguments other than a possible exception are
given to the completion callback.
See the POSIX ftruncate(2) documentation for more detail.
If the file referred to by the file descriptor was larger than len bytes, only
the first len bytes will be retained in the file.
For example, the following program retains only the first four bytes of the
file:
import { open, close, ftruncate } from 'node:fs';

function closeFd(fd) {
  close(fd, (err) => {
    if (err) throw err;
  });
}

open('temp.txt', 'r+', (err, fd) => {
  if (err) throw err;

  try {
    ftruncate(fd, 4, (err) => {
      closeFd(fd);
      if (err) throw err;
    });
  } catch (err) {
    closeFd(fd);
    if (err) throw err;
  }
}); copy
If the file previously was shorter than len bytes, it is extended, and the
extended part is filled with null bytes ('\0'):
If len is negative then 0 will be used.

fs.futimes(fd, atime, mtime, callback)#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v10.0.0
The callback parameter is no longer optional. Not passing it will throw a TypeError at runtime.
v7.0.0
The callback parameter is no longer optional. Not passing it will emit a deprecation warning with id DEP0013.
v4.1.0
Numeric strings, NaN, and Infinity are now allowed time specifiers.
v0.4.2
Added in: v0.4.2




fd <integer>
atime <number> | <string> | <Date>
mtime <number> | <string> | <Date>
callback <Function>

err <Error>



Change the file system timestamps of the object referenced by the supplied file
descriptor. See fs.utimes().

fs.glob(pattern[, options], callback)#

History

VersionChanges
v24.0.0
Marking the API stable.
v23.7.0, v22.14.0
Add support for exclude option to accept glob patterns.
v22.2.0
Add support for withFileTypes as an option.
v22.0.0
Added in: v22.0.0





pattern <string> | <string[]>


options <Object>

cwd <string> current working directory. Default: process.cwd()
exclude <Function> | <string[]> Function to filter out files/directories or a
list of glob patterns to be excluded. If a function is provided, return
true to exclude the item, false to include it. Default: undefined.
withFileTypes <boolean> true if the glob should return paths as Dirents,
false otherwise. Default: false.



callback <Function>

err <Error>



Retrieves the files matching the specified pattern.



import { glob } from 'node:fs';

glob('**/*.js', (err, matches) => {
  if (err) throw err;
  console.log(matches);
});const { glob } = require('node:fs');

glob('**/*.js', (err, matches) => {
  if (err) throw err;
  console.log(matches);
});copy

fs.lchmod(path, mode, callback)#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v16.0.0
The error returned may be an AggregateError if more than one error is returned.
v10.0.0
The callback parameter is no longer optional. Not passing it will throw a TypeError at runtime.
v7.0.0
The callback parameter is no longer optional. Not passing it will emit a deprecation warning with id DEP0013.
v0.4.7
Deprecated since: v0.4.7



Stability: 0 - Deprecated

path <string> | <Buffer> | <URL>
mode <integer>
callback <Function>

err <Error> | <AggregateError>



Changes the permissions on a symbolic link. No arguments other than a possible
exception are given to the completion callback.
This method is only implemented on macOS.
See the POSIX lchmod(2) documentation for more detail.

fs.lchown(path, uid, gid, callback)#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v10.6.0
This API is no longer deprecated.
v10.0.0
The callback parameter is no longer optional. Not passing it will throw a TypeError at runtime.
v7.0.0
The callback parameter is no longer optional. Not passing it will emit a deprecation warning with id DEP0013.
v0.4.7
Documentation-only deprecation.




path <string> | <Buffer> | <URL>
uid <integer>
gid <integer>
callback <Function>

err <Error>



Set the owner of the symbolic link. No arguments other than a possible
exception are given to the completion callback.
See the POSIX lchown(2) documentation for more detail.

fs.lutimes(path, atime, mtime, callback)#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v14.5.0, v12.19.0
Added in: v14.5.0, v12.19.0




path <string> | <Buffer> | <URL>
atime <number> | <string> | <Date>
mtime <number> | <string> | <Date>
callback <Function>

err <Error>



Changes the access and modification times of a file in the same way as
fs.utimes(), with the difference that if the path refers to a symbolic
link, then the link is not dereferenced: instead, the timestamps of the
symbolic link itself are changed.
No arguments other than a possible exception are given to the completion
callback.

fs.link(existingPath, newPath, callback)#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v10.0.0
The callback parameter is no longer optional. Not passing it will throw a TypeError at runtime.
v7.6.0
The existingPath and newPath parameters can be WHATWG URL objects using file: protocol. Support is currently still experimental.
v7.0.0
The callback parameter is no longer optional. Not passing it will emit a deprecation warning with id DEP0013.
v0.1.31
Added in: v0.1.31




existingPath <string> | <Buffer> | <URL>
newPath <string> | <Buffer> | <URL>
callback <Function>

err <Error>



Creates a new link from the existingPath to the newPath. See the POSIX
link(2) documentation for more detail. No arguments other than a possible
exception are given to the completion callback.

fs.lstat(path[, options], callback)#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v10.5.0
Accepts an additional options object to specify whether the numeric values returned should be bigint.
v10.0.0
The callback parameter is no longer optional. Not passing it will throw a TypeError at runtime.
v7.6.0
The path parameter can be a WHATWG URL object using file: protocol.
v7.0.0
The callback parameter is no longer optional. Not passing it will emit a deprecation warning with id DEP0013.
v0.1.30
Added in: v0.1.30




path <string> | <Buffer> | <URL>
options <Object>

bigint <boolean> Whether the numeric values in the returned
<fs.Stats> object should be bigint. Default: false.


callback <Function>

err <Error>
stats <fs.Stats>



Retrieves the <fs.Stats> for the symbolic link referred to by the path.
The callback gets two arguments (err, stats) where stats is a <fs.Stats>
object. lstat() is identical to stat(), except that if path is a symbolic
link, then the link itself is stat-ed, not the file that it refers to.
See the POSIX lstat(2) documentation for more details.

fs.mkdir(path[, options], callback)#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v13.11.0, v12.17.0
In recursive mode, the callback now receives the first created path as an argument.
v10.12.0
The second argument can now be an options object with recursive and mode properties.
v10.0.0
The callback parameter is no longer optional. Not passing it will throw a TypeError at runtime.
v7.6.0
The path parameter can be a WHATWG URL object using file: protocol.
v7.0.0
The callback parameter is no longer optional. Not passing it will emit a deprecation warning with id DEP0013.
v0.1.8
Added in: v0.1.8




path <string> | <Buffer> | <URL>
options <Object> | <integer>

recursive <boolean> Default: false
mode <string> | <integer> Not supported on Windows. Default: 0o777.


callback <Function>

err <Error>
path <string> | <undefined> Present only if a directory is created with
recursive set to true.



Asynchronously creates a directory.
The callback is given a possible exception and, if recursive is true, the
first directory path created, (err[, path]).
path can still be undefined when recursive is true, if no directory was
created (for instance, if it was previously created).
The optional options argument can be an integer specifying mode (permission
and sticky bits), or an object with a mode property and a recursive
property indicating whether parent directories should be created. Calling
fs.mkdir() when path is a directory that exists results in an error only
when recursive is false. If recursive is false and the directory exists,
an EEXIST error occurs.
import { mkdir } from 'node:fs';

// Create ./tmp/a/apple, regardless of whether ./tmp and ./tmp/a exist.
mkdir('./tmp/a/apple', { recursive: true }, (err) => {
  if (err) throw err;
}); copy
On Windows, using fs.mkdir() on the root directory even with recursion will
result in an error:
import { mkdir } from 'node:fs';

mkdir('/', { recursive: true }, (err) => {
  // => [Error: EPERM: operation not permitted, mkdir 'C:\']
}); copy
See the POSIX mkdir(2) documentation for more details.

fs.mkdtemp(prefix[, options], callback)#

History

VersionChanges
v20.6.0, v18.19.0
The prefix parameter now accepts buffers and URL.
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v16.5.0, v14.18.0
The prefix parameter now accepts an empty string.
v10.0.0
The callback parameter is no longer optional. Not passing it will throw a TypeError at runtime.
v7.0.0
The callback parameter is no longer optional. Not passing it will emit a deprecation warning with id DEP0013.
v6.2.1
The callback parameter is optional now.
v5.10.0
Added in: v5.10.0




prefix <string> | <Buffer> | <URL>
options <string> | <Object>

encoding <string> Default: 'utf8'


callback <Function>

err <Error>
directory <string>



Creates a unique temporary directory.
Generates six random characters to be appended behind a required
prefix to create a unique temporary directory. Due to platform
inconsistencies, avoid trailing X characters in prefix. Some platforms,
notably the BSDs, can return more than six random characters, and replace
trailing X characters in prefix with random characters.
The created directory path is passed as a string to the callback's second
parameter.
The optional options argument can be a string specifying an encoding, or an
object with an encoding property specifying the character encoding to use.
import { mkdtemp } from 'node:fs';
import { join } from 'node:path';
import { tmpdir } from 'node:os';

mkdtemp(join(tmpdir(), 'foo-'), (err, directory) => {
  if (err) throw err;
  console.log(directory);
  // Prints: /tmp/foo-itXde2 or C:\Users\...\AppData\Local\Temp\foo-itXde2
}); copy
The fs.mkdtemp() method will append the six randomly selected characters
directly to the prefix string. For instance, given a directory /tmp, if the
intention is to create a temporary directory within /tmp, the prefix
must end with a trailing platform-specific path separator
(require('node:path').sep).
import { tmpdir } from 'node:os';
import { mkdtemp } from 'node:fs';

// The parent directory for the new temporary directory
const tmpDir = tmpdir();

// This method is *INCORRECT*:
mkdtemp(tmpDir, (err, directory) => {
  if (err) throw err;
  console.log(directory);
  // Will print something similar to `/tmpabc123`.
  // A new temporary directory is created at the file system root
  // rather than *within* the /tmp directory.
});

// This method is *CORRECT*:
import { sep } from 'node:path';
mkdtemp(`${tmpDir}${sep}`, (err, directory) => {
  if (err) throw err;
  console.log(directory);
  // Will print something similar to `/tmp/abc123`.
  // A new temporary directory is created within
  // the /tmp directory.
}); copy

fs.open(path[, flags[, mode]], callback)#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v11.1.0
The flags argument is now optional and defaults to 'r'.
v9.9.0
The as and as+ flags are supported now.
v7.6.0
The path parameter can be a WHATWG URL object using file: protocol.
v0.0.2
Added in: v0.0.2




path <string> | <Buffer> | <URL>
flags <string> | <number> See support of file system flags.
Default: 'r'.
mode <string> | <integer> Default: 0o666 (readable and writable)
callback <Function>

err <Error>
fd <integer>



Asynchronous file open. See the POSIX open(2) documentation for more details.
mode sets the file mode (permission and sticky bits), but only if the file was
created. On Windows, only the write permission can be manipulated; see
fs.chmod().
The callback gets two arguments (err, fd).
Some characters (< > : " / \ | ? *) are reserved under Windows as documented
by Naming Files, Paths, and Namespaces. Under NTFS, if the filename contains
a colon, Node.js will open a file system stream, as described by
this MSDN page.
Functions based on fs.open() exhibit this behavior as well:
fs.writeFile(), fs.readFile(), etc.

fs.openAsBlob(path[, options])#

History

VersionChanges
v24.0.0
Marking the API stable.
v19.8.0
Added in: v19.8.0




path <string> | <Buffer> | <URL>
options <Object>

type <string> An optional mime type for the blob.


Returns: <Promise> Fulfills with a <Blob> upon success.

Returns a <Blob> whose data is backed by the given file.
The file must not be modified after the <Blob> is created. Any modifications
will cause reading the <Blob> data to fail with a DOMException error.
Synchronous stat operations on the file when the Blob is created, and before
each read in order to detect whether the file data has been modified on disk.

import { openAsBlob } from 'node:fs';

const blob = await openAsBlob('the.file.txt');
const ab = await blob.arrayBuffer();
blob.stream();const { openAsBlob } = require('node:fs');

(async () => {
  const blob = await openAsBlob('the.file.txt');
  const ab = await blob.arrayBuffer();
  blob.stream();
})();copy

fs.opendir(path[, options], callback)#

History

VersionChanges
v20.1.0, v18.17.0
Added recursive option.
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v13.1.0, v12.16.0
The bufferSize option was introduced.
v12.12.0
Added in: v12.12.0




path <string> | <Buffer> | <URL>
options <Object>

encoding <string> | <null> Default: 'utf8'
bufferSize <number> Number of directory entries that are buffered
internally when reading from the directory. Higher values lead to better
performance but higher memory usage. Default: 32
recursive <boolean> Default: false


callback <Function>

err <Error>
dir <fs.Dir>



Asynchronously open a directory. See the POSIX opendir(3) documentation for
more details.
Creates an <fs.Dir>, which contains all further functions for reading from
and cleaning up the directory.
The encoding option sets the encoding for the path while opening the
directory and subsequent read operations.

fs.read(fd, buffer, offset, length, position, callback)#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v10.10.0
The buffer parameter can now be any TypedArray, or a DataView.
v7.4.0
The buffer parameter can now be a Uint8Array.
v6.0.0
The length parameter can now be 0.
v0.0.2
Added in: v0.0.2




fd <integer>
buffer <Buffer> | <TypedArray> | <DataView> The buffer that the data will be
written to.
offset <integer> The position in buffer to write the data to.
length <integer> The number of bytes to read.
position <integer> | <bigint> | <null> Specifies where to begin reading from in the
file. If position is null or -1 , data will be read from the current
file position, and the file position will be updated. If position is
a non-negative integer, the file position will be unchanged.
callback <Function>

err <Error>
bytesRead <integer>
buffer <Buffer>



Read data from the file specified by fd.
The callback is given the three arguments, (err, bytesRead, buffer).
If the file is not modified concurrently, the end-of-file is reached when the
number of bytes read is zero.
If this method is invoked as its util.promisify()ed version, it returns
a promise for an Object with bytesRead and buffer properties.
The fs.read() method reads data from the file specified
by the file descriptor (fd).
The length argument indicates the maximum number
of bytes that Node.js
will attempt to read from the kernel.
However, the actual number of bytes read (bytesRead) can be lower
than the specified length for various reasons.
For example:

If the file is shorter than the specified length, bytesRead
will be set to the actual number of bytes read.
If the file encounters EOF (End of File) before the buffer could
be filled, Node.js will read all available bytes until EOF is encountered,
and the bytesRead parameter in the callback will indicate
the actual number of bytes read, which may be less than the specified length.
If the file is on a slow network filesystem
or encounters any other issue during reading,
bytesRead can be lower than the specified length.

Therefore, when using fs.read(), it's important to
check the bytesRead value to
determine how many bytes were actually read from the file.
Depending on your application
logic, you may need to handle cases where bytesRead
is lower than the specified length,
such as by wrapping the read call in a loop if you require
a minimum amount of bytes.
This behavior is similar to the POSIX preadv2 function.

fs.read(fd[, options], callback)#

History

VersionChanges
v13.11.0, v12.17.0
Options object can be passed in to make buffer, offset, length, and position optional.
v13.11.0, v12.17.0
Added in: v13.11.0, v12.17.0




fd <integer>
options <Object>

buffer <Buffer> | <TypedArray> | <DataView> Default: Buffer.alloc(16384)
offset <integer> Default: 0
length <integer> Default: buffer.byteLength - offset
position <integer> | <bigint> | <null> Default: null


callback <Function>

err <Error>
bytesRead <integer>
buffer <Buffer>



Similar to the fs.read() function, this version takes an optional
options object. If no options object is specified, it will default with the
above values.

fs.read(fd, buffer[, options], callback)#

Added in: v18.2.0, v16.17.0


fd <integer>
buffer <Buffer> | <TypedArray> | <DataView> The buffer that the data will be
written to.
options <Object>

offset <integer> Default: 0
length <integer> Default: buffer.byteLength - offset
position <integer> | <bigint> Default: null


callback <Function>

err <Error>
bytesRead <integer>
buffer <Buffer>



Similar to the fs.read() function, this version takes an optional
options object. If no options object is specified, it will default with the
above values.

fs.readdir(path[, options], callback)#

History

VersionChanges
v20.1.0, v18.17.0
Added recursive option.
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v10.10.0
New option withFileTypes was added.
v10.0.0
The callback parameter is no longer optional. Not passing it will throw a TypeError at runtime.
v7.6.0
The path parameter can be a WHATWG URL object using file: protocol.
v7.0.0
The callback parameter is no longer optional. Not passing it will emit a deprecation warning with id DEP0013.
v6.0.0
The options parameter was added.
v0.1.8
Added in: v0.1.8




path <string> | <Buffer> | <URL>
options <string> | <Object>

encoding <string> Default: 'utf8'
withFileTypes <boolean> Default: false
recursive <boolean> If true, reads the contents of a directory
recursively. In recursive mode, it will list all files, sub files and
directories. Default: false.


callback <Function>

err <Error>
files <string[]> | <Buffer[]> | <fs.Dirent[]>



Reads the contents of a directory. The callback gets two arguments (err, files)
where files is an array of the names of the files in the directory excluding
'.' and '..'.
See the POSIX readdir(3) documentation for more details.
The optional options argument can be a string specifying an encoding, or an
object with an encoding property specifying the character encoding to use for
the filenames passed to the callback. If the encoding is set to 'buffer',
the filenames returned will be passed as <Buffer> objects.
If options.withFileTypes is set to true, the files array will contain
<fs.Dirent> objects.

fs.readFile(path[, options], callback)#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v16.0.0
The error returned may be an AggregateError if more than one error is returned.
v15.2.0, v14.17.0
The options argument may include an AbortSignal to abort an ongoing readFile request.
v10.0.0
The callback parameter is no longer optional. Not passing it will throw a TypeError at runtime.
v7.6.0
The path parameter can be a WHATWG URL object using file: protocol.
v7.0.0
The callback parameter is no longer optional. Not passing it will emit a deprecation warning with id DEP0013.
v5.1.0
The callback will always be called with null as the error parameter in case of success.
v5.0.0
The path parameter can be a file descriptor now.
v0.1.29
Added in: v0.1.29




path <string> | <Buffer> | <URL> | <integer> filename or file descriptor
options <Object> | <string>

encoding <string> | <null> Default: null
flag <string> See support of file system flags. Default: 'r'.
signal <AbortSignal> allows aborting an in-progress readFile


callback <Function>

err <Error> | <AggregateError>
data <string> | <Buffer>



Asynchronously reads the entire contents of a file.
import { readFile } from 'node:fs';

readFile('/etc/passwd', (err, data) => {
  if (err) throw err;
  console.log(data);
}); copy
The callback is passed two arguments (err, data), where data is the
contents of the file.
If no encoding is specified, then the raw buffer is returned.
If options is a string, then it specifies the encoding:
import { readFile } from 'node:fs';

readFile('/etc/passwd', 'utf8', callback); copy
When the path is a directory, the behavior of fs.readFile() and
fs.readFileSync() is platform-specific. On macOS, Linux, and Windows, an
error will be returned. On FreeBSD, a representation of the directory's contents
will be returned.
import { readFile } from 'node:fs';

// macOS, Linux, and Windows
readFile('<directory>', (err, data) => {
  // => [Error: EISDIR: illegal operation on a directory, read <directory>]
});

//  FreeBSD
readFile('<directory>', (err, data) => {
  // => null, <data>
}); copy
It is possible to abort an ongoing request using an AbortSignal. If a
request is aborted the callback is called with an AbortError:
import { readFile } from 'node:fs';

const controller = new AbortController();
const signal = controller.signal;
readFile(fileInfo[0].name, { signal }, (err, buf) => {
  // ...
});
// When you want to abort the request
controller.abort(); copy
The fs.readFile() function buffers the entire file. To minimize memory costs,
when possible prefer streaming via fs.createReadStream().
Aborting an ongoing request does not abort individual operating
system requests but rather the internal buffering fs.readFile performs.

File descriptors#

Any specified file descriptor has to support reading.
If a file descriptor is specified as the path, it will not be closed
automatically.
The reading will begin at the current position. For example, if the file
already had 'Hello World' and six bytes are read with the file descriptor,
the call to fs.readFile() with the same file descriptor, would give
'World', rather than 'Hello World'.


Performance Considerations#
The fs.readFile() method asynchronously reads the contents of a file into
memory one chunk at a time, allowing the event loop to turn between each chunk.
This allows the read operation to have less impact on other activity that may
be using the underlying libuv thread pool but means that it will take longer
to read a complete file into memory.
The additional read overhead can vary broadly on different systems and depends
on the type of file being read. If the file type is not a regular file (a pipe
for instance) and Node.js is unable to determine an actual file size, each read
operation will load on 64 KiB of data. For regular files, each read will process
512 KiB of data.
For applications that require as-fast-as-possible reading of file contents, it
is better to use fs.read() directly and for application code to manage
reading the full contents of the file itself.
The Node.js GitHub issue #25741 provides more information and a detailed
analysis on the performance of fs.readFile() for multiple file sizes in
different Node.js versions.

fs.readlink(path[, options], callback)#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v10.0.0
The callback parameter is no longer optional. Not passing it will throw a TypeError at runtime.
v7.6.0
The path parameter can be a WHATWG URL object using file: protocol.
v7.0.0
The callback parameter is no longer optional. Not passing it will emit a deprecation warning with id DEP0013.
v0.1.31
Added in: v0.1.31




path <string> | <Buffer> | <URL>
options <string> | <Object>

encoding <string> Default: 'utf8'


callback <Function>

err <Error>
linkString <string> | <Buffer>



Reads the contents of the symbolic link referred to by path. The callback gets
two arguments (err, linkString).
See the POSIX readlink(2) documentation for more details.
The optional options argument can be a string specifying an encoding, or an
object with an encoding property specifying the character encoding to use for
the link path passed to the callback. If the encoding is set to 'buffer',
the link path returned will be passed as a <Buffer> object.

fs.readv(fd, buffers[, position], callback)#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v13.13.0, v12.17.0
Added in: v13.13.0, v12.17.0




fd <integer>
buffers <ArrayBufferView[]>
position <integer> | <null> Default: null
callback <Function>

err <Error>
bytesRead <integer>
buffers <ArrayBufferView[]>



Read from a file specified by fd and write to an array of ArrayBufferViews
using readv().
position is the offset from the beginning of the file from where data
should be read. If typeof position !== 'number', the data will be read
from the current position.
The callback will be given three arguments: err, bytesRead, and
buffers. bytesRead is how many bytes were read from the file.
If this method is invoked as its util.promisify()ed version, it returns
a promise for an Object with bytesRead and buffers properties.

fs.realpath(path[, options], callback)#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v10.0.0
The callback parameter is no longer optional. Not passing it will throw a TypeError at runtime.
v8.0.0
Pipe/Socket resolve support was added.
v7.6.0
The path parameter can be a WHATWG URL object using file: protocol.
v7.0.0
The callback parameter is no longer optional. Not passing it will emit a deprecation warning with id DEP0013.
v6.4.0
Calling realpath now works again for various edge cases on Windows.
v6.0.0
The cache parameter was removed.
v0.1.31
Added in: v0.1.31




path <string> | <Buffer> | <URL>
options <string> | <Object>

encoding <string> Default: 'utf8'


callback <Function>

err <Error>
resolvedPath <string> | <Buffer>



Asynchronously computes the canonical pathname by resolving ., .., and
symbolic links.
A canonical pathname is not necessarily unique. Hard links and bind mounts can
expose a file system entity through many pathnames.
This function behaves like realpath(3), with some exceptions:


No case conversion is performed on case-insensitive file systems.


The maximum number of symbolic links is platform-independent and generally
(much) higher than what the native realpath(3) implementation supports.


The callback gets two arguments (err, resolvedPath). May use process.cwd
to resolve relative paths.
Only paths that can be converted to UTF8 strings are supported.
The optional options argument can be a string specifying an encoding, or an
object with an encoding property specifying the character encoding to use for
the path passed to the callback. If the encoding is set to 'buffer',
the path returned will be passed as a <Buffer> object.
If path resolves to a socket or a pipe, the function will return a system
dependent name for that object.
A path that does not exist results in an ENOENT error.
error.path is the absolute file path.

fs.realpath.native(path[, options], callback)#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v9.2.0
Added in: v9.2.0




path <string> | <Buffer> | <URL>
options <string> | <Object>

encoding <string> Default: 'utf8'


callback <Function>

err <Error>
resolvedPath <string> | <Buffer>



Asynchronous realpath(3).
The callback gets two arguments (err, resolvedPath).
Only paths that can be converted to UTF8 strings are supported.
The optional options argument can be a string specifying an encoding, or an
object with an encoding property specifying the character encoding to use for
the path passed to the callback. If the encoding is set to 'buffer',
the path returned will be passed as a <Buffer> object.
On Linux, when Node.js is linked against musl libc, the procfs file system must
be mounted on /proc in order for this function to work. Glibc does not have
this restriction.

fs.rename(oldPath, newPath, callback)#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v10.0.0
The callback parameter is no longer optional. Not passing it will throw a TypeError at runtime.
v7.6.0
The oldPath and newPath parameters can be WHATWG URL objects using file: protocol. Support is currently still experimental.
v7.0.0
The callback parameter is no longer optional. Not passing it will emit a deprecation warning with id DEP0013.
v0.0.2
Added in: v0.0.2




oldPath <string> | <Buffer> | <URL>
newPath <string> | <Buffer> | <URL>
callback <Function>

err <Error>



Asynchronously rename file at oldPath to the pathname provided
as newPath. In the case that newPath already exists, it will
be overwritten. If there is a directory at newPath, an error will
be raised instead. No arguments other than a possible exception are
given to the completion callback.
See also: rename(2).
import { rename } from 'node:fs';

rename('oldFile.txt', 'newFile.txt', (err) => {
  if (err) throw err;
  console.log('Rename complete!');
}); copy

fs.rmdir(path[, options], callback)#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v16.0.0
Using fs.rmdir(path, { recursive: true }) on a path that is a file is no longer permitted and results in an ENOENT error on Windows and an ENOTDIR error on POSIX.
v16.0.0
Using fs.rmdir(path, { recursive: true }) on a path that does not exist is no longer permitted and results in a ENOENT error.
v16.0.0
The recursive option is deprecated, using it triggers a deprecation warning.
v14.14.0
The recursive option is deprecated, use fs.rm instead.
v13.3.0, v12.16.0
The maxBusyTries option is renamed to maxRetries, and its default is 0. The emfileWait option has been removed, and EMFILE errors use the same retry logic as other errors. The retryDelay option is now supported. ENFILE errors are now retried.
v12.10.0
The recursive, maxBusyTries, and emfileWait options are now supported.
v10.0.0
The callback parameter is no longer optional. Not passing it will throw a TypeError at runtime.
v7.6.0
The path parameters can be a WHATWG URL object using file: protocol.
v7.0.0
The callback parameter is no longer optional. Not passing it will emit a deprecation warning with id DEP0013.
v0.0.2
Added in: v0.0.2




path <string> | <Buffer> | <URL>
options <Object>

maxRetries <integer> If an EBUSY, EMFILE, ENFILE, ENOTEMPTY, or
EPERM error is encountered, Node.js retries the operation with a linear
backoff wait of retryDelay milliseconds longer on each try. This option
represents the number of retries. This option is ignored if the recursive
option is not true. Default: 0.
recursive <boolean> If true, perform a recursive directory removal. In
recursive mode, operations are retried on failure. Default: false.
Deprecated.
retryDelay <integer> The amount of time in milliseconds to wait between
retries. This option is ignored if the recursive option is not true.
Default: 100.


callback <Function>

err <Error>



Asynchronous rmdir(2). No arguments other than a possible exception are given
to the completion callback.
Using fs.rmdir() on a file (not a directory) results in an ENOENT error on
Windows and an ENOTDIR error on POSIX.
To get a behavior similar to the rm -rf Unix command, use fs.rm()
with options { recursive: true, force: true }.

fs.rm(path[, options], callback)#

History

VersionChanges
v17.3.0, v16.14.0
The path parameter can be a WHATWG URL object using file: protocol.
v14.14.0
Added in: v14.14.0




path <string> | <Buffer> | <URL>
options <Object>

force <boolean> When true, exceptions will be ignored if path does
not exist. Default: false.
maxRetries <integer> If an EBUSY, EMFILE, ENFILE, ENOTEMPTY, or
EPERM error is encountered, Node.js will retry the operation with a linear
backoff wait of retryDelay milliseconds longer on each try. This option
represents the number of retries. This option is ignored if the recursive
option is not true. Default: 0.
recursive <boolean> If true, perform a recursive removal. In
recursive mode operations are retried on failure. Default: false.
retryDelay <integer> The amount of time in milliseconds to wait between
retries. This option is ignored if the recursive option is not true.
Default: 100.


callback <Function>

err <Error>



Asynchronously removes files and directories (modeled on the standard POSIX rm
utility). No arguments other than a possible exception are given to the
completion callback.

fs.stat(path[, options], callback)#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v10.5.0
Accepts an additional options object to specify whether the numeric values returned should be bigint.
v10.0.0
The callback parameter is no longer optional. Not passing it will throw a TypeError at runtime.
v7.6.0
The path parameter can be a WHATWG URL object using file: protocol.
v7.0.0
The callback parameter is no longer optional. Not passing it will emit a deprecation warning with id DEP0013.
v0.0.2
Added in: v0.0.2




path <string> | <Buffer> | <URL>
options <Object>

bigint <boolean> Whether the numeric values in the returned
<fs.Stats> object should be bigint. Default: false.


callback <Function>

err <Error>
stats <fs.Stats>



Asynchronous stat(2). The callback gets two arguments (err, stats) where
stats is an <fs.Stats> object.
In case of an error, the err.code will be one of Common System Errors.
fs.stat() follows symbolic links. Use fs.lstat() to look at the
links themselves.
Using fs.stat() to check for the existence of a file before calling
fs.open(), fs.readFile(), or fs.writeFile() is not recommended.
Instead, user code should open/read/write the file directly and handle the
error raised if the file is not available.
To check if a file exists without manipulating it afterwards, fs.access()
is recommended.
For example, given the following directory structure:
- txtDir
-- file.txt
- app.js copy
The next program will check for the stats of the given paths:
import { stat } from 'node:fs';

const pathsToCheck = ['./txtDir', './txtDir/file.txt'];

for (let i = 0; i < pathsToCheck.length; i++) {
  stat(pathsToCheck[i], (err, stats) => {
    console.log(stats.isDirectory());
    console.log(stats);
  });
} copy
The resulting output will resemble:
true
Stats {
  dev: 16777220,
  mode: 16877,
  nlink: 3,
  uid: 501,
  gid: 20,
  rdev: 0,
  blksize: 4096,
  ino: 14214262,
  size: 96,
  blocks: 0,
  atimeMs: 1561174653071.963,
  mtimeMs: 1561174614583.3518,
  ctimeMs: 1561174626623.5366,
  birthtimeMs: 1561174126937.2893,
  atime: 2019-06-22T03:37:33.072Z,
  mtime: 2019-06-22T03:36:54.583Z,
  ctime: 2019-06-22T03:37:06.624Z,
  birthtime: 2019-06-22T03:28:46.937Z
}
false
Stats {
  dev: 16777220,
  mode: 33188,
  nlink: 1,
  uid: 501,
  gid: 20,
  rdev: 0,
  blksize: 4096,
  ino: 14214074,
  size: 8,
  blocks: 8,
  atimeMs: 1561174616618.8555,
  mtimeMs: 1561174614584,
  ctimeMs: 1561174614583.8145,
  birthtimeMs: 1561174007710.7478,
  atime: 2019-06-22T03:36:56.619Z,
  mtime: 2019-06-22T03:36:54.584Z,
  ctime: 2019-06-22T03:36:54.584Z,
  birthtime: 2019-06-22T03:26:47.711Z
} copy

fs.statfs(path[, options], callback)#

Added in: v19.6.0, v18.15.0


path <string> | <Buffer> | <URL>
options <Object>

bigint <boolean> Whether the numeric values in the returned
<fs.StatFs> object should be bigint. Default: false.


callback <Function>

err <Error>
stats <fs.StatFs>



Asynchronous statfs(2). Returns information about the mounted file system which
contains path. The callback gets two arguments (err, stats) where stats
is an <fs.StatFs> object.
In case of an error, the err.code will be one of Common System Errors.

fs.symlink(target, path[, type], callback)#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v12.0.0
If the type argument is left undefined, Node will autodetect target type and automatically select dir or file.
v7.6.0
The target and path parameters can be WHATWG URL objects using file: protocol. Support is currently still experimental.
v0.1.31
Added in: v0.1.31




target <string> | <Buffer> | <URL>
path <string> | <Buffer> | <URL>
type <string> | <null> Default: null
callback <Function>

err <Error>



Creates the link called path pointing to target. No arguments other than a
possible exception are given to the completion callback.
See the POSIX symlink(2) documentation for more details.
The type argument is only available on Windows and ignored on other platforms.
It can be set to 'dir', 'file', or 'junction'. If the type argument is
null, Node.js will autodetect target type and use 'file' or 'dir'.
If the target does not exist, 'file' will be used. Windows junction points
require the destination path to be absolute. When using 'junction', the
target argument will automatically be normalized to absolute path. Junction
points on NTFS volumes can only point to directories.
Relative targets are relative to the link's parent directory.
import { symlink } from 'node:fs';

symlink('./mew', './mewtwo', callback); copy
The above example creates a symbolic link mewtwo which points to mew in the
same directory:
$ tree .
.
├── mew
└── mewtwo -> ./mew copy

fs.truncate(path[, len], callback)#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v16.0.0
The error returned may be an AggregateError if more than one error is returned.
v10.0.0
The callback parameter is no longer optional. Not passing it will throw a TypeError at runtime.
v7.0.0
The callback parameter is no longer optional. Not passing it will emit a deprecation warning with id DEP0013.
v0.8.6
Added in: v0.8.6




path <string> | <Buffer> | <URL>
len <integer> Default: 0
callback <Function>

err <Error> | <AggregateError>



Truncates the file. No arguments other than a possible exception are
given to the completion callback. A file descriptor can also be passed as the
first argument. In this case, fs.ftruncate() is called.

import { truncate } from 'node:fs';
// Assuming that 'path/file.txt' is a regular file.
truncate('path/file.txt', (err) => {
  if (err) throw err;
  console.log('path/file.txt was truncated');
});const { truncate } = require('node:fs');
// Assuming that 'path/file.txt' is a regular file.
truncate('path/file.txt', (err) => {
  if (err) throw err;
  console.log('path/file.txt was truncated');
});copy
Passing a file descriptor is deprecated and may result in an error being thrown
in the future.
See the POSIX truncate(2) documentation for more details.

fs.unlink(path, callback)#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v10.0.0
The callback parameter is no longer optional. Not passing it will throw a TypeError at runtime.
v7.6.0
The path parameter can be a WHATWG URL object using file: protocol.
v7.0.0
The callback parameter is no longer optional. Not passing it will emit a deprecation warning with id DEP0013.
v0.0.2
Added in: v0.0.2




path <string> | <Buffer> | <URL>
callback <Function>

err <Error>



Asynchronously removes a file or symbolic link. No arguments other than a
possible exception are given to the completion callback.
import { unlink } from 'node:fs';
// Assuming that 'path/file.txt' is a regular file.
unlink('path/file.txt', (err) => {
  if (err) throw err;
  console.log('path/file.txt was deleted');
}); copy
fs.unlink() will not work on a directory, empty or otherwise. To remove a
directory, use fs.rmdir().
See the POSIX unlink(2) documentation for more details.

fs.unwatchFile(filename[, listener])#

Added in: v0.1.31


filename <string> | <Buffer> | <URL>
listener <Function> Optional, a listener previously attached using
fs.watchFile()

Stop watching for changes on filename. If listener is specified, only that
particular listener is removed. Otherwise, all listeners are removed,
effectively stopping watching of filename.
Calling fs.unwatchFile() with a filename that is not being watched is a
no-op, not an error.
Using fs.watch() is more efficient than fs.watchFile() and
fs.unwatchFile(). fs.watch() should be used instead of fs.watchFile()
and fs.unwatchFile() when possible.

fs.utimes(path, atime, mtime, callback)#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v10.0.0
The callback parameter is no longer optional. Not passing it will throw a TypeError at runtime.
v8.0.0
NaN, Infinity, and -Infinity are no longer valid time specifiers.
v7.6.0
The path parameter can be a WHATWG URL object using file: protocol.
v7.0.0
The callback parameter is no longer optional. Not passing it will emit a deprecation warning with id DEP0013.
v4.1.0
Numeric strings, NaN, and Infinity are now allowed time specifiers.
v0.4.2
Added in: v0.4.2




path <string> | <Buffer> | <URL>
atime <number> | <string> | <Date>
mtime <number> | <string> | <Date>
callback <Function>

err <Error>



Change the file system timestamps of the object referenced by path.
The atime and mtime arguments follow these rules:

Values can be either numbers representing Unix epoch time in seconds,
Dates, or a numeric string like '123456789.0'.
If the value can not be converted to a number, or is NaN, Infinity, or
-Infinity, an Error will be thrown.


fs.watch(filename[, options][, listener])#

History

VersionChanges
v19.1.0
Added recursive support for Linux, AIX and IBMi.
v15.9.0, v14.17.0
Added support for closing the watcher with an AbortSignal.
v7.6.0
The filename parameter can be a WHATWG URL object using file: protocol.
v7.0.0
The passed options object will never be modified.
v0.5.10
Added in: v0.5.10




filename <string> | <Buffer> | <URL>
options <string> | <Object>

persistent <boolean> Indicates whether the process should continue to run
as long as files are being watched. Default: true.
recursive <boolean> Indicates whether all subdirectories should be
watched, or only the current directory. This applies when a directory is
specified, and only on supported platforms (See caveats). Default:
false.
encoding <string> Specifies the character encoding to be used for the
filename passed to the listener. Default: 'utf8'.
signal <AbortSignal> allows closing the watcher with an AbortSignal.


listener <Function> | <undefined> Default: undefined

eventType <string>
filename <string> | <Buffer> | <null>


Returns: <fs.FSWatcher>

Watch for changes on filename, where filename is either a file or a
directory.
The second argument is optional. If options is provided as a string, it
specifies the encoding. Otherwise options should be passed as an object.
The listener callback gets two arguments (eventType, filename). eventType
is either 'rename' or 'change', and filename is the name of the file
which triggered the event.
On most platforms, 'rename' is emitted whenever a filename appears or
disappears in the directory.
The listener callback is attached to the 'change' event fired by
<fs.FSWatcher>, but it is not the same thing as the 'change' value of
eventType.
If a signal is passed, aborting the corresponding AbortController will close
the returned <fs.FSWatcher>.

Caveats#

The fs.watch API is not 100% consistent across platforms, and is
unavailable in some situations.
On Windows, no events will be emitted if the watched directory is moved or
renamed. An EPERM error is reported when the watched directory is deleted.
The fs.watch API does not provide any protection with respect
to malicious actions on the file system. For example, on Windows it is
implemented by monitoring changes in a directory versus specific files. This
allows substitution of a file and fs reporting changes on the new file
with the same filename.

Availability#

This feature depends on the underlying operating system providing a way
to be notified of file system changes.

On Linux systems, this uses inotify(7).
On BSD systems, this uses kqueue(2).
On macOS, this uses kqueue(2) for files and FSEvents for
directories.
On SunOS systems (including Solaris and SmartOS), this uses event ports.
On Windows systems, this feature depends on ReadDirectoryChangesW.
On AIX systems, this feature depends on AHAFS, which must be enabled.
On IBM i systems, this feature is not supported.

If the underlying functionality is not available for some reason, then
fs.watch() will not be able to function and may throw an exception.
For example, watching files or directories can be unreliable, and in some
cases impossible, on network file systems (NFS, SMB, etc) or host file systems
when using virtualization software such as Vagrant or Docker.
It is still possible to use fs.watchFile(), which uses stat polling, but
this method is slower and less reliable.

Inodes#

On Linux and macOS systems, fs.watch() resolves the path to an inode and
watches the inode. If the watched path is deleted and recreated, it is assigned
a new inode. The watch will emit an event for the delete but will continue
watching the original inode. Events for the new inode will not be emitted.
This is expected behavior.
AIX files retain the same inode for the lifetime of a file. Saving and closing a
watched file on AIX will result in two notifications (one for adding new
content, and one for truncation).

Filename argument#

Providing filename argument in the callback is only supported on Linux,
macOS, Windows, and AIX. Even on supported platforms, filename is not always
guaranteed to be provided. Therefore, don't assume that filename argument is
always provided in the callback, and have some fallback logic if it is null.
import { watch } from 'node:fs';
watch('somedir', (eventType, filename) => {
  console.log(`event type is: ${eventType}`);
  if (filename) {
    console.log(`filename provided: ${filename}`);
  } else {
    console.log('filename not provided');
  }
}); copy

fs.watchFile(filename[, options], listener)#

History

VersionChanges
v10.5.0
The bigint option is now supported.
v7.6.0
The filename parameter can be a WHATWG URL object using file: protocol.
v0.1.31
Added in: v0.1.31




filename <string> | <Buffer> | <URL>
options <Object>

bigint <boolean> Default: false
persistent <boolean> Default: true
interval <integer> Default: 5007


listener <Function>

current <fs.Stats>
previous <fs.Stats>


Returns: <fs.StatWatcher>

Watch for changes on filename. The callback listener will be called each
time the file is accessed.
The options argument may be omitted. If provided, it should be an object. The
options object may contain a boolean named persistent that indicates
whether the process should continue to run as long as files are being watched.
The options object may specify an interval property indicating how often the
target should be polled in milliseconds.
The listener gets two arguments the current stat object and the previous
stat object:
import { watchFile } from 'node:fs';

watchFile('message.text', (curr, prev) => {
  console.log(`the current mtime is: ${curr.mtime}`);
  console.log(`the previous mtime was: ${prev.mtime}`);
}); copy
These stat objects are instances of fs.Stat. If the bigint option is true,
the numeric values in these objects are specified as BigInts.
To be notified when the file was modified, not just accessed, it is necessary
to compare curr.mtimeMs and prev.mtimeMs.
When an fs.watchFile operation results in an ENOENT error, it
will invoke the listener once, with all the fields zeroed (or, for dates, the
Unix Epoch). If the file is created later on, the listener will be called
again, with the latest stat objects. This is a change in functionality since
v0.10.
Using fs.watch() is more efficient than fs.watchFile and
fs.unwatchFile. fs.watch should be used instead of fs.watchFile and
fs.unwatchFile when possible.
When a file being watched by fs.watchFile() disappears and reappears,
then the contents of previous in the second callback event (the file's
reappearance) will be the same as the contents of previous in the first
callback event (its disappearance).
This happens when:

the file is deleted, followed by a restore
the file is renamed and then renamed a second time back to its original name


fs.write(fd, buffer, offset[, length[, position]], callback)#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v14.0.0
The buffer parameter won't coerce unsupported input to strings anymore.
v10.10.0
The buffer parameter can now be any TypedArray or a DataView.
v10.0.0
The callback parameter is no longer optional. Not passing it will throw a TypeError at runtime.
v7.4.0
The buffer parameter can now be a Uint8Array.
v7.2.0
The offset and length parameters are optional now.
v7.0.0
The callback parameter is no longer optional. Not passing it will emit a deprecation warning with id DEP0013.
v0.0.2
Added in: v0.0.2




fd <integer>
buffer <Buffer> | <TypedArray> | <DataView>
offset <integer> Default: 0
length <integer> Default: buffer.byteLength - offset
position <integer> | <null> Default: null
callback <Function>

err <Error>
bytesWritten <integer>
buffer <Buffer> | <TypedArray> | <DataView>



Write buffer to the file specified by fd.
offset determines the part of the buffer to be written, and length is
an integer specifying the number of bytes to write.
position refers to the offset from the beginning of the file where this data
should be written. If typeof position !== 'number', the data will be written
at the current position. See pwrite(2).
The callback will be given three arguments (err, bytesWritten, buffer) where
bytesWritten specifies how many bytes were written from buffer.
If this method is invoked as its util.promisify()ed version, it returns
a promise for an Object with bytesWritten and buffer properties.
It is unsafe to use fs.write() multiple times on the same file without waiting
for the callback. For this scenario, fs.createWriteStream() is
recommended.
On Linux, positional writes don't work when the file is opened in append mode.
The kernel ignores the position argument and always appends the data to
the end of the file.

fs.write(fd, buffer[, options], callback)#

Added in: v18.3.0, v16.17.0


fd <integer>
buffer <Buffer> | <TypedArray> | <DataView>
options <Object>

offset <integer> Default: 0
length <integer> Default: buffer.byteLength - offset
position <integer> | <null> Default: null


callback <Function>

err <Error>
bytesWritten <integer>
buffer <Buffer> | <TypedArray> | <DataView>



Write buffer to the file specified by fd.
Similar to the above fs.write function, this version takes an
optional options object. If no options object is specified, it will
default with the above values.

fs.write(fd, string[, position[, encoding]], callback)#

History

VersionChanges
v19.0.0
Passing to the string parameter an object with an own toString function is no longer supported.
v17.8.0
Passing to the string parameter an object with an own toString function is deprecated.
v14.12.0
The string parameter will stringify an object with an explicit toString function.
v14.0.0
The string parameter won't coerce unsupported input to strings anymore.
v10.0.0
The callback parameter is no longer optional. Not passing it will throw a TypeError at runtime.
v7.2.0
The position parameter is optional now.
v7.0.0
The callback parameter is no longer optional. Not passing it will emit a deprecation warning with id DEP0013.
v0.11.5
Added in: v0.11.5




fd <integer>
string <string>
position <integer> | <null> Default: null
encoding <string> Default: 'utf8'
callback <Function>

err <Error>
written <integer>
string <string>



Write string to the file specified by fd. If string is not a string,
an exception is thrown.
position refers to the offset from the beginning of the file where this data
should be written. If typeof position !== 'number' the data will be written at
the current position. See pwrite(2).
encoding is the expected string encoding.
The callback will receive the arguments (err, written, string) where written
specifies how many bytes the passed string required to be written. Bytes
written is not necessarily the same as string characters written. See
Buffer.byteLength.
It is unsafe to use fs.write() multiple times on the same file without waiting
for the callback. For this scenario, fs.createWriteStream() is
recommended.
On Linux, positional writes don't work when the file is opened in append mode.
The kernel ignores the position argument and always appends the data to
the end of the file.
On Windows, if the file descriptor is connected to the console (e.g. fd == 1
or stdout) a string containing non-ASCII characters will not be rendered
properly by default, regardless of the encoding used.
It is possible to configure the console to render UTF-8 properly by changing the
active codepage with the chcp 65001 command. See the chcp docs for more
details.

fs.writeFile(file, data[, options], callback)#

History

VersionChanges
v21.0.0, v20.10.0
The flush option is now supported.
v19.0.0
Passing to the string parameter an object with an own toString function is no longer supported.
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v17.8.0
Passing to the string parameter an object with an own toString function is deprecated.
v16.0.0
The error returned may be an AggregateError if more than one error is returned.
v15.2.0, v14.17.0
The options argument may include an AbortSignal to abort an ongoing writeFile request.
v14.12.0
The data parameter will stringify an object with an explicit toString function.
v14.0.0
The data parameter won't coerce unsupported input to strings anymore.
v10.10.0
The data parameter can now be any TypedArray or a DataView.
v10.0.0
The callback parameter is no longer optional. Not passing it will throw a TypeError at runtime.
v7.4.0
The data parameter can now be a Uint8Array.
v7.0.0
The callback parameter is no longer optional. Not passing it will emit a deprecation warning with id DEP0013.
v5.0.0
The file parameter can be a file descriptor now.
v0.1.29
Added in: v0.1.29




file <string> | <Buffer> | <URL> | <integer> filename or file descriptor
data <string> | <Buffer> | <TypedArray> | <DataView>
options <Object> | <string>

encoding <string> | <null> Default: 'utf8'
mode <integer> Default: 0o666
flag <string> See support of file system flags. Default: 'w'.
flush <boolean> If all data is successfully written to the file, and
flush is true, fs.fsync() is used to flush the data.
Default: false.
signal <AbortSignal> allows aborting an in-progress writeFile


callback <Function>

err <Error> | <AggregateError>



When file is a filename, asynchronously writes data to the file, replacing the
file if it already exists. data can be a string or a buffer.
When file is a file descriptor, the behavior is similar to calling
fs.write() directly (which is recommended). See the notes below on using
a file descriptor.
The encoding option is ignored if data is a buffer.
The mode option only affects the newly created file. See fs.open()
for more details.
import { writeFile } from 'node:fs';
import { Buffer } from 'node:buffer';

const data = new Uint8Array(Buffer.from('Hello Node.js'));
writeFile('message.txt', data, (err) => {
  if (err) throw err;
  console.log('The file has been saved!');
}); copy
If options is a string, then it specifies the encoding:
import { writeFile } from 'node:fs';

writeFile('message.txt', 'Hello Node.js', 'utf8', callback); copy
It is unsafe to use fs.writeFile() multiple times on the same file without
waiting for the callback. For this scenario, fs.createWriteStream() is
recommended.
Similarly to fs.readFile - fs.writeFile is a convenience method that
performs multiple write calls internally to write the buffer passed to it.
For performance sensitive code consider using fs.createWriteStream().
It is possible to use an <AbortSignal> to cancel an fs.writeFile().
Cancelation is "best effort", and some amount of data is likely still
to be written.
import { writeFile } from 'node:fs';
import { Buffer } from 'node:buffer';

const controller = new AbortController();
const { signal } = controller;
const data = new Uint8Array(Buffer.from('Hello Node.js'));
writeFile('message.txt', data, { signal }, (err) => {
  // When a request is aborted - the callback is called with an AbortError
});
// When the request should be aborted
controller.abort(); copy
Aborting an ongoing request does not abort individual operating
system requests but rather the internal buffering fs.writeFile performs.

Using fs.writeFile() with file descriptors#
When file is a file descriptor, the behavior is almost identical to directly
calling fs.write() like:
import { write } from 'node:fs';
import { Buffer } from 'node:buffer';

write(fd, Buffer.from(data, options.encoding), callback); copy
The difference from directly calling fs.write() is that under some unusual
conditions, fs.write() might write only part of the buffer and need to be
retried to write the remaining data, whereas fs.writeFile() retries until
the data is entirely written (or an error occurs).
The implications of this are a common source of confusion. In
the file descriptor case, the file is not replaced! The data is not necessarily
written to the beginning of the file, and the file's original data may remain
before and/or after the newly written data.
For example, if fs.writeFile() is called twice in a row, first to write the
string 'Hello', then to write the string ', World', the file would contain
'Hello, World', and might contain some of the file's original data (depending
on the size of the original file, and the position of the file descriptor). If
a file name had been used instead of a descriptor, the file would be guaranteed
to contain only ', World'.

fs.writev(fd, buffers[, position], callback)#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v12.9.0
Added in: v12.9.0




fd <integer>
buffers <ArrayBufferView[]>
position <integer> | <null> Default: null
callback <Function>

err <Error>
bytesWritten <integer>
buffers <ArrayBufferView[]>



Write an array of ArrayBufferViews to the file specified by fd using
writev().
position is the offset from the beginning of the file where this data
should be written. If typeof position !== 'number', the data will be written
at the current position.
The callback will be given three arguments: err, bytesWritten, and
buffers. bytesWritten is how many bytes were written from buffers.
If this method is util.promisify()ed, it returns a promise for an
Object with bytesWritten and buffers properties.
It is unsafe to use fs.writev() multiple times on the same file without
waiting for the callback. For this scenario, use fs.createWriteStream().
On Linux, positional writes don't work when the file is opened in append mode.
The kernel ignores the position argument and always appends the data to
the end of the file.

Synchronous API#
The synchronous APIs perform all operations synchronously, blocking the
event loop until the operation completes or fails.

fs.accessSync(path[, mode])#

History

VersionChanges
v7.6.0
The path parameter can be a WHATWG URL object using file: protocol.
v0.11.15
Added in: v0.11.15




path <string> | <Buffer> | <URL>
mode <integer> Default: fs.constants.F_OK

Synchronously tests a user's permissions for the file or directory specified
by path. The mode argument is an optional integer that specifies the
accessibility checks to be performed. mode should be either the value
fs.constants.F_OK or a mask consisting of the bitwise OR of any of
fs.constants.R_OK, fs.constants.W_OK, and fs.constants.X_OK (e.g.
fs.constants.W_OK | fs.constants.R_OK). Check File access constants for
possible values of mode.
If any of the accessibility checks fail, an Error will be thrown. Otherwise,
the method will return undefined.
import { accessSync, constants } from 'node:fs';

try {
  accessSync('etc/passwd', constants.R_OK | constants.W_OK);
  console.log('can read/write');
} catch (err) {
  console.error('no access!');
} copy

fs.appendFileSync(path, data[, options])#

History

VersionChanges
v21.1.0, v20.10.0
The flush option is now supported.
v7.0.0
The passed options object will never be modified.
v5.0.0
The file parameter can be a file descriptor now.
v0.6.7
Added in: v0.6.7




path <string> | <Buffer> | <URL> | <number> filename or file descriptor
data <string> | <Buffer>
options <Object> | <string>

encoding <string> | <null> Default: 'utf8'
mode <integer> Default: 0o666
flag <string> See support of file system flags. Default: 'a'.
flush <boolean> If true, the underlying file descriptor is flushed
prior to closing it. Default: false.



Synchronously append data to a file, creating the file if it does not yet
exist. data can be a string or a <Buffer>.
The mode option only affects the newly created file. See fs.open()
for more details.
import { appendFileSync } from 'node:fs';

try {
  appendFileSync('message.txt', 'data to append');
  console.log('The "data to append" was appended to file!');
} catch (err) {
  /* Handle the error */
} copy
If options is a string, then it specifies the encoding:
import { appendFileSync } from 'node:fs';

appendFileSync('message.txt', 'data to append', 'utf8'); copy
The path may be specified as a numeric file descriptor that has been opened
for appending (using fs.open() or fs.openSync()). The file descriptor will
not be closed automatically.
import { openSync, closeSync, appendFileSync } from 'node:fs';

let fd;

try {
  fd = openSync('message.txt', 'a');
  appendFileSync(fd, 'data to append', 'utf8');
} catch (err) {
  /* Handle the error */
} finally {
  if (fd !== undefined)
    closeSync(fd);
} copy

fs.chmodSync(path, mode)#

History

VersionChanges
v7.6.0
The path parameter can be a WHATWG URL object using file: protocol.
v0.6.7
Added in: v0.6.7




path <string> | <Buffer> | <URL>
mode <string> | <integer>

For detailed information, see the documentation of the asynchronous version of
this API: fs.chmod().
See the POSIX chmod(2) documentation for more detail.

fs.chownSync(path, uid, gid)#

History

VersionChanges
v7.6.0
The path parameter can be a WHATWG URL object using file: protocol.
v0.1.97
Added in: v0.1.97




path <string> | <Buffer> | <URL>
uid <integer>
gid <integer>

Synchronously changes owner and group of a file. Returns undefined.
This is the synchronous version of fs.chown().
See the POSIX chown(2) documentation for more detail.

fs.closeSync(fd)#

Added in: v0.1.21


fd <integer>

Closes the file descriptor. Returns undefined.
Calling fs.closeSync() on any file descriptor (fd) that is currently in use
through any other fs operation may lead to undefined behavior.
See the POSIX close(2) documentation for more detail.

fs.copyFileSync(src, dest[, mode])#

History

VersionChanges
v14.0.0
Changed flags argument to mode and imposed stricter type validation.
v8.5.0
Added in: v8.5.0




src <string> | <Buffer> | <URL> source filename to copy
dest <string> | <Buffer> | <URL> destination filename of the copy operation
mode <integer> modifiers for copy operation. Default: 0.

Synchronously copies src to dest. By default, dest is overwritten if it
already exists. Returns undefined. Node.js makes no guarantees about the
atomicity of the copy operation. If an error occurs after the destination file
has been opened for writing, Node.js will attempt to remove the destination.
mode is an optional integer that specifies the behavior
of the copy operation. It is possible to create a mask consisting of the bitwise
OR of two or more values (e.g.
fs.constants.COPYFILE_EXCL | fs.constants.COPYFILE_FICLONE).

fs.constants.COPYFILE_EXCL: The copy operation will fail if dest already
exists.
fs.constants.COPYFILE_FICLONE: The copy operation will attempt to create a
copy-on-write reflink. If the platform does not support copy-on-write, then a
fallback copy mechanism is used.
fs.constants.COPYFILE_FICLONE_FORCE: The copy operation will attempt to
create a copy-on-write reflink. If the platform does not support
copy-on-write, then the operation will fail.

import { copyFileSync, constants } from 'node:fs';

// destination.txt will be created or overwritten by default.
copyFileSync('source.txt', 'destination.txt');
console.log('source.txt was copied to destination.txt');

// By using COPYFILE_EXCL, the operation will fail if destination.txt exists.
copyFileSync('source.txt', 'destination.txt', constants.COPYFILE_EXCL); copy

fs.cpSync(src, dest[, options])#

History

VersionChanges
v22.3.0
This API is no longer experimental.
v20.1.0, v18.17.0
Accept an additional mode option to specify the copy behavior as the mode argument of fs.copyFile().
v17.6.0, v16.15.0
Accepts an additional verbatimSymlinks option to specify whether to perform path resolution for symlinks.
v16.7.0
Added in: v16.7.0




src <string> | <URL> source path to copy.
dest <string> | <URL> destination path to copy to.
options <Object>

dereference <boolean> dereference symlinks. Default: false.
errorOnExist <boolean> when force is false, and the destination
exists, throw an error. Default: false.
filter <Function> Function to filter copied files/directories. Return
true to copy the item, false to ignore it. When ignoring a directory,
all of its contents will be skipped as well. Default: undefined

src <string> source path to copy.
dest <string> destination path to copy to.
Returns: <boolean> Any non-Promise value that is coercible
to boolean.


force <boolean> overwrite existing file or directory. The copy
operation will ignore errors if you set this to false and the destination
exists. Use the errorOnExist option to change this behavior.
Default: true.
mode <integer> modifiers for copy operation. Default: 0.
See mode flag of fs.copyFileSync().
preserveTimestamps <boolean> When true timestamps from src will
be preserved. Default: false.
recursive <boolean> copy directories recursively Default: false
verbatimSymlinks <boolean> When true, path resolution for symlinks will
be skipped. Default: false



Synchronously copies the entire directory structure from src to dest,
including subdirectories and files.
When copying a directory to another directory, globs are not supported and
behavior is similar to cp dir1/ dir2/.

fs.existsSync(path)#

History

VersionChanges
v7.6.0
The path parameter can be a WHATWG URL object using file: protocol.
v0.1.21
Added in: v0.1.21




path <string> | <Buffer> | <URL>
Returns: <boolean>

Returns true if the path exists, false otherwise.
For detailed information, see the documentation of the asynchronous version of
this API: fs.exists().
fs.exists() is deprecated, but fs.existsSync() is not. The callback
parameter to fs.exists() accepts parameters that are inconsistent with other
Node.js callbacks. fs.existsSync() does not use a callback.
import { existsSync } from 'node:fs';

if (existsSync('/etc/passwd'))
  console.log('The path exists.'); copy

fs.fchmodSync(fd, mode)#

Added in: v0.4.7


fd <integer>
mode <string> | <integer>

Sets the permissions on the file. Returns undefined.
See the POSIX fchmod(2) documentation for more detail.

fs.fchownSync(fd, uid, gid)#

Added in: v0.4.7


fd <integer>
uid <integer> The file's new owner's user id.
gid <integer> The file's new group's group id.

Sets the owner of the file. Returns undefined.
See the POSIX fchown(2) documentation for more detail.

fs.fdatasyncSync(fd)#

Added in: v0.1.96


fd <integer>

Forces all currently queued I/O operations associated with the file to the
operating system's synchronized I/O completion state. Refer to the POSIX
fdatasync(2) documentation for details. Returns undefined.

fs.fstatSync(fd[, options])#

History

VersionChanges
v10.5.0
Accepts an additional options object to specify whether the numeric values returned should be bigint.
v0.1.95
Added in: v0.1.95




fd <integer>
options <Object>

bigint <boolean> Whether the numeric values in the returned
<fs.Stats> object should be bigint. Default: false.


Returns: <fs.Stats>

Retrieves the <fs.Stats> for the file descriptor.
See the POSIX fstat(2) documentation for more detail.

fs.fsyncSync(fd)#

Added in: v0.1.96


fd <integer>

Request that all data for the open file descriptor is flushed to the storage
device. The specific implementation is operating system and device specific.
Refer to the POSIX fsync(2) documentation for more detail. Returns undefined.

fs.ftruncateSync(fd[, len])#

Added in: v0.8.6


fd <integer>
len <integer> Default: 0

Truncates the file descriptor. Returns undefined.
For detailed information, see the documentation of the asynchronous version of
this API: fs.ftruncate().

fs.futimesSync(fd, atime, mtime)#

History

VersionChanges
v4.1.0
Numeric strings, NaN, and Infinity are now allowed time specifiers.
v0.4.2
Added in: v0.4.2




fd <integer>
atime <number> | <string> | <Date>
mtime <number> | <string> | <Date>

Synchronous version of fs.futimes(). Returns undefined.

fs.globSync(pattern[, options])#

History

VersionChanges
v24.0.0
Marking the API stable.
v23.7.0, v22.14.0
Add support for exclude option to accept glob patterns.
v22.2.0
Add support for withFileTypes as an option.
v22.0.0
Added in: v22.0.0




pattern <string> | <string[]>
options <Object>

cwd <string> current working directory. Default: process.cwd()
exclude <Function> | <string[]> Function to filter out files/directories or a
list of glob patterns to be excluded. If a function is provided, return
true to exclude the item, false to include it. Default: undefined.
withFileTypes <boolean> true if the glob should return paths as Dirents,
false otherwise. Default: false.


Returns: <string[]> paths of files that match the pattern.


import { globSync } from 'node:fs';

console.log(globSync('**/*.js'));const { globSync } = require('node:fs');

console.log(globSync('**/*.js'));copy

fs.lchmodSync(path, mode)#

Deprecated since: v0.4.7

Stability: 0 - Deprecated

path <string> | <Buffer> | <URL>
mode <integer>

Changes the permissions on a symbolic link. Returns undefined.
This method is only implemented on macOS.
See the POSIX lchmod(2) documentation for more detail.

fs.lchownSync(path, uid, gid)#

History

VersionChanges
v10.6.0
This API is no longer deprecated.
v0.4.7
Documentation-only deprecation.




path <string> | <Buffer> | <URL>
uid <integer> The file's new owner's user id.
gid <integer> The file's new group's group id.

Set the owner for the path. Returns undefined.
See the POSIX lchown(2) documentation for more details.

fs.lutimesSync(path, atime, mtime)#

Added in: v14.5.0, v12.19.0


path <string> | <Buffer> | <URL>
atime <number> | <string> | <Date>
mtime <number> | <string> | <Date>

Change the file system timestamps of the symbolic link referenced by path.
Returns undefined, or throws an exception when parameters are incorrect or
the operation fails. This is the synchronous version of fs.lutimes().

fs.linkSync(existingPath, newPath)#

History

VersionChanges
v7.6.0
The existingPath and newPath parameters can be WHATWG URL objects using file: protocol. Support is currently still experimental.
v0.1.31
Added in: v0.1.31




existingPath <string> | <Buffer> | <URL>
newPath <string> | <Buffer> | <URL>

Creates a new link from the existingPath to the newPath. See the POSIX
link(2) documentation for more detail. Returns undefined.

fs.lstatSync(path[, options])#

History

VersionChanges
v15.3.0, v14.17.0
Accepts a throwIfNoEntry option to specify whether an exception should be thrown if the entry does not exist.
v10.5.0
Accepts an additional options object to specify whether the numeric values returned should be bigint.
v7.6.0
The path parameter can be a WHATWG URL object using file: protocol.
v0.1.30
Added in: v0.1.30




path <string> | <Buffer> | <URL>
options <Object>

bigint <boolean> Whether the numeric values in the returned
<fs.Stats> object should be bigint. Default: false.
throwIfNoEntry <boolean> Whether an exception will be thrown
if no file system entry exists, rather than returning undefined.
Default: true.


Returns: <fs.Stats>

Retrieves the <fs.Stats> for the symbolic link referred to by path.
See the POSIX lstat(2) documentation for more details.

fs.mkdirSync(path[, options])#

History

VersionChanges
v13.11.0, v12.17.0
In recursive mode, the first created path is returned now.
v10.12.0
The second argument can now be an options object with recursive and mode properties.
v7.6.0
The path parameter can be a WHATWG URL object using file: protocol.
v0.1.21
Added in: v0.1.21




path <string> | <Buffer> | <URL>
options <Object> | <integer>

recursive <boolean> Default: false
mode <string> | <integer> Not supported on Windows. Default: 0o777.


Returns: <string> | <undefined>

Synchronously creates a directory. Returns undefined, or if recursive is
true, the first directory path created.
This is the synchronous version of fs.mkdir().
See the POSIX mkdir(2) documentation for more details.

fs.mkdtempSync(prefix[, options])#

History

VersionChanges
v20.6.0, v18.19.0
The prefix parameter now accepts buffers and URL.
v16.5.0, v14.18.0
The prefix parameter now accepts an empty string.
v5.10.0
Added in: v5.10.0




prefix <string> | <Buffer> | <URL>
options <string> | <Object>

encoding <string> Default: 'utf8'


Returns: <string>

Returns the created directory path.
For detailed information, see the documentation of the asynchronous version of
this API: fs.mkdtemp().
The optional options argument can be a string specifying an encoding, or an
object with an encoding property specifying the character encoding to use.

fs.opendirSync(path[, options])#

History

VersionChanges
v20.1.0, v18.17.0
Added recursive option.
v13.1.0, v12.16.0
The bufferSize option was introduced.
v12.12.0
Added in: v12.12.0




path <string> | <Buffer> | <URL>
options <Object>

encoding <string> | <null> Default: 'utf8'
bufferSize <number> Number of directory entries that are buffered
internally when reading from the directory. Higher values lead to better
performance but higher memory usage. Default: 32
recursive <boolean> Default: false


Returns: <fs.Dir>

Synchronously open a directory. See opendir(3).
Creates an <fs.Dir>, which contains all further functions for reading from
and cleaning up the directory.
The encoding option sets the encoding for the path while opening the
directory and subsequent read operations.

fs.openSync(path[, flags[, mode]])#

History

VersionChanges
v11.1.0
The flags argument is now optional and defaults to 'r'.
v9.9.0
The as and as+ flags are supported now.
v7.6.0
The path parameter can be a WHATWG URL object using file: protocol.
v0.1.21
Added in: v0.1.21




path <string> | <Buffer> | <URL>
flags <string> | <number> Default: 'r'.
See support of file system flags.
mode <string> | <integer> Default: 0o666
Returns: <number>

Returns an integer representing the file descriptor.
For detailed information, see the documentation of the asynchronous version of
this API: fs.open().

fs.readdirSync(path[, options])#

History

VersionChanges
v20.1.0, v18.17.0
Added recursive option.
v10.10.0
New option withFileTypes was added.
v7.6.0
The path parameter can be a WHATWG URL object using file: protocol.
v0.1.21
Added in: v0.1.21




path <string> | <Buffer> | <URL>
options <string> | <Object>

encoding <string> Default: 'utf8'
withFileTypes <boolean> Default: false
recursive <boolean> If true, reads the contents of a directory
recursively. In recursive mode, it will list all files, sub files, and
directories. Default: false.


Returns: <string[]> | <Buffer[]> | <fs.Dirent[]>

Reads the contents of the directory.
See the POSIX readdir(3) documentation for more details.
The optional options argument can be a string specifying an encoding, or an
object with an encoding property specifying the character encoding to use for
the filenames returned. If the encoding is set to 'buffer',
the filenames returned will be passed as <Buffer> objects.
If options.withFileTypes is set to true, the result will contain
<fs.Dirent> objects.

fs.readFileSync(path[, options])#

History

VersionChanges
v7.6.0
The path parameter can be a WHATWG URL object using file: protocol.
v5.0.0
The path parameter can be a file descriptor now.
v0.1.8
Added in: v0.1.8




path <string> | <Buffer> | <URL> | <integer> filename or file descriptor
options <Object> | <string>

encoding <string> | <null> Default: null
flag <string> See support of file system flags. Default: 'r'.


Returns: <string> | <Buffer>

Returns the contents of the path.
For detailed information, see the documentation of the asynchronous version of
this API: fs.readFile().
If the encoding option is specified then this function returns a
string. Otherwise it returns a buffer.
Similar to fs.readFile(), when the path is a directory, the behavior of
fs.readFileSync() is platform-specific.
import { readFileSync } from 'node:fs';

// macOS, Linux, and Windows
readFileSync('<directory>');
// => [Error: EISDIR: illegal operation on a directory, read <directory>]

//  FreeBSD
readFileSync('<directory>'); // => <data> copy

fs.readlinkSync(path[, options])#

History

VersionChanges
v7.6.0
The path parameter can be a WHATWG URL object using file: protocol.
v0.1.31
Added in: v0.1.31




path <string> | <Buffer> | <URL>
options <string> | <Object>

encoding <string> Default: 'utf8'


Returns: <string> | <Buffer>

Returns the symbolic link's string value.
See the POSIX readlink(2) documentation for more details.
The optional options argument can be a string specifying an encoding, or an
object with an encoding property specifying the character encoding to use for
the link path returned. If the encoding is set to 'buffer',
the link path returned will be passed as a <Buffer> object.

fs.readSync(fd, buffer, offset, length[, position])#

History

VersionChanges
v10.10.0
The buffer parameter can now be any TypedArray or a DataView.
v6.0.0
The length parameter can now be 0.
v0.1.21
Added in: v0.1.21




fd <integer>
buffer <Buffer> | <TypedArray> | <DataView>
offset <integer>
length <integer>
position <integer> | <bigint> | <null> Default: null
Returns: <number>

Returns the number of bytesRead.
For detailed information, see the documentation of the asynchronous version of
this API: fs.read().

fs.readSync(fd, buffer[, options])#

History

VersionChanges
v13.13.0, v12.17.0
Options object can be passed in to make offset, length, and position optional.
v13.13.0, v12.17.0
Added in: v13.13.0, v12.17.0




fd <integer>
buffer <Buffer> | <TypedArray> | <DataView>
options <Object>

offset <integer> Default: 0
length <integer> Default: buffer.byteLength - offset
position <integer> | <bigint> | <null> Default: null


Returns: <number>

Returns the number of bytesRead.
Similar to the above fs.readSync function, this version takes an optional options object.
If no options object is specified, it will default with the above values.
For detailed information, see the documentation of the asynchronous version of
this API: fs.read().

fs.readvSync(fd, buffers[, position])#

Added in: v13.13.0, v12.17.0


fd <integer>
buffers <ArrayBufferView[]>
position <integer> | <null> Default: null
Returns: <number> The number of bytes read.

For detailed information, see the documentation of the asynchronous version of
this API: fs.readv().

fs.realpathSync(path[, options])#

History

VersionChanges
v8.0.0
Pipe/Socket resolve support was added.
v7.6.0
The path parameter can be a WHATWG URL object using file: protocol.
v6.4.0
Calling realpathSync now works again for various edge cases on Windows.
v6.0.0
The cache parameter was removed.
v0.1.31
Added in: v0.1.31




path <string> | <Buffer> | <URL>
options <string> | <Object>

encoding <string> Default: 'utf8'


Returns: <string> | <Buffer>

Returns the resolved pathname.
For detailed information, see the documentation of the asynchronous version of
this API: fs.realpath().

fs.realpathSync.native(path[, options])#

Added in: v9.2.0


path <string> | <Buffer> | <URL>
options <string> | <Object>

encoding <string> Default: 'utf8'


Returns: <string> | <Buffer>

Synchronous realpath(3).
Only paths that can be converted to UTF8 strings are supported.
The optional options argument can be a string specifying an encoding, or an
object with an encoding property specifying the character encoding to use for
the path returned. If the encoding is set to 'buffer',
the path returned will be passed as a <Buffer> object.
On Linux, when Node.js is linked against musl libc, the procfs file system must
be mounted on /proc in order for this function to work. Glibc does not have
this restriction.

fs.renameSync(oldPath, newPath)#

History

VersionChanges
v7.6.0
The oldPath and newPath parameters can be WHATWG URL objects using file: protocol. Support is currently still experimental.
v0.1.21
Added in: v0.1.21




oldPath <string> | <Buffer> | <URL>
newPath <string> | <Buffer> | <URL>

Renames the file from oldPath to newPath. Returns undefined.
See the POSIX rename(2) documentation for more details.

fs.rmdirSync(path[, options])#

History

VersionChanges
v16.0.0
Using fs.rmdirSync(path, { recursive: true }) on a path that is a file is no longer permitted and results in an ENOENT error on Windows and an ENOTDIR error on POSIX.
v16.0.0
Using fs.rmdirSync(path, { recursive: true }) on a path that does not exist is no longer permitted and results in a ENOENT error.
v16.0.0
The recursive option is deprecated, using it triggers a deprecation warning.
v14.14.0
The recursive option is deprecated, use fs.rmSync instead.
v13.3.0, v12.16.0
The maxBusyTries option is renamed to maxRetries, and its default is 0. The emfileWait option has been removed, and EMFILE errors use the same retry logic as other errors. The retryDelay option is now supported. ENFILE errors are now retried.
v12.10.0
The recursive, maxBusyTries, and emfileWait options are now supported.
v7.6.0
The path parameters can be a WHATWG URL object using file: protocol.
v0.1.21
Added in: v0.1.21




path <string> | <Buffer> | <URL>
options <Object>

maxRetries <integer> If an EBUSY, EMFILE, ENFILE, ENOTEMPTY, or
EPERM error is encountered, Node.js retries the operation with a linear
backoff wait of retryDelay milliseconds longer on each try. This option
represents the number of retries. This option is ignored if the recursive
option is not true. Default: 0.
recursive <boolean> If true, perform a recursive directory removal. In
recursive mode, operations are retried on failure. Default: false.
Deprecated.
retryDelay <integer> The amount of time in milliseconds to wait between
retries. This option is ignored if the recursive option is not true.
Default: 100.



Synchronous rmdir(2). Returns undefined.
Using fs.rmdirSync() on a file (not a directory) results in an ENOENT error
on Windows and an ENOTDIR error on POSIX.
To get a behavior similar to the rm -rf Unix command, use fs.rmSync()
with options { recursive: true, force: true }.

fs.rmSync(path[, options])#

History

VersionChanges
v17.3.0, v16.14.0
The path parameter can be a WHATWG URL object using file: protocol.
v14.14.0
Added in: v14.14.0




path <string> | <Buffer> | <URL>
options <Object>

force <boolean> When true, exceptions will be ignored if path does
not exist. Default: false.
maxRetries <integer> If an EBUSY, EMFILE, ENFILE, ENOTEMPTY, or
EPERM error is encountered, Node.js will retry the operation with a linear
backoff wait of retryDelay milliseconds longer on each try. This option
represents the number of retries. This option is ignored if the recursive
option is not true. Default: 0.
recursive <boolean> If true, perform a recursive directory removal. In
recursive mode operations are retried on failure. Default: false.
retryDelay <integer> The amount of time in milliseconds to wait between
retries. This option is ignored if the recursive option is not true.
Default: 100.



Synchronously removes files and directories (modeled on the standard POSIX rm
utility). Returns undefined.

fs.statSync(path[, options])#

History

VersionChanges
v15.3.0, v14.17.0
Accepts a throwIfNoEntry option to specify whether an exception should be thrown if the entry does not exist.
v10.5.0
Accepts an additional options object to specify whether the numeric values returned should be bigint.
v7.6.0
The path parameter can be a WHATWG URL object using file: protocol.
v0.1.21
Added in: v0.1.21




path <string> | <Buffer> | <URL>
options <Object>

bigint <boolean> Whether the numeric values in the returned
<fs.Stats> object should be bigint. Default: false.
throwIfNoEntry <boolean> Whether an exception will be thrown
if no file system entry exists, rather than returning undefined.
Default: true.


Returns: <fs.Stats>

Retrieves the <fs.Stats> for the path.

fs.statfsSync(path[, options])#

Added in: v19.6.0, v18.15.0


path <string> | <Buffer> | <URL>
options <Object>

bigint <boolean> Whether the numeric values in the returned
<fs.StatFs> object should be bigint. Default: false.


Returns: <fs.StatFs>

Synchronous statfs(2). Returns information about the mounted file system which
contains path.
In case of an error, the err.code will be one of Common System Errors.

fs.symlinkSync(target, path[, type])#

History

VersionChanges
v12.0.0
If the type argument is left undefined, Node will autodetect target type and automatically select dir or file.
v7.6.0
The target and path parameters can be WHATWG URL objects using file: protocol. Support is currently still experimental.
v0.1.31
Added in: v0.1.31




target <string> | <Buffer> | <URL>
path <string> | <Buffer> | <URL>
type <string> | <null> Default: null

Returns undefined.
For detailed information, see the documentation of the asynchronous version of
this API: fs.symlink().

fs.truncateSync(path[, len])#

Added in: v0.8.6


path <string> | <Buffer> | <URL>
len <integer> Default: 0

Truncates the file. Returns undefined. A file descriptor can also be
passed as the first argument. In this case, fs.ftruncateSync() is called.
Passing a file descriptor is deprecated and may result in an error being thrown
in the future.

fs.unlinkSync(path)#

History

VersionChanges
v7.6.0
The path parameter can be a WHATWG URL object using file: protocol.
v0.1.21
Added in: v0.1.21




path <string> | <Buffer> | <URL>

Synchronous unlink(2). Returns undefined.

fs.utimesSync(path, atime, mtime)#

History

VersionChanges
v8.0.0
NaN, Infinity, and -Infinity are no longer valid time specifiers.
v7.6.0
The path parameter can be a WHATWG URL object using file: protocol.
v4.1.0
Numeric strings, NaN, and Infinity are now allowed time specifiers.
v0.4.2
Added in: v0.4.2




path <string> | <Buffer> | <URL>
atime <number> | <string> | <Date>
mtime <number> | <string> | <Date>

Returns undefined.
For detailed information, see the documentation of the asynchronous version of
this API: fs.utimes().

fs.writeFileSync(file, data[, options])#

History

VersionChanges
v21.0.0, v20.10.0
The flush option is now supported.
v19.0.0
Passing to the data parameter an object with an own toString function is no longer supported.
v17.8.0
Passing to the data parameter an object with an own toString function is deprecated.
v14.12.0
The data parameter will stringify an object with an explicit toString function.
v14.0.0
The data parameter won't coerce unsupported input to strings anymore.
v10.10.0
The data parameter can now be any TypedArray or a DataView.
v7.4.0
The data parameter can now be a Uint8Array.
v5.0.0
The file parameter can be a file descriptor now.
v0.1.29
Added in: v0.1.29




file <string> | <Buffer> | <URL> | <integer> filename or file descriptor
data <string> | <Buffer> | <TypedArray> | <DataView>
options <Object> | <string>

encoding <string> | <null> Default: 'utf8'
mode <integer> Default: 0o666
flag <string> See support of file system flags. Default: 'w'.
flush <boolean> If all data is successfully written to the file, and
flush is true, fs.fsyncSync() is used to flush the data.



Returns undefined.
The mode option only affects the newly created file. See fs.open()
for more details.
For detailed information, see the documentation of the asynchronous version of
this API: fs.writeFile().

fs.writeSync(fd, buffer, offset[, length[, position]])#

History

VersionChanges
v14.0.0
The buffer parameter won't coerce unsupported input to strings anymore.
v10.10.0
The buffer parameter can now be any TypedArray or a DataView.
v7.4.0
The buffer parameter can now be a Uint8Array.
v7.2.0
The offset and length parameters are optional now.
v0.1.21
Added in: v0.1.21




fd <integer>
buffer <Buffer> | <TypedArray> | <DataView>
offset <integer> Default: 0
length <integer> Default: buffer.byteLength - offset
position <integer> | <null> Default: null
Returns: <number> The number of bytes written.

For detailed information, see the documentation of the asynchronous version of
this API: fs.write(fd, buffer...).

fs.writeSync(fd, buffer[, options])#

Added in: v18.3.0, v16.17.0


fd <integer>
buffer <Buffer> | <TypedArray> | <DataView>
options <Object>

offset <integer> Default: 0
length <integer> Default: buffer.byteLength - offset
position <integer> | <null> Default: null


Returns: <number> The number of bytes written.

For detailed information, see the documentation of the asynchronous version of
this API: fs.write(fd, buffer...).

fs.writeSync(fd, string[, position[, encoding]])#

History

VersionChanges
v14.0.0
The string parameter won't coerce unsupported input to strings anymore.
v7.2.0
The position parameter is optional now.
v0.11.5
Added in: v0.11.5




fd <integer>
string <string>
position <integer> | <null> Default: null
encoding <string> Default: 'utf8'
Returns: <number> The number of bytes written.

For detailed information, see the documentation of the asynchronous version of
this API: fs.write(fd, string...).

fs.writevSync(fd, buffers[, position])#

Added in: v12.9.0


fd <integer>
buffers <ArrayBufferView[]>
position <integer> | <null> Default: null
Returns: <number> The number of bytes written.

For detailed information, see the documentation of the asynchronous version of
this API: fs.writev().

Common Objects#
The common objects are shared by all of the file system API variants
(promise, callback, and synchronous).

Class: fs.Dir#

Added in: v12.12.0

A class representing a directory stream.
Created by fs.opendir(), fs.opendirSync(), or
fsPromises.opendir().
import { opendir } from 'node:fs/promises';

try {
  const dir = await opendir('./');
  for await (const dirent of dir)
    console.log(dirent.name);
} catch (err) {
  console.error(err);
} copy
When using the async iterator, the <fs.Dir> object will be automatically
closed after the iterator exits.

dir.close()#

Added in: v12.12.0


Returns: <Promise>

Asynchronously close the directory's underlying resource handle.
Subsequent reads will result in errors.
A promise is returned that will be fulfilled after the resource has been
closed.

dir.close(callback)#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v12.12.0
Added in: v12.12.0




callback <Function>

err <Error>



Asynchronously close the directory's underlying resource handle.
Subsequent reads will result in errors.
The callback will be called after the resource handle has been closed.

dir.closeSync()#

Added in: v12.12.0

Synchronously close the directory's underlying resource handle.
Subsequent reads will result in errors.

dir.path#

Added in: v12.12.0


<string>

The read-only path of this directory as was provided to fs.opendir(),
fs.opendirSync(), or fsPromises.opendir().

dir.read()#

Added in: v12.12.0


Returns: <Promise> Fulfills with a <fs.Dirent> | <null>

Asynchronously read the next directory entry via readdir(3) as an
<fs.Dirent>.
A promise is returned that will be fulfilled with an <fs.Dirent>, or null
if there are no more directory entries to read.
Directory entries returned by this function are in no particular order as
provided by the operating system's underlying directory mechanisms.
Entries added or removed while iterating over the directory might not be
included in the iteration results.

dir.read(callback)#

Added in: v12.12.0


callback <Function>

err <Error>
dirent <fs.Dirent> | <null>



Asynchronously read the next directory entry via readdir(3) as an
<fs.Dirent>.
After the read is completed, the callback will be called with an
<fs.Dirent>, or null if there are no more directory entries to read.
Directory entries returned by this function are in no particular order as
provided by the operating system's underlying directory mechanisms.
Entries added or removed while iterating over the directory might not be
included in the iteration results.

dir.readSync()#

Added in: v12.12.0


Returns: <fs.Dirent> | <null>

Synchronously read the next directory entry as an <fs.Dirent>. See the
POSIX readdir(3) documentation for more detail.
If there are no more directory entries to read, null will be returned.
Directory entries returned by this function are in no particular order as
provided by the operating system's underlying directory mechanisms.
Entries added or removed while iterating over the directory might not be
included in the iteration results.

dir[Symbol.asyncIterator]()#

Added in: v12.12.0


Returns: <AsyncIterator> An AsyncIterator of <fs.Dirent>

Asynchronously iterates over the directory until all entries have
been read. Refer to the POSIX readdir(3) documentation for more detail.
Entries returned by the async iterator are always an <fs.Dirent>.
The null case from dir.read() is handled internally.
See <fs.Dir> for an example.
Directory entries returned by this iterator are in no particular order as
provided by the operating system's underlying directory mechanisms.
Entries added or removed while iterating over the directory might not be
included in the iteration results.

Class: fs.Dirent#

Added in: v10.10.0

A representation of a directory entry, which can be a file or a subdirectory
within the directory, as returned by reading from an <fs.Dir>. The
directory entry is a combination of the file name and file type pairs.
Additionally, when fs.readdir() or fs.readdirSync() is called with
the withFileTypes option set to true, the resulting array is filled with
<fs.Dirent> objects, rather than strings or <Buffer>s.

dirent.isBlockDevice()#

Added in: v10.10.0


Returns: <boolean>

Returns true if the <fs.Dirent> object describes a block device.

dirent.isCharacterDevice()#

Added in: v10.10.0


Returns: <boolean>

Returns true if the <fs.Dirent> object describes a character device.

dirent.isDirectory()#

Added in: v10.10.0


Returns: <boolean>

Returns true if the <fs.Dirent> object describes a file system
directory.

dirent.isFIFO()#

Added in: v10.10.0


Returns: <boolean>

Returns true if the <fs.Dirent> object describes a first-in-first-out
(FIFO) pipe.

dirent.isFile()#

Added in: v10.10.0


Returns: <boolean>

Returns true if the <fs.Dirent> object describes a regular file.

dirent.isSocket()#

Added in: v10.10.0


Returns: <boolean>

Returns true if the <fs.Dirent> object describes a socket.

dirent.isSymbolicLink()#

Added in: v10.10.0


Returns: <boolean>

Returns true if the <fs.Dirent> object describes a symbolic link.

dirent.name#

Added in: v10.10.0


<string> | <Buffer>

The file name that this <fs.Dirent> object refers to. The type of this
value is determined by the options.encoding passed to fs.readdir() or
fs.readdirSync().

dirent.parentPath#

History

VersionChanges
v24.0.0
Marking the API stable.
v21.4.0, v20.12.0, v18.20.0
Added in: v21.4.0, v20.12.0, v18.20.0




<string>

The path to the parent directory of the file this <fs.Dirent> object refers to.

Class: fs.FSWatcher#

Added in: v0.5.8


Extends <EventEmitter>

A successful call to fs.watch() method will return a new <fs.FSWatcher>
object.
All <fs.FSWatcher> objects emit a 'change' event whenever a specific watched
file is modified.

Event: 'change'#

Added in: v0.5.8


eventType <string> The type of change event that has occurred
filename <string> | <Buffer> The filename that changed (if relevant/available)

Emitted when something changes in a watched directory or file.
See more details in fs.watch().
The filename argument may not be provided depending on operating system
support. If filename is provided, it will be provided as a <Buffer> if
fs.watch() is called with its encoding option set to 'buffer', otherwise
filename will be a UTF-8 string.
import { watch } from 'node:fs';
// Example when handled through fs.watch() listener
watch('./tmp', { encoding: 'buffer' }, (eventType, filename) => {
  if (filename) {
    console.log(filename);
    // Prints: <Buffer ...>
  }
}); copy

Event: 'close'#

Added in: v10.0.0

Emitted when the watcher stops watching for changes. The closed
<fs.FSWatcher> object is no longer usable in the event handler.

Event: 'error'#

Added in: v0.5.8


error <Error>

Emitted when an error occurs while watching the file. The errored
<fs.FSWatcher> object is no longer usable in the event handler.

watcher.close()#

Added in: v0.5.8

Stop watching for changes on the given <fs.FSWatcher>. Once stopped, the
<fs.FSWatcher> object is no longer usable.

watcher.ref()#

Added in: v14.3.0, v12.20.0


Returns: <fs.FSWatcher>

When called, requests that the Node.js event loop not exit so long as the
<fs.FSWatcher> is active. Calling watcher.ref() multiple times will have
no effect.
By default, all <fs.FSWatcher> objects are "ref'ed", making it normally
unnecessary to call watcher.ref() unless watcher.unref() had been
called previously.

watcher.unref()#

Added in: v14.3.0, v12.20.0


Returns: <fs.FSWatcher>

When called, the active <fs.FSWatcher> object will not require the Node.js
event loop to remain active. If there is no other activity keeping the
event loop running, the process may exit before the <fs.FSWatcher> object's
callback is invoked. Calling watcher.unref() multiple times will have
no effect.

Class: fs.StatWatcher#

Added in: v14.3.0, v12.20.0


Extends <EventEmitter>

A successful call to fs.watchFile() method will return a new <fs.StatWatcher>
object.

watcher.ref()#

Added in: v14.3.0, v12.20.0


Returns: <fs.StatWatcher>

When called, requests that the Node.js event loop not exit so long as the
<fs.StatWatcher> is active. Calling watcher.ref() multiple times will have
no effect.
By default, all <fs.StatWatcher> objects are "ref'ed", making it normally
unnecessary to call watcher.ref() unless watcher.unref() had been
called previously.

watcher.unref()#

Added in: v14.3.0, v12.20.0


Returns: <fs.StatWatcher>

When called, the active <fs.StatWatcher> object will not require the Node.js
event loop to remain active. If there is no other activity keeping the
event loop running, the process may exit before the <fs.StatWatcher> object's
callback is invoked. Calling watcher.unref() multiple times will have
no effect.

Class: fs.ReadStream#

Added in: v0.1.93


Extends: <stream.Readable>

Instances of <fs.ReadStream> are created and returned using the
fs.createReadStream() function.

Event: 'close'#

Added in: v0.1.93

Emitted when the <fs.ReadStream>'s underlying file descriptor has been closed.

Event: 'open'#

Added in: v0.1.93


fd <integer> Integer file descriptor used by the <fs.ReadStream>.

Emitted when the <fs.ReadStream>'s file descriptor has been opened.

Event: 'ready'#

Added in: v9.11.0

Emitted when the <fs.ReadStream> is ready to be used.
Fires immediately after 'open'.

readStream.bytesRead#

Added in: v6.4.0


<number>

The number of bytes that have been read so far.

readStream.path#

Added in: v0.1.93


<string> | <Buffer>

The path to the file the stream is reading from as specified in the first
argument to fs.createReadStream(). If path is passed as a string, then
readStream.path will be a string. If path is passed as a <Buffer>, then
readStream.path will be a <Buffer>. If fd is specified, then
readStream.path will be undefined.

readStream.pending#

Added in: v11.2.0, v10.16.0


<boolean>

This property is true if the underlying file has not been opened yet,
i.e. before the 'ready' event is emitted.

Class: fs.Stats#

History

VersionChanges
v22.0.0, v20.13.0
Public constructor is deprecated.
v8.1.0
Added times as numbers.
v0.1.21
Added in: v0.1.21



A <fs.Stats> object provides information about a file.
Objects returned from fs.stat(), fs.lstat(), fs.fstat(), and
their synchronous counterparts are of this type.
If bigint in the options passed to those methods is true, the numeric values
will be bigint instead of number, and the object will contain additional
nanosecond-precision properties suffixed with Ns.
Stat objects are not to be created directly using the new keyword.
Stats {
  dev: 2114,
  ino: 48064969,
  mode: 33188,
  nlink: 1,
  uid: 85,
  gid: 100,
  rdev: 0,
  size: 527,
  blksize: 4096,
  blocks: 8,
  atimeMs: 1318289051000.1,
  mtimeMs: 1318289051000.1,
  ctimeMs: 1318289051000.1,
  birthtimeMs: 1318289051000.1,
  atime: Mon, 10 Oct 2011 23:24:11 GMT,
  mtime: Mon, 10 Oct 2011 23:24:11 GMT,
  ctime: Mon, 10 Oct 2011 23:24:11 GMT,
  birthtime: Mon, 10 Oct 2011 23:24:11 GMT } copy
bigint version:
BigIntStats {
  dev: 2114n,
  ino: 48064969n,
  mode: 33188n,
  nlink: 1n,
  uid: 85n,
  gid: 100n,
  rdev: 0n,
  size: 527n,
  blksize: 4096n,
  blocks: 8n,
  atimeMs: 1318289051000n,
  mtimeMs: 1318289051000n,
  ctimeMs: 1318289051000n,
  birthtimeMs: 1318289051000n,
  atimeNs: 1318289051000000000n,
  mtimeNs: 1318289051000000000n,
  ctimeNs: 1318289051000000000n,
  birthtimeNs: 1318289051000000000n,
  atime: Mon, 10 Oct 2011 23:24:11 GMT,
  mtime: Mon, 10 Oct 2011 23:24:11 GMT,
  ctime: Mon, 10 Oct 2011 23:24:11 GMT,
  birthtime: Mon, 10 Oct 2011 23:24:11 GMT } copy

stats.isBlockDevice()#

Added in: v0.1.10


Returns: <boolean>

Returns true if the <fs.Stats> object describes a block device.

stats.isCharacterDevice()#

Added in: v0.1.10


Returns: <boolean>

Returns true if the <fs.Stats> object describes a character device.

stats.isDirectory()#

Added in: v0.1.10


Returns: <boolean>

Returns true if the <fs.Stats> object describes a file system directory.
If the <fs.Stats> object was obtained from calling fs.lstat() on a
symbolic link which resolves to a directory, this method will return false.
This is because fs.lstat() returns information
about a symbolic link itself and not the path it resolves to.

stats.isFIFO()#

Added in: v0.1.10


Returns: <boolean>

Returns true if the <fs.Stats> object describes a first-in-first-out (FIFO)
pipe.

stats.isFile()#

Added in: v0.1.10


Returns: <boolean>

Returns true if the <fs.Stats> object describes a regular file.

stats.isSocket()#

Added in: v0.1.10


Returns: <boolean>

Returns true if the <fs.Stats> object describes a socket.

stats.isSymbolicLink()#

Added in: v0.1.10


Returns: <boolean>

Returns true if the <fs.Stats> object describes a symbolic link.
This method is only valid when using fs.lstat().

stats.dev#

<number> | <bigint>

The numeric identifier of the device containing the file.

stats.ino#

<number> | <bigint>

The file system specific "Inode" number for the file.

stats.mode#

<number> | <bigint>

A bit-field describing the file type and mode.

stats.nlink#

<number> | <bigint>

The number of hard-links that exist for the file.

stats.uid#

<number> | <bigint>

The numeric user identifier of the user that owns the file (POSIX).

stats.gid#

<number> | <bigint>

The numeric group identifier of the group that owns the file (POSIX).

stats.rdev#

<number> | <bigint>

A numeric device identifier if the file represents a device.

stats.size#

<number> | <bigint>

The size of the file in bytes.
If the underlying file system does not support getting the size of the file,
this will be 0.

stats.blksize#

<number> | <bigint>

The file system block size for i/o operations.

stats.blocks#

<number> | <bigint>

The number of blocks allocated for this file.

stats.atimeMs#

Added in: v8.1.0


<number> | <bigint>

The timestamp indicating the last time this file was accessed expressed in
milliseconds since the POSIX Epoch.

stats.mtimeMs#

Added in: v8.1.0


<number> | <bigint>

The timestamp indicating the last time this file was modified expressed in
milliseconds since the POSIX Epoch.

stats.ctimeMs#

Added in: v8.1.0


<number> | <bigint>

The timestamp indicating the last time the file status was changed expressed
in milliseconds since the POSIX Epoch.

stats.birthtimeMs#

Added in: v8.1.0


<number> | <bigint>

The timestamp indicating the creation time of this file expressed in
milliseconds since the POSIX Epoch.

stats.atimeNs#

Added in: v12.10.0


<bigint>

Only present when bigint: true is passed into the method that generates
the object.
The timestamp indicating the last time this file was accessed expressed in
nanoseconds since the POSIX Epoch.

stats.mtimeNs#

Added in: v12.10.0


<bigint>

Only present when bigint: true is passed into the method that generates
the object.
The timestamp indicating the last time this file was modified expressed in
nanoseconds since the POSIX Epoch.

stats.ctimeNs#

Added in: v12.10.0


<bigint>

Only present when bigint: true is passed into the method that generates
the object.
The timestamp indicating the last time the file status was changed expressed
in nanoseconds since the POSIX Epoch.

stats.birthtimeNs#

Added in: v12.10.0


<bigint>

Only present when bigint: true is passed into the method that generates
the object.
The timestamp indicating the creation time of this file expressed in
nanoseconds since the POSIX Epoch.

stats.atime#

Added in: v0.11.13


<Date>

The timestamp indicating the last time this file was accessed.

stats.mtime#

Added in: v0.11.13


<Date>

The timestamp indicating the last time this file was modified.

stats.ctime#

Added in: v0.11.13


<Date>

The timestamp indicating the last time the file status was changed.

stats.birthtime#

Added in: v0.11.13


<Date>

The timestamp indicating the creation time of this file.

Stat time values#
The atimeMs, mtimeMs, ctimeMs, birthtimeMs properties are
numeric values that hold the corresponding times in milliseconds. Their
precision is platform specific. When bigint: true is passed into the
method that generates the object, the properties will be bigints,
otherwise they will be numbers.
The atimeNs, mtimeNs, ctimeNs, birthtimeNs properties are
bigints that hold the corresponding times in nanoseconds. They are
only present when bigint: true is passed into the method that generates
the object. Their precision is platform specific.
atime, mtime, ctime, and birthtime are
Date object alternate representations of the various times. The
Date and number values are not connected. Assigning a new number value, or
mutating the Date value, will not be reflected in the corresponding alternate
representation.
The times in the stat object have the following semantics:

atime "Access Time": Time when file data last accessed. Changed
by the mknod(2), utimes(2), and read(2) system calls.
mtime "Modified Time": Time when file data last modified.
Changed by the mknod(2), utimes(2), and write(2) system calls.
ctime "Change Time": Time when file status was last changed
(inode data modification). Changed by the chmod(2), chown(2),
link(2), mknod(2), rename(2), unlink(2), utimes(2),
read(2), and write(2) system calls.
birthtime "Birth Time": Time of file creation. Set once when the
file is created. On file systems where birthtime is not available,
this field may instead hold either the ctime or
1970-01-01T00:00Z (ie, Unix epoch timestamp 0). This value may be greater
than atime or mtime in this case. On Darwin and other FreeBSD variants,
also set if the atime is explicitly set to an earlier value than the current
birthtime using the utimes(2) system call.

Prior to Node.js 0.12, the ctime held the birthtime on Windows systems. As
of 0.12, ctime is not "creation time", and on Unix systems, it never was.

Class: fs.StatFs#

Added in: v19.6.0, v18.15.0

Provides information about a mounted file system.
Objects returned from fs.statfs() and its synchronous counterpart are of
this type. If bigint in the options passed to those methods is true, the
numeric values will be bigint instead of number.
StatFs {
  type: 1397114950,
  bsize: 4096,
  blocks: 121938943,
  bfree: 61058895,
  bavail: 61058895,
  files: 999,
  ffree: 1000000
} copy
bigint version:
StatFs {
  type: 1397114950n,
  bsize: 4096n,
  blocks: 121938943n,
  bfree: 61058895n,
  bavail: 61058895n,
  files: 999n,
  ffree: 1000000n
} copy

statfs.bavail#

Added in: v19.6.0, v18.15.0


<number> | <bigint>

Free blocks available to unprivileged users.

statfs.bfree#

Added in: v19.6.0, v18.15.0


<number> | <bigint>

Free blocks in file system.

statfs.blocks#

Added in: v19.6.0, v18.15.0


<number> | <bigint>

Total data blocks in file system.

statfs.bsize#

Added in: v19.6.0, v18.15.0


<number> | <bigint>

Optimal transfer block size.

statfs.ffree#

Added in: v19.6.0, v18.15.0


<number> | <bigint>

Free file nodes in file system.

statfs.files#

Added in: v19.6.0, v18.15.0


<number> | <bigint>

Total file nodes in file system.

statfs.type#

Added in: v19.6.0, v18.15.0


<number> | <bigint>

Type of file system.

Class: fs.WriteStream#

Added in: v0.1.93


Extends <stream.Writable>

Instances of <fs.WriteStream> are created and returned using the
fs.createWriteStream() function.

Event: 'close'#

Added in: v0.1.93

Emitted when the <fs.WriteStream>'s underlying file descriptor has been closed.

Event: 'open'#

Added in: v0.1.93


fd <integer> Integer file descriptor used by the <fs.WriteStream>.

Emitted when the <fs.WriteStream>'s file is opened.

Event: 'ready'#

Added in: v9.11.0

Emitted when the <fs.WriteStream> is ready to be used.
Fires immediately after 'open'.

writeStream.bytesWritten#

Added in: v0.4.7

The number of bytes written so far. Does not include data that is still queued
for writing.

writeStream.close([callback])#

Added in: v0.9.4


callback <Function>

err <Error>



Closes writeStream. Optionally accepts a
callback that will be executed once the writeStream
is closed.

writeStream.path#

Added in: v0.1.93

The path to the file the stream is writing to as specified in the first
argument to fs.createWriteStream(). If path is passed as a string, then
writeStream.path will be a string. If path is passed as a <Buffer>, then
writeStream.path will be a <Buffer>.

writeStream.pending#

Added in: v11.2.0


<boolean>

This property is true if the underlying file has not been opened yet,
i.e. before the 'ready' event is emitted.

fs.constants#

<Object>

Returns an object containing commonly used constants for file system
operations.

FS constants#
The following constants are exported by fs.constants and fsPromises.constants.
Not every constant will be available on every operating system;
this is especially important for Windows, where many of the POSIX specific
definitions are not available.
For portable applications it is recommended to check for their presence
before use.
To use more than one constant, use the bitwise OR | operator.
Example:
import { open, constants } from 'node:fs';

const {
  O_RDWR,
  O_CREAT,
  O_EXCL,
} = constants;

open('/path/to/my/file', O_RDWR | O_CREAT | O_EXCL, (err, fd) => {
  // ...
}); copy

File access constants#
The following constants are meant for use as the mode parameter passed to
fsPromises.access(), fs.access(), and fs.accessSync().

  
    Constant
    Description
  
  
    F_OK
    Flag indicating that the file is visible to the calling process.
     This is useful for determining if a file exists, but says nothing
     about rwx permissions. Default if no mode is specified.
  
  
    R_OK
    Flag indicating that the file can be read by the calling process.
  
  
    W_OK
    Flag indicating that the file can be written by the calling
    process.
  
  
    X_OK
    Flag indicating that the file can be executed by the calling
    process. This has no effect on Windows
    (will behave like fs.constants.F_OK).
  

The definitions are also available on Windows.

File copy constants#
The following constants are meant for use with fs.copyFile().

  
    Constant
    Description
  
  
    COPYFILE_EXCL
    If present, the copy operation will fail with an error if the
    destination path already exists.
  
  
    COPYFILE_FICLONE
    If present, the copy operation will attempt to create a
    copy-on-write reflink. If the underlying platform does not support
    copy-on-write, then a fallback copy mechanism is used.
  
  
    COPYFILE_FICLONE_FORCE
    If present, the copy operation will attempt to create a
    copy-on-write reflink. If the underlying platform does not support
    copy-on-write, then the operation will fail with an error.
  

The definitions are also available on Windows.

File open constants#
The following constants are meant for use with fs.open().

  
    Constant
    Description
  
  
    O_RDONLY
    Flag indicating to open a file for read-only access.
  
  
    O_WRONLY
    Flag indicating to open a file for write-only access.
  
  
    O_RDWR
    Flag indicating to open a file for read-write access.
  
  
    O_CREAT
    Flag indicating to create the file if it does not already exist.
  
  
    O_EXCL
    Flag indicating that opening a file should fail if the
    O_CREAT flag is set and the file already exists.
  
  
    O_NOCTTY
    Flag indicating that if path identifies a terminal device, opening the
    path shall not cause that terminal to become the controlling terminal for
    the process (if the process does not already have one).
  
  
    O_TRUNC
    Flag indicating that if the file exists and is a regular file, and the
    file is opened successfully for write access, its length shall be truncated
    to zero.
  
  
    O_APPEND
    Flag indicating that data will be appended to the end of the file.
  
  
    O_DIRECTORY
    Flag indicating that the open should fail if the path is not a
    directory.
  
  
  O_NOATIME
    Flag indicating reading accesses to the file system will no longer
    result in an update to the atime information associated with
    the file. This flag is available on Linux operating systems only.
  
  
    O_NOFOLLOW
    Flag indicating that the open should fail if the path is a symbolic
    link.
  
  
    O_SYNC
    Flag indicating that the file is opened for synchronized I/O with write
    operations waiting for file integrity.
  
  
    O_DSYNC
    Flag indicating that the file is opened for synchronized I/O with write
    operations waiting for data integrity.
  
  
    O_SYMLINK
    Flag indicating to open the symbolic link itself rather than the
    resource it is pointing to.
  
  
    O_DIRECT
    When set, an attempt will be made to minimize caching effects of file
    I/O.
  
  
    O_NONBLOCK
    Flag indicating to open the file in nonblocking mode when possible.
  
  
    UV_FS_O_FILEMAP
    When set, a memory file mapping is used to access the file. This flag
    is available on Windows operating systems only. On other operating systems,
    this flag is ignored.
  

On Windows, only O_APPEND, O_CREAT, O_EXCL, O_RDONLY, O_RDWR,
O_TRUNC, O_WRONLY, and UV_FS_O_FILEMAP are available.

File type constants#
The following constants are meant for use with the <fs.Stats> object's
mode property for determining a file's type.

  
    Constant
    Description
  
  
    S_IFMT
    Bit mask used to extract the file type code.
  
  
    S_IFREG
    File type constant for a regular file.
  
  
    S_IFDIR
    File type constant for a directory.
  
  
    S_IFCHR
    File type constant for a character-oriented device file.
  
  
    S_IFBLK
    File type constant for a block-oriented device file.
  
  
    S_IFIFO
    File type constant for a FIFO/pipe.
  
  
    S_IFLNK
    File type constant for a symbolic link.
  
  
    S_IFSOCK
    File type constant for a socket.
  

On Windows, only S_IFCHR, S_IFDIR, S_IFLNK, S_IFMT, and S_IFREG,
are available.

File mode constants#
The following constants are meant for use with the <fs.Stats> object's
mode property for determining the access permissions for a file.

  
    Constant
    Description
  
  
    S_IRWXU
    File mode indicating readable, writable, and executable by owner.
  
  
    S_IRUSR
    File mode indicating readable by owner.
  
  
    S_IWUSR
    File mode indicating writable by owner.
  
  
    S_IXUSR
    File mode indicating executable by owner.
  
  
    S_IRWXG
    File mode indicating readable, writable, and executable by group.
  
  
    S_IRGRP
    File mode indicating readable by group.
  
  
    S_IWGRP
    File mode indicating writable by group.
  
  
    S_IXGRP
    File mode indicating executable by group.
  
  
    S_IRWXO
    File mode indicating readable, writable, and executable by others.
  
  
    S_IROTH
    File mode indicating readable by others.
  
  
    S_IWOTH
    File mode indicating writable by others.
  
  
    S_IXOTH
    File mode indicating executable by others.
  

On Windows, only S_IRUSR and S_IWUSR are available.

Notes#

Ordering of callback and promise-based operations#
Because they are executed asynchronously by the underlying thread pool,
there is no guaranteed ordering when using either the callback or
promise-based methods.
For example, the following is prone to error because the fs.stat()
operation might complete before the fs.rename() operation:
const fs = require('node:fs');

fs.rename('/tmp/hello', '/tmp/world', (err) => {
  if (err) throw err;
  console.log('renamed complete');
});
fs.stat('/tmp/world', (err, stats) => {
  if (err) throw err;
  console.log(`stats: ${JSON.stringify(stats)}`);
}); copy
It is important to correctly order the operations by awaiting the results
of one before invoking the other:

import { rename, stat } from 'node:fs/promises';

const oldPath = '/tmp/hello';
const newPath = '/tmp/world';

try {
  await rename(oldPath, newPath);
  const stats = await stat(newPath);
  console.log(`stats: ${JSON.stringify(stats)}`);
} catch (error) {
  console.error('there was an error:', error.message);
}const { rename, stat } = require('node:fs/promises');

(async function(oldPath, newPath) {
  try {
    await rename(oldPath, newPath);
    const stats = await stat(newPath);
    console.log(`stats: ${JSON.stringify(stats)}`);
  } catch (error) {
    console.error('there was an error:', error.message);
  }
})('/tmp/hello', '/tmp/world');copy
Or, when using the callback APIs, move the fs.stat() call into the callback
of the fs.rename() operation:

import { rename, stat } from 'node:fs';

rename('/tmp/hello', '/tmp/world', (err) => {
  if (err) throw err;
  stat('/tmp/world', (err, stats) => {
    if (err) throw err;
    console.log(`stats: ${JSON.stringify(stats)}`);
  });
});const { rename, stat } = require('node:fs/promises');

rename('/tmp/hello', '/tmp/world', (err) => {
  if (err) throw err;
  stat('/tmp/world', (err, stats) => {
    if (err) throw err;
    console.log(`stats: ${JSON.stringify(stats)}`);
  });
});copy

File paths#
Most fs operations accept file paths that may be specified in the form of
a string, a <Buffer>, or a <URL> object using the file: protocol.

String paths#
String paths are interpreted as UTF-8 character sequences identifying
the absolute or relative filename. Relative paths will be resolved relative
to the current working directory as determined by calling process.cwd().
Example using an absolute path on POSIX:
import { open } from 'node:fs/promises';

let fd;
try {
  fd = await open('/open/some/file.txt', 'r');
  // Do something with the file
} finally {
  await fd?.close();
} copy
Example using a relative path on POSIX (relative to process.cwd()):
import { open } from 'node:fs/promises';

let fd;
try {
  fd = await open('file.txt', 'r');
  // Do something with the file
} finally {
  await fd?.close();
} copy

File URL paths#

Added in: v7.6.0

For most node:fs module functions, the path or filename argument may be
passed as a <URL> object using the file: protocol.
import { readFileSync } from 'node:fs';

readFileSync(new URL('file:///tmp/hello')); copy
file: URLs are always absolute paths.

Platform-specific considerations#
On Windows, file: <URL>s with a host name convert to UNC paths, while file:
<URL>s with drive letters convert to local absolute paths. file: <URL>s
with no host name and no drive letter will result in an error:
import { readFileSync } from 'node:fs';
// On Windows :

// - WHATWG file URLs with hostname convert to UNC path
// file://hostname/p/a/t/h/file => \\hostname\p\a\t\h\file
readFileSync(new URL('file://hostname/p/a/t/h/file'));

// - WHATWG file URLs with drive letters convert to absolute path
// file:///C:/tmp/hello => C:\tmp\hello
readFileSync(new URL('file:///C:/tmp/hello'));

// - WHATWG file URLs without hostname must have a drive letters
readFileSync(new URL('file:///notdriveletter/p/a/t/h/file'));
readFileSync(new URL('file:///c/p/a/t/h/file'));
// TypeError [ERR_INVALID_FILE_URL_PATH]: File URL path must be absolute copy
file: <URL>s with drive letters must use : as a separator just after
the drive letter. Using another separator will result in an error.
On all other platforms, file: <URL>s with a host name are unsupported and
will result in an error:
import { readFileSync } from 'node:fs';
// On other platforms:

// - WHATWG file URLs with hostname are unsupported
// file://hostname/p/a/t/h/file => throw!
readFileSync(new URL('file://hostname/p/a/t/h/file'));
// TypeError [ERR_INVALID_FILE_URL_PATH]: must be absolute

// - WHATWG file URLs convert to absolute path
// file:///tmp/hello => /tmp/hello
readFileSync(new URL('file:///tmp/hello')); copy
A file: <URL> having encoded slash characters will result in an error on all
platforms:
import { readFileSync } from 'node:fs';

// On Windows
readFileSync(new URL('file:///C:/p/a/t/h/%2F'));
readFileSync(new URL('file:///C:/p/a/t/h/%2f'));
/* TypeError [ERR_INVALID_FILE_URL_PATH]: File URL path must not include encoded
\ or / characters */

// On POSIX
readFileSync(new URL('file:///p/a/t/h/%2F'));
readFileSync(new URL('file:///p/a/t/h/%2f'));
/* TypeError [ERR_INVALID_FILE_URL_PATH]: File URL path must not include encoded
/ characters */ copy
On Windows, file: <URL>s having encoded backslash will result in an error:
import { readFileSync } from 'node:fs';

// On Windows
readFileSync(new URL('file:///C:/path/%5C'));
readFileSync(new URL('file:///C:/path/%5c'));
/* TypeError [ERR_INVALID_FILE_URL_PATH]: File URL path must not include encoded
\ or / characters */ copy

Buffer paths#
Paths specified using a <Buffer> are useful primarily on certain POSIX
operating systems that treat file paths as opaque byte sequences. On such
systems, it is possible for a single file path to contain sub-sequences that
use multiple character encodings. As with string paths, <Buffer> paths may
be relative or absolute:
Example using an absolute path on POSIX:
import { open } from 'node:fs/promises';
import { Buffer } from 'node:buffer';

let fd;
try {
  fd = await open(Buffer.from('/open/some/file.txt'), 'r');
  // Do something with the file
} finally {
  await fd?.close();
} copy

Per-drive working directories on Windows#
On Windows, Node.js follows the concept of per-drive working directory. This
behavior can be observed when using a drive path without a backslash. For
example fs.readdirSync('C:\\') can potentially return a different result than
fs.readdirSync('C:'). For more information, see
this MSDN page.

File descriptors#
On POSIX systems, for every process, the kernel maintains a table of currently
open files and resources. Each open file is assigned a simple numeric
identifier called a file descriptor. At the system-level, all file system
operations use these file descriptors to identify and track each specific
file. Windows systems use a different but conceptually similar mechanism for
tracking resources. To simplify things for users, Node.js abstracts away the
differences between operating systems and assigns all open files a numeric file
descriptor.
The callback-based fs.open(), and synchronous fs.openSync() methods open a
file and allocate a new file descriptor. Once allocated, the file descriptor may
be used to read data from, write data to, or request information about the file.
Operating systems limit the number of file descriptors that may be open
at any given time so it is critical to close the descriptor when operations
are completed. Failure to do so will result in a memory leak that will
eventually cause an application to crash.
import { open, close, fstat } from 'node:fs';

function closeFd(fd) {
  close(fd, (err) => {
    if (err) throw err;
  });
}

open('/open/some/file.txt', 'r', (err, fd) => {
  if (err) throw err;
  try {
    fstat(fd, (err, stat) => {
      if (err) {
        closeFd(fd);
        throw err;
      }

      // use stat

      closeFd(fd);
    });
  } catch (err) {
    closeFd(fd);
    throw err;
  }
}); copy
The promise-based APIs use a <FileHandle> object in place of the numeric
file descriptor. These objects are better managed by the system to ensure
that resources are not leaked. However, it is still required that they are
closed when operations are completed:
import { open } from 'node:fs/promises';

let file;
try {
  file = await open('/open/some/file.txt', 'r');
  const stat = await file.stat();
  // use stat
} finally {
  await file.close();
} copy

Threadpool usage#
All callback and promise-based file system APIs (with the exception of
fs.FSWatcher()) use libuv's threadpool. This can have surprising and negative
performance implications for some applications. See the
UV_THREADPOOL_SIZE documentation for more information.

File system flags#
The following flags are available wherever the flag option takes a
string.


'a': Open file for appending.
The file is created if it does not exist.


'ax': Like 'a' but fails if the path exists.


'a+': Open file for reading and appending.
The file is created if it does not exist.


'ax+': Like 'a+' but fails if the path exists.


'as': Open file for appending in synchronous mode.
The file is created if it does not exist.


'as+': Open file for reading and appending in synchronous mode.
The file is created if it does not exist.


'r': Open file for reading.
An exception occurs if the file does not exist.


'rs': Open file for reading in synchronous mode.
An exception occurs if the file does not exist.


'r+': Open file for reading and writing.
An exception occurs if the file does not exist.


'rs+': Open file for reading and writing in synchronous mode. Instructs
the operating system to bypass the local file system cache.
This is primarily useful for opening files on NFS mounts as it allows
skipping the potentially stale local cache. It has a very real impact on
I/O performance so using this flag is not recommended unless it is needed.
This doesn't turn fs.open() or fsPromises.open() into a synchronous
blocking call. If synchronous operation is desired, something like
fs.openSync() should be used.


'w': Open file for writing.
The file is created (if it does not exist) or truncated (if it exists).


'wx': Like 'w' but fails if the path exists.


'w+': Open file for reading and writing.
The file is created (if it does not exist) or truncated (if it exists).


'wx+': Like 'w+' but fails if the path exists.


flag can also be a number as documented by open(2); commonly used constants
are available from fs.constants. On Windows, flags are translated to
their equivalent ones where applicable, e.g. O_WRONLY to FILE_GENERIC_WRITE,
or O_EXCL|O_CREAT to CREATE_NEW, as accepted by CreateFileW.
The exclusive flag 'x' (O_EXCL flag in open(2)) causes the operation to
return an error if the path already exists. On POSIX, if the path is a symbolic
link, using O_EXCL returns an error even if the link is to a path that does
not exist. The exclusive flag might not work with network file systems.
On Linux, positional writes don't work when the file is opened in append mode.
The kernel ignores the position argument and always appends the data to
the end of the file.
Modifying a file rather than replacing it may require the flag option to be
set to 'r+' rather than the default 'w'.
The behavior of some flags are platform-specific. As such, opening a directory
on macOS and Linux with the 'a+' flag, as in the example below, will return an
error. In contrast, on Windows and FreeBSD, a file descriptor or a FileHandle
will be returned.
// macOS and Linux
fs.open('<directory>', 'a+', (err, fd) => {
  // => [Error: EISDIR: illegal operation on a directory, open <directory>]
});

// Windows and FreeBSD
fs.open('<directory>', 'a+', (err, fd) => {
  // => null, <fd>
}); copy
On Windows, opening an existing hidden file using the 'w' flag (either
through fs.open(), fs.writeFile(), or fsPromises.open()) will fail with
EPERM. Existing hidden files can be opened for writing with the 'r+' flag.
A call to fs.ftruncate() or filehandle.truncate() can be used to reset
the file contents.\n\n\n\nNode.js
        
      
      
About this documentation
Usage and example



Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Modules: TypeScript
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
Readline
REPL
Report
Single executable applications
SQLite
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker

    

    
      
        
          Node.js v24.0.1 documentation
          
            
            
          
        
        
          
            Node.js v24.0.1
            
    
      
        
        Table of contents
      

      
Global objects

Class: AbortController

abortController.abort([reason])
abortController.signal
Class: AbortSignal

Static method: AbortSignal.abort([reason])
Static method: AbortSignal.timeout(delay)
Static method: AbortSignal.any(signals)
Event: 'abort'
abortSignal.aborted
abortSignal.onabort
abortSignal.reason
abortSignal.throwIfAborted()




Class: Blob
Class: Buffer
Class: ByteLengthQueuingStrategy
__dirname
__filename
atob(data)
BroadcastChannel
btoa(data)
clearImmediate(immediateObject)
clearInterval(intervalObject)
clearTimeout(timeoutObject)
CloseEvent
Class: CompressionStream
console
Class: CountQueuingStrategy
Crypto
crypto
CryptoKey
CustomEvent
Class: DecompressionStream
Event
EventSource
EventTarget
exports
fetch
Custom dispatcher
Related classes
Class: File
Class FormData
global
Class Headers
localStorage
MessageChannel
MessageEvent
MessagePort
module
Navigator
navigator

navigator.hardwareConcurrency
navigator.language
navigator.languages
navigator.platform
navigator.userAgent


PerformanceEntry
PerformanceMark
PerformanceMeasure
PerformanceObserver
PerformanceObserverEntryList
PerformanceResourceTiming
performance
process
queueMicrotask(callback)
Class: ReadableByteStreamController
Class: ReadableStream
Class: ReadableStreamBYOBReader
Class: ReadableStreamBYOBRequest
Class: ReadableStreamDefaultController
Class: ReadableStreamDefaultReader
require()
Response
Request
sessionStorage
setImmediate(callback[, ...args])
setInterval(callback, delay[, ...args])
setTimeout(callback, delay[, ...args])
Class: Storage
structuredClone(value[, options])
SubtleCrypto
DOMException
TextDecoder
Class: TextDecoderStream
TextEncoder
Class: TextEncoderStream
Class: TransformStream
Class: TransformStreamDefaultController
URL
URLPattern
URLSearchParams
WebAssembly
WebSocket
Class: WritableStream
Class: WritableStreamDefaultController
Class: WritableStreamDefaultWriter



    
  
            
    
      
        
        Index
      

      
About this documentation
Usage and example

      
        Index
      
    
  


Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Modules: TypeScript
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
Readline
REPL
Report
Single executable applications
SQLite
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker

    
  
            
    
      
        
        Other versions
      
      24.x
23.x
22.x LTS
21.x
20.x LTS
19.x
18.x
17.x
16.x
15.x
14.x
13.x
12.x
11.x
10.x
9.x
8.x
7.x
6.x
5.x
4.x
0.12.x
0.10.x
    
  
            
              
                
                Options
              
        
              
                
                  
                    View on single page
                  
                  
                    View as JSON
                  
                  Edit on GitHub    
                
              
            
          
        
        
      

      Table of contents
Global objects

Class: AbortController

abortController.abort([reason])
abortController.signal
Class: AbortSignal

Static method: AbortSignal.abort([reason])
Static method: AbortSignal.timeout(delay)
Static method: AbortSignal.any(signals)
Event: 'abort'
abortSignal.aborted
abortSignal.onabort
abortSignal.reason
abortSignal.throwIfAborted()




Class: Blob
Class: Buffer
Class: ByteLengthQueuingStrategy
__dirname
__filename
atob(data)
BroadcastChannel
btoa(data)
clearImmediate(immediateObject)
clearInterval(intervalObject)
clearTimeout(timeoutObject)
CloseEvent
Class: CompressionStream
console
Class: CountQueuingStrategy
Crypto
crypto
CryptoKey
CustomEvent
Class: DecompressionStream
Event
EventSource
EventTarget
exports
fetch
Custom dispatcher
Related classes
Class: File
Class FormData
global
Class Headers
localStorage
MessageChannel
MessageEvent
MessagePort
module
Navigator
navigator

navigator.hardwareConcurrency
navigator.language
navigator.languages
navigator.platform
navigator.userAgent


PerformanceEntry
PerformanceMark
PerformanceMeasure
PerformanceObserver
PerformanceObserverEntryList
PerformanceResourceTiming
performance
process
queueMicrotask(callback)
Class: ReadableByteStreamController
Class: ReadableStream
Class: ReadableStreamBYOBReader
Class: ReadableStreamBYOBRequest
Class: ReadableStreamDefaultController
Class: ReadableStreamDefaultReader
require()
Response
Request
sessionStorage
setImmediate(callback[, ...args])
setInterval(callback, delay[, ...args])
setTimeout(callback, delay[, ...args])
Class: Storage
structuredClone(value[, options])
SubtleCrypto
DOMException
TextDecoder
Class: TextDecoderStream
TextEncoder
Class: TextEncoderStream
Class: TransformStream
Class: TransformStreamDefaultController
URL
URLPattern
URLSearchParams
WebAssembly
WebSocket
Class: WritableStream
Class: WritableStreamDefaultController
Class: WritableStreamDefaultWriter




      
        Global objects#


These objects are available in all modules.
The following variables may appear to be global but are not. They exist only in
the scope of CommonJS modules:

__dirname
__filename
exports
module
require()

The objects listed here are specific to Node.js. There are built-in objects
that are part of the JavaScript language itself, which are also globally
accessible.
Class: AbortController#

History

VersionChanges
v15.4.0
No longer experimental.
v15.0.0, v14.17.0
Added in: v15.0.0, v14.17.0



Stability: 2 - Stable

A utility class used to signal cancelation in selected Promise-based APIs.
The API is based on the Web API AbortController.
const ac = new AbortController();

ac.signal.addEventListener('abort', () => console.log('Aborted!'),
                           { once: true });

ac.abort();

console.log(ac.signal.aborted);  // Prints true copy

abortController.abort([reason])#

History

VersionChanges
v17.2.0, v16.14.0
Added the new optional reason argument.
v15.0.0, v14.17.0
Added in: v15.0.0, v14.17.0




reason <any> An optional reason, retrievable on the AbortSignal's
reason property.

Triggers the abort signal, causing the abortController.signal to emit
the 'abort' event.

abortController.signal#

Added in: v15.0.0, v14.17.0


Type: <AbortSignal>


Class: AbortSignal#

Added in: v15.0.0, v14.17.0


Extends: <EventTarget>

The AbortSignal is used to notify observers when the
abortController.abort() method is called.

Static method: AbortSignal.abort([reason])#

History

VersionChanges
v17.2.0, v16.14.0
Added the new optional reason argument.
v15.12.0, v14.17.0
Added in: v15.12.0, v14.17.0




reason: <any>
Returns: <AbortSignal>

Returns a new already aborted AbortSignal.

Static method: AbortSignal.timeout(delay)#

Added in: v17.3.0, v16.14.0


delay <number> The number of milliseconds to wait before triggering
the AbortSignal.

Returns a new AbortSignal which will be aborted in delay milliseconds.

Static method: AbortSignal.any(signals)#

Added in: v20.3.0, v18.17.0


signals <AbortSignal[]> The AbortSignals of which to compose a new AbortSignal.

Returns a new AbortSignal which will be aborted if any of the provided
signals are aborted. Its abortSignal.reason will be set to whichever
one of the signals caused it to be aborted.

Event: 'abort'#

Added in: v15.0.0, v14.17.0

The 'abort' event is emitted when the abortController.abort() method
is called. The callback is invoked with a single object argument with a
single type property set to 'abort':
const ac = new AbortController();

// Use either the onabort property...
ac.signal.onabort = () => console.log('aborted!');

// Or the EventTarget API...
ac.signal.addEventListener('abort', (event) => {
  console.log(event.type);  // Prints 'abort'
}, { once: true });

ac.abort(); copy
The AbortController with which the AbortSignal is associated will only
ever trigger the 'abort' event once. We recommended that code check
that the abortSignal.aborted attribute is false before adding an 'abort'
event listener.
Any event listeners attached to the AbortSignal should use the
{ once: true } option (or, if using the EventEmitter APIs to attach a
listener, use the once() method) to ensure that the event listener is
removed as soon as the 'abort' event is handled. Failure to do so may
result in memory leaks.

abortSignal.aborted#

Added in: v15.0.0, v14.17.0


Type: <boolean> True after the AbortController has been aborted.


abortSignal.onabort#

Added in: v15.0.0, v14.17.0


Type: <Function>

An optional callback function that may be set by user code to be notified
when the abortController.abort() function has been called.

abortSignal.reason#

Added in: v17.2.0, v16.14.0


Type: <any>

An optional reason specified when the AbortSignal was triggered.
const ac = new AbortController();
ac.abort(new Error('boom!'));
console.log(ac.signal.reason);  // Error: boom! copy

abortSignal.throwIfAborted()#

Added in: v17.3.0, v16.17.0

If abortSignal.aborted is true, throws abortSignal.reason.

Class: Blob#

Added in: v18.0.0

Stability: 2 - Stable

See <Blob>.
Class: Buffer#

Added in: v0.1.103

Stability: 2 - Stable


<Function>

Used to handle binary data. See the buffer section.
Class: ByteLengthQueuingStrategy#

History

VersionChanges
v23.11.0, v22.15.0
Marking the API stable.
v18.0.0
Added in: v18.0.0



A browser-compatible implementation of ByteLengthQueuingStrategy.
__dirname#
This variable may appear to be global but is not. See __dirname.
__filename#
This variable may appear to be global but is not. See __filename.
atob(data)#

Added in: v16.0.0

Stability: 3 - Legacy. Use Buffer.from(data, 'base64') instead.
Global alias for buffer.atob().
BroadcastChannel#

Added in: v18.0.0

Stability: 2 - Stable
See <BroadcastChannel>.
btoa(data)#

Added in: v16.0.0

Stability: 3 - Legacy. Use buf.toString('base64') instead.
Global alias for buffer.btoa().
clearImmediate(immediateObject)#

Added in: v0.9.1

Stability: 2 - Stable

clearImmediate is described in the timers section.
clearInterval(intervalObject)#

Added in: v0.0.1

Stability: 2 - Stable

clearInterval is described in the timers section.
clearTimeout(timeoutObject)#

Added in: v0.0.1

Stability: 2 - Stable

clearTimeout is described in the timers section.
CloseEvent#

Added in: v23.0.0

Stability: 2 - Stable

The CloseEvent class. See CloseEvent for more details.
A browser-compatible implementation of CloseEvent. Disable this API
with the --no-experimental-websocket CLI flag.
Class: CompressionStream#

History

VersionChanges
v23.11.0, v22.15.0
Marking the API stable.
v18.0.0
Added in: v18.0.0



A browser-compatible implementation of CompressionStream.
console#

Added in: v0.1.100

Stability: 2 - Stable


<Object>

Used to print to stdout and stderr. See the console section.
Class: CountQueuingStrategy#

History

VersionChanges
v23.11.0, v22.15.0
Marking the API stable.
v18.0.0
Added in: v18.0.0



A browser-compatible implementation of CountQueuingStrategy.
Crypto#

History

VersionChanges
v23.0.0
No longer experimental.
v19.0.0
No longer behind --experimental-global-webcrypto CLI flag.
v17.6.0, v16.15.0
Added in: v17.6.0, v16.15.0



Stability: 2 - Stable
A browser-compatible implementation of <Crypto>. This global is available
only if the Node.js binary was compiled with including support for the
node:crypto module.
crypto#

History

VersionChanges
v23.0.0
No longer experimental.
v19.0.0
No longer behind --experimental-global-webcrypto CLI flag.
v17.6.0, v16.15.0
Added in: v17.6.0, v16.15.0



Stability: 2 - Stable
A browser-compatible implementation of the Web Crypto API.
CryptoKey#

History

VersionChanges
v23.0.0
No longer experimental.
v19.0.0
No longer behind --experimental-global-webcrypto CLI flag.
v17.6.0, v16.15.0
Added in: v17.6.0, v16.15.0



Stability: 2 - Stable
A browser-compatible implementation of <CryptoKey>. This global is available
only if the Node.js binary was compiled with including support for the
node:crypto module.
CustomEvent#

History

VersionChanges
v23.0.0
No longer experimental.
v22.1.0, v20.13.0
CustomEvent is now stable.
v19.0.0
No longer behind --experimental-global-customevent CLI flag.
v18.7.0, v16.17.0
Added in: v18.7.0, v16.17.0



Stability: 2 - Stable

A browser-compatible implementation of the CustomEvent Web API.
Class: DecompressionStream#

History

VersionChanges
v23.11.0, v22.15.0
Marking the API stable.
v18.0.0
Added in: v18.0.0



A browser-compatible implementation of DecompressionStream.
Event#

History

VersionChanges
v15.4.0
No longer experimental.
v15.0.0
Added in: v15.0.0



Stability: 2 - Stable

A browser-compatible implementation of the Event class. See
EventTarget and Event API for more details.
EventSource#

Added in: v22.3.0, v20.18.0

Stability: 1 - Experimental. Enable this API with the --experimental-eventsource
CLI flag.
A browser-compatible implementation of the EventSource class.
EventTarget#

History

VersionChanges
v15.4.0
No longer experimental.
v15.0.0
Added in: v15.0.0



Stability: 2 - Stable

A browser-compatible implementation of the EventTarget class. See
EventTarget and Event API for more details.
exports#
This variable may appear to be global but is not. See exports.
fetch#

History

VersionChanges
v21.0.0
No longer experimental.
v18.0.0
No longer behind --experimental-fetch CLI flag.
v17.5.0, v16.15.0
Added in: v17.5.0, v16.15.0



Stability: 2 - Stable
A browser-compatible implementation of the fetch() function.
const res = await fetch('https://nodejs.org/api/documentation.json');
if (res.ok) {
  const data = await res.json();
  console.log(data);
} copy
The implementation is based upon undici, an HTTP/1.1 client
written from scratch for Node.js. You can figure out which version of undici is bundled
in your Node.js process reading the process.versions.undici property.
Custom dispatcher#
You can use a custom dispatcher to dispatch requests passing it in fetch's options object.
The dispatcher must be compatible with undici's
Dispatcher class.
fetch(url, { dispatcher: new MyAgent() }); copy
It is possible to change the global dispatcher in Node.js installing undici and using
the setGlobalDispatcher() method. Calling this method will affect both undici and
Node.js.
import { setGlobalDispatcher } from 'undici';
setGlobalDispatcher(new MyAgent()); copy
Related classes#
The following globals are available to use with fetch:

FormData
Headers
Request
Response.

Class: File#

Added in: v20.0.0

Stability: 2 - Stable

See <File>.
Class FormData#

History

VersionChanges
v21.0.0
No longer experimental.
v18.0.0
No longer behind --experimental-fetch CLI flag.
v17.6.0, v16.15.0
Added in: v17.6.0, v16.15.0



Stability: 2 - Stable
A browser-compatible implementation of <FormData>.
global#

Added in: v0.1.27


Stability: 3 - Legacy. Use globalThis instead.

<Object> The global namespace object.

In browsers, the top-level scope has traditionally been the global scope. This
means that var something will define a new global variable, except within
ECMAScript modules. In Node.js, this is different. The top-level scope is not
the global scope; var something inside a Node.js module will be local to that
module, regardless of whether it is a CommonJS module or an
ECMAScript module.
Class Headers#

History

VersionChanges
v21.0.0
No longer experimental.
v18.0.0
No longer behind --experimental-fetch CLI flag.
v17.5.0, v16.15.0
Added in: v17.5.0, v16.15.0



Stability: 2 - Stable
A browser-compatible implementation of <Headers>.
localStorage#

Added in: v22.4.0

Stability: 1.0 - Early development.
A browser-compatible implementation of localStorage. Data is stored
unencrypted in the file specified by the --localstorage-file CLI flag.
The maximum amount of data that can be stored is 10 MB.
Any modification of this data outside of the Web Storage API is not supported.
Enable this API with the --experimental-webstorage CLI flag.
localStorage data is not stored per user or per request when used in the context
of a server, it is shared across all users and requests.
MessageChannel#

Added in: v15.0.0

Stability: 2 - Stable

The MessageChannel class. See MessageChannel for more details.
MessageEvent#

Added in: v15.0.0

Stability: 2 - Stable

The MessageEvent class. See MessageEvent for more details.
MessagePort#

Added in: v15.0.0

Stability: 2 - Stable

The MessagePort class. See MessagePort for more details.
module#
This variable may appear to be global but is not. See module.
Navigator#

Added in: v21.0.0

Stability: 1.1 - Active development. Disable this API with the
--no-experimental-global-navigator CLI flag.
A partial implementation of the Navigator API.
navigator#

Added in: v21.0.0

Stability: 1.1 - Active development. Disable this API with the
--no-experimental-global-navigator CLI flag.
A partial implementation of window.navigator.

navigator.hardwareConcurrency#

Added in: v21.0.0


<number>

The navigator.hardwareConcurrency read-only property returns the number of
logical processors available to the current Node.js instance.
console.log(`This process is running on ${navigator.hardwareConcurrency} logical processors`); copy

navigator.language#

Added in: v21.2.0


<string>

The navigator.language read-only property returns a string representing the
preferred language of the Node.js instance. The language will be determined by
the ICU library used by Node.js at runtime based on the
default language of the operating system.
The value is representing the language version as defined in RFC 5646.
The fallback value on builds without ICU is 'en-US'.
console.log(`The preferred language of the Node.js instance has the tag '${navigator.language}'`); copy

navigator.languages#

Added in: v21.2.0


{Array}

The navigator.languages read-only property returns an array of strings
representing the preferred languages of the Node.js instance.
By default navigator.languages contains only the value of
navigator.language, which will be determined by the ICU library used by
Node.js at runtime based on the default language of the operating system.
The fallback value on builds without ICU is ['en-US'].
console.log(`The preferred languages are '${navigator.languages}'`); copy

navigator.platform#

Added in: v21.2.0


<string>

The navigator.platform read-only property returns a string identifying the
platform on which the Node.js instance is running.
console.log(`This process is running on ${navigator.platform}`); copy

navigator.userAgent#

Added in: v21.1.0


<string>

The navigator.userAgent read-only property returns user agent
consisting of the runtime name and major version number.
console.log(`The user-agent is ${navigator.userAgent}`); // Prints "Node.js/21" copy

PerformanceEntry#

Added in: v19.0.0

Stability: 2 - Stable

The PerformanceEntry class. See PerformanceEntry for more details.
PerformanceMark#

Added in: v19.0.0

Stability: 2 - Stable

The PerformanceMark class. See PerformanceMark for more details.
PerformanceMeasure#

Added in: v19.0.0

Stability: 2 - Stable

The PerformanceMeasure class. See PerformanceMeasure for more details.
PerformanceObserver#

Added in: v19.0.0

Stability: 2 - Stable

The PerformanceObserver class. See PerformanceObserver for more details.
PerformanceObserverEntryList#

Added in: v19.0.0

Stability: 2 - Stable

The PerformanceObserverEntryList class. See
PerformanceObserverEntryList for more details.
PerformanceResourceTiming#

Added in: v19.0.0

Stability: 2 - Stable

The PerformanceResourceTiming class. See PerformanceResourceTiming for
more details.
performance#

Added in: v16.0.0

Stability: 2 - Stable
The perf_hooks.performance object.
process#

Added in: v0.1.7

Stability: 2 - Stable


<Object>

The process object. See the process object section.
queueMicrotask(callback)#

Added in: v11.0.0

Stability: 2 - Stable


callback <Function> Function to be queued.

The queueMicrotask() method queues a microtask to invoke callback. If
callback throws an exception, the process object 'uncaughtException'
event will be emitted.
The microtask queue is managed by V8 and may be used in a similar manner to
the process.nextTick() queue, which is managed by Node.js. The
process.nextTick() queue is always processed before the microtask queue
within each turn of the Node.js event loop.
// Here, `queueMicrotask()` is used to ensure the 'load' event is always
// emitted asynchronously, and therefore consistently. Using
// `process.nextTick()` here would result in the 'load' event always emitting
// before any other promise jobs.

DataHandler.prototype.load = async function load(key) {
  const hit = this._cache.get(key);
  if (hit !== undefined) {
    queueMicrotask(() => {
      this.emit('load', hit);
    });
    return;
  }

  const data = await fetchData(key);
  this._cache.set(key, data);
  this.emit('load', data);
}; copy
Class: ReadableByteStreamController#

History

VersionChanges
v23.11.0, v22.15.0
Marking the API stable.
v18.0.0
Added in: v18.0.0



A browser-compatible implementation of ReadableByteStreamController.
Class: ReadableStream#

History

VersionChanges
v23.11.0, v22.15.0
Marking the API stable.
v18.0.0
Added in: v18.0.0



A browser-compatible implementation of ReadableStream.
Class: ReadableStreamBYOBReader#

History

VersionChanges
v23.11.0, v22.15.0
Marking the API stable.
v18.0.0
Added in: v18.0.0



A browser-compatible implementation of ReadableStreamBYOBReader.
Class: ReadableStreamBYOBRequest#

History

VersionChanges
v23.11.0, v22.15.0
Marking the API stable.
v18.0.0
Added in: v18.0.0



A browser-compatible implementation of ReadableStreamBYOBRequest.
Class: ReadableStreamDefaultController#

History

VersionChanges
v23.11.0, v22.15.0
Marking the API stable.
v18.0.0
Added in: v18.0.0



A browser-compatible implementation of ReadableStreamDefaultController.
Class: ReadableStreamDefaultReader#

History

VersionChanges
v23.11.0, v22.15.0
Marking the API stable.
v18.0.0
Added in: v18.0.0



A browser-compatible implementation of ReadableStreamDefaultReader.
require()#
This variable may appear to be global but is not. See require().
Response#

History

VersionChanges
v21.0.0
No longer experimental.
v18.0.0
No longer behind --experimental-fetch CLI flag.
v17.5.0, v16.15.0
Added in: v17.5.0, v16.15.0



Stability: 2 - Stable
A browser-compatible implementation of <Response>.
Request#

History

VersionChanges
v21.0.0
No longer experimental.
v18.0.0
No longer behind --experimental-fetch CLI flag.
v17.5.0, v16.15.0
Added in: v17.5.0, v16.15.0



Stability: 2 - Stable
A browser-compatible implementation of <Request>.
sessionStorage#

Added in: v22.4.0

Stability: 1.0 - Early development.
A browser-compatible implementation of sessionStorage. Data is stored in
memory, with a storage quota of 10 MB. sessionStorage data persists only within
the currently running process, and is not shared between workers.
setImmediate(callback[, ...args])#

Added in: v0.9.1

Stability: 2 - Stable

setImmediate is described in the timers section.
setInterval(callback, delay[, ...args])#

Added in: v0.0.1

Stability: 2 - Stable

setInterval is described in the timers section.
setTimeout(callback, delay[, ...args])#

Added in: v0.0.1

Stability: 2 - Stable

setTimeout is described in the timers section.
Class: Storage#

Added in: v22.4.0

Stability: 1.0 - Early development.
A browser-compatible implementation of Storage. Enable this API with the
--experimental-webstorage CLI flag.
structuredClone(value[, options])#

Added in: v17.0.0

Stability: 2 - Stable

The WHATWG structuredClone method.
SubtleCrypto#

History

VersionChanges
v19.0.0
No longer behind --experimental-global-webcrypto CLI flag.
v17.6.0, v16.15.0
Added in: v17.6.0, v16.15.0



Stability: 2 - Stable
A browser-compatible implementation of <SubtleCrypto>. This global is available
only if the Node.js binary was compiled with including support for the
node:crypto module.
DOMException#

Added in: v17.0.0

Stability: 2 - Stable

The WHATWG DOMException class. See DOMException for more details.
TextDecoder#

Added in: v11.0.0

Stability: 2 - Stable

The WHATWG TextDecoder class. See the TextDecoder section.
Class: TextDecoderStream#

History

VersionChanges
v23.11.0, v22.15.0
Marking the API stable.
v18.0.0
Added in: v18.0.0



A browser-compatible implementation of TextDecoderStream.
TextEncoder#

Added in: v11.0.0

Stability: 2 - Stable

The WHATWG TextEncoder class. See the TextEncoder section.
Class: TextEncoderStream#

History

VersionChanges
v23.11.0, v22.15.0
Marking the API stable.
v18.0.0
Added in: v18.0.0



A browser-compatible implementation of TextEncoderStream.
Class: TransformStream#

History

VersionChanges
v23.11.0, v22.15.0
Marking the API stable.
v18.0.0
Added in: v18.0.0



A browser-compatible implementation of TransformStream.
Class: TransformStreamDefaultController#

History

VersionChanges
v23.11.0, v22.15.0
Marking the API stable.
v18.0.0
Added in: v18.0.0



A browser-compatible implementation of TransformStreamDefaultController.
URL#

Added in: v10.0.0

Stability: 2 - Stable

The WHATWG URL class. See the URL section.
URLPattern#

Added in: v24.0.0

Stability: 1 - Experimental

The WHATWG URLPattern class. See the URLPattern section.
URLSearchParams#

Added in: v10.0.0

Stability: 2 - Stable

The WHATWG URLSearchParams class. See the URLSearchParams section.
WebAssembly#

Added in: v8.0.0

Stability: 2 - Stable


<Object>

The object that acts as the namespace for all W3C
WebAssembly related functionality. See the
Mozilla Developer Network for usage and compatibility.
WebSocket#

History

VersionChanges
v22.4.0
No longer experimental.
v22.0.0
No longer behind --experimental-websocket CLI flag.
v21.0.0, v20.10.0
Added in: v21.0.0, v20.10.0



Stability: 2 - Stable
A browser-compatible implementation of WebSocket. Disable this API
with the --no-experimental-websocket CLI flag.
Class: WritableStream#

History

VersionChanges
v23.11.0, v22.15.0
Marking the API stable.
v18.0.0
Added in: v18.0.0



A browser-compatible implementation of WritableStream.
Class: WritableStreamDefaultController#

History

VersionChanges
v23.11.0, v22.15.0
Marking the API stable.
v18.0.0
Added in: v18.0.0



A browser-compatible implementation of WritableStreamDefaultController.
Class: WritableStreamDefaultWriter#

History

VersionChanges
v23.11.0, v22.15.0
Marking the API stable.
v18.0.0
Added in: v18.0.0



A browser-compatible implementation of WritableStreamDefaultWriter.\n\n\n\nWednesday, May 14, 2025 Security ReleasesThe Node.js ProjectWednesday, May 14, 2025 Security ReleasesSummary
The Node.js project will release new versions of the 24.x, 23.x, 22.x, 20.x
releases lines on or shortly after, Wednesday, May 14, 2025 in order to address:

1 high severity issues.
1 medium severity issues.
1 low severity issues.

Impact

The 24.x release line of Node.js is vulnerable to 1 high severity issues.
The 23.x release line of Node.js is vulnerable to 1 high severity issues.
The 22.x release line of Node.js is vulnerable to 1 low severity issues, 1 high severity issues.
The 20.x release line of Node.js is vulnerable to 1 low severity issues, 1 high severity issues, 1 medium severity issues.

It's important to note that End-of-Life versions are always affected when a security release occurs.
To ensure your system's security, please use an up-to-date version as outlined in our
Release Schedule.
Release timing
Releases will be available on, or shortly after, Wednesday, May 14, 2025.
Contact and future updates
The current Node.js security policy can be found at https://nodejs.org/en/security/.
Please follow the process outlined in https://github.com/nodejs/node/blob/master/SECURITY.md if you wish to report a vulnerability in Node.js.
Subscribe to the low-volume announcement-only nodejs-sec mailing list at https://groups.google.com/forum/#!forum/nodejs-sec to stay up to date on security vulnerabilities and security-related releases of Node.js and the projects maintained in the nodejs GitHub organization.NextNode.js Test CI Security Incident\n\n\n\nNext-10 SurveyWe need your feedback to help us shape Node.jsRun JavaScript EverywhereNode.js® is a free, open-source, cross-platform JavaScript runtime environment
that lets developers create servers, web apps, command line tools and scripts.Download Node.js (LTS)Download Node.js (LTS)Downloads Node.js v22.15.01 with long-term support. Node.js can also be installed via version managers.Want new features sooner? Get Node.js v24.0.11 instead.
Create an HTTP ServerWrite TestsRead and Hash a FileStreams PipelineWork with Threads// server.mjs
import { createServer } from 'node:http';

const server = createServer((req, res) => {
  res.writeHead(200, { 'Content-Type': 'text/plain' });
  res.end('Hello World!\n');
});

// starts a simple http server locally on port 3000
server.listen(3000, '127.0.0.1', () => {
  console.log('Listening on 127.0.0.1:3000');
});

// run with `node server.mjs`
JavaScriptCopy to clipboardLearn more what Node.js is able to offer with our Learning materials.\n\n\n\nIntroduction to Node.js
Node.js is an open-source and cross-platform JavaScript runtime environment. It is a popular tool for almost any kind of project!
Node.js runs the V8 JavaScript engine, the core of Google Chrome, outside of the browser. This allows Node.js to be very performant.
A Node.js app runs in a single process, without creating a new thread for every request. Node.js provides a set of asynchronous I/O primitives in its standard library that prevent JavaScript code from blocking and generally, libraries in Node.js are written using non-blocking paradigms, making blocking behavior the exception rather than the norm.
When Node.js performs an I/O operation, like reading from the network, accessing a database or the filesystem, instead of blocking the thread and wasting CPU cycles waiting, Node.js will resume the operations when the response comes back.
This allows Node.js to handle thousands of concurrent connections with a single server without introducing the burden of managing thread concurrency, which could be a significant source of bugs.
Node.js has a unique advantage because millions of frontend developers that write JavaScript for the browser are now able to write the server-side code in addition to the client-side code without the need to learn a completely different language.
In Node.js the new ECMAScript standards can be used without problems, as you don't have to wait for all your users to update their browsers - you are in charge of deciding which ECMAScript version to use by changing the Node.js version, and you can also enable specific experimental features by running Node.js with flags.
An Example Node.js Application
The most common example Hello World of Node.js is a web server:
CJSMJSconst { createServer } = require('node:http');

const hostname = '127.0.0.1';
const port = 3000;

const server = createServer((req, res) => {
  res.statusCode = 200;
  res.setHeader('Content-Type', 'text/plain');
  res.end('Hello World');
});

server.listen(port, hostname, () => {
  console.log(`Server running at http://${hostname}:${port}/`);
});
JavaScriptCopy to clipboardTo run this snippet, save it as a server.js file and run node server.js in your terminal.
If you use mjs version of the code, you should save it as a server.mjs file and run node server.mjs in your terminal.
This code first includes the Node.js http module.
Node.js has a fantastic standard library, including first-class support for networking.
The createServer() method of http creates a new HTTP server and returns it.
The server is set to listen on the specified port and host name. When the server is ready, the callback function is called, in this case informing us that the server is running.
Whenever a new request is received, the request event is called, providing two objects: a request (an http.IncomingMessage object) and a response (an http.ServerResponse object).
Those 2 objects are essential to handle the HTTP call.
The first provides the request details. In this simple example, this is not used, but you could access the request headers and request data.
The second is used to return data to the caller.
In this case with:
res.statusCode = 200;
JavaScriptCopy to clipboard
we set the statusCode property to 200, to indicate a successful response.
We set the Content-Type header:
res.setHeader('Content-Type', 'text/plain');
JavaScriptCopy to clipboard
and we close the response, adding the content as an argument to end():
res.end('Hello World\n');
JavaScriptCopy to clipboard
If you haven't already done so, download Node.js.NextHow much JavaScript do you need to know to use Node.js?\n\n\n\nAbout Node.js®
As an asynchronous event-driven JavaScript runtime, Node.js is designed to build
scalable network applications. In the following "hello world" example, many
connections can be handled concurrently. Upon each connection, the callback is
fired, but if there is no work to be done, Node.js will sleep.
CJSMJSconst { createServer } = require('node:http');

const hostname = '127.0.0.1';
const port = 3000;

const server = createServer((req, res) => {
  res.statusCode = 200;
  res.setHeader('Content-Type', 'text/plain');
  res.end('Hello World');
});

server.listen(port, hostname, () => {
  console.log(`Server running at http://${hostname}:${port}/`);
});
JavaScriptCopy to clipboardThis is in contrast to today's more common concurrency model, in which OS threads
are employed. Thread-based networking is relatively inefficient and very
difficult to use. Furthermore, users of Node.js are free from worries of
dead-locking the process, since there are no locks. Almost no function in
Node.js directly performs I/O, so the process never blocks except when the I/O is performed using
synchronous methods of Node.js standard library. Because nothing blocks, scalable systems are very
reasonable to develop in Node.js.
If some of this language is unfamiliar, there is a full article on
Blocking vs. Non-Blocking.

Node.js is similar in design to, and influenced by, systems like Ruby's
Event Machine and Python's Twisted. Node.js takes the event model a bit
further. It presents an event loop as a runtime construct instead of as a library. In other systems,
there is always a blocking call to start the event-loop.
Typically, behavior is defined through callbacks at the beginning of a script, and
at the end a server is started through a blocking call like EventMachine::run().
In Node.js, there is no such start-the-event-loop call. Node.js simply enters the event loop after executing the input script. Node.js
exits the event loop when there are no more callbacks to perform. This behavior
is like browser JavaScript — the event loop is hidden from the user.
HTTP is a first-class citizen in Node.js, designed with streaming and low
latency in mind. This makes Node.js well suited for the foundation of a web
library or framework.
Node.js being designed without threads doesn't mean you can't take
advantage of multiple cores in your environment. Child processes can be spawned
by using our child_process.fork() API, and are designed to be easy to
communicate with. Built upon that same interface is the cluster module,
which allows you to share sockets between processes to enable load balancing
over your cores.
Official Node.js Resources
To ensure authenticity and security when working with Node.js, always use official sources. Avoid trusting emails,
binaries, or downloads from unofficial sources.
Official Node.js Domains
For downloading Node.js binaries and accessing official documentation, use only these domains:

nodejs.org
nodejs.dev (Redirects to https://nodejs.org)
iojs.org (Redirects to https://nodejs.org)

Official npm Packages
The Node.js team maintains the following official npm package scopes:

@node-core
@pkgjs

Additionally, the Node.js team maintains packages published by the nodejs-foundation npm account,
though other Node.js-related packages (like undici) may also be maintained by contributors closely
tied to the project.
Using packages from the Node.js team guarantees that you are working with officially supported Node.js components.
Official GitHub Organizations
Node.js and related projects are maintained under these official GitHub organizations:

nodejs
pkgjs

Official Communication Channels
Node.js and the OpenJS Foundation communicate through various official and community-supported channels. You can find details on
how to get involved on the Get Involved page.
Reporting Website Issues & Downtime
If you encounter issues with the Node.js website, report them at the Node.js website repository.
For real-time updates on outages, visit the Node.js Status Page.\n\n\n\nDownload Node.js®Get Node.js® v22.15.0 (LTS) for Unknown using  with npmBashCopy to clipboard and their installation scripts are not maintained by the Node.js project. If you encounter any issues please visit 's websiteOr get a prebuilt Node.js® for Unknown running a Unknown architecture.N/A Installer (.gz)Standalone Binary (.gz)
Read the changelog or blog post for this version.Learn more about Node.js releases, including the release schedule and LTS status.Learn how to verify signed SHASUMS.Looking for Node.js source? Download a signed Node.js source tarball.Check out our nightly binaries or
all previous releases
or the unofficial binaries for other platforms.\n\n\n\nNode v24.0.1 (Current)ReleasesNode v24.0.1 (Current)Antoine du HamelMay 08, 2025Wednesday, May 14, 2025 Security ReleasesVulnerabilitiesWednesday, May 14, 2025 Security ReleasesThe Node.js ProjectMay 08, 2025Node v24.0.0 (Current)ReleasesNode v24.0.0 (Current)Rafael GonzagaMay 06, 2025Node.js Test CI Security IncidentVulnerabilitiesNode.js Test CI Security IncidentNode.js Technical Steering CommitteeApr 23, 2025Node v22.15.0 (LTS)ReleasesNode v22.15.0 (LTS)Ulises GascónApr 23, 2025Node v20.19.1 (LTS)ReleasesNode v20.19.1 (LTS)Ulises GascónApr 22, 2025\n\nBlogThe latest Node.js news, case studies, tutorials, and resources.EverythingAnnouncementsReleasesVulnerabilitiesEventsCategoriesEverythingNode v24.0.1 (Current)ReleasesNode v24.0.1 (Current)Antoine du HamelMay 08, 2025Wednesday, May 14, 2025 Security ReleasesVulnerabilitiesWednesday, May 14, 2025 Security ReleasesThe Node.js ProjectMay 08, 2025Node v24.0.0 (Current)ReleasesNode v24.0.0 (Current)Rafael GonzagaMay 06, 2025Node.js Test CI Security IncidentVulnerabilitiesNode.js Test CI Security IncidentNode.js Technical Steering CommitteeApr 23, 2025Node v22.15.0 (LTS)ReleasesNode v22.15.0 (LTS)Ulises GascónApr 23, 2025Node v20.19.1 (LTS)ReleasesNode v20.19.1 (LTS)Ulises GascónApr 22, 2025Previous12345...159Next\n\n\n\nNode.js
        
      
      
About this documentation
Usage and example



Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Modules: TypeScript
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
Readline
REPL
Report
Single executable applications
SQLite
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker

    

    
      
        
          Node.js v24.0.1 documentation
          
            
            
          
        
        
          
            Node.js v24.0.1
            
            
            
    
      
        
        Other versions
      
      24.x
23.x
22.x LTS
21.x
20.x LTS
19.x
18.x
17.x
16.x
15.x
14.x
13.x
12.x
11.x
10.x
9.x
8.x
7.x
6.x
5.x
4.x
0.12.x
0.10.x
    
  
            
              
                
                Options
              
        
              
                
                  
                    View on single page
                  
                  
                    View as JSON
                  
                  Edit on GitHub    
                
              
            
          
        
        
      

      

      
        


About this documentation
Usage and example



Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Modules: TypeScript
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
Readline
REPL
Report
Single executable applications
SQLite
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker\n\n\n\nNode.js Releases
Major Node.js versions enter Current release status for six months, which gives library authors time to add support for them.
After six months, odd-numbered releases (9, 11, etc.) become unsupported, and even-numbered releases (10, 12, etc.) move to Active LTS status and are ready for general use.
LTS release status is "long-term support", which typically guarantees that critical bugs will be fixed for a total of 30 months.
Production applications should only use Active LTS or Maintenance LTS releases.
Release Schedule

Full details regarding the Node.js release schedule are available on GitHub.
Commercial Support
Commercial support for versions past the Maintenance phase is available through our OpenJS Ecosystem Sustainability Program partner HeroDevs.
Looking for the latest release of a version branch?
Node.jsCodenameFirst releasedLast updatedStatusv24-May 06, 2025May 08, 2025CurrentDetailsv23-Oct 16, 2024Apr 01, 2025MaintenanceDetailsv22JodApr 24, 2024Apr 22, 2025LTSDetailsv21-Oct 17, 2023Apr 10, 2024End-of-lifeDetailsv20IronApr 18, 2023Apr 22, 2025MaintenanceDetailsv19-Oct 18, 2022Apr 10, 2023End-of-lifeDetailsv18HydrogenApr 19, 2022Mar 27, 2025End-of-lifeDetailsv17-Oct 19, 2021Jun 01, 2022End-of-lifeDetailsv16GalliumApr 20, 2021Aug 08, 2023End-of-lifeDetailsv15-Oct 20, 2020Apr 06, 2021End-of-lifeDetailsv14FermiumApr 21, 2020Feb 16, 2023End-of-lifeDetailsv13-Oct 22, 2019Apr 29, 2020End-of-lifeDetailsv12ErbiumApr 23, 2019Apr 05, 2022End-of-lifeDetailsv11-Oct 23, 2018Apr 30, 2019End-of-lifeDetailsv10DubniumApr 24, 2018Apr 06, 2021End-of-lifeDetailsv9-Oct 01, 2017Jun 12, 2018End-of-lifeDetailsv8CarbonMay 30, 2017Dec 17, 2019End-of-lifeDetailsv7-Oct 25, 2016Jul 11, 2017End-of-lifeDetailsv6BoronApr 26, 2016Apr 03, 2019End-of-lifeDetailsv5-Oct 29, 2015Jun 23, 2016End-of-lifeDetailsv4ArgonSep 08, 2015Mar 29, 2018End-of-lifeDetailsv0-Feb 06, 2015Feb 22, 2017End-of-lifeDetails
Official vs. Community Installation Methods
The Node.js website provides several non-interactive installation methods, including command-line interfaces (CLIs), operating system (OS) package managers (e.g., brew), and Node.js version managers (e.g., nvm).
To highlight and promote community contributions, the Node.js project introduced a revised Downloads page categorizing installation methods as either “Official” or “Community.” This provides users with increased flexibility and choice. To ensure clarity, we’ve defined criteria for each category.
Official Installation Methods
Installation methods designated as “Official” must meet the following requirements:
Requirements (Official Installation Methods)New Node.js releases must be available simultaneously with the official release.Project maintainers must have a close relationship with the Node.js project, including direct communication channels.Installation method must download official binaries bundled by the Node.js project.Installation method must not build from source when pre-built binaries are available, nor should it alter the official binaries.
Community Installation Methods
Community installation methods included on the self-service download page (/download) must also adhere to a minimum set of criteria:

Version Support: Must support all currently supported, non-End-of-Life (EOL) Node.js versions.
OS Compatibility: Must function on at least one officially supported Operating System (OS).
Broad OS Support: Cannot be limited to a subset of OS distributions or versions.

For example, an installation method claiming compatibility with “Windows” must function on “Windows 10”, “Windows 11”, and all their editions (including server versions).
Similarly, an installation method claiming compatibility with “Linux” must be installable on all major Linux distributions, not just a specific subset. It cannot rely on distribution-specific package managers like apt or dnf.


Free and Open Source: Must be free to use and open source, must not be sold as a commercial product, and must not be a paid service.\n\n\n\n\n\nNode.js
        
      
      
About this documentation
Usage and example



Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Modules: TypeScript
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
Readline
REPL
Report
Single executable applications
SQLite
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker

    

    
      
        
          Node.js v24.0.1 documentation
          
            
            
          
        
        
          
            Node.js v24.0.1
            
    
      
        
        Table of contents
      

      
About this documentation

Contributing
Stability index
Stability overview
JSON output
System calls and man pages



    
  
            
    
      
        
        Index
      

      
About this documentation
Usage and example

      
        Index
      
    
  


Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Modules: TypeScript
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
Readline
REPL
Report
Single executable applications
SQLite
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker

    
  
            
    
      
        
        Other versions
      
      24.x
23.x
22.x LTS
21.x
20.x LTS
19.x
18.x
17.x
16.x
15.x
14.x
13.x
12.x
11.x
10.x
9.x
8.x
7.x
6.x
5.x
4.x
0.12.x
0.10.x
    
  
            
              
                
                Options
              
        
              
                
                  
                    View on single page
                  
                  
                    View as JSON
                  
                  Edit on GitHub    
                
              
            
          
        
        
      

      Table of contents
About this documentation

Contributing
Stability index
Stability overview
JSON output
System calls and man pages




      
        About this documentation#


Welcome to the official API reference documentation for Node.js!
Node.js is a JavaScript runtime built on the V8 JavaScript engine.
Contributing#
Report errors in this documentation in the issue tracker. See
the contributing guide for directions on how to submit pull requests.
Stability index#

Throughout the documentation are indications of a section's stability. Some APIs
are so proven and so relied upon that they are unlikely to ever change at all.
Others are brand new and experimental, or known to be hazardous.
The stability indexes are as follows:
Stability: 0 - Deprecated. The feature may emit warnings. Backward
compatibility is not guaranteed.

Stability: 1 - Experimental. The feature is not subject to
semantic versioning rules. Non-backward compatible changes or removal may
occur in any future release. Use of the feature is not recommended in
production environments.Experimental features are subdivided into stages:
1.0 - Early development. Experimental features at this stage are unfinished
and subject to substantial change.
1.1 - Active development. Experimental features at this stage are nearing
minimum viability.
1.2 - Release candidate. Experimental features at this stage are hopefully
ready to become stable. No further breaking changes are anticipated but may
still occur in response to user feedback. We encourage user testing and
feedback so that we can know that this feature is ready to be marked as
stable.
Experimental features leave the experimental status typically either by
graduating to stable, or are removed without a deprecation cycle.

Stability: 2 - Stable. Compatibility with the npm ecosystem is a high
priority.

Stability: 3 - Legacy. Although this feature is unlikely to be removed and is
still covered by semantic versioning guarantees, it is no longer actively
maintained, and other alternatives are available.
Features are marked as legacy rather than being deprecated if their use does no
harm, and they are widely relied upon within the npm ecosystem. Bugs found in
legacy features are unlikely to be fixed.
Use caution when making use of Experimental features, particularly when
authoring libraries. Users may not be aware that experimental features are being
used. Bugs or behavior changes may surprise users when Experimental API
modifications occur. To avoid surprises, use of an Experimental feature may need
a command-line flag. Experimental features may also emit a warning.
Stability overview#
APIStabilityAssert(2) StableAsync hooks(1) ExperimentalAsynchronous context tracking(2) StableBuffer(2) StableChild process(2) StableCluster(2) StableConsole(2) StableCrypto(2) StableDiagnostics Channel(2) StableDNS(2) StableDomain(0) DeprecatedFile system(2) StableHTTP(2) StableHTTP/2(2) StableHTTPS(2) StableInspector(2) StableModules: node:module API(1) .2 - Release candidate (asynchronous version) Stability: 1.1 - Active development (synchronous version)Modules: CommonJS modules(2) StableModules: TypeScript(1) .2 - Release candidateOS(2) StablePath(2) StablePerformance measurement APIs(2) StablePunycode(0) DeprecatedQuery string(2) StableReadline(2) StableREPL(2) StableSingle executable applications(1) .1 - Active developmentSQLite(1) .1 - Active development.Stream(2) StableString decoder(2) StableTest runner(2) StableTimers(2) StableTLS (SSL)(2) StableTrace events(1) ExperimentalTTY(2) StableUDP/datagram sockets(2) StableURL(2) StableUtil(2) StableVM (executing JavaScript)(2) StableWeb Crypto API(2) StableWeb Streams API(2) StableWebAssembly System Interface (WASI)(1) ExperimentalWorker threads(2) StableZlib(2) Stable
JSON output#

Added in: v0.6.12

Every .html document has a corresponding .json document. This is for IDEs
and other utilities that consume the documentation.
System calls and man pages#
Node.js functions which wrap a system call will document that. The docs link
to the corresponding man pages which describe how the system call works.
Most Unix system calls have Windows analogues. Still, behavior differences may
be unavoidable.\n\n\n\nNode.js
        
      
      
About this documentation
Usage and example



Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Modules: TypeScript
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
Readline
REPL
Report
Single executable applications
SQLite
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker

    

    
      
        
          Node.js v24.0.1 documentation
          
            
            
          
        
        
          
            Node.js v24.0.1
            
    
      
        
        Table of contents
      

      
Usage and example

Usage
Example



    
  
            
    
      
        
        Index
      

      
About this documentation
Usage and example

      
        Index
      
    
  


Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Modules: TypeScript
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
Readline
REPL
Report
Single executable applications
SQLite
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker

    
  
            
    
      
        
        Other versions
      
      24.x
23.x
22.x LTS
21.x
20.x LTS
19.x
18.x
17.x
16.x
15.x
14.x
13.x
12.x
11.x
10.x
9.x
8.x
7.x
6.x
5.x
4.x
0.12.x
0.10.x
    
  
            
              
                
                Options
              
        
              
                
                  
                    View on single page
                  
                  
                    View as JSON
                  
                  Edit on GitHub    
                
              
            
          
        
        
      

      Table of contents
Usage and example

Usage
Example




      
        Usage and example#
Usage#


node [options] [V8 options] [script.js | -e "script" | - ] [arguments]
Please see the Command-line options document for more information.
Example#
An example of a web server written with Node.js which responds with
'Hello, World!':
Commands in this document start with $ or > to replicate how they would
appear in a user's terminal. Do not include the $ and > characters. They are
there to show the start of each command.
Lines that don't start with $ or > character show the output of the previous
command.
First, make sure to have downloaded and installed Node.js. See
Installing Node.js via package manager for further install information.
Now, create an empty project folder called projects, then navigate into it.
Linux and Mac:
mkdir ~/projects
cd ~/projects copy
Windows CMD:
mkdir %USERPROFILE%\projects
cd %USERPROFILE%\projects copy
Windows PowerShell:
mkdir $env:USERPROFILE\projects
cd $env:USERPROFILE\projects copy
Next, create a new source file in the projects
folder and call it hello-world.js.
Open hello-world.js in any preferred text editor and
paste in the following content:
const http = require('node:http');

const hostname = '127.0.0.1';
const port = 3000;

const server = http.createServer((req, res) => {
  res.statusCode = 200;
  res.setHeader('Content-Type', 'text/plain');
  res.end('Hello, World!\n');
});

server.listen(port, hostname, () => {
  console.log(`Server running at http://${hostname}:${port}/`);
}); copy
Save the file. Then, in the terminal window, to run the hello-world.js file,
enter:
node hello-world.js copy
Output like this should appear in the terminal:
Server running at http://127.0.0.1:3000/ copy
Now, open any preferred web browser and visit http://127.0.0.1:3000.
If the browser displays the string Hello, World!, that indicates
the server is working.\n\n\n\nNode.js
        
      
      
About this documentation
Usage and example



Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Modules: TypeScript
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
Readline
REPL
Report
Single executable applications
SQLite
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker

    

    
      
        
          Node.js v24.0.1 documentation
          
            
            
          
        
        
          
            Node.js v24.0.1
            
    
      
        
        Table of contents
      

      
Assert

Strict assertion mode
Legacy assertion mode
Class: assert.AssertionError

new assert.AssertionError(options)


Class: assert.CallTracker

new assert.CallTracker()
tracker.calls([fn][, exact])
tracker.getCalls(fn)
tracker.report()
tracker.reset([fn])
tracker.verify()


assert(value[, message])
assert.deepEqual(actual, expected[, message])

Comparison details


assert.deepStrictEqual(actual, expected[, message])

Comparison details


assert.doesNotMatch(string, regexp[, message])
assert.doesNotReject(asyncFn[, error][, message])
assert.doesNotThrow(fn[, error][, message])
assert.equal(actual, expected[, message])
assert.fail([message])
assert.fail(actual, expected[, message[, operator[, stackStartFn]]])
assert.ifError(value)
assert.match(string, regexp[, message])
assert.notDeepEqual(actual, expected[, message])
assert.notDeepStrictEqual(actual, expected[, message])
assert.notEqual(actual, expected[, message])
assert.notStrictEqual(actual, expected[, message])
assert.ok(value[, message])
assert.rejects(asyncFn[, error][, message])
assert.strictEqual(actual, expected[, message])
assert.throws(fn[, error][, message])
assert.partialDeepStrictEqual(actual, expected[, message])

Comparison details





    
  
            
    
      
        
        Index
      

      
About this documentation
Usage and example

      
        Index
      
    
  


Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Modules: TypeScript
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
Readline
REPL
Report
Single executable applications
SQLite
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker

    
  
            
    
      
        
        Other versions
      
      24.x
23.x
22.x LTS
21.x
20.x LTS
19.x
18.x
17.x
16.x
15.x
14.x
13.x
12.x
11.x
10.x
9.x
8.x
7.x
6.x
5.x
4.x
0.12.x
0.10.x
    
  
            
              
                
                Options
              
        
              
                
                  
                    View on single page
                  
                  
                    View as JSON
                  
                  Edit on GitHub    
                
              
            
          
        
        
      

      Table of contents
Assert

Strict assertion mode
Legacy assertion mode
Class: assert.AssertionError

new assert.AssertionError(options)


Class: assert.CallTracker

new assert.CallTracker()
tracker.calls([fn][, exact])
tracker.getCalls(fn)
tracker.report()
tracker.reset([fn])
tracker.verify()


assert(value[, message])
assert.deepEqual(actual, expected[, message])

Comparison details


assert.deepStrictEqual(actual, expected[, message])

Comparison details


assert.doesNotMatch(string, regexp[, message])
assert.doesNotReject(asyncFn[, error][, message])
assert.doesNotThrow(fn[, error][, message])
assert.equal(actual, expected[, message])
assert.fail([message])
assert.fail(actual, expected[, message[, operator[, stackStartFn]]])
assert.ifError(value)
assert.match(string, regexp[, message])
assert.notDeepEqual(actual, expected[, message])
assert.notDeepStrictEqual(actual, expected[, message])
assert.notEqual(actual, expected[, message])
assert.notStrictEqual(actual, expected[, message])
assert.ok(value[, message])
assert.rejects(asyncFn[, error][, message])
assert.strictEqual(actual, expected[, message])
assert.throws(fn[, error][, message])
assert.partialDeepStrictEqual(actual, expected[, message])

Comparison details






      
        Assert#

Stability: 2 - Stable
Source Code: lib/assert.js
The node:assert module provides a set of assertion functions for verifying
invariants.
Strict assertion mode#

History

VersionChanges
v15.0.0
Exposed as require('node:assert/strict').
v13.9.0, v12.16.2
Changed "strict mode" to "strict assertion mode" and "legacy mode" to "legacy assertion mode" to avoid confusion with the more usual meaning of "strict mode".
v9.9.0
Added error diffs to the strict assertion mode.
v9.9.0
Added strict assertion mode to the assert module.
v9.9.0
Added in: v9.9.0



In strict assertion mode, non-strict methods behave like their corresponding
strict methods. For example, assert.deepEqual() will behave like
assert.deepStrictEqual().
In strict assertion mode, error messages for objects display a diff. In legacy
assertion mode, error messages for objects display the objects, often truncated.
To use strict assertion mode:

import { strict as assert } from 'node:assert';const assert = require('node:assert').strict;copy

import assert from 'node:assert/strict';const assert = require('node:assert/strict');copy
Example error diff:

import { strict as assert } from 'node:assert';

assert.deepEqual([[[1, 2, 3]], 4, 5], [[[1, 2, '3']], 4, 5]);
// AssertionError: Expected inputs to be strictly deep-equal:
// + actual - expected ... Lines skipped
//
//   [
//     [
// ...
//       2,
// +     3
// -     '3'
//     ],
// ...
//     5
//   ]const assert = require('node:assert/strict');

assert.deepEqual([[[1, 2, 3]], 4, 5], [[[1, 2, '3']], 4, 5]);
// AssertionError: Expected inputs to be strictly deep-equal:
// + actual - expected ... Lines skipped
//
//   [
//     [
// ...
//       2,
// +     3
// -     '3'
//     ],
// ...
//     5
//   ]copy
To deactivate the colors, use the NO_COLOR or NODE_DISABLE_COLORS
environment variables. This will also deactivate the colors in the REPL. For
more on color support in terminal environments, read the tty
getColorDepth() documentation.
Legacy assertion mode#
Legacy assertion mode uses the == operator in:

assert.deepEqual()
assert.equal()
assert.notDeepEqual()
assert.notEqual()

To use legacy assertion mode:

import assert from 'node:assert';const assert = require('node:assert');copy
Legacy assertion mode may have surprising results, especially when using
assert.deepEqual():
// WARNING: This does not throw an AssertionError in legacy assertion mode!
assert.deepEqual(/a/gi, new Date()); copy
Class: assert.AssertionError[src]#

Extends: <errors.Error>

Indicates the failure of an assertion. All errors thrown by the node:assert
module will be instances of the AssertionError class.

new assert.AssertionError(options)#

Added in: v0.1.21


options <Object>

message <string> If provided, the error message is set to this value.
actual <any> The actual property on the error instance.
expected <any> The expected property on the error instance.
operator <string> The operator property on the error instance.
stackStartFn <Function> If provided, the generated stack trace omits
frames before this function.



A subclass of <Error> that indicates the failure of an assertion.
All instances contain the built-in Error properties (message and name)
and:

actual <any> Set to the actual argument for methods such as
assert.strictEqual().
expected <any> Set to the expected value for methods such as
assert.strictEqual().
generatedMessage <boolean> Indicates if the message was auto-generated
(true) or not.
code <string> Value is always ERR_ASSERTION to show that the error is an
assertion error.
operator <string> Set to the passed in operator value.


import assert from 'node:assert';

// Generate an AssertionError to compare the error message later:
const { message } = new assert.AssertionError({
  actual: 1,
  expected: 2,
  operator: 'strictEqual',
});

// Verify error output:
try {
  assert.strictEqual(1, 2);
} catch (err) {
  assert(err instanceof assert.AssertionError);
  assert.strictEqual(err.message, message);
  assert.strictEqual(err.name, 'AssertionError');
  assert.strictEqual(err.actual, 1);
  assert.strictEqual(err.expected, 2);
  assert.strictEqual(err.code, 'ERR_ASSERTION');
  assert.strictEqual(err.operator, 'strictEqual');
  assert.strictEqual(err.generatedMessage, true);
}const assert = require('node:assert');

// Generate an AssertionError to compare the error message later:
const { message } = new assert.AssertionError({
  actual: 1,
  expected: 2,
  operator: 'strictEqual',
});

// Verify error output:
try {
  assert.strictEqual(1, 2);
} catch (err) {
  assert(err instanceof assert.AssertionError);
  assert.strictEqual(err.message, message);
  assert.strictEqual(err.name, 'AssertionError');
  assert.strictEqual(err.actual, 1);
  assert.strictEqual(err.expected, 2);
  assert.strictEqual(err.code, 'ERR_ASSERTION');
  assert.strictEqual(err.operator, 'strictEqual');
  assert.strictEqual(err.generatedMessage, true);
}copy

Class: assert.CallTracker#

History

VersionChanges
v20.1.0
the assert.CallTracker class has been deprecated and will be removed in a future version.
v14.2.0, v12.19.0
Added in: v14.2.0, v12.19.0



Stability: 0 - Deprecated
This feature is deprecated and will be removed in a future version.
Please consider using alternatives such as the
mock helper function.

new assert.CallTracker()#

Added in: v14.2.0, v12.19.0

Creates a new CallTracker object which can be used to track if functions
were called a specific number of times. The tracker.verify() must be called
for the verification to take place. The usual pattern would be to call it in a
process.on('exit') handler.

import assert from 'node:assert';
import process from 'node:process';

const tracker = new assert.CallTracker();

function func() {}

// callsfunc() must be called exactly 1 time before tracker.verify().
const callsfunc = tracker.calls(func, 1);

callsfunc();

// Calls tracker.verify() and verifies if all tracker.calls() functions have
// been called exact times.
process.on('exit', () => {
  tracker.verify();
});const assert = require('node:assert');
const process = require('node:process');

const tracker = new assert.CallTracker();

function func() {}

// callsfunc() must be called exactly 1 time before tracker.verify().
const callsfunc = tracker.calls(func, 1);

callsfunc();

// Calls tracker.verify() and verifies if all tracker.calls() functions have
// been called exact times.
process.on('exit', () => {
  tracker.verify();
});copy

tracker.calls([fn][, exact])#

Added in: v14.2.0, v12.19.0


fn <Function> Default: A no-op function.
exact <number> Default: 1.
Returns: <Function> A function that wraps fn.

The wrapper function is expected to be called exactly exact times. If the
function has not been called exactly exact times when
tracker.verify() is called, then tracker.verify() will throw an
error.

import assert from 'node:assert';

// Creates call tracker.
const tracker = new assert.CallTracker();

function func() {}

// Returns a function that wraps func() that must be called exact times
// before tracker.verify().
const callsfunc = tracker.calls(func);const assert = require('node:assert');

// Creates call tracker.
const tracker = new assert.CallTracker();

function func() {}

// Returns a function that wraps func() that must be called exact times
// before tracker.verify().
const callsfunc = tracker.calls(func);copy

tracker.getCalls(fn)#

Added in: v18.8.0, v16.18.0



fn <Function>


Returns: <Array> An array with all the calls to a tracked function.


Object <Object>

thisArg <Object>
arguments <Array> the arguments passed to the tracked function




import assert from 'node:assert';

const tracker = new assert.CallTracker();

function func() {}
const callsfunc = tracker.calls(func);
callsfunc(1, 2, 3);

assert.deepStrictEqual(tracker.getCalls(callsfunc),
                       [{ thisArg: undefined, arguments: [1, 2, 3] }]);const assert = require('node:assert');

// Creates call tracker.
const tracker = new assert.CallTracker();

function func() {}
const callsfunc = tracker.calls(func);
callsfunc(1, 2, 3);

assert.deepStrictEqual(tracker.getCalls(callsfunc),
                       [{ thisArg: undefined, arguments: [1, 2, 3] }]);copy

tracker.report()#

Added in: v14.2.0, v12.19.0


Returns: <Array> An array of objects containing information about the wrapper
functions returned by tracker.calls().
Object <Object>

message <string>
actual <number> The actual number of times the function was called.
expected <number> The number of times the function was expected to be
called.
operator <string> The name of the function that is wrapped.
stack <Object> A stack trace of the function.



The arrays contains information about the expected and actual number of calls of
the functions that have not been called the expected number of times.

import assert from 'node:assert';

// Creates call tracker.
const tracker = new assert.CallTracker();

function func() {}

// Returns a function that wraps func() that must be called exact times
// before tracker.verify().
const callsfunc = tracker.calls(func, 2);

// Returns an array containing information on callsfunc()
console.log(tracker.report());
// [
//  {
//    message: 'Expected the func function to be executed 2 time(s) but was
//    executed 0 time(s).',
//    actual: 0,
//    expected: 2,
//    operator: 'func',
//    stack: stack trace
//  }
// ]const assert = require('node:assert');

// Creates call tracker.
const tracker = new assert.CallTracker();

function func() {}

// Returns a function that wraps func() that must be called exact times
// before tracker.verify().
const callsfunc = tracker.calls(func, 2);

// Returns an array containing information on callsfunc()
console.log(tracker.report());
// [
//  {
//    message: 'Expected the func function to be executed 2 time(s) but was
//    executed 0 time(s).',
//    actual: 0,
//    expected: 2,
//    operator: 'func',
//    stack: stack trace
//  }
// ]copy

tracker.reset([fn])#

Added in: v18.8.0, v16.18.0


fn <Function> a tracked function to reset.

Reset calls of the call tracker.
If a tracked function is passed as an argument, the calls will be reset for it.
If no arguments are passed, all tracked functions will be reset.

import assert from 'node:assert';

const tracker = new assert.CallTracker();

function func() {}
const callsfunc = tracker.calls(func);

callsfunc();
// Tracker was called once
assert.strictEqual(tracker.getCalls(callsfunc).length, 1);

tracker.reset(callsfunc);
assert.strictEqual(tracker.getCalls(callsfunc).length, 0);const assert = require('node:assert');

const tracker = new assert.CallTracker();

function func() {}
const callsfunc = tracker.calls(func);

callsfunc();
// Tracker was called once
assert.strictEqual(tracker.getCalls(callsfunc).length, 1);

tracker.reset(callsfunc);
assert.strictEqual(tracker.getCalls(callsfunc).length, 0);copy

tracker.verify()#

Added in: v14.2.0, v12.19.0

Iterates through the list of functions passed to
tracker.calls() and will throw an error for functions that
have not been called the expected number of times.

import assert from 'node:assert';

// Creates call tracker.
const tracker = new assert.CallTracker();

function func() {}

// Returns a function that wraps func() that must be called exact times
// before tracker.verify().
const callsfunc = tracker.calls(func, 2);

callsfunc();

// Will throw an error since callsfunc() was only called once.
tracker.verify();const assert = require('node:assert');

// Creates call tracker.
const tracker = new assert.CallTracker();

function func() {}

// Returns a function that wraps func() that must be called exact times
// before tracker.verify().
const callsfunc = tracker.calls(func, 2);

callsfunc();

// Will throw an error since callsfunc() was only called once.
tracker.verify();copy

assert(value[, message])#

Added in: v0.5.9


value <any> The input that is checked for being truthy.
message <string> | <Error>

An alias of assert.ok().
assert.deepEqual(actual, expected[, message])#

History

VersionChanges
v24.0.0
Recursion now stops when either side encounters a circular reference.
v22.2.0, v20.15.0
Error cause and errors properties are now compared as well.
v18.0.0
Regular expressions lastIndex property is now compared as well.
v16.0.0, v14.18.0
In Legacy assertion mode, changed status from Deprecated to Legacy.
v14.0.0
NaN is now treated as being identical if both sides are NaN.
v12.0.0
The type tags are now properly compared and there are a couple minor comparison adjustments to make the check less surprising.
v9.0.0
The Error names and messages are now properly compared.
v8.0.0
The Set and Map content is also compared.
v6.4.0, v4.7.1
Typed array slices are handled correctly now.
v6.1.0, v4.5.0
Objects with circular references can be used as inputs now.
v5.10.1, v4.4.3
Handle non-Uint8Array typed arrays correctly.
v0.1.21
Added in: v0.1.21




actual <any>
expected <any>
message <string> | <Error>

Strict assertion mode
An alias of assert.deepStrictEqual().
Legacy assertion mode
Stability: 3 - Legacy: Use assert.deepStrictEqual() instead.
Tests for deep equality between the actual and expected parameters. Consider
using assert.deepStrictEqual() instead. assert.deepEqual() can have
surprising results.
Deep equality means that the enumerable "own" properties of child objects
are also recursively evaluated by the following rules.

Comparison details#

Primitive values are compared with the == operator,
with the exception of <NaN>. It is treated as being identical in case
both sides are <NaN>.
Type tags of objects should be the same.
Only enumerable "own" properties are considered.
<Error> names, messages, causes, and errors are always compared,
even if these are not enumerable properties.
Object wrappers are compared both as objects and unwrapped values.
Object properties are compared unordered.
<Map> keys and <Set> items are compared unordered.
Recursion stops when both sides differ or either side encounters a circular
reference.
Implementation does not test the [[Prototype]] of
objects.
<Symbol> properties are not compared.
<WeakMap> and <WeakSet> comparison does not rely on their values
but only on their instances.
<RegExp> lastIndex, flags, and source are always compared, even if these
are not enumerable properties.

The following example does not throw an AssertionError because the
primitives are compared using the == operator.

import assert from 'node:assert';
// WARNING: This does not throw an AssertionError!

assert.deepEqual('+00000000', false);const assert = require('node:assert');
// WARNING: This does not throw an AssertionError!

assert.deepEqual('+00000000', false);copy
"Deep" equality means that the enumerable "own" properties of child objects
are evaluated also:

import assert from 'node:assert';

const obj1 = {
  a: {
    b: 1,
  },
};
const obj2 = {
  a: {
    b: 2,
  },
};
const obj3 = {
  a: {
    b: 1,
  },
};
const obj4 = { __proto__: obj1 };

assert.deepEqual(obj1, obj1);
// OK

// Values of b are different:
assert.deepEqual(obj1, obj2);
// AssertionError: { a: { b: 1 } } deepEqual { a: { b: 2 } }

assert.deepEqual(obj1, obj3);
// OK

// Prototypes are ignored:
assert.deepEqual(obj1, obj4);
// AssertionError: { a: { b: 1 } } deepEqual {}const assert = require('node:assert');

const obj1 = {
  a: {
    b: 1,
  },
};
const obj2 = {
  a: {
    b: 2,
  },
};
const obj3 = {
  a: {
    b: 1,
  },
};
const obj4 = { __proto__: obj1 };

assert.deepEqual(obj1, obj1);
// OK

// Values of b are different:
assert.deepEqual(obj1, obj2);
// AssertionError: { a: { b: 1 } } deepEqual { a: { b: 2 } }

assert.deepEqual(obj1, obj3);
// OK

// Prototypes are ignored:
assert.deepEqual(obj1, obj4);
// AssertionError: { a: { b: 1 } } deepEqual {}copy
If the values are not equal, an AssertionError is thrown with a message
property set equal to the value of the message parameter. If the message
parameter is undefined, a default error message is assigned. If the message
parameter is an instance of <Error> then it will be thrown instead of the
AssertionError.

assert.deepStrictEqual(actual, expected[, message])#

History

VersionChanges
v24.0.0
Recursion now stops when either side encounters a circular reference.
v22.2.0, v20.15.0
Error cause and errors properties are now compared as well.
v18.0.0
Regular expressions lastIndex property is now compared as well.
v9.0.0
Enumerable symbol properties are now compared.
v9.0.0
The NaN is now compared using the SameValueZero comparison.
v8.5.0
The Error names and messages are now properly compared.
v8.0.0
The Set and Map content is also compared.
v6.1.0
Objects with circular references can be used as inputs now.
v6.4.0, v4.7.1
Typed array slices are handled correctly now.
v5.10.1, v4.4.3
Handle non-Uint8Array typed arrays correctly.
v1.2.0
Added in: v1.2.0




actual <any>
expected <any>
message <string> | <Error>

Tests for deep equality between the actual and expected parameters.
"Deep" equality means that the enumerable "own" properties of child objects
are recursively evaluated also by the following rules.

Comparison details#

Primitive values are compared using Object.is().
Type tags of objects should be the same.
[[Prototype]] of objects are compared using
the === operator.
Only enumerable "own" properties are considered.
<Error> names, messages, causes, and errors are always compared,
even if these are not enumerable properties.
errors is also compared.
Enumerable own <Symbol> properties are compared as well.
Object wrappers are compared both as objects and unwrapped values.
Object properties are compared unordered.
<Map> keys and <Set> items are compared unordered.
Recursion stops when both sides differ or either side encounters a circular
reference.
<WeakMap> and <WeakSet> instances are not compared structurally.
They are only equal if they reference the same object. Any comparison between
different WeakMap or WeakSet instances will result in inequality,
even if they contain the same entries.
<RegExp> lastIndex, flags, and source are always compared, even if these
are not enumerable properties.


import assert from 'node:assert/strict';

// This fails because 1 !== '1'.
assert.deepStrictEqual({ a: 1 }, { a: '1' });
// AssertionError: Expected inputs to be strictly deep-equal:
// + actual - expected
//
//   {
// +   a: 1
// -   a: '1'
//   }

// The following objects don't have own properties
const date = new Date();
const object = {};
const fakeDate = {};
Object.setPrototypeOf(fakeDate, Date.prototype);

// Different [[Prototype]]:
assert.deepStrictEqual(object, fakeDate);
// AssertionError: Expected inputs to be strictly deep-equal:
// + actual - expected
//
// + {}
// - Date {}

// Different type tags:
assert.deepStrictEqual(date, fakeDate);
// AssertionError: Expected inputs to be strictly deep-equal:
// + actual - expected
//
// + 2018-04-26T00:49:08.604Z
// - Date {}

assert.deepStrictEqual(NaN, NaN);
// OK because Object.is(NaN, NaN) is true.

// Different unwrapped numbers:
assert.deepStrictEqual(new Number(1), new Number(2));
// AssertionError: Expected inputs to be strictly deep-equal:
// + actual - expected
//
// + [Number: 1]
// - [Number: 2]

assert.deepStrictEqual(new String('foo'), Object('foo'));
// OK because the object and the string are identical when unwrapped.

assert.deepStrictEqual(-0, -0);
// OK

// Different zeros:
assert.deepStrictEqual(0, -0);
// AssertionError: Expected inputs to be strictly deep-equal:
// + actual - expected
//
// + 0
// - -0

const symbol1 = Symbol();
const symbol2 = Symbol();
assert.deepStrictEqual({ [symbol1]: 1 }, { [symbol1]: 1 });
// OK, because it is the same symbol on both objects.

assert.deepStrictEqual({ [symbol1]: 1 }, { [symbol2]: 1 });
// AssertionError [ERR_ASSERTION]: Inputs identical but not reference equal:
//
// {
//   Symbol(): 1
// }

const weakMap1 = new WeakMap();
const weakMap2 = new WeakMap();
const obj = {};

weakMap1.set(obj, 'value');
weakMap2.set(obj, 'value');

// Comparing different instances fails, even with same contents
assert.deepStrictEqual(weakMap1, weakMap2);
// AssertionError: Values have same structure but are not reference-equal:
//
// WeakMap {
//   <items unknown>
// }

// Comparing the same instance to itself succeeds
assert.deepStrictEqual(weakMap1, weakMap1);
// OK

const weakSet1 = new WeakSet();
const weakSet2 = new WeakSet();
weakSet1.add(obj);
weakSet2.add(obj);

// Comparing different instances fails, even with same contents
assert.deepStrictEqual(weakSet1, weakSet2);
// AssertionError: Values have same structure but are not reference-equal:
// + actual - expected
//
// WeakSet {
//   <items unknown>
// }

// Comparing the same instance to itself succeeds
assert.deepStrictEqual(weakSet1, weakSet1);
// OKconst assert = require('node:assert/strict');

// This fails because 1 !== '1'.
assert.deepStrictEqual({ a: 1 }, { a: '1' });
// AssertionError: Expected inputs to be strictly deep-equal:
// + actual - expected
//
//   {
// +   a: 1
// -   a: '1'
//   }

// The following objects don't have own properties
const date = new Date();
const object = {};
const fakeDate = {};
Object.setPrototypeOf(fakeDate, Date.prototype);

// Different [[Prototype]]:
assert.deepStrictEqual(object, fakeDate);
// AssertionError: Expected inputs to be strictly deep-equal:
// + actual - expected
//
// + {}
// - Date {}

// Different type tags:
assert.deepStrictEqual(date, fakeDate);
// AssertionError: Expected inputs to be strictly deep-equal:
// + actual - expected
//
// + 2018-04-26T00:49:08.604Z
// - Date {}

assert.deepStrictEqual(NaN, NaN);
// OK because Object.is(NaN, NaN) is true.

// Different unwrapped numbers:
assert.deepStrictEqual(new Number(1), new Number(2));
// AssertionError: Expected inputs to be strictly deep-equal:
// + actual - expected
//
// + [Number: 1]
// - [Number: 2]

assert.deepStrictEqual(new String('foo'), Object('foo'));
// OK because the object and the string are identical when unwrapped.

assert.deepStrictEqual(-0, -0);
// OK

// Different zeros:
assert.deepStrictEqual(0, -0);
// AssertionError: Expected inputs to be strictly deep-equal:
// + actual - expected
//
// + 0
// - -0

const symbol1 = Symbol();
const symbol2 = Symbol();
assert.deepStrictEqual({ [symbol1]: 1 }, { [symbol1]: 1 });
// OK, because it is the same symbol on both objects.

assert.deepStrictEqual({ [symbol1]: 1 }, { [symbol2]: 1 });
// AssertionError [ERR_ASSERTION]: Inputs identical but not reference equal:
//
// {
//   Symbol(): 1
// }

const weakMap1 = new WeakMap();
const weakMap2 = new WeakMap();
const obj = {};

weakMap1.set(obj, 'value');
weakMap2.set(obj, 'value');

// Comparing different instances fails, even with same contents
assert.deepStrictEqual(weakMap1, weakMap2);
// AssertionError: Values have same structure but are not reference-equal:
//
// WeakMap {
//   <items unknown>
// }

// Comparing the same instance to itself succeeds
assert.deepStrictEqual(weakMap1, weakMap1);
// OK

const weakSet1 = new WeakSet();
const weakSet2 = new WeakSet();
weakSet1.add(obj);
weakSet2.add(obj);

// Comparing different instances fails, even with same contents
assert.deepStrictEqual(weakSet1, weakSet2);
// AssertionError: Values have same structure but are not reference-equal:
// + actual - expected
//
// WeakSet {
//   <items unknown>
// }

// Comparing the same instance to itself succeeds
assert.deepStrictEqual(weakSet1, weakSet1);
// OKcopy
If the values are not equal, an AssertionError is thrown with a message
property set equal to the value of the message parameter. If the message
parameter is undefined, a default error message is assigned. If the message
parameter is an instance of <Error> then it will be thrown instead of the
AssertionError.

assert.doesNotMatch(string, regexp[, message])#

History

VersionChanges
v16.0.0
This API is no longer experimental.
v13.6.0, v12.16.0
Added in: v13.6.0, v12.16.0




string <string>
regexp <RegExp>
message <string> | <Error>

Expects the string input not to match the regular expression.

import assert from 'node:assert/strict';

assert.doesNotMatch('I will fail', /fail/);
// AssertionError [ERR_ASSERTION]: The input was expected to not match the ...

assert.doesNotMatch(123, /pass/);
// AssertionError [ERR_ASSERTION]: The "string" argument must be of type string.

assert.doesNotMatch('I will pass', /different/);
// OKconst assert = require('node:assert/strict');

assert.doesNotMatch('I will fail', /fail/);
// AssertionError [ERR_ASSERTION]: The input was expected to not match the ...

assert.doesNotMatch(123, /pass/);
// AssertionError [ERR_ASSERTION]: The "string" argument must be of type string.

assert.doesNotMatch('I will pass', /different/);
// OKcopy
If the values do match, or if the string argument is of another type than
string, an AssertionError is thrown with a message property set equal
to the value of the message parameter. If the message parameter is
undefined, a default error message is assigned. If the message parameter is an
instance of <Error> then it will be thrown instead of the
AssertionError.
assert.doesNotReject(asyncFn[, error][, message])#

Added in: v10.0.0


asyncFn <Function> | <Promise>
error <RegExp> | <Function>
message <string>
Returns: <Promise>

Awaits the asyncFn promise or, if asyncFn is a function, immediately
calls the function and awaits the returned promise to complete. It will then
check that the promise is not rejected.
If asyncFn is a function and it throws an error synchronously,
assert.doesNotReject() will return a rejected Promise with that error. If
the function does not return a promise, assert.doesNotReject() will return a
rejected Promise with an ERR_INVALID_RETURN_VALUE error. In both cases
the error handler is skipped.
Using assert.doesNotReject() is actually not useful because there is little
benefit in catching a rejection and then rejecting it again. Instead, consider
adding a comment next to the specific code path that should not reject and keep
error messages as expressive as possible.
If specified, error can be a Class, <RegExp> or a validation
function. See assert.throws() for more details.
Besides the async nature to await the completion behaves identically to
assert.doesNotThrow().

import assert from 'node:assert/strict';

await assert.doesNotReject(
  async () => {
    throw new TypeError('Wrong value');
  },
  SyntaxError,
);const assert = require('node:assert/strict');

(async () => {
  await assert.doesNotReject(
    async () => {
      throw new TypeError('Wrong value');
    },
    SyntaxError,
  );
})();copy

import assert from 'node:assert/strict';

assert.doesNotReject(Promise.reject(new TypeError('Wrong value')))
  .then(() => {
    // ...
  });const assert = require('node:assert/strict');

assert.doesNotReject(Promise.reject(new TypeError('Wrong value')))
  .then(() => {
    // ...
  });copy
assert.doesNotThrow(fn[, error][, message])#

History

VersionChanges
v5.11.0, v4.4.5
The message parameter is respected now.
v4.2.0
The error parameter can now be an arrow function.
v0.1.21
Added in: v0.1.21




fn <Function>
error <RegExp> | <Function>
message <string>

Asserts that the function fn does not throw an error.
Using assert.doesNotThrow() is actually not useful because there
is no benefit in catching an error and then rethrowing it. Instead, consider
adding a comment next to the specific code path that should not throw and keep
error messages as expressive as possible.
When assert.doesNotThrow() is called, it will immediately call the fn
function.
If an error is thrown and it is the same type as that specified by the error
parameter, then an AssertionError is thrown. If the error is of a
different type, or if the error parameter is undefined, the error is
propagated back to the caller.
If specified, error can be a Class, <RegExp>, or a validation
function. See assert.throws() for more details.
The following, for instance, will throw the <TypeError> because there is no
matching error type in the assertion:

import assert from 'node:assert/strict';

assert.doesNotThrow(
  () => {
    throw new TypeError('Wrong value');
  },
  SyntaxError,
);const assert = require('node:assert/strict');

assert.doesNotThrow(
  () => {
    throw new TypeError('Wrong value');
  },
  SyntaxError,
);copy
However, the following will result in an AssertionError with the message
'Got unwanted exception...':

import assert from 'node:assert/strict';

assert.doesNotThrow(
  () => {
    throw new TypeError('Wrong value');
  },
  TypeError,
);const assert = require('node:assert/strict');

assert.doesNotThrow(
  () => {
    throw new TypeError('Wrong value');
  },
  TypeError,
);copy
If an AssertionError is thrown and a value is provided for the message
parameter, the value of message will be appended to the AssertionError
message:

import assert from 'node:assert/strict';

assert.doesNotThrow(
  () => {
    throw new TypeError('Wrong value');
  },
  /Wrong value/,
  'Whoops',
);
// Throws: AssertionError: Got unwanted exception: Whoopsconst assert = require('node:assert/strict');

assert.doesNotThrow(
  () => {
    throw new TypeError('Wrong value');
  },
  /Wrong value/,
  'Whoops',
);
// Throws: AssertionError: Got unwanted exception: Whoopscopy
assert.equal(actual, expected[, message])#

History

VersionChanges
v16.0.0, v14.18.0
In Legacy assertion mode, changed status from Deprecated to Legacy.
v14.0.0
NaN is now treated as being identical if both sides are NaN.
v0.1.21
Added in: v0.1.21




actual <any>
expected <any>
message <string> | <Error>

Strict assertion mode
An alias of assert.strictEqual().
Legacy assertion mode
Stability: 3 - Legacy: Use assert.strictEqual() instead.
Tests shallow, coercive equality between the actual and expected parameters
using the == operator. NaN is specially handled
and treated as being identical if both sides are NaN.

import assert from 'node:assert';

assert.equal(1, 1);
// OK, 1 == 1
assert.equal(1, '1');
// OK, 1 == '1'
assert.equal(NaN, NaN);
// OK

assert.equal(1, 2);
// AssertionError: 1 == 2
assert.equal({ a: { b: 1 } }, { a: { b: 1 } });
// AssertionError: { a: { b: 1 } } == { a: { b: 1 } }const assert = require('node:assert');

assert.equal(1, 1);
// OK, 1 == 1
assert.equal(1, '1');
// OK, 1 == '1'
assert.equal(NaN, NaN);
// OK

assert.equal(1, 2);
// AssertionError: 1 == 2
assert.equal({ a: { b: 1 } }, { a: { b: 1 } });
// AssertionError: { a: { b: 1 } } == { a: { b: 1 } }copy
If the values are not equal, an AssertionError is thrown with a message
property set equal to the value of the message parameter. If the message
parameter is undefined, a default error message is assigned. If the message
parameter is an instance of <Error> then it will be thrown instead of the
AssertionError.
assert.fail([message])#

Added in: v0.1.21


message <string> | <Error> Default: 'Failed'

Throws an AssertionError with the provided error message or a default
error message. If the message parameter is an instance of <Error> then
it will be thrown instead of the AssertionError.

import assert from 'node:assert/strict';

assert.fail();
// AssertionError [ERR_ASSERTION]: Failed

assert.fail('boom');
// AssertionError [ERR_ASSERTION]: boom

assert.fail(new TypeError('need array'));
// TypeError: need arrayconst assert = require('node:assert/strict');

assert.fail();
// AssertionError [ERR_ASSERTION]: Failed

assert.fail('boom');
// AssertionError [ERR_ASSERTION]: boom

assert.fail(new TypeError('need array'));
// TypeError: need arraycopy
Using assert.fail() with more than two arguments is possible but deprecated.
See below for further details.
assert.fail(actual, expected[, message[, operator[, stackStartFn]]])#

History

VersionChanges
v10.0.0
Calling assert.fail() with more than one argument is deprecated and emits a warning.
v0.1.21
Added in: v0.1.21



Stability: 0 - Deprecated: Use assert.fail([message]) or other assert
functions instead.

actual <any>
expected <any>
message <string> | <Error>
operator <string> Default: '!='
stackStartFn <Function> Default: assert.fail

If message is falsy, the error message is set as the values of actual and
expected separated by the provided operator. If just the two actual and
expected arguments are provided, operator will default to '!='. If
message is provided as third argument it will be used as the error message and
the other arguments will be stored as properties on the thrown object. If
stackStartFn is provided, all stack frames above that function will be
removed from stacktrace (see Error.captureStackTrace). If no arguments are
given, the default message Failed will be used.

import assert from 'node:assert/strict';

assert.fail('a', 'b');
// AssertionError [ERR_ASSERTION]: 'a' != 'b'

assert.fail(1, 2, undefined, '>');
// AssertionError [ERR_ASSERTION]: 1 > 2

assert.fail(1, 2, 'fail');
// AssertionError [ERR_ASSERTION]: fail

assert.fail(1, 2, 'whoops', '>');
// AssertionError [ERR_ASSERTION]: whoops

assert.fail(1, 2, new TypeError('need array'));
// TypeError: need arrayconst assert = require('node:assert/strict');

assert.fail('a', 'b');
// AssertionError [ERR_ASSERTION]: 'a' != 'b'

assert.fail(1, 2, undefined, '>');
// AssertionError [ERR_ASSERTION]: 1 > 2

assert.fail(1, 2, 'fail');
// AssertionError [ERR_ASSERTION]: fail

assert.fail(1, 2, 'whoops', '>');
// AssertionError [ERR_ASSERTION]: whoops

assert.fail(1, 2, new TypeError('need array'));
// TypeError: need arraycopy
In the last three cases actual, expected, and operator have no
influence on the error message.
Example use of stackStartFn for truncating the exception's stacktrace:

import assert from 'node:assert/strict';

function suppressFrame() {
  assert.fail('a', 'b', undefined, '!==', suppressFrame);
}
suppressFrame();
// AssertionError [ERR_ASSERTION]: 'a' !== 'b'
//     at repl:1:1
//     at ContextifyScript.Script.runInThisContext (vm.js:44:33)
//     ...const assert = require('node:assert/strict');

function suppressFrame() {
  assert.fail('a', 'b', undefined, '!==', suppressFrame);
}
suppressFrame();
// AssertionError [ERR_ASSERTION]: 'a' !== 'b'
//     at repl:1:1
//     at ContextifyScript.Script.runInThisContext (vm.js:44:33)
//     ...copy
assert.ifError(value)#

History

VersionChanges
v10.0.0
Instead of throwing the original error it is now wrapped into an [AssertionError][] that contains the full stack trace.
v10.0.0
Value may now only be undefined or null. Before all falsy values were handled the same as null and did not throw.
v0.1.97
Added in: v0.1.97




value <any>

Throws value if value is not undefined or null. This is useful when
testing the error argument in callbacks. The stack trace contains all frames
from the error passed to ifError() including the potential new frames for
ifError() itself.

import assert from 'node:assert/strict';

assert.ifError(null);
// OK
assert.ifError(0);
// AssertionError [ERR_ASSERTION]: ifError got unwanted exception: 0
assert.ifError('error');
// AssertionError [ERR_ASSERTION]: ifError got unwanted exception: 'error'
assert.ifError(new Error());
// AssertionError [ERR_ASSERTION]: ifError got unwanted exception: Error

// Create some random error frames.
let err;
(function errorFrame() {
  err = new Error('test error');
})();

(function ifErrorFrame() {
  assert.ifError(err);
})();
// AssertionError [ERR_ASSERTION]: ifError got unwanted exception: test error
//     at ifErrorFrame
//     at errorFrameconst assert = require('node:assert/strict');

assert.ifError(null);
// OK
assert.ifError(0);
// AssertionError [ERR_ASSERTION]: ifError got unwanted exception: 0
assert.ifError('error');
// AssertionError [ERR_ASSERTION]: ifError got unwanted exception: 'error'
assert.ifError(new Error());
// AssertionError [ERR_ASSERTION]: ifError got unwanted exception: Error

// Create some random error frames.
let err;
(function errorFrame() {
  err = new Error('test error');
})();

(function ifErrorFrame() {
  assert.ifError(err);
})();
// AssertionError [ERR_ASSERTION]: ifError got unwanted exception: test error
//     at ifErrorFrame
//     at errorFramecopy
assert.match(string, regexp[, message])#

History

VersionChanges
v16.0.0
This API is no longer experimental.
v13.6.0, v12.16.0
Added in: v13.6.0, v12.16.0




string <string>
regexp <RegExp>
message <string> | <Error>

Expects the string input to match the regular expression.

import assert from 'node:assert/strict';

assert.match('I will fail', /pass/);
// AssertionError [ERR_ASSERTION]: The input did not match the regular ...

assert.match(123, /pass/);
// AssertionError [ERR_ASSERTION]: The "string" argument must be of type string.

assert.match('I will pass', /pass/);
// OKconst assert = require('node:assert/strict');

assert.match('I will fail', /pass/);
// AssertionError [ERR_ASSERTION]: The input did not match the regular ...

assert.match(123, /pass/);
// AssertionError [ERR_ASSERTION]: The "string" argument must be of type string.

assert.match('I will pass', /pass/);
// OKcopy
If the values do not match, or if the string argument is of another type than
string, an AssertionError is thrown with a message property set equal
to the value of the message parameter. If the message parameter is
undefined, a default error message is assigned. If the message parameter is an
instance of <Error> then it will be thrown instead of the
AssertionError.
assert.notDeepEqual(actual, expected[, message])#

History

VersionChanges
v16.0.0, v14.18.0
In Legacy assertion mode, changed status from Deprecated to Legacy.
v14.0.0
NaN is now treated as being identical if both sides are NaN.
v9.0.0
The Error names and messages are now properly compared.
v8.0.0
The Set and Map content is also compared.
v6.4.0, v4.7.1
Typed array slices are handled correctly now.
v6.1.0, v4.5.0
Objects with circular references can be used as inputs now.
v5.10.1, v4.4.3
Handle non-Uint8Array typed arrays correctly.
v0.1.21
Added in: v0.1.21




actual <any>
expected <any>
message <string> | <Error>

Strict assertion mode
An alias of assert.notDeepStrictEqual().
Legacy assertion mode
Stability: 3 - Legacy: Use assert.notDeepStrictEqual() instead.
Tests for any deep inequality. Opposite of assert.deepEqual().

import assert from 'node:assert';

const obj1 = {
  a: {
    b: 1,
  },
};
const obj2 = {
  a: {
    b: 2,
  },
};
const obj3 = {
  a: {
    b: 1,
  },
};
const obj4 = { __proto__: obj1 };

assert.notDeepEqual(obj1, obj1);
// AssertionError: { a: { b: 1 } } notDeepEqual { a: { b: 1 } }

assert.notDeepEqual(obj1, obj2);
// OK

assert.notDeepEqual(obj1, obj3);
// AssertionError: { a: { b: 1 } } notDeepEqual { a: { b: 1 } }

assert.notDeepEqual(obj1, obj4);
// OKconst assert = require('node:assert');

const obj1 = {
  a: {
    b: 1,
  },
};
const obj2 = {
  a: {
    b: 2,
  },
};
const obj3 = {
  a: {
    b: 1,
  },
};
const obj4 = { __proto__: obj1 };

assert.notDeepEqual(obj1, obj1);
// AssertionError: { a: { b: 1 } } notDeepEqual { a: { b: 1 } }

assert.notDeepEqual(obj1, obj2);
// OK

assert.notDeepEqual(obj1, obj3);
// AssertionError: { a: { b: 1 } } notDeepEqual { a: { b: 1 } }

assert.notDeepEqual(obj1, obj4);
// OKcopy
If the values are deeply equal, an AssertionError is thrown with a
message property set equal to the value of the message parameter. If the
message parameter is undefined, a default error message is assigned. If the
message parameter is an instance of <Error> then it will be thrown
instead of the AssertionError.
assert.notDeepStrictEqual(actual, expected[, message])#

History

VersionChanges
v9.0.0
The -0 and +0 are not considered equal anymore.
v9.0.0
The NaN is now compared using the SameValueZero comparison.
v9.0.0
The Error names and messages are now properly compared.
v8.0.0
The Set and Map content is also compared.
v6.1.0
Objects with circular references can be used as inputs now.
v6.4.0, v4.7.1
Typed array slices are handled correctly now.
v5.10.1, v4.4.3
Handle non-Uint8Array typed arrays correctly.
v1.2.0
Added in: v1.2.0




actual <any>
expected <any>
message <string> | <Error>

Tests for deep strict inequality. Opposite of assert.deepStrictEqual().

import assert from 'node:assert/strict';

assert.notDeepStrictEqual({ a: 1 }, { a: '1' });
// OKconst assert = require('node:assert/strict');

assert.notDeepStrictEqual({ a: 1 }, { a: '1' });
// OKcopy
If the values are deeply and strictly equal, an AssertionError is thrown
with a message property set equal to the value of the message parameter. If
the message parameter is undefined, a default error message is assigned. If
the message parameter is an instance of <Error> then it will be thrown
instead of the AssertionError.
assert.notEqual(actual, expected[, message])#

History

VersionChanges
v16.0.0, v14.18.0
In Legacy assertion mode, changed status from Deprecated to Legacy.
v14.0.0
NaN is now treated as being identical if both sides are NaN.
v0.1.21
Added in: v0.1.21




actual <any>
expected <any>
message <string> | <Error>

Strict assertion mode
An alias of assert.notStrictEqual().
Legacy assertion mode
Stability: 3 - Legacy: Use assert.notStrictEqual() instead.
Tests shallow, coercive inequality with the != operator. NaN is
specially handled and treated as being identical if both sides are NaN.

import assert from 'node:assert';

assert.notEqual(1, 2);
// OK

assert.notEqual(1, 1);
// AssertionError: 1 != 1

assert.notEqual(1, '1');
// AssertionError: 1 != '1'const assert = require('node:assert');

assert.notEqual(1, 2);
// OK

assert.notEqual(1, 1);
// AssertionError: 1 != 1

assert.notEqual(1, '1');
// AssertionError: 1 != '1'copy
If the values are equal, an AssertionError is thrown with a message
property set equal to the value of the message parameter. If the message
parameter is undefined, a default error message is assigned. If the message
parameter is an instance of <Error> then it will be thrown instead of the
AssertionError.
assert.notStrictEqual(actual, expected[, message])#

History

VersionChanges
v10.0.0
Used comparison changed from Strict Equality to Object.is().
v0.1.21
Added in: v0.1.21




actual <any>
expected <any>
message <string> | <Error>

Tests strict inequality between the actual and expected parameters as
determined by Object.is().

import assert from 'node:assert/strict';

assert.notStrictEqual(1, 2);
// OK

assert.notStrictEqual(1, 1);
// AssertionError [ERR_ASSERTION]: Expected "actual" to be strictly unequal to:
//
// 1

assert.notStrictEqual(1, '1');
// OKconst assert = require('node:assert/strict');

assert.notStrictEqual(1, 2);
// OK

assert.notStrictEqual(1, 1);
// AssertionError [ERR_ASSERTION]: Expected "actual" to be strictly unequal to:
//
// 1

assert.notStrictEqual(1, '1');
// OKcopy
If the values are strictly equal, an AssertionError is thrown with a
message property set equal to the value of the message parameter. If the
message parameter is undefined, a default error message is assigned. If the
message parameter is an instance of <Error> then it will be thrown
instead of the AssertionError.
assert.ok(value[, message])#

History

VersionChanges
v10.0.0
The assert.ok() (no arguments) will now use a predefined error message.
v0.1.21
Added in: v0.1.21




value <any>
message <string> | <Error>

Tests if value is truthy. It is equivalent to
assert.equal(!!value, true, message).
If value is not truthy, an AssertionError is thrown with a message
property set equal to the value of the message parameter. If the message
parameter is undefined, a default error message is assigned. If the message
parameter is an instance of <Error> then it will be thrown instead of the
AssertionError.
If no arguments are passed in at all message will be set to the string:
'No value argument passed to `assert.ok()`'.
Be aware that in the repl the error message will be different to the one
thrown in a file! See below for further details.

import assert from 'node:assert/strict';

assert.ok(true);
// OK
assert.ok(1);
// OK

assert.ok();
// AssertionError: No value argument passed to `assert.ok()`

assert.ok(false, 'it\'s false');
// AssertionError: it's false

// In the repl:
assert.ok(typeof 123 === 'string');
// AssertionError: false == true

// In a file (e.g. test.js):
assert.ok(typeof 123 === 'string');
// AssertionError: The expression evaluated to a falsy value:
//
//   assert.ok(typeof 123 === 'string')

assert.ok(false);
// AssertionError: The expression evaluated to a falsy value:
//
//   assert.ok(false)

assert.ok(0);
// AssertionError: The expression evaluated to a falsy value:
//
//   assert.ok(0)const assert = require('node:assert/strict');

assert.ok(true);
// OK
assert.ok(1);
// OK

assert.ok();
// AssertionError: No value argument passed to `assert.ok()`

assert.ok(false, 'it\'s false');
// AssertionError: it's false

// In the repl:
assert.ok(typeof 123 === 'string');
// AssertionError: false == true

// In a file (e.g. test.js):
assert.ok(typeof 123 === 'string');
// AssertionError: The expression evaluated to a falsy value:
//
//   assert.ok(typeof 123 === 'string')

assert.ok(false);
// AssertionError: The expression evaluated to a falsy value:
//
//   assert.ok(false)

assert.ok(0);
// AssertionError: The expression evaluated to a falsy value:
//
//   assert.ok(0)copy

import assert from 'node:assert/strict';

// Using `assert()` works the same:
assert(0);
// AssertionError: The expression evaluated to a falsy value:
//
//   assert(0)const assert = require('node:assert');

// Using `assert()` works the same:
assert(0);
// AssertionError: The expression evaluated to a falsy value:
//
//   assert(0)copy
assert.rejects(asyncFn[, error][, message])#

Added in: v10.0.0


asyncFn <Function> | <Promise>
error <RegExp> | <Function> | <Object> | <Error>
message <string>
Returns: <Promise>

Awaits the asyncFn promise or, if asyncFn is a function, immediately
calls the function and awaits the returned promise to complete. It will then
check that the promise is rejected.
If asyncFn is a function and it throws an error synchronously,
assert.rejects() will return a rejected Promise with that error. If the
function does not return a promise, assert.rejects() will return a rejected
Promise with an ERR_INVALID_RETURN_VALUE error. In both cases the error
handler is skipped.
Besides the async nature to await the completion behaves identically to
assert.throws().
If specified, error can be a Class, <RegExp>, a validation function,
an object where each property will be tested for, or an instance of error where
each property will be tested for including the non-enumerable message and
name properties.
If specified, message will be the message provided by the AssertionError
if the asyncFn fails to reject.

import assert from 'node:assert/strict';

await assert.rejects(
  async () => {
    throw new TypeError('Wrong value');
  },
  {
    name: 'TypeError',
    message: 'Wrong value',
  },
);const assert = require('node:assert/strict');

(async () => {
  await assert.rejects(
    async () => {
      throw new TypeError('Wrong value');
    },
    {
      name: 'TypeError',
      message: 'Wrong value',
    },
  );
})();copy

import assert from 'node:assert/strict';

await assert.rejects(
  async () => {
    throw new TypeError('Wrong value');
  },
  (err) => {
    assert.strictEqual(err.name, 'TypeError');
    assert.strictEqual(err.message, 'Wrong value');
    return true;
  },
);const assert = require('node:assert/strict');

(async () => {
  await assert.rejects(
    async () => {
      throw new TypeError('Wrong value');
    },
    (err) => {
      assert.strictEqual(err.name, 'TypeError');
      assert.strictEqual(err.message, 'Wrong value');
      return true;
    },
  );
})();copy

import assert from 'node:assert/strict';

assert.rejects(
  Promise.reject(new Error('Wrong value')),
  Error,
).then(() => {
  // ...
});const assert = require('node:assert/strict');

assert.rejects(
  Promise.reject(new Error('Wrong value')),
  Error,
).then(() => {
  // ...
});copy
error cannot be a string. If a string is provided as the second
argument, then error is assumed to be omitted and the string will be used for
message instead. This can lead to easy-to-miss mistakes. Please read the
example in assert.throws() carefully if using a string as the second
argument gets considered.
assert.strictEqual(actual, expected[, message])#

History

VersionChanges
v10.0.0
Used comparison changed from Strict Equality to Object.is().
v0.1.21
Added in: v0.1.21




actual <any>
expected <any>
message <string> | <Error>

Tests strict equality between the actual and expected parameters as
determined by Object.is().

import assert from 'node:assert/strict';

assert.strictEqual(1, 2);
// AssertionError [ERR_ASSERTION]: Expected inputs to be strictly equal:
//
// 1 !== 2

assert.strictEqual(1, 1);
// OK

assert.strictEqual('Hello foobar', 'Hello World!');
// AssertionError [ERR_ASSERTION]: Expected inputs to be strictly equal:
// + actual - expected
//
// + 'Hello foobar'
// - 'Hello World!'
//          ^

const apples = 1;
const oranges = 2;
assert.strictEqual(apples, oranges, `apples ${apples} !== oranges ${oranges}`);
// AssertionError [ERR_ASSERTION]: apples 1 !== oranges 2

assert.strictEqual(1, '1', new TypeError('Inputs are not identical'));
// TypeError: Inputs are not identicalconst assert = require('node:assert/strict');

assert.strictEqual(1, 2);
// AssertionError [ERR_ASSERTION]: Expected inputs to be strictly equal:
//
// 1 !== 2

assert.strictEqual(1, 1);
// OK

assert.strictEqual('Hello foobar', 'Hello World!');
// AssertionError [ERR_ASSERTION]: Expected inputs to be strictly equal:
// + actual - expected
//
// + 'Hello foobar'
// - 'Hello World!'
//          ^

const apples = 1;
const oranges = 2;
assert.strictEqual(apples, oranges, `apples ${apples} !== oranges ${oranges}`);
// AssertionError [ERR_ASSERTION]: apples 1 !== oranges 2

assert.strictEqual(1, '1', new TypeError('Inputs are not identical'));
// TypeError: Inputs are not identicalcopy
If the values are not strictly equal, an AssertionError is thrown with a
message property set equal to the value of the message parameter. If the
message parameter is undefined, a default error message is assigned. If the
message parameter is an instance of <Error> then it will be thrown
instead of the AssertionError.
assert.throws(fn[, error][, message])#

History

VersionChanges
v10.2.0
The error parameter can be an object containing regular expressions now.
v9.9.0
The error parameter can now be an object as well.
v4.2.0
The error parameter can now be an arrow function.
v0.1.21
Added in: v0.1.21




fn <Function>
error <RegExp> | <Function> | <Object> | <Error>
message <string>

Expects the function fn to throw an error.
If specified, error can be a Class, <RegExp>, a validation function,
a validation object where each property will be tested for strict deep equality,
or an instance of error where each property will be tested for strict deep
equality including the non-enumerable message and name properties. When
using an object, it is also possible to use a regular expression, when
validating against a string property. See below for examples.
If specified, message will be appended to the message provided by the
AssertionError if the fn call fails to throw or in case the error validation
fails.
Custom validation object/error instance:

import assert from 'node:assert/strict';

const err = new TypeError('Wrong value');
err.code = 404;
err.foo = 'bar';
err.info = {
  nested: true,
  baz: 'text',
};
err.reg = /abc/i;

assert.throws(
  () => {
    throw err;
  },
  {
    name: 'TypeError',
    message: 'Wrong value',
    info: {
      nested: true,
      baz: 'text',
    },
    // Only properties on the validation object will be tested for.
    // Using nested objects requires all properties to be present. Otherwise
    // the validation is going to fail.
  },
);

// Using regular expressions to validate error properties:
assert.throws(
  () => {
    throw err;
  },
  {
    // The `name` and `message` properties are strings and using regular
    // expressions on those will match against the string. If they fail, an
    // error is thrown.
    name: /^TypeError$/,
    message: /Wrong/,
    foo: 'bar',
    info: {
      nested: true,
      // It is not possible to use regular expressions for nested properties!
      baz: 'text',
    },
    // The `reg` property contains a regular expression and only if the
    // validation object contains an identical regular expression, it is going
    // to pass.
    reg: /abc/i,
  },
);

// Fails due to the different `message` and `name` properties:
assert.throws(
  () => {
    const otherErr = new Error('Not found');
    // Copy all enumerable properties from `err` to `otherErr`.
    for (const [key, value] of Object.entries(err)) {
      otherErr[key] = value;
    }
    throw otherErr;
  },
  // The error's `message` and `name` properties will also be checked when using
  // an error as validation object.
  err,
);const assert = require('node:assert/strict');

const err = new TypeError('Wrong value');
err.code = 404;
err.foo = 'bar';
err.info = {
  nested: true,
  baz: 'text',
};
err.reg = /abc/i;

assert.throws(
  () => {
    throw err;
  },
  {
    name: 'TypeError',
    message: 'Wrong value',
    info: {
      nested: true,
      baz: 'text',
    },
    // Only properties on the validation object will be tested for.
    // Using nested objects requires all properties to be present. Otherwise
    // the validation is going to fail.
  },
);

// Using regular expressions to validate error properties:
assert.throws(
  () => {
    throw err;
  },
  {
    // The `name` and `message` properties are strings and using regular
    // expressions on those will match against the string. If they fail, an
    // error is thrown.
    name: /^TypeError$/,
    message: /Wrong/,
    foo: 'bar',
    info: {
      nested: true,
      // It is not possible to use regular expressions for nested properties!
      baz: 'text',
    },
    // The `reg` property contains a regular expression and only if the
    // validation object contains an identical regular expression, it is going
    // to pass.
    reg: /abc/i,
  },
);

// Fails due to the different `message` and `name` properties:
assert.throws(
  () => {
    const otherErr = new Error('Not found');
    // Copy all enumerable properties from `err` to `otherErr`.
    for (const [key, value] of Object.entries(err)) {
      otherErr[key] = value;
    }
    throw otherErr;
  },
  // The error's `message` and `name` properties will also be checked when using
  // an error as validation object.
  err,
);copy
Validate instanceof using constructor:

import assert from 'node:assert/strict';

assert.throws(
  () => {
    throw new Error('Wrong value');
  },
  Error,
);const assert = require('node:assert/strict');

assert.throws(
  () => {
    throw new Error('Wrong value');
  },
  Error,
);copy
Validate error message using <RegExp>:
Using a regular expression runs .toString on the error object, and will
therefore also include the error name.

import assert from 'node:assert/strict';

assert.throws(
  () => {
    throw new Error('Wrong value');
  },
  /^Error: Wrong value$/,
);const assert = require('node:assert/strict');

assert.throws(
  () => {
    throw new Error('Wrong value');
  },
  /^Error: Wrong value$/,
);copy
Custom error validation:
The function must return true to indicate all internal validations passed.
It will otherwise fail with an AssertionError.

import assert from 'node:assert/strict';

assert.throws(
  () => {
    throw new Error('Wrong value');
  },
  (err) => {
    assert(err instanceof Error);
    assert(/value/.test(err));
    // Avoid returning anything from validation functions besides `true`.
    // Otherwise, it's not clear what part of the validation failed. Instead,
    // throw an error about the specific validation that failed (as done in this
    // example) and add as much helpful debugging information to that error as
    // possible.
    return true;
  },
  'unexpected error',
);const assert = require('node:assert/strict');

assert.throws(
  () => {
    throw new Error('Wrong value');
  },
  (err) => {
    assert(err instanceof Error);
    assert(/value/.test(err));
    // Avoid returning anything from validation functions besides `true`.
    // Otherwise, it's not clear what part of the validation failed. Instead,
    // throw an error about the specific validation that failed (as done in this
    // example) and add as much helpful debugging information to that error as
    // possible.
    return true;
  },
  'unexpected error',
);copy
error cannot be a string. If a string is provided as the second
argument, then error is assumed to be omitted and the string will be used for
message instead. This can lead to easy-to-miss mistakes. Using the same
message as the thrown error message is going to result in an
ERR_AMBIGUOUS_ARGUMENT error. Please read the example below carefully if using
a string as the second argument gets considered:

import assert from 'node:assert/strict';

function throwingFirst() {
  throw new Error('First');
}

function throwingSecond() {
  throw new Error('Second');
}

function notThrowing() {}

// The second argument is a string and the input function threw an Error.
// The first case will not throw as it does not match for the error message
// thrown by the input function!
assert.throws(throwingFirst, 'Second');
// In the next example the message has no benefit over the message from the
// error and since it is not clear if the user intended to actually match
// against the error message, Node.js throws an `ERR_AMBIGUOUS_ARGUMENT` error.
assert.throws(throwingSecond, 'Second');
// TypeError [ERR_AMBIGUOUS_ARGUMENT]

// The string is only used (as message) in case the function does not throw:
assert.throws(notThrowing, 'Second');
// AssertionError [ERR_ASSERTION]: Missing expected exception: Second

// If it was intended to match for the error message do this instead:
// It does not throw because the error messages match.
assert.throws(throwingSecond, /Second$/);

// If the error message does not match, an AssertionError is thrown.
assert.throws(throwingFirst, /Second$/);
// AssertionError [ERR_ASSERTION]const assert = require('node:assert/strict');

function throwingFirst() {
  throw new Error('First');
}

function throwingSecond() {
  throw new Error('Second');
}

function notThrowing() {}

// The second argument is a string and the input function threw an Error.
// The first case will not throw as it does not match for the error message
// thrown by the input function!
assert.throws(throwingFirst, 'Second');
// In the next example the message has no benefit over the message from the
// error and since it is not clear if the user intended to actually match
// against the error message, Node.js throws an `ERR_AMBIGUOUS_ARGUMENT` error.
assert.throws(throwingSecond, 'Second');
// TypeError [ERR_AMBIGUOUS_ARGUMENT]

// The string is only used (as message) in case the function does not throw:
assert.throws(notThrowing, 'Second');
// AssertionError [ERR_ASSERTION]: Missing expected exception: Second

// If it was intended to match for the error message do this instead:
// It does not throw because the error messages match.
assert.throws(throwingSecond, /Second$/);

// If the error message does not match, an AssertionError is thrown.
assert.throws(throwingFirst, /Second$/);
// AssertionError [ERR_ASSERTION]copy
Due to the confusing error-prone notation, avoid a string as the second
argument.
assert.partialDeepStrictEqual(actual, expected[, message])#

History

VersionChanges
v24.0.0
partialDeepStrictEqual is now Stable. Previously, it had been Experimental.
v23.4.0, v22.13.0
Added in: v23.4.0, v22.13.0




actual <any>
expected <any>
message <string> | <Error>

Tests for partial deep equality between the actual and expected parameters.
"Deep" equality means that the enumerable "own" properties of child objects
are recursively evaluated also by the following rules. "Partial" equality means
that only properties that exist on the expected parameter are going to be
compared.
This method always passes the same test cases as assert.deepStrictEqual(),
behaving as a super set of it.

Comparison details#

Primitive values are compared using Object.is().
Type tags of objects should be the same.
[[Prototype]] of objects are not compared.
Only enumerable "own" properties are considered.
<Error> names, messages, causes, and errors are always compared,
even if these are not enumerable properties.
errors is also compared.
Enumerable own <Symbol> properties are compared as well.
Object wrappers are compared both as objects and unwrapped values.
Object properties are compared unordered.
<Map> keys and <Set> items are compared unordered.
Recursion stops when both sides differ or both sides encounter a circular
reference.
<WeakMap> and <WeakSet> instances are not compared structurally.
They are only equal if they reference the same object. Any comparison between
different WeakMap or WeakSet instances will result in inequality,
even if they contain the same entries.
<RegExp> lastIndex, flags, and source are always compared, even if these
are not enumerable properties.
Holes in sparse arrays are ignored.


import assert from 'node:assert';

assert.partialDeepStrictEqual(
  { a: { b: { c: 1 } } },
  { a: { b: { c: 1 } } },
);
// OK

assert.partialDeepStrictEqual(
  { a: 1, b: 2, c: 3 },
  { b: 2 },
);
// OK

assert.partialDeepStrictEqual(
  [1, 2, 3, 4, 5, 6, 7, 8, 9],
  [4, 5, 8],
);
// OK

assert.partialDeepStrictEqual(
  new Set([{ a: 1 }, { b: 1 }]),
  new Set([{ a: 1 }]),
);
// OK

assert.partialDeepStrictEqual(
  new Map([['key1', 'value1'], ['key2', 'value2']]),
  new Map([['key2', 'value2']]),
);
// OK

assert.partialDeepStrictEqual(123n, 123n);
// OK

assert.partialDeepStrictEqual(
  [1, 2, 3, 4, 5, 6, 7, 8, 9],
  [5, 4, 8],
);
// AssertionError

assert.partialDeepStrictEqual(
  { a: 1 },
  { a: 1, b: 2 },
);
// AssertionError

assert.partialDeepStrictEqual(
  { a: { b: 2 } },
  { a: { b: '2' } },
);
// AssertionErrorconst assert = require('node:assert');

assert.partialDeepStrictEqual(
  { a: { b: { c: 1 } } },
  { a: { b: { c: 1 } } },
);
// OK

assert.partialDeepStrictEqual(
  { a: 1, b: 2, c: 3 },
  { b: 2 },
);
// OK

assert.partialDeepStrictEqual(
  [1, 2, 3, 4, 5, 6, 7, 8, 9],
  [4, 5, 8],
);
// OK

assert.partialDeepStrictEqual(
  new Set([{ a: 1 }, { b: 1 }]),
  new Set([{ a: 1 }]),
);
// OK

assert.partialDeepStrictEqual(
  new Map([['key1', 'value1'], ['key2', 'value2']]),
  new Map([['key2', 'value2']]),
);
// OK

assert.partialDeepStrictEqual(123n, 123n);
// OK

assert.partialDeepStrictEqual(
  [1, 2, 3, 4, 5, 6, 7, 8, 9],
  [5, 4, 8],
);
// AssertionError

assert.partialDeepStrictEqual(
  { a: 1 },
  { a: 1, b: 2 },
);
// AssertionError

assert.partialDeepStrictEqual(
  { a: { b: 2 } },
  { a: { b: '2' } },
);
// AssertionErrorcopy\n\n\n\nNode.js
        
      
      
About this documentation
Usage and example



Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Modules: TypeScript
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
Readline
REPL
Report
Single executable applications
SQLite
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker

    

    
      
        
          Node.js v24.0.1 documentation
          
            
            
          
        
        
          
            Node.js v24.0.1
            
    
      
        
        Table of contents
      

      
Asynchronous context tracking

Introduction
Class: AsyncLocalStorage

new AsyncLocalStorage([options])
Static method: AsyncLocalStorage.bind(fn)
Static method: AsyncLocalStorage.snapshot()
asyncLocalStorage.disable()
asyncLocalStorage.getStore()
asyncLocalStorage.enterWith(store)
asyncLocalStorage.name
asyncLocalStorage.run(store, callback[, ...args])
asyncLocalStorage.exit(callback[, ...args])
Usage with async/await
Troubleshooting: Context loss


Class: AsyncResource

new AsyncResource(type[, options])
Static method: AsyncResource.bind(fn[, type[, thisArg]])
asyncResource.bind(fn[, thisArg])
asyncResource.runInAsyncScope(fn[, thisArg, ...args])
asyncResource.emitDestroy()
asyncResource.asyncId()
asyncResource.triggerAsyncId()
Using AsyncResource for a Worker thread pool
Integrating AsyncResource with EventEmitter





    
  
            
    
      
        
        Index
      

      
About this documentation
Usage and example

      
        Index
      
    
  


Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Modules: TypeScript
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
Readline
REPL
Report
Single executable applications
SQLite
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker

    
  
            
    
      
        
        Other versions
      
      24.x
23.x
22.x LTS
21.x
20.x LTS
19.x
18.x
17.x
16.x
    
  
            
              
                
                Options
              
        
              
                
                  
                    View on single page
                  
                  
                    View as JSON
                  
                  Edit on GitHub    
                
              
            
          
        
        
      

      Table of contents
Asynchronous context tracking

Introduction
Class: AsyncLocalStorage

new AsyncLocalStorage([options])
Static method: AsyncLocalStorage.bind(fn)
Static method: AsyncLocalStorage.snapshot()
asyncLocalStorage.disable()
asyncLocalStorage.getStore()
asyncLocalStorage.enterWith(store)
asyncLocalStorage.name
asyncLocalStorage.run(store, callback[, ...args])
asyncLocalStorage.exit(callback[, ...args])
Usage with async/await
Troubleshooting: Context loss


Class: AsyncResource

new AsyncResource(type[, options])
Static method: AsyncResource.bind(fn[, type[, thisArg]])
asyncResource.bind(fn[, thisArg])
asyncResource.runInAsyncScope(fn[, thisArg, ...args])
asyncResource.emitDestroy()
asyncResource.asyncId()
asyncResource.triggerAsyncId()
Using AsyncResource for a Worker thread pool
Integrating AsyncResource with EventEmitter






      
        Asynchronous context tracking#

Stability: 2 - Stable
Source Code: lib/async_hooks.js
Introduction#
These classes are used to associate state and propagate it throughout
callbacks and promise chains.
They allow storing data throughout the lifetime of a web request
or any other asynchronous duration. It is similar to thread-local storage
in other languages.
The AsyncLocalStorage and AsyncResource classes are part of the
node:async_hooks module:

import { AsyncLocalStorage, AsyncResource } from 'node:async_hooks';const { AsyncLocalStorage, AsyncResource } = require('node:async_hooks');copy
Class: AsyncLocalStorage#

History

VersionChanges
v16.4.0
AsyncLocalStorage is now Stable. Previously, it had been Experimental.
v13.10.0, v12.17.0
Added in: v13.10.0, v12.17.0



This class creates stores that stay coherent through asynchronous operations.
While you can create your own implementation on top of the node:async_hooks
module, AsyncLocalStorage should be preferred as it is a performant and memory
safe implementation that involves significant optimizations that are non-obvious
to implement.
The following example uses AsyncLocalStorage to build a simple logger
that assigns IDs to incoming HTTP requests and includes them in messages
logged within each request.

import http from 'node:http';
import { AsyncLocalStorage } from 'node:async_hooks';

const asyncLocalStorage = new AsyncLocalStorage();

function logWithId(msg) {
  const id = asyncLocalStorage.getStore();
  console.log(`${id !== undefined ? id : '-'}:`, msg);
}

let idSeq = 0;
http.createServer((req, res) => {
  asyncLocalStorage.run(idSeq++, () => {
    logWithId('start');
    // Imagine any chain of async operations here
    setImmediate(() => {
      logWithId('finish');
      res.end();
    });
  });
}).listen(8080);

http.get('http://localhost:8080');
http.get('http://localhost:8080');
// Prints:
//   0: start
//   0: finish
//   1: start
//   1: finishconst http = require('node:http');
const { AsyncLocalStorage } = require('node:async_hooks');

const asyncLocalStorage = new AsyncLocalStorage();

function logWithId(msg) {
  const id = asyncLocalStorage.getStore();
  console.log(`${id !== undefined ? id : '-'}:`, msg);
}

let idSeq = 0;
http.createServer((req, res) => {
  asyncLocalStorage.run(idSeq++, () => {
    logWithId('start');
    // Imagine any chain of async operations here
    setImmediate(() => {
      logWithId('finish');
      res.end();
    });
  });
}).listen(8080);

http.get('http://localhost:8080');
http.get('http://localhost:8080');
// Prints:
//   0: start
//   0: finish
//   1: start
//   1: finishcopy
Each instance of AsyncLocalStorage maintains an independent storage context.
Multiple instances can safely exist simultaneously without risk of interfering
with each other's data.

new AsyncLocalStorage([options])#

History

VersionChanges
v24.0.0
Add defaultValue and name options.
v19.7.0, v18.16.0
Removed experimental onPropagate option.
v19.2.0, v18.13.0
Add option onPropagate.
v13.10.0, v12.17.0
Added in: v13.10.0, v12.17.0




options <Object>

defaultValue <any> The default value to be used when no store is provided.
name <string> A name for the AsyncLocalStorage value.



Creates a new instance of AsyncLocalStorage. Store is only provided within a
run() call or after an enterWith() call.

Static method: AsyncLocalStorage.bind(fn)#

History

VersionChanges
v23.11.0, v22.15.0
Marking the API stable.
v19.8.0, v18.16.0
Added in: v19.8.0, v18.16.0




fn <Function> The function to bind to the current execution context.
Returns: <Function> A new function that calls fn within the captured
execution context.

Binds the given function to the current execution context.

Static method: AsyncLocalStorage.snapshot()#

History

VersionChanges
v23.11.0, v22.15.0
Marking the API stable.
v19.8.0, v18.16.0
Added in: v19.8.0, v18.16.0




Returns: <Function> A new function with the signature
(fn: (...args) : R, ...args) : R.

Captures the current execution context and returns a function that accepts a
function as an argument. Whenever the returned function is called, it
calls the function passed to it within the captured context.
const asyncLocalStorage = new AsyncLocalStorage();
const runInAsyncScope = asyncLocalStorage.run(123, () => AsyncLocalStorage.snapshot());
const result = asyncLocalStorage.run(321, () => runInAsyncScope(() => asyncLocalStorage.getStore()));
console.log(result);  // returns 123 copy
AsyncLocalStorage.snapshot() can replace the use of AsyncResource for simple
async context tracking purposes, for example:
class Foo {
  #runInAsyncScope = AsyncLocalStorage.snapshot();

  get() { return this.#runInAsyncScope(() => asyncLocalStorage.getStore()); }
}

const foo = asyncLocalStorage.run(123, () => new Foo());
console.log(asyncLocalStorage.run(321, () => foo.get())); // returns 123 copy

asyncLocalStorage.disable()#

Added in: v13.10.0, v12.17.0

Stability: 1 - Experimental
Disables the instance of AsyncLocalStorage. All subsequent calls
to asyncLocalStorage.getStore() will return undefined until
asyncLocalStorage.run() or asyncLocalStorage.enterWith() is called again.
When calling asyncLocalStorage.disable(), all current contexts linked to the
instance will be exited.
Calling asyncLocalStorage.disable() is required before the
asyncLocalStorage can be garbage collected. This does not apply to stores
provided by the asyncLocalStorage, as those objects are garbage collected
along with the corresponding async resources.
Use this method when the asyncLocalStorage is not in use anymore
in the current process.

asyncLocalStorage.getStore()#

Added in: v13.10.0, v12.17.0


Returns: <any>

Returns the current store.
If called outside of an asynchronous context initialized by
calling asyncLocalStorage.run() or asyncLocalStorage.enterWith(), it
returns undefined.

asyncLocalStorage.enterWith(store)#

Added in: v13.11.0, v12.17.0

Stability: 1 - Experimental

store <any>

Transitions into the context for the remainder of the current
synchronous execution and then persists the store through any following
asynchronous calls.
Example:
const store = { id: 1 };
// Replaces previous store with the given store object
asyncLocalStorage.enterWith(store);
asyncLocalStorage.getStore(); // Returns the store object
someAsyncOperation(() => {
  asyncLocalStorage.getStore(); // Returns the same object
}); copy
This transition will continue for the entire synchronous execution.
This means that if, for example, the context is entered within an event
handler subsequent event handlers will also run within that context unless
specifically bound to another context with an AsyncResource. That is why
run() should be preferred over enterWith() unless there are strong reasons
to use the latter method.
const store = { id: 1 };

emitter.on('my-event', () => {
  asyncLocalStorage.enterWith(store);
});
emitter.on('my-event', () => {
  asyncLocalStorage.getStore(); // Returns the same object
});

asyncLocalStorage.getStore(); // Returns undefined
emitter.emit('my-event');
asyncLocalStorage.getStore(); // Returns the same object copy

asyncLocalStorage.name#

Added in: v24.0.0


<string>

The name of the AsyncLocalStorage instance if provided.

asyncLocalStorage.run(store, callback[, ...args])#

Added in: v13.10.0, v12.17.0


store <any>
callback <Function>
...args <any>

Runs a function synchronously within a context and returns its
return value. The store is not accessible outside of the callback function.
The store is accessible to any asynchronous operations created within the
callback.
The optional args are passed to the callback function.
If the callback function throws an error, the error is thrown by run() too.
The stacktrace is not impacted by this call and the context is exited.
Example:
const store = { id: 2 };
try {
  asyncLocalStorage.run(store, () => {
    asyncLocalStorage.getStore(); // Returns the store object
    setTimeout(() => {
      asyncLocalStorage.getStore(); // Returns the store object
    }, 200);
    throw new Error();
  });
} catch (e) {
  asyncLocalStorage.getStore(); // Returns undefined
  // The error will be caught here
} copy

asyncLocalStorage.exit(callback[, ...args])#

Added in: v13.10.0, v12.17.0

Stability: 1 - Experimental

callback <Function>
...args <any>

Runs a function synchronously outside of a context and returns its
return value. The store is not accessible within the callback function or
the asynchronous operations created within the callback. Any getStore()
call done within the callback function will always return undefined.
The optional args are passed to the callback function.
If the callback function throws an error, the error is thrown by exit() too.
The stacktrace is not impacted by this call and the context is re-entered.
Example:
// Within a call to run
try {
  asyncLocalStorage.getStore(); // Returns the store object or value
  asyncLocalStorage.exit(() => {
    asyncLocalStorage.getStore(); // Returns undefined
    throw new Error();
  });
} catch (e) {
  asyncLocalStorage.getStore(); // Returns the same object or value
  // The error will be caught here
} copy

Usage with async/await#
If, within an async function, only one await call is to run within a context,
the following pattern should be used:
async function fn() {
  await asyncLocalStorage.run(new Map(), () => {
    asyncLocalStorage.getStore().set('key', value);
    return foo(); // The return value of foo will be awaited
  });
} copy
In this example, the store is only available in the callback function and the
functions called by foo. Outside of run, calling getStore will return
undefined.

Troubleshooting: Context loss#
In most cases, AsyncLocalStorage works without issues. In rare situations, the
current store is lost in one of the asynchronous operations.
If your code is callback-based, it is enough to promisify it with
util.promisify() so it starts working with native promises.
If you need to use a callback-based API or your code assumes
a custom thenable implementation, use the AsyncResource class
to associate the asynchronous operation with the correct execution context.
Find the function call responsible for the context loss by logging the content
of asyncLocalStorage.getStore() after the calls you suspect are responsible
for the loss. When the code logs undefined, the last callback called is
probably responsible for the context loss.

Class: AsyncResource#

History

VersionChanges
v16.4.0
AsyncResource is now Stable. Previously, it had been Experimental.



The class AsyncResource is designed to be extended by the embedder's async
resources. Using this, users can easily trigger the lifetime events of their
own resources.
The init hook will trigger when an AsyncResource is instantiated.
The following is an overview of the AsyncResource API.

import { AsyncResource, executionAsyncId } from 'node:async_hooks';

// AsyncResource() is meant to be extended. Instantiating a
// new AsyncResource() also triggers init. If triggerAsyncId is omitted then
// async_hook.executionAsyncId() is used.
const asyncResource = new AsyncResource(
  type, { triggerAsyncId: executionAsyncId(), requireManualDestroy: false },
);

// Run a function in the execution context of the resource. This will
// * establish the context of the resource
// * trigger the AsyncHooks before callbacks
// * call the provided function `fn` with the supplied arguments
// * trigger the AsyncHooks after callbacks
// * restore the original execution context
asyncResource.runInAsyncScope(fn, thisArg, ...args);

// Call AsyncHooks destroy callbacks.
asyncResource.emitDestroy();

// Return the unique ID assigned to the AsyncResource instance.
asyncResource.asyncId();

// Return the trigger ID for the AsyncResource instance.
asyncResource.triggerAsyncId();const { AsyncResource, executionAsyncId } = require('node:async_hooks');

// AsyncResource() is meant to be extended. Instantiating a
// new AsyncResource() also triggers init. If triggerAsyncId is omitted then
// async_hook.executionAsyncId() is used.
const asyncResource = new AsyncResource(
  type, { triggerAsyncId: executionAsyncId(), requireManualDestroy: false },
);

// Run a function in the execution context of the resource. This will
// * establish the context of the resource
// * trigger the AsyncHooks before callbacks
// * call the provided function `fn` with the supplied arguments
// * trigger the AsyncHooks after callbacks
// * restore the original execution context
asyncResource.runInAsyncScope(fn, thisArg, ...args);

// Call AsyncHooks destroy callbacks.
asyncResource.emitDestroy();

// Return the unique ID assigned to the AsyncResource instance.
asyncResource.asyncId();

// Return the trigger ID for the AsyncResource instance.
asyncResource.triggerAsyncId();copy

new AsyncResource(type[, options])#

type <string> The type of async event.
options <Object>

triggerAsyncId <number> The ID of the execution context that created this
async event. Default: executionAsyncId().
requireManualDestroy <boolean> If set to true, disables emitDestroy
when the object is garbage collected. This usually does not need to be set
(even if emitDestroy is called manually), unless the resource's asyncId
is retrieved and the sensitive API's emitDestroy is called with it.
When set to false, the emitDestroy call on garbage collection
will only take place if there is at least one active destroy hook.
Default: false.



Example usage:
class DBQuery extends AsyncResource {
  constructor(db) {
    super('DBQuery');
    this.db = db;
  }

  getInfo(query, callback) {
    this.db.get(query, (err, data) => {
      this.runInAsyncScope(callback, null, err, data);
    });
  }

  close() {
    this.db = null;
    this.emitDestroy();
  }
} copy

Static method: AsyncResource.bind(fn[, type[, thisArg]])#

History

VersionChanges
v20.0.0
The asyncResource property added to the bound function has been deprecated and will be removed in a future version.
v17.8.0, v16.15.0
Changed the default when thisArg is undefined to use this from the caller.
v16.0.0
Added optional thisArg.
v14.8.0, v12.19.0
Added in: v14.8.0, v12.19.0




fn <Function> The function to bind to the current execution context.
type <string> An optional name to associate with the underlying
AsyncResource.
thisArg <any>

Binds the given function to the current execution context.

asyncResource.bind(fn[, thisArg])#

History

VersionChanges
v20.0.0
The asyncResource property added to the bound function has been deprecated and will be removed in a future version.
v17.8.0, v16.15.0
Changed the default when thisArg is undefined to use this from the caller.
v16.0.0
Added optional thisArg.
v14.8.0, v12.19.0
Added in: v14.8.0, v12.19.0




fn <Function> The function to bind to the current AsyncResource.
thisArg <any>

Binds the given function to execute to this AsyncResource's scope.

asyncResource.runInAsyncScope(fn[, thisArg, ...args])#

Added in: v9.6.0


fn <Function> The function to call in the execution context of this async
resource.
thisArg <any> The receiver to be used for the function call.
...args <any> Optional arguments to pass to the function.

Call the provided function with the provided arguments in the execution context
of the async resource. This will establish the context, trigger the AsyncHooks
before callbacks, call the function, trigger the AsyncHooks after callbacks, and
then restore the original execution context.

asyncResource.emitDestroy()#

Returns: <AsyncResource> A reference to asyncResource.

Call all destroy hooks. This should only ever be called once. An error will
be thrown if it is called more than once. This must be manually called. If
the resource is left to be collected by the GC then the destroy hooks will
never be called.

asyncResource.asyncId()#

Returns: <number> The unique asyncId assigned to the resource.


asyncResource.triggerAsyncId()#

Returns: <number> The same triggerAsyncId that is passed to the
AsyncResource constructor.



Using AsyncResource for a Worker thread pool#
The following example shows how to use the AsyncResource class to properly
provide async tracking for a Worker pool. Other resource pools, such as
database connection pools, can follow a similar model.
Assuming that the task is adding two numbers, using a file named
task_processor.js with the following content:

import { parentPort } from 'node:worker_threads';
parentPort.on('message', (task) => {
  parentPort.postMessage(task.a + task.b);
});const { parentPort } = require('node:worker_threads');
parentPort.on('message', (task) => {
  parentPort.postMessage(task.a + task.b);
});copy
a Worker pool around it could use the following structure:

import { AsyncResource } from 'node:async_hooks';
import { EventEmitter } from 'node:events';
import { Worker } from 'node:worker_threads';

const kTaskInfo = Symbol('kTaskInfo');
const kWorkerFreedEvent = Symbol('kWorkerFreedEvent');

class WorkerPoolTaskInfo extends AsyncResource {
  constructor(callback) {
    super('WorkerPoolTaskInfo');
    this.callback = callback;
  }

  done(err, result) {
    this.runInAsyncScope(this.callback, null, err, result);
    this.emitDestroy();  // `TaskInfo`s are used only once.
  }
}

export default class WorkerPool extends EventEmitter {
  constructor(numThreads) {
    super();
    this.numThreads = numThreads;
    this.workers = [];
    this.freeWorkers = [];
    this.tasks = [];

    for (let i = 0; i < numThreads; i++)
      this.addNewWorker();

    // Any time the kWorkerFreedEvent is emitted, dispatch
    // the next task pending in the queue, if any.
    this.on(kWorkerFreedEvent, () => {
      if (this.tasks.length > 0) {
        const { task, callback } = this.tasks.shift();
        this.runTask(task, callback);
      }
    });
  }

  addNewWorker() {
    const worker = new Worker(new URL('task_processor.js', import.meta.url));
    worker.on('message', (result) => {
      // In case of success: Call the callback that was passed to `runTask`,
      // remove the `TaskInfo` associated with the Worker, and mark it as free
      // again.
      worker[kTaskInfo].done(null, result);
      worker[kTaskInfo] = null;
      this.freeWorkers.push(worker);
      this.emit(kWorkerFreedEvent);
    });
    worker.on('error', (err) => {
      // In case of an uncaught exception: Call the callback that was passed to
      // `runTask` with the error.
      if (worker[kTaskInfo])
        worker[kTaskInfo].done(err, null);
      else
        this.emit('error', err);
      // Remove the worker from the list and start a new Worker to replace the
      // current one.
      this.workers.splice(this.workers.indexOf(worker), 1);
      this.addNewWorker();
    });
    this.workers.push(worker);
    this.freeWorkers.push(worker);
    this.emit(kWorkerFreedEvent);
  }

  runTask(task, callback) {
    if (this.freeWorkers.length === 0) {
      // No free threads, wait until a worker thread becomes free.
      this.tasks.push({ task, callback });
      return;
    }

    const worker = this.freeWorkers.pop();
    worker[kTaskInfo] = new WorkerPoolTaskInfo(callback);
    worker.postMessage(task);
  }

  close() {
    for (const worker of this.workers) worker.terminate();
  }
}const { AsyncResource } = require('node:async_hooks');
const { EventEmitter } = require('node:events');
const path = require('node:path');
const { Worker } = require('node:worker_threads');

const kTaskInfo = Symbol('kTaskInfo');
const kWorkerFreedEvent = Symbol('kWorkerFreedEvent');

class WorkerPoolTaskInfo extends AsyncResource {
  constructor(callback) {
    super('WorkerPoolTaskInfo');
    this.callback = callback;
  }

  done(err, result) {
    this.runInAsyncScope(this.callback, null, err, result);
    this.emitDestroy();  // `TaskInfo`s are used only once.
  }
}

class WorkerPool extends EventEmitter {
  constructor(numThreads) {
    super();
    this.numThreads = numThreads;
    this.workers = [];
    this.freeWorkers = [];
    this.tasks = [];

    for (let i = 0; i < numThreads; i++)
      this.addNewWorker();

    // Any time the kWorkerFreedEvent is emitted, dispatch
    // the next task pending in the queue, if any.
    this.on(kWorkerFreedEvent, () => {
      if (this.tasks.length > 0) {
        const { task, callback } = this.tasks.shift();
        this.runTask(task, callback);
      }
    });
  }

  addNewWorker() {
    const worker = new Worker(path.resolve(__dirname, 'task_processor.js'));
    worker.on('message', (result) => {
      // In case of success: Call the callback that was passed to `runTask`,
      // remove the `TaskInfo` associated with the Worker, and mark it as free
      // again.
      worker[kTaskInfo].done(null, result);
      worker[kTaskInfo] = null;
      this.freeWorkers.push(worker);
      this.emit(kWorkerFreedEvent);
    });
    worker.on('error', (err) => {
      // In case of an uncaught exception: Call the callback that was passed to
      // `runTask` with the error.
      if (worker[kTaskInfo])
        worker[kTaskInfo].done(err, null);
      else
        this.emit('error', err);
      // Remove the worker from the list and start a new Worker to replace the
      // current one.
      this.workers.splice(this.workers.indexOf(worker), 1);
      this.addNewWorker();
    });
    this.workers.push(worker);
    this.freeWorkers.push(worker);
    this.emit(kWorkerFreedEvent);
  }

  runTask(task, callback) {
    if (this.freeWorkers.length === 0) {
      // No free threads, wait until a worker thread becomes free.
      this.tasks.push({ task, callback });
      return;
    }

    const worker = this.freeWorkers.pop();
    worker[kTaskInfo] = new WorkerPoolTaskInfo(callback);
    worker.postMessage(task);
  }

  close() {
    for (const worker of this.workers) worker.terminate();
  }
}

module.exports = WorkerPool;copy
Without the explicit tracking added by the WorkerPoolTaskInfo objects,
it would appear that the callbacks are associated with the individual Worker
objects. However, the creation of the Workers is not associated with the
creation of the tasks and does not provide information about when tasks
were scheduled.
This pool could be used as follows:

import WorkerPool from './worker_pool.js';
import os from 'node:os';

const pool = new WorkerPool(os.availableParallelism());

let finished = 0;
for (let i = 0; i < 10; i++) {
  pool.runTask({ a: 42, b: 100 }, (err, result) => {
    console.log(i, err, result);
    if (++finished === 10)
      pool.close();
  });
}const WorkerPool = require('./worker_pool.js');
const os = require('node:os');

const pool = new WorkerPool(os.availableParallelism());

let finished = 0;
for (let i = 0; i < 10; i++) {
  pool.runTask({ a: 42, b: 100 }, (err, result) => {
    console.log(i, err, result);
    if (++finished === 10)
      pool.close();
  });
}copy

Integrating AsyncResource with EventEmitter#
Event listeners triggered by an EventEmitter may be run in a different
execution context than the one that was active when eventEmitter.on() was
called.
The following example shows how to use the AsyncResource class to properly
associate an event listener with the correct execution context. The same
approach can be applied to a Stream or a similar event-driven class.

import { createServer } from 'node:http';
import { AsyncResource, executionAsyncId } from 'node:async_hooks';

const server = createServer((req, res) => {
  req.on('close', AsyncResource.bind(() => {
    // Execution context is bound to the current outer scope.
  }));
  req.on('close', () => {
    // Execution context is bound to the scope that caused 'close' to emit.
  });
  res.end();
}).listen(3000);const { createServer } = require('node:http');
const { AsyncResource, executionAsyncId } = require('node:async_hooks');

const server = createServer((req, res) => {
  req.on('close', AsyncResource.bind(() => {
    // Execution context is bound to the current outer scope.
  }));
  req.on('close', () => {
    // Execution context is bound to the scope that caused 'close' to emit.
  });
  res.end();
}).listen(3000);copy\n\n\n\nNode.js
        
      
      
About this documentation
Usage and example



Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Modules: TypeScript
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
Readline
REPL
Report
Single executable applications
SQLite
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker

    

    
      
        
          Node.js v24.0.1 documentation
          
            
            
          
        
        
          
            Node.js v24.0.1
            
    
      
        
        Table of contents
      

      
Async hooks

Terminology
Overview
async_hooks.createHook(callbacks)

Error handling
Printing in AsyncHook callbacks


Class: AsyncHook

asyncHook.enable()
asyncHook.disable()
Hook callbacks

init(asyncId, type, triggerAsyncId, resource)

type
triggerAsyncId
resource
Asynchronous context example


before(asyncId)
after(asyncId)
destroy(asyncId)
promiseResolve(asyncId)


async_hooks.executionAsyncResource()
async_hooks.executionAsyncId()
async_hooks.triggerAsyncId()
async_hooks.asyncWrapProviders


Promise execution tracking
JavaScript embedder API

Class: AsyncResource


Class: AsyncLocalStorage



    
  
            
    
      
        
        Index
      

      
About this documentation
Usage and example

      
        Index
      
    
  


Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Modules: TypeScript
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
Readline
REPL
Report
Single executable applications
SQLite
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker

    
  
            
    
      
        
        Other versions
      
      24.x
23.x
22.x LTS
21.x
20.x LTS
19.x
18.x
17.x
16.x
15.x
14.x
13.x
12.x
11.x
10.x
9.x
8.x
    
  
            
              
                
                Options
              
        
              
                
                  
                    View on single page
                  
                  
                    View as JSON
                  
                  Edit on GitHub    
                
              
            
          
        
        
      

      Table of contents
Async hooks

Terminology
Overview
async_hooks.createHook(callbacks)

Error handling
Printing in AsyncHook callbacks


Class: AsyncHook

asyncHook.enable()
asyncHook.disable()
Hook callbacks

init(asyncId, type, triggerAsyncId, resource)

type
triggerAsyncId
resource
Asynchronous context example


before(asyncId)
after(asyncId)
destroy(asyncId)
promiseResolve(asyncId)


async_hooks.executionAsyncResource()
async_hooks.executionAsyncId()
async_hooks.triggerAsyncId()
async_hooks.asyncWrapProviders


Promise execution tracking
JavaScript embedder API

Class: AsyncResource


Class: AsyncLocalStorage




      
        Async hooks#

Stability: 1 - Experimental. Please migrate away from this API, if you can.
We do not recommend using the createHook, AsyncHook, and
executionAsyncResource APIs as they have usability issues, safety risks,
and performance implications. Async context tracking use cases are better
served by the stable AsyncLocalStorage API. If you have a use case for
createHook, AsyncHook, or executionAsyncResource beyond the context
tracking need solved by AsyncLocalStorage or diagnostics data currently
provided by Diagnostics Channel, please open an issue at
https://github.com/nodejs/node/issues describing your use case so we can
create a more purpose-focused API.
Source Code: lib/async_hooks.js
We strongly discourage the use of the async_hooks API.
Other APIs that can cover most of its use cases include:

AsyncLocalStorage tracks async context
process.getActiveResourcesInfo() tracks active resources

The node:async_hooks module provides an API to track asynchronous resources.
It can be accessed using:

import async_hooks from 'node:async_hooks';const async_hooks = require('node:async_hooks');copy
Terminology#
An asynchronous resource represents an object with an associated callback.
This callback may be called multiple times, such as the 'connection'
event in net.createServer(), or just a single time like in fs.open().
A resource can also be closed before the callback is called. AsyncHook does
not explicitly distinguish between these different cases but will represent them
as the abstract concept that is a resource.
If Workers are used, each thread has an independent async_hooks
interface, and each thread will use a new set of async IDs.
Overview#
Following is a simple overview of the public API.

import async_hooks from 'node:async_hooks';

// Return the ID of the current execution context.
const eid = async_hooks.executionAsyncId();

// Return the ID of the handle responsible for triggering the callback of the
// current execution scope to call.
const tid = async_hooks.triggerAsyncId();

// Create a new AsyncHook instance. All of these callbacks are optional.
const asyncHook =
    async_hooks.createHook({ init, before, after, destroy, promiseResolve });

// Allow callbacks of this AsyncHook instance to call. This is not an implicit
// action after running the constructor, and must be explicitly run to begin
// executing callbacks.
asyncHook.enable();

// Disable listening for new asynchronous events.
asyncHook.disable();

//
// The following are the callbacks that can be passed to createHook().
//

// init() is called during object construction. The resource may not have
// completed construction when this callback runs. Therefore, all fields of the
// resource referenced by "asyncId" may not have been populated.
function init(asyncId, type, triggerAsyncId, resource) { }

// before() is called just before the resource's callback is called. It can be
// called 0-N times for handles (such as TCPWrap), and will be called exactly 1
// time for requests (such as FSReqCallback).
function before(asyncId) { }

// after() is called just after the resource's callback has finished.
function after(asyncId) { }

// destroy() is called when the resource is destroyed.
function destroy(asyncId) { }

// promiseResolve() is called only for promise resources, when the
// resolve() function passed to the Promise constructor is invoked
// (either directly or through other means of resolving a promise).
function promiseResolve(asyncId) { }const async_hooks = require('node:async_hooks');

// Return the ID of the current execution context.
const eid = async_hooks.executionAsyncId();

// Return the ID of the handle responsible for triggering the callback of the
// current execution scope to call.
const tid = async_hooks.triggerAsyncId();

// Create a new AsyncHook instance. All of these callbacks are optional.
const asyncHook =
    async_hooks.createHook({ init, before, after, destroy, promiseResolve });

// Allow callbacks of this AsyncHook instance to call. This is not an implicit
// action after running the constructor, and must be explicitly run to begin
// executing callbacks.
asyncHook.enable();

// Disable listening for new asynchronous events.
asyncHook.disable();

//
// The following are the callbacks that can be passed to createHook().
//

// init() is called during object construction. The resource may not have
// completed construction when this callback runs. Therefore, all fields of the
// resource referenced by "asyncId" may not have been populated.
function init(asyncId, type, triggerAsyncId, resource) { }

// before() is called just before the resource's callback is called. It can be
// called 0-N times for handles (such as TCPWrap), and will be called exactly 1
// time for requests (such as FSReqCallback).
function before(asyncId) { }

// after() is called just after the resource's callback has finished.
function after(asyncId) { }

// destroy() is called when the resource is destroyed.
function destroy(asyncId) { }

// promiseResolve() is called only for promise resources, when the
// resolve() function passed to the Promise constructor is invoked
// (either directly or through other means of resolving a promise).
function promiseResolve(asyncId) { }copy
async_hooks.createHook(callbacks)#

Added in: v8.1.0


callbacks <Object> The Hook Callbacks to register

init <Function> The init callback.
before <Function> The before callback.
after <Function> The after callback.
destroy <Function> The destroy callback.
promiseResolve <Function> The promiseResolve callback.


Returns: <AsyncHook> Instance used for disabling and enabling hooks

Registers functions to be called for different lifetime events of each async
operation.
The callbacks init()/before()/after()/destroy() are called for the
respective asynchronous event during a resource's lifetime.
All callbacks are optional. For example, if only resource cleanup needs to
be tracked, then only the destroy callback needs to be passed. The
specifics of all functions that can be passed to callbacks is in the
Hook Callbacks section.

import { createHook } from 'node:async_hooks';

const asyncHook = createHook({
  init(asyncId, type, triggerAsyncId, resource) { },
  destroy(asyncId) { },
});const async_hooks = require('node:async_hooks');

const asyncHook = async_hooks.createHook({
  init(asyncId, type, triggerAsyncId, resource) { },
  destroy(asyncId) { },
});copy
The callbacks will be inherited via the prototype chain:
class MyAsyncCallbacks {
  init(asyncId, type, triggerAsyncId, resource) { }
  destroy(asyncId) {}
}

class MyAddedCallbacks extends MyAsyncCallbacks {
  before(asyncId) { }
  after(asyncId) { }
}

const asyncHook = async_hooks.createHook(new MyAddedCallbacks()); copy
Because promises are asynchronous resources whose lifecycle is tracked
via the async hooks mechanism, the init(), before(), after(), and
destroy() callbacks must not be async functions that return promises.

Error handling#
If any AsyncHook callbacks throw, the application will print the stack trace
and exit. The exit path does follow that of an uncaught exception, but
all 'uncaughtException' listeners are removed, thus forcing the process to
exit. The 'exit' callbacks will still be called unless the application is run
with --abort-on-uncaught-exception, in which case a stack trace will be
printed and the application exits, leaving a core file.
The reason for this error handling behavior is that these callbacks are running
at potentially volatile points in an object's lifetime, for example during
class construction and destruction. Because of this, it is deemed necessary to
bring down the process quickly in order to prevent an unintentional abort in the
future. This is subject to change in the future if a comprehensive analysis is
performed to ensure an exception can follow the normal control flow without
unintentional side effects.

Printing in AsyncHook callbacks#
Because printing to the console is an asynchronous operation, console.log()
will cause AsyncHook callbacks to be called. Using console.log() or
similar asynchronous operations inside an AsyncHook callback function will
cause an infinite recursion. An easy solution to this when debugging is to use a
synchronous logging operation such as fs.writeFileSync(file, msg, flag).
This will print to the file and will not invoke AsyncHook recursively because
it is synchronous.

import { writeFileSync } from 'node:fs';
import { format } from 'node:util';

function debug(...args) {
  // Use a function like this one when debugging inside an AsyncHook callback
  writeFileSync('log.out', `${format(...args)}\n`, { flag: 'a' });
}const fs = require('node:fs');
const util = require('node:util');

function debug(...args) {
  // Use a function like this one when debugging inside an AsyncHook callback
  fs.writeFileSync('log.out', `${util.format(...args)}\n`, { flag: 'a' });
}copy
If an asynchronous operation is needed for logging, it is possible to keep
track of what caused the asynchronous operation using the information
provided by AsyncHook itself. The logging should then be skipped when
it was the logging itself that caused the AsyncHook callback to be called. By
doing this, the otherwise infinite recursion is broken.

Class: AsyncHook#
The class AsyncHook exposes an interface for tracking lifetime events
of asynchronous operations.

asyncHook.enable()#

Returns: <AsyncHook> A reference to asyncHook.

Enable the callbacks for a given AsyncHook instance. If no callbacks are
provided, enabling is a no-op.
The AsyncHook instance is disabled by default. If the AsyncHook instance
should be enabled immediately after creation, the following pattern can be used.

import { createHook } from 'node:async_hooks';

const hook = createHook(callbacks).enable();const async_hooks = require('node:async_hooks');

const hook = async_hooks.createHook(callbacks).enable();copy

asyncHook.disable()#

Returns: <AsyncHook> A reference to asyncHook.

Disable the callbacks for a given AsyncHook instance from the global pool of
AsyncHook callbacks to be executed. Once a hook has been disabled it will not
be called again until enabled.
For API consistency disable() also returns the AsyncHook instance.

Hook callbacks#
Key events in the lifetime of asynchronous events have been categorized into
four areas: instantiation, before/after the callback is called, and when the
instance is destroyed.

init(asyncId, type, triggerAsyncId, resource)#

asyncId <number> A unique ID for the async resource.
type <string> The type of the async resource.
triggerAsyncId <number> The unique ID of the async resource in whose
execution context this async resource was created.
resource <Object> Reference to the resource representing the async
operation, needs to be released during destroy.

Called when a class is constructed that has the possibility to emit an
asynchronous event. This does not mean the instance must call
before/after before destroy is called, only that the possibility
exists.
This behavior can be observed by doing something like opening a resource then
closing it before the resource can be used. The following snippet demonstrates
this.

import { createServer } from 'node:net';

createServer().listen(function() { this.close(); });
// OR
clearTimeout(setTimeout(() => {}, 10));require('node:net').createServer().listen(function() { this.close(); });
// OR
clearTimeout(setTimeout(() => {}, 10));copy
Every new resource is assigned an ID that is unique within the scope of the
current Node.js instance.

type#
The type is a string identifying the type of resource that caused
init to be called. Generally, it will correspond to the name of the
resource's constructor.
The type of resources created by Node.js itself can change in any Node.js
release. Valid values include TLSWRAP,
TCPWRAP, TCPSERVERWRAP, GETADDRINFOREQWRAP, FSREQCALLBACK,
Microtask, and Timeout. Inspect the source code of the Node.js version used
to get the full list.
Furthermore users of AsyncResource create async resources independent
of Node.js itself.
There is also the PROMISE resource type, which is used to track Promise
instances and asynchronous work scheduled by them.
Users are able to define their own type when using the public embedder API.
It is possible to have type name collisions. Embedders are encouraged to use
unique prefixes, such as the npm package name, to prevent collisions when
listening to the hooks.

triggerAsyncId#
triggerAsyncId is the asyncId of the resource that caused (or "triggered")
the new resource to initialize and that caused init to call. This is different
from async_hooks.executionAsyncId() that only shows when a resource was
created, while triggerAsyncId shows why a resource was created.
The following is a simple demonstration of triggerAsyncId:

import { createHook, executionAsyncId } from 'node:async_hooks';
import { stdout } from 'node:process';
import net from 'node:net';
import fs from 'node:fs';

createHook({
  init(asyncId, type, triggerAsyncId) {
    const eid = executionAsyncId();
    fs.writeSync(
      stdout.fd,
      `${type}(${asyncId}): trigger: ${triggerAsyncId} execution: ${eid}\n`);
  },
}).enable();

net.createServer((conn) => {}).listen(8080);const { createHook, executionAsyncId } = require('node:async_hooks');
const { stdout } = require('node:process');
const net = require('node:net');
const fs = require('node:fs');

createHook({
  init(asyncId, type, triggerAsyncId) {
    const eid = executionAsyncId();
    fs.writeSync(
      stdout.fd,
      `${type}(${asyncId}): trigger: ${triggerAsyncId} execution: ${eid}\n`);
  },
}).enable();

net.createServer((conn) => {}).listen(8080);copy
Output when hitting the server with nc localhost 8080:
TCPSERVERWRAP(5): trigger: 1 execution: 1
TCPWRAP(7): trigger: 5 execution: 0 copy
The TCPSERVERWRAP is the server which receives the connections.
The TCPWRAP is the new connection from the client. When a new
connection is made, the TCPWrap instance is immediately constructed. This
happens outside of any JavaScript stack. (An executionAsyncId() of 0 means
that it is being executed from C++ with no JavaScript stack above it.) With only
that information, it would be impossible to link resources together in
terms of what caused them to be created, so triggerAsyncId is given the task
of propagating what resource is responsible for the new resource's existence.

resource#
resource is an object that represents the actual async resource that has
been initialized. The API to access the object may be specified by the
creator of the resource. Resources created by Node.js itself are internal
and may change at any time. Therefore no API is specified for these.
In some cases the resource object is reused for performance reasons, it is
thus not safe to use it as a key in a WeakMap or add properties to it.

Asynchronous context example#
The context tracking use case is covered by the stable API AsyncLocalStorage.
This example only illustrates async hooks operation but AsyncLocalStorage
fits better to this use case.
The following is an example with additional information about the calls to
init between the before and after calls, specifically what the
callback to listen() will look like. The output formatting is slightly more
elaborate to make calling context easier to see.

import async_hooks from 'node:async_hooks';
import fs from 'node:fs';
import net from 'node:net';
import { stdout } from 'node:process';
const { fd } = stdout;

let indent = 0;
async_hooks.createHook({
  init(asyncId, type, triggerAsyncId) {
    const eid = async_hooks.executionAsyncId();
    const indentStr = ' '.repeat(indent);
    fs.writeSync(
      fd,
      `${indentStr}${type}(${asyncId}):` +
      ` trigger: ${triggerAsyncId} execution: ${eid}\n`);
  },
  before(asyncId) {
    const indentStr = ' '.repeat(indent);
    fs.writeSync(fd, `${indentStr}before:  ${asyncId}\n`);
    indent += 2;
  },
  after(asyncId) {
    indent -= 2;
    const indentStr = ' '.repeat(indent);
    fs.writeSync(fd, `${indentStr}after:  ${asyncId}\n`);
  },
  destroy(asyncId) {
    const indentStr = ' '.repeat(indent);
    fs.writeSync(fd, `${indentStr}destroy:  ${asyncId}\n`);
  },
}).enable();

net.createServer(() => {}).listen(8080, () => {
  // Let's wait 10ms before logging the server started.
  setTimeout(() => {
    console.log('>>>', async_hooks.executionAsyncId());
  }, 10);
});const async_hooks = require('node:async_hooks');
const fs = require('node:fs');
const net = require('node:net');
const { fd } = process.stdout;

let indent = 0;
async_hooks.createHook({
  init(asyncId, type, triggerAsyncId) {
    const eid = async_hooks.executionAsyncId();
    const indentStr = ' '.repeat(indent);
    fs.writeSync(
      fd,
      `${indentStr}${type}(${asyncId}):` +
      ` trigger: ${triggerAsyncId} execution: ${eid}\n`);
  },
  before(asyncId) {
    const indentStr = ' '.repeat(indent);
    fs.writeSync(fd, `${indentStr}before:  ${asyncId}\n`);
    indent += 2;
  },
  after(asyncId) {
    indent -= 2;
    const indentStr = ' '.repeat(indent);
    fs.writeSync(fd, `${indentStr}after:  ${asyncId}\n`);
  },
  destroy(asyncId) {
    const indentStr = ' '.repeat(indent);
    fs.writeSync(fd, `${indentStr}destroy:  ${asyncId}\n`);
  },
}).enable();

net.createServer(() => {}).listen(8080, () => {
  // Let's wait 10ms before logging the server started.
  setTimeout(() => {
    console.log('>>>', async_hooks.executionAsyncId());
  }, 10);
});copy
Output from only starting the server:
TCPSERVERWRAP(5): trigger: 1 execution: 1
TickObject(6): trigger: 5 execution: 1
before:  6
  Timeout(7): trigger: 6 execution: 6
after:   6
destroy: 6
before:  7
>>> 7
  TickObject(8): trigger: 7 execution: 7
after:   7
before:  8
after:   8 copy
As illustrated in the example, executionAsyncId() and execution each specify
the value of the current execution context; which is delineated by calls to
before and after.
Only using execution to graph resource allocation results in the following:
  root(1)
     ^
     |
TickObject(6)
     ^
     |
 Timeout(7) copy
The TCPSERVERWRAP is not part of this graph, even though it was the reason for
console.log() being called. This is because binding to a port without a host
name is a synchronous operation, but to maintain a completely asynchronous
API the user's callback is placed in a process.nextTick(). Which is why
TickObject is present in the output and is a 'parent' for .listen()
callback.
The graph only shows when a resource was created, not why, so to track
the why use triggerAsyncId. Which can be represented with the following
graph:
 bootstrap(1)
     |
     ˅
TCPSERVERWRAP(5)
     |
     ˅
 TickObject(6)
     |
     ˅
  Timeout(7) copy

before(asyncId)#

asyncId <number>

When an asynchronous operation is initiated (such as a TCP server receiving a
new connection) or completes (such as writing data to disk) a callback is
called to notify the user. The before callback is called just before said
callback is executed. asyncId is the unique identifier assigned to the
resource about to execute the callback.
The before callback will be called 0 to N times. The before callback
will typically be called 0 times if the asynchronous operation was cancelled
or, for example, if no connections are received by a TCP server. Persistent
asynchronous resources like a TCP server will typically call the before
callback multiple times, while other operations like fs.open() will call
it only once.

after(asyncId)#

asyncId <number>

Called immediately after the callback specified in before is completed.
If an uncaught exception occurs during execution of the callback, then after
will run after the 'uncaughtException' event is emitted or a domain's
handler runs.

destroy(asyncId)#

asyncId <number>

Called after the resource corresponding to asyncId is destroyed. It is also
called asynchronously from the embedder API emitDestroy().
Some resources depend on garbage collection for cleanup, so if a reference is
made to the resource object passed to init it is possible that destroy
will never be called, causing a memory leak in the application. If the resource
does not depend on garbage collection, then this will not be an issue.
Using the destroy hook results in additional overhead because it enables
tracking of Promise instances via the garbage collector.

promiseResolve(asyncId)#

Added in: v8.6.0


asyncId <number>

Called when the resolve function passed to the Promise constructor is
invoked (either directly or through other means of resolving a promise).
resolve() does not do any observable synchronous work.
The Promise is not necessarily fulfilled or rejected at this point if the
Promise was resolved by assuming the state of another Promise.
new Promise((resolve) => resolve(true)).then((a) => {}); copy
calls the following callbacks:
init for PROMISE with id 5, trigger id: 1
  promise resolve 5      # corresponds to resolve(true)
init for PROMISE with id 6, trigger id: 5  # the Promise returned by then()
  before 6               # the then() callback is entered
  promise resolve 6      # the then() callback resolves the promise by returning
  after 6 copy

async_hooks.executionAsyncResource()#

Added in: v13.9.0, v12.17.0


Returns: <Object> The resource representing the current execution.
Useful to store data within the resource.

Resource objects returned by executionAsyncResource() are most often internal
Node.js handle objects with undocumented APIs. Using any functions or properties
on the object is likely to crash your application and should be avoided.
Using executionAsyncResource() in the top-level execution context will
return an empty object as there is no handle or request object to use,
but having an object representing the top-level can be helpful.

import { open } from 'node:fs';
import { executionAsyncId, executionAsyncResource } from 'node:async_hooks';

console.log(executionAsyncId(), executionAsyncResource());  // 1 {}
open(new URL(import.meta.url), 'r', (err, fd) => {
  console.log(executionAsyncId(), executionAsyncResource());  // 7 FSReqWrap
});const { open } = require('node:fs');
const { executionAsyncId, executionAsyncResource } = require('node:async_hooks');

console.log(executionAsyncId(), executionAsyncResource());  // 1 {}
open(__filename, 'r', (err, fd) => {
  console.log(executionAsyncId(), executionAsyncResource());  // 7 FSReqWrap
});copy
This can be used to implement continuation local storage without the
use of a tracking Map to store the metadata:

import { createServer } from 'node:http';
import {
  executionAsyncId,
  executionAsyncResource,
  createHook,
} from 'node:async_hooks';
const sym = Symbol('state'); // Private symbol to avoid pollution

createHook({
  init(asyncId, type, triggerAsyncId, resource) {
    const cr = executionAsyncResource();
    if (cr) {
      resource[sym] = cr[sym];
    }
  },
}).enable();

const server = createServer((req, res) => {
  executionAsyncResource()[sym] = { state: req.url };
  setTimeout(function() {
    res.end(JSON.stringify(executionAsyncResource()[sym]));
  }, 100);
}).listen(3000);const { createServer } = require('node:http');
const {
  executionAsyncId,
  executionAsyncResource,
  createHook,
} = require('node:async_hooks');
const sym = Symbol('state'); // Private symbol to avoid pollution

createHook({
  init(asyncId, type, triggerAsyncId, resource) {
    const cr = executionAsyncResource();
    if (cr) {
      resource[sym] = cr[sym];
    }
  },
}).enable();

const server = createServer((req, res) => {
  executionAsyncResource()[sym] = { state: req.url };
  setTimeout(function() {
    res.end(JSON.stringify(executionAsyncResource()[sym]));
  }, 100);
}).listen(3000);copy

async_hooks.executionAsyncId()#

History

VersionChanges
v8.2.0
Renamed from currentId.
v8.1.0
Added in: v8.1.0




Returns: <number> The asyncId of the current execution context. Useful to
track when something calls.


import { executionAsyncId } from 'node:async_hooks';
import fs from 'node:fs';

console.log(executionAsyncId());  // 1 - bootstrap
const path = '.';
fs.open(path, 'r', (err, fd) => {
  console.log(executionAsyncId());  // 6 - open()
});const async_hooks = require('node:async_hooks');
const fs = require('node:fs');

console.log(async_hooks.executionAsyncId());  // 1 - bootstrap
const path = '.';
fs.open(path, 'r', (err, fd) => {
  console.log(async_hooks.executionAsyncId());  // 6 - open()
});copy
The ID returned from executionAsyncId() is related to execution timing, not
causality (which is covered by triggerAsyncId()):
const server = net.createServer((conn) => {
  // Returns the ID of the server, not of the new connection, because the
  // callback runs in the execution scope of the server's MakeCallback().
  async_hooks.executionAsyncId();

}).listen(port, () => {
  // Returns the ID of a TickObject (process.nextTick()) because all
  // callbacks passed to .listen() are wrapped in a nextTick().
  async_hooks.executionAsyncId();
}); copy
Promise contexts may not get precise executionAsyncIds by default.
See the section on promise execution tracking.

async_hooks.triggerAsyncId()#

Returns: <number> The ID of the resource responsible for calling the callback
that is currently being executed.

const server = net.createServer((conn) => {
  // The resource that caused (or triggered) this callback to be called
  // was that of the new connection. Thus the return value of triggerAsyncId()
  // is the asyncId of "conn".
  async_hooks.triggerAsyncId();

}).listen(port, () => {
  // Even though all callbacks passed to .listen() are wrapped in a nextTick()
  // the callback itself exists because the call to the server's .listen()
  // was made. So the return value would be the ID of the server.
  async_hooks.triggerAsyncId();
}); copy
Promise contexts may not get valid triggerAsyncIds by default. See
the section on promise execution tracking.

async_hooks.asyncWrapProviders#

Added in: v17.2.0, v16.14.0


Returns: A map of provider types to the corresponding numeric id.
This map contains all the event types that might be emitted by the async_hooks.init() event.

This feature suppresses the deprecated usage of process.binding('async_wrap').Providers.
See: DEP0111

Promise execution tracking#
By default, promise executions are not assigned asyncIds due to the relatively
expensive nature of the promise introspection API provided by
V8. This means that programs using promises or async/await will not get
correct execution and trigger ids for promise callback contexts by default.

import { executionAsyncId, triggerAsyncId } from 'node:async_hooks';

Promise.resolve(1729).then(() => {
  console.log(`eid ${executionAsyncId()} tid ${triggerAsyncId()}`);
});
// produces:
// eid 1 tid 0const { executionAsyncId, triggerAsyncId } = require('node:async_hooks');

Promise.resolve(1729).then(() => {
  console.log(`eid ${executionAsyncId()} tid ${triggerAsyncId()}`);
});
// produces:
// eid 1 tid 0copy
Observe that the then() callback claims to have executed in the context of the
outer scope even though there was an asynchronous hop involved. Also,
the triggerAsyncId value is 0, which means that we are missing context about
the resource that caused (triggered) the then() callback to be executed.
Installing async hooks via async_hooks.createHook enables promise execution
tracking:

import { createHook, executionAsyncId, triggerAsyncId } from 'node:async_hooks';
createHook({ init() {} }).enable(); // forces PromiseHooks to be enabled.
Promise.resolve(1729).then(() => {
  console.log(`eid ${executionAsyncId()} tid ${triggerAsyncId()}`);
});
// produces:
// eid 7 tid 6const { createHook, executionAsyncId, triggerAsyncId } = require('node:async_hooks');

createHook({ init() {} }).enable(); // forces PromiseHooks to be enabled.
Promise.resolve(1729).then(() => {
  console.log(`eid ${executionAsyncId()} tid ${triggerAsyncId()}`);
});
// produces:
// eid 7 tid 6copy
In this example, adding any actual hook function enabled the tracking of
promises. There are two promises in the example above; the promise created by
Promise.resolve() and the promise returned by the call to then(). In the
example above, the first promise got the asyncId 6 and the latter got
asyncId 7. During the execution of the then() callback, we are executing
in the context of promise with asyncId 7. This promise was triggered by
async resource 6.
Another subtlety with promises is that before and after callbacks are run
only on chained promises. That means promises not created by then()/catch()
will not have the before and after callbacks fired on them. For more details
see the details of the V8 PromiseHooks API.
JavaScript embedder API#
Library developers that handle their own asynchronous resources performing tasks
like I/O, connection pooling, or managing callback queues may use the
AsyncResource JavaScript API so that all the appropriate callbacks are called.

Class: AsyncResource#
The documentation for this class has moved AsyncResource.

Class: AsyncLocalStorage#
The documentation for this class has moved AsyncLocalStorage.\n\n\n\nNode.js
        
      
      
About this documentation
Usage and example



Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Modules: TypeScript
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
Readline
REPL
Report
Single executable applications
SQLite
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker

    

    
      
        
          Node.js v24.0.1 documentation
          
            
            
          
        
        
          
            Node.js v24.0.1
            
    
      
        
        Table of contents
      

      
Buffer

Buffers and character encodings
Buffers and TypedArrays
Buffers and iteration
Class: Blob

new buffer.Blob([sources[, options]])
blob.arrayBuffer()

blob.bytes()


blob.size
blob.slice([start[, end[, type]]])
blob.stream()
blob.text()
blob.type
Blob objects and MessageChannel


Class: Buffer

Static method: Buffer.alloc(size[, fill[, encoding]])
Static method: Buffer.allocUnsafe(size)
Static method: Buffer.allocUnsafeSlow(size)
Static method: Buffer.byteLength(string[, encoding])
Static method: Buffer.compare(buf1, buf2)
Static method: Buffer.concat(list[, totalLength])
Static method: Buffer.copyBytesFrom(view[, offset[, length]])
Static method: Buffer.from(array)
Static method: Buffer.from(arrayBuffer[, byteOffset[, length]])
Static method: Buffer.from(buffer)
Static method: Buffer.from(object[, offsetOrEncoding[, length]])
Static method: Buffer.from(string[, encoding])
Static method: Buffer.isBuffer(obj)
Static method: Buffer.isEncoding(encoding)
Class property: Buffer.poolSize
buf[index]
buf.buffer
buf.byteOffset
buf.compare(target[, targetStart[, targetEnd[, sourceStart[, sourceEnd]]]])
buf.copy(target[, targetStart[, sourceStart[, sourceEnd]]])
buf.entries()
buf.equals(otherBuffer)
buf.fill(value[, offset[, end]][, encoding])
buf.includes(value[, byteOffset][, encoding])
buf.indexOf(value[, byteOffset][, encoding])
buf.keys()
buf.lastIndexOf(value[, byteOffset][, encoding])
buf.length
buf.parent
buf.readBigInt64BE([offset])
buf.readBigInt64LE([offset])
buf.readBigUInt64BE([offset])
buf.readBigUInt64LE([offset])
buf.readDoubleBE([offset])
buf.readDoubleLE([offset])
buf.readFloatBE([offset])
buf.readFloatLE([offset])
buf.readInt8([offset])
buf.readInt16BE([offset])
buf.readInt16LE([offset])
buf.readInt32BE([offset])
buf.readInt32LE([offset])
buf.readIntBE(offset, byteLength)
buf.readIntLE(offset, byteLength)
buf.readUInt8([offset])
buf.readUInt16BE([offset])
buf.readUInt16LE([offset])
buf.readUInt32BE([offset])
buf.readUInt32LE([offset])
buf.readUIntBE(offset, byteLength)
buf.readUIntLE(offset, byteLength)
buf.subarray([start[, end]])
buf.slice([start[, end]])
buf.swap16()
buf.swap32()
buf.swap64()
buf.toJSON()
buf.toString([encoding[, start[, end]]])
buf.values()
buf.write(string[, offset[, length]][, encoding])
buf.writeBigInt64BE(value[, offset])
buf.writeBigInt64LE(value[, offset])
buf.writeBigUInt64BE(value[, offset])
buf.writeBigUInt64LE(value[, offset])
buf.writeDoubleBE(value[, offset])
buf.writeDoubleLE(value[, offset])
buf.writeFloatBE(value[, offset])
buf.writeFloatLE(value[, offset])
buf.writeInt8(value[, offset])
buf.writeInt16BE(value[, offset])
buf.writeInt16LE(value[, offset])
buf.writeInt32BE(value[, offset])
buf.writeInt32LE(value[, offset])
buf.writeIntBE(value, offset, byteLength)
buf.writeIntLE(value, offset, byteLength)
buf.writeUInt8(value[, offset])
buf.writeUInt16BE(value[, offset])
buf.writeUInt16LE(value[, offset])
buf.writeUInt32BE(value[, offset])
buf.writeUInt32LE(value[, offset])
buf.writeUIntBE(value, offset, byteLength)
buf.writeUIntLE(value, offset, byteLength)
new Buffer(array)
new Buffer(arrayBuffer[, byteOffset[, length]])
new Buffer(buffer)
new Buffer(size)
new Buffer(string[, encoding])


Class: File

new buffer.File(sources, fileName[, options])
file.name
file.lastModified


node:buffer module APIs

buffer.atob(data)
buffer.btoa(data)
buffer.isAscii(input)
buffer.isUtf8(input)
buffer.INSPECT_MAX_BYTES
buffer.kMaxLength
buffer.kStringMaxLength
buffer.resolveObjectURL(id)
buffer.transcode(source, fromEnc, toEnc)
Class: SlowBuffer

new SlowBuffer(size)


Buffer constants

buffer.constants.MAX_LENGTH
buffer.constants.MAX_STRING_LENGTH




Buffer.from(), Buffer.alloc(), and Buffer.allocUnsafe()

The --zero-fill-buffers command-line option
What makes Buffer.allocUnsafe() and Buffer.allocUnsafeSlow() "unsafe"?





    
  
            
    
      
        
        Index
      

      
About this documentation
Usage and example

      
        Index
      
    
  


Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Modules: TypeScript
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
Readline
REPL
Report
Single executable applications
SQLite
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker

    
  
            
    
      
        
        Other versions
      
      24.x
23.x
22.x LTS
21.x
20.x LTS
19.x
18.x
17.x
16.x
15.x
14.x
13.x
12.x
11.x
10.x
9.x
8.x
7.x
6.x
5.x
4.x
0.12.x
0.10.x
    
  
            
              
                
                Options
              
        
              
                
                  
                    View on single page
                  
                  
                    View as JSON
                  
                  Edit on GitHub    
                
              
            
          
        
        
      

      Table of contents
Buffer

Buffers and character encodings
Buffers and TypedArrays
Buffers and iteration
Class: Blob

new buffer.Blob([sources[, options]])
blob.arrayBuffer()

blob.bytes()


blob.size
blob.slice([start[, end[, type]]])
blob.stream()
blob.text()
blob.type
Blob objects and MessageChannel


Class: Buffer

Static method: Buffer.alloc(size[, fill[, encoding]])
Static method: Buffer.allocUnsafe(size)
Static method: Buffer.allocUnsafeSlow(size)
Static method: Buffer.byteLength(string[, encoding])
Static method: Buffer.compare(buf1, buf2)
Static method: Buffer.concat(list[, totalLength])
Static method: Buffer.copyBytesFrom(view[, offset[, length]])
Static method: Buffer.from(array)
Static method: Buffer.from(arrayBuffer[, byteOffset[, length]])
Static method: Buffer.from(buffer)
Static method: Buffer.from(object[, offsetOrEncoding[, length]])
Static method: Buffer.from(string[, encoding])
Static method: Buffer.isBuffer(obj)
Static method: Buffer.isEncoding(encoding)
Class property: Buffer.poolSize
buf[index]
buf.buffer
buf.byteOffset
buf.compare(target[, targetStart[, targetEnd[, sourceStart[, sourceEnd]]]])
buf.copy(target[, targetStart[, sourceStart[, sourceEnd]]])
buf.entries()
buf.equals(otherBuffer)
buf.fill(value[, offset[, end]][, encoding])
buf.includes(value[, byteOffset][, encoding])
buf.indexOf(value[, byteOffset][, encoding])
buf.keys()
buf.lastIndexOf(value[, byteOffset][, encoding])
buf.length
buf.parent
buf.readBigInt64BE([offset])
buf.readBigInt64LE([offset])
buf.readBigUInt64BE([offset])
buf.readBigUInt64LE([offset])
buf.readDoubleBE([offset])
buf.readDoubleLE([offset])
buf.readFloatBE([offset])
buf.readFloatLE([offset])
buf.readInt8([offset])
buf.readInt16BE([offset])
buf.readInt16LE([offset])
buf.readInt32BE([offset])
buf.readInt32LE([offset])
buf.readIntBE(offset, byteLength)
buf.readIntLE(offset, byteLength)
buf.readUInt8([offset])
buf.readUInt16BE([offset])
buf.readUInt16LE([offset])
buf.readUInt32BE([offset])
buf.readUInt32LE([offset])
buf.readUIntBE(offset, byteLength)
buf.readUIntLE(offset, byteLength)
buf.subarray([start[, end]])
buf.slice([start[, end]])
buf.swap16()
buf.swap32()
buf.swap64()
buf.toJSON()
buf.toString([encoding[, start[, end]]])
buf.values()
buf.write(string[, offset[, length]][, encoding])
buf.writeBigInt64BE(value[, offset])
buf.writeBigInt64LE(value[, offset])
buf.writeBigUInt64BE(value[, offset])
buf.writeBigUInt64LE(value[, offset])
buf.writeDoubleBE(value[, offset])
buf.writeDoubleLE(value[, offset])
buf.writeFloatBE(value[, offset])
buf.writeFloatLE(value[, offset])
buf.writeInt8(value[, offset])
buf.writeInt16BE(value[, offset])
buf.writeInt16LE(value[, offset])
buf.writeInt32BE(value[, offset])
buf.writeInt32LE(value[, offset])
buf.writeIntBE(value, offset, byteLength)
buf.writeIntLE(value, offset, byteLength)
buf.writeUInt8(value[, offset])
buf.writeUInt16BE(value[, offset])
buf.writeUInt16LE(value[, offset])
buf.writeUInt32BE(value[, offset])
buf.writeUInt32LE(value[, offset])
buf.writeUIntBE(value, offset, byteLength)
buf.writeUIntLE(value, offset, byteLength)
new Buffer(array)
new Buffer(arrayBuffer[, byteOffset[, length]])
new Buffer(buffer)
new Buffer(size)
new Buffer(string[, encoding])


Class: File

new buffer.File(sources, fileName[, options])
file.name
file.lastModified


node:buffer module APIs

buffer.atob(data)
buffer.btoa(data)
buffer.isAscii(input)
buffer.isUtf8(input)
buffer.INSPECT_MAX_BYTES
buffer.kMaxLength
buffer.kStringMaxLength
buffer.resolveObjectURL(id)
buffer.transcode(source, fromEnc, toEnc)
Class: SlowBuffer

new SlowBuffer(size)


Buffer constants

buffer.constants.MAX_LENGTH
buffer.constants.MAX_STRING_LENGTH




Buffer.from(), Buffer.alloc(), and Buffer.allocUnsafe()

The --zero-fill-buffers command-line option
What makes Buffer.allocUnsafe() and Buffer.allocUnsafeSlow() "unsafe"?






      
        Buffer#

Stability: 2 - Stable
Source Code: lib/buffer.js
Buffer objects are used to represent a fixed-length sequence of bytes. Many
Node.js APIs support Buffers.
The Buffer class is a subclass of JavaScript's <Uint8Array> class and
extends it with methods that cover additional use cases. Node.js APIs accept
plain <Uint8Array>s wherever Buffers are supported as well.
While the Buffer class is available within the global scope, it is still
recommended to explicitly reference it via an import or require statement.

import { Buffer } from 'node:buffer';

// Creates a zero-filled Buffer of length 10.
const buf1 = Buffer.alloc(10);

// Creates a Buffer of length 10,
// filled with bytes which all have the value `1`.
const buf2 = Buffer.alloc(10, 1);

// Creates an uninitialized buffer of length 10.
// This is faster than calling Buffer.alloc() but the returned
// Buffer instance might contain old data that needs to be
// overwritten using fill(), write(), or other functions that fill the Buffer's
// contents.
const buf3 = Buffer.allocUnsafe(10);

// Creates a Buffer containing the bytes [1, 2, 3].
const buf4 = Buffer.from([1, 2, 3]);

// Creates a Buffer containing the bytes [1, 1, 1, 1] – the entries
// are all truncated using `(value & 255)` to fit into the range 0–255.
const buf5 = Buffer.from([257, 257.5, -255, '1']);

// Creates a Buffer containing the UTF-8-encoded bytes for the string 'tést':
// [0x74, 0xc3, 0xa9, 0x73, 0x74] (in hexadecimal notation)
// [116, 195, 169, 115, 116] (in decimal notation)
const buf6 = Buffer.from('tést');

// Creates a Buffer containing the Latin-1 bytes [0x74, 0xe9, 0x73, 0x74].
const buf7 = Buffer.from('tést', 'latin1');const { Buffer } = require('node:buffer');

// Creates a zero-filled Buffer of length 10.
const buf1 = Buffer.alloc(10);

// Creates a Buffer of length 10,
// filled with bytes which all have the value `1`.
const buf2 = Buffer.alloc(10, 1);

// Creates an uninitialized buffer of length 10.
// This is faster than calling Buffer.alloc() but the returned
// Buffer instance might contain old data that needs to be
// overwritten using fill(), write(), or other functions that fill the Buffer's
// contents.
const buf3 = Buffer.allocUnsafe(10);

// Creates a Buffer containing the bytes [1, 2, 3].
const buf4 = Buffer.from([1, 2, 3]);

// Creates a Buffer containing the bytes [1, 1, 1, 1] – the entries
// are all truncated using `(value & 255)` to fit into the range 0–255.
const buf5 = Buffer.from([257, 257.5, -255, '1']);

// Creates a Buffer containing the UTF-8-encoded bytes for the string 'tést':
// [0x74, 0xc3, 0xa9, 0x73, 0x74] (in hexadecimal notation)
// [116, 195, 169, 115, 116] (in decimal notation)
const buf6 = Buffer.from('tést');

// Creates a Buffer containing the Latin-1 bytes [0x74, 0xe9, 0x73, 0x74].
const buf7 = Buffer.from('tést', 'latin1');copy
Buffers and character encodings#

History

VersionChanges
v15.7.0, v14.18.0
Introduced base64url encoding.
v6.4.0
Introduced latin1 as an alias for binary.
v5.0.0
Removed the deprecated raw and raws encodings.



When converting between Buffers and strings, a character encoding may be
specified. If no character encoding is specified, UTF-8 will be used as the
default.

import { Buffer } from 'node:buffer';

const buf = Buffer.from('hello world', 'utf8');

console.log(buf.toString('hex'));
// Prints: 68656c6c6f20776f726c64
console.log(buf.toString('base64'));
// Prints: aGVsbG8gd29ybGQ=

console.log(Buffer.from('fhqwhgads', 'utf8'));
// Prints: <Buffer 66 68 71 77 68 67 61 64 73>
console.log(Buffer.from('fhqwhgads', 'utf16le'));
// Prints: <Buffer 66 00 68 00 71 00 77 00 68 00 67 00 61 00 64 00 73 00>const { Buffer } = require('node:buffer');

const buf = Buffer.from('hello world', 'utf8');

console.log(buf.toString('hex'));
// Prints: 68656c6c6f20776f726c64
console.log(buf.toString('base64'));
// Prints: aGVsbG8gd29ybGQ=

console.log(Buffer.from('fhqwhgads', 'utf8'));
// Prints: <Buffer 66 68 71 77 68 67 61 64 73>
console.log(Buffer.from('fhqwhgads', 'utf16le'));
// Prints: <Buffer 66 00 68 00 71 00 77 00 68 00 67 00 61 00 64 00 73 00>copy
Node.js buffers accept all case variations of encoding strings that they
receive. For example, UTF-8 can be specified as 'utf8', 'UTF8', or 'uTf8'.
The character encodings currently supported by Node.js are the following:


'utf8' (alias: 'utf-8'): Multi-byte encoded Unicode characters. Many web
pages and other document formats use UTF-8. This is the default character
encoding. When decoding a Buffer into a string that does not exclusively
contain valid UTF-8 data, the Unicode replacement character U+FFFD � will be
used to represent those errors.


'utf16le' (alias: 'utf-16le'): Multi-byte encoded Unicode characters.
Unlike 'utf8', each character in the string will be encoded using either 2
or 4 bytes. Node.js only supports the little-endian variant of
UTF-16.


'latin1': Latin-1 stands for ISO-8859-1. This character encoding only
supports the Unicode characters from U+0000 to U+00FF. Each character is
encoded using a single byte. Characters that do not fit into that range are
truncated and will be mapped to characters in that range.


Converting a Buffer into a string using one of the above is referred to as
decoding, and converting a string into a Buffer is referred to as encoding.
Node.js also supports the following binary-to-text encodings. For
binary-to-text encodings, the naming convention is reversed: Converting a
Buffer into a string is typically referred to as encoding, and converting a
string into a Buffer as decoding.


'base64': Base64 encoding. When creating a Buffer from a string,
this encoding will also correctly accept "URL and Filename Safe Alphabet" as
specified in RFC 4648, Section 5. Whitespace characters such as spaces,
tabs, and new lines contained within the base64-encoded string are ignored.


'base64url': base64url encoding as specified in
RFC 4648, Section 5. When creating a Buffer from a string, this
encoding will also correctly accept regular base64-encoded strings. When
encoding a Buffer to a string, this encoding will omit padding.


'hex': Encode each byte as two hexadecimal characters. Data truncation
may occur when decoding strings that do not exclusively consist of an even
number of hexadecimal characters. See below for an example.


The following legacy character encodings are also supported:


'ascii': For 7-bit ASCII data only. When encoding a string into a
Buffer, this is equivalent to using 'latin1'. When decoding a Buffer
into a string, using this encoding will additionally unset the highest bit of
each byte before decoding as 'latin1'.
Generally, there should be no reason to use this encoding, as 'utf8'
(or, if the data is known to always be ASCII-only, 'latin1') will be a
better choice when encoding or decoding ASCII-only text. It is only provided
for legacy compatibility.


'binary': Alias for 'latin1'.
The name of this encoding can be very misleading, as all of the
encodings listed here convert between strings and binary data. For converting
between strings and Buffers, typically 'utf8' is the right choice.


'ucs2', 'ucs-2': Aliases of 'utf16le'. UCS-2 used to refer to a variant
of UTF-16 that did not support characters that had code points larger than
U+FFFF. In Node.js, these code points are always supported.



import { Buffer } from 'node:buffer';

Buffer.from('1ag123', 'hex');
// Prints <Buffer 1a>, data truncated when first non-hexadecimal value
// ('g') encountered.

Buffer.from('1a7', 'hex');
// Prints <Buffer 1a>, data truncated when data ends in single digit ('7').

Buffer.from('1634', 'hex');
// Prints <Buffer 16 34>, all data represented.const { Buffer } = require('node:buffer');

Buffer.from('1ag123', 'hex');
// Prints <Buffer 1a>, data truncated when first non-hexadecimal value
// ('g') encountered.

Buffer.from('1a7', 'hex');
// Prints <Buffer 1a>, data truncated when data ends in single digit ('7').

Buffer.from('1634', 'hex');
// Prints <Buffer 16 34>, all data represented.copy
Modern Web browsers follow the WHATWG Encoding Standard which aliases
both 'latin1' and 'ISO-8859-1' to 'win-1252'. This means that while doing
something like http.get(), if the returned charset is one of those listed in
the WHATWG specification it is possible that the server actually returned
'win-1252'-encoded data, and using 'latin1' encoding may incorrectly decode
the characters.
Buffers and TypedArrays#

History

VersionChanges
v3.0.0
The Buffer class now inherits from Uint8Array.



Buffer instances are also JavaScript <Uint8Array> and <TypedArray>
instances. All <TypedArray> methods are available on Buffers. There are,
however, subtle incompatibilities between the Buffer API and the
<TypedArray> API.
In particular:

While TypedArray.prototype.slice() creates a copy of part of the TypedArray,
Buffer.prototype.slice() creates a view over the existing Buffer
without copying. This behavior can be surprising, and only exists for legacy
compatibility. TypedArray.prototype.subarray() can be used to achieve
the behavior of Buffer.prototype.slice() on both Buffers
and other TypedArrays and should be preferred.
buf.toString() is incompatible with its TypedArray equivalent.
A number of methods, e.g. buf.indexOf(), support additional arguments.

There are two ways to create new <TypedArray> instances from a Buffer:

Passing a Buffer to a <TypedArray> constructor will copy the Buffer's
contents, interpreted as an array of integers, and not as a byte sequence
of the target type.


import { Buffer } from 'node:buffer';

const buf = Buffer.from([1, 2, 3, 4]);
const uint32array = new Uint32Array(buf);

console.log(uint32array);

// Prints: Uint32Array(4) [ 1, 2, 3, 4 ]const { Buffer } = require('node:buffer');

const buf = Buffer.from([1, 2, 3, 4]);
const uint32array = new Uint32Array(buf);

console.log(uint32array);

// Prints: Uint32Array(4) [ 1, 2, 3, 4 ]copy

Passing the Buffer's underlying <ArrayBuffer> will create a
<TypedArray> that shares its memory with the Buffer.


import { Buffer } from 'node:buffer';

const buf = Buffer.from('hello', 'utf16le');
const uint16array = new Uint16Array(
  buf.buffer,
  buf.byteOffset,
  buf.length / Uint16Array.BYTES_PER_ELEMENT);

console.log(uint16array);

// Prints: Uint16Array(5) [ 104, 101, 108, 108, 111 ]const { Buffer } = require('node:buffer');

const buf = Buffer.from('hello', 'utf16le');
const uint16array = new Uint16Array(
  buf.buffer,
  buf.byteOffset,
  buf.length / Uint16Array.BYTES_PER_ELEMENT);

console.log(uint16array);

// Prints: Uint16Array(5) [ 104, 101, 108, 108, 111 ]copy
It is possible to create a new Buffer that shares the same allocated
memory as a <TypedArray> instance by using the TypedArray object's
.buffer property in the same way. Buffer.from()
behaves like new Uint8Array() in this context.

import { Buffer } from 'node:buffer';

const arr = new Uint16Array(2);

arr[0] = 5000;
arr[1] = 4000;

// Copies the contents of `arr`.
const buf1 = Buffer.from(arr);

// Shares memory with `arr`.
const buf2 = Buffer.from(arr.buffer);

console.log(buf1);
// Prints: <Buffer 88 a0>
console.log(buf2);
// Prints: <Buffer 88 13 a0 0f>

arr[1] = 6000;

console.log(buf1);
// Prints: <Buffer 88 a0>
console.log(buf2);
// Prints: <Buffer 88 13 70 17>const { Buffer } = require('node:buffer');

const arr = new Uint16Array(2);

arr[0] = 5000;
arr[1] = 4000;

// Copies the contents of `arr`.
const buf1 = Buffer.from(arr);

// Shares memory with `arr`.
const buf2 = Buffer.from(arr.buffer);

console.log(buf1);
// Prints: <Buffer 88 a0>
console.log(buf2);
// Prints: <Buffer 88 13 a0 0f>

arr[1] = 6000;

console.log(buf1);
// Prints: <Buffer 88 a0>
console.log(buf2);
// Prints: <Buffer 88 13 70 17>copy
When creating a Buffer using a <TypedArray>'s .buffer, it is
possible to use only a portion of the underlying <ArrayBuffer> by passing in
byteOffset and length parameters.

import { Buffer } from 'node:buffer';

const arr = new Uint16Array(20);
const buf = Buffer.from(arr.buffer, 0, 16);

console.log(buf.length);
// Prints: 16const { Buffer } = require('node:buffer');

const arr = new Uint16Array(20);
const buf = Buffer.from(arr.buffer, 0, 16);

console.log(buf.length);
// Prints: 16copy
The Buffer.from() and TypedArray.from() have different signatures and
implementations. Specifically, the <TypedArray> variants accept a second
argument that is a mapping function that is invoked on every element of the
typed array:

TypedArray.from(source[, mapFn[, thisArg]])

The Buffer.from() method, however, does not support the use of a mapping
function:

Buffer.from(array)
Buffer.from(buffer)
Buffer.from(arrayBuffer[, byteOffset[, length]])
Buffer.from(string[, encoding])

Buffers and iteration#
Buffer instances can be iterated over using for..of syntax:

import { Buffer } from 'node:buffer';

const buf = Buffer.from([1, 2, 3]);

for (const b of buf) {
  console.log(b);
}
// Prints:
//   1
//   2
//   3const { Buffer } = require('node:buffer');

const buf = Buffer.from([1, 2, 3]);

for (const b of buf) {
  console.log(b);
}
// Prints:
//   1
//   2
//   3copy
Additionally, the buf.values(), buf.keys(), and
buf.entries() methods can be used to create iterators.
Class: Blob#

History

VersionChanges
v18.0.0, v16.17.0
No longer experimental.
v15.7.0, v14.18.0
Added in: v15.7.0, v14.18.0



A Blob encapsulates immutable, raw data that can be safely shared across
multiple worker threads.

new buffer.Blob([sources[, options]])#

History

VersionChanges
v16.7.0
Added the standard endings option to replace line-endings, and removed the non-standard encoding option.
v15.7.0, v14.18.0
Added in: v15.7.0, v14.18.0




sources <string[]> | <ArrayBuffer[]> | <TypedArray[]> | <DataView[]> | <Blob[]> An
array of string, <ArrayBuffer>, <TypedArray>, <DataView>, or <Blob> objects,
or any mix of such objects, that will be stored within the Blob.
options <Object>

endings <string> One of either 'transparent' or 'native'. When set
to 'native', line endings in string source parts will be converted to
the platform native line-ending as specified by require('node:os').EOL.
type <string> The Blob content-type. The intent is for type to convey
the MIME media type of the data, however no validation of the type format
is performed.



Creates a new Blob object containing a concatenation of the given sources.
<ArrayBuffer>, <TypedArray>, <DataView>, and <Buffer> sources are copied into
the 'Blob' and can therefore be safely modified after the 'Blob' is created.
String sources are encoded as UTF-8 byte sequences and copied into the Blob.
Unmatched surrogate pairs within each string part will be replaced by Unicode
U+FFFD replacement characters.

blob.arrayBuffer()#

Added in: v15.7.0, v14.18.0


Returns: <Promise>

Returns a promise that fulfills with an <ArrayBuffer> containing a copy of
the Blob data.

blob.bytes()#

Added in: v22.3.0, v20.16.0

The blob.bytes() method returns the byte of the Blob object as a Promise<Uint8Array>.
const blob = new Blob(['hello']);
blob.bytes().then((bytes) => {
  console.log(bytes); // Outputs: Uint8Array(5) [ 104, 101, 108, 108, 111 ]
}); copy

blob.size#

Added in: v15.7.0, v14.18.0

The total size of the Blob in bytes.

blob.slice([start[, end[, type]]])#

Added in: v15.7.0, v14.18.0


start <number> The starting index.
end <number> The ending index.
type <string> The content-type for the new Blob

Creates and returns a new Blob containing a subset of this Blob objects
data. The original Blob is not altered.

blob.stream()#

Added in: v16.7.0


Returns: <ReadableStream>

Returns a new ReadableStream that allows the content of the Blob to be read.

blob.text()#

Added in: v15.7.0, v14.18.0


Returns: <Promise>

Returns a promise that fulfills with the contents of the Blob decoded as a
UTF-8 string.

blob.type#

Added in: v15.7.0, v14.18.0


Type: <string>

The content-type of the Blob.

Blob objects and MessageChannel#
Once a <Blob> object is created, it can be sent via MessagePort to multiple
destinations without transferring or immediately copying the data. The data
contained by the Blob is copied only when the arrayBuffer() or text()
methods are called.

import { Blob } from 'node:buffer';
import { setTimeout as delay } from 'node:timers/promises';

const blob = new Blob(['hello there']);

const mc1 = new MessageChannel();
const mc2 = new MessageChannel();

mc1.port1.onmessage = async ({ data }) => {
  console.log(await data.arrayBuffer());
  mc1.port1.close();
};

mc2.port1.onmessage = async ({ data }) => {
  await delay(1000);
  console.log(await data.arrayBuffer());
  mc2.port1.close();
};

mc1.port2.postMessage(blob);
mc2.port2.postMessage(blob);

// The Blob is still usable after posting.
blob.text().then(console.log);const { Blob } = require('node:buffer');
const { setTimeout: delay } = require('node:timers/promises');

const blob = new Blob(['hello there']);

const mc1 = new MessageChannel();
const mc2 = new MessageChannel();

mc1.port1.onmessage = async ({ data }) => {
  console.log(await data.arrayBuffer());
  mc1.port1.close();
};

mc2.port1.onmessage = async ({ data }) => {
  await delay(1000);
  console.log(await data.arrayBuffer());
  mc2.port1.close();
};

mc1.port2.postMessage(blob);
mc2.port2.postMessage(blob);

// The Blob is still usable after posting.
blob.text().then(console.log);copy

Class: Buffer#
The Buffer class is a global type for dealing with binary data directly.
It can be constructed in a variety of ways.

Static method: Buffer.alloc(size[, fill[, encoding]])#

History

VersionChanges
v20.0.0
Throw ERR_INVALID_ARG_TYPE or ERR_OUT_OF_RANGE instead of ERR_INVALID_ARG_VALUE for invalid input arguments.
v15.0.0
Throw ERR_INVALID_ARG_VALUE instead of ERR_INVALID_OPT_VALUE for invalid input arguments.
v10.0.0
Attempting to fill a non-zero length buffer with a zero length buffer triggers a thrown exception.
v10.0.0
Specifying an invalid string for fill triggers a thrown exception.
v8.9.3
Specifying an invalid string for fill now results in a zero-filled buffer.
v5.10.0
Added in: v5.10.0




size <integer> The desired length of the new Buffer.
fill <string> | <Buffer> | <Uint8Array> | <integer> A value to pre-fill the new Buffer
with. Default: 0.
encoding <string> If fill is a string, this is its encoding.
Default: 'utf8'.
Returns: <Buffer>

Allocates a new Buffer of size bytes. If fill is undefined, the
Buffer will be zero-filled.

import { Buffer } from 'node:buffer';

const buf = Buffer.alloc(5);

console.log(buf);
// Prints: <Buffer 00 00 00 00 00>const { Buffer } = require('node:buffer');

const buf = Buffer.alloc(5);

console.log(buf);
// Prints: <Buffer 00 00 00 00 00>copy
If size is larger than
buffer.constants.MAX_LENGTH or smaller than 0, ERR_OUT_OF_RANGE
is thrown.
If fill is specified, the allocated Buffer will be initialized by calling
buf.fill(fill).

import { Buffer } from 'node:buffer';

const buf = Buffer.alloc(5, 'a');

console.log(buf);
// Prints: <Buffer 61 61 61 61 61>const { Buffer } = require('node:buffer');

const buf = Buffer.alloc(5, 'a');

console.log(buf);
// Prints: <Buffer 61 61 61 61 61>copy
If both fill and encoding are specified, the allocated Buffer will be
initialized by calling buf.fill(fill, encoding).

import { Buffer } from 'node:buffer';

const buf = Buffer.alloc(11, 'aGVsbG8gd29ybGQ=', 'base64');

console.log(buf);
// Prints: <Buffer 68 65 6c 6c 6f 20 77 6f 72 6c 64>const { Buffer } = require('node:buffer');

const buf = Buffer.alloc(11, 'aGVsbG8gd29ybGQ=', 'base64');

console.log(buf);
// Prints: <Buffer 68 65 6c 6c 6f 20 77 6f 72 6c 64>copy
Calling Buffer.alloc() can be measurably slower than the alternative
Buffer.allocUnsafe() but ensures that the newly created Buffer instance
contents will never contain sensitive data from previous allocations, including
data that might not have been allocated for Buffers.
A TypeError will be thrown if size is not a number.

Static method: Buffer.allocUnsafe(size)#

History

VersionChanges
v20.0.0
Throw ERR_INVALID_ARG_TYPE or ERR_OUT_OF_RANGE instead of ERR_INVALID_ARG_VALUE for invalid input arguments.
v15.0.0
Throw ERR_INVALID_ARG_VALUE instead of ERR_INVALID_OPT_VALUE for invalid input arguments.
v7.0.0
Passing a negative size will now throw an error.
v5.10.0
Added in: v5.10.0




size <integer> The desired length of the new Buffer.
Returns: <Buffer>

Allocates a new Buffer of size bytes. If size is larger than
buffer.constants.MAX_LENGTH or smaller than 0, ERR_OUT_OF_RANGE
is thrown.
The underlying memory for Buffer instances created in this way is not
initialized. The contents of the newly created Buffer are unknown and
may contain sensitive data. Use Buffer.alloc() instead to initialize
Buffer instances with zeroes.

import { Buffer } from 'node:buffer';

const buf = Buffer.allocUnsafe(10);

console.log(buf);
// Prints (contents may vary): <Buffer a0 8b 28 3f 01 00 00 00 50 32>

buf.fill(0);

console.log(buf);
// Prints: <Buffer 00 00 00 00 00 00 00 00 00 00>const { Buffer } = require('node:buffer');

const buf = Buffer.allocUnsafe(10);

console.log(buf);
// Prints (contents may vary): <Buffer a0 8b 28 3f 01 00 00 00 50 32>

buf.fill(0);

console.log(buf);
// Prints: <Buffer 00 00 00 00 00 00 00 00 00 00>copy
A TypeError will be thrown if size is not a number.
The Buffer module pre-allocates an internal Buffer instance of
size Buffer.poolSize that is used as a pool for the fast allocation of new
Buffer instances created using Buffer.allocUnsafe(), Buffer.from(array),
Buffer.from(string), and Buffer.concat() only when size is less than
Buffer.poolSize >>> 1 (floor of Buffer.poolSize divided by two).
Use of this pre-allocated internal memory pool is a key difference between
calling Buffer.alloc(size, fill) vs. Buffer.allocUnsafe(size).fill(fill).
Specifically, Buffer.alloc(size, fill) will never use the internal Buffer
pool, while Buffer.allocUnsafe(size).fill(fill) will use the internal
Buffer pool if size is less than or equal to half Buffer.poolSize. The
difference is subtle but can be important when an application requires the
additional performance that Buffer.allocUnsafe() provides.

Static method: Buffer.allocUnsafeSlow(size)#

History

VersionChanges
v20.0.0
Throw ERR_INVALID_ARG_TYPE or ERR_OUT_OF_RANGE instead of ERR_INVALID_ARG_VALUE for invalid input arguments.
v15.0.0
Throw ERR_INVALID_ARG_VALUE instead of ERR_INVALID_OPT_VALUE for invalid input arguments.
v5.12.0
Added in: v5.12.0




size <integer> The desired length of the new Buffer.
Returns: <Buffer>

Allocates a new Buffer of size bytes. If size is larger than
buffer.constants.MAX_LENGTH or smaller than 0, ERR_OUT_OF_RANGE
is thrown. A zero-length Buffer is created if size is 0.
The underlying memory for Buffer instances created in this way is not
initialized. The contents of the newly created Buffer are unknown and
may contain sensitive data. Use buf.fill(0) to initialize
such Buffer instances with zeroes.
When using Buffer.allocUnsafe() to allocate new Buffer instances,
allocations less than Buffer.poolSize >>> 1 (4KiB when default poolSize is used) are sliced
from a single pre-allocated Buffer. This allows applications to avoid the
garbage collection overhead of creating many individually allocated Buffer
instances. This approach improves both performance and memory usage by
eliminating the need to track and clean up as many individual ArrayBuffer objects.
However, in the case where a developer may need to retain a small chunk of
memory from a pool for an indeterminate amount of time, it may be appropriate
to create an un-pooled Buffer instance using Buffer.allocUnsafeSlow() and
then copying out the relevant bits.

import { Buffer } from 'node:buffer';

// Need to keep around a few small chunks of memory.
const store = [];

socket.on('readable', () => {
  let data;
  while (null !== (data = readable.read())) {
    // Allocate for retained data.
    const sb = Buffer.allocUnsafeSlow(10);

    // Copy the data into the new allocation.
    data.copy(sb, 0, 0, 10);

    store.push(sb);
  }
});const { Buffer } = require('node:buffer');

// Need to keep around a few small chunks of memory.
const store = [];

socket.on('readable', () => {
  let data;
  while (null !== (data = readable.read())) {
    // Allocate for retained data.
    const sb = Buffer.allocUnsafeSlow(10);

    // Copy the data into the new allocation.
    data.copy(sb, 0, 0, 10);

    store.push(sb);
  }
});copy
A TypeError will be thrown if size is not a number.

Static method: Buffer.byteLength(string[, encoding])#

History

VersionChanges
v7.0.0
Passing invalid input will now throw an error.
v5.10.0
The string parameter can now be any TypedArray, DataView or ArrayBuffer.
v0.1.90
Added in: v0.1.90




string <string> | <Buffer> | <TypedArray> | <DataView> | <ArrayBuffer> | <SharedArrayBuffer> A
value to calculate the length of.
encoding <string> If string is a string, this is its encoding.
Default: 'utf8'.
Returns: <integer> The number of bytes contained within string.

Returns the byte length of a string when encoded using encoding.
This is not the same as String.prototype.length, which does not account
for the encoding that is used to convert the string into bytes.
For 'base64', 'base64url', and 'hex', this function assumes valid input.
For strings that contain non-base64/hex-encoded data (e.g. whitespace), the
return value might be greater than the length of a Buffer created from the
string.

import { Buffer } from 'node:buffer';

const str = '\u00bd + \u00bc = \u00be';

console.log(`${str}: ${str.length} characters, ` +
            `${Buffer.byteLength(str, 'utf8')} bytes`);
// Prints: ½ + ¼ = ¾: 9 characters, 12 bytesconst { Buffer } = require('node:buffer');

const str = '\u00bd + \u00bc = \u00be';

console.log(`${str}: ${str.length} characters, ` +
            `${Buffer.byteLength(str, 'utf8')} bytes`);
// Prints: ½ + ¼ = ¾: 9 characters, 12 bytescopy
When string is a <Buffer> | <DataView> | <TypedArray> | <ArrayBuffer> | <SharedArrayBuffer>,
the byte length as reported by .byteLength is returned.

Static method: Buffer.compare(buf1, buf2)#

History

VersionChanges
v8.0.0
The arguments can now be Uint8Arrays.
v0.11.13
Added in: v0.11.13




buf1 <Buffer> | <Uint8Array>
buf2 <Buffer> | <Uint8Array>
Returns: <integer> Either -1, 0, or 1, depending on the result of the
comparison. See buf.compare() for details.

Compares buf1 to buf2, typically for the purpose of sorting arrays of
Buffer instances. This is equivalent to calling
buf1.compare(buf2).

import { Buffer } from 'node:buffer';

const buf1 = Buffer.from('1234');
const buf2 = Buffer.from('0123');
const arr = [buf1, buf2];

console.log(arr.sort(Buffer.compare));
// Prints: [ <Buffer 30 31 32 33>, <Buffer 31 32 33 34> ]
// (This result is equal to: [buf2, buf1].)const { Buffer } = require('node:buffer');

const buf1 = Buffer.from('1234');
const buf2 = Buffer.from('0123');
const arr = [buf1, buf2];

console.log(arr.sort(Buffer.compare));
// Prints: [ <Buffer 30 31 32 33>, <Buffer 31 32 33 34> ]
// (This result is equal to: [buf2, buf1].)copy

Static method: Buffer.concat(list[, totalLength])#

History

VersionChanges
v8.0.0
The elements of list can now be Uint8Arrays.
v0.7.11
Added in: v0.7.11




list <Buffer[]> | <Uint8Array[]> List of Buffer or <Uint8Array>
instances to concatenate.
totalLength <integer> Total length of the Buffer instances in list
when concatenated.
Returns: <Buffer>

Returns a new Buffer which is the result of concatenating all the Buffer
instances in the list together.
If the list has no items, or if the totalLength is 0, then a new zero-length
Buffer is returned.
If totalLength is not provided, it is calculated from the Buffer instances
in list by adding their lengths.
If totalLength is provided, it is coerced to an unsigned integer. If the
combined length of the Buffers in list exceeds totalLength, the result is
truncated to totalLength. If the combined length of the Buffers in list is
less than totalLength, the remaining space is filled with zeros.

import { Buffer } from 'node:buffer';

// Create a single `Buffer` from a list of three `Buffer` instances.

const buf1 = Buffer.alloc(10);
const buf2 = Buffer.alloc(14);
const buf3 = Buffer.alloc(18);
const totalLength = buf1.length + buf2.length + buf3.length;

console.log(totalLength);
// Prints: 42

const bufA = Buffer.concat([buf1, buf2, buf3], totalLength);

console.log(bufA);
// Prints: <Buffer 00 00 00 00 ...>
console.log(bufA.length);
// Prints: 42const { Buffer } = require('node:buffer');

// Create a single `Buffer` from a list of three `Buffer` instances.

const buf1 = Buffer.alloc(10);
const buf2 = Buffer.alloc(14);
const buf3 = Buffer.alloc(18);
const totalLength = buf1.length + buf2.length + buf3.length;

console.log(totalLength);
// Prints: 42

const bufA = Buffer.concat([buf1, buf2, buf3], totalLength);

console.log(bufA);
// Prints: <Buffer 00 00 00 00 ...>
console.log(bufA.length);
// Prints: 42copy
Buffer.concat() may also use the internal Buffer pool like
Buffer.allocUnsafe() does.

Static method: Buffer.copyBytesFrom(view[, offset[, length]])#

Added in: v19.8.0, v18.16.0


view <TypedArray> The <TypedArray> to copy.
offset <integer> The starting offset within view. Default: 0.
length <integer> The number of elements from view to copy.
Default: view.length - offset.
Returns: <Buffer>

Copies the underlying memory of view into a new Buffer.
const u16 = new Uint16Array([0, 0xffff]);
const buf = Buffer.copyBytesFrom(u16, 1, 1);
u16[1] = 0;
console.log(buf.length); // 2
console.log(buf[0]); // 255
console.log(buf[1]); // 255 copy

Static method: Buffer.from(array)#

Added in: v5.10.0


array <integer[]>
Returns: <Buffer>

Allocates a new Buffer using an array of bytes in the range 0 – 255.
Array entries outside that range will be truncated to fit into it.

import { Buffer } from 'node:buffer';

// Creates a new Buffer containing the UTF-8 bytes of the string 'buffer'.
const buf = Buffer.from([0x62, 0x75, 0x66, 0x66, 0x65, 0x72]);const { Buffer } = require('node:buffer');

// Creates a new Buffer containing the UTF-8 bytes of the string 'buffer'.
const buf = Buffer.from([0x62, 0x75, 0x66, 0x66, 0x65, 0x72]);copy
If array is an Array-like object (that is, one with a length property of
type number), it is treated as if it is an array, unless it is a Buffer or
a Uint8Array. This means all other TypedArray variants get treated as an
Array. To create a Buffer from the bytes backing a TypedArray, use
Buffer.copyBytesFrom().
A TypeError will be thrown if array is not an Array or another type
appropriate for Buffer.from() variants.
Buffer.from(array) and Buffer.from(string) may also use the internal
Buffer pool like Buffer.allocUnsafe() does.

Static method: Buffer.from(arrayBuffer[, byteOffset[, length]])#

Added in: v5.10.0


arrayBuffer <ArrayBuffer> | <SharedArrayBuffer> An <ArrayBuffer>,
<SharedArrayBuffer>, for example the .buffer property of a
<TypedArray>.
byteOffset <integer> Index of first byte to expose. Default: 0.
length <integer> Number of bytes to expose.
Default: arrayBuffer.byteLength - byteOffset.
Returns: <Buffer>

This creates a view of the <ArrayBuffer> without copying the underlying
memory. For example, when passed a reference to the .buffer property of a
<TypedArray> instance, the newly created Buffer will share the same
allocated memory as the <TypedArray>'s underlying ArrayBuffer.

import { Buffer } from 'node:buffer';

const arr = new Uint16Array(2);

arr[0] = 5000;
arr[1] = 4000;

// Shares memory with `arr`.
const buf = Buffer.from(arr.buffer);

console.log(buf);
// Prints: <Buffer 88 13 a0 0f>

// Changing the original Uint16Array changes the Buffer also.
arr[1] = 6000;

console.log(buf);
// Prints: <Buffer 88 13 70 17>const { Buffer } = require('node:buffer');

const arr = new Uint16Array(2);

arr[0] = 5000;
arr[1] = 4000;

// Shares memory with `arr`.
const buf = Buffer.from(arr.buffer);

console.log(buf);
// Prints: <Buffer 88 13 a0 0f>

// Changing the original Uint16Array changes the Buffer also.
arr[1] = 6000;

console.log(buf);
// Prints: <Buffer 88 13 70 17>copy
The optional byteOffset and length arguments specify a memory range within
the arrayBuffer that will be shared by the Buffer.

import { Buffer } from 'node:buffer';

const ab = new ArrayBuffer(10);
const buf = Buffer.from(ab, 0, 2);

console.log(buf.length);
// Prints: 2const { Buffer } = require('node:buffer');

const ab = new ArrayBuffer(10);
const buf = Buffer.from(ab, 0, 2);

console.log(buf.length);
// Prints: 2copy
A TypeError will be thrown if arrayBuffer is not an <ArrayBuffer> or a
<SharedArrayBuffer> or another type appropriate for Buffer.from()
variants.
It is important to remember that a backing ArrayBuffer can cover a range
of memory that extends beyond the bounds of a TypedArray view. A new
Buffer created using the buffer property of a TypedArray may extend
beyond the range of the TypedArray:

import { Buffer } from 'node:buffer';

const arrA = Uint8Array.from([0x63, 0x64, 0x65, 0x66]); // 4 elements
const arrB = new Uint8Array(arrA.buffer, 1, 2); // 2 elements
console.log(arrA.buffer === arrB.buffer); // true

const buf = Buffer.from(arrB.buffer);
console.log(buf);
// Prints: <Buffer 63 64 65 66>const { Buffer } = require('node:buffer');

const arrA = Uint8Array.from([0x63, 0x64, 0x65, 0x66]); // 4 elements
const arrB = new Uint8Array(arrA.buffer, 1, 2); // 2 elements
console.log(arrA.buffer === arrB.buffer); // true

const buf = Buffer.from(arrB.buffer);
console.log(buf);
// Prints: <Buffer 63 64 65 66>copy

Static method: Buffer.from(buffer)#

Added in: v5.10.0


buffer <Buffer> | <Uint8Array> An existing Buffer or <Uint8Array> from
which to copy data.
Returns: <Buffer>

Copies the passed buffer data onto a new Buffer instance.

import { Buffer } from 'node:buffer';

const buf1 = Buffer.from('buffer');
const buf2 = Buffer.from(buf1);

buf1[0] = 0x61;

console.log(buf1.toString());
// Prints: auffer
console.log(buf2.toString());
// Prints: bufferconst { Buffer } = require('node:buffer');

const buf1 = Buffer.from('buffer');
const buf2 = Buffer.from(buf1);

buf1[0] = 0x61;

console.log(buf1.toString());
// Prints: auffer
console.log(buf2.toString());
// Prints: buffercopy
A TypeError will be thrown if buffer is not a Buffer or another type
appropriate for Buffer.from() variants.

Static method: Buffer.from(object[, offsetOrEncoding[, length]])#

Added in: v8.2.0


object <Object> An object supporting Symbol.toPrimitive or valueOf().
offsetOrEncoding <integer> | <string> A byte-offset or encoding.
length <integer> A length.
Returns: <Buffer>

For objects whose valueOf() function returns a value not strictly equal to
object, returns Buffer.from(object.valueOf(), offsetOrEncoding, length).

import { Buffer } from 'node:buffer';

const buf = Buffer.from(new String('this is a test'));
// Prints: <Buffer 74 68 69 73 20 69 73 20 61 20 74 65 73 74>const { Buffer } = require('node:buffer');

const buf = Buffer.from(new String('this is a test'));
// Prints: <Buffer 74 68 69 73 20 69 73 20 61 20 74 65 73 74>copy
For objects that support Symbol.toPrimitive, returns
Buffer.from(object[Symbol.toPrimitive]('string'), offsetOrEncoding).

import { Buffer } from 'node:buffer';

class Foo {
  [Symbol.toPrimitive]() {
    return 'this is a test';
  }
}

const buf = Buffer.from(new Foo(), 'utf8');
// Prints: <Buffer 74 68 69 73 20 69 73 20 61 20 74 65 73 74>const { Buffer } = require('node:buffer');

class Foo {
  [Symbol.toPrimitive]() {
    return 'this is a test';
  }
}

const buf = Buffer.from(new Foo(), 'utf8');
// Prints: <Buffer 74 68 69 73 20 69 73 20 61 20 74 65 73 74>copy
A TypeError will be thrown if object does not have the mentioned methods or
is not of another type appropriate for Buffer.from() variants.

Static method: Buffer.from(string[, encoding])#

Added in: v5.10.0


string <string> A string to encode.
encoding <string> The encoding of string. Default: 'utf8'.
Returns: <Buffer>

Creates a new Buffer containing string. The encoding parameter identifies
the character encoding to be used when converting string into bytes.

import { Buffer } from 'node:buffer';

const buf1 = Buffer.from('this is a tést');
const buf2 = Buffer.from('7468697320697320612074c3a97374', 'hex');

console.log(buf1.toString());
// Prints: this is a tést
console.log(buf2.toString());
// Prints: this is a tést
console.log(buf1.toString('latin1'));
// Prints: this is a tÃ©stconst { Buffer } = require('node:buffer');

const buf1 = Buffer.from('this is a tést');
const buf2 = Buffer.from('7468697320697320612074c3a97374', 'hex');

console.log(buf1.toString());
// Prints: this is a tést
console.log(buf2.toString());
// Prints: this is a tést
console.log(buf1.toString('latin1'));
// Prints: this is a tÃ©stcopy
A TypeError will be thrown if string is not a string or another type
appropriate for Buffer.from() variants.
Buffer.from(string) may also use the internal Buffer pool like
Buffer.allocUnsafe() does.

Static method: Buffer.isBuffer(obj)#

Added in: v0.1.101


obj <Object>
Returns: <boolean>

Returns true if obj is a Buffer, false otherwise.

import { Buffer } from 'node:buffer';

Buffer.isBuffer(Buffer.alloc(10)); // true
Buffer.isBuffer(Buffer.from('foo')); // true
Buffer.isBuffer('a string'); // false
Buffer.isBuffer([]); // false
Buffer.isBuffer(new Uint8Array(1024)); // falseconst { Buffer } = require('node:buffer');

Buffer.isBuffer(Buffer.alloc(10)); // true
Buffer.isBuffer(Buffer.from('foo')); // true
Buffer.isBuffer('a string'); // false
Buffer.isBuffer([]); // false
Buffer.isBuffer(new Uint8Array(1024)); // falsecopy

Static method: Buffer.isEncoding(encoding)#

Added in: v0.9.1


encoding <string> A character encoding name to check.
Returns: <boolean>

Returns true if encoding is the name of a supported character encoding,
or false otherwise.

import { Buffer } from 'node:buffer';

console.log(Buffer.isEncoding('utf8'));
// Prints: true

console.log(Buffer.isEncoding('hex'));
// Prints: true

console.log(Buffer.isEncoding('utf/8'));
// Prints: false

console.log(Buffer.isEncoding(''));
// Prints: falseconst { Buffer } = require('node:buffer');

console.log(Buffer.isEncoding('utf8'));
// Prints: true

console.log(Buffer.isEncoding('hex'));
// Prints: true

console.log(Buffer.isEncoding('utf/8'));
// Prints: false

console.log(Buffer.isEncoding(''));
// Prints: falsecopy

Class property: Buffer.poolSize#

Added in: v0.11.3


<integer> Default: 8192

This is the size (in bytes) of pre-allocated internal Buffer instances used
for pooling. This value may be modified.

buf[index]#

index <integer>

The index operator [index] can be used to get and set the octet at position
index in buf. The values refer to individual bytes, so the legal value
range is between 0x00 and 0xFF (hex) or 0 and 255 (decimal).
This operator is inherited from Uint8Array, so its behavior on out-of-bounds
access is the same as Uint8Array. In other words, buf[index] returns
undefined when index is negative or greater or equal to buf.length, and
buf[index] = value does not modify the buffer if index is negative or
>= buf.length.

import { Buffer } from 'node:buffer';

// Copy an ASCII string into a `Buffer` one byte at a time.
// (This only works for ASCII-only strings. In general, one should use
// `Buffer.from()` to perform this conversion.)

const str = 'Node.js';
const buf = Buffer.allocUnsafe(str.length);

for (let i = 0; i < str.length; i++) {
  buf[i] = str.charCodeAt(i);
}

console.log(buf.toString('utf8'));
// Prints: Node.jsconst { Buffer } = require('node:buffer');

// Copy an ASCII string into a `Buffer` one byte at a time.
// (This only works for ASCII-only strings. In general, one should use
// `Buffer.from()` to perform this conversion.)

const str = 'Node.js';
const buf = Buffer.allocUnsafe(str.length);

for (let i = 0; i < str.length; i++) {
  buf[i] = str.charCodeAt(i);
}

console.log(buf.toString('utf8'));
// Prints: Node.jscopy

buf.buffer#

<ArrayBuffer> The underlying ArrayBuffer object based on which this Buffer
object is created.

This ArrayBuffer is not guaranteed to correspond exactly to the original
Buffer. See the notes on buf.byteOffset for details.

import { Buffer } from 'node:buffer';

const arrayBuffer = new ArrayBuffer(16);
const buffer = Buffer.from(arrayBuffer);

console.log(buffer.buffer === arrayBuffer);
// Prints: trueconst { Buffer } = require('node:buffer');

const arrayBuffer = new ArrayBuffer(16);
const buffer = Buffer.from(arrayBuffer);

console.log(buffer.buffer === arrayBuffer);
// Prints: truecopy

buf.byteOffset#

<integer> The byteOffset of the Buffer's underlying ArrayBuffer object.

When setting byteOffset in Buffer.from(ArrayBuffer, byteOffset, length),
or sometimes when allocating a Buffer smaller than Buffer.poolSize, the
buffer does not start from a zero offset on the underlying ArrayBuffer.
This can cause problems when accessing the underlying ArrayBuffer directly
using buf.buffer, as other parts of the ArrayBuffer may be unrelated
to the Buffer object itself.
A common issue when creating a TypedArray object that shares its memory with
a Buffer is that in this case one needs to specify the byteOffset correctly:

import { Buffer } from 'node:buffer';

// Create a buffer smaller than `Buffer.poolSize`.
const nodeBuffer = Buffer.from([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]);

// When casting the Node.js Buffer to an Int8Array, use the byteOffset
// to refer only to the part of `nodeBuffer.buffer` that contains the memory
// for `nodeBuffer`.
new Int8Array(nodeBuffer.buffer, nodeBuffer.byteOffset, nodeBuffer.length);const { Buffer } = require('node:buffer');

// Create a buffer smaller than `Buffer.poolSize`.
const nodeBuffer = Buffer.from([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]);

// When casting the Node.js Buffer to an Int8Array, use the byteOffset
// to refer only to the part of `nodeBuffer.buffer` that contains the memory
// for `nodeBuffer`.
new Int8Array(nodeBuffer.buffer, nodeBuffer.byteOffset, nodeBuffer.length);copy

buf.compare(target[, targetStart[, targetEnd[, sourceStart[, sourceEnd]]]])#

History

VersionChanges
v8.0.0
The target parameter can now be a Uint8Array.
v5.11.0
Additional parameters for specifying offsets are supported now.
v0.11.13
Added in: v0.11.13




target <Buffer> | <Uint8Array> A Buffer or <Uint8Array> with which to
compare buf.
targetStart <integer> The offset within target at which to begin
comparison. Default: 0.
targetEnd <integer> The offset within target at which to end comparison
(not inclusive). Default: target.length.
sourceStart <integer> The offset within buf at which to begin comparison.
Default: 0.
sourceEnd <integer> The offset within buf at which to end comparison
(not inclusive). Default: buf.length.
Returns: <integer>

Compares buf with target and returns a number indicating whether buf
comes before, after, or is the same as target in sort order.
Comparison is based on the actual sequence of bytes in each Buffer.

0 is returned if target is the same as buf
1 is returned if target should come before buf when sorted.
-1 is returned if target should come after buf when sorted.


import { Buffer } from 'node:buffer';

const buf1 = Buffer.from('ABC');
const buf2 = Buffer.from('BCD');
const buf3 = Buffer.from('ABCD');

console.log(buf1.compare(buf1));
// Prints: 0
console.log(buf1.compare(buf2));
// Prints: -1
console.log(buf1.compare(buf3));
// Prints: -1
console.log(buf2.compare(buf1));
// Prints: 1
console.log(buf2.compare(buf3));
// Prints: 1
console.log([buf1, buf2, buf3].sort(Buffer.compare));
// Prints: [ <Buffer 41 42 43>, <Buffer 41 42 43 44>, <Buffer 42 43 44> ]
// (This result is equal to: [buf1, buf3, buf2].)const { Buffer } = require('node:buffer');

const buf1 = Buffer.from('ABC');
const buf2 = Buffer.from('BCD');
const buf3 = Buffer.from('ABCD');

console.log(buf1.compare(buf1));
// Prints: 0
console.log(buf1.compare(buf2));
// Prints: -1
console.log(buf1.compare(buf3));
// Prints: -1
console.log(buf2.compare(buf1));
// Prints: 1
console.log(buf2.compare(buf3));
// Prints: 1
console.log([buf1, buf2, buf3].sort(Buffer.compare));
// Prints: [ <Buffer 41 42 43>, <Buffer 41 42 43 44>, <Buffer 42 43 44> ]
// (This result is equal to: [buf1, buf3, buf2].)copy
The optional targetStart, targetEnd, sourceStart, and sourceEnd
arguments can be used to limit the comparison to specific ranges within target
and buf respectively.

import { Buffer } from 'node:buffer';

const buf1 = Buffer.from([1, 2, 3, 4, 5, 6, 7, 8, 9]);
const buf2 = Buffer.from([5, 6, 7, 8, 9, 1, 2, 3, 4]);

console.log(buf1.compare(buf2, 5, 9, 0, 4));
// Prints: 0
console.log(buf1.compare(buf2, 0, 6, 4));
// Prints: -1
console.log(buf1.compare(buf2, 5, 6, 5));
// Prints: 1const { Buffer } = require('node:buffer');

const buf1 = Buffer.from([1, 2, 3, 4, 5, 6, 7, 8, 9]);
const buf2 = Buffer.from([5, 6, 7, 8, 9, 1, 2, 3, 4]);

console.log(buf1.compare(buf2, 5, 9, 0, 4));
// Prints: 0
console.log(buf1.compare(buf2, 0, 6, 4));
// Prints: -1
console.log(buf1.compare(buf2, 5, 6, 5));
// Prints: 1copy
ERR_OUT_OF_RANGE is thrown if targetStart < 0, sourceStart < 0,
targetEnd > target.byteLength, or sourceEnd > source.byteLength.

buf.copy(target[, targetStart[, sourceStart[, sourceEnd]]])#

Added in: v0.1.90


target <Buffer> | <Uint8Array> A Buffer or <Uint8Array> to copy into.
targetStart <integer> The offset within target at which to begin
writing. Default: 0.
sourceStart <integer> The offset within buf from which to begin copying.
Default: 0.
sourceEnd <integer> The offset within buf at which to stop copying (not
inclusive). Default: buf.length.
Returns: <integer> The number of bytes copied.

Copies data from a region of buf to a region in target, even if the target
memory region overlaps with buf.
TypedArray.prototype.set() performs the same operation, and is available
for all TypedArrays, including Node.js Buffers, although it takes
different function arguments.

import { Buffer } from 'node:buffer';

// Create two `Buffer` instances.
const buf1 = Buffer.allocUnsafe(26);
const buf2 = Buffer.allocUnsafe(26).fill('!');

for (let i = 0; i < 26; i++) {
  // 97 is the decimal ASCII value for 'a'.
  buf1[i] = i + 97;
}

// Copy `buf1` bytes 16 through 19 into `buf2` starting at byte 8 of `buf2`.
buf1.copy(buf2, 8, 16, 20);
// This is equivalent to:
// buf2.set(buf1.subarray(16, 20), 8);

console.log(buf2.toString('ascii', 0, 25));
// Prints: !!!!!!!!qrst!!!!!!!!!!!!!const { Buffer } = require('node:buffer');

// Create two `Buffer` instances.
const buf1 = Buffer.allocUnsafe(26);
const buf2 = Buffer.allocUnsafe(26).fill('!');

for (let i = 0; i < 26; i++) {
  // 97 is the decimal ASCII value for 'a'.
  buf1[i] = i + 97;
}

// Copy `buf1` bytes 16 through 19 into `buf2` starting at byte 8 of `buf2`.
buf1.copy(buf2, 8, 16, 20);
// This is equivalent to:
// buf2.set(buf1.subarray(16, 20), 8);

console.log(buf2.toString('ascii', 0, 25));
// Prints: !!!!!!!!qrst!!!!!!!!!!!!!copy

import { Buffer } from 'node:buffer';

// Create a `Buffer` and copy data from one region to an overlapping region
// within the same `Buffer`.

const buf = Buffer.allocUnsafe(26);

for (let i = 0; i < 26; i++) {
  // 97 is the decimal ASCII value for 'a'.
  buf[i] = i + 97;
}

buf.copy(buf, 0, 4, 10);

console.log(buf.toString());
// Prints: efghijghijklmnopqrstuvwxyzconst { Buffer } = require('node:buffer');

// Create a `Buffer` and copy data from one region to an overlapping region
// within the same `Buffer`.

const buf = Buffer.allocUnsafe(26);

for (let i = 0; i < 26; i++) {
  // 97 is the decimal ASCII value for 'a'.
  buf[i] = i + 97;
}

buf.copy(buf, 0, 4, 10);

console.log(buf.toString());
// Prints: efghijghijklmnopqrstuvwxyzcopy

buf.entries()#

Added in: v1.1.0


Returns: <Iterator>

Creates and returns an iterator of [index, byte] pairs from the contents
of buf.

import { Buffer } from 'node:buffer';

// Log the entire contents of a `Buffer`.

const buf = Buffer.from('buffer');

for (const pair of buf.entries()) {
  console.log(pair);
}
// Prints:
//   [0, 98]
//   [1, 117]
//   [2, 102]
//   [3, 102]
//   [4, 101]
//   [5, 114]const { Buffer } = require('node:buffer');

// Log the entire contents of a `Buffer`.

const buf = Buffer.from('buffer');

for (const pair of buf.entries()) {
  console.log(pair);
}
// Prints:
//   [0, 98]
//   [1, 117]
//   [2, 102]
//   [3, 102]
//   [4, 101]
//   [5, 114]copy

buf.equals(otherBuffer)#

History

VersionChanges
v8.0.0
The arguments can now be Uint8Arrays.
v0.11.13
Added in: v0.11.13




otherBuffer <Buffer> | <Uint8Array> A Buffer or <Uint8Array> with which to
compare buf.
Returns: <boolean>

Returns true if both buf and otherBuffer have exactly the same bytes,
false otherwise. Equivalent to
buf.compare(otherBuffer) === 0.

import { Buffer } from 'node:buffer';

const buf1 = Buffer.from('ABC');
const buf2 = Buffer.from('414243', 'hex');
const buf3 = Buffer.from('ABCD');

console.log(buf1.equals(buf2));
// Prints: true
console.log(buf1.equals(buf3));
// Prints: falseconst { Buffer } = require('node:buffer');

const buf1 = Buffer.from('ABC');
const buf2 = Buffer.from('414243', 'hex');
const buf3 = Buffer.from('ABCD');

console.log(buf1.equals(buf2));
// Prints: true
console.log(buf1.equals(buf3));
// Prints: falsecopy

buf.fill(value[, offset[, end]][, encoding])#

History

VersionChanges
v11.0.0
Throws ERR_OUT_OF_RANGE instead of ERR_INDEX_OUT_OF_RANGE.
v10.0.0
Negative end values throw an ERR_INDEX_OUT_OF_RANGE error.
v10.0.0
Attempting to fill a non-zero length buffer with a zero length buffer triggers a thrown exception.
v10.0.0
Specifying an invalid string for value triggers a thrown exception.
v5.7.0
The encoding parameter is supported now.
v0.5.0
Added in: v0.5.0




value <string> | <Buffer> | <Uint8Array> | <integer> The value with which to fill buf.
Empty value (string, Uint8Array, Buffer) is coerced to 0.
offset <integer> Number of bytes to skip before starting to fill buf.
Default: 0.
end <integer> Where to stop filling buf (not inclusive). Default:
buf.length.
encoding <string> The encoding for value if value is a string.
Default: 'utf8'.
Returns: <Buffer> A reference to buf.

Fills buf with the specified value. If the offset and end are not given,
the entire buf will be filled:

import { Buffer } from 'node:buffer';

// Fill a `Buffer` with the ASCII character 'h'.

const b = Buffer.allocUnsafe(50).fill('h');

console.log(b.toString());
// Prints: hhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh

// Fill a buffer with empty string
const c = Buffer.allocUnsafe(5).fill('');

console.log(c.fill(''));
// Prints: <Buffer 00 00 00 00 00>const { Buffer } = require('node:buffer');

// Fill a `Buffer` with the ASCII character 'h'.

const b = Buffer.allocUnsafe(50).fill('h');

console.log(b.toString());
// Prints: hhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh

// Fill a buffer with empty string
const c = Buffer.allocUnsafe(5).fill('');

console.log(c.fill(''));
// Prints: <Buffer 00 00 00 00 00>copy
value is coerced to a uint32 value if it is not a string, Buffer, or
integer. If the resulting integer is greater than 255 (decimal), buf will be
filled with value & 255.
If the final write of a fill() operation falls on a multi-byte character,
then only the bytes of that character that fit into buf are written:

import { Buffer } from 'node:buffer';

// Fill a `Buffer` with character that takes up two bytes in UTF-8.

console.log(Buffer.allocUnsafe(5).fill('\u0222'));
// Prints: <Buffer c8 a2 c8 a2 c8>const { Buffer } = require('node:buffer');

// Fill a `Buffer` with character that takes up two bytes in UTF-8.

console.log(Buffer.allocUnsafe(5).fill('\u0222'));
// Prints: <Buffer c8 a2 c8 a2 c8>copy
If value contains invalid characters, it is truncated; if no valid
fill data remains, an exception is thrown:

import { Buffer } from 'node:buffer';

const buf = Buffer.allocUnsafe(5);

console.log(buf.fill('a'));
// Prints: <Buffer 61 61 61 61 61>
console.log(buf.fill('aazz', 'hex'));
// Prints: <Buffer aa aa aa aa aa>
console.log(buf.fill('zz', 'hex'));
// Throws an exception.const { Buffer } = require('node:buffer');

const buf = Buffer.allocUnsafe(5);

console.log(buf.fill('a'));
// Prints: <Buffer 61 61 61 61 61>
console.log(buf.fill('aazz', 'hex'));
// Prints: <Buffer aa aa aa aa aa>
console.log(buf.fill('zz', 'hex'));
// Throws an exception.copy

buf.includes(value[, byteOffset][, encoding])#

Added in: v5.3.0


value <string> | <Buffer> | <Uint8Array> | <integer> What to search for.
byteOffset <integer> Where to begin searching in buf. If negative, then
offset is calculated from the end of buf. Default: 0.
encoding <string> If value is a string, this is its encoding.
Default: 'utf8'.
Returns: <boolean> true if value was found in buf, false otherwise.

Equivalent to buf.indexOf() !== -1.

import { Buffer } from 'node:buffer';

const buf = Buffer.from('this is a buffer');

console.log(buf.includes('this'));
// Prints: true
console.log(buf.includes('is'));
// Prints: true
console.log(buf.includes(Buffer.from('a buffer')));
// Prints: true
console.log(buf.includes(97));
// Prints: true (97 is the decimal ASCII value for 'a')
console.log(buf.includes(Buffer.from('a buffer example')));
// Prints: false
console.log(buf.includes(Buffer.from('a buffer example').slice(0, 8)));
// Prints: true
console.log(buf.includes('this', 4));
// Prints: falseconst { Buffer } = require('node:buffer');

const buf = Buffer.from('this is a buffer');

console.log(buf.includes('this'));
// Prints: true
console.log(buf.includes('is'));
// Prints: true
console.log(buf.includes(Buffer.from('a buffer')));
// Prints: true
console.log(buf.includes(97));
// Prints: true (97 is the decimal ASCII value for 'a')
console.log(buf.includes(Buffer.from('a buffer example')));
// Prints: false
console.log(buf.includes(Buffer.from('a buffer example').slice(0, 8)));
// Prints: true
console.log(buf.includes('this', 4));
// Prints: falsecopy

buf.indexOf(value[, byteOffset][, encoding])#

History

VersionChanges
v8.0.0
The value can now be a Uint8Array.
v5.7.0, v4.4.0
When encoding is being passed, the byteOffset parameter is no longer required.
v1.5.0
Added in: v1.5.0




value <string> | <Buffer> | <Uint8Array> | <integer> What to search for.
byteOffset <integer> Where to begin searching in buf. If negative, then
offset is calculated from the end of buf. Default: 0.
encoding <string> If value is a string, this is the encoding used to
determine the binary representation of the string that will be searched for in
buf. Default: 'utf8'.
Returns: <integer> The index of the first occurrence of value in buf, or
-1 if buf does not contain value.

If value is:

a string, value is interpreted according to the character encoding in
encoding.
a Buffer or <Uint8Array>, value will be used in its entirety.
To compare a partial Buffer, use buf.subarray.
a number, value will be interpreted as an unsigned 8-bit integer
value between 0 and 255.


import { Buffer } from 'node:buffer';

const buf = Buffer.from('this is a buffer');

console.log(buf.indexOf('this'));
// Prints: 0
console.log(buf.indexOf('is'));
// Prints: 2
console.log(buf.indexOf(Buffer.from('a buffer')));
// Prints: 8
console.log(buf.indexOf(97));
// Prints: 8 (97 is the decimal ASCII value for 'a')
console.log(buf.indexOf(Buffer.from('a buffer example')));
// Prints: -1
console.log(buf.indexOf(Buffer.from('a buffer example').slice(0, 8)));
// Prints: 8

const utf16Buffer = Buffer.from('\u039a\u0391\u03a3\u03a3\u0395', 'utf16le');

console.log(utf16Buffer.indexOf('\u03a3', 0, 'utf16le'));
// Prints: 4
console.log(utf16Buffer.indexOf('\u03a3', -4, 'utf16le'));
// Prints: 6const { Buffer } = require('node:buffer');

const buf = Buffer.from('this is a buffer');

console.log(buf.indexOf('this'));
// Prints: 0
console.log(buf.indexOf('is'));
// Prints: 2
console.log(buf.indexOf(Buffer.from('a buffer')));
// Prints: 8
console.log(buf.indexOf(97));
// Prints: 8 (97 is the decimal ASCII value for 'a')
console.log(buf.indexOf(Buffer.from('a buffer example')));
// Prints: -1
console.log(buf.indexOf(Buffer.from('a buffer example').slice(0, 8)));
// Prints: 8

const utf16Buffer = Buffer.from('\u039a\u0391\u03a3\u03a3\u0395', 'utf16le');

console.log(utf16Buffer.indexOf('\u03a3', 0, 'utf16le'));
// Prints: 4
console.log(utf16Buffer.indexOf('\u03a3', -4, 'utf16le'));
// Prints: 6copy
If value is not a string, number, or Buffer, this method will throw a
TypeError. If value is a number, it will be coerced to a valid byte value,
an integer between 0 and 255.
If byteOffset is not a number, it will be coerced to a number. If the result
of coercion is NaN or 0, then the entire buffer will be searched. This
behavior matches String.prototype.indexOf().

import { Buffer } from 'node:buffer';

const b = Buffer.from('abcdef');

// Passing a value that's a number, but not a valid byte.
// Prints: 2, equivalent to searching for 99 or 'c'.
console.log(b.indexOf(99.9));
console.log(b.indexOf(256 + 99));

// Passing a byteOffset that coerces to NaN or 0.
// Prints: 1, searching the whole buffer.
console.log(b.indexOf('b', undefined));
console.log(b.indexOf('b', {}));
console.log(b.indexOf('b', null));
console.log(b.indexOf('b', []));const { Buffer } = require('node:buffer');

const b = Buffer.from('abcdef');

// Passing a value that's a number, but not a valid byte.
// Prints: 2, equivalent to searching for 99 or 'c'.
console.log(b.indexOf(99.9));
console.log(b.indexOf(256 + 99));

// Passing a byteOffset that coerces to NaN or 0.
// Prints: 1, searching the whole buffer.
console.log(b.indexOf('b', undefined));
console.log(b.indexOf('b', {}));
console.log(b.indexOf('b', null));
console.log(b.indexOf('b', []));copy
If value is an empty string or empty Buffer and byteOffset is less
than buf.length, byteOffset will be returned. If value is empty and
byteOffset is at least buf.length, buf.length will be returned.

buf.keys()#

Added in: v1.1.0


Returns: <Iterator>

Creates and returns an iterator of buf keys (indexes).

import { Buffer } from 'node:buffer';

const buf = Buffer.from('buffer');

for (const key of buf.keys()) {
  console.log(key);
}
// Prints:
//   0
//   1
//   2
//   3
//   4
//   5const { Buffer } = require('node:buffer');

const buf = Buffer.from('buffer');

for (const key of buf.keys()) {
  console.log(key);
}
// Prints:
//   0
//   1
//   2
//   3
//   4
//   5copy

buf.lastIndexOf(value[, byteOffset][, encoding])#

History

VersionChanges
v8.0.0
The value can now be a Uint8Array.
v6.0.0
Added in: v6.0.0




value <string> | <Buffer> | <Uint8Array> | <integer> What to search for.
byteOffset <integer> Where to begin searching in buf. If negative, then
offset is calculated from the end of buf. Default:
buf.length - 1.
encoding <string> If value is a string, this is the encoding used to
determine the binary representation of the string that will be searched for in
buf. Default: 'utf8'.
Returns: <integer> The index of the last occurrence of value in buf, or
-1 if buf does not contain value.

Identical to buf.indexOf(), except the last occurrence of value is found
rather than the first occurrence.

import { Buffer } from 'node:buffer';

const buf = Buffer.from('this buffer is a buffer');

console.log(buf.lastIndexOf('this'));
// Prints: 0
console.log(buf.lastIndexOf('buffer'));
// Prints: 17
console.log(buf.lastIndexOf(Buffer.from('buffer')));
// Prints: 17
console.log(buf.lastIndexOf(97));
// Prints: 15 (97 is the decimal ASCII value for 'a')
console.log(buf.lastIndexOf(Buffer.from('yolo')));
// Prints: -1
console.log(buf.lastIndexOf('buffer', 5));
// Prints: 5
console.log(buf.lastIndexOf('buffer', 4));
// Prints: -1

const utf16Buffer = Buffer.from('\u039a\u0391\u03a3\u03a3\u0395', 'utf16le');

console.log(utf16Buffer.lastIndexOf('\u03a3', undefined, 'utf16le'));
// Prints: 6
console.log(utf16Buffer.lastIndexOf('\u03a3', -5, 'utf16le'));
// Prints: 4const { Buffer } = require('node:buffer');

const buf = Buffer.from('this buffer is a buffer');

console.log(buf.lastIndexOf('this'));
// Prints: 0
console.log(buf.lastIndexOf('buffer'));
// Prints: 17
console.log(buf.lastIndexOf(Buffer.from('buffer')));
// Prints: 17
console.log(buf.lastIndexOf(97));
// Prints: 15 (97 is the decimal ASCII value for 'a')
console.log(buf.lastIndexOf(Buffer.from('yolo')));
// Prints: -1
console.log(buf.lastIndexOf('buffer', 5));
// Prints: 5
console.log(buf.lastIndexOf('buffer', 4));
// Prints: -1

const utf16Buffer = Buffer.from('\u039a\u0391\u03a3\u03a3\u0395', 'utf16le');

console.log(utf16Buffer.lastIndexOf('\u03a3', undefined, 'utf16le'));
// Prints: 6
console.log(utf16Buffer.lastIndexOf('\u03a3', -5, 'utf16le'));
// Prints: 4copy
If value is not a string, number, or Buffer, this method will throw a
TypeError. If value is a number, it will be coerced to a valid byte value,
an integer between 0 and 255.
If byteOffset is not a number, it will be coerced to a number. Any arguments
that coerce to NaN, like {} or undefined, will search the whole buffer.
This behavior matches String.prototype.lastIndexOf().

import { Buffer } from 'node:buffer';

const b = Buffer.from('abcdef');

// Passing a value that's a number, but not a valid byte.
// Prints: 2, equivalent to searching for 99 or 'c'.
console.log(b.lastIndexOf(99.9));
console.log(b.lastIndexOf(256 + 99));

// Passing a byteOffset that coerces to NaN.
// Prints: 1, searching the whole buffer.
console.log(b.lastIndexOf('b', undefined));
console.log(b.lastIndexOf('b', {}));

// Passing a byteOffset that coerces to 0.
// Prints: -1, equivalent to passing 0.
console.log(b.lastIndexOf('b', null));
console.log(b.lastIndexOf('b', []));const { Buffer } = require('node:buffer');

const b = Buffer.from('abcdef');

// Passing a value that's a number, but not a valid byte.
// Prints: 2, equivalent to searching for 99 or 'c'.
console.log(b.lastIndexOf(99.9));
console.log(b.lastIndexOf(256 + 99));

// Passing a byteOffset that coerces to NaN.
// Prints: 1, searching the whole buffer.
console.log(b.lastIndexOf('b', undefined));
console.log(b.lastIndexOf('b', {}));

// Passing a byteOffset that coerces to 0.
// Prints: -1, equivalent to passing 0.
console.log(b.lastIndexOf('b', null));
console.log(b.lastIndexOf('b', []));copy
If value is an empty string or empty Buffer, byteOffset will be returned.

buf.length#

Added in: v0.1.90


<integer>

Returns the number of bytes in buf.

import { Buffer } from 'node:buffer';

// Create a `Buffer` and write a shorter string to it using UTF-8.

const buf = Buffer.alloc(1234);

console.log(buf.length);
// Prints: 1234

buf.write('some string', 0, 'utf8');

console.log(buf.length);
// Prints: 1234const { Buffer } = require('node:buffer');

// Create a `Buffer` and write a shorter string to it using UTF-8.

const buf = Buffer.alloc(1234);

console.log(buf.length);
// Prints: 1234

buf.write('some string', 0, 'utf8');

console.log(buf.length);
// Prints: 1234copy

buf.parent#

Deprecated since: v8.0.0

Stability: 0 - Deprecated: Use buf.buffer instead.
The buf.parent property is a deprecated alias for buf.buffer.

buf.readBigInt64BE([offset])#

Added in: v12.0.0, v10.20.0


offset <integer> Number of bytes to skip before starting to read. Must
satisfy: 0 <= offset <= buf.length - 8. Default: 0.
Returns: <bigint>

Reads a signed, big-endian 64-bit integer from buf at the specified offset.
Integers read from a Buffer are interpreted as two's complement signed
values.

buf.readBigInt64LE([offset])#

Added in: v12.0.0, v10.20.0


offset <integer> Number of bytes to skip before starting to read. Must
satisfy: 0 <= offset <= buf.length - 8. Default: 0.
Returns: <bigint>

Reads a signed, little-endian 64-bit integer from buf at the specified
offset.
Integers read from a Buffer are interpreted as two's complement signed
values.

buf.readBigUInt64BE([offset])#

History

VersionChanges
v14.10.0, v12.19.0
This function is also available as buf.readBigUint64BE().
v12.0.0, v10.20.0
Added in: v12.0.0, v10.20.0




offset <integer> Number of bytes to skip before starting to read. Must
satisfy: 0 <= offset <= buf.length - 8. Default: 0.
Returns: <bigint>

Reads an unsigned, big-endian 64-bit integer from buf at the specified
offset.
This function is also available under the readBigUint64BE alias.

import { Buffer } from 'node:buffer';

const buf = Buffer.from([0x00, 0x00, 0x00, 0x00, 0xff, 0xff, 0xff, 0xff]);

console.log(buf.readBigUInt64BE(0));
// Prints: 4294967295nconst { Buffer } = require('node:buffer');

const buf = Buffer.from([0x00, 0x00, 0x00, 0x00, 0xff, 0xff, 0xff, 0xff]);

console.log(buf.readBigUInt64BE(0));
// Prints: 4294967295ncopy

buf.readBigUInt64LE([offset])#

History

VersionChanges
v14.10.0, v12.19.0
This function is also available as buf.readBigUint64LE().
v12.0.0, v10.20.0
Added in: v12.0.0, v10.20.0




offset <integer> Number of bytes to skip before starting to read. Must
satisfy: 0 <= offset <= buf.length - 8. Default: 0.
Returns: <bigint>

Reads an unsigned, little-endian 64-bit integer from buf at the specified
offset.
This function is also available under the readBigUint64LE alias.

import { Buffer } from 'node:buffer';

const buf = Buffer.from([0x00, 0x00, 0x00, 0x00, 0xff, 0xff, 0xff, 0xff]);

console.log(buf.readBigUInt64LE(0));
// Prints: 18446744069414584320nconst { Buffer } = require('node:buffer');

const buf = Buffer.from([0x00, 0x00, 0x00, 0x00, 0xff, 0xff, 0xff, 0xff]);

console.log(buf.readBigUInt64LE(0));
// Prints: 18446744069414584320ncopy

buf.readDoubleBE([offset])#

History

VersionChanges
v10.0.0
Removed noAssert and no implicit coercion of the offset to uint32 anymore.
v0.11.15
Added in: v0.11.15




offset <integer> Number of bytes to skip before starting to read. Must
satisfy 0 <= offset <= buf.length - 8. Default: 0.
Returns: <number>

Reads a 64-bit, big-endian double from buf at the specified offset.

import { Buffer } from 'node:buffer';

const buf = Buffer.from([1, 2, 3, 4, 5, 6, 7, 8]);

console.log(buf.readDoubleBE(0));
// Prints: 8.20788039913184e-304const { Buffer } = require('node:buffer');

const buf = Buffer.from([1, 2, 3, 4, 5, 6, 7, 8]);

console.log(buf.readDoubleBE(0));
// Prints: 8.20788039913184e-304copy

buf.readDoubleLE([offset])#

History

VersionChanges
v10.0.0
Removed noAssert and no implicit coercion of the offset to uint32 anymore.
v0.11.15
Added in: v0.11.15




offset <integer> Number of bytes to skip before starting to read. Must
satisfy 0 <= offset <= buf.length - 8. Default: 0.
Returns: <number>

Reads a 64-bit, little-endian double from buf at the specified offset.

import { Buffer } from 'node:buffer';

const buf = Buffer.from([1, 2, 3, 4, 5, 6, 7, 8]);

console.log(buf.readDoubleLE(0));
// Prints: 5.447603722011605e-270
console.log(buf.readDoubleLE(1));
// Throws ERR_OUT_OF_RANGE.const { Buffer } = require('node:buffer');

const buf = Buffer.from([1, 2, 3, 4, 5, 6, 7, 8]);

console.log(buf.readDoubleLE(0));
// Prints: 5.447603722011605e-270
console.log(buf.readDoubleLE(1));
// Throws ERR_OUT_OF_RANGE.copy

buf.readFloatBE([offset])#

History

VersionChanges
v10.0.0
Removed noAssert and no implicit coercion of the offset to uint32 anymore.
v0.11.15
Added in: v0.11.15




offset <integer> Number of bytes to skip before starting to read. Must
satisfy 0 <= offset <= buf.length - 4. Default: 0.
Returns: <number>

Reads a 32-bit, big-endian float from buf at the specified offset.

import { Buffer } from 'node:buffer';

const buf = Buffer.from([1, 2, 3, 4]);

console.log(buf.readFloatBE(0));
// Prints: 2.387939260590663e-38const { Buffer } = require('node:buffer');

const buf = Buffer.from([1, 2, 3, 4]);

console.log(buf.readFloatBE(0));
// Prints: 2.387939260590663e-38copy

buf.readFloatLE([offset])#

History

VersionChanges
v10.0.0
Removed noAssert and no implicit coercion of the offset to uint32 anymore.
v0.11.15
Added in: v0.11.15




offset <integer> Number of bytes to skip before starting to read. Must
satisfy 0 <= offset <= buf.length - 4. Default: 0.
Returns: <number>

Reads a 32-bit, little-endian float from buf at the specified offset.

import { Buffer } from 'node:buffer';

const buf = Buffer.from([1, 2, 3, 4]);

console.log(buf.readFloatLE(0));
// Prints: 1.539989614439558e-36
console.log(buf.readFloatLE(1));
// Throws ERR_OUT_OF_RANGE.const { Buffer } = require('node:buffer');

const buf = Buffer.from([1, 2, 3, 4]);

console.log(buf.readFloatLE(0));
// Prints: 1.539989614439558e-36
console.log(buf.readFloatLE(1));
// Throws ERR_OUT_OF_RANGE.copy

buf.readInt8([offset])#

History

VersionChanges
v10.0.0
Removed noAssert and no implicit coercion of the offset to uint32 anymore.
v0.5.0
Added in: v0.5.0




offset <integer> Number of bytes to skip before starting to read. Must
satisfy 0 <= offset <= buf.length - 1. Default: 0.
Returns: <integer>

Reads a signed 8-bit integer from buf at the specified offset.
Integers read from a Buffer are interpreted as two's complement signed values.

import { Buffer } from 'node:buffer';

const buf = Buffer.from([-1, 5]);

console.log(buf.readInt8(0));
// Prints: -1
console.log(buf.readInt8(1));
// Prints: 5
console.log(buf.readInt8(2));
// Throws ERR_OUT_OF_RANGE.const { Buffer } = require('node:buffer');

const buf = Buffer.from([-1, 5]);

console.log(buf.readInt8(0));
// Prints: -1
console.log(buf.readInt8(1));
// Prints: 5
console.log(buf.readInt8(2));
// Throws ERR_OUT_OF_RANGE.copy

buf.readInt16BE([offset])#

History

VersionChanges
v10.0.0
Removed noAssert and no implicit coercion of the offset to uint32 anymore.
v0.5.5
Added in: v0.5.5




offset <integer> Number of bytes to skip before starting to read. Must
satisfy 0 <= offset <= buf.length - 2. Default: 0.
Returns: <integer>

Reads a signed, big-endian 16-bit integer from buf at the specified offset.
Integers read from a Buffer are interpreted as two's complement signed values.

import { Buffer } from 'node:buffer';

const buf = Buffer.from([0, 5]);

console.log(buf.readInt16BE(0));
// Prints: 5const { Buffer } = require('node:buffer');

const buf = Buffer.from([0, 5]);

console.log(buf.readInt16BE(0));
// Prints: 5copy

buf.readInt16LE([offset])#

History

VersionChanges
v10.0.0
Removed noAssert and no implicit coercion of the offset to uint32 anymore.
v0.5.5
Added in: v0.5.5




offset <integer> Number of bytes to skip before starting to read. Must
satisfy 0 <= offset <= buf.length - 2. Default: 0.
Returns: <integer>

Reads a signed, little-endian 16-bit integer from buf at the specified
offset.
Integers read from a Buffer are interpreted as two's complement signed values.

import { Buffer } from 'node:buffer';

const buf = Buffer.from([0, 5]);

console.log(buf.readInt16LE(0));
// Prints: 1280
console.log(buf.readInt16LE(1));
// Throws ERR_OUT_OF_RANGE.const { Buffer } = require('node:buffer');

const buf = Buffer.from([0, 5]);

console.log(buf.readInt16LE(0));
// Prints: 1280
console.log(buf.readInt16LE(1));
// Throws ERR_OUT_OF_RANGE.copy

buf.readInt32BE([offset])#

History

VersionChanges
v10.0.0
Removed noAssert and no implicit coercion of the offset to uint32 anymore.
v0.5.5
Added in: v0.5.5




offset <integer> Number of bytes to skip before starting to read. Must
satisfy 0 <= offset <= buf.length - 4. Default: 0.
Returns: <integer>

Reads a signed, big-endian 32-bit integer from buf at the specified offset.
Integers read from a Buffer are interpreted as two's complement signed values.

import { Buffer } from 'node:buffer';

const buf = Buffer.from([0, 0, 0, 5]);

console.log(buf.readInt32BE(0));
// Prints: 5const { Buffer } = require('node:buffer');

const buf = Buffer.from([0, 0, 0, 5]);

console.log(buf.readInt32BE(0));
// Prints: 5copy

buf.readInt32LE([offset])#

History

VersionChanges
v10.0.0
Removed noAssert and no implicit coercion of the offset to uint32 anymore.
v0.5.5
Added in: v0.5.5




offset <integer> Number of bytes to skip before starting to read. Must
satisfy 0 <= offset <= buf.length - 4. Default: 0.
Returns: <integer>

Reads a signed, little-endian 32-bit integer from buf at the specified
offset.
Integers read from a Buffer are interpreted as two's complement signed values.

import { Buffer } from 'node:buffer';

const buf = Buffer.from([0, 0, 0, 5]);

console.log(buf.readInt32LE(0));
// Prints: 83886080
console.log(buf.readInt32LE(1));
// Throws ERR_OUT_OF_RANGE.const { Buffer } = require('node:buffer');

const buf = Buffer.from([0, 0, 0, 5]);

console.log(buf.readInt32LE(0));
// Prints: 83886080
console.log(buf.readInt32LE(1));
// Throws ERR_OUT_OF_RANGE.copy

buf.readIntBE(offset, byteLength)#

History

VersionChanges
v10.0.0
Removed noAssert and no implicit coercion of the offset and byteLength to uint32 anymore.
v0.11.15
Added in: v0.11.15




offset <integer> Number of bytes to skip before starting to read. Must
satisfy 0 <= offset <= buf.length - byteLength.
byteLength <integer> Number of bytes to read. Must satisfy
0 < byteLength <= 6.
Returns: <integer>

Reads byteLength number of bytes from buf at the specified offset
and interprets the result as a big-endian, two's complement signed value
supporting up to 48 bits of accuracy.

import { Buffer } from 'node:buffer';

const buf = Buffer.from([0x12, 0x34, 0x56, 0x78, 0x90, 0xab]);

console.log(buf.readIntBE(0, 6).toString(16));
// Prints: 1234567890ab
console.log(buf.readIntBE(1, 6).toString(16));
// Throws ERR_OUT_OF_RANGE.
console.log(buf.readIntBE(1, 0).toString(16));
// Throws ERR_OUT_OF_RANGE.const { Buffer } = require('node:buffer');

const buf = Buffer.from([0x12, 0x34, 0x56, 0x78, 0x90, 0xab]);

console.log(buf.readIntBE(0, 6).toString(16));
// Prints: 1234567890ab
console.log(buf.readIntBE(1, 6).toString(16));
// Throws ERR_OUT_OF_RANGE.
console.log(buf.readIntBE(1, 0).toString(16));
// Throws ERR_OUT_OF_RANGE.copy

buf.readIntLE(offset, byteLength)#

History

VersionChanges
v10.0.0
Removed noAssert and no implicit coercion of the offset and byteLength to uint32 anymore.
v0.11.15
Added in: v0.11.15




offset <integer> Number of bytes to skip before starting to read. Must
satisfy 0 <= offset <= buf.length - byteLength.
byteLength <integer> Number of bytes to read. Must satisfy
0 < byteLength <= 6.
Returns: <integer>

Reads byteLength number of bytes from buf at the specified offset
and interprets the result as a little-endian, two's complement signed value
supporting up to 48 bits of accuracy.

import { Buffer } from 'node:buffer';

const buf = Buffer.from([0x12, 0x34, 0x56, 0x78, 0x90, 0xab]);

console.log(buf.readIntLE(0, 6).toString(16));
// Prints: -546f87a9cbeeconst { Buffer } = require('node:buffer');

const buf = Buffer.from([0x12, 0x34, 0x56, 0x78, 0x90, 0xab]);

console.log(buf.readIntLE(0, 6).toString(16));
// Prints: -546f87a9cbeecopy

buf.readUInt8([offset])#

History

VersionChanges
v14.9.0, v12.19.0
This function is also available as buf.readUint8().
v10.0.0
Removed noAssert and no implicit coercion of the offset to uint32 anymore.
v0.5.0
Added in: v0.5.0




offset <integer> Number of bytes to skip before starting to read. Must
satisfy 0 <= offset <= buf.length - 1. Default: 0.
Returns: <integer>

Reads an unsigned 8-bit integer from buf at the specified offset.
This function is also available under the readUint8 alias.

import { Buffer } from 'node:buffer';

const buf = Buffer.from([1, -2]);

console.log(buf.readUInt8(0));
// Prints: 1
console.log(buf.readUInt8(1));
// Prints: 254
console.log(buf.readUInt8(2));
// Throws ERR_OUT_OF_RANGE.const { Buffer } = require('node:buffer');

const buf = Buffer.from([1, -2]);

console.log(buf.readUInt8(0));
// Prints: 1
console.log(buf.readUInt8(1));
// Prints: 254
console.log(buf.readUInt8(2));
// Throws ERR_OUT_OF_RANGE.copy

buf.readUInt16BE([offset])#

History

VersionChanges
v14.9.0, v12.19.0
This function is also available as buf.readUint16BE().
v10.0.0
Removed noAssert and no implicit coercion of the offset to uint32 anymore.
v0.5.5
Added in: v0.5.5




offset <integer> Number of bytes to skip before starting to read. Must
satisfy 0 <= offset <= buf.length - 2. Default: 0.
Returns: <integer>

Reads an unsigned, big-endian 16-bit integer from buf at the specified
offset.
This function is also available under the readUint16BE alias.

import { Buffer } from 'node:buffer';

const buf = Buffer.from([0x12, 0x34, 0x56]);

console.log(buf.readUInt16BE(0).toString(16));
// Prints: 1234
console.log(buf.readUInt16BE(1).toString(16));
// Prints: 3456const { Buffer } = require('node:buffer');

const buf = Buffer.from([0x12, 0x34, 0x56]);

console.log(buf.readUInt16BE(0).toString(16));
// Prints: 1234
console.log(buf.readUInt16BE(1).toString(16));
// Prints: 3456copy

buf.readUInt16LE([offset])#

History

VersionChanges
v14.9.0, v12.19.0
This function is also available as buf.readUint16LE().
v10.0.0
Removed noAssert and no implicit coercion of the offset to uint32 anymore.
v0.5.5
Added in: v0.5.5




offset <integer> Number of bytes to skip before starting to read. Must
satisfy 0 <= offset <= buf.length - 2. Default: 0.
Returns: <integer>

Reads an unsigned, little-endian 16-bit integer from buf at the specified
offset.
This function is also available under the readUint16LE alias.

import { Buffer } from 'node:buffer';

const buf = Buffer.from([0x12, 0x34, 0x56]);

console.log(buf.readUInt16LE(0).toString(16));
// Prints: 3412
console.log(buf.readUInt16LE(1).toString(16));
// Prints: 5634
console.log(buf.readUInt16LE(2).toString(16));
// Throws ERR_OUT_OF_RANGE.const { Buffer } = require('node:buffer');

const buf = Buffer.from([0x12, 0x34, 0x56]);

console.log(buf.readUInt16LE(0).toString(16));
// Prints: 3412
console.log(buf.readUInt16LE(1).toString(16));
// Prints: 5634
console.log(buf.readUInt16LE(2).toString(16));
// Throws ERR_OUT_OF_RANGE.copy

buf.readUInt32BE([offset])#

History

VersionChanges
v14.9.0, v12.19.0
This function is also available as buf.readUint32BE().
v10.0.0
Removed noAssert and no implicit coercion of the offset to uint32 anymore.
v0.5.5
Added in: v0.5.5




offset <integer> Number of bytes to skip before starting to read. Must
satisfy 0 <= offset <= buf.length - 4. Default: 0.
Returns: <integer>

Reads an unsigned, big-endian 32-bit integer from buf at the specified
offset.
This function is also available under the readUint32BE alias.

import { Buffer } from 'node:buffer';

const buf = Buffer.from([0x12, 0x34, 0x56, 0x78]);

console.log(buf.readUInt32BE(0).toString(16));
// Prints: 12345678const { Buffer } = require('node:buffer');

const buf = Buffer.from([0x12, 0x34, 0x56, 0x78]);

console.log(buf.readUInt32BE(0).toString(16));
// Prints: 12345678copy

buf.readUInt32LE([offset])#

History

VersionChanges
v14.9.0, v12.19.0
This function is also available as buf.readUint32LE().
v10.0.0
Removed noAssert and no implicit coercion of the offset to uint32 anymore.
v0.5.5
Added in: v0.5.5




offset <integer> Number of bytes to skip before starting to read. Must
satisfy 0 <= offset <= buf.length - 4. Default: 0.
Returns: <integer>

Reads an unsigned, little-endian 32-bit integer from buf at the specified
offset.
This function is also available under the readUint32LE alias.

import { Buffer } from 'node:buffer';

const buf = Buffer.from([0x12, 0x34, 0x56, 0x78]);

console.log(buf.readUInt32LE(0).toString(16));
// Prints: 78563412
console.log(buf.readUInt32LE(1).toString(16));
// Throws ERR_OUT_OF_RANGE.const { Buffer } = require('node:buffer');

const buf = Buffer.from([0x12, 0x34, 0x56, 0x78]);

console.log(buf.readUInt32LE(0).toString(16));
// Prints: 78563412
console.log(buf.readUInt32LE(1).toString(16));
// Throws ERR_OUT_OF_RANGE.copy

buf.readUIntBE(offset, byteLength)#

History

VersionChanges
v14.9.0, v12.19.0
This function is also available as buf.readUintBE().
v10.0.0
Removed noAssert and no implicit coercion of the offset and byteLength to uint32 anymore.
v0.11.15
Added in: v0.11.15




offset <integer> Number of bytes to skip before starting to read. Must
satisfy 0 <= offset <= buf.length - byteLength.
byteLength <integer> Number of bytes to read. Must satisfy
0 < byteLength <= 6.
Returns: <integer>

Reads byteLength number of bytes from buf at the specified offset
and interprets the result as an unsigned big-endian integer supporting
up to 48 bits of accuracy.
This function is also available under the readUintBE alias.

import { Buffer } from 'node:buffer';

const buf = Buffer.from([0x12, 0x34, 0x56, 0x78, 0x90, 0xab]);

console.log(buf.readUIntBE(0, 6).toString(16));
// Prints: 1234567890ab
console.log(buf.readUIntBE(1, 6).toString(16));
// Throws ERR_OUT_OF_RANGE.const { Buffer } = require('node:buffer');

const buf = Buffer.from([0x12, 0x34, 0x56, 0x78, 0x90, 0xab]);

console.log(buf.readUIntBE(0, 6).toString(16));
// Prints: 1234567890ab
console.log(buf.readUIntBE(1, 6).toString(16));
// Throws ERR_OUT_OF_RANGE.copy

buf.readUIntLE(offset, byteLength)#

History

VersionChanges
v14.9.0, v12.19.0
This function is also available as buf.readUintLE().
v10.0.0
Removed noAssert and no implicit coercion of the offset and byteLength to uint32 anymore.
v0.11.15
Added in: v0.11.15




offset <integer> Number of bytes to skip before starting to read. Must
satisfy 0 <= offset <= buf.length - byteLength.
byteLength <integer> Number of bytes to read. Must satisfy
0 < byteLength <= 6.
Returns: <integer>

Reads byteLength number of bytes from buf at the specified offset
and interprets the result as an unsigned, little-endian integer supporting
up to 48 bits of accuracy.
This function is also available under the readUintLE alias.

import { Buffer } from 'node:buffer';

const buf = Buffer.from([0x12, 0x34, 0x56, 0x78, 0x90, 0xab]);

console.log(buf.readUIntLE(0, 6).toString(16));
// Prints: ab9078563412const { Buffer } = require('node:buffer');

const buf = Buffer.from([0x12, 0x34, 0x56, 0x78, 0x90, 0xab]);

console.log(buf.readUIntLE(0, 6).toString(16));
// Prints: ab9078563412copy

buf.subarray([start[, end]])#

Added in: v3.0.0


start <integer> Where the new Buffer will start. Default: 0.
end <integer> Where the new Buffer will end (not inclusive).
Default: buf.length.
Returns: <Buffer>

Returns a new Buffer that references the same memory as the original, but
offset and cropped by the start and end indexes.
Specifying end greater than buf.length will return the same result as
that of end equal to buf.length.
This method is inherited from TypedArray.prototype.subarray().
Modifying the new Buffer slice will modify the memory in the original Buffer
because the allocated memory of the two objects overlap.

import { Buffer } from 'node:buffer';

// Create a `Buffer` with the ASCII alphabet, take a slice, and modify one byte
// from the original `Buffer`.

const buf1 = Buffer.allocUnsafe(26);

for (let i = 0; i < 26; i++) {
  // 97 is the decimal ASCII value for 'a'.
  buf1[i] = i + 97;
}

const buf2 = buf1.subarray(0, 3);

console.log(buf2.toString('ascii', 0, buf2.length));
// Prints: abc

buf1[0] = 33;

console.log(buf2.toString('ascii', 0, buf2.length));
// Prints: !bcconst { Buffer } = require('node:buffer');

// Create a `Buffer` with the ASCII alphabet, take a slice, and modify one byte
// from the original `Buffer`.

const buf1 = Buffer.allocUnsafe(26);

for (let i = 0; i < 26; i++) {
  // 97 is the decimal ASCII value for 'a'.
  buf1[i] = i + 97;
}

const buf2 = buf1.subarray(0, 3);

console.log(buf2.toString('ascii', 0, buf2.length));
// Prints: abc

buf1[0] = 33;

console.log(buf2.toString('ascii', 0, buf2.length));
// Prints: !bccopy
Specifying negative indexes causes the slice to be generated relative to the
end of buf rather than the beginning.

import { Buffer } from 'node:buffer';

const buf = Buffer.from('buffer');

console.log(buf.subarray(-6, -1).toString());
// Prints: buffe
// (Equivalent to buf.subarray(0, 5).)

console.log(buf.subarray(-6, -2).toString());
// Prints: buff
// (Equivalent to buf.subarray(0, 4).)

console.log(buf.subarray(-5, -2).toString());
// Prints: uff
// (Equivalent to buf.subarray(1, 4).)const { Buffer } = require('node:buffer');

const buf = Buffer.from('buffer');

console.log(buf.subarray(-6, -1).toString());
// Prints: buffe
// (Equivalent to buf.subarray(0, 5).)

console.log(buf.subarray(-6, -2).toString());
// Prints: buff
// (Equivalent to buf.subarray(0, 4).)

console.log(buf.subarray(-5, -2).toString());
// Prints: uff
// (Equivalent to buf.subarray(1, 4).)copy

buf.slice([start[, end]])#

History

VersionChanges
v17.5.0, v16.15.0
The buf.slice() method has been deprecated.
v7.0.0
All offsets are now coerced to integers before doing any calculations with them.
v7.1.0, v6.9.2
Coercing the offsets to integers now handles values outside the 32-bit integer range properly.
v0.3.0
Added in: v0.3.0




start <integer> Where the new Buffer will start. Default: 0.
end <integer> Where the new Buffer will end (not inclusive).
Default: buf.length.
Returns: <Buffer>

Stability: 0 - Deprecated: Use buf.subarray instead.
Returns a new Buffer that references the same memory as the original, but
offset and cropped by the start and end indexes.
This method is not compatible with the Uint8Array.prototype.slice(),
which is a superclass of Buffer. To copy the slice, use
Uint8Array.prototype.slice().

import { Buffer } from 'node:buffer';

const buf = Buffer.from('buffer');

const copiedBuf = Uint8Array.prototype.slice.call(buf);
copiedBuf[0]++;
console.log(copiedBuf.toString());
// Prints: cuffer

console.log(buf.toString());
// Prints: buffer

// With buf.slice(), the original buffer is modified.
const notReallyCopiedBuf = buf.slice();
notReallyCopiedBuf[0]++;
console.log(notReallyCopiedBuf.toString());
// Prints: cuffer
console.log(buf.toString());
// Also prints: cuffer (!)const { Buffer } = require('node:buffer');

const buf = Buffer.from('buffer');

const copiedBuf = Uint8Array.prototype.slice.call(buf);
copiedBuf[0]++;
console.log(copiedBuf.toString());
// Prints: cuffer

console.log(buf.toString());
// Prints: buffer

// With buf.slice(), the original buffer is modified.
const notReallyCopiedBuf = buf.slice();
notReallyCopiedBuf[0]++;
console.log(notReallyCopiedBuf.toString());
// Prints: cuffer
console.log(buf.toString());
// Also prints: cuffer (!)copy

buf.swap16()#

Added in: v5.10.0


Returns: <Buffer> A reference to buf.

Interprets buf as an array of unsigned 16-bit integers and swaps the
byte order in-place. Throws ERR_INVALID_BUFFER_SIZE if buf.length
is not a multiple of 2.

import { Buffer } from 'node:buffer';

const buf1 = Buffer.from([0x1, 0x2, 0x3, 0x4, 0x5, 0x6, 0x7, 0x8]);

console.log(buf1);
// Prints: <Buffer 01 02 03 04 05 06 07 08>

buf1.swap16();

console.log(buf1);
// Prints: <Buffer 02 01 04 03 06 05 08 07>

const buf2 = Buffer.from([0x1, 0x2, 0x3]);

buf2.swap16();
// Throws ERR_INVALID_BUFFER_SIZE.const { Buffer } = require('node:buffer');

const buf1 = Buffer.from([0x1, 0x2, 0x3, 0x4, 0x5, 0x6, 0x7, 0x8]);

console.log(buf1);
// Prints: <Buffer 01 02 03 04 05 06 07 08>

buf1.swap16();

console.log(buf1);
// Prints: <Buffer 02 01 04 03 06 05 08 07>

const buf2 = Buffer.from([0x1, 0x2, 0x3]);

buf2.swap16();
// Throws ERR_INVALID_BUFFER_SIZE.copy
One convenient use of buf.swap16() is to perform a fast in-place conversion
between UTF-16 little-endian and UTF-16 big-endian:

import { Buffer } from 'node:buffer';

const buf = Buffer.from('This is little-endian UTF-16', 'utf16le');
buf.swap16(); // Convert to big-endian UTF-16 text.const { Buffer } = require('node:buffer');

const buf = Buffer.from('This is little-endian UTF-16', 'utf16le');
buf.swap16(); // Convert to big-endian UTF-16 text.copy

buf.swap32()#

Added in: v5.10.0


Returns: <Buffer> A reference to buf.

Interprets buf as an array of unsigned 32-bit integers and swaps the
byte order in-place. Throws ERR_INVALID_BUFFER_SIZE if buf.length
is not a multiple of 4.

import { Buffer } from 'node:buffer';

const buf1 = Buffer.from([0x1, 0x2, 0x3, 0x4, 0x5, 0x6, 0x7, 0x8]);

console.log(buf1);
// Prints: <Buffer 01 02 03 04 05 06 07 08>

buf1.swap32();

console.log(buf1);
// Prints: <Buffer 04 03 02 01 08 07 06 05>

const buf2 = Buffer.from([0x1, 0x2, 0x3]);

buf2.swap32();
// Throws ERR_INVALID_BUFFER_SIZE.const { Buffer } = require('node:buffer');

const buf1 = Buffer.from([0x1, 0x2, 0x3, 0x4, 0x5, 0x6, 0x7, 0x8]);

console.log(buf1);
// Prints: <Buffer 01 02 03 04 05 06 07 08>

buf1.swap32();

console.log(buf1);
// Prints: <Buffer 04 03 02 01 08 07 06 05>

const buf2 = Buffer.from([0x1, 0x2, 0x3]);

buf2.swap32();
// Throws ERR_INVALID_BUFFER_SIZE.copy

buf.swap64()#

Added in: v6.3.0


Returns: <Buffer> A reference to buf.

Interprets buf as an array of 64-bit numbers and swaps byte order in-place.
Throws ERR_INVALID_BUFFER_SIZE if buf.length is not a multiple of 8.

import { Buffer } from 'node:buffer';

const buf1 = Buffer.from([0x1, 0x2, 0x3, 0x4, 0x5, 0x6, 0x7, 0x8]);

console.log(buf1);
// Prints: <Buffer 01 02 03 04 05 06 07 08>

buf1.swap64();

console.log(buf1);
// Prints: <Buffer 08 07 06 05 04 03 02 01>

const buf2 = Buffer.from([0x1, 0x2, 0x3]);

buf2.swap64();
// Throws ERR_INVALID_BUFFER_SIZE.const { Buffer } = require('node:buffer');

const buf1 = Buffer.from([0x1, 0x2, 0x3, 0x4, 0x5, 0x6, 0x7, 0x8]);

console.log(buf1);
// Prints: <Buffer 01 02 03 04 05 06 07 08>

buf1.swap64();

console.log(buf1);
// Prints: <Buffer 08 07 06 05 04 03 02 01>

const buf2 = Buffer.from([0x1, 0x2, 0x3]);

buf2.swap64();
// Throws ERR_INVALID_BUFFER_SIZE.copy

buf.toJSON()#

Added in: v0.9.2


Returns: <Object>

Returns a JSON representation of buf. JSON.stringify() implicitly calls
this function when stringifying a Buffer instance.
Buffer.from() accepts objects in the format returned from this method.
In particular, Buffer.from(buf.toJSON()) works like Buffer.from(buf).

import { Buffer } from 'node:buffer';

const buf = Buffer.from([0x1, 0x2, 0x3, 0x4, 0x5]);
const json = JSON.stringify(buf);

console.log(json);
// Prints: {"type":"Buffer","data":[1,2,3,4,5]}

const copy = JSON.parse(json, (key, value) => {
  return value && value.type === 'Buffer' ?
    Buffer.from(value) :
    value;
});

console.log(copy);
// Prints: <Buffer 01 02 03 04 05>const { Buffer } = require('node:buffer');

const buf = Buffer.from([0x1, 0x2, 0x3, 0x4, 0x5]);
const json = JSON.stringify(buf);

console.log(json);
// Prints: {"type":"Buffer","data":[1,2,3,4,5]}

const copy = JSON.parse(json, (key, value) => {
  return value && value.type === 'Buffer' ?
    Buffer.from(value) :
    value;
});

console.log(copy);
// Prints: <Buffer 01 02 03 04 05>copy

buf.toString([encoding[, start[, end]]])#

Added in: v0.1.90


encoding <string> The character encoding to use. Default: 'utf8'.
start <integer> The byte offset to start decoding at. Default: 0.
end <integer> The byte offset to stop decoding at (not inclusive).
Default: buf.length.
Returns: <string>

Decodes buf to a string according to the specified character encoding in
encoding. start and end may be passed to decode only a subset of buf.
If encoding is 'utf8' and a byte sequence in the input is not valid UTF-8,
then each invalid byte is replaced with the replacement character U+FFFD.
The maximum length of a string instance (in UTF-16 code units) is available
as buffer.constants.MAX_STRING_LENGTH.

import { Buffer } from 'node:buffer';

const buf1 = Buffer.allocUnsafe(26);

for (let i = 0; i < 26; i++) {
  // 97 is the decimal ASCII value for 'a'.
  buf1[i] = i + 97;
}

console.log(buf1.toString('utf8'));
// Prints: abcdefghijklmnopqrstuvwxyz
console.log(buf1.toString('utf8', 0, 5));
// Prints: abcde

const buf2 = Buffer.from('tést');

console.log(buf2.toString('hex'));
// Prints: 74c3a97374
console.log(buf2.toString('utf8', 0, 3));
// Prints: té
console.log(buf2.toString(undefined, 0, 3));
// Prints: téconst { Buffer } = require('node:buffer');

const buf1 = Buffer.allocUnsafe(26);

for (let i = 0; i < 26; i++) {
  // 97 is the decimal ASCII value for 'a'.
  buf1[i] = i + 97;
}

console.log(buf1.toString('utf8'));
// Prints: abcdefghijklmnopqrstuvwxyz
console.log(buf1.toString('utf8', 0, 5));
// Prints: abcde

const buf2 = Buffer.from('tést');

console.log(buf2.toString('hex'));
// Prints: 74c3a97374
console.log(buf2.toString('utf8', 0, 3));
// Prints: té
console.log(buf2.toString(undefined, 0, 3));
// Prints: técopy

buf.values()#

Added in: v1.1.0


Returns: <Iterator>

Creates and returns an iterator for buf values (bytes). This function is
called automatically when a Buffer is used in a for..of statement.

import { Buffer } from 'node:buffer';

const buf = Buffer.from('buffer');

for (const value of buf.values()) {
  console.log(value);
}
// Prints:
//   98
//   117
//   102
//   102
//   101
//   114

for (const value of buf) {
  console.log(value);
}
// Prints:
//   98
//   117
//   102
//   102
//   101
//   114const { Buffer } = require('node:buffer');

const buf = Buffer.from('buffer');

for (const value of buf.values()) {
  console.log(value);
}
// Prints:
//   98
//   117
//   102
//   102
//   101
//   114

for (const value of buf) {
  console.log(value);
}
// Prints:
//   98
//   117
//   102
//   102
//   101
//   114copy

buf.write(string[, offset[, length]][, encoding])#

Added in: v0.1.90


string <string> String to write to buf.
offset <integer> Number of bytes to skip before starting to write string.
Default: 0.
length <integer> Maximum number of bytes to write (written bytes will not
exceed buf.length - offset). Default: buf.length - offset.
encoding <string> The character encoding of string. Default: 'utf8'.
Returns: <integer> Number of bytes written.

Writes string to buf at offset according to the character encoding in
encoding. The length parameter is the number of bytes to write. If buf did
not contain enough space to fit the entire string, only part of string will be
written. However, partially encoded characters will not be written.

import { Buffer } from 'node:buffer';

const buf = Buffer.alloc(256);

const len = buf.write('\u00bd + \u00bc = \u00be', 0);

console.log(`${len} bytes: ${buf.toString('utf8', 0, len)}`);
// Prints: 12 bytes: ½ + ¼ = ¾

const buffer = Buffer.alloc(10);

const length = buffer.write('abcd', 8);

console.log(`${length} bytes: ${buffer.toString('utf8', 8, 10)}`);
// Prints: 2 bytes : abconst { Buffer } = require('node:buffer');

const buf = Buffer.alloc(256);

const len = buf.write('\u00bd + \u00bc = \u00be', 0);

console.log(`${len} bytes: ${buf.toString('utf8', 0, len)}`);
// Prints: 12 bytes: ½ + ¼ = ¾

const buffer = Buffer.alloc(10);

const length = buffer.write('abcd', 8);

console.log(`${length} bytes: ${buffer.toString('utf8', 8, 10)}`);
// Prints: 2 bytes : abcopy

buf.writeBigInt64BE(value[, offset])#

Added in: v12.0.0, v10.20.0


value <bigint> Number to be written to buf.
offset <integer> Number of bytes to skip before starting to write. Must
satisfy: 0 <= offset <= buf.length - 8. Default: 0.
Returns: <integer> offset plus the number of bytes written.

Writes value to buf at the specified offset as big-endian.
value is interpreted and written as a two's complement signed integer.

import { Buffer } from 'node:buffer';

const buf = Buffer.allocUnsafe(8);

buf.writeBigInt64BE(0x0102030405060708n, 0);

console.log(buf);
// Prints: <Buffer 01 02 03 04 05 06 07 08>const { Buffer } = require('node:buffer');

const buf = Buffer.allocUnsafe(8);

buf.writeBigInt64BE(0x0102030405060708n, 0);

console.log(buf);
// Prints: <Buffer 01 02 03 04 05 06 07 08>copy

buf.writeBigInt64LE(value[, offset])#

Added in: v12.0.0, v10.20.0


value <bigint> Number to be written to buf.
offset <integer> Number of bytes to skip before starting to write. Must
satisfy: 0 <= offset <= buf.length - 8. Default: 0.
Returns: <integer> offset plus the number of bytes written.

Writes value to buf at the specified offset as little-endian.
value is interpreted and written as a two's complement signed integer.

import { Buffer } from 'node:buffer';

const buf = Buffer.allocUnsafe(8);

buf.writeBigInt64LE(0x0102030405060708n, 0);

console.log(buf);
// Prints: <Buffer 08 07 06 05 04 03 02 01>const { Buffer } = require('node:buffer');

const buf = Buffer.allocUnsafe(8);

buf.writeBigInt64LE(0x0102030405060708n, 0);

console.log(buf);
// Prints: <Buffer 08 07 06 05 04 03 02 01>copy

buf.writeBigUInt64BE(value[, offset])#

History

VersionChanges
v14.10.0, v12.19.0
This function is also available as buf.writeBigUint64BE().
v12.0.0, v10.20.0
Added in: v12.0.0, v10.20.0




value <bigint> Number to be written to buf.
offset <integer> Number of bytes to skip before starting to write. Must
satisfy: 0 <= offset <= buf.length - 8. Default: 0.
Returns: <integer> offset plus the number of bytes written.

Writes value to buf at the specified offset as big-endian.
This function is also available under the writeBigUint64BE alias.

import { Buffer } from 'node:buffer';

const buf = Buffer.allocUnsafe(8);

buf.writeBigUInt64BE(0xdecafafecacefaden, 0);

console.log(buf);
// Prints: <Buffer de ca fa fe ca ce fa de>const { Buffer } = require('node:buffer');

const buf = Buffer.allocUnsafe(8);

buf.writeBigUInt64BE(0xdecafafecacefaden, 0);

console.log(buf);
// Prints: <Buffer de ca fa fe ca ce fa de>copy

buf.writeBigUInt64LE(value[, offset])#

History

VersionChanges
v14.10.0, v12.19.0
This function is also available as buf.writeBigUint64LE().
v12.0.0, v10.20.0
Added in: v12.0.0, v10.20.0




value <bigint> Number to be written to buf.
offset <integer> Number of bytes to skip before starting to write. Must
satisfy: 0 <= offset <= buf.length - 8. Default: 0.
Returns: <integer> offset plus the number of bytes written.

Writes value to buf at the specified offset as little-endian

import { Buffer } from 'node:buffer';

const buf = Buffer.allocUnsafe(8);

buf.writeBigUInt64LE(0xdecafafecacefaden, 0);

console.log(buf);
// Prints: <Buffer de fa ce ca fe fa ca de>const { Buffer } = require('node:buffer');

const buf = Buffer.allocUnsafe(8);

buf.writeBigUInt64LE(0xdecafafecacefaden, 0);

console.log(buf);
// Prints: <Buffer de fa ce ca fe fa ca de>copy
This function is also available under the writeBigUint64LE alias.

buf.writeDoubleBE(value[, offset])#

History

VersionChanges
v10.0.0
Removed noAssert and no implicit coercion of the offset to uint32 anymore.
v0.11.15
Added in: v0.11.15




value <number> Number to be written to buf.
offset <integer> Number of bytes to skip before starting to write. Must
satisfy 0 <= offset <= buf.length - 8. Default: 0.
Returns: <integer> offset plus the number of bytes written.

Writes value to buf at the specified offset as big-endian. The value
must be a JavaScript number. Behavior is undefined when value is anything
other than a JavaScript number.

import { Buffer } from 'node:buffer';

const buf = Buffer.allocUnsafe(8);

buf.writeDoubleBE(123.456, 0);

console.log(buf);
// Prints: <Buffer 40 5e dd 2f 1a 9f be 77>const { Buffer } = require('node:buffer');

const buf = Buffer.allocUnsafe(8);

buf.writeDoubleBE(123.456, 0);

console.log(buf);
// Prints: <Buffer 40 5e dd 2f 1a 9f be 77>copy

buf.writeDoubleLE(value[, offset])#

History

VersionChanges
v10.0.0
Removed noAssert and no implicit coercion of the offset to uint32 anymore.
v0.11.15
Added in: v0.11.15




value <number> Number to be written to buf.
offset <integer> Number of bytes to skip before starting to write. Must
satisfy 0 <= offset <= buf.length - 8. Default: 0.
Returns: <integer> offset plus the number of bytes written.

Writes value to buf at the specified offset as little-endian. The value
must be a JavaScript number. Behavior is undefined when value is anything
other than a JavaScript number.

import { Buffer } from 'node:buffer';

const buf = Buffer.allocUnsafe(8);

buf.writeDoubleLE(123.456, 0);

console.log(buf);
// Prints: <Buffer 77 be 9f 1a 2f dd 5e 40>const { Buffer } = require('node:buffer');

const buf = Buffer.allocUnsafe(8);

buf.writeDoubleLE(123.456, 0);

console.log(buf);
// Prints: <Buffer 77 be 9f 1a 2f dd 5e 40>copy

buf.writeFloatBE(value[, offset])#

History

VersionChanges
v10.0.0
Removed noAssert and no implicit coercion of the offset to uint32 anymore.
v0.11.15
Added in: v0.11.15




value <number> Number to be written to buf.
offset <integer> Number of bytes to skip before starting to write. Must
satisfy 0 <= offset <= buf.length - 4. Default: 0.
Returns: <integer> offset plus the number of bytes written.

Writes value to buf at the specified offset as big-endian. Behavior is
undefined when value is anything other than a JavaScript number.

import { Buffer } from 'node:buffer';

const buf = Buffer.allocUnsafe(4);

buf.writeFloatBE(0xcafebabe, 0);

console.log(buf);
// Prints: <Buffer 4f 4a fe bb>const { Buffer } = require('node:buffer');

const buf = Buffer.allocUnsafe(4);

buf.writeFloatBE(0xcafebabe, 0);

console.log(buf);
// Prints: <Buffer 4f 4a fe bb>copy

buf.writeFloatLE(value[, offset])#

History

VersionChanges
v10.0.0
Removed noAssert and no implicit coercion of the offset to uint32 anymore.
v0.11.15
Added in: v0.11.15




value <number> Number to be written to buf.
offset <integer> Number of bytes to skip before starting to write. Must
satisfy 0 <= offset <= buf.length - 4. Default: 0.
Returns: <integer> offset plus the number of bytes written.

Writes value to buf at the specified offset as little-endian. Behavior is
undefined when value is anything other than a JavaScript number.

import { Buffer } from 'node:buffer';

const buf = Buffer.allocUnsafe(4);

buf.writeFloatLE(0xcafebabe, 0);

console.log(buf);
// Prints: <Buffer bb fe 4a 4f>const { Buffer } = require('node:buffer');

const buf = Buffer.allocUnsafe(4);

buf.writeFloatLE(0xcafebabe, 0);

console.log(buf);
// Prints: <Buffer bb fe 4a 4f>copy

buf.writeInt8(value[, offset])#

History

VersionChanges
v10.0.0
Removed noAssert and no implicit coercion of the offset to uint32 anymore.
v0.5.0
Added in: v0.5.0




value <integer> Number to be written to buf.
offset <integer> Number of bytes to skip before starting to write. Must
satisfy 0 <= offset <= buf.length - 1. Default: 0.
Returns: <integer> offset plus the number of bytes written.

Writes value to buf at the specified offset. value must be a valid
signed 8-bit integer. Behavior is undefined when value is anything other than
a signed 8-bit integer.
value is interpreted and written as a two's complement signed integer.

import { Buffer } from 'node:buffer';

const buf = Buffer.allocUnsafe(2);

buf.writeInt8(2, 0);
buf.writeInt8(-2, 1);

console.log(buf);
// Prints: <Buffer 02 fe>const { Buffer } = require('node:buffer');

const buf = Buffer.allocUnsafe(2);

buf.writeInt8(2, 0);
buf.writeInt8(-2, 1);

console.log(buf);
// Prints: <Buffer 02 fe>copy

buf.writeInt16BE(value[, offset])#

History

VersionChanges
v10.0.0
Removed noAssert and no implicit coercion of the offset to uint32 anymore.
v0.5.5
Added in: v0.5.5




value <integer> Number to be written to buf.
offset <integer> Number of bytes to skip before starting to write. Must
satisfy 0 <= offset <= buf.length - 2. Default: 0.
Returns: <integer> offset plus the number of bytes written.

Writes value to buf at the specified offset as big-endian.  The value
must be a valid signed 16-bit integer. Behavior is undefined when value is
anything other than a signed 16-bit integer.
The value is interpreted and written as a two's complement signed integer.

import { Buffer } from 'node:buffer';

const buf = Buffer.allocUnsafe(2);

buf.writeInt16BE(0x0102, 0);

console.log(buf);
// Prints: <Buffer 01 02>const { Buffer } = require('node:buffer');

const buf = Buffer.allocUnsafe(2);

buf.writeInt16BE(0x0102, 0);

console.log(buf);
// Prints: <Buffer 01 02>copy

buf.writeInt16LE(value[, offset])#

History

VersionChanges
v10.0.0
Removed noAssert and no implicit coercion of the offset to uint32 anymore.
v0.5.5
Added in: v0.5.5




value <integer> Number to be written to buf.
offset <integer> Number of bytes to skip before starting to write. Must
satisfy 0 <= offset <= buf.length - 2. Default: 0.
Returns: <integer> offset plus the number of bytes written.

Writes value to buf at the specified offset as little-endian.  The value
must be a valid signed 16-bit integer. Behavior is undefined when value is
anything other than a signed 16-bit integer.
The value is interpreted and written as a two's complement signed integer.

import { Buffer } from 'node:buffer';

const buf = Buffer.allocUnsafe(2);

buf.writeInt16LE(0x0304, 0);

console.log(buf);
// Prints: <Buffer 04 03>const { Buffer } = require('node:buffer');

const buf = Buffer.allocUnsafe(2);

buf.writeInt16LE(0x0304, 0);

console.log(buf);
// Prints: <Buffer 04 03>copy

buf.writeInt32BE(value[, offset])#

History

VersionChanges
v10.0.0
Removed noAssert and no implicit coercion of the offset to uint32 anymore.
v0.5.5
Added in: v0.5.5




value <integer> Number to be written to buf.
offset <integer> Number of bytes to skip before starting to write. Must
satisfy 0 <= offset <= buf.length - 4. Default: 0.
Returns: <integer> offset plus the number of bytes written.

Writes value to buf at the specified offset as big-endian. The value
must be a valid signed 32-bit integer. Behavior is undefined when value is
anything other than a signed 32-bit integer.
The value is interpreted and written as a two's complement signed integer.

import { Buffer } from 'node:buffer';

const buf = Buffer.allocUnsafe(4);

buf.writeInt32BE(0x01020304, 0);

console.log(buf);
// Prints: <Buffer 01 02 03 04>const { Buffer } = require('node:buffer');

const buf = Buffer.allocUnsafe(4);

buf.writeInt32BE(0x01020304, 0);

console.log(buf);
// Prints: <Buffer 01 02 03 04>copy

buf.writeInt32LE(value[, offset])#

History

VersionChanges
v10.0.0
Removed noAssert and no implicit coercion of the offset to uint32 anymore.
v0.5.5
Added in: v0.5.5




value <integer> Number to be written to buf.
offset <integer> Number of bytes to skip before starting to write. Must
satisfy 0 <= offset <= buf.length - 4. Default: 0.
Returns: <integer> offset plus the number of bytes written.

Writes value to buf at the specified offset as little-endian. The value
must be a valid signed 32-bit integer. Behavior is undefined when value is
anything other than a signed 32-bit integer.
The value is interpreted and written as a two's complement signed integer.

import { Buffer } from 'node:buffer';

const buf = Buffer.allocUnsafe(4);

buf.writeInt32LE(0x05060708, 0);

console.log(buf);
// Prints: <Buffer 08 07 06 05>const { Buffer } = require('node:buffer');

const buf = Buffer.allocUnsafe(4);

buf.writeInt32LE(0x05060708, 0);

console.log(buf);
// Prints: <Buffer 08 07 06 05>copy

buf.writeIntBE(value, offset, byteLength)#

History

VersionChanges
v10.0.0
Removed noAssert and no implicit coercion of the offset and byteLength to uint32 anymore.
v0.11.15
Added in: v0.11.15




value <integer> Number to be written to buf.
offset <integer> Number of bytes to skip before starting to write. Must
satisfy 0 <= offset <= buf.length - byteLength.
byteLength <integer> Number of bytes to write. Must satisfy
0 < byteLength <= 6.
Returns: <integer> offset plus the number of bytes written.

Writes byteLength bytes of value to buf at the specified offset
as big-endian. Supports up to 48 bits of accuracy. Behavior is undefined when
value is anything other than a signed integer.

import { Buffer } from 'node:buffer';

const buf = Buffer.allocUnsafe(6);

buf.writeIntBE(0x1234567890ab, 0, 6);

console.log(buf);
// Prints: <Buffer 12 34 56 78 90 ab>const { Buffer } = require('node:buffer');

const buf = Buffer.allocUnsafe(6);

buf.writeIntBE(0x1234567890ab, 0, 6);

console.log(buf);
// Prints: <Buffer 12 34 56 78 90 ab>copy

buf.writeIntLE(value, offset, byteLength)#

History

VersionChanges
v10.0.0
Removed noAssert and no implicit coercion of the offset and byteLength to uint32 anymore.
v0.11.15
Added in: v0.11.15




value <integer> Number to be written to buf.
offset <integer> Number of bytes to skip before starting to write. Must
satisfy 0 <= offset <= buf.length - byteLength.
byteLength <integer> Number of bytes to write. Must satisfy
0 < byteLength <= 6.
Returns: <integer> offset plus the number of bytes written.

Writes byteLength bytes of value to buf at the specified offset
as little-endian. Supports up to 48 bits of accuracy. Behavior is undefined
when value is anything other than a signed integer.

import { Buffer } from 'node:buffer';

const buf = Buffer.allocUnsafe(6);

buf.writeIntLE(0x1234567890ab, 0, 6);

console.log(buf);
// Prints: <Buffer ab 90 78 56 34 12>const { Buffer } = require('node:buffer');

const buf = Buffer.allocUnsafe(6);

buf.writeIntLE(0x1234567890ab, 0, 6);

console.log(buf);
// Prints: <Buffer ab 90 78 56 34 12>copy

buf.writeUInt8(value[, offset])#

History

VersionChanges
v14.9.0, v12.19.0
This function is also available as buf.writeUint8().
v10.0.0
Removed noAssert and no implicit coercion of the offset to uint32 anymore.
v0.5.0
Added in: v0.5.0




value <integer> Number to be written to buf.
offset <integer> Number of bytes to skip before starting to write. Must
satisfy 0 <= offset <= buf.length - 1. Default: 0.
Returns: <integer> offset plus the number of bytes written.

Writes value to buf at the specified offset. value must be a
valid unsigned 8-bit integer. Behavior is undefined when value is anything
other than an unsigned 8-bit integer.
This function is also available under the writeUint8 alias.

import { Buffer } from 'node:buffer';

const buf = Buffer.allocUnsafe(4);

buf.writeUInt8(0x3, 0);
buf.writeUInt8(0x4, 1);
buf.writeUInt8(0x23, 2);
buf.writeUInt8(0x42, 3);

console.log(buf);
// Prints: <Buffer 03 04 23 42>const { Buffer } = require('node:buffer');

const buf = Buffer.allocUnsafe(4);

buf.writeUInt8(0x3, 0);
buf.writeUInt8(0x4, 1);
buf.writeUInt8(0x23, 2);
buf.writeUInt8(0x42, 3);

console.log(buf);
// Prints: <Buffer 03 04 23 42>copy

buf.writeUInt16BE(value[, offset])#

History

VersionChanges
v14.9.0, v12.19.0
This function is also available as buf.writeUint16BE().
v10.0.0
Removed noAssert and no implicit coercion of the offset to uint32 anymore.
v0.5.5
Added in: v0.5.5




value <integer> Number to be written to buf.
offset <integer> Number of bytes to skip before starting to write. Must
satisfy 0 <= offset <= buf.length - 2. Default: 0.
Returns: <integer> offset plus the number of bytes written.

Writes value to buf at the specified offset as big-endian. The value
must be a valid unsigned 16-bit integer. Behavior is undefined when value
is anything other than an unsigned 16-bit integer.
This function is also available under the writeUint16BE alias.

import { Buffer } from 'node:buffer';

const buf = Buffer.allocUnsafe(4);

buf.writeUInt16BE(0xdead, 0);
buf.writeUInt16BE(0xbeef, 2);

console.log(buf);
// Prints: <Buffer de ad be ef>const { Buffer } = require('node:buffer');

const buf = Buffer.allocUnsafe(4);

buf.writeUInt16BE(0xdead, 0);
buf.writeUInt16BE(0xbeef, 2);

console.log(buf);
// Prints: <Buffer de ad be ef>copy

buf.writeUInt16LE(value[, offset])#

History

VersionChanges
v14.9.0, v12.19.0
This function is also available as buf.writeUint16LE().
v10.0.0
Removed noAssert and no implicit coercion of the offset to uint32 anymore.
v0.5.5
Added in: v0.5.5




value <integer> Number to be written to buf.
offset <integer> Number of bytes to skip before starting to write. Must
satisfy 0 <= offset <= buf.length - 2. Default: 0.
Returns: <integer> offset plus the number of bytes written.

Writes value to buf at the specified offset as little-endian. The value
must be a valid unsigned 16-bit integer. Behavior is undefined when value is
anything other than an unsigned 16-bit integer.
This function is also available under the writeUint16LE alias.

import { Buffer } from 'node:buffer';

const buf = Buffer.allocUnsafe(4);

buf.writeUInt16LE(0xdead, 0);
buf.writeUInt16LE(0xbeef, 2);

console.log(buf);
// Prints: <Buffer ad de ef be>const { Buffer } = require('node:buffer');

const buf = Buffer.allocUnsafe(4);

buf.writeUInt16LE(0xdead, 0);
buf.writeUInt16LE(0xbeef, 2);

console.log(buf);
// Prints: <Buffer ad de ef be>copy

buf.writeUInt32BE(value[, offset])#

History

VersionChanges
v14.9.0, v12.19.0
This function is also available as buf.writeUint32BE().
v10.0.0
Removed noAssert and no implicit coercion of the offset to uint32 anymore.
v0.5.5
Added in: v0.5.5




value <integer> Number to be written to buf.
offset <integer> Number of bytes to skip before starting to write. Must
satisfy 0 <= offset <= buf.length - 4. Default: 0.
Returns: <integer> offset plus the number of bytes written.

Writes value to buf at the specified offset as big-endian. The value
must be a valid unsigned 32-bit integer. Behavior is undefined when value
is anything other than an unsigned 32-bit integer.
This function is also available under the writeUint32BE alias.

import { Buffer } from 'node:buffer';

const buf = Buffer.allocUnsafe(4);

buf.writeUInt32BE(0xfeedface, 0);

console.log(buf);
// Prints: <Buffer fe ed fa ce>const { Buffer } = require('node:buffer');

const buf = Buffer.allocUnsafe(4);

buf.writeUInt32BE(0xfeedface, 0);

console.log(buf);
// Prints: <Buffer fe ed fa ce>copy

buf.writeUInt32LE(value[, offset])#

History

VersionChanges
v14.9.0, v12.19.0
This function is also available as buf.writeUint32LE().
v10.0.0
Removed noAssert and no implicit coercion of the offset to uint32 anymore.
v0.5.5
Added in: v0.5.5




value <integer> Number to be written to buf.
offset <integer> Number of bytes to skip before starting to write. Must
satisfy 0 <= offset <= buf.length - 4. Default: 0.
Returns: <integer> offset plus the number of bytes written.

Writes value to buf at the specified offset as little-endian. The value
must be a valid unsigned 32-bit integer. Behavior is undefined when value is
anything other than an unsigned 32-bit integer.
This function is also available under the writeUint32LE alias.

import { Buffer } from 'node:buffer';

const buf = Buffer.allocUnsafe(4);

buf.writeUInt32LE(0xfeedface, 0);

console.log(buf);
// Prints: <Buffer ce fa ed fe>const { Buffer } = require('node:buffer');

const buf = Buffer.allocUnsafe(4);

buf.writeUInt32LE(0xfeedface, 0);

console.log(buf);
// Prints: <Buffer ce fa ed fe>copy

buf.writeUIntBE(value, offset, byteLength)#

History

VersionChanges
v14.9.0, v12.19.0
This function is also available as buf.writeUintBE().
v10.0.0
Removed noAssert and no implicit coercion of the offset and byteLength to uint32 anymore.
v0.5.5
Added in: v0.5.5




value <integer> Number to be written to buf.
offset <integer> Number of bytes to skip before starting to write. Must
satisfy 0 <= offset <= buf.length - byteLength.
byteLength <integer> Number of bytes to write. Must satisfy
0 < byteLength <= 6.
Returns: <integer> offset plus the number of bytes written.

Writes byteLength bytes of value to buf at the specified offset
as big-endian. Supports up to 48 bits of accuracy. Behavior is undefined
when value is anything other than an unsigned integer.
This function is also available under the writeUintBE alias.

import { Buffer } from 'node:buffer';

const buf = Buffer.allocUnsafe(6);

buf.writeUIntBE(0x1234567890ab, 0, 6);

console.log(buf);
// Prints: <Buffer 12 34 56 78 90 ab>const { Buffer } = require('node:buffer');

const buf = Buffer.allocUnsafe(6);

buf.writeUIntBE(0x1234567890ab, 0, 6);

console.log(buf);
// Prints: <Buffer 12 34 56 78 90 ab>copy

buf.writeUIntLE(value, offset, byteLength)#

History

VersionChanges
v14.9.0, v12.19.0
This function is also available as buf.writeUintLE().
v10.0.0
Removed noAssert and no implicit coercion of the offset and byteLength to uint32 anymore.
v0.5.5
Added in: v0.5.5




value <integer> Number to be written to buf.
offset <integer> Number of bytes to skip before starting to write. Must
satisfy 0 <= offset <= buf.length - byteLength.
byteLength <integer> Number of bytes to write. Must satisfy
0 < byteLength <= 6.
Returns: <integer> offset plus the number of bytes written.

Writes byteLength bytes of value to buf at the specified offset
as little-endian. Supports up to 48 bits of accuracy. Behavior is undefined
when value is anything other than an unsigned integer.
This function is also available under the writeUintLE alias.

import { Buffer } from 'node:buffer';

const buf = Buffer.allocUnsafe(6);

buf.writeUIntLE(0x1234567890ab, 0, 6);

console.log(buf);
// Prints: <Buffer ab 90 78 56 34 12>const { Buffer } = require('node:buffer');

const buf = Buffer.allocUnsafe(6);

buf.writeUIntLE(0x1234567890ab, 0, 6);

console.log(buf);
// Prints: <Buffer ab 90 78 56 34 12>copy

new Buffer(array)#

History

VersionChanges
v10.0.0
Calling this constructor emits a deprecation warning when run from code outside the node_modules directory.
v7.2.1
Calling this constructor no longer emits a deprecation warning.
v7.0.0
Calling this constructor emits a deprecation warning now.
v6.0.0
Deprecated since: v6.0.0



Stability: 0 - Deprecated: Use Buffer.from(array) instead.

array <integer[]> An array of bytes to copy from.

See Buffer.from(array).

new Buffer(arrayBuffer[, byteOffset[, length]])#

History

VersionChanges
v10.0.0
Calling this constructor emits a deprecation warning when run from code outside the node_modules directory.
v7.2.1
Calling this constructor no longer emits a deprecation warning.
v7.0.0
Calling this constructor emits a deprecation warning now.
v6.0.0
The byteOffset and length parameters are supported now.
v6.0.0
Deprecated since: v6.0.0
v3.0.0
Added in: v3.0.0



Stability: 0 - Deprecated: Use
Buffer.from(arrayBuffer[, byteOffset[, length]])
instead.

arrayBuffer <ArrayBuffer> | <SharedArrayBuffer> An <ArrayBuffer>,
<SharedArrayBuffer> or the .buffer property of a <TypedArray>.
byteOffset <integer> Index of first byte to expose. Default: 0.
length <integer> Number of bytes to expose.
Default: arrayBuffer.byteLength - byteOffset.

See
Buffer.from(arrayBuffer[, byteOffset[, length]]).

new Buffer(buffer)#

History

VersionChanges
v10.0.0
Calling this constructor emits a deprecation warning when run from code outside the node_modules directory.
v7.2.1
Calling this constructor no longer emits a deprecation warning.
v7.0.0
Calling this constructor emits a deprecation warning now.
v6.0.0
Deprecated since: v6.0.0



Stability: 0 - Deprecated: Use Buffer.from(buffer) instead.

buffer <Buffer> | <Uint8Array> An existing Buffer or <Uint8Array> from
which to copy data.

See Buffer.from(buffer).

new Buffer(size)#

History

VersionChanges
v10.0.0
Calling this constructor emits a deprecation warning when run from code outside the node_modules directory.
v8.0.0
The new Buffer(size) will return zero-filled memory by default.
v7.2.1
Calling this constructor no longer emits a deprecation warning.
v7.0.0
Calling this constructor emits a deprecation warning now.
v6.0.0
Deprecated since: v6.0.0



Stability: 0 - Deprecated: Use Buffer.alloc() instead (also see
Buffer.allocUnsafe()).

size <integer> The desired length of the new Buffer.

See Buffer.alloc() and Buffer.allocUnsafe(). This variant of the
constructor is equivalent to Buffer.alloc().

new Buffer(string[, encoding])#

History

VersionChanges
v10.0.0
Calling this constructor emits a deprecation warning when run from code outside the node_modules directory.
v7.2.1
Calling this constructor no longer emits a deprecation warning.
v7.0.0
Calling this constructor emits a deprecation warning now.
v6.0.0
Deprecated since: v6.0.0



Stability: 0 - Deprecated:
Use Buffer.from(string[, encoding]) instead.

string <string> String to encode.
encoding <string> The encoding of string. Default: 'utf8'.

See Buffer.from(string[, encoding]).

Class: File#

History

VersionChanges
v23.0.0
Makes File instances cloneable.
v20.0.0
No longer experimental.
v19.2.0, v18.13.0
Added in: v19.2.0, v18.13.0




Extends: <Blob>

A <File> provides information about files.

new buffer.File(sources, fileName[, options])#

Added in: v19.2.0, v18.13.0


sources <string[]> | <ArrayBuffer[]> | <TypedArray[]> | <DataView[]> | <Blob[]> | <File[]>
An array of string, <ArrayBuffer>, <TypedArray>, <DataView>, <File>, or <Blob>
objects, or any mix of such objects, that will be stored within the File.
fileName <string> The name of the file.
options <Object>

endings <string> One of either 'transparent' or 'native'. When set
to 'native', line endings in string source parts will be converted to
the platform native line-ending as specified by require('node:os').EOL.
type <string> The File content-type.
lastModified <number> The last modified date of the file.
Default: Date.now().




file.name#

Added in: v19.2.0, v18.13.0


Type: <string>

The name of the File.

file.lastModified#

Added in: v19.2.0, v18.13.0


Type: <number>

The last modified date of the File.

node:buffer module APIs#
While, the Buffer object is available as a global, there are additional
Buffer-related APIs that are available only via the node:buffer module
accessed using require('node:buffer').

buffer.atob(data)#

Added in: v15.13.0, v14.17.0

Stability: 3 - Legacy. Use Buffer.from(data, 'base64') instead.

data <any> The Base64-encoded input string.

Decodes a string of Base64-encoded data into bytes, and encodes those bytes
into a string using Latin-1 (ISO-8859-1).
The data may be any JavaScript-value that can be coerced into a string.
This function is only provided for compatibility with legacy web platform APIs
and should never be used in new code, because they use strings to represent
binary data and predate the introduction of typed arrays in JavaScript.
For code running using Node.js APIs, converting between base64-encoded strings
and binary data should be performed using Buffer.from(str, 'base64') and
buf.toString('base64').

buffer.btoa(data)#

Added in: v15.13.0, v14.17.0

Stability: 3 - Legacy. Use buf.toString('base64') instead.

data <any> An ASCII (Latin1) string.

Decodes a string into bytes using Latin-1 (ISO-8859), and encodes those bytes
into a string using Base64.
The data may be any JavaScript-value that can be coerced into a string.
This function is only provided for compatibility with legacy web platform APIs
and should never be used in new code, because they use strings to represent
binary data and predate the introduction of typed arrays in JavaScript.
For code running using Node.js APIs, converting between base64-encoded strings
and binary data should be performed using Buffer.from(str, 'base64') and
buf.toString('base64').

buffer.isAscii(input)#

Added in: v19.6.0, v18.15.0


input <Buffer> | <ArrayBuffer> | <TypedArray> The input to validate.
Returns: <boolean>

This function returns true if input contains only valid ASCII-encoded data,
including the case in which input is empty.
Throws if the input is a detached array buffer.

buffer.isUtf8(input)#

Added in: v19.4.0, v18.14.0


input <Buffer> | <ArrayBuffer> | <TypedArray> The input to validate.
Returns: <boolean>

This function returns true if input contains only valid UTF-8-encoded data,
including the case in which input is empty.
Throws if the input is a detached array buffer.

buffer.INSPECT_MAX_BYTES#

Added in: v0.5.4


<integer> Default: 50

Returns the maximum number of bytes that will be returned when
buf.inspect() is called. This can be overridden by user modules. See
util.inspect() for more details on buf.inspect() behavior.

buffer.kMaxLength#

Added in: v3.0.0


<integer> The largest size allowed for a single Buffer instance.

An alias for buffer.constants.MAX_LENGTH.

buffer.kStringMaxLength#

Added in: v3.0.0


<integer> The largest length allowed for a single string instance.

An alias for buffer.constants.MAX_STRING_LENGTH.

buffer.resolveObjectURL(id)#

History

VersionChanges
v24.0.0
Marking the API stable.
v16.7.0
Added in: v16.7.0




id <string> A 'blob:nodedata:... URL string returned by a prior call to
URL.createObjectURL().
Returns: <Blob>

Resolves a 'blob:nodedata:...' an associated <Blob> object registered using
a prior call to URL.createObjectURL().

buffer.transcode(source, fromEnc, toEnc)#

History

VersionChanges
v8.0.0
The source parameter can now be a Uint8Array.
v7.1.0
Added in: v7.1.0




source <Buffer> | <Uint8Array> A Buffer or Uint8Array instance.
fromEnc <string> The current encoding.
toEnc <string> To target encoding.
Returns: <Buffer>

Re-encodes the given Buffer or Uint8Array instance from one character
encoding to another. Returns a new Buffer instance.
Throws if the fromEnc or toEnc specify invalid character encodings or if
conversion from fromEnc to toEnc is not permitted.
Encodings supported by buffer.transcode() are: 'ascii', 'utf8',
'utf16le', 'ucs2', 'latin1', and 'binary'.
The transcoding process will use substitution characters if a given byte
sequence cannot be adequately represented in the target encoding. For instance:

import { Buffer, transcode } from 'node:buffer';

const newBuf = transcode(Buffer.from('€'), 'utf8', 'ascii');
console.log(newBuf.toString('ascii'));
// Prints: '?'const { Buffer, transcode } = require('node:buffer');

const newBuf = transcode(Buffer.from('€'), 'utf8', 'ascii');
console.log(newBuf.toString('ascii'));
// Prints: '?'copy
Because the Euro (€) sign is not representable in US-ASCII, it is replaced
with ? in the transcoded Buffer.

Class: SlowBuffer#

Deprecated since: v6.0.0

Stability: 0 - Deprecated: Use Buffer.allocUnsafeSlow() instead.
See Buffer.allocUnsafeSlow(). This was never a class in the sense that
the constructor always returned a Buffer instance, rather than a SlowBuffer
instance.

new SlowBuffer(size)#

Deprecated since: v6.0.0


size <integer> The desired length of the new SlowBuffer.

See Buffer.allocUnsafeSlow().

Buffer constants#

Added in: v8.2.0


buffer.constants.MAX_LENGTH#

History

VersionChanges
v22.0.0
Value is changed to 253 - 1 on 64-bit architectures.
v15.0.0
Value is changed to 232 on 64-bit architectures.
v14.0.0
Value is changed from 231 - 1 to 232 - 1 on 64-bit architectures.
v8.2.0
Added in: v8.2.0




<integer> The largest size allowed for a single Buffer instance.

On 32-bit architectures, this value currently is 230 - 1 (about 1
GiB).
On 64-bit architectures, this value currently is 253 - 1 (about 8 PiB).
It reflects v8::TypedArray::kMaxLength under the hood.
This value is also available as buffer.kMaxLength.

buffer.constants.MAX_STRING_LENGTH#

Added in: v8.2.0


<integer> The largest length allowed for a single string instance.

Represents the largest length that a string primitive can have, counted
in UTF-16 code units.
This value may depend on the JS engine that is being used.

Buffer.from(), Buffer.alloc(), and Buffer.allocUnsafe()#
In versions of Node.js prior to 6.0.0, Buffer instances were created using the
Buffer constructor function, which allocates the returned Buffer
differently based on what arguments are provided:

Passing a number as the first argument to Buffer() (e.g. new Buffer(10))
allocates a new Buffer object of the specified size. Prior to Node.js 8.0.0,
the memory allocated for such Buffer instances is not initialized and
can contain sensitive data. Such Buffer instances must be subsequently
initialized by using either buf.fill(0) or by writing to the
entire Buffer before reading data from the Buffer.
While this behavior is intentional to improve performance,
development experience has demonstrated that a more explicit distinction is
required between creating a fast-but-uninitialized Buffer versus creating a
slower-but-safer Buffer. Since Node.js 8.0.0, Buffer(num) and new Buffer(num) return a Buffer with initialized memory.
Passing a string, array, or Buffer as the first argument copies the
passed object's data into the Buffer.
Passing an <ArrayBuffer> or a <SharedArrayBuffer> returns a Buffer
that shares allocated memory with the given array buffer.

Because the behavior of new Buffer() is different depending on the type of the
first argument, security and reliability issues can be inadvertently introduced
into applications when argument validation or Buffer initialization is not
performed.
For example, if an attacker can cause an application to receive a number where
a string is expected, the application may call new Buffer(100)
instead of new Buffer("100"), leading it to allocate a 100 byte buffer instead
of allocating a 3 byte buffer with content "100". This is commonly possible
using JSON API calls. Since JSON distinguishes between numeric and string types,
it allows injection of numbers where a naively written application that does not
validate its input sufficiently might expect to always receive a string.
Before Node.js 8.0.0, the 100 byte buffer might contain
arbitrary pre-existing in-memory data, so may be used to expose in-memory
secrets to a remote attacker. Since Node.js 8.0.0, exposure of memory cannot
occur because the data is zero-filled. However, other attacks are still
possible, such as causing very large buffers to be allocated by the server,
leading to performance degradation or crashing on memory exhaustion.
To make the creation of Buffer instances more reliable and less error-prone,
the various forms of the new Buffer() constructor have been deprecated
and replaced by separate Buffer.from(), Buffer.alloc(), and
Buffer.allocUnsafe() methods.
Developers should migrate all existing uses of the new Buffer() constructors
to one of these new APIs.

Buffer.from(array) returns a new Buffer that contains a copy of the
provided octets.
Buffer.from(arrayBuffer[, byteOffset[, length]])
returns a new Buffer that shares the same allocated memory as the given
<ArrayBuffer>.
Buffer.from(buffer) returns a new Buffer that contains a copy of the
contents of the given Buffer.
Buffer.from(string[, encoding]) returns a new
Buffer that contains a copy of the provided string.
Buffer.alloc(size[, fill[, encoding]]) returns a new
initialized Buffer of the specified size. This method is slower than
Buffer.allocUnsafe(size) but guarantees that newly
created Buffer instances never contain old data that is potentially
sensitive. A TypeError will be thrown if size is not a number.
Buffer.allocUnsafe(size) and
Buffer.allocUnsafeSlow(size) each return a
new uninitialized Buffer of the specified size. Because the Buffer is
uninitialized, the allocated segment of memory might contain old data that is
potentially sensitive.

Buffer instances returned by Buffer.allocUnsafe(), Buffer.from(string),
Buffer.concat() and Buffer.from(array) may be allocated off a shared
internal memory pool if size is less than or equal to half Buffer.poolSize.
Instances returned by Buffer.allocUnsafeSlow() never use the shared internal
memory pool.

The --zero-fill-buffers command-line option#

Added in: v5.10.0

Node.js can be started using the --zero-fill-buffers command-line option to
cause all newly-allocated Buffer instances to be zero-filled upon creation by
default. Without the option, buffers created with Buffer.allocUnsafe(),
Buffer.allocUnsafeSlow(), and new SlowBuffer(size) are not zero-filled.
Use of this flag can have a measurable negative impact on performance. Use the
--zero-fill-buffers option only when necessary to enforce that newly allocated
Buffer instances cannot contain old data that is potentially sensitive.
$ node --zero-fill-buffers
> Buffer.allocUnsafe(5);
<Buffer 00 00 00 00 00> copy

What makes Buffer.allocUnsafe() and Buffer.allocUnsafeSlow() "unsafe"?#
When calling Buffer.allocUnsafe() and Buffer.allocUnsafeSlow(), the
segment of allocated memory is uninitialized (it is not zeroed-out). While
this design makes the allocation of memory quite fast, the allocated segment of
memory might contain old data that is potentially sensitive. Using a Buffer
created by Buffer.allocUnsafe() without completely overwriting the
memory can allow this old data to be leaked when the Buffer memory is read.
While there are clear performance advantages to using
Buffer.allocUnsafe(), extra care must be taken in order to avoid
introducing security vulnerabilities into an application.\n\n\n\nNode.js
        
      
      
About this documentation
Usage and example



Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Modules: TypeScript
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
Readline
REPL
Report
Single executable applications
SQLite
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker

    

    
      
        
          Node.js v24.0.1 documentation
          
            
            
          
        
        
          
            Node.js v24.0.1
            
    
      
        
        Table of contents
      

      
C++ addons

Hello world

Context-aware addons

Worker support


Building
Linking to libraries included with Node.js
Loading addons using require()


Native abstractions for Node.js
Node-API
Addon examples

Function arguments
Callbacks
Object factory
Function factory
Wrapping C++ objects
Factory of wrapped objects
Passing wrapped objects around





    
  
            
    
      
        
        Index
      

      
About this documentation
Usage and example

      
        Index
      
    
  


Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Modules: TypeScript
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
Readline
REPL
Report
Single executable applications
SQLite
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker

    
  
            
    
      
        
        Other versions
      
      24.x
23.x
22.x LTS
21.x
20.x LTS
19.x
18.x
17.x
16.x
15.x
14.x
13.x
12.x
11.x
10.x
9.x
8.x
7.x
6.x
5.x
4.x
0.12.x
0.10.x
    
  
            
              
                
                Options
              
        
              
                
                  
                    View on single page
                  
                  
                    View as JSON
                  
                  Edit on GitHub    
                
              
            
          
        
        
      

      Table of contents
C++ addons

Hello world

Context-aware addons

Worker support


Building
Linking to libraries included with Node.js
Loading addons using require()


Native abstractions for Node.js
Node-API
Addon examples

Function arguments
Callbacks
Object factory
Function factory
Wrapping C++ objects
Factory of wrapped objects
Passing wrapped objects around






      
        C++ addons#


Addons are dynamically-linked shared objects written in C++. The
require() function can load addons as ordinary Node.js modules.
Addons provide an interface between JavaScript and C/C++ libraries.
There are three options for implementing addons:

Node-API
nan (Native Abstractions for Node.js)
direct use of internal V8, libuv, and Node.js libraries

Unless there is a need for direct access to functionality which is not
exposed by Node-API, use Node-API.
Refer to C/C++ addons with Node-API for more information on
Node-API.
When not using Node-API, implementing addons becomes more complex, requiring
knowledge of multiple components and APIs:


V8: the C++ library Node.js uses to provide the
JavaScript implementation. It provides the mechanisms for creating objects,
calling functions, etc. The V8's API is documented mostly in the
v8.h header file (deps/v8/include/v8.h in the Node.js source
tree), and is also available online.


libuv: The C library that implements the Node.js event loop, its worker
threads and all of the asynchronous behaviors of the platform. It also
serves as a cross-platform abstraction library, giving easy, POSIX-like
access across all major operating systems to many common system tasks, such
as interacting with the file system, sockets, timers, and system events. libuv
also provides a threading abstraction similar to POSIX threads for
more sophisticated asynchronous addons that need to move beyond the
standard event loop. Addon authors should
avoid blocking the event loop with I/O or other time-intensive tasks by
offloading work via libuv to non-blocking system operations, worker threads,
or a custom use of libuv threads.


Internal Node.js libraries: Node.js itself exports C++ APIs that addons can
use, the most important of which is the node::ObjectWrap class.


Other statically linked libraries (including OpenSSL): These
other libraries are located in the deps/ directory in the Node.js source
tree. Only the libuv, OpenSSL, V8, and zlib symbols are purposefully
re-exported by Node.js and may be used to various extents by addons. See
Linking to libraries included with Node.js for additional information.


All of the following examples are available for download and may
be used as the starting-point for an addon.
Hello world#
This "Hello world" example is a simple addon, written in C++, that is the
equivalent of the following JavaScript code:
module.exports.hello = () => 'world'; copy
First, create the file hello.cc:
// hello.cc
#include <node.h>

namespace demo {

using v8::FunctionCallbackInfo;
using v8::Isolate;
using v8::Local;
using v8::NewStringType;
using v8::Object;
using v8::String;
using v8::Value;

void Method(const FunctionCallbackInfo<Value>& args) {
  Isolate* isolate = args.GetIsolate();
  args.GetReturnValue().Set(String::NewFromUtf8(
      isolate, "world", NewStringType::kNormal).ToLocalChecked());
}

void Initialize(Local<Object> exports) {
  NODE_SET_METHOD(exports, "hello", Method);
}

NODE_MODULE(NODE_GYP_MODULE_NAME, Initialize)

}  // namespace demo copy
All Node.js addons must export an initialization function following
the pattern:
void Initialize(Local<Object> exports);
NODE_MODULE(NODE_GYP_MODULE_NAME, Initialize) copy
There is no semi-colon after NODE_MODULE as it's not a function (see
node.h).
The module_name must match the filename of the final binary (excluding
the .node suffix).
In the hello.cc example, then, the initialization function is Initialize
and the addon module name is addon.
When building addons with node-gyp, using the macro NODE_GYP_MODULE_NAME as
the first parameter of NODE_MODULE() will ensure that the name of the final
binary will be passed to NODE_MODULE().
Addons defined with NODE_MODULE() can not be loaded in multiple contexts or
multiple threads at the same time.

Context-aware addons#
There are environments in which Node.js addons may need to be loaded multiple
times in multiple contexts. For example, the Electron runtime runs multiple
instances of Node.js in a single process. Each instance will have its own
require() cache, and thus each instance will need a native addon to behave
correctly when loaded via require(). This means that the addon
must support multiple initializations.
A context-aware addon can be constructed by using the macro
NODE_MODULE_INITIALIZER, which expands to the name of a function which Node.js
will expect to find when it loads an addon. An addon can thus be initialized as
in the following example:
using namespace v8;

extern "C" NODE_MODULE_EXPORT void
NODE_MODULE_INITIALIZER(Local<Object> exports,
                        Local<Value> module,
                        Local<Context> context) {
  /* Perform addon initialization steps here. */
} copy
Another option is to use the macro NODE_MODULE_INIT(), which will also
construct a context-aware addon. Unlike NODE_MODULE(), which is used to
construct an addon around a given addon initializer function,
NODE_MODULE_INIT() serves as the declaration of such an initializer to be
followed by a function body.
The following three variables may be used inside the function body following an
invocation of NODE_MODULE_INIT():

Local<Object> exports,
Local<Value> module, and
Local<Context> context

Building a context-aware addon requires careful management of global static data
to ensure stability and correctness. Since the addon may be loaded multiple
times, potentially even from different threads, any global static data stored
in the addon must be properly protected, and must not contain any persistent
references to JavaScript objects. The reason for this is that JavaScript
objects are only valid in one context, and will likely cause a crash when
accessed from the wrong context or from a different thread than the one on which
they were created.
The context-aware addon can be structured to avoid global static data by
performing the following steps:

Define a class which will hold per-addon-instance data and which has a static
member of the form
static void DeleteInstance(void* data) {
  // Cast `data` to an instance of the class and delete it.
} copy

Heap-allocate an instance of this class in the addon initializer. This can be
accomplished using the new keyword.
Call node::AddEnvironmentCleanupHook(), passing it the above-created
instance and a pointer to DeleteInstance(). This will ensure the instance is
deleted when the environment is torn down.
Store the instance of the class in a v8::External, and
Pass the v8::External to all methods exposed to JavaScript by passing it
to v8::FunctionTemplate::New() or v8::Function::New() which creates the
native-backed JavaScript functions. The third parameter of
v8::FunctionTemplate::New() or v8::Function::New()  accepts the
v8::External and makes it available in the native callback using the
v8::FunctionCallbackInfo::Data() method.

This will ensure that the per-addon-instance data reaches each binding that can
be called from JavaScript. The per-addon-instance data must also be passed into
any asynchronous callbacks the addon may create.
The following example illustrates the implementation of a context-aware addon:
#include <node.h>

using namespace v8;

class AddonData {
 public:
  explicit AddonData(Isolate* isolate):
      call_count(0) {
    // Ensure this per-addon-instance data is deleted at environment cleanup.
    node::AddEnvironmentCleanupHook(isolate, DeleteInstance, this);
  }

  // Per-addon data.
  int call_count;

  static void DeleteInstance(void* data) {
    delete static_cast<AddonData*>(data);
  }
};

static void Method(const v8::FunctionCallbackInfo<v8::Value>& info) {
  // Retrieve the per-addon-instance data.
  AddonData* data =
      reinterpret_cast<AddonData*>(info.Data().As<External>()->Value());
  data->call_count++;
  info.GetReturnValue().Set((double)data->call_count);
}

// Initialize this addon to be context-aware.
NODE_MODULE_INIT(/* exports, module, context */) {
  Isolate* isolate = context->GetIsolate();

  // Create a new instance of `AddonData` for this instance of the addon and
  // tie its life cycle to that of the Node.js environment.
  AddonData* data = new AddonData(isolate);

  // Wrap the data in a `v8::External` so we can pass it to the method we
  // expose.
  Local<External> external = External::New(isolate, data);

  // Expose the method `Method` to JavaScript, and make sure it receives the
  // per-addon-instance data we created above by passing `external` as the
  // third parameter to the `FunctionTemplate` constructor.
  exports->Set(context,
               String::NewFromUtf8(isolate, "method").ToLocalChecked(),
               FunctionTemplate::New(isolate, Method, external)
                  ->GetFunction(context).ToLocalChecked()).FromJust();
} copy

Worker support#

History

VersionChanges
v14.8.0, v12.19.0
Cleanup hooks may now be asynchronous.



In order to be loaded from multiple Node.js environments,
such as a main thread and a Worker thread, an add-on needs to either:

Be an Node-API addon, or
Be declared as context-aware using NODE_MODULE_INIT() as described above

In order to support Worker threads, addons need to clean up any resources
they may have allocated when such a thread exits. This can be achieved through
the usage of the AddEnvironmentCleanupHook() function:
void AddEnvironmentCleanupHook(v8::Isolate* isolate,
                               void (*fun)(void* arg),
                               void* arg); copy
This function adds a hook that will run before a given Node.js instance shuts
down. If necessary, such hooks can be removed before they are run using
RemoveEnvironmentCleanupHook(), which has the same signature. Callbacks are
run in last-in first-out order.
If necessary, there is an additional pair of AddEnvironmentCleanupHook()
and RemoveEnvironmentCleanupHook() overloads, where the cleanup hook takes a
callback function. This can be used for shutting down asynchronous resources,
such as any libuv handles registered by the addon.
The following addon.cc uses AddEnvironmentCleanupHook:
// addon.cc
#include <node.h>
#include <assert.h>
#include <stdlib.h>

using node::AddEnvironmentCleanupHook;
using v8::HandleScope;
using v8::Isolate;
using v8::Local;
using v8::Object;

// Note: In a real-world application, do not rely on static/global data.
static char cookie[] = "yum yum";
static int cleanup_cb1_called = 0;
static int cleanup_cb2_called = 0;

static void cleanup_cb1(void* arg) {
  Isolate* isolate = static_cast<Isolate*>(arg);
  HandleScope scope(isolate);
  Local<Object> obj = Object::New(isolate);
  assert(!obj.IsEmpty());  // assert VM is still alive
  assert(obj->IsObject());
  cleanup_cb1_called++;
}

static void cleanup_cb2(void* arg) {
  assert(arg == static_cast<void*>(cookie));
  cleanup_cb2_called++;
}

static void sanity_check(void*) {
  assert(cleanup_cb1_called == 1);
  assert(cleanup_cb2_called == 1);
}

// Initialize this addon to be context-aware.
NODE_MODULE_INIT(/* exports, module, context */) {
  Isolate* isolate = context->GetIsolate();

  AddEnvironmentCleanupHook(isolate, sanity_check, nullptr);
  AddEnvironmentCleanupHook(isolate, cleanup_cb2, cookie);
  AddEnvironmentCleanupHook(isolate, cleanup_cb1, isolate);
} copy
Test in JavaScript by running:
// test.js
require('./build/Release/addon'); copy

Building#
Once the source code has been written, it must be compiled into the binary
addon.node file. To do so, create a file called binding.gyp in the
top-level of the project describing the build configuration of the module
using a JSON-like format. This file is used by node-gyp, a tool written
specifically to compile Node.js addons.
{
  "targets": [
    {
      "target_name": "addon",
      "sources": [ "hello.cc" ]
    }
  ]
} copy
A version of the node-gyp utility is bundled and distributed with
Node.js as part of npm. This version is not made directly available for
developers to use and is intended only to support the ability to use the
npm install command to compile and install addons. Developers who wish to
use node-gyp directly can install it using the command
npm install -g node-gyp. See the node-gyp installation instructions for
more information, including platform-specific requirements.
Once the binding.gyp file has been created, use node-gyp configure to
generate the appropriate project build files for the current platform. This
will generate either a Makefile (on Unix platforms) or a vcxproj file
(on Windows) in the build/ directory.
Next, invoke the node-gyp build command to generate the compiled addon.node
file. This will be put into the build/Release/ directory.
When using npm install to install a Node.js addon, npm uses its own bundled
version of node-gyp to perform this same set of actions, generating a
compiled version of the addon for the user's platform on demand.
Once built, the binary addon can be used from within Node.js by pointing
require() to the built addon.node module:
// hello.js
const addon = require('./build/Release/addon');

console.log(addon.hello());
// Prints: 'world' copy
Because the exact path to the compiled addon binary can vary depending on how
it is compiled (i.e. sometimes it may be in ./build/Debug/), addons can use
the bindings package to load the compiled module.
While the bindings package implementation is more sophisticated in how it
locates addon modules, it is essentially using a try…catch pattern similar to:
try {
  return require('./build/Release/addon.node');
} catch (err) {
  return require('./build/Debug/addon.node');
} copy

Linking to libraries included with Node.js#
Node.js uses statically linked libraries such as V8, libuv, and OpenSSL. All
addons are required to link to V8 and may link to any of the other dependencies
as well. Typically, this is as simple as including the appropriate
#include <...> statements (e.g. #include <v8.h>) and node-gyp will locate
the appropriate headers automatically. However, there are a few caveats to be
aware of:


When node-gyp runs, it will detect the specific release version of Node.js
and download either the full source tarball or just the headers. If the full
source is downloaded, addons will have complete access to the full set of
Node.js dependencies. However, if only the Node.js headers are downloaded,
then only the symbols exported by Node.js will be available.


node-gyp can be run using the --nodedir flag pointing at a local Node.js
source image. Using this option, the addon will have access to the full set of
dependencies.



Loading addons using require()#
The filename extension of the compiled addon binary is .node (as opposed
to .dll or .so). The require() function is written to look for
files with the .node file extension and initialize those as dynamically-linked
libraries.
When calling require(), the .node extension can usually be
omitted and Node.js will still find and initialize the addon. One caveat,
however, is that Node.js will first attempt to locate and load modules or
JavaScript files that happen to share the same base name. For instance, if
there is a file addon.js in the same directory as the binary addon.node,
then require('addon') will give precedence to the addon.js file
and load it instead.

Native abstractions for Node.js#
Each of the examples illustrated in this document directly use the
Node.js and V8 APIs for implementing addons. The V8 API can, and has, changed
dramatically from one V8 release to the next (and one major Node.js release to
the next). With each change, addons may need to be updated and recompiled in
order to continue functioning. The Node.js release schedule is designed to
minimize the frequency and impact of such changes but there is little that
Node.js can do to ensure stability of the V8 APIs.
The Native Abstractions for Node.js (or nan) provide a set of tools that
addon developers are recommended to use to keep compatibility between past and
future releases of V8 and Node.js. See the nan examples for an
illustration of how it can be used.
Node-API#
Stability: 2 - Stable
Node-API is an API for building native addons. It is independent from
the underlying JavaScript runtime (e.g. V8) and is maintained as part of
Node.js itself. This API will be Application Binary Interface (ABI) stable
across versions of Node.js. It is intended to insulate addons from
changes in the underlying JavaScript engine and allow modules
compiled for one version to run on later versions of Node.js without
recompilation. Addons are built/packaged with the same approach/tools
outlined in this document (node-gyp, etc.). The only difference is the
set of APIs that are used by the native code. Instead of using the V8
or Native Abstractions for Node.js APIs, the functions available
in the Node-API are used.
Creating and maintaining an addon that benefits from the ABI stability
provided by Node-API carries with it certain
implementation considerations.
To use Node-API in the above "Hello world" example, replace the content of
hello.cc with the following. All other instructions remain the same.
// hello.cc using Node-API
#include <node_api.h>

namespace demo {

napi_value Method(napi_env env, napi_callback_info args) {
  napi_value greeting;
  napi_status status;

  status = napi_create_string_utf8(env, "world", NAPI_AUTO_LENGTH, &greeting);
  if (status != napi_ok) return nullptr;
  return greeting;
}

napi_value init(napi_env env, napi_value exports) {
  napi_status status;
  napi_value fn;

  status = napi_create_function(env, nullptr, 0, Method, nullptr, &fn);
  if (status != napi_ok) return nullptr;

  status = napi_set_named_property(env, exports, "hello", fn);
  if (status != napi_ok) return nullptr;
  return exports;
}

NAPI_MODULE(NODE_GYP_MODULE_NAME, init)

}  // namespace demo copy
The functions available and how to use them are documented in
C/C++ addons with Node-API.
Addon examples#
Following are some example addons intended to help developers get started. The
examples use the V8 APIs. Refer to the online V8 reference
for help with the various V8 calls, and V8's Embedder's Guide for an
explanation of several concepts used such as handles, scopes, function
templates, etc.
Each of these examples using the following binding.gyp file:
{
  "targets": [
    {
      "target_name": "addon",
      "sources": [ "addon.cc" ]
    }
  ]
} copy
In cases where there is more than one .cc file, simply add the additional
filename to the sources array:
"sources": ["addon.cc", "myexample.cc"] copy
Once the binding.gyp file is ready, the example addons can be configured and
built using node-gyp:
node-gyp configure build copy

Function arguments#
Addons will typically expose objects and functions that can be accessed from
JavaScript running within Node.js. When functions are invoked from JavaScript,
the input arguments and return value must be mapped to and from the C/C++
code.
The following example illustrates how to read function arguments passed from
JavaScript and how to return a result:
// addon.cc
#include <node.h>

namespace demo {

using v8::Exception;
using v8::FunctionCallbackInfo;
using v8::Isolate;
using v8::Local;
using v8::Number;
using v8::Object;
using v8::String;
using v8::Value;

// This is the implementation of the "add" method
// Input arguments are passed using the
// const FunctionCallbackInfo<Value>& args struct
void Add(const FunctionCallbackInfo<Value>& args) {
  Isolate* isolate = args.GetIsolate();

  // Check the number of arguments passed.
  if (args.Length() < 2) {
    // Throw an Error that is passed back to JavaScript
    isolate->ThrowException(Exception::TypeError(
        String::NewFromUtf8(isolate,
                            "Wrong number of arguments").ToLocalChecked()));
    return;
  }

  // Check the argument types
  if (!args[0]->IsNumber() || !args[1]->IsNumber()) {
    isolate->ThrowException(Exception::TypeError(
        String::NewFromUtf8(isolate,
                            "Wrong arguments").ToLocalChecked()));
    return;
  }

  // Perform the operation
  double value =
      args[0].As<Number>()->Value() + args[1].As<Number>()->Value();
  Local<Number> num = Number::New(isolate, value);

  // Set the return value (using the passed in
  // FunctionCallbackInfo<Value>&)
  args.GetReturnValue().Set(num);
}

void Init(Local<Object> exports) {
  NODE_SET_METHOD(exports, "add", Add);
}

NODE_MODULE(NODE_GYP_MODULE_NAME, Init)

}  // namespace demo copy
Once compiled, the example addon can be required and used from within Node.js:
// test.js
const addon = require('./build/Release/addon');

console.log('This should be eight:', addon.add(3, 5)); copy

Callbacks#
It is common practice within addons to pass JavaScript functions to a C++
function and execute them from there. The following example illustrates how
to invoke such callbacks:
// addon.cc
#include <node.h>

namespace demo {

using v8::Context;
using v8::Function;
using v8::FunctionCallbackInfo;
using v8::Isolate;
using v8::Local;
using v8::Null;
using v8::Object;
using v8::String;
using v8::Value;

void RunCallback(const FunctionCallbackInfo<Value>& args) {
  Isolate* isolate = args.GetIsolate();
  Local<Context> context = isolate->GetCurrentContext();
  Local<Function> cb = Local<Function>::Cast(args[0]);
  const unsigned argc = 1;
  Local<Value> argv[argc] = {
      String::NewFromUtf8(isolate,
                          "hello world").ToLocalChecked() };
  cb->Call(context, Null(isolate), argc, argv).ToLocalChecked();
}

void Init(Local<Object> exports, Local<Object> module) {
  NODE_SET_METHOD(module, "exports", RunCallback);
}

NODE_MODULE(NODE_GYP_MODULE_NAME, Init)

}  // namespace demo copy
This example uses a two-argument form of Init() that receives the full
module object as the second argument. This allows the addon to completely
overwrite exports with a single function instead of adding the function as a
property of exports.
To test it, run the following JavaScript:
// test.js
const addon = require('./build/Release/addon');

addon((msg) => {
  console.log(msg);
// Prints: 'hello world'
}); copy
In this example, the callback function is invoked synchronously.

Object factory#
Addons can create and return new objects from within a C++ function as
illustrated in the following example. An object is created and returned with a
property msg that echoes the string passed to createObject():
// addon.cc
#include <node.h>

namespace demo {

using v8::Context;
using v8::FunctionCallbackInfo;
using v8::Isolate;
using v8::Local;
using v8::Object;
using v8::String;
using v8::Value;

void CreateObject(const FunctionCallbackInfo<Value>& args) {
  Isolate* isolate = args.GetIsolate();
  Local<Context> context = isolate->GetCurrentContext();

  Local<Object> obj = Object::New(isolate);
  obj->Set(context,
           String::NewFromUtf8(isolate,
                               "msg").ToLocalChecked(),
                               args[0]->ToString(context).ToLocalChecked())
           .FromJust();

  args.GetReturnValue().Set(obj);
}

void Init(Local<Object> exports, Local<Object> module) {
  NODE_SET_METHOD(module, "exports", CreateObject);
}

NODE_MODULE(NODE_GYP_MODULE_NAME, Init)

}  // namespace demo copy
To test it in JavaScript:
// test.js
const addon = require('./build/Release/addon');

const obj1 = addon('hello');
const obj2 = addon('world');
console.log(obj1.msg, obj2.msg);
// Prints: 'hello world' copy

Function factory#
Another common scenario is creating JavaScript functions that wrap C++
functions and returning those back to JavaScript:
// addon.cc
#include <node.h>

namespace demo {

using v8::Context;
using v8::Function;
using v8::FunctionCallbackInfo;
using v8::FunctionTemplate;
using v8::Isolate;
using v8::Local;
using v8::Object;
using v8::String;
using v8::Value;

void MyFunction(const FunctionCallbackInfo<Value>& args) {
  Isolate* isolate = args.GetIsolate();
  args.GetReturnValue().Set(String::NewFromUtf8(
      isolate, "hello world").ToLocalChecked());
}

void CreateFunction(const FunctionCallbackInfo<Value>& args) {
  Isolate* isolate = args.GetIsolate();

  Local<Context> context = isolate->GetCurrentContext();
  Local<FunctionTemplate> tpl = FunctionTemplate::New(isolate, MyFunction);
  Local<Function> fn = tpl->GetFunction(context).ToLocalChecked();

  // omit this to make it anonymous
  fn->SetName(String::NewFromUtf8(
      isolate, "theFunction").ToLocalChecked());

  args.GetReturnValue().Set(fn);
}

void Init(Local<Object> exports, Local<Object> module) {
  NODE_SET_METHOD(module, "exports", CreateFunction);
}

NODE_MODULE(NODE_GYP_MODULE_NAME, Init)

}  // namespace demo copy
To test:
// test.js
const addon = require('./build/Release/addon');

const fn = addon();
console.log(fn());
// Prints: 'hello world' copy

Wrapping C++ objects#
It is also possible to wrap C++ objects/classes in a way that allows new
instances to be created using the JavaScript new operator:
// addon.cc
#include <node.h>
#include "myobject.h"

namespace demo {

using v8::Local;
using v8::Object;

void InitAll(Local<Object> exports) {
  MyObject::Init(exports);
}

NODE_MODULE(NODE_GYP_MODULE_NAME, InitAll)

}  // namespace demo copy
Then, in myobject.h, the wrapper class inherits from node::ObjectWrap:
// myobject.h
#ifndef MYOBJECT_H
#define MYOBJECT_H

#include <node.h>
#include <node_object_wrap.h>

namespace demo {

class MyObject : public node::ObjectWrap {
 public:
  static void Init(v8::Local<v8::Object> exports);

 private:
  explicit MyObject(double value = 0);
  ~MyObject();

  static void New(const v8::FunctionCallbackInfo<v8::Value>& args);
  static void PlusOne(const v8::FunctionCallbackInfo<v8::Value>& args);

  double value_;
};

}  // namespace demo

#endif copy
In myobject.cc, implement the various methods that are to be exposed.
In the following code, the method plusOne() is exposed by adding it to the
constructor's prototype:
// myobject.cc
#include "myobject.h"

namespace demo {

using v8::Context;
using v8::Function;
using v8::FunctionCallbackInfo;
using v8::FunctionTemplate;
using v8::Isolate;
using v8::Local;
using v8::Number;
using v8::Object;
using v8::ObjectTemplate;
using v8::String;
using v8::Value;

MyObject::MyObject(double value) : value_(value) {
}

MyObject::~MyObject() {
}

void MyObject::Init(Local<Object> exports) {
  Isolate* isolate = exports->GetIsolate();
  Local<Context> context = isolate->GetCurrentContext();

  Local<ObjectTemplate> addon_data_tpl = ObjectTemplate::New(isolate);
  addon_data_tpl->SetInternalFieldCount(1);  // 1 field for the MyObject::New()
  Local<Object> addon_data =
      addon_data_tpl->NewInstance(context).ToLocalChecked();

  // Prepare constructor template
  Local<FunctionTemplate> tpl = FunctionTemplate::New(isolate, New, addon_data);
  tpl->SetClassName(String::NewFromUtf8(isolate, "MyObject").ToLocalChecked());
  tpl->InstanceTemplate()->SetInternalFieldCount(1);

  // Prototype
  NODE_SET_PROTOTYPE_METHOD(tpl, "plusOne", PlusOne);

  Local<Function> constructor = tpl->GetFunction(context).ToLocalChecked();
  addon_data->SetInternalField(0, constructor);
  exports->Set(context, String::NewFromUtf8(
      isolate, "MyObject").ToLocalChecked(),
      constructor).FromJust();
}

void MyObject::New(const FunctionCallbackInfo<Value>& args) {
  Isolate* isolate = args.GetIsolate();
  Local<Context> context = isolate->GetCurrentContext();

  if (args.IsConstructCall()) {
    // Invoked as constructor: `new MyObject(...)`
    double value = args[0]->IsUndefined() ?
        0 : args[0]->NumberValue(context).FromMaybe(0);
    MyObject* obj = new MyObject(value);
    obj->Wrap(args.This());
    args.GetReturnValue().Set(args.This());
  } else {
    // Invoked as plain function `MyObject(...)`, turn into construct call.
    const int argc = 1;
    Local<Value> argv[argc] = { args[0] };
    Local<Function> cons =
        args.Data().As<Object>()->GetInternalField(0)
            .As<Value>().As<Function>();
    Local<Object> result =
        cons->NewInstance(context, argc, argv).ToLocalChecked();
    args.GetReturnValue().Set(result);
  }
}

void MyObject::PlusOne(const FunctionCallbackInfo<Value>& args) {
  Isolate* isolate = args.GetIsolate();

  MyObject* obj = ObjectWrap::Unwrap<MyObject>(args.This());
  obj->value_ += 1;

  args.GetReturnValue().Set(Number::New(isolate, obj->value_));
}

}  // namespace demo copy
To build this example, the myobject.cc file must be added to the
binding.gyp:
{
  "targets": [
    {
      "target_name": "addon",
      "sources": [
        "addon.cc",
        "myobject.cc"
      ]
    }
  ]
} copy
Test it with:
// test.js
const addon = require('./build/Release/addon');

const obj = new addon.MyObject(10);
console.log(obj.plusOne());
// Prints: 11
console.log(obj.plusOne());
// Prints: 12
console.log(obj.plusOne());
// Prints: 13 copy
The destructor for a wrapper object will run when the object is
garbage-collected. For destructor testing, there are command-line flags that
can be used to make it possible to force garbage collection. These flags are
provided by the underlying V8 JavaScript engine. They are subject to change
or removal at any time. They are not documented by Node.js or V8, and they
should never be used outside of testing.
During shutdown of the process or worker threads destructors are not called
by the JS engine. Therefore it's the responsibility of the user to track
these objects and ensure proper destruction to avoid resource leaks.

Factory of wrapped objects#
Alternatively, it is possible to use a factory pattern to avoid explicitly
creating object instances using the JavaScript new operator:
const obj = addon.createObject();
// instead of:
// const obj = new addon.Object(); copy
First, the createObject() method is implemented in addon.cc:
// addon.cc
#include <node.h>
#include "myobject.h"

namespace demo {

using v8::FunctionCallbackInfo;
using v8::Isolate;
using v8::Local;
using v8::Object;
using v8::String;
using v8::Value;

void CreateObject(const FunctionCallbackInfo<Value>& args) {
  MyObject::NewInstance(args);
}

void InitAll(Local<Object> exports, Local<Object> module) {
  MyObject::Init(exports->GetIsolate());

  NODE_SET_METHOD(module, "exports", CreateObject);
}

NODE_MODULE(NODE_GYP_MODULE_NAME, InitAll)

}  // namespace demo copy
In myobject.h, the static method NewInstance() is added to handle
instantiating the object. This method takes the place of using new in
JavaScript:
// myobject.h
#ifndef MYOBJECT_H
#define MYOBJECT_H

#include <node.h>
#include <node_object_wrap.h>

namespace demo {

class MyObject : public node::ObjectWrap {
 public:
  static void Init(v8::Isolate* isolate);
  static void NewInstance(const v8::FunctionCallbackInfo<v8::Value>& args);

 private:
  explicit MyObject(double value = 0);
  ~MyObject();

  static void New(const v8::FunctionCallbackInfo<v8::Value>& args);
  static void PlusOne(const v8::FunctionCallbackInfo<v8::Value>& args);
  static v8::Global<v8::Function> constructor;
  double value_;
};

}  // namespace demo

#endif copy
The implementation in myobject.cc is similar to the previous example:
// myobject.cc
#include <node.h>
#include "myobject.h"

namespace demo {

using node::AddEnvironmentCleanupHook;
using v8::Context;
using v8::Function;
using v8::FunctionCallbackInfo;
using v8::FunctionTemplate;
using v8::Global;
using v8::Isolate;
using v8::Local;
using v8::Number;
using v8::Object;
using v8::String;
using v8::Value;

// Warning! This is not thread-safe, this addon cannot be used for worker
// threads.
Global<Function> MyObject::constructor;

MyObject::MyObject(double value) : value_(value) {
}

MyObject::~MyObject() {
}

void MyObject::Init(Isolate* isolate) {
  // Prepare constructor template
  Local<FunctionTemplate> tpl = FunctionTemplate::New(isolate, New);
  tpl->SetClassName(String::NewFromUtf8(isolate, "MyObject").ToLocalChecked());
  tpl->InstanceTemplate()->SetInternalFieldCount(1);

  // Prototype
  NODE_SET_PROTOTYPE_METHOD(tpl, "plusOne", PlusOne);

  Local<Context> context = isolate->GetCurrentContext();
  constructor.Reset(isolate, tpl->GetFunction(context).ToLocalChecked());

  AddEnvironmentCleanupHook(isolate, [](void*) {
    constructor.Reset();
  }, nullptr);
}

void MyObject::New(const FunctionCallbackInfo<Value>& args) {
  Isolate* isolate = args.GetIsolate();
  Local<Context> context = isolate->GetCurrentContext();

  if (args.IsConstructCall()) {
    // Invoked as constructor: `new MyObject(...)`
    double value = args[0]->IsUndefined() ?
        0 : args[0]->NumberValue(context).FromMaybe(0);
    MyObject* obj = new MyObject(value);
    obj->Wrap(args.This());
    args.GetReturnValue().Set(args.This());
  } else {
    // Invoked as plain function `MyObject(...)`, turn into construct call.
    const int argc = 1;
    Local<Value> argv[argc] = { args[0] };
    Local<Function> cons = Local<Function>::New(isolate, constructor);
    Local<Object> instance =
        cons->NewInstance(context, argc, argv).ToLocalChecked();
    args.GetReturnValue().Set(instance);
  }
}

void MyObject::NewInstance(const FunctionCallbackInfo<Value>& args) {
  Isolate* isolate = args.GetIsolate();

  const unsigned argc = 1;
  Local<Value> argv[argc] = { args[0] };
  Local<Function> cons = Local<Function>::New(isolate, constructor);
  Local<Context> context = isolate->GetCurrentContext();
  Local<Object> instance =
      cons->NewInstance(context, argc, argv).ToLocalChecked();

  args.GetReturnValue().Set(instance);
}

void MyObject::PlusOne(const FunctionCallbackInfo<Value>& args) {
  Isolate* isolate = args.GetIsolate();

  MyObject* obj = ObjectWrap::Unwrap<MyObject>(args.This());
  obj->value_ += 1;

  args.GetReturnValue().Set(Number::New(isolate, obj->value_));
}

}  // namespace demo copy
Once again, to build this example, the myobject.cc file must be added to the
binding.gyp:
{
  "targets": [
    {
      "target_name": "addon",
      "sources": [
        "addon.cc",
        "myobject.cc"
      ]
    }
  ]
} copy
Test it with:
// test.js
const createObject = require('./build/Release/addon');

const obj = createObject(10);
console.log(obj.plusOne());
// Prints: 11
console.log(obj.plusOne());
// Prints: 12
console.log(obj.plusOne());
// Prints: 13

const obj2 = createObject(20);
console.log(obj2.plusOne());
// Prints: 21
console.log(obj2.plusOne());
// Prints: 22
console.log(obj2.plusOne());
// Prints: 23 copy

Passing wrapped objects around#
In addition to wrapping and returning C++ objects, it is possible to pass
wrapped objects around by unwrapping them with the Node.js helper function
node::ObjectWrap::Unwrap. The following examples shows a function add()
that can take two MyObject objects as input arguments:
// addon.cc
#include <node.h>
#include <node_object_wrap.h>
#include "myobject.h"

namespace demo {

using v8::Context;
using v8::FunctionCallbackInfo;
using v8::Isolate;
using v8::Local;
using v8::Number;
using v8::Object;
using v8::String;
using v8::Value;

void CreateObject(const FunctionCallbackInfo<Value>& args) {
  MyObject::NewInstance(args);
}

void Add(const FunctionCallbackInfo<Value>& args) {
  Isolate* isolate = args.GetIsolate();
  Local<Context> context = isolate->GetCurrentContext();

  MyObject* obj1 = node::ObjectWrap::Unwrap<MyObject>(
      args[0]->ToObject(context).ToLocalChecked());
  MyObject* obj2 = node::ObjectWrap::Unwrap<MyObject>(
      args[1]->ToObject(context).ToLocalChecked());

  double sum = obj1->value() + obj2->value();
  args.GetReturnValue().Set(Number::New(isolate, sum));
}

void InitAll(Local<Object> exports) {
  MyObject::Init(exports->GetIsolate());

  NODE_SET_METHOD(exports, "createObject", CreateObject);
  NODE_SET_METHOD(exports, "add", Add);
}

NODE_MODULE(NODE_GYP_MODULE_NAME, InitAll)

}  // namespace demo copy
In myobject.h, a new public method is added to allow access to private values
after unwrapping the object.
// myobject.h
#ifndef MYOBJECT_H
#define MYOBJECT_H

#include <node.h>
#include <node_object_wrap.h>

namespace demo {

class MyObject : public node::ObjectWrap {
 public:
  static void Init(v8::Isolate* isolate);
  static void NewInstance(const v8::FunctionCallbackInfo<v8::Value>& args);
  inline double value() const { return value_; }

 private:
  explicit MyObject(double value = 0);
  ~MyObject();

  static void New(const v8::FunctionCallbackInfo<v8::Value>& args);
  static v8::Global<v8::Function> constructor;
  double value_;
};

}  // namespace demo

#endif copy
The implementation of myobject.cc remains similar to the previous version:
// myobject.cc
#include <node.h>
#include "myobject.h"

namespace demo {

using node::AddEnvironmentCleanupHook;
using v8::Context;
using v8::Function;
using v8::FunctionCallbackInfo;
using v8::FunctionTemplate;
using v8::Global;
using v8::Isolate;
using v8::Local;
using v8::Object;
using v8::String;
using v8::Value;

// Warning! This is not thread-safe, this addon cannot be used for worker
// threads.
Global<Function> MyObject::constructor;

MyObject::MyObject(double value) : value_(value) {
}

MyObject::~MyObject() {
}

void MyObject::Init(Isolate* isolate) {
  // Prepare constructor template
  Local<FunctionTemplate> tpl = FunctionTemplate::New(isolate, New);
  tpl->SetClassName(String::NewFromUtf8(isolate, "MyObject").ToLocalChecked());
  tpl->InstanceTemplate()->SetInternalFieldCount(1);

  Local<Context> context = isolate->GetCurrentContext();
  constructor.Reset(isolate, tpl->GetFunction(context).ToLocalChecked());

  AddEnvironmentCleanupHook(isolate, [](void*) {
    constructor.Reset();
  }, nullptr);
}

void MyObject::New(const FunctionCallbackInfo<Value>& args) {
  Isolate* isolate = args.GetIsolate();
  Local<Context> context = isolate->GetCurrentContext();

  if (args.IsConstructCall()) {
    // Invoked as constructor: `new MyObject(...)`
    double value = args[0]->IsUndefined() ?
        0 : args[0]->NumberValue(context).FromMaybe(0);
    MyObject* obj = new MyObject(value);
    obj->Wrap(args.This());
    args.GetReturnValue().Set(args.This());
  } else {
    // Invoked as plain function `MyObject(...)`, turn into construct call.
    const int argc = 1;
    Local<Value> argv[argc] = { args[0] };
    Local<Function> cons = Local<Function>::New(isolate, constructor);
    Local<Object> instance =
        cons->NewInstance(context, argc, argv).ToLocalChecked();
    args.GetReturnValue().Set(instance);
  }
}

void MyObject::NewInstance(const FunctionCallbackInfo<Value>& args) {
  Isolate* isolate = args.GetIsolate();

  const unsigned argc = 1;
  Local<Value> argv[argc] = { args[0] };
  Local<Function> cons = Local<Function>::New(isolate, constructor);
  Local<Context> context = isolate->GetCurrentContext();
  Local<Object> instance =
      cons->NewInstance(context, argc, argv).ToLocalChecked();

  args.GetReturnValue().Set(instance);
}

}  // namespace demo copy
Test it with:
// test.js
const addon = require('./build/Release/addon');

const obj1 = addon.createObject(10);
const obj2 = addon.createObject(20);
const result = addon.add(obj1, obj2);

console.log(result);
// Prints: 30 copy\n\n\n\nNode.js
        
      
      
About this documentation
Usage and example



Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Modules: TypeScript
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
Readline
REPL
Report
Single executable applications
SQLite
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker

    

    
      
        
          Node.js v24.0.1 documentation
          
            
            
          
        
        
          
            Node.js v24.0.1
            
    
      
        
        Table of contents
      

      
Node-API

Implications of ABI stability
Building

Build tools

node-gyp
CMake.js


Uploading precompiled binaries

node-pre-gyp
prebuild
prebuildify




Usage
Node-API version matrix
Environment life cycle APIs

napi_set_instance_data
napi_get_instance_data


Basic Node-API data types

napi_status
napi_extended_error_info
napi_env
node_api_basic_env
napi_value
napi_threadsafe_function
napi_threadsafe_function_release_mode
napi_threadsafe_function_call_mode
Node-API memory management types

napi_handle_scope
napi_escapable_handle_scope
napi_ref
napi_type_tag
napi_async_cleanup_hook_handle


Node-API callback types

napi_callback_info
napi_callback
node_api_basic_finalize
napi_finalize
napi_async_execute_callback
napi_async_complete_callback
napi_threadsafe_function_call_js
napi_cleanup_hook
napi_async_cleanup_hook




Error handling

Return values

napi_get_last_error_info


Exceptions

napi_throw
napi_throw_error
napi_throw_type_error
napi_throw_range_error
node_api_throw_syntax_error
napi_is_error
napi_create_error
napi_create_type_error
napi_create_range_error
node_api_create_syntax_error
napi_get_and_clear_last_exception
napi_is_exception_pending
napi_fatal_exception


Fatal errors

napi_fatal_error




Object lifetime management

Making handle lifespan shorter than that of the native method

napi_open_handle_scope
napi_close_handle_scope
napi_open_escapable_handle_scope
napi_close_escapable_handle_scope
napi_escape_handle


References to values with a lifespan longer than that of the native method

napi_create_reference
napi_delete_reference
napi_reference_ref
napi_reference_unref
napi_get_reference_value


Cleanup on exit of the current Node.js environment

napi_add_env_cleanup_hook
napi_remove_env_cleanup_hook
napi_add_async_cleanup_hook
napi_remove_async_cleanup_hook


Finalization on the exit of the Node.js environment


Module registration
Working with JavaScript values

Enum types

napi_key_collection_mode
napi_key_filter
napi_key_conversion
napi_valuetype
napi_typedarray_type


Object creation functions

napi_create_array
napi_create_array_with_length
napi_create_arraybuffer
napi_create_buffer
napi_create_buffer_copy
napi_create_date
napi_create_external
napi_create_external_arraybuffer
napi_create_external_buffer
napi_create_object
napi_create_symbol
node_api_symbol_for
napi_create_typedarray
node_api_create_buffer_from_arraybuffer
napi_create_dataview


Functions to convert from C types to Node-API

napi_create_int32
napi_create_uint32
napi_create_int64
napi_create_double
napi_create_bigint_int64
napi_create_bigint_uint64
napi_create_bigint_words
napi_create_string_latin1
node_api_create_external_string_latin1
napi_create_string_utf16
node_api_create_external_string_utf16
napi_create_string_utf8


Functions to create optimized property keys

node_api_create_property_key_latin1
node_api_create_property_key_utf16
node_api_create_property_key_utf8


Functions to convert from Node-API to C types

napi_get_array_length
napi_get_arraybuffer_info
napi_get_buffer_info
napi_get_prototype
napi_get_typedarray_info
napi_get_dataview_info
napi_get_date_value
napi_get_value_bool
napi_get_value_double
napi_get_value_bigint_int64
napi_get_value_bigint_uint64
napi_get_value_bigint_words
napi_get_value_external
napi_get_value_int32
napi_get_value_int64
napi_get_value_string_latin1
napi_get_value_string_utf8
napi_get_value_string_utf16
napi_get_value_uint32


Functions to get global instances

napi_get_boolean
napi_get_global
napi_get_null
napi_get_undefined




Working with JavaScript values and abstract operations

napi_coerce_to_bool
napi_coerce_to_number
napi_coerce_to_object
napi_coerce_to_string
napi_typeof
napi_instanceof
napi_is_array
napi_is_arraybuffer
napi_is_buffer
napi_is_date
napi_is_error
napi_is_typedarray
napi_is_dataview
napi_strict_equals
napi_detach_arraybuffer
napi_is_detached_arraybuffer


Working with JavaScript properties

Structures

napi_property_attributes
napi_property_descriptor


Functions

napi_get_property_names
napi_get_all_property_names
napi_set_property
napi_get_property
napi_has_property
napi_delete_property
napi_has_own_property
napi_set_named_property
napi_get_named_property
napi_has_named_property
napi_set_element
napi_get_element
napi_has_element
napi_delete_element
napi_define_properties
napi_object_freeze
napi_object_seal




Working with JavaScript functions

napi_call_function
napi_create_function
napi_get_cb_info
napi_get_new_target
napi_new_instance


Object wrap

napi_define_class
napi_wrap
napi_unwrap
napi_remove_wrap
napi_type_tag_object
napi_check_object_type_tag
napi_add_finalizer

node_api_post_finalizer




Simple asynchronous operations

napi_create_async_work
napi_delete_async_work
napi_queue_async_work
napi_cancel_async_work


Custom asynchronous operations

napi_async_init
napi_async_destroy
napi_make_callback
napi_open_callback_scope
napi_close_callback_scope


Version management

napi_get_node_version
napi_get_version


Memory management

napi_adjust_external_memory


Promises

napi_create_promise
napi_resolve_deferred
napi_reject_deferred
napi_is_promise


Script execution

napi_run_script


libuv event loop

napi_get_uv_event_loop


Asynchronous thread-safe function calls

Calling a thread-safe function
Reference counting of thread-safe functions
Deciding whether to keep the process running
napi_create_threadsafe_function
napi_get_threadsafe_function_context
napi_call_threadsafe_function
napi_acquire_threadsafe_function
napi_release_threadsafe_function
napi_ref_threadsafe_function
napi_unref_threadsafe_function


Miscellaneous utilities

node_api_get_module_file_name





    
  
            
    
      
        
        Index
      

      
About this documentation
Usage and example

      
        Index
      
    
  


Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Modules: TypeScript
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
Readline
REPL
Report
Single executable applications
SQLite
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker

    
  
            
    
      
        
        Other versions
      
      24.x
23.x
22.x LTS
21.x
20.x LTS
19.x
18.x
17.x
16.x
15.x
14.x
13.x
12.x
11.x
10.x
9.x
8.x
    
  
            
              
                
                Options
              
        
              
                
                  
                    View on single page
                  
                  
                    View as JSON
                  
                  Edit on GitHub    
                
              
            
          
        
        
      

      Table of contents
Node-API

Implications of ABI stability
Building

Build tools

node-gyp
CMake.js


Uploading precompiled binaries

node-pre-gyp
prebuild
prebuildify




Usage
Node-API version matrix
Environment life cycle APIs

napi_set_instance_data
napi_get_instance_data


Basic Node-API data types

napi_status
napi_extended_error_info
napi_env
node_api_basic_env
napi_value
napi_threadsafe_function
napi_threadsafe_function_release_mode
napi_threadsafe_function_call_mode
Node-API memory management types

napi_handle_scope
napi_escapable_handle_scope
napi_ref
napi_type_tag
napi_async_cleanup_hook_handle


Node-API callback types

napi_callback_info
napi_callback
node_api_basic_finalize
napi_finalize
napi_async_execute_callback
napi_async_complete_callback
napi_threadsafe_function_call_js
napi_cleanup_hook
napi_async_cleanup_hook




Error handling

Return values

napi_get_last_error_info


Exceptions

napi_throw
napi_throw_error
napi_throw_type_error
napi_throw_range_error
node_api_throw_syntax_error
napi_is_error
napi_create_error
napi_create_type_error
napi_create_range_error
node_api_create_syntax_error
napi_get_and_clear_last_exception
napi_is_exception_pending
napi_fatal_exception


Fatal errors

napi_fatal_error




Object lifetime management

Making handle lifespan shorter than that of the native method

napi_open_handle_scope
napi_close_handle_scope
napi_open_escapable_handle_scope
napi_close_escapable_handle_scope
napi_escape_handle


References to values with a lifespan longer than that of the native method

napi_create_reference
napi_delete_reference
napi_reference_ref
napi_reference_unref
napi_get_reference_value


Cleanup on exit of the current Node.js environment

napi_add_env_cleanup_hook
napi_remove_env_cleanup_hook
napi_add_async_cleanup_hook
napi_remove_async_cleanup_hook


Finalization on the exit of the Node.js environment


Module registration
Working with JavaScript values

Enum types

napi_key_collection_mode
napi_key_filter
napi_key_conversion
napi_valuetype
napi_typedarray_type


Object creation functions

napi_create_array
napi_create_array_with_length
napi_create_arraybuffer
napi_create_buffer
napi_create_buffer_copy
napi_create_date
napi_create_external
napi_create_external_arraybuffer
napi_create_external_buffer
napi_create_object
napi_create_symbol
node_api_symbol_for
napi_create_typedarray
node_api_create_buffer_from_arraybuffer
napi_create_dataview


Functions to convert from C types to Node-API

napi_create_int32
napi_create_uint32
napi_create_int64
napi_create_double
napi_create_bigint_int64
napi_create_bigint_uint64
napi_create_bigint_words
napi_create_string_latin1
node_api_create_external_string_latin1
napi_create_string_utf16
node_api_create_external_string_utf16
napi_create_string_utf8


Functions to create optimized property keys

node_api_create_property_key_latin1
node_api_create_property_key_utf16
node_api_create_property_key_utf8


Functions to convert from Node-API to C types

napi_get_array_length
napi_get_arraybuffer_info
napi_get_buffer_info
napi_get_prototype
napi_get_typedarray_info
napi_get_dataview_info
napi_get_date_value
napi_get_value_bool
napi_get_value_double
napi_get_value_bigint_int64
napi_get_value_bigint_uint64
napi_get_value_bigint_words
napi_get_value_external
napi_get_value_int32
napi_get_value_int64
napi_get_value_string_latin1
napi_get_value_string_utf8
napi_get_value_string_utf16
napi_get_value_uint32


Functions to get global instances

napi_get_boolean
napi_get_global
napi_get_null
napi_get_undefined




Working with JavaScript values and abstract operations

napi_coerce_to_bool
napi_coerce_to_number
napi_coerce_to_object
napi_coerce_to_string
napi_typeof
napi_instanceof
napi_is_array
napi_is_arraybuffer
napi_is_buffer
napi_is_date
napi_is_error
napi_is_typedarray
napi_is_dataview
napi_strict_equals
napi_detach_arraybuffer
napi_is_detached_arraybuffer


Working with JavaScript properties

Structures

napi_property_attributes
napi_property_descriptor


Functions

napi_get_property_names
napi_get_all_property_names
napi_set_property
napi_get_property
napi_has_property
napi_delete_property
napi_has_own_property
napi_set_named_property
napi_get_named_property
napi_has_named_property
napi_set_element
napi_get_element
napi_has_element
napi_delete_element
napi_define_properties
napi_object_freeze
napi_object_seal




Working with JavaScript functions

napi_call_function
napi_create_function
napi_get_cb_info
napi_get_new_target
napi_new_instance


Object wrap

napi_define_class
napi_wrap
napi_unwrap
napi_remove_wrap
napi_type_tag_object
napi_check_object_type_tag
napi_add_finalizer

node_api_post_finalizer




Simple asynchronous operations

napi_create_async_work
napi_delete_async_work
napi_queue_async_work
napi_cancel_async_work


Custom asynchronous operations

napi_async_init
napi_async_destroy
napi_make_callback
napi_open_callback_scope
napi_close_callback_scope


Version management

napi_get_node_version
napi_get_version


Memory management

napi_adjust_external_memory


Promises

napi_create_promise
napi_resolve_deferred
napi_reject_deferred
napi_is_promise


Script execution

napi_run_script


libuv event loop

napi_get_uv_event_loop


Asynchronous thread-safe function calls

Calling a thread-safe function
Reference counting of thread-safe functions
Deciding whether to keep the process running
napi_create_threadsafe_function
napi_get_threadsafe_function_context
napi_call_threadsafe_function
napi_acquire_threadsafe_function
napi_release_threadsafe_function
napi_ref_threadsafe_function
napi_unref_threadsafe_function


Miscellaneous utilities

node_api_get_module_file_name






      
        Node-API#


Stability: 2 - Stable
Node-API (formerly N-API) is an API for building native Addons. It is
independent from the underlying JavaScript runtime (for example, V8) and is
maintained as part of Node.js itself. This API will be Application Binary
Interface (ABI) stable across versions of Node.js. It is intended to insulate
addons from changes in the underlying JavaScript engine and allow modules
compiled for one major version to run on later major versions of Node.js without
recompilation. The ABI Stability guide provides a more in-depth explanation.
Addons are built/packaged with the same approach/tools outlined in the section
titled C++ Addons. The only difference is the set of APIs that are used by
the native code. Instead of using the V8 or Native Abstractions for Node.js
APIs, the functions available in Node-API are used.
APIs exposed by Node-API are generally used to create and manipulate
JavaScript values. Concepts and operations generally map to ideas specified
in the ECMA-262 Language Specification. The APIs have the following
properties:

All Node-API calls return a status code of type napi_status. This
status indicates whether the API call succeeded or failed.
The API's return value is passed via an out parameter.
All JavaScript values are abstracted behind an opaque type named
napi_value.
In case of an error status code, additional information can be obtained
using napi_get_last_error_info. More information can be found in the error
handling section Error handling.

Node-API is a C API that ensures ABI stability across Node.js versions
and different compiler levels. A C++ API can be easier to use.
To support using C++, the project maintains a
C++ wrapper module called node-addon-api.
This wrapper provides an inlinable C++ API. Binaries built
with node-addon-api will depend on the symbols for the Node-API C-based
functions exported by Node.js. node-addon-api is a more
efficient way to write code that calls Node-API. Take, for example, the
following node-addon-api code. The first section shows the
node-addon-api code and the second section shows what actually gets
used in the addon.
Object obj = Object::New(env);
obj["foo"] = String::New(env, "bar"); copy
napi_status status;
napi_value object, string;
status = napi_create_object(env, &object);
if (status != napi_ok) {
  napi_throw_error(env, ...);
  return;
}

status = napi_create_string_utf8(env, "bar", NAPI_AUTO_LENGTH, &string);
if (status != napi_ok) {
  napi_throw_error(env, ...);
  return;
}

status = napi_set_named_property(env, object, "foo", string);
if (status != napi_ok) {
  napi_throw_error(env, ...);
  return;
} copy
The end result is that the addon only uses the exported C APIs. As a result,
it still gets the benefits of the ABI stability provided by the C API.
When using node-addon-api instead of the C APIs, start with the API docs
for node-addon-api.
The Node-API Resource offers
an excellent orientation and tips for developers just getting started with
Node-API and node-addon-api. Additional media resources can be found on the
Node-API Media page.
Implications of ABI stability#
Although Node-API provides an ABI stability guarantee, other parts of Node.js do
not, and any external libraries used from the addon may not. In particular,
none of the following APIs provide an ABI stability guarantee across major
versions:


the Node.js C++ APIs available via any of
#include <node.h>
#include <node_buffer.h>
#include <node_version.h>
#include <node_object_wrap.h> copy


the libuv APIs which are also included with Node.js and available via
#include <uv.h> copy


the V8 API available via
#include <v8.h> copy


Thus, for an addon to remain ABI-compatible across Node.js major versions, it
must use Node-API exclusively by restricting itself to using
#include <node_api.h> copy
and by checking, for all external libraries that it uses, that the external
library makes ABI stability guarantees similar to Node-API.
Building#
Unlike modules written in JavaScript, developing and deploying Node.js
native addons using Node-API requires an additional set of tools. Besides the
basic tools required to develop for Node.js, the native addon developer
requires a toolchain that can compile C and C++ code into a binary. In
addition, depending upon how the native addon is deployed, the user of
the native addon will also need to have a C/C++ toolchain installed.
For Linux developers, the necessary C/C++ toolchain packages are readily
available. GCC is widely used in the Node.js community to build and
test across a variety of platforms. For many developers, the LLVM
compiler infrastructure is also a good choice.
For Mac developers, Xcode offers all the required compiler tools.
However, it is not necessary to install the entire Xcode IDE. The following
command installs the necessary toolchain:
xcode-select --install copy
For Windows developers, Visual Studio offers all the required compiler
tools. However, it is not necessary to install the entire Visual Studio
IDE. The following command installs the necessary toolchain:
npm install --global windows-build-tools copy
The sections below describe the additional tools available for developing
and deploying Node.js native addons.

Build tools#
Both the tools listed here require that users of the native
addon have a C/C++ toolchain installed in order to successfully install
the native addon.

node-gyp#
node-gyp is a build system based on the gyp-next fork of
Google's GYP tool and comes bundled with npm. GYP, and therefore node-gyp,
requires that Python be installed.
Historically, node-gyp has been the tool of choice for building native
addons. It has widespread adoption and documentation. However, some
developers have run into limitations in node-gyp.

CMake.js#
CMake.js is an alternative build system based on CMake.
CMake.js is a good choice for projects that already use CMake or for
developers affected by limitations in node-gyp. build_with_cmake is an
example of a CMake-based native addon project.

Uploading precompiled binaries#
The three tools listed here permit native addon developers and maintainers
to create and upload binaries to public or private servers. These tools are
typically integrated with CI/CD build systems like Travis CI and
AppVeyor to build and upload binaries for a variety of platforms and
architectures. These binaries are then available for download by users who
do not need to have a C/C++ toolchain installed.

node-pre-gyp#
node-pre-gyp is a tool based on node-gyp that adds the ability to
upload binaries to a server of the developer's choice. node-pre-gyp has
particularly good support for uploading binaries to Amazon S3.

prebuild#
prebuild is a tool that supports builds using either node-gyp or
CMake.js. Unlike node-pre-gyp which supports a variety of servers, prebuild
uploads binaries only to GitHub releases. prebuild is a good choice for
GitHub projects using CMake.js.

prebuildify#
prebuildify is a tool based on node-gyp. The advantage of prebuildify is
that the built binaries are bundled with the native addon when it's
uploaded to npm. The binaries are downloaded from npm and are immediately
available to the module user when the native addon is installed.

Usage#
In order to use the Node-API functions, include the file node_api.h which
is located in the src directory in the node development tree:
#include <node_api.h> copy
This will opt into the default NAPI_VERSION for the given release of Node.js.
In order to ensure compatibility with specific versions of Node-API, the version
can be specified explicitly when including the header:
#define NAPI_VERSION 3
#include <node_api.h> copy
This restricts the Node-API surface to just the functionality that was available
in the specified (and earlier) versions.
Some of the Node-API surface is experimental and requires explicit opt-in:
#define NAPI_EXPERIMENTAL
#include <node_api.h> copy
In this case the entire API surface, including any experimental APIs, will be
available to the module code.
Occasionally, experimental features are introduced that affect already-released
and stable APIs. These features can be disabled by an opt-out:
#define NAPI_EXPERIMENTAL
#define NODE_API_EXPERIMENTAL_<FEATURE_NAME>_OPT_OUT
#include <node_api.h> copy
where <FEATURE_NAME> is the name of an experimental feature that affects both
experimental and stable APIs.
Node-API version matrix#
Up until version 9, Node-API versions were additive and versioned
independently from Node.js. This meant that any version was
an extension to the previous version in that it had all of
the APIs from the previous version with some additions. Each
Node.js version only supported a single Node-API version.
For example v18.15.0 supports only Node-API version 8. ABI stability was
achieved because 8 was a strict superset of all previous versions.
As of version 9, while Node-API versions continue to be versioned
independently an add-on that ran with Node-API version 9 may need
code updates to run with Node-API version 10. ABI stability
is maintained, however, because Node.js versions that support
Node-API versions higher than 8 will support all versions
between 8 and the highest version they support and will default
to providing the version 8 APIs unless an add-on opts into a
higher Node-API version. This approach provides the flexibility
of better optimizing existing Node-API functions while
maintaining ABI stability. Existing add-ons can continue to run without
recompilation using an earlier version of Node-API. If an add-on
needs functionality from a newer Node-API version, changes to existing
code and recompilation will be needed to use those new functions anyway.
In versions of Node.js that support Node-API version 9 and later, defining
NAPI_VERSION=X and using the existing add-on initialization macros
will bake in the requested Node-API version that will be used at runtime
into the add-on. If NAPI_VERSION is not set it will default to 8.
This table may not be up to date in older streams, the most up to date
information is in the latest API documentation in:
Node-API version matrix


  
    Node-API version
    Supported In
  
  
    10
    v22.14.0+, 23.6.0+ and all later versions
  
  
    9
    v18.17.0+, 20.3.0+, 21.0.0 and all later versions
  
  
    8
    v12.22.0+, v14.17.0+, v15.12.0+, 16.0.0 and all later versions
  
  
    7
    v10.23.0+, v12.19.0+, v14.12.0+, 15.0.0 and all later versions
  
  
    6
    v10.20.0+, v12.17.0+, 14.0.0 and all later versions
  
  
    5
    v10.17.0+, v12.11.0+, 13.0.0 and all later versions
  
  
    4
    v10.16.0+, v11.8.0+, 12.0.0 and all later versions
  
  
    
    3
    v6.14.2*, 8.11.2+, v9.11.0+*, 10.0.0 and all later versions
  
  
    2
    v8.10.0+*, v9.3.0+*, 10.0.0 and all later versions
  
  
    1
    v8.6.0+**, v9.0.0+*, 10.0.0 and all later versions
  

* Node-API was experimental.
** Node.js 8.0.0 included Node-API as experimental. It was released as
Node-API version 1 but continued to evolve until Node.js 8.6.0. The API is
different in versions prior to Node.js 8.6.0. We recommend Node-API version 3 or
later.
Each API documented for Node-API will have a header named added in:, and APIs
which are stable will have the additional header Node-API version:.
APIs are directly usable when using a Node.js version which supports
the Node-API version shown in Node-API version: or higher.
When using a Node.js version that does not support the
Node-API version: listed or if there is no Node-API version: listed,
then the API will only be available if
#define NAPI_EXPERIMENTAL precedes the inclusion of node_api.h
or js_native_api.h. If an API appears not to be available on
a version of Node.js which is later than the one shown in added in: then
this is most likely the reason for the apparent absence.
The Node-APIs associated strictly with accessing ECMAScript features from native
code can be found separately in js_native_api.h and js_native_api_types.h.
The APIs defined in these headers are included in node_api.h and
node_api_types.h. The headers are structured in this way in order to allow
implementations of Node-API outside of Node.js. For those implementations the
Node.js specific APIs may not be applicable.
The Node.js-specific parts of an addon can be separated from the code that
exposes the actual functionality to the JavaScript environment so that the
latter may be used with multiple implementations of Node-API. In the example
below, addon.c and addon.h refer only to js_native_api.h. This ensures
that addon.c can be reused to compile against either the Node.js
implementation of Node-API or any implementation of Node-API outside of Node.js.
addon_node.c is a separate file that contains the Node.js specific entry point
to the addon and which instantiates the addon by calling into addon.c when the
addon is loaded into a Node.js environment.
// addon.h
#ifndef _ADDON_H_
#define _ADDON_H_
#include <js_native_api.h>
napi_value create_addon(napi_env env);
#endif  // _ADDON_H_ copy
// addon.c
#include "addon.h"

#define NODE_API_CALL(env, call)                                  \
  do {                                                            \
    napi_status status = (call);                                  \
    if (status != napi_ok) {                                      \
      const napi_extended_error_info* error_info = NULL;          \
      napi_get_last_error_info((env), &error_info);               \
      const char* err_message = error_info->error_message;        \
      bool is_pending;                                            \
      napi_is_exception_pending((env), &is_pending);              \
      /* If an exception is already pending, don't rethrow it */  \
      if (!is_pending) {                                          \
        const char* message = (err_message == NULL)               \
            ? "empty error message"                               \
            : err_message;                                        \
        napi_throw_error((env), NULL, message);                   \
      }                                                           \
      return NULL;                                                \
    }                                                             \
  } while(0)

static napi_value
DoSomethingUseful(napi_env env, napi_callback_info info) {
  // Do something useful.
  return NULL;
}

napi_value create_addon(napi_env env) {
  napi_value result;
  NODE_API_CALL(env, napi_create_object(env, &result));

  napi_value exported_function;
  NODE_API_CALL(env, napi_create_function(env,
                                          "doSomethingUseful",
                                          NAPI_AUTO_LENGTH,
                                          DoSomethingUseful,
                                          NULL,
                                          &exported_function));

  NODE_API_CALL(env, napi_set_named_property(env,
                                             result,
                                             "doSomethingUseful",
                                             exported_function));

  return result;
} copy
// addon_node.c
#include <node_api.h>
#include "addon.h"

NAPI_MODULE_INIT(/* napi_env env, napi_value exports */) {
  // This function body is expected to return a `napi_value`.
  // The variables `napi_env env` and `napi_value exports` may be used within
  // the body, as they are provided by the definition of `NAPI_MODULE_INIT()`.
  return create_addon(env);
} copy
Environment life cycle APIs#
Section 8.7 of the ECMAScript Language Specification defines the concept
of an "Agent" as a self-contained environment in which JavaScript code runs.
Multiple such Agents may be started and terminated either concurrently or in
sequence by the process.
A Node.js environment corresponds to an ECMAScript Agent. In the main process,
an environment is created at startup, and additional environments can be created
on separate threads to serve as worker threads. When Node.js is embedded in
another application, the main thread of the application may also construct and
destroy a Node.js environment multiple times during the life cycle of the
application process such that each Node.js environment created by the
application may, in turn, during its life cycle create and destroy additional
environments as worker threads.
From the perspective of a native addon this means that the bindings it provides
may be called multiple times, from multiple contexts, and even concurrently from
multiple threads.
Native addons may need to allocate global state which they use during
their life cycle of an Node.js environment such that the state can be
unique to each instance of the addon.
To this end, Node-API provides a way to associate data such that its life cycle
is tied to the life cycle of a Node.js environment.

napi_set_instance_data#

Added in: v12.8.0, v10.20.0
N-API version: 6

napi_status napi_set_instance_data(node_api_basic_env env,
                                   void* data,
                                   napi_finalize finalize_cb,
                                   void* finalize_hint); copy

[in] env: The environment that the Node-API call is invoked under.
[in] data: The data item to make available to bindings of this instance.
[in] finalize_cb: The function to call when the environment is being torn
down. The function receives data so that it might free it.
napi_finalize provides more details.
[in] finalize_hint: Optional hint to pass to the finalize callback during
collection.

Returns napi_ok if the API succeeded.
This API associates data with the currently running Node.js environment. data
can later be retrieved using napi_get_instance_data(). Any existing data
associated with the currently running Node.js environment which was set by means
of a previous call to napi_set_instance_data() will be overwritten. If a
finalize_cb was provided by the previous call, it will not be called.

napi_get_instance_data#

Added in: v12.8.0, v10.20.0
N-API version: 6

napi_status napi_get_instance_data(node_api_basic_env env,
                                   void** data); copy

[in] env: The environment that the Node-API call is invoked under.
[out] data: The data item that was previously associated with the currently
running Node.js environment by a call to napi_set_instance_data().

Returns napi_ok if the API succeeded.
This API retrieves data that was previously associated with the currently
running Node.js environment via napi_set_instance_data(). If no data is set,
the call will succeed and data will be set to NULL.

Basic Node-API data types#
Node-API exposes the following fundamental data types as abstractions that are
consumed by the various APIs. These APIs should be treated as opaque,
introspectable only with other Node-API calls.

napi_status#

Added in: v8.0.0
N-API version: 1

Integral status code indicating the success or failure of a Node-API call.
Currently, the following status codes are supported.
typedef enum {
  napi_ok,
  napi_invalid_arg,
  napi_object_expected,
  napi_string_expected,
  napi_name_expected,
  napi_function_expected,
  napi_number_expected,
  napi_boolean_expected,
  napi_array_expected,
  napi_generic_failure,
  napi_pending_exception,
  napi_cancelled,
  napi_escape_called_twice,
  napi_handle_scope_mismatch,
  napi_callback_scope_mismatch,
  napi_queue_full,
  napi_closing,
  napi_bigint_expected,
  napi_date_expected,
  napi_arraybuffer_expected,
  napi_detachable_arraybuffer_expected,
  napi_would_deadlock,  /* unused */
  napi_no_external_buffers_allowed,
  napi_cannot_run_js
} napi_status; copy
If additional information is required upon an API returning a failed status,
it can be obtained by calling napi_get_last_error_info.

napi_extended_error_info#

Added in: v8.0.0
N-API version: 1

typedef struct {
  const char* error_message;
  void* engine_reserved;
  uint32_t engine_error_code;
  napi_status error_code;
} napi_extended_error_info; copy

error_message: UTF8-encoded string containing a VM-neutral description of
the error.
engine_reserved: Reserved for VM-specific error details. This is currently
not implemented for any VM.
engine_error_code: VM-specific error code. This is currently
not implemented for any VM.
error_code: The Node-API status code that originated with the last error.

See the Error handling section for additional information.

napi_env#
napi_env is used to represent a context that the underlying Node-API
implementation can use to persist VM-specific state. This structure is passed
to native functions when they're invoked, and it must be passed back when
making Node-API calls. Specifically, the same napi_env that was passed in when
the initial native function was called must be passed to any subsequent
nested Node-API calls. Caching the napi_env for the purpose of general reuse,
and passing the napi_env between instances of the same addon running on
different Worker threads is not allowed. The napi_env becomes invalid
when an instance of a native addon is unloaded. Notification of this event is
delivered through the callbacks given to napi_add_env_cleanup_hook and
napi_set_instance_data.

node_api_basic_env#
Stability: 1 - Experimental
This variant of napi_env is passed to synchronous finalizers
(node_api_basic_finalize). There is a subset of Node-APIs which accept
a parameter of type node_api_basic_env as their first argument. These APIs do
not access the state of the JavaScript engine and are thus safe to call from
synchronous finalizers. Passing a parameter of type napi_env to these APIs is
allowed, however, passing a parameter of type node_api_basic_env to APIs that
access the JavaScript engine state is not allowed. Attempting to do so without
a cast will produce a compiler warning or an error when add-ons are compiled
with flags which cause them to emit warnings and/or errors when incorrect
pointer types are passed into a function. Calling such APIs from a synchronous
finalizer will ultimately result in the termination of the application.

napi_value#
This is an opaque pointer that is used to represent a JavaScript value.

napi_threadsafe_function#

Added in: v10.6.0
N-API version: 4

This is an opaque pointer that represents a JavaScript function which can be
called asynchronously from multiple threads via
napi_call_threadsafe_function().

napi_threadsafe_function_release_mode#

Added in: v10.6.0
N-API version: 4

A value to be given to napi_release_threadsafe_function() to indicate whether
the thread-safe function is to be closed immediately (napi_tsfn_abort) or
merely released (napi_tsfn_release) and thus available for subsequent use via
napi_acquire_threadsafe_function() and napi_call_threadsafe_function().
typedef enum {
  napi_tsfn_release,
  napi_tsfn_abort
} napi_threadsafe_function_release_mode; copy

napi_threadsafe_function_call_mode#

Added in: v10.6.0
N-API version: 4

A value to be given to napi_call_threadsafe_function() to indicate whether
the call should block whenever the queue associated with the thread-safe
function is full.
typedef enum {
  napi_tsfn_nonblocking,
  napi_tsfn_blocking
} napi_threadsafe_function_call_mode; copy

Node-API memory management types#

napi_handle_scope#
This is an abstraction used to control and modify the lifetime of objects
created within a particular scope. In general, Node-API values are created
within the context of a handle scope. When a native method is called from
JavaScript, a default handle scope will exist. If the user does not explicitly
create a new handle scope, Node-API values will be created in the default handle
scope. For any invocations of code outside the execution of a native method
(for instance, during a libuv callback invocation), the module is required to
create a scope before invoking any functions that can result in the creation
of JavaScript values.
Handle scopes are created using napi_open_handle_scope and are destroyed
using napi_close_handle_scope. Closing the scope can indicate to the GC
that all napi_values created during the lifetime of the handle scope are no
longer referenced from the current stack frame.
For more details, review the Object lifetime management.

napi_escapable_handle_scope#

Added in: v8.0.0
N-API version: 1

Escapable handle scopes are a special type of handle scope to return values
created within a particular handle scope to a parent scope.

napi_ref#

Added in: v8.0.0
N-API version: 1

This is the abstraction to use to reference a napi_value. This allows for
users to manage the lifetimes of JavaScript values, including defining their
minimum lifetimes explicitly.
For more details, review the Object lifetime management.

napi_type_tag#

Added in: v14.8.0, v12.19.0
N-API version: 8

A 128-bit value stored as two unsigned 64-bit integers. It serves as a UUID
with which JavaScript objects or externals can be "tagged" in order to
ensure that they are of a certain type. This is a stronger check than
napi_instanceof, because the latter can report a false positive if the
object's prototype has been manipulated. Type-tagging is most useful in
conjunction with napi_wrap because it ensures that the pointer retrieved
from a wrapped object can be safely cast to the native type corresponding to the
type tag that had been previously applied to the JavaScript object.
typedef struct {
  uint64_t lower;
  uint64_t upper;
} napi_type_tag; copy

napi_async_cleanup_hook_handle#

Added in: v14.10.0, v12.19.0

An opaque value returned by napi_add_async_cleanup_hook. It must be passed
to napi_remove_async_cleanup_hook when the chain of asynchronous cleanup
events completes.

Node-API callback types#

napi_callback_info#

Added in: v8.0.0
N-API version: 1

Opaque datatype that is passed to a callback function. It can be used for
getting additional information about the context in which the callback was
invoked.

napi_callback#

Added in: v8.0.0
N-API version: 1

Function pointer type for user-provided native functions which are to be
exposed to JavaScript via Node-API. Callback functions should satisfy the
following signature:
typedef napi_value (*napi_callback)(napi_env, napi_callback_info); copy
Unless for reasons discussed in Object Lifetime Management, creating a
handle and/or callback scope inside a napi_callback is not necessary.

node_api_basic_finalize#

Added in: v21.6.0, v20.12.0, v18.20.0

Stability: 1 - Experimental
Function pointer type for add-on provided functions that allow the user to be
notified when externally-owned data is ready to be cleaned up because the
object it was associated with has been garbage-collected. The user must provide
a function satisfying the following signature which would get called upon the
object's collection. Currently, node_api_basic_finalize can be used for
finding out when objects that have external data are collected.
typedef void (*node_api_basic_finalize)(node_api_basic_env env,
                                      void* finalize_data,
                                      void* finalize_hint); copy
Unless for reasons discussed in Object Lifetime Management, creating a
handle and/or callback scope inside the function body is not necessary.
Since these functions may be called while the JavaScript engine is in a state
where it cannot execute JavaScript code, only Node-APIs which accept a
node_api_basic_env as their first parameter may be called.
node_api_post_finalizer can be used to schedule Node-API calls that
require access to the JavaScript engine's state to run after the current
garbage collection cycle has completed.
In the case of node_api_create_external_string_latin1 and
node_api_create_external_string_utf16 the env parameter may be null,
because external strings can be collected during the latter part of environment
shutdown.
Change History:


experimental (NAPI_EXPERIMENTAL):
Only Node-API calls that accept a node_api_basic_env as their first
parameter may be called, otherwise the application will be terminated with an
appropriate error message. This feature can be turned off by defining
NODE_API_EXPERIMENTAL_BASIC_ENV_OPT_OUT.



napi_finalize#

Added in: v8.0.0
N-API version: 1

Function pointer type for add-on provided function that allow the user to
schedule a group of calls to Node-APIs in response to a garbage collection
event, after the garbage collection cycle has completed. These function
pointers can be used with node_api_post_finalizer.
typedef void (*napi_finalize)(napi_env env,
                              void* finalize_data,
                              void* finalize_hint); copy
Change History:


experimental (NAPI_EXPERIMENTAL is defined):
A function of this type may no longer be used as a finalizer, except with
node_api_post_finalizer. node_api_basic_finalize must be used
instead. This feature can be turned off by defining
NODE_API_EXPERIMENTAL_BASIC_ENV_OPT_OUT.



napi_async_execute_callback#

Added in: v8.0.0
N-API version: 1

Function pointer used with functions that support asynchronous
operations. Callback functions must satisfy the following signature:
typedef void (*napi_async_execute_callback)(napi_env env, void* data); copy
Implementations of this function must avoid making Node-API calls that execute
JavaScript or interact with JavaScript objects. Node-API calls should be in the
napi_async_complete_callback instead. Do not use the napi_env parameter as
it will likely result in execution of JavaScript.

napi_async_complete_callback#

Added in: v8.0.0
N-API version: 1

Function pointer used with functions that support asynchronous
operations. Callback functions must satisfy the following signature:
typedef void (*napi_async_complete_callback)(napi_env env,
                                             napi_status status,
                                             void* data); copy
Unless for reasons discussed in Object Lifetime Management, creating a
handle and/or callback scope inside the function body is not necessary.

napi_threadsafe_function_call_js#

Added in: v10.6.0
N-API version: 4

Function pointer used with asynchronous thread-safe function calls. The callback
will be called on the main thread. Its purpose is to use a data item arriving
via the queue from one of the secondary threads to construct the parameters
necessary for a call into JavaScript, usually via napi_call_function, and then
make the call into JavaScript.
The data arriving from the secondary thread via the queue is given in the data
parameter and the JavaScript function to call is given in the js_callback
parameter.
Node-API sets up the environment prior to calling this callback, so it is
sufficient to call the JavaScript function via napi_call_function rather than
via napi_make_callback.
Callback functions must satisfy the following signature:
typedef void (*napi_threadsafe_function_call_js)(napi_env env,
                                                 napi_value js_callback,
                                                 void* context,
                                                 void* data); copy

[in] env: The environment to use for API calls, or NULL if the thread-safe
function is being torn down and data may need to be freed.
[in] js_callback: The JavaScript function to call, or NULL if the
thread-safe function is being torn down and data may need to be freed. It
may also be NULL if the thread-safe function was created without
js_callback.
[in] context: The optional data with which the thread-safe function was
created.
[in] data: Data created by the secondary thread. It is the responsibility of
the callback to convert this native data to JavaScript values (with Node-API
functions) that can be passed as parameters when js_callback is invoked.
This pointer is managed entirely by the threads and this callback. Thus this
callback should free the data.

Unless for reasons discussed in Object Lifetime Management, creating a
handle and/or callback scope inside the function body is not necessary.

napi_cleanup_hook#

Added in: v19.2.0, v18.13.0
N-API version: 3

Function pointer used with napi_add_env_cleanup_hook. It will be called
when the environment is being torn down.
Callback functions must satisfy the following signature:
typedef void (*napi_cleanup_hook)(void* data); copy

[in] data: The data that was passed to napi_add_env_cleanup_hook.


napi_async_cleanup_hook#

Added in: v14.10.0, v12.19.0

Function pointer used with napi_add_async_cleanup_hook. It will be called
when the environment is being torn down.
Callback functions must satisfy the following signature:
typedef void (*napi_async_cleanup_hook)(napi_async_cleanup_hook_handle handle,
                                        void* data); copy

[in] handle: The handle that must be passed to
napi_remove_async_cleanup_hook after completion of the asynchronous
cleanup.
[in] data: The data that was passed to napi_add_async_cleanup_hook.

The body of the function should initiate the asynchronous cleanup actions at the
end of which handle must be passed in a call to
napi_remove_async_cleanup_hook.

Error handling#
Node-API uses both return values and JavaScript exceptions for error handling.
The following sections explain the approach for each case.

Return values#
All of the Node-API functions share the same error handling pattern. The
return type of all API functions is napi_status.
The return value will be napi_ok if the request was successful and
no uncaught JavaScript exception was thrown. If an error occurred AND
an exception was thrown, the napi_status value for the error
will be returned. If an exception was thrown, and no error occurred,
napi_pending_exception will be returned.
In cases where a return value other than napi_ok or
napi_pending_exception is returned, napi_is_exception_pending
must be called to check if an exception is pending.
See the section on exceptions for more details.
The full set of possible napi_status values is defined
in napi_api_types.h.
The napi_status return value provides a VM-independent representation of
the error which occurred. In some cases it is useful to be able to get
more detailed information, including a string representing the error as well as
VM (engine)-specific information.
In order to retrieve this information napi_get_last_error_info
is provided which returns a napi_extended_error_info structure.
The format of the napi_extended_error_info structure is as follows:

Added in: v8.0.0
N-API version: 1

typedef struct napi_extended_error_info {
  const char* error_message;
  void* engine_reserved;
  uint32_t engine_error_code;
  napi_status error_code;
}; copy

error_message: Textual representation of the error that occurred.
engine_reserved: Opaque handle reserved for engine use only.
engine_error_code: VM specific error code.
error_code: Node-API status code for the last error.

napi_get_last_error_info returns the information for the last
Node-API call that was made.
Do not rely on the content or format of any of the extended information as it
is not subject to SemVer and may change at any time. It is intended only for
logging purposes.

napi_get_last_error_info#

Added in: v8.0.0
N-API version: 1

napi_status
napi_get_last_error_info(node_api_basic_env env,
                         const napi_extended_error_info** result); copy

[in] env: The environment that the API is invoked under.
[out] result: The napi_extended_error_info structure with more
information about the error.

Returns napi_ok if the API succeeded.
This API retrieves a napi_extended_error_info structure with information
about the last error that occurred.
The content of the napi_extended_error_info returned is only valid up until
a Node-API function is called on the same env. This includes a call to
napi_is_exception_pending so it may often be necessary to make a copy
of the information so that it can be used later. The pointer returned
in error_message points to a statically-defined string so it is safe to use
that pointer if you have copied it out of the error_message field (which will
be overwritten) before another Node-API function was called.
Do not rely on the content or format of any of the extended information as it
is not subject to SemVer and may change at any time. It is intended only for
logging purposes.
This API can be called even if there is a pending JavaScript exception.

Exceptions#
Any Node-API function call may result in a pending JavaScript exception. This is
the case for any of the API functions, even those that may not cause the
execution of JavaScript.
If the napi_status returned by a function is napi_ok then no
exception is pending and no additional action is required. If the
napi_status returned is anything other than napi_ok or
napi_pending_exception, in order to try to recover and continue
instead of simply returning immediately, napi_is_exception_pending
must be called in order to determine if an exception is pending or not.
In many cases when a Node-API function is called and an exception is
already pending, the function will return immediately with a
napi_status of napi_pending_exception. However, this is not the case
for all functions. Node-API allows a subset of the functions to be
called to allow for some minimal cleanup before returning to JavaScript.
In that case, napi_status will reflect the status for the function. It
will not reflect previous pending exceptions. To avoid confusion, check
the error status after every function call.
When an exception is pending one of two approaches can be employed.
The first approach is to do any appropriate cleanup and then return so that
execution will return to JavaScript. As part of the transition back to
JavaScript, the exception will be thrown at the point in the JavaScript
code where the native method was invoked. The behavior of most Node-API calls
is unspecified while an exception is pending, and many will simply return
napi_pending_exception, so do as little as possible and then return to
JavaScript where the exception can be handled.
The second approach is to try to handle the exception. There will be cases
where the native code can catch the exception, take the appropriate action,
and then continue. This is only recommended in specific cases
where it is known that the exception can be safely handled. In these
cases napi_get_and_clear_last_exception can be used to get and
clear the exception. On success, result will contain the handle to
the last JavaScript Object thrown. If it is determined, after
retrieving the exception, the exception cannot be handled after all
it can be re-thrown it with napi_throw where error is the
JavaScript value to be thrown.
The following utility functions are also available in case native code
needs to throw an exception or determine if a napi_value is an instance
of a JavaScript Error object: napi_throw_error,
napi_throw_type_error, napi_throw_range_error, node_api_throw_syntax_error and napi_is_error.
The following utility functions are also available in case native
code needs to create an Error object: napi_create_error,
napi_create_type_error, napi_create_range_error and node_api_create_syntax_error,
where result is the napi_value that refers to the newly created
JavaScript Error object.
The Node.js project is adding error codes to all of the errors
generated internally. The goal is for applications to use these
error codes for all error checking. The associated error messages
will remain, but will only be meant to be used for logging and
display with the expectation that the message can change without
SemVer applying. In order to support this model with Node-API, both
in internal functionality and for module specific functionality
(as its good practice), the throw_ and create_ functions
take an optional code parameter which is the string for the code
to be added to the error object. If the optional parameter is NULL
then no code will be associated with the error. If a code is provided,
the name associated with the error is also updated to be:
originalName [code] copy
where originalName is the original name associated with the error
and code is the code that was provided. For example, if the code
is 'ERR_ERROR_1' and a TypeError is being created the name will be:
TypeError [ERR_ERROR_1] copy

napi_throw#

Added in: v8.0.0
N-API version: 1

NAPI_EXTERN napi_status napi_throw(napi_env env, napi_value error); copy

[in] env: The environment that the API is invoked under.
[in] error: The JavaScript value to be thrown.

Returns napi_ok if the API succeeded.
This API throws the JavaScript value provided.

napi_throw_error#

Added in: v8.0.0
N-API version: 1

NAPI_EXTERN napi_status napi_throw_error(napi_env env,
                                         const char* code,
                                         const char* msg); copy

[in] env: The environment that the API is invoked under.
[in] code: Optional error code to be set on the error.
[in] msg: C string representing the text to be associated with the error.

Returns napi_ok if the API succeeded.
This API throws a JavaScript Error with the text provided.

napi_throw_type_error#

Added in: v8.0.0
N-API version: 1

NAPI_EXTERN napi_status napi_throw_type_error(napi_env env,
                                              const char* code,
                                              const char* msg); copy

[in] env: The environment that the API is invoked under.
[in] code: Optional error code to be set on the error.
[in] msg: C string representing the text to be associated with the error.

Returns napi_ok if the API succeeded.
This API throws a JavaScript TypeError with the text provided.

napi_throw_range_error#

Added in: v8.0.0
N-API version: 1

NAPI_EXTERN napi_status napi_throw_range_error(napi_env env,
                                               const char* code,
                                               const char* msg); copy

[in] env: The environment that the API is invoked under.
[in] code: Optional error code to be set on the error.
[in] msg: C string representing the text to be associated with the error.

Returns napi_ok if the API succeeded.
This API throws a JavaScript RangeError with the text provided.

node_api_throw_syntax_error#

Added in: v17.2.0, v16.14.0
N-API version: 9

NAPI_EXTERN napi_status node_api_throw_syntax_error(napi_env env,
                                                    const char* code,
                                                    const char* msg); copy

[in] env: The environment that the API is invoked under.
[in] code: Optional error code to be set on the error.
[in] msg: C string representing the text to be associated with the error.

Returns napi_ok if the API succeeded.
This API throws a JavaScript SyntaxError with the text provided.

napi_is_error#

Added in: v8.0.0
N-API version: 1

NAPI_EXTERN napi_status napi_is_error(napi_env env,
                                      napi_value value,
                                      bool* result); copy

[in] env: The environment that the API is invoked under.
[in] value: The napi_value to be checked.
[out] result: Boolean value that is set to true if napi_value represents
an error, false otherwise.

Returns napi_ok if the API succeeded.
This API queries a napi_value to check if it represents an error object.

napi_create_error#

Added in: v8.0.0
N-API version: 1

NAPI_EXTERN napi_status napi_create_error(napi_env env,
                                          napi_value code,
                                          napi_value msg,
                                          napi_value* result); copy

[in] env: The environment that the API is invoked under.
[in] code: Optional napi_value with the string for the error code to be
associated with the error.
[in] msg: napi_value that references a JavaScript string to be used as
the message for the Error.
[out] result: napi_value representing the error created.

Returns napi_ok if the API succeeded.
This API returns a JavaScript Error with the text provided.

napi_create_type_error#

Added in: v8.0.0
N-API version: 1

NAPI_EXTERN napi_status napi_create_type_error(napi_env env,
                                               napi_value code,
                                               napi_value msg,
                                               napi_value* result); copy

[in] env: The environment that the API is invoked under.
[in] code: Optional napi_value with the string for the error code to be
associated with the error.
[in] msg: napi_value that references a JavaScript string to be used as
the message for the Error.
[out] result: napi_value representing the error created.

Returns napi_ok if the API succeeded.
This API returns a JavaScript TypeError with the text provided.

napi_create_range_error#

Added in: v8.0.0
N-API version: 1

NAPI_EXTERN napi_status napi_create_range_error(napi_env env,
                                                napi_value code,
                                                napi_value msg,
                                                napi_value* result); copy

[in] env: The environment that the API is invoked under.
[in] code: Optional napi_value with the string for the error code to be
associated with the error.
[in] msg: napi_value that references a JavaScript string to be used as
the message for the Error.
[out] result: napi_value representing the error created.

Returns napi_ok if the API succeeded.
This API returns a JavaScript RangeError with the text provided.

node_api_create_syntax_error#

Added in: v17.2.0, v16.14.0
N-API version: 9

NAPI_EXTERN napi_status node_api_create_syntax_error(napi_env env,
                                                     napi_value code,
                                                     napi_value msg,
                                                     napi_value* result); copy

[in] env: The environment that the API is invoked under.
[in] code: Optional napi_value with the string for the error code to be
associated with the error.
[in] msg: napi_value that references a JavaScript string to be used as
the message for the Error.
[out] result: napi_value representing the error created.

Returns napi_ok if the API succeeded.
This API returns a JavaScript SyntaxError with the text provided.

napi_get_and_clear_last_exception#

Added in: v8.0.0
N-API version: 1

napi_status napi_get_and_clear_last_exception(napi_env env,
                                              napi_value* result); copy

[in] env: The environment that the API is invoked under.
[out] result: The exception if one is pending, NULL otherwise.

Returns napi_ok if the API succeeded.
This API can be called even if there is a pending JavaScript exception.

napi_is_exception_pending#

Added in: v8.0.0
N-API version: 1

napi_status napi_is_exception_pending(napi_env env, bool* result); copy

[in] env: The environment that the API is invoked under.
[out] result: Boolean value that is set to true if an exception is pending.

Returns napi_ok if the API succeeded.
This API can be called even if there is a pending JavaScript exception.

napi_fatal_exception#

Added in: v9.10.0
N-API version: 3

napi_status napi_fatal_exception(napi_env env, napi_value err); copy

[in] env: The environment that the API is invoked under.
[in] err: The error that is passed to 'uncaughtException'.

Trigger an 'uncaughtException' in JavaScript. Useful if an async
callback throws an exception with no way to recover.

Fatal errors#
In the event of an unrecoverable error in a native addon, a fatal error can be
thrown to immediately terminate the process.

napi_fatal_error#

Added in: v8.2.0
N-API version: 1

NAPI_NO_RETURN void napi_fatal_error(const char* location,
                                     size_t location_len,
                                     const char* message,
                                     size_t message_len); copy

[in] location: Optional location at which the error occurred.
[in] location_len: The length of the location in bytes, or
NAPI_AUTO_LENGTH if it is null-terminated.
[in] message: The message associated with the error.
[in] message_len: The length of the message in bytes, or NAPI_AUTO_LENGTH
if it is null-terminated.

The function call does not return, the process will be terminated.
This API can be called even if there is a pending JavaScript exception.

Object lifetime management#
As Node-API calls are made, handles to objects in the heap for the underlying
VM may be returned as napi_values. These handles must hold the
objects 'live' until they are no longer required by the native code,
otherwise the objects could be collected before the native code was
finished using them.
As object handles are returned they are associated with a
'scope'. The lifespan for the default scope is tied to the lifespan
of the native method call. The result is that, by default, handles
remain valid and the objects associated with these handles will be
held live for the lifespan of the native method call.
In many cases, however, it is necessary that the handles remain valid for
either a shorter or longer lifespan than that of the native method.
The sections which follow describe the Node-API functions that can be used
to change the handle lifespan from the default.

Making handle lifespan shorter than that of the native method#
It is often necessary to make the lifespan of handles shorter than
the lifespan of a native method. For example, consider a native method
that has a loop which iterates through the elements in a large array:
for (int i = 0; i < 1000000; i++) {
  napi_value result;
  napi_status status = napi_get_element(env, object, i, &result);
  if (status != napi_ok) {
    break;
  }
  // do something with element
} copy
This would result in a large number of handles being created, consuming
substantial resources. In addition, even though the native code could only
use the most recent handle, all of the associated objects would also be
kept alive since they all share the same scope.
To handle this case, Node-API provides the ability to establish a new 'scope' to
which newly created handles will be associated. Once those handles
are no longer required, the scope can be 'closed' and any handles associated
with the scope are invalidated. The methods available to open/close scopes are
napi_open_handle_scope and napi_close_handle_scope.
Node-API only supports a single nested hierarchy of scopes. There is only one
active scope at any time, and all new handles will be associated with that
scope while it is active. Scopes must be closed in the reverse order from
which they are opened. In addition, all scopes created within a native method
must be closed before returning from that method.
Taking the earlier example, adding calls to napi_open_handle_scope and
napi_close_handle_scope would ensure that at most a single handle
is valid throughout the execution of the loop:
for (int i = 0; i < 1000000; i++) {
  napi_handle_scope scope;
  napi_status status = napi_open_handle_scope(env, &scope);
  if (status != napi_ok) {
    break;
  }
  napi_value result;
  status = napi_get_element(env, object, i, &result);
  if (status != napi_ok) {
    break;
  }
  // do something with element
  status = napi_close_handle_scope(env, scope);
  if (status != napi_ok) {
    break;
  }
} copy
When nesting scopes, there are cases where a handle from an
inner scope needs to live beyond the lifespan of that scope. Node-API supports
an 'escapable scope' in order to support this case. An escapable scope
allows one handle to be 'promoted' so that it 'escapes' the
current scope and the lifespan of the handle changes from the current
scope to that of the outer scope.
The methods available to open/close escapable scopes are
napi_open_escapable_handle_scope and
napi_close_escapable_handle_scope.
The request to promote a handle is made through napi_escape_handle which
can only be called once.

napi_open_handle_scope#

Added in: v8.0.0
N-API version: 1

NAPI_EXTERN napi_status napi_open_handle_scope(napi_env env,
                                               napi_handle_scope* result); copy

[in] env: The environment that the API is invoked under.
[out] result: napi_value representing the new scope.

Returns napi_ok if the API succeeded.
This API opens a new scope.

napi_close_handle_scope#

Added in: v8.0.0
N-API version: 1

NAPI_EXTERN napi_status napi_close_handle_scope(napi_env env,
                                                napi_handle_scope scope); copy

[in] env: The environment that the API is invoked under.
[in] scope: napi_value representing the scope to be closed.

Returns napi_ok if the API succeeded.
This API closes the scope passed in. Scopes must be closed in the
reverse order from which they were created.
This API can be called even if there is a pending JavaScript exception.

napi_open_escapable_handle_scope#

Added in: v8.0.0
N-API version: 1

NAPI_EXTERN napi_status
    napi_open_escapable_handle_scope(napi_env env,
                                     napi_handle_scope* result); copy

[in] env: The environment that the API is invoked under.
[out] result: napi_value representing the new scope.

Returns napi_ok if the API succeeded.
This API opens a new scope from which one object can be promoted
to the outer scope.

napi_close_escapable_handle_scope#

Added in: v8.0.0
N-API version: 1

NAPI_EXTERN napi_status
    napi_close_escapable_handle_scope(napi_env env,
                                      napi_handle_scope scope); copy

[in] env: The environment that the API is invoked under.
[in] scope: napi_value representing the scope to be closed.

Returns napi_ok if the API succeeded.
This API closes the scope passed in. Scopes must be closed in the
reverse order from which they were created.
This API can be called even if there is a pending JavaScript exception.

napi_escape_handle#

Added in: v8.0.0
N-API version: 1

napi_status napi_escape_handle(napi_env env,
                               napi_escapable_handle_scope scope,
                               napi_value escapee,
                               napi_value* result); copy

[in] env: The environment that the API is invoked under.
[in] scope: napi_value representing the current scope.
[in] escapee: napi_value representing the JavaScript Object to be
escaped.
[out] result: napi_value representing the handle to the escaped Object
in the outer scope.

Returns napi_ok if the API succeeded.
This API promotes the handle to the JavaScript object so that it is valid
for the lifetime of the outer scope. It can only be called once per scope.
If it is called more than once an error will be returned.
This API can be called even if there is a pending JavaScript exception.

References to values with a lifespan longer than that of the native method#
In some cases, an addon will need to be able to create and reference values
with a lifespan longer than that of a single native method invocation. For
example, to create a constructor and later use that constructor
in a request to create instances, it must be possible to reference
the constructor object across many different instance creation requests. This
would not be possible with a normal handle returned as a napi_value as
described in the earlier section. The lifespan of a normal handle is
managed by scopes and all scopes must be closed before the end of a native
method.
Node-API provides methods for creating persistent references to values.
Currently Node-API only allows references to be created for a
limited set of value types, including object, external, function, and symbol.
Each reference has an associated count with a value of 0 or higher,
which determines whether the reference will keep the corresponding value alive.
References with a count of 0 do not prevent values from being collected.
Values of object (object, function, external) and symbol types are becoming
'weak' references and can still be accessed while they are not collected.
Any count greater than 0 will prevent the values from being collected.
Symbol values have different flavors. The true weak reference behavior is
only supported by local symbols created with the napi_create_symbol function
or the JavaScript Symbol() constructor calls. Globally registered symbols
created with the node_api_symbol_for function or JavaScript Symbol.for()
function calls remain always strong references because the garbage collector
does not collect them. The same is true for well-known symbols such as
Symbol.iterator. They are also never collected by the garbage collector.
References can be created with an initial reference count. The count can
then be modified through napi_reference_ref and
napi_reference_unref. If an object is collected while the count
for a reference is 0, all subsequent calls to
get the object associated with the reference napi_get_reference_value
will return NULL for the returned napi_value. An attempt to call
napi_reference_ref for a reference whose object has been collected
results in an error.
References must be deleted once they are no longer required by the addon. When
a reference is deleted, it will no longer prevent the corresponding object from
being collected. Failure to delete a persistent reference results in
a 'memory leak' with both the native memory for the persistent reference and
the corresponding object on the heap being retained forever.
There can be multiple persistent references created which refer to the same
object, each of which will either keep the object live or not based on its
individual count. Multiple persistent references to the same object
can result in unexpectedly keeping alive native memory. The native structures
for a persistent reference must be kept alive until finalizers for the
referenced object are executed. If a new persistent reference is created
for the same object, the finalizers for that object will not be
run and the native memory pointed by the earlier persistent reference
will not be freed. This can be avoided by calling
napi_delete_reference in addition to napi_reference_unref when possible.
Change History:


Version 10 (NAPI_VERSION is defined as 10 or higher):
References can be created for all value types. The new supported value
types do not support weak reference semantic and the values of these types
are released when the reference count becomes 0 and cannot be accessed from
the reference anymore.



napi_create_reference#

Added in: v8.0.0
N-API version: 1

NAPI_EXTERN napi_status napi_create_reference(napi_env env,
                                              napi_value value,
                                              uint32_t initial_refcount,
                                              napi_ref* result); copy

[in] env: The environment that the API is invoked under.
[in] value: The napi_value for which a reference is being created.
[in] initial_refcount: Initial reference count for the new reference.
[out] result: napi_ref pointing to the new reference.

Returns napi_ok if the API succeeded.
This API creates a new reference with the specified reference count
to the value passed in.

napi_delete_reference#

Added in: v8.0.0
N-API version: 1

NAPI_EXTERN napi_status napi_delete_reference(napi_env env, napi_ref ref); copy

[in] env: The environment that the API is invoked under.
[in] ref: napi_ref to be deleted.

Returns napi_ok if the API succeeded.
This API deletes the reference passed in.
This API can be called even if there is a pending JavaScript exception.

napi_reference_ref#

Added in: v8.0.0
N-API version: 1

NAPI_EXTERN napi_status napi_reference_ref(napi_env env,
                                           napi_ref ref,
                                           uint32_t* result); copy

[in] env: The environment that the API is invoked under.
[in] ref: napi_ref for which the reference count will be incremented.
[out] result: The new reference count.

Returns napi_ok if the API succeeded.
This API increments the reference count for the reference
passed in and returns the resulting reference count.

napi_reference_unref#

Added in: v8.0.0
N-API version: 1

NAPI_EXTERN napi_status napi_reference_unref(napi_env env,
                                             napi_ref ref,
                                             uint32_t* result); copy

[in] env: The environment that the API is invoked under.
[in] ref: napi_ref for which the reference count will be decremented.
[out] result: The new reference count.

Returns napi_ok if the API succeeded.
This API decrements the reference count for the reference
passed in and returns the resulting reference count.

napi_get_reference_value#

Added in: v8.0.0
N-API version: 1

NAPI_EXTERN napi_status napi_get_reference_value(napi_env env,
                                                 napi_ref ref,
                                                 napi_value* result); copy

[in] env: The environment that the API is invoked under.
[in] ref: The napi_ref for which the corresponding value is
being requested.
[out] result: The napi_value referenced by the napi_ref.

Returns napi_ok if the API succeeded.
If still valid, this API returns the napi_value representing the
JavaScript value associated with the napi_ref. Otherwise, result
will be NULL.

Cleanup on exit of the current Node.js environment#
While a Node.js process typically releases all its resources when exiting,
embedders of Node.js, or future Worker support, may require addons to register
clean-up hooks that will be run once the current Node.js environment exits.
Node-API provides functions for registering and un-registering such callbacks.
When those callbacks are run, all resources that are being held by the addon
should be freed up.

napi_add_env_cleanup_hook#

Added in: v10.2.0
N-API version: 3

NODE_EXTERN napi_status napi_add_env_cleanup_hook(node_api_basic_env env,
                                                  napi_cleanup_hook fun,
                                                  void* arg); copy
Registers fun as a function to be run with the arg parameter once the
current Node.js environment exits.
A function can safely be specified multiple times with different
arg values. In that case, it will be called multiple times as well.
Providing the same fun and arg values multiple times is not allowed
and will lead the process to abort.
The hooks will be called in reverse order, i.e. the most recently added one
will be called first.
Removing this hook can be done by using napi_remove_env_cleanup_hook.
Typically, that happens when the resource for which this hook was added
is being torn down anyway.
For asynchronous cleanup, napi_add_async_cleanup_hook is available.

napi_remove_env_cleanup_hook#

Added in: v10.2.0
N-API version: 3

NAPI_EXTERN napi_status napi_remove_env_cleanup_hook(node_api_basic_env env,
                                                     void (*fun)(void* arg),
                                                     void* arg); copy
Unregisters fun as a function to be run with the arg parameter once the
current Node.js environment exits. Both the argument and the function value
need to be exact matches.
The function must have originally been registered
with napi_add_env_cleanup_hook, otherwise the process will abort.

napi_add_async_cleanup_hook#

History

VersionChanges
v14.10.0, v12.19.0
Changed signature of the hook callback.
v14.8.0, v12.19.0
Added in: v14.8.0, v12.19.0


N-API version: 8

NAPI_EXTERN napi_status napi_add_async_cleanup_hook(
    node_api_basic_env env,
    napi_async_cleanup_hook hook,
    void* arg,
    napi_async_cleanup_hook_handle* remove_handle); copy

[in] env: The environment that the API is invoked under.
[in] hook: The function pointer to call at environment teardown.
[in] arg: The pointer to pass to hook when it gets called.
[out] remove_handle: Optional handle that refers to the asynchronous cleanup
hook.

Registers hook, which is a function of type napi_async_cleanup_hook, as
a function to be run with the remove_handle and arg parameters once the
current Node.js environment exits.
Unlike napi_add_env_cleanup_hook, the hook is allowed to be asynchronous.
Otherwise, behavior generally matches that of napi_add_env_cleanup_hook.
If remove_handle is not NULL, an opaque value will be stored in it
that must later be passed to napi_remove_async_cleanup_hook,
regardless of whether the hook has already been invoked.
Typically, that happens when the resource for which this hook was added
is being torn down anyway.

napi_remove_async_cleanup_hook#

History

VersionChanges
v14.10.0, v12.19.0
Removed env parameter.
v14.8.0, v12.19.0
Added in: v14.8.0, v12.19.0



NAPI_EXTERN napi_status napi_remove_async_cleanup_hook(
    napi_async_cleanup_hook_handle remove_handle); copy

[in] remove_handle: The handle to an asynchronous cleanup hook that was
created with napi_add_async_cleanup_hook.

Unregisters the cleanup hook corresponding to remove_handle. This will prevent
the hook from being executed, unless it has already started executing.
This must be called on any napi_async_cleanup_hook_handle value obtained
from napi_add_async_cleanup_hook.

Finalization on the exit of the Node.js environment#
The Node.js environment may be torn down at an arbitrary time as soon as
possible with JavaScript execution disallowed, like on the request of
worker.terminate(). When the environment is being torn down, the
registered napi_finalize callbacks of JavaScript objects, thread-safe
functions and environment instance data are invoked immediately and
independently.
The invocation of napi_finalize callbacks is scheduled after the manually
registered cleanup hooks. In order to ensure a proper order of addon
finalization during environment shutdown to avoid use-after-free in the
napi_finalize callback, addons should register a cleanup hook with
napi_add_env_cleanup_hook and napi_add_async_cleanup_hook to manually
release the allocated resource in a proper order.

Module registration#
Node-API modules are registered in a manner similar to other modules
except that instead of using the NODE_MODULE macro the following
is used:
NAPI_MODULE(NODE_GYP_MODULE_NAME, Init) copy
The next difference is the signature for the Init method. For a Node-API
module it is as follows:
napi_value Init(napi_env env, napi_value exports); copy
The return value from Init is treated as the exports object for the module.
The Init method is passed an empty object via the exports parameter as a
convenience. If Init returns NULL, the parameter passed as exports is
exported by the module. Node-API modules cannot modify the module object but
can specify anything as the exports property of the module.
To add the method hello as a function so that it can be called as a method
provided by the addon:
napi_value Init(napi_env env, napi_value exports) {
  napi_status status;
  napi_property_descriptor desc = {
    "hello",
    NULL,
    Method,
    NULL,
    NULL,
    NULL,
    napi_writable | napi_enumerable | napi_configurable,
    NULL
  };
  status = napi_define_properties(env, exports, 1, &desc);
  if (status != napi_ok) return NULL;
  return exports;
} copy
To set a function to be returned by the require() for the addon:
napi_value Init(napi_env env, napi_value exports) {
  napi_value method;
  napi_status status;
  status = napi_create_function(env, "exports", NAPI_AUTO_LENGTH, Method, NULL, &method);
  if (status != napi_ok) return NULL;
  return method;
} copy
To define a class so that new instances can be created (often used with
Object wrap):
// NOTE: partial example, not all referenced code is included
napi_value Init(napi_env env, napi_value exports) {
  napi_status status;
  napi_property_descriptor properties[] = {
    { "value", NULL, NULL, GetValue, SetValue, NULL, napi_writable | napi_configurable, NULL },
    DECLARE_NAPI_METHOD("plusOne", PlusOne),
    DECLARE_NAPI_METHOD("multiply", Multiply),
  };

  napi_value cons;
  status =
      napi_define_class(env, "MyObject", New, NULL, 3, properties, &cons);
  if (status != napi_ok) return NULL;

  status = napi_create_reference(env, cons, 1, &constructor);
  if (status != napi_ok) return NULL;

  status = napi_set_named_property(env, exports, "MyObject", cons);
  if (status != napi_ok) return NULL;

  return exports;
} copy
You can also use the NAPI_MODULE_INIT macro, which acts as a shorthand
for NAPI_MODULE and defining an Init function:
NAPI_MODULE_INIT(/* napi_env env, napi_value exports */) {
  napi_value answer;
  napi_status result;

  status = napi_create_int64(env, 42, &answer);
  if (status != napi_ok) return NULL;

  status = napi_set_named_property(env, exports, "answer", answer);
  if (status != napi_ok) return NULL;

  return exports;
} copy
The parameters env and exports are provided to the body of the
NAPI_MODULE_INIT macro.
All Node-API addons are context-aware, meaning they may be loaded multiple
times. There are a few design considerations when declaring such a module.
The documentation on context-aware addons provides more details.
The variables env and exports will be available inside the function body
following the macro invocation.
For more details on setting properties on objects, see the section on
Working with JavaScript properties.
For more details on building addon modules in general, refer to the existing
API.
Working with JavaScript values#
Node-API exposes a set of APIs to create all types of JavaScript values.
Some of these types are documented under Section 6
of the ECMAScript Language Specification.
Fundamentally, these APIs are used to do one of the following:

Create a new JavaScript object
Convert from a primitive C type to a Node-API value
Convert from Node-API value to a primitive C type
Get global instances including undefined and null

Node-API values are represented by the type napi_value.
Any Node-API call that requires a JavaScript value takes in a napi_value.
In some cases, the API does check the type of the napi_value up-front.
However, for better performance, it's better for the caller to make sure that
the napi_value in question is of the JavaScript type expected by the API.

Enum types#

napi_key_collection_mode#

Added in: v13.7.0, v12.17.0, v10.20.0
N-API version: 6

typedef enum {
  napi_key_include_prototypes,
  napi_key_own_only
} napi_key_collection_mode; copy
Describes the Keys/Properties filter enums:
napi_key_collection_mode limits the range of collected properties.
napi_key_own_only limits the collected properties to the given
object only. napi_key_include_prototypes will include all keys
of the objects's prototype chain as well.

napi_key_filter#

Added in: v13.7.0, v12.17.0, v10.20.0
N-API version: 6

typedef enum {
  napi_key_all_properties = 0,
  napi_key_writable = 1,
  napi_key_enumerable = 1 << 1,
  napi_key_configurable = 1 << 2,
  napi_key_skip_strings = 1 << 3,
  napi_key_skip_symbols = 1 << 4
} napi_key_filter; copy
Property filter bits. They can be or'ed to build a composite filter.

napi_key_conversion#

Added in: v13.7.0, v12.17.0, v10.20.0
N-API version: 6

typedef enum {
  napi_key_keep_numbers,
  napi_key_numbers_to_strings
} napi_key_conversion; copy
napi_key_numbers_to_strings will convert integer indexes to
strings. napi_key_keep_numbers will return numbers for integer
indexes.

napi_valuetype#
typedef enum {
  // ES6 types (corresponds to typeof)
  napi_undefined,
  napi_null,
  napi_boolean,
  napi_number,
  napi_string,
  napi_symbol,
  napi_object,
  napi_function,
  napi_external,
  napi_bigint,
} napi_valuetype; copy
Describes the type of a napi_value. This generally corresponds to the types
described in Section 6.1 of the ECMAScript Language Specification.
In addition to types in that section, napi_valuetype can also represent
Functions and Objects with external data.
A JavaScript value of type napi_external appears in JavaScript as a plain
object such that no properties can be set on it, and no prototype.

napi_typedarray_type#
typedef enum {
  napi_int8_array,
  napi_uint8_array,
  napi_uint8_clamped_array,
  napi_int16_array,
  napi_uint16_array,
  napi_int32_array,
  napi_uint32_array,
  napi_float32_array,
  napi_float64_array,
  napi_bigint64_array,
  napi_biguint64_array,
} napi_typedarray_type; copy
This represents the underlying binary scalar datatype of the TypedArray.
Elements of this enum correspond to
Section 22.2 of the ECMAScript Language Specification.

Object creation functions#

napi_create_array#

Added in: v8.0.0
N-API version: 1

napi_status napi_create_array(napi_env env, napi_value* result) copy

[in] env: The environment that the Node-API call is invoked under.
[out] result: A napi_value representing a JavaScript Array.

Returns napi_ok if the API succeeded.
This API returns a Node-API value corresponding to a JavaScript Array type.
JavaScript arrays are described in
Section 22.1 of the ECMAScript Language Specification.

napi_create_array_with_length#

Added in: v8.0.0
N-API version: 1

napi_status napi_create_array_with_length(napi_env env,
                                          size_t length,
                                          napi_value* result) copy

[in] env: The environment that the API is invoked under.
[in] length: The initial length of the Array.
[out] result: A napi_value representing a JavaScript Array.

Returns napi_ok if the API succeeded.
This API returns a Node-API value corresponding to a JavaScript Array type.
The Array's length property is set to the passed-in length parameter.
However, the underlying buffer is not guaranteed to be pre-allocated by the VM
when the array is created. That behavior is left to the underlying VM
implementation. If the buffer must be a contiguous block of memory that can be
directly read and/or written via C, consider using
napi_create_external_arraybuffer.
JavaScript arrays are described in
Section 22.1 of the ECMAScript Language Specification.

napi_create_arraybuffer#

Added in: v8.0.0
N-API version: 1

napi_status napi_create_arraybuffer(napi_env env,
                                    size_t byte_length,
                                    void** data,
                                    napi_value* result) copy

[in] env: The environment that the API is invoked under.
[in] length: The length in bytes of the array buffer to create.
[out] data: Pointer to the underlying byte buffer of the ArrayBuffer.
data can optionally be ignored by passing NULL.
[out] result: A napi_value representing a JavaScript ArrayBuffer.

Returns napi_ok if the API succeeded.
This API returns a Node-API value corresponding to a JavaScript ArrayBuffer.
ArrayBuffers are used to represent fixed-length binary data buffers. They are
normally used as a backing-buffer for TypedArray objects.
The ArrayBuffer allocated will have an underlying byte buffer whose size is
determined by the length parameter that's passed in.
The underlying buffer is optionally returned back to the caller in case the
caller wants to directly manipulate the buffer. This buffer can only be
written to directly from native code. To write to this buffer from JavaScript,
a typed array or DataView object would need to be created.
JavaScript ArrayBuffer objects are described in
Section 24.1 of the ECMAScript Language Specification.

napi_create_buffer#

Added in: v8.0.0
N-API version: 1

napi_status napi_create_buffer(napi_env env,
                               size_t size,
                               void** data,
                               napi_value* result) copy

[in] env: The environment that the API is invoked under.
[in] size: Size in bytes of the underlying buffer.
[out] data: Raw pointer to the underlying buffer.
data can optionally be ignored by passing NULL.
[out] result: A napi_value representing a node::Buffer.

Returns napi_ok if the API succeeded.
This API allocates a node::Buffer object. While this is still a
fully-supported data structure, in most cases using a TypedArray will suffice.

napi_create_buffer_copy#

Added in: v8.0.0
N-API version: 1

napi_status napi_create_buffer_copy(napi_env env,
                                    size_t length,
                                    const void* data,
                                    void** result_data,
                                    napi_value* result) copy

[in] env: The environment that the API is invoked under.
[in] size: Size in bytes of the input buffer (should be the same as the size
of the new buffer).
[in] data: Raw pointer to the underlying buffer to copy from.
[out] result_data: Pointer to the new Buffer's underlying data buffer.
result_data can optionally be ignored by passing NULL.
[out] result: A napi_value representing a node::Buffer.

Returns napi_ok if the API succeeded.
This API allocates a node::Buffer object and initializes it with data copied
from the passed-in buffer. While this is still a fully-supported data
structure, in most cases using a TypedArray will suffice.

napi_create_date#

Added in: v11.11.0, v10.17.0
N-API version: 5

napi_status napi_create_date(napi_env env,
                             double time,
                             napi_value* result); copy

[in] env: The environment that the API is invoked under.
[in] time: ECMAScript time value in milliseconds since 01 January, 1970 UTC.
[out] result: A napi_value representing a JavaScript Date.

Returns napi_ok if the API succeeded.
This API does not observe leap seconds; they are ignored, as
ECMAScript aligns with POSIX time specification.
This API allocates a JavaScript Date object.
JavaScript Date objects are described in
Section 20.3 of the ECMAScript Language Specification.

napi_create_external#

Added in: v8.0.0
N-API version: 1

napi_status napi_create_external(napi_env env,
                                 void* data,
                                 napi_finalize finalize_cb,
                                 void* finalize_hint,
                                 napi_value* result) copy

[in] env: The environment that the API is invoked under.
[in] data: Raw pointer to the external data.
[in] finalize_cb: Optional callback to call when the external value is being
collected. napi_finalize provides more details.
[in] finalize_hint: Optional hint to pass to the finalize callback during
collection.
[out] result: A napi_value representing an external value.

Returns napi_ok if the API succeeded.
This API allocates a JavaScript value with external data attached to it. This
is used to pass external data through JavaScript code, so it can be retrieved
later by native code using napi_get_value_external.
The API adds a napi_finalize callback which will be called when the JavaScript
object just created has been garbage collected.
The created value is not an object, and therefore does not support additional
properties. It is considered a distinct value type: calling napi_typeof() with
an external value yields napi_external.

napi_create_external_arraybuffer#

Added in: v8.0.0
N-API version: 1

napi_status
napi_create_external_arraybuffer(napi_env env,
                                 void* external_data,
                                 size_t byte_length,
                                 napi_finalize finalize_cb,
                                 void* finalize_hint,
                                 napi_value* result) copy

[in] env: The environment that the API is invoked under.
[in] external_data: Pointer to the underlying byte buffer of the
ArrayBuffer.
[in] byte_length: The length in bytes of the underlying buffer.
[in] finalize_cb: Optional callback to call when the ArrayBuffer is being
collected. napi_finalize provides more details.
[in] finalize_hint: Optional hint to pass to the finalize callback during
collection.
[out] result: A napi_value representing a JavaScript ArrayBuffer.

Returns napi_ok if the API succeeded.
Some runtimes other than Node.js have dropped support for external buffers.
On runtimes other than Node.js this method may return
napi_no_external_buffers_allowed to indicate that external
buffers are not supported. One such runtime is Electron as
described in this issue
electron/issues/35801.
In order to maintain broadest compatibility with all runtimes
you may define NODE_API_NO_EXTERNAL_BUFFERS_ALLOWED in your addon before
includes for the node-api headers. Doing so will hide the 2 functions
that create external buffers. This will ensure a compilation error
occurs if you accidentally use one of these methods.
This API returns a Node-API value corresponding to a JavaScript ArrayBuffer.
The underlying byte buffer of the ArrayBuffer is externally allocated and
managed. The caller must ensure that the byte buffer remains valid until the
finalize callback is called.
The API adds a napi_finalize callback which will be called when the JavaScript
object just created has been garbage collected.
JavaScript ArrayBuffers are described in
Section 24.1 of the ECMAScript Language Specification.

napi_create_external_buffer#

Added in: v8.0.0
N-API version: 1

napi_status napi_create_external_buffer(napi_env env,
                                        size_t length,
                                        void* data,
                                        napi_finalize finalize_cb,
                                        void* finalize_hint,
                                        napi_value* result) copy

[in] env: The environment that the API is invoked under.
[in] length: Size in bytes of the input buffer (should be the same as the
size of the new buffer).
[in] data: Raw pointer to the underlying buffer to expose to JavaScript.
[in] finalize_cb: Optional callback to call when the ArrayBuffer is being
collected. napi_finalize provides more details.
[in] finalize_hint: Optional hint to pass to the finalize callback during
collection.
[out] result: A napi_value representing a node::Buffer.

Returns napi_ok if the API succeeded.
Some runtimes other than Node.js have dropped support for external buffers.
On runtimes other than Node.js this method may return
napi_no_external_buffers_allowed to indicate that external
buffers are not supported. One such runtime is Electron as
described in this issue
electron/issues/35801.
In order to maintain broadest compatibility with all runtimes
you may define NODE_API_NO_EXTERNAL_BUFFERS_ALLOWED in your addon before
includes for the node-api headers. Doing so will hide the 2 functions
that create external buffers. This will ensure a compilation error
occurs if you accidentally use one of these methods.
This API allocates a node::Buffer object and initializes it with data
backed by the passed in buffer. While this is still a fully-supported data
structure, in most cases using a TypedArray will suffice.
The API adds a napi_finalize callback which will be called when the JavaScript
object just created has been garbage collected.
For Node.js >=4 Buffers are Uint8Arrays.

napi_create_object#

Added in: v8.0.0
N-API version: 1

napi_status napi_create_object(napi_env env, napi_value* result) copy

[in] env: The environment that the API is invoked under.
[out] result: A napi_value representing a JavaScript Object.

Returns napi_ok if the API succeeded.
This API allocates a default JavaScript Object.
It is the equivalent of doing new Object() in JavaScript.
The JavaScript Object type is described in Section 6.1.7 of the
ECMAScript Language Specification.

napi_create_symbol#

Added in: v8.0.0
N-API version: 1

napi_status napi_create_symbol(napi_env env,
                               napi_value description,
                               napi_value* result) copy

[in] env: The environment that the API is invoked under.
[in] description: Optional napi_value which refers to a JavaScript
string to be set as the description for the symbol.
[out] result: A napi_value representing a JavaScript symbol.

Returns napi_ok if the API succeeded.
This API creates a JavaScript symbol value from a UTF8-encoded C string.
The JavaScript symbol type is described in Section 19.4
of the ECMAScript Language Specification.

node_api_symbol_for#

Added in: v17.5.0, v16.15.0
N-API version: 9

napi_status node_api_symbol_for(napi_env env,
                                const char* utf8description,
                                size_t length,
                                napi_value* result) copy

[in] env: The environment that the API is invoked under.
[in] utf8description: UTF-8 C string representing the text to be used as the
description for the symbol.
[in] length: The length of the description string in bytes, or
NAPI_AUTO_LENGTH if it is null-terminated.
[out] result: A napi_value representing a JavaScript symbol.

Returns napi_ok if the API succeeded.
This API searches in the global registry for an existing symbol with the given
description. If the symbol already exists it will be returned, otherwise a new
symbol will be created in the registry.
The JavaScript symbol type is described in Section 19.4 of the ECMAScript
Language Specification.

napi_create_typedarray#

Added in: v8.0.0
N-API version: 1

napi_status napi_create_typedarray(napi_env env,
                                   napi_typedarray_type type,
                                   size_t length,
                                   napi_value arraybuffer,
                                   size_t byte_offset,
                                   napi_value* result) copy

[in] env: The environment that the API is invoked under.
[in] type: Scalar datatype of the elements within the TypedArray.
[in] length: Number of elements in the TypedArray.
[in] arraybuffer: ArrayBuffer underlying the typed array.
[in] byte_offset: The byte offset within the ArrayBuffer from which to
start projecting the TypedArray.
[out] result: A napi_value representing a JavaScript TypedArray.

Returns napi_ok if the API succeeded.
This API creates a JavaScript TypedArray object over an existing
ArrayBuffer. TypedArray objects provide an array-like view over an
underlying data buffer where each element has the same underlying binary scalar
datatype.
It's required that (length * size_of_element) + byte_offset should
be <= the size in bytes of the array passed in. If not, a RangeError exception
is raised.
JavaScript TypedArray objects are described in
Section 22.2 of the ECMAScript Language Specification.

node_api_create_buffer_from_arraybuffer#

Added in: v23.0.0, v22.12.0
N-API version: 10

napi_status NAPI_CDECL node_api_create_buffer_from_arraybuffer(napi_env env,
                                                              napi_value arraybuffer,
                                                              size_t byte_offset,
                                                              size_t byte_length,
                                                              napi_value* result) copy

[in] env: The environment that the API is invoked under.
[in] arraybuffer: The ArrayBuffer from which the buffer will be created.
[in] byte_offset: The byte offset within the ArrayBuffer from which to start creating the buffer.
[in] byte_length: The length in bytes of the buffer to be created from the ArrayBuffer.
[out] result: A napi_value representing the created JavaScript Buffer object.

Returns napi_ok if the API succeeded.
This API creates a JavaScript Buffer object from an existing ArrayBuffer.
The Buffer object is a Node.js-specific class that provides a way to work with binary data directly in JavaScript.
The byte range [byte_offset, byte_offset + byte_length)
must be within the bounds of the ArrayBuffer. If byte_offset + byte_length
exceeds the size of the ArrayBuffer, a RangeError exception is raised.

napi_create_dataview#

Added in: v8.3.0
N-API version: 1

napi_status napi_create_dataview(napi_env env,
                                 size_t byte_length,
                                 napi_value arraybuffer,
                                 size_t byte_offset,
                                 napi_value* result) copy

[in] env: The environment that the API is invoked under.
[in] length: Number of elements in the DataView.
[in] arraybuffer: ArrayBuffer underlying the DataView.
[in] byte_offset: The byte offset within the ArrayBuffer from which to
start projecting the DataView.
[out] result: A napi_value representing a JavaScript DataView.

Returns napi_ok if the API succeeded.
This API creates a JavaScript DataView object over an existing ArrayBuffer.
DataView objects provide an array-like view over an underlying data buffer,
but one which allows items of different size and type in the ArrayBuffer.
It is required that byte_length + byte_offset is less than or equal to the
size in bytes of the array passed in. If not, a RangeError exception is
raised.
JavaScript DataView objects are described in
Section 24.3 of the ECMAScript Language Specification.

Functions to convert from C types to Node-API#

napi_create_int32#

Added in: v8.4.0
N-API version: 1

napi_status napi_create_int32(napi_env env, int32_t value, napi_value* result) copy

[in] env: The environment that the API is invoked under.
[in] value: Integer value to be represented in JavaScript.
[out] result: A napi_value representing a JavaScript number.

Returns napi_ok if the API succeeded.
This API is used to convert from the C int32_t type to the JavaScript
number type.
The JavaScript number type is described in
Section 6.1.6 of the ECMAScript Language Specification.

napi_create_uint32#

Added in: v8.4.0
N-API version: 1

napi_status napi_create_uint32(napi_env env, uint32_t value, napi_value* result) copy

[in] env: The environment that the API is invoked under.
[in] value: Unsigned integer value to be represented in JavaScript.
[out] result: A napi_value representing a JavaScript number.

Returns napi_ok if the API succeeded.
This API is used to convert from the C uint32_t type to the JavaScript
number type.
The JavaScript number type is described in
Section 6.1.6 of the ECMAScript Language Specification.

napi_create_int64#

Added in: v8.4.0
N-API version: 1

napi_status napi_create_int64(napi_env env, int64_t value, napi_value* result) copy

[in] env: The environment that the API is invoked under.
[in] value: Integer value to be represented in JavaScript.
[out] result: A napi_value representing a JavaScript number.

Returns napi_ok if the API succeeded.
This API is used to convert from the C int64_t type to the JavaScript
number type.
The JavaScript number type is described in Section 6.1.6
of the ECMAScript Language Specification. Note the complete range of int64_t
cannot be represented with full precision in JavaScript. Integer values
outside the range of Number.MIN_SAFE_INTEGER -(2**53 - 1) -
Number.MAX_SAFE_INTEGER (2**53 - 1) will lose precision.

napi_create_double#

Added in: v8.4.0
N-API version: 1

napi_status napi_create_double(napi_env env, double value, napi_value* result) copy

[in] env: The environment that the API is invoked under.
[in] value: Double-precision value to be represented in JavaScript.
[out] result: A napi_value representing a JavaScript number.

Returns napi_ok if the API succeeded.
This API is used to convert from the C double type to the JavaScript
number type.
The JavaScript number type is described in
Section 6.1.6 of the ECMAScript Language Specification.

napi_create_bigint_int64#

Added in: v10.7.0
N-API version: 6

napi_status napi_create_bigint_int64(napi_env env,
                                     int64_t value,
                                     napi_value* result); copy

[in] env: The environment that the API is invoked under.
[in] value: Integer value to be represented in JavaScript.
[out] result: A napi_value representing a JavaScript BigInt.

Returns napi_ok if the API succeeded.
This API converts the C int64_t type to the JavaScript BigInt type.

napi_create_bigint_uint64#

Added in: v10.7.0
N-API version: 6

napi_status napi_create_bigint_uint64(napi_env env,
                                      uint64_t value,
                                      napi_value* result); copy

[in] env: The environment that the API is invoked under.
[in] value: Unsigned integer value to be represented in JavaScript.
[out] result: A napi_value representing a JavaScript BigInt.

Returns napi_ok if the API succeeded.
This API converts the C uint64_t type to the JavaScript BigInt type.

napi_create_bigint_words#

Added in: v10.7.0
N-API version: 6

napi_status napi_create_bigint_words(napi_env env,
                                     int sign_bit,
                                     size_t word_count,
                                     const uint64_t* words,
                                     napi_value* result); copy

[in] env: The environment that the API is invoked under.
[in] sign_bit: Determines if the resulting BigInt will be positive or
negative.
[in] word_count: The length of the words array.
[in] words: An array of uint64_t little-endian 64-bit words.
[out] result: A napi_value representing a JavaScript BigInt.

Returns napi_ok if the API succeeded.
This API converts an array of unsigned 64-bit words into a single BigInt
value.
The resulting BigInt is calculated as: (–1)sign_bit (words[0]
× (264)0 + words[1] × (264)1 + …)

napi_create_string_latin1#

Added in: v8.0.0
N-API version: 1

napi_status napi_create_string_latin1(napi_env env,
                                      const char* str,
                                      size_t length,
                                      napi_value* result); copy

[in] env: The environment that the API is invoked under.
[in] str: Character buffer representing an ISO-8859-1-encoded string.
[in] length: The length of the string in bytes, or NAPI_AUTO_LENGTH if it
is null-terminated.
[out] result: A napi_value representing a JavaScript string.

Returns napi_ok if the API succeeded.
This API creates a JavaScript string value from an ISO-8859-1-encoded C
string. The native string is copied.
The JavaScript string type is described in
Section 6.1.4 of the ECMAScript Language Specification.

node_api_create_external_string_latin1#

Added in: v20.4.0, v18.18.0
N-API version: 10

napi_status
node_api_create_external_string_latin1(napi_env env,
                                       char* str,
                                       size_t length,
                                       napi_finalize finalize_callback,
                                       void* finalize_hint,
                                       napi_value* result,
                                       bool* copied); copy

[in] env: The environment that the API is invoked under.
[in] str: Character buffer representing an ISO-8859-1-encoded string.
[in] length: The length of the string in bytes, or NAPI_AUTO_LENGTH if it
is null-terminated.
[in] finalize_callback: The function to call when the string is being
collected. The function will be called with the following parameters:

[in] env: The environment in which the add-on is running. This value
may be null if the string is being collected as part of the termination
of the worker or the main Node.js instance.
[in] data: This is the value str as a void* pointer.
[in] finalize_hint: This is the value finalize_hint that was given
to the API.
napi_finalize provides more details.
This parameter is optional. Passing a null value means that the add-on
doesn't need to be notified when the corresponding JavaScript string is
collected.


[in] finalize_hint: Optional hint to pass to the finalize callback during
collection.
[out] result: A napi_value representing a JavaScript string.
[out] copied: Whether the string was copied. If it was, the finalizer will
already have been invoked to destroy str.

Returns napi_ok if the API succeeded.
This API creates a JavaScript string value from an ISO-8859-1-encoded C
string. The native string may not be copied and must thus exist for the entire
life cycle of the JavaScript value.
The JavaScript string type is described in
Section 6.1.4 of the ECMAScript Language Specification.

napi_create_string_utf16#

Added in: v8.0.0
N-API version: 1

napi_status napi_create_string_utf16(napi_env env,
                                     const char16_t* str,
                                     size_t length,
                                     napi_value* result) copy

[in] env: The environment that the API is invoked under.
[in] str: Character buffer representing a UTF16-LE-encoded string.
[in] length: The length of the string in two-byte code units, or
NAPI_AUTO_LENGTH if it is null-terminated.
[out] result: A napi_value representing a JavaScript string.

Returns napi_ok if the API succeeded.
This API creates a JavaScript string value from a UTF16-LE-encoded C string.
The native string is copied.
The JavaScript string type is described in
Section 6.1.4 of the ECMAScript Language Specification.

node_api_create_external_string_utf16#

Added in: v20.4.0, v18.18.0
N-API version: 10

napi_status
node_api_create_external_string_utf16(napi_env env,
                                      char16_t* str,
                                      size_t length,
                                      napi_finalize finalize_callback,
                                      void* finalize_hint,
                                      napi_value* result,
                                      bool* copied); copy

[in] env: The environment that the API is invoked under.
[in] str: Character buffer representing a UTF16-LE-encoded string.
[in] length: The length of the string in two-byte code units, or
NAPI_AUTO_LENGTH if it is null-terminated.
[in] finalize_callback: The function to call when the string is being
collected. The function will be called with the following parameters:

[in] env: The environment in which the add-on is running. This value
may be null if the string is being collected as part of the termination
of the worker or the main Node.js instance.
[in] data: This is the value str as a void* pointer.
[in] finalize_hint: This is the value finalize_hint that was given
to the API.
napi_finalize provides more details.
This parameter is optional. Passing a null value means that the add-on
doesn't need to be notified when the corresponding JavaScript string is
collected.


[in] finalize_hint: Optional hint to pass to the finalize callback during
collection.
[out] result: A napi_value representing a JavaScript string.
[out] copied: Whether the string was copied. If it was, the finalizer will
already have been invoked to destroy str.

Returns napi_ok if the API succeeded.
This API creates a JavaScript string value from a UTF16-LE-encoded C string.
The native string may not be copied and must thus exist for the entire life
cycle of the JavaScript value.
The JavaScript string type is described in
Section 6.1.4 of the ECMAScript Language Specification.

napi_create_string_utf8#

Added in: v8.0.0
N-API version: 1

napi_status napi_create_string_utf8(napi_env env,
                                    const char* str,
                                    size_t length,
                                    napi_value* result) copy

[in] env: The environment that the API is invoked under.
[in] str: Character buffer representing a UTF8-encoded string.
[in] length: The length of the string in bytes, or NAPI_AUTO_LENGTH if it
is null-terminated.
[out] result: A napi_value representing a JavaScript string.

Returns napi_ok if the API succeeded.
This API creates a JavaScript string value from a UTF8-encoded C string.
The native string is copied.
The JavaScript string type is described in
Section 6.1.4 of the ECMAScript Language Specification.

Functions to create optimized property keys#
Many JavaScript engines including V8 use internalized strings as keys
to set and get property values. They typically use a hash table to create
and lookup such strings. While it adds some cost per key creation, it improves
the performance after that by enabling comparison of string pointers instead
of the whole strings.
If a new JavaScript string is intended to be used as a property key, then for
some JavaScript engines it will be more efficient to use the functions in this
section. Otherwise, use the napi_create_string_utf8 or
node_api_create_external_string_utf8 series functions as there may be
additional overhead in creating/storing strings with the property key
creation methods.

node_api_create_property_key_latin1#

Added in: v22.9.0, v20.18.0
N-API version: 10

napi_status NAPI_CDECL node_api_create_property_key_latin1(napi_env env,
                                                           const char* str,
                                                           size_t length,
                                                           napi_value* result); copy

[in] env: The environment that the API is invoked under.
[in] str: Character buffer representing an ISO-8859-1-encoded string.
[in] length: The length of the string in bytes, or NAPI_AUTO_LENGTH if it
is null-terminated.
[out] result: A napi_value representing an optimized JavaScript string
to be used as a property key for objects.

Returns napi_ok if the API succeeded.
This API creates an optimized JavaScript string value from
an ISO-8859-1-encoded C string to be used as a property key for objects.
The native string is copied. In contrast with napi_create_string_latin1,
subsequent calls to this function with the same str pointer may benefit from a speedup
in the creation of the requested napi_value, depending on the engine.
The JavaScript string type is described in
Section 6.1.4 of the ECMAScript Language Specification.

node_api_create_property_key_utf16#

Added in: v21.7.0, v20.12.0
N-API version: 10

napi_status NAPI_CDECL node_api_create_property_key_utf16(napi_env env,
                                                          const char16_t* str,
                                                          size_t length,
                                                          napi_value* result); copy

[in] env: The environment that the API is invoked under.
[in] str: Character buffer representing a UTF16-LE-encoded string.
[in] length: The length of the string in two-byte code units, or
NAPI_AUTO_LENGTH if it is null-terminated.
[out] result: A napi_value representing an optimized JavaScript string
to be used as a property key for objects.

Returns napi_ok if the API succeeded.
This API creates an optimized JavaScript string value from
a UTF16-LE-encoded C string to be used as a property key for objects.
The native string is copied.
The JavaScript string type is described in
Section 6.1.4 of the ECMAScript Language Specification.

node_api_create_property_key_utf8#

Added in: v22.9.0, v20.18.0
N-API version: 10

napi_status NAPI_CDECL node_api_create_property_key_utf8(napi_env env,
                                                         const char* str,
                                                         size_t length,
                                                         napi_value* result); copy

[in] env: The environment that the API is invoked under.
[in] str: Character buffer representing a UTF8-encoded string.
[in] length: The length of the string in two-byte code units, or
NAPI_AUTO_LENGTH if it is null-terminated.
[out] result: A napi_value representing an optimized JavaScript string
to be used as a property key for objects.

Returns napi_ok if the API succeeded.
This API creates an optimized JavaScript string value from
a UTF8-encoded C string to be used as a property key for objects.
The native string is copied.
The JavaScript string type is described in
Section 6.1.4 of the ECMAScript Language Specification.

Functions to convert from Node-API to C types#

napi_get_array_length#

Added in: v8.0.0
N-API version: 1

napi_status napi_get_array_length(napi_env env,
                                  napi_value value,
                                  uint32_t* result) copy

[in] env: The environment that the API is invoked under.
[in] value: napi_value representing the JavaScript Array whose length is
being queried.
[out] result: uint32 representing length of the array.

Returns napi_ok if the API succeeded.
This API returns the length of an array.
Array length is described in Section 22.1.4.1 of the ECMAScript Language
Specification.

napi_get_arraybuffer_info#

Added in: v8.0.0
N-API version: 1

napi_status napi_get_arraybuffer_info(napi_env env,
                                      napi_value arraybuffer,
                                      void** data,
                                      size_t* byte_length) copy

[in] env: The environment that the API is invoked under.
[in] arraybuffer: napi_value representing the ArrayBuffer being queried.
[out] data: The underlying data buffer of the ArrayBuffer. If byte_length
is 0, this may be NULL or any other pointer value.
[out] byte_length: Length in bytes of the underlying data buffer.

Returns napi_ok if the API succeeded.
This API is used to retrieve the underlying data buffer of an ArrayBuffer and
its length.
WARNING: Use caution while using this API. The lifetime of the underlying data
buffer is managed by the ArrayBuffer even after it's returned. A
possible safe way to use this API is in conjunction with
napi_create_reference, which can be used to guarantee control over the
lifetime of the ArrayBuffer. It's also safe to use the returned data buffer
within the same callback as long as there are no calls to other APIs that might
trigger a GC.

napi_get_buffer_info#

Added in: v8.0.0
N-API version: 1

napi_status napi_get_buffer_info(napi_env env,
                                 napi_value value,
                                 void** data,
                                 size_t* length) copy

[in] env: The environment that the API is invoked under.
[in] value: napi_value representing the node::Buffer or Uint8Array
being queried.
[out] data: The underlying data buffer of the node::Buffer or
Uint8Array. If length is 0, this may be NULL or any other pointer value.
[out] length: Length in bytes of the underlying data buffer.

Returns napi_ok if the API succeeded.
This method returns the identical data and byte_length as
napi_get_typedarray_info. And napi_get_typedarray_info accepts a
node::Buffer (a Uint8Array) as the value too.
This API is used to retrieve the underlying data buffer of a node::Buffer
and its length.
Warning: Use caution while using this API since the underlying data buffer's
lifetime is not guaranteed if it's managed by the VM.

napi_get_prototype#

Added in: v8.0.0
N-API version: 1

napi_status napi_get_prototype(napi_env env,
                               napi_value object,
                               napi_value* result) copy

[in] env: The environment that the API is invoked under.
[in] object: napi_value representing JavaScript Object whose prototype
to return. This returns the equivalent of Object.getPrototypeOf (which is
not the same as the function's prototype property).
[out] result: napi_value representing prototype of the given object.

Returns napi_ok if the API succeeded.

napi_get_typedarray_info#

Added in: v8.0.0
N-API version: 1

napi_status napi_get_typedarray_info(napi_env env,
                                     napi_value typedarray,
                                     napi_typedarray_type* type,
                                     size_t* length,
                                     void** data,
                                     napi_value* arraybuffer,
                                     size_t* byte_offset) copy

[in] env: The environment that the API is invoked under.
[in] typedarray: napi_value representing the TypedArray whose
properties to query.
[out] type: Scalar datatype of the elements within the TypedArray.
[out] length: The number of elements in the TypedArray.
[out] data: The data buffer underlying the TypedArray adjusted by
the byte_offset value so that it points to the first element in the
TypedArray. If the length of the array is 0, this may be NULL or
any other pointer value.
[out] arraybuffer: The ArrayBuffer underlying the TypedArray.
[out] byte_offset: The byte offset within the underlying native array
at which the first element of the arrays is located. The value for the data
parameter has already been adjusted so that data points to the first element
in the array. Therefore, the first byte of the native array would be at
data - byte_offset.

Returns napi_ok if the API succeeded.
This API returns various properties of a typed array.
Any of the out parameters may be NULL if that property is unneeded.
Warning: Use caution while using this API since the underlying data buffer
is managed by the VM.

napi_get_dataview_info#

Added in: v8.3.0
N-API version: 1

napi_status napi_get_dataview_info(napi_env env,
                                   napi_value dataview,
                                   size_t* byte_length,
                                   void** data,
                                   napi_value* arraybuffer,
                                   size_t* byte_offset) copy

[in] env: The environment that the API is invoked under.
[in] dataview: napi_value representing the DataView whose
properties to query.
[out] byte_length: Number of bytes in the DataView.
[out] data: The data buffer underlying the DataView.
If byte_length is 0, this may be NULL or any other pointer value.
[out] arraybuffer: ArrayBuffer underlying the DataView.
[out] byte_offset: The byte offset within the data buffer from which
to start projecting the DataView.

Returns napi_ok if the API succeeded.
Any of the out parameters may be NULL if that property is unneeded.
This API returns various properties of a DataView.

napi_get_date_value#

Added in: v11.11.0, v10.17.0
N-API version: 5

napi_status napi_get_date_value(napi_env env,
                                napi_value value,
                                double* result) copy

[in] env: The environment that the API is invoked under.
[in] value: napi_value representing a JavaScript Date.
[out] result: Time value as a double represented as milliseconds since
midnight at the beginning of 01 January, 1970 UTC.

This API does not observe leap seconds; they are ignored, as
ECMAScript aligns with POSIX time specification.
Returns napi_ok if the API succeeded. If a non-date napi_value is passed
in it returns napi_date_expected.
This API returns the C double primitive of time value for the given JavaScript
Date.

napi_get_value_bool#

Added in: v8.0.0
N-API version: 1

napi_status napi_get_value_bool(napi_env env, napi_value value, bool* result) copy

[in] env: The environment that the API is invoked under.
[in] value: napi_value representing JavaScript Boolean.
[out] result: C boolean primitive equivalent of the given JavaScript
Boolean.

Returns napi_ok if the API succeeded. If a non-boolean napi_value is
passed in it returns napi_boolean_expected.
This API returns the C boolean primitive equivalent of the given JavaScript
Boolean.

napi_get_value_double#

Added in: v8.0.0
N-API version: 1

napi_status napi_get_value_double(napi_env env,
                                  napi_value value,
                                  double* result) copy

[in] env: The environment that the API is invoked under.
[in] value: napi_value representing JavaScript number.
[out] result: C double primitive equivalent of the given JavaScript
number.

Returns napi_ok if the API succeeded. If a non-number napi_value is passed
in it returns napi_number_expected.
This API returns the C double primitive equivalent of the given JavaScript
number.

napi_get_value_bigint_int64#

Added in: v10.7.0
N-API version: 6

napi_status napi_get_value_bigint_int64(napi_env env,
                                        napi_value value,
                                        int64_t* result,
                                        bool* lossless); copy

[in] env: The environment that the API is invoked under
[in] value: napi_value representing JavaScript BigInt.
[out] result: C int64_t primitive equivalent of the given JavaScript
BigInt.
[out] lossless: Indicates whether the BigInt value was converted
losslessly.

Returns napi_ok if the API succeeded. If a non-BigInt is passed in it
returns napi_bigint_expected.
This API returns the C int64_t primitive equivalent of the given JavaScript
BigInt. If needed it will truncate the value, setting lossless to false.

napi_get_value_bigint_uint64#

Added in: v10.7.0
N-API version: 6

napi_status napi_get_value_bigint_uint64(napi_env env,
                                        napi_value value,
                                        uint64_t* result,
                                        bool* lossless); copy

[in] env: The environment that the API is invoked under.
[in] value: napi_value representing JavaScript BigInt.
[out] result: C uint64_t primitive equivalent of the given JavaScript
BigInt.
[out] lossless: Indicates whether the BigInt value was converted
losslessly.

Returns napi_ok if the API succeeded. If a non-BigInt is passed in it
returns napi_bigint_expected.
This API returns the C uint64_t primitive equivalent of the given JavaScript
BigInt. If needed it will truncate the value, setting lossless to false.

napi_get_value_bigint_words#

Added in: v10.7.0
N-API version: 6

napi_status napi_get_value_bigint_words(napi_env env,
                                        napi_value value,
                                        int* sign_bit,
                                        size_t* word_count,
                                        uint64_t* words); copy

[in] env: The environment that the API is invoked under.
[in] value: napi_value representing JavaScript BigInt.
[out] sign_bit: Integer representing if the JavaScript BigInt is positive
or negative.
[in/out] word_count: Must be initialized to the length of the words
array. Upon return, it will be set to the actual number of words that
would be needed to store this BigInt.
[out] words: Pointer to a pre-allocated 64-bit word array.

Returns napi_ok if the API succeeded.
This API converts a single BigInt value into a sign bit, 64-bit little-endian
array, and the number of elements in the array. sign_bit and words may be
both set to NULL, in order to get only word_count.

napi_get_value_external#

Added in: v8.0.0
N-API version: 1

napi_status napi_get_value_external(napi_env env,
                                    napi_value value,
                                    void** result) copy

[in] env: The environment that the API is invoked under.
[in] value: napi_value representing JavaScript external value.
[out] result: Pointer to the data wrapped by the JavaScript external value.

Returns napi_ok if the API succeeded. If a non-external napi_value is
passed in it returns napi_invalid_arg.
This API retrieves the external data pointer that was previously passed to
napi_create_external().

napi_get_value_int32#

Added in: v8.0.0
N-API version: 1

napi_status napi_get_value_int32(napi_env env,
                                 napi_value value,
                                 int32_t* result) copy

[in] env: The environment that the API is invoked under.
[in] value: napi_value representing JavaScript number.
[out] result: C int32 primitive equivalent of the given JavaScript
number.

Returns napi_ok if the API succeeded. If a non-number napi_value
is passed in napi_number_expected.
This API returns the C int32 primitive equivalent
of the given JavaScript number.
If the number exceeds the range of the 32 bit integer, then the result is
truncated to the equivalent of the bottom 32 bits. This can result in a large
positive number becoming a negative number if the value is > 231 - 1.
Non-finite number values (NaN, +Infinity, or -Infinity) set the
result to zero.

napi_get_value_int64#

Added in: v8.0.0
N-API version: 1

napi_status napi_get_value_int64(napi_env env,
                                 napi_value value,
                                 int64_t* result) copy

[in] env: The environment that the API is invoked under.
[in] value: napi_value representing JavaScript number.
[out] result: C int64 primitive equivalent of the given JavaScript
number.

Returns napi_ok if the API succeeded. If a non-number napi_value
is passed in it returns napi_number_expected.
This API returns the C int64 primitive equivalent of the given JavaScript
number.
number values outside the range of Number.MIN_SAFE_INTEGER
-(2**53 - 1) - Number.MAX_SAFE_INTEGER (2**53 - 1) will lose
precision.
Non-finite number values (NaN, +Infinity, or -Infinity) set the
result to zero.

napi_get_value_string_latin1#

Added in: v8.0.0
N-API version: 1

napi_status napi_get_value_string_latin1(napi_env env,
                                         napi_value value,
                                         char* buf,
                                         size_t bufsize,
                                         size_t* result) copy

[in] env: The environment that the API is invoked under.
[in] value: napi_value representing JavaScript string.
[in] buf: Buffer to write the ISO-8859-1-encoded string into. If NULL is
passed in, the length of the string in bytes and excluding the null terminator
is returned in result.
[in] bufsize: Size of the destination buffer. When this value is
insufficient, the returned string is truncated and null-terminated.
[out] result: Number of bytes copied into the buffer, excluding the null
terminator.

Returns napi_ok if the API succeeded. If a non-string napi_value
is passed in it returns napi_string_expected.
This API returns the ISO-8859-1-encoded string corresponding the value passed
in.

napi_get_value_string_utf8#

Added in: v8.0.0
N-API version: 1

napi_status napi_get_value_string_utf8(napi_env env,
                                       napi_value value,
                                       char* buf,
                                       size_t bufsize,
                                       size_t* result) copy

[in] env: The environment that the API is invoked under.
[in] value: napi_value representing JavaScript string.
[in] buf: Buffer to write the UTF8-encoded string into. If NULL is passed
in, the length of the string in bytes and excluding the null terminator is
returned in result.
[in] bufsize: Size of the destination buffer. When this value is
insufficient, the returned string is truncated and null-terminated.
[out] result: Number of bytes copied into the buffer, excluding the null
terminator.

Returns napi_ok if the API succeeded. If a non-string napi_value
is passed in it returns napi_string_expected.
This API returns the UTF8-encoded string corresponding the value passed in.

napi_get_value_string_utf16#

Added in: v8.0.0
N-API version: 1

napi_status napi_get_value_string_utf16(napi_env env,
                                        napi_value value,
                                        char16_t* buf,
                                        size_t bufsize,
                                        size_t* result) copy

[in] env: The environment that the API is invoked under.
[in] value: napi_value representing JavaScript string.
[in] buf: Buffer to write the UTF16-LE-encoded string into. If NULL is
passed in, the length of the string in 2-byte code units and excluding the
null terminator is returned.
[in] bufsize: Size of the destination buffer. When this value is
insufficient, the returned string is truncated and null-terminated.
[out] result: Number of 2-byte code units copied into the buffer, excluding
the null terminator.

Returns napi_ok if the API succeeded. If a non-string napi_value
is passed in it returns napi_string_expected.
This API returns the UTF16-encoded string corresponding the value passed in.

napi_get_value_uint32#

Added in: v8.0.0
N-API version: 1

napi_status napi_get_value_uint32(napi_env env,
                                  napi_value value,
                                  uint32_t* result) copy

[in] env: The environment that the API is invoked under.
[in] value: napi_value representing JavaScript number.
[out] result: C primitive equivalent of the given napi_value as a
uint32_t.

Returns napi_ok if the API succeeded. If a non-number napi_value
is passed in it returns napi_number_expected.
This API returns the C primitive equivalent of the given napi_value as a
uint32_t.

Functions to get global instances#

napi_get_boolean#

Added in: v8.0.0
N-API version: 1

napi_status napi_get_boolean(napi_env env, bool value, napi_value* result) copy

[in] env: The environment that the API is invoked under.
[in] value: The value of the boolean to retrieve.
[out] result: napi_value representing JavaScript Boolean singleton to
retrieve.

Returns napi_ok if the API succeeded.
This API is used to return the JavaScript singleton object that is used to
represent the given boolean value.

napi_get_global#

Added in: v8.0.0
N-API version: 1

napi_status napi_get_global(napi_env env, napi_value* result) copy

[in] env: The environment that the API is invoked under.
[out] result: napi_value representing JavaScript global object.

Returns napi_ok if the API succeeded.
This API returns the global object.

napi_get_null#

Added in: v8.0.0
N-API version: 1

napi_status napi_get_null(napi_env env, napi_value* result) copy

[in] env: The environment that the API is invoked under.
[out] result: napi_value representing JavaScript null object.

Returns napi_ok if the API succeeded.
This API returns the null object.

napi_get_undefined#

Added in: v8.0.0
N-API version: 1

napi_status napi_get_undefined(napi_env env, napi_value* result) copy

[in] env: The environment that the API is invoked under.
[out] result: napi_value representing JavaScript Undefined value.

Returns napi_ok if the API succeeded.
This API returns the Undefined object.

Working with JavaScript values and abstract operations#
Node-API exposes a set of APIs to perform some abstract operations on JavaScript
values. Some of these operations are documented under Section 7
of the ECMAScript Language Specification.
These APIs support doing one of the following:

Coerce JavaScript values to specific JavaScript types (such as number or
string).
Check the type of a JavaScript value.
Check for equality between two JavaScript values.


napi_coerce_to_bool#

Added in: v8.0.0
N-API version: 1

napi_status napi_coerce_to_bool(napi_env env,
                                napi_value value,
                                napi_value* result) copy

[in] env: The environment that the API is invoked under.
[in] value: The JavaScript value to coerce.
[out] result: napi_value representing the coerced JavaScript Boolean.

Returns napi_ok if the API succeeded.
This API implements the abstract operation ToBoolean() as defined in
Section 7.1.2 of the ECMAScript Language Specification.

napi_coerce_to_number#

Added in: v8.0.0
N-API version: 1

napi_status napi_coerce_to_number(napi_env env,
                                  napi_value value,
                                  napi_value* result) copy

[in] env: The environment that the API is invoked under.
[in] value: The JavaScript value to coerce.
[out] result: napi_value representing the coerced JavaScript number.

Returns napi_ok if the API succeeded.
This API implements the abstract operation ToNumber() as defined in
Section 7.1.3 of the ECMAScript Language Specification.
This function potentially runs JS code if the passed-in value is an
object.

napi_coerce_to_object#

Added in: v8.0.0
N-API version: 1

napi_status napi_coerce_to_object(napi_env env,
                                  napi_value value,
                                  napi_value* result) copy

[in] env: The environment that the API is invoked under.
[in] value: The JavaScript value to coerce.
[out] result: napi_value representing the coerced JavaScript Object.

Returns napi_ok if the API succeeded.
This API implements the abstract operation ToObject() as defined in
Section 7.1.13 of the ECMAScript Language Specification.

napi_coerce_to_string#

Added in: v8.0.0
N-API version: 1

napi_status napi_coerce_to_string(napi_env env,
                                  napi_value value,
                                  napi_value* result) copy

[in] env: The environment that the API is invoked under.
[in] value: The JavaScript value to coerce.
[out] result: napi_value representing the coerced JavaScript string.

Returns napi_ok if the API succeeded.
This API implements the abstract operation ToString() as defined in
Section 7.1.13 of the ECMAScript Language Specification.
This function potentially runs JS code if the passed-in value is an
object.

napi_typeof#

Added in: v8.0.0
N-API version: 1

napi_status napi_typeof(napi_env env, napi_value value, napi_valuetype* result) copy

[in] env: The environment that the API is invoked under.
[in] value: The JavaScript value whose type to query.
[out] result: The type of the JavaScript value.

Returns napi_ok if the API succeeded.

napi_invalid_arg if the type of value is not a known ECMAScript type and
value is not an External value.

This API represents behavior similar to invoking the typeof Operator on
the object as defined in Section 12.5.5 of the ECMAScript Language
Specification. However, there are some differences:

It has support for detecting an External value.
It detects null as a separate type, while ECMAScript typeof would detect
object.

If value has a type that is invalid, an error is returned.

napi_instanceof#

Added in: v8.0.0
N-API version: 1

napi_status napi_instanceof(napi_env env,
                            napi_value object,
                            napi_value constructor,
                            bool* result) copy

[in] env: The environment that the API is invoked under.
[in] object: The JavaScript value to check.
[in] constructor: The JavaScript function object of the constructor function
to check against.
[out] result: Boolean that is set to true if object instanceof constructor
is true.

Returns napi_ok if the API succeeded.
This API represents invoking the instanceof Operator on the object as
defined in Section 12.10.4 of the ECMAScript Language Specification.

napi_is_array#

Added in: v8.0.0
N-API version: 1

napi_status napi_is_array(napi_env env, napi_value value, bool* result) copy

[in] env: The environment that the API is invoked under.
[in] value: The JavaScript value to check.
[out] result: Whether the given object is an array.

Returns napi_ok if the API succeeded.
This API represents invoking the IsArray operation on the object
as defined in Section 7.2.2 of the ECMAScript Language Specification.

napi_is_arraybuffer#

Added in: v8.0.0
N-API version: 1

napi_status napi_is_arraybuffer(napi_env env, napi_value value, bool* result) copy

[in] env: The environment that the API is invoked under.
[in] value: The JavaScript value to check.
[out] result: Whether the given object is an ArrayBuffer.

Returns napi_ok if the API succeeded.
This API checks if the Object passed in is an array buffer.

napi_is_buffer#

Added in: v8.0.0
N-API version: 1

napi_status napi_is_buffer(napi_env env, napi_value value, bool* result) copy

[in] env: The environment that the API is invoked under.
[in] value: The JavaScript value to check.
[out] result: Whether the given napi_value represents a node::Buffer or
Uint8Array object.

Returns napi_ok if the API succeeded.
This API checks if the Object passed in is a buffer or Uint8Array.
napi_is_typedarray should be preferred if the caller needs to check if the
value is a Uint8Array.

napi_is_date#

Added in: v11.11.0, v10.17.0
N-API version: 5

napi_status napi_is_date(napi_env env, napi_value value, bool* result) copy

[in] env: The environment that the API is invoked under.
[in] value: The JavaScript value to check.
[out] result: Whether the given napi_value represents a JavaScript Date
object.

Returns napi_ok if the API succeeded.
This API checks if the Object passed in is a date.

napi_is_error#

Added in: v8.0.0
N-API version: 1

napi_status napi_is_error(napi_env env, napi_value value, bool* result) copy

[in] env: The environment that the API is invoked under.
[in] value: The JavaScript value to check.
[out] result: Whether the given napi_value represents an Error object.

Returns napi_ok if the API succeeded.
This API checks if the Object passed in is an Error.

napi_is_typedarray#

Added in: v8.0.0
N-API version: 1

napi_status napi_is_typedarray(napi_env env, napi_value value, bool* result) copy

[in] env: The environment that the API is invoked under.
[in] value: The JavaScript value to check.
[out] result: Whether the given napi_value represents a TypedArray.

Returns napi_ok if the API succeeded.
This API checks if the Object passed in is a typed array.

napi_is_dataview#

Added in: v8.3.0
N-API version: 1

napi_status napi_is_dataview(napi_env env, napi_value value, bool* result) copy

[in] env: The environment that the API is invoked under.
[in] value: The JavaScript value to check.
[out] result: Whether the given napi_value represents a DataView.

Returns napi_ok if the API succeeded.
This API checks if the Object passed in is a DataView.

napi_strict_equals#

Added in: v8.0.0
N-API version: 1

napi_status napi_strict_equals(napi_env env,
                               napi_value lhs,
                               napi_value rhs,
                               bool* result) copy

[in] env: The environment that the API is invoked under.
[in] lhs: The JavaScript value to check.
[in] rhs: The JavaScript value to check against.
[out] result: Whether the two napi_value objects are equal.

Returns napi_ok if the API succeeded.
This API represents the invocation of the Strict Equality algorithm as
defined in Section 7.2.14 of the ECMAScript Language Specification.

napi_detach_arraybuffer#

Added in: v13.0.0, v12.16.0, v10.22.0
N-API version: 7

napi_status napi_detach_arraybuffer(napi_env env,
                                    napi_value arraybuffer) copy

[in] env: The environment that the API is invoked under.
[in] arraybuffer: The JavaScript ArrayBuffer to be detached.

Returns napi_ok if the API succeeded. If a non-detachable ArrayBuffer is
passed in it returns napi_detachable_arraybuffer_expected.
Generally, an ArrayBuffer is non-detachable if it has been detached before.
The engine may impose additional conditions on whether an ArrayBuffer is
detachable. For example, V8 requires that the ArrayBuffer be external,
that is, created with napi_create_external_arraybuffer.
This API represents the invocation of the ArrayBuffer detach operation as
defined in Section 24.1.1.3 of the ECMAScript Language Specification.

napi_is_detached_arraybuffer#

Added in: v13.3.0, v12.16.0, v10.22.0
N-API version: 7

napi_status napi_is_detached_arraybuffer(napi_env env,
                                         napi_value arraybuffer,
                                         bool* result) copy

[in] env: The environment that the API is invoked under.
[in] arraybuffer: The JavaScript ArrayBuffer to be checked.
[out] result: Whether the arraybuffer is detached.

Returns napi_ok if the API succeeded.
The ArrayBuffer is considered detached if its internal data is null.
This API represents the invocation of the ArrayBuffer IsDetachedBuffer
operation as defined in Section 24.1.1.2 of the ECMAScript Language
Specification.

Working with JavaScript properties#
Node-API exposes a set of APIs to get and set properties on JavaScript
objects. Some of these types are documented under Section 7 of the
ECMAScript Language Specification.
Properties in JavaScript are represented as a tuple of a key and a value.
Fundamentally, all property keys in Node-API can be represented in one of the
following forms:

Named: a simple UTF8-encoded string
Integer-Indexed: an index value represented by uint32_t
JavaScript value: these are represented in Node-API by napi_value. This can
be a napi_value representing a string, number, or symbol.

Node-API values are represented by the type napi_value.
Any Node-API call that requires a JavaScript value takes in a napi_value.
However, it's the caller's responsibility to make sure that the
napi_value in question is of the JavaScript type expected by the API.
The APIs documented in this section provide a simple interface to
get and set properties on arbitrary JavaScript objects represented by
napi_value.
For instance, consider the following JavaScript code snippet:
const obj = {};
obj.myProp = 123; copy
The equivalent can be done using Node-API values with the following snippet:
napi_status status = napi_generic_failure;

// const obj = {}
napi_value obj, value;
status = napi_create_object(env, &obj);
if (status != napi_ok) return status;

// Create a napi_value for 123
status = napi_create_int32(env, 123, &value);
if (status != napi_ok) return status;

// obj.myProp = 123
status = napi_set_named_property(env, obj, "myProp", value);
if (status != napi_ok) return status; copy
Indexed properties can be set in a similar manner. Consider the following
JavaScript snippet:
const arr = [];
arr[123] = 'hello'; copy
The equivalent can be done using Node-API values with the following snippet:
napi_status status = napi_generic_failure;

// const arr = [];
napi_value arr, value;
status = napi_create_array(env, &arr);
if (status != napi_ok) return status;

// Create a napi_value for 'hello'
status = napi_create_string_utf8(env, "hello", NAPI_AUTO_LENGTH, &value);
if (status != napi_ok) return status;

// arr[123] = 'hello';
status = napi_set_element(env, arr, 123, value);
if (status != napi_ok) return status; copy
Properties can be retrieved using the APIs described in this section.
Consider the following JavaScript snippet:
const arr = [];
const value = arr[123]; copy
The following is the approximate equivalent of the Node-API counterpart:
napi_status status = napi_generic_failure;

// const arr = []
napi_value arr, value;
status = napi_create_array(env, &arr);
if (status != napi_ok) return status;

// const value = arr[123]
status = napi_get_element(env, arr, 123, &value);
if (status != napi_ok) return status; copy
Finally, multiple properties can also be defined on an object for performance
reasons. Consider the following JavaScript:
const obj = {};
Object.defineProperties(obj, {
  'foo': { value: 123, writable: true, configurable: true, enumerable: true },
  'bar': { value: 456, writable: true, configurable: true, enumerable: true },
}); copy
The following is the approximate equivalent of the Node-API counterpart:
napi_status status = napi_status_generic_failure;

// const obj = {};
napi_value obj;
status = napi_create_object(env, &obj);
if (status != napi_ok) return status;

// Create napi_values for 123 and 456
napi_value fooValue, barValue;
status = napi_create_int32(env, 123, &fooValue);
if (status != napi_ok) return status;
status = napi_create_int32(env, 456, &barValue);
if (status != napi_ok) return status;

// Set the properties
napi_property_descriptor descriptors[] = {
  { "foo", NULL, NULL, NULL, NULL, fooValue, napi_writable | napi_configurable, NULL },
  { "bar", NULL, NULL, NULL, NULL, barValue, napi_writable | napi_configurable, NULL }
}
status = napi_define_properties(env,
                                obj,
                                sizeof(descriptors) / sizeof(descriptors[0]),
                                descriptors);
if (status != napi_ok) return status; copy

Structures#

napi_property_attributes#

History

VersionChanges
v14.12.0
added napi_default_method and napi_default_property.



typedef enum {
  napi_default = 0,
  napi_writable = 1 << 0,
  napi_enumerable = 1 << 1,
  napi_configurable = 1 << 2,

  // Used with napi_define_class to distinguish static properties
  // from instance properties. Ignored by napi_define_properties.
  napi_static = 1 << 10,

  // Default for class methods.
  napi_default_method = napi_writable | napi_configurable,

  // Default for object properties, like in JS obj[prop].
  napi_default_jsproperty = napi_writable |
                          napi_enumerable |
                          napi_configurable,
} napi_property_attributes; copy
napi_property_attributes are flags used to control the behavior of properties
set on a JavaScript object. Other than napi_static they correspond to the
attributes listed in Section 6.1.7.1
of the ECMAScript Language Specification.
They can be one or more of the following bitflags:

napi_default: No explicit attributes are set on the property. By default, a
property is read only, not enumerable and not configurable.
napi_writable: The property is writable.
napi_enumerable: The property is enumerable.
napi_configurable: The property is configurable as defined in
Section 6.1.7.1 of the ECMAScript Language Specification.
napi_static: The property will be defined as a static property on a class as
opposed to an instance property, which is the default. This is used only by
napi_define_class. It is ignored by napi_define_properties.
napi_default_method: Like a method in a JS class, the property is
configurable and writeable, but not enumerable.
napi_default_jsproperty: Like a property set via assignment in JavaScript,
the property is writable, enumerable, and configurable.


napi_property_descriptor#
typedef struct {
  // One of utf8name or name should be NULL.
  const char* utf8name;
  napi_value name;

  napi_callback method;
  napi_callback getter;
  napi_callback setter;
  napi_value value;

  napi_property_attributes attributes;
  void* data;
} napi_property_descriptor; copy

utf8name: Optional string describing the key for the property,
encoded as UTF8. One of utf8name or name must be provided for the
property.
name: Optional napi_value that points to a JavaScript string or symbol
to be used as the key for the property. One of utf8name or name must
be provided for the property.
value: The value that's retrieved by a get access of the property if the
property is a data property. If this is passed in, set getter, setter,
method and data to NULL (since these members won't be used).
getter: A function to call when a get access of the property is performed.
If this is passed in, set value and method to NULL (since these members
won't be used). The given function is called implicitly by the runtime when
the property is accessed from JavaScript code (or if a get on the property is
performed using a Node-API call). napi_callback provides more details.
setter: A function to call when a set access of the property is performed.
If this is passed in, set value and method to NULL (since these members
won't be used). The given function is called implicitly by the runtime when
the property is set from JavaScript code (or if a set on the property is
performed using a Node-API call). napi_callback provides more details.
method: Set this to make the property descriptor object's value
property to be a JavaScript function represented by method. If this is
passed in, set value, getter and setter to NULL (since these members
won't be used). napi_callback provides more details.
attributes: The attributes associated with the particular property. See
napi_property_attributes.
data: The callback data passed into method, getter and setter if this
function is invoked.


Functions#

napi_get_property_names#

Added in: v8.0.0
N-API version: 1

napi_status napi_get_property_names(napi_env env,
                                    napi_value object,
                                    napi_value* result); copy

[in] env: The environment that the Node-API call is invoked under.
[in] object: The object from which to retrieve the properties.
[out] result: A napi_value representing an array of JavaScript values
that represent the property names of the object. The API can be used to
iterate over result using napi_get_array_length
and napi_get_element.

Returns napi_ok if the API succeeded.
This API returns the names of the enumerable properties of object as an array
of strings. The properties of object whose key is a symbol will not be
included.

napi_get_all_property_names#

Added in: v13.7.0, v12.17.0, v10.20.0
N-API version: 6

napi_get_all_property_names(napi_env env,
                            napi_value object,
                            napi_key_collection_mode key_mode,
                            napi_key_filter key_filter,
                            napi_key_conversion key_conversion,
                            napi_value* result); copy

[in] env: The environment that the Node-API call is invoked under.
[in] object: The object from which to retrieve the properties.
[in] key_mode: Whether to retrieve prototype properties as well.
[in] key_filter: Which properties to retrieve
(enumerable/readable/writable).
[in] key_conversion: Whether to convert numbered property keys to strings.
[out] result: A napi_value representing an array of JavaScript values
that represent the property names of the object. napi_get_array_length
and napi_get_element can be used to iterate over result.

Returns napi_ok if the API succeeded.
This API returns an array containing the names of the available properties
of this object.

napi_set_property#

Added in: v8.0.0
N-API version: 1

napi_status napi_set_property(napi_env env,
                              napi_value object,
                              napi_value key,
                              napi_value value); copy

[in] env: The environment that the Node-API call is invoked under.
[in] object: The object on which to set the property.
[in] key: The name of the property to set.
[in] value: The property value.

Returns napi_ok if the API succeeded.
This API set a property on the Object passed in.

napi_get_property#

Added in: v8.0.0
N-API version: 1

napi_status napi_get_property(napi_env env,
                              napi_value object,
                              napi_value key,
                              napi_value* result); copy

[in] env: The environment that the Node-API call is invoked under.
[in] object: The object from which to retrieve the property.
[in] key: The name of the property to retrieve.
[out] result: The value of the property.

Returns napi_ok if the API succeeded.
This API gets the requested property from the Object passed in.

napi_has_property#

Added in: v8.0.0
N-API version: 1

napi_status napi_has_property(napi_env env,
                              napi_value object,
                              napi_value key,
                              bool* result); copy

[in] env: The environment that the Node-API call is invoked under.
[in] object: The object to query.
[in] key: The name of the property whose existence to check.
[out] result: Whether the property exists on the object or not.

Returns napi_ok if the API succeeded.
This API checks if the Object passed in has the named property.

napi_delete_property#

Added in: v8.2.0
N-API version: 1

napi_status napi_delete_property(napi_env env,
                                 napi_value object,
                                 napi_value key,
                                 bool* result); copy

[in] env: The environment that the Node-API call is invoked under.
[in] object: The object to query.
[in] key: The name of the property to delete.
[out] result: Whether the property deletion succeeded or not. result can
optionally be ignored by passing NULL.

Returns napi_ok if the API succeeded.
This API attempts to delete the key own property from object.

napi_has_own_property#

Added in: v8.2.0
N-API version: 1

napi_status napi_has_own_property(napi_env env,
                                  napi_value object,
                                  napi_value key,
                                  bool* result); copy

[in] env: The environment that the Node-API call is invoked under.
[in] object: The object to query.
[in] key: The name of the own property whose existence to check.
[out] result: Whether the own property exists on the object or not.

Returns napi_ok if the API succeeded.
This API checks if the Object passed in has the named own property. key must
be a string or a symbol, or an error will be thrown. Node-API will not
perform any conversion between data types.

napi_set_named_property#

Added in: v8.0.0
N-API version: 1

napi_status napi_set_named_property(napi_env env,
                                    napi_value object,
                                    const char* utf8Name,
                                    napi_value value); copy

[in] env: The environment that the Node-API call is invoked under.
[in] object: The object on which to set the property.
[in] utf8Name: The name of the property to set.
[in] value: The property value.

Returns napi_ok if the API succeeded.
This method is equivalent to calling napi_set_property with a napi_value
created from the string passed in as utf8Name.

napi_get_named_property#

Added in: v8.0.0
N-API version: 1

napi_status napi_get_named_property(napi_env env,
                                    napi_value object,
                                    const char* utf8Name,
                                    napi_value* result); copy

[in] env: The environment that the Node-API call is invoked under.
[in] object: The object from which to retrieve the property.
[in] utf8Name: The name of the property to get.
[out] result: The value of the property.

Returns napi_ok if the API succeeded.
This method is equivalent to calling napi_get_property with a napi_value
created from the string passed in as utf8Name.

napi_has_named_property#

Added in: v8.0.0
N-API version: 1

napi_status napi_has_named_property(napi_env env,
                                    napi_value object,
                                    const char* utf8Name,
                                    bool* result); copy

[in] env: The environment that the Node-API call is invoked under.
[in] object: The object to query.
[in] utf8Name: The name of the property whose existence to check.
[out] result: Whether the property exists on the object or not.

Returns napi_ok if the API succeeded.
This method is equivalent to calling napi_has_property with a napi_value
created from the string passed in as utf8Name.

napi_set_element#

Added in: v8.0.0
N-API version: 1

napi_status napi_set_element(napi_env env,
                             napi_value object,
                             uint32_t index,
                             napi_value value); copy

[in] env: The environment that the Node-API call is invoked under.
[in] object: The object from which to set the properties.
[in] index: The index of the property to set.
[in] value: The property value.

Returns napi_ok if the API succeeded.
This API sets an element on the Object passed in.

napi_get_element#

Added in: v8.0.0
N-API version: 1

napi_status napi_get_element(napi_env env,
                             napi_value object,
                             uint32_t index,
                             napi_value* result); copy

[in] env: The environment that the Node-API call is invoked under.
[in] object: The object from which to retrieve the property.
[in] index: The index of the property to get.
[out] result: The value of the property.

Returns napi_ok if the API succeeded.
This API gets the element at the requested index.

napi_has_element#

Added in: v8.0.0
N-API version: 1

napi_status napi_has_element(napi_env env,
                             napi_value object,
                             uint32_t index,
                             bool* result); copy

[in] env: The environment that the Node-API call is invoked under.
[in] object: The object to query.
[in] index: The index of the property whose existence to check.
[out] result: Whether the property exists on the object or not.

Returns napi_ok if the API succeeded.
This API returns if the Object passed in has an element at the
requested index.

napi_delete_element#

Added in: v8.2.0
N-API version: 1

napi_status napi_delete_element(napi_env env,
                                napi_value object,
                                uint32_t index,
                                bool* result); copy

[in] env: The environment that the Node-API call is invoked under.
[in] object: The object to query.
[in] index: The index of the property to delete.
[out] result: Whether the element deletion succeeded or not. result can
optionally be ignored by passing NULL.

Returns napi_ok if the API succeeded.
This API attempts to delete the specified index from object.

napi_define_properties#

Added in: v8.0.0
N-API version: 1

napi_status napi_define_properties(napi_env env,
                                   napi_value object,
                                   size_t property_count,
                                   const napi_property_descriptor* properties); copy

[in] env: The environment that the Node-API call is invoked under.
[in] object: The object from which to retrieve the properties.
[in] property_count: The number of elements in the properties array.
[in] properties: The array of property descriptors.

Returns napi_ok if the API succeeded.
This method allows the efficient definition of multiple properties on a given
object. The properties are defined using property descriptors (see
napi_property_descriptor). Given an array of such property descriptors,
this API will set the properties on the object one at a time, as defined by
DefineOwnProperty() (described in Section 9.1.6 of the ECMA-262
specification).

napi_object_freeze#

Added in: v14.14.0, v12.20.0
N-API version: 8

napi_status napi_object_freeze(napi_env env,
                               napi_value object); copy

[in] env: The environment that the Node-API call is invoked under.
[in] object: The object to freeze.

Returns napi_ok if the API succeeded.
This method freezes a given object. This prevents new properties from
being added to it, existing properties from being removed, prevents
changing the enumerability, configurability, or writability of existing
properties, and prevents the values of existing properties from being changed.
It also prevents the object's prototype from being changed. This is described
in Section 19.1.2.6 of the
ECMA-262 specification.

napi_object_seal#

Added in: v14.14.0, v12.20.0
N-API version: 8

napi_status napi_object_seal(napi_env env,
                             napi_value object); copy

[in] env: The environment that the Node-API call is invoked under.
[in] object: The object to seal.

Returns napi_ok if the API succeeded.
This method seals a given object. This prevents new properties from being
added to it, as well as marking all existing properties as non-configurable.
This is described in Section 19.1.2.20
of the ECMA-262 specification.

Working with JavaScript functions#
Node-API provides a set of APIs that allow JavaScript code to
call back into native code. Node-APIs that support calling back
into native code take in a callback functions represented by
the napi_callback type. When the JavaScript VM calls back to
native code, the napi_callback function provided is invoked. The APIs
documented in this section allow the callback function to do the
following:

Get information about the context in which the callback was invoked.
Get the arguments passed into the callback.
Return a napi_value back from the callback.

Additionally, Node-API provides a set of functions which allow calling
JavaScript functions from native code. One can either call a function
like a regular JavaScript function call, or as a constructor
function.
Any non-NULL data which is passed to this API via the data field of the
napi_property_descriptor items can be associated with object and freed
whenever object is garbage-collected by passing both object and the data to
napi_add_finalizer.

napi_call_function#

Added in: v8.0.0
N-API version: 1

NAPI_EXTERN napi_status napi_call_function(napi_env env,
                                           napi_value recv,
                                           napi_value func,
                                           size_t argc,
                                           const napi_value* argv,
                                           napi_value* result); copy

[in] env: The environment that the API is invoked under.
[in] recv: The this value passed to the called function.
[in] func: napi_value representing the JavaScript function to be invoked.
[in] argc: The count of elements in the argv array.
[in] argv: Array of napi_values representing JavaScript values passed in
as arguments to the function.
[out] result: napi_value representing the JavaScript object returned.

Returns napi_ok if the API succeeded.
This method allows a JavaScript function object to be called from a native
add-on. This is the primary mechanism of calling back from the add-on's
native code into JavaScript. For the special case of calling into JavaScript
after an async operation, see napi_make_callback.
A sample use case might look as follows. Consider the following JavaScript
snippet:
function AddTwo(num) {
  return num + 2;
}
global.AddTwo = AddTwo; copy
Then, the above function can be invoked from a native add-on using the
following code:
// Get the function named "AddTwo" on the global object
napi_value global, add_two, arg;
napi_status status = napi_get_global(env, &global);
if (status != napi_ok) return;

status = napi_get_named_property(env, global, "AddTwo", &add_two);
if (status != napi_ok) return;

// const arg = 1337
status = napi_create_int32(env, 1337, &arg);
if (status != napi_ok) return;

napi_value* argv = &arg;
size_t argc = 1;

// AddTwo(arg);
napi_value return_val;
status = napi_call_function(env, global, add_two, argc, argv, &return_val);
if (status != napi_ok) return;

// Convert the result back to a native type
int32_t result;
status = napi_get_value_int32(env, return_val, &result);
if (status != napi_ok) return; copy

napi_create_function#

Added in: v8.0.0
N-API version: 1

napi_status napi_create_function(napi_env env,
                                 const char* utf8name,
                                 size_t length,
                                 napi_callback cb,
                                 void* data,
                                 napi_value* result); copy

[in] env: The environment that the API is invoked under.
[in] utf8Name: Optional name of the function encoded as UTF8. This is
visible within JavaScript as the new function object's name property.
[in] length: The length of the utf8name in bytes, or NAPI_AUTO_LENGTH if
it is null-terminated.
[in] cb: The native function which should be called when this function
object is invoked. napi_callback provides more details.
[in] data: User-provided data context. This will be passed back into the
function when invoked later.
[out] result: napi_value representing the JavaScript function object for
the newly created function.

Returns napi_ok if the API succeeded.
This API allows an add-on author to create a function object in native code.
This is the primary mechanism to allow calling into the add-on's native code
from JavaScript.
The newly created function is not automatically visible from script after this
call. Instead, a property must be explicitly set on any object that is visible
to JavaScript, in order for the function to be accessible from script.
In order to expose a function as part of the
add-on's module exports, set the newly created function on the exports
object. A sample module might look as follows:
napi_value SayHello(napi_env env, napi_callback_info info) {
  printf("Hello\n");
  return NULL;
}

napi_value Init(napi_env env, napi_value exports) {
  napi_status status;

  napi_value fn;
  status = napi_create_function(env, NULL, 0, SayHello, NULL, &fn);
  if (status != napi_ok) return NULL;

  status = napi_set_named_property(env, exports, "sayHello", fn);
  if (status != napi_ok) return NULL;

  return exports;
}

NAPI_MODULE(NODE_GYP_MODULE_NAME, Init) copy
Given the above code, the add-on can be used from JavaScript as follows:
const myaddon = require('./addon');
myaddon.sayHello(); copy
The string passed to require() is the name of the target in binding.gyp
responsible for creating the .node file.
Any non-NULL data which is passed to this API via the data parameter can
be associated with the resulting JavaScript function (which is returned in the
result parameter) and freed whenever the function is garbage-collected by
passing both the JavaScript function and the data to napi_add_finalizer.
JavaScript Functions are described in Section 19.2 of the ECMAScript
Language Specification.

napi_get_cb_info#

Added in: v8.0.0
N-API version: 1

napi_status napi_get_cb_info(napi_env env,
                             napi_callback_info cbinfo,
                             size_t* argc,
                             napi_value* argv,
                             napi_value* thisArg,
                             void** data) copy

[in] env: The environment that the API is invoked under.
[in] cbinfo: The callback info passed into the callback function.
[in-out] argc: Specifies the length of the provided argv array and
receives the actual count of arguments. argc can
optionally be ignored by passing NULL.
[out] argv: C array of napi_values to which the arguments will be
copied. If there are more arguments than the provided count, only the
requested number of arguments are copied. If there are fewer arguments
provided than claimed, the rest of argv is filled with napi_value values
that represent undefined. argv can optionally be ignored by
passing NULL.
[out] thisArg: Receives the JavaScript this argument for the call.
thisArg can optionally be ignored by passing NULL.
[out] data: Receives the data pointer for the callback. data can
optionally be ignored by passing NULL.

Returns napi_ok if the API succeeded.
This method is used within a callback function to retrieve details about the
call like the arguments and the this pointer from a given callback info.

napi_get_new_target#

Added in: v8.6.0
N-API version: 1

napi_status napi_get_new_target(napi_env env,
                                napi_callback_info cbinfo,
                                napi_value* result) copy

[in] env: The environment that the API is invoked under.
[in] cbinfo: The callback info passed into the callback function.
[out] result: The new.target of the constructor call.

Returns napi_ok if the API succeeded.
This API returns the new.target of the constructor call. If the current
callback is not a constructor call, the result is NULL.

napi_new_instance#

Added in: v8.0.0
N-API version: 1

napi_status napi_new_instance(napi_env env,
                              napi_value cons,
                              size_t argc,
                              napi_value* argv,
                              napi_value* result) copy

[in] env: The environment that the API is invoked under.
[in] cons: napi_value representing the JavaScript function to be invoked
as a constructor.
[in] argc: The count of elements in the argv array.
[in] argv: Array of JavaScript values as napi_value representing the
arguments to the constructor. If argc is zero this parameter may be
omitted by passing in NULL.
[out] result: napi_value representing the JavaScript object returned,
which in this case is the constructed object.

This method is used to instantiate a new JavaScript value using a given
napi_value that represents the constructor for the object. For example,
consider the following snippet:
function MyObject(param) {
  this.param = param;
}

const arg = 'hello';
const value = new MyObject(arg); copy
The following can be approximated in Node-API using the following snippet:
// Get the constructor function MyObject
napi_value global, constructor, arg, value;
napi_status status = napi_get_global(env, &global);
if (status != napi_ok) return;

status = napi_get_named_property(env, global, "MyObject", &constructor);
if (status != napi_ok) return;

// const arg = "hello"
status = napi_create_string_utf8(env, "hello", NAPI_AUTO_LENGTH, &arg);
if (status != napi_ok) return;

napi_value* argv = &arg;
size_t argc = 1;

// const value = new MyObject(arg)
status = napi_new_instance(env, constructor, argc, argv, &value); copy
Returns napi_ok if the API succeeded.

Object wrap#
Node-API offers a way to "wrap" C++ classes and instances so that the class
constructor and methods can be called from JavaScript.

The napi_define_class API defines a JavaScript class with constructor,
static properties and methods, and instance properties and methods that
correspond to the C++ class.
When JavaScript code invokes the constructor, the constructor callback
uses napi_wrap to wrap a new C++ instance in a JavaScript object,
then returns the wrapper object.
When JavaScript code invokes a method or property accessor on the class,
the corresponding napi_callback C++ function is invoked. For an instance
callback, napi_unwrap obtains the C++ instance that is the target of
the call.

For wrapped objects it may be difficult to distinguish between a function
called on a class prototype and a function called on an instance of a class.
A common pattern used to address this problem is to save a persistent
reference to the class constructor for later instanceof checks.
napi_value MyClass_constructor = NULL;
status = napi_get_reference_value(env, MyClass::es_constructor, &MyClass_constructor);
assert(napi_ok == status);
bool is_instance = false;
status = napi_instanceof(env, es_this, MyClass_constructor, &is_instance);
assert(napi_ok == status);
if (is_instance) {
  // napi_unwrap() ...
} else {
  // otherwise...
} copy
The reference must be freed once it is no longer needed.
There are occasions where napi_instanceof() is insufficient for ensuring that
a JavaScript object is a wrapper for a certain native type. This is the case
especially when wrapped JavaScript objects are passed back into the addon via
static methods rather than as the this value of prototype methods. In such
cases there is a chance that they may be unwrapped incorrectly.
const myAddon = require('./build/Release/my_addon.node');

// `openDatabase()` returns a JavaScript object that wraps a native database
// handle.
const dbHandle = myAddon.openDatabase();

// `query()` returns a JavaScript object that wraps a native query handle.
const queryHandle = myAddon.query(dbHandle, 'Gimme ALL the things!');

// There is an accidental error in the line below. The first parameter to
// `myAddon.queryHasRecords()` should be the database handle (`dbHandle`), not
// the query handle (`query`), so the correct condition for the while-loop
// should be
//
// myAddon.queryHasRecords(dbHandle, queryHandle)
//
while (myAddon.queryHasRecords(queryHandle, dbHandle)) {
  // retrieve records
} copy
In the above example myAddon.queryHasRecords() is a method that accepts two
arguments. The first is a database handle and the second is a query handle.
Internally, it unwraps the first argument and casts the resulting pointer to a
native database handle. It then unwraps the second argument and casts the
resulting pointer to a query handle. If the arguments are passed in the wrong
order, the casts will work, however, there is a good chance that the underlying
database operation will fail, or will even cause an invalid memory access.
To ensure that the pointer retrieved from the first argument is indeed a pointer
to a database handle and, similarly, that the pointer retrieved from the second
argument is indeed a pointer to a query handle, the implementation of
queryHasRecords() has to perform a type validation. Retaining the JavaScript
class constructor from which the database handle was instantiated and the
constructor from which the query handle was instantiated in napi_refs can
help, because napi_instanceof() can then be used to ensure that the instances
passed into queryHashRecords() are indeed of the correct type.
Unfortunately, napi_instanceof() does not protect against prototype
manipulation. For example, the prototype of the database handle instance can be
set to the prototype of the constructor for query handle instances. In this
case, the database handle instance can appear as a query handle instance, and it
will pass the napi_instanceof() test for a query handle instance, while still
containing a pointer to a database handle.
To this end, Node-API provides type-tagging capabilities.
A type tag is a 128-bit integer unique to the addon. Node-API provides the
napi_type_tag structure for storing a type tag. When such a value is passed
along with a JavaScript object or external stored in a napi_value to
napi_type_tag_object(), the JavaScript object will be "marked" with the
type tag. The "mark" is invisible on the JavaScript side. When a JavaScript
object arrives into a native binding, napi_check_object_type_tag() can be used
along with the original type tag to determine whether the JavaScript object was
previously "marked" with the type tag. This creates a type-checking capability
of a higher fidelity than napi_instanceof() can provide, because such type-
tagging survives prototype manipulation and addon unloading/reloading.
Continuing the above example, the following skeleton addon implementation
illustrates the use of napi_type_tag_object() and
napi_check_object_type_tag().
// This value is the type tag for a database handle. The command
//
//   uuidgen | sed -r -e 's/-//g' -e 's/(.{16})(.*)/0x\1, 0x\2/'
//
// can be used to obtain the two values with which to initialize the structure.
static const napi_type_tag DatabaseHandleTypeTag = {
  0x1edf75a38336451d, 0xa5ed9ce2e4c00c38
};

// This value is the type tag for a query handle.
static const napi_type_tag QueryHandleTypeTag = {
  0x9c73317f9fad44a3, 0x93c3920bf3b0ad6a
};

static napi_value
openDatabase(napi_env env, napi_callback_info info) {
  napi_status status;
  napi_value result;

  // Perform the underlying action which results in a database handle.
  DatabaseHandle* dbHandle = open_database();

  // Create a new, empty JS object.
  status = napi_create_object(env, &result);
  if (status != napi_ok) return NULL;

  // Tag the object to indicate that it holds a pointer to a `DatabaseHandle`.
  status = napi_type_tag_object(env, result, &DatabaseHandleTypeTag);
  if (status != napi_ok) return NULL;

  // Store the pointer to the `DatabaseHandle` structure inside the JS object.
  status = napi_wrap(env, result, dbHandle, NULL, NULL, NULL);
  if (status != napi_ok) return NULL;

  return result;
}

// Later when we receive a JavaScript object purporting to be a database handle
// we can use `napi_check_object_type_tag()` to ensure that it is indeed such a
// handle.

static napi_value
query(napi_env env, napi_callback_info info) {
  napi_status status;
  size_t argc = 2;
  napi_value argv[2];
  bool is_db_handle;

  status = napi_get_cb_info(env, info, &argc, argv, NULL, NULL);
  if (status != napi_ok) return NULL;

  // Check that the object passed as the first parameter has the previously
  // applied tag.
  status = napi_check_object_type_tag(env,
                                      argv[0],
                                      &DatabaseHandleTypeTag,
                                      &is_db_handle);
  if (status != napi_ok) return NULL;

  // Throw a `TypeError` if it doesn't.
  if (!is_db_handle) {
    // Throw a TypeError.
    return NULL;
  }
} copy

napi_define_class#

Added in: v8.0.0
N-API version: 1

napi_status napi_define_class(napi_env env,
                              const char* utf8name,
                              size_t length,
                              napi_callback constructor,
                              void* data,
                              size_t property_count,
                              const napi_property_descriptor* properties,
                              napi_value* result); copy

[in] env: The environment that the API is invoked under.
[in] utf8name: Name of the JavaScript constructor function. For clarity,
it is recommended to use the C++ class name when wrapping a C++ class.
[in] length: The length of the utf8name in bytes, or NAPI_AUTO_LENGTH
if it is null-terminated.
[in] constructor: Callback function that handles constructing instances
of the class. When wrapping a C++ class, this method must be a static member
with the napi_callback signature. A C++ class constructor cannot be
used. napi_callback provides more details.
[in] data: Optional data to be passed to the constructor callback as
the data property of the callback info.
[in] property_count: Number of items in the properties array argument.
[in] properties: Array of property descriptors describing static and
instance data properties, accessors, and methods on the class
See napi_property_descriptor.
[out] result: A napi_value representing the constructor function for
the class.

Returns napi_ok if the API succeeded.
Defines a JavaScript class, including:

A JavaScript constructor function that has the class name. When wrapping a
corresponding C++ class, the callback passed via constructor can be used to
instantiate a new C++ class instance, which can then be placed inside the
JavaScript object instance being constructed using napi_wrap.
Properties on the constructor function whose implementation can call
corresponding static data properties, accessors, and methods of the C++
class (defined by property descriptors with the napi_static attribute).
Properties on the constructor function's prototype object. When wrapping a
C++ class, non-static data properties, accessors, and methods of the C++
class can be called from the static functions given in the property
descriptors without the napi_static attribute after retrieving the C++ class
instance placed inside the JavaScript object instance by using
napi_unwrap.

When wrapping a C++ class, the C++ constructor callback passed via constructor
should be a static method on the class that calls the actual class constructor,
then wraps the new C++ instance in a JavaScript object, and returns the wrapper
object. See napi_wrap for details.
The JavaScript constructor function returned from napi_define_class is
often saved and used later to construct new instances of the class from native
code, and/or to check whether provided values are instances of the class. In
that case, to prevent the function value from being garbage-collected, a
strong persistent reference to it can be created using
napi_create_reference, ensuring that the reference count is kept >= 1.
Any non-NULL data which is passed to this API via the data parameter or via
the data field of the napi_property_descriptor array items can be associated
with the resulting JavaScript constructor (which is returned in the result
parameter) and freed whenever the class is garbage-collected by passing both
the JavaScript function and the data to napi_add_finalizer.

napi_wrap#

Added in: v8.0.0
N-API version: 1

napi_status napi_wrap(napi_env env,
                      napi_value js_object,
                      void* native_object,
                      napi_finalize finalize_cb,
                      void* finalize_hint,
                      napi_ref* result); copy

[in] env: The environment that the API is invoked under.
[in] js_object: The JavaScript object that will be the wrapper for the
native object.
[in] native_object: The native instance that will be wrapped in the
JavaScript object.
[in] finalize_cb: Optional native callback that can be used to free the
native instance when the JavaScript object has been garbage-collected.
napi_finalize provides more details.
[in] finalize_hint: Optional contextual hint that is passed to the
finalize callback.
[out] result: Optional reference to the wrapped object.

Returns napi_ok if the API succeeded.
Wraps a native instance in a JavaScript object. The native instance can be
retrieved later using napi_unwrap().
When JavaScript code invokes a constructor for a class that was defined using
napi_define_class(), the napi_callback for the constructor is invoked.
After constructing an instance of the native class, the callback must then call
napi_wrap() to wrap the newly constructed instance in the already-created
JavaScript object that is the this argument to the constructor callback.
(That this object was created from the constructor function's prototype,
so it already has definitions of all the instance properties and methods.)
Typically when wrapping a class instance, a finalize callback should be
provided that simply deletes the native instance that is received as the data
argument to the finalize callback.
The optional returned reference is initially a weak reference, meaning it
has a reference count of 0. Typically this reference count would be incremented
temporarily during async operations that require the instance to remain valid.
Caution: The optional returned reference (if obtained) should be deleted via
napi_delete_reference ONLY in response to the finalize callback
invocation. If it is deleted before then, then the finalize callback may never
be invoked. Therefore, when obtaining a reference a finalize callback is also
required in order to enable correct disposal of the reference.
Finalizer callbacks may be deferred, leaving a window where the object has
been garbage collected (and the weak reference is invalid) but the finalizer
hasn't been called yet. When using napi_get_reference_value() on weak
references returned by napi_wrap(), you should still handle an empty result.
Calling napi_wrap() a second time on an object will return an error. To
associate another native instance with the object, use napi_remove_wrap()
first.

napi_unwrap#

Added in: v8.0.0
N-API version: 1

napi_status napi_unwrap(napi_env env,
                        napi_value js_object,
                        void** result); copy

[in] env: The environment that the API is invoked under.
[in] js_object: The object associated with the native instance.
[out] result: Pointer to the wrapped native instance.

Returns napi_ok if the API succeeded.
Retrieves a native instance that was previously wrapped in a JavaScript
object using napi_wrap().
When JavaScript code invokes a method or property accessor on the class, the
corresponding napi_callback is invoked. If the callback is for an instance
method or accessor, then the this argument to the callback is the wrapper
object; the wrapped C++ instance that is the target of the call can be obtained
then by calling napi_unwrap() on the wrapper object.

napi_remove_wrap#

Added in: v8.5.0
N-API version: 1

napi_status napi_remove_wrap(napi_env env,
                             napi_value js_object,
                             void** result); copy

[in] env: The environment that the API is invoked under.
[in] js_object: The object associated with the native instance.
[out] result: Pointer to the wrapped native instance.

Returns napi_ok if the API succeeded.
Retrieves a native instance that was previously wrapped in the JavaScript
object js_object using napi_wrap() and removes the wrapping. If a finalize
callback was associated with the wrapping, it will no longer be called when the
JavaScript object becomes garbage-collected.

napi_type_tag_object#

Added in: v14.8.0, v12.19.0
N-API version: 8

napi_status napi_type_tag_object(napi_env env,
                                 napi_value js_object,
                                 const napi_type_tag* type_tag); copy

[in] env: The environment that the API is invoked under.
[in] js_object: The JavaScript object or external to be marked.
[in] type_tag: The tag with which the object is to be marked.

Returns napi_ok if the API succeeded.
Associates the value of the type_tag pointer with the JavaScript object or
external. napi_check_object_type_tag() can then be used to compare the tag
that was attached to the object with one owned by the addon to ensure that the
object has the right type.
If the object already has an associated type tag, this API will return
napi_invalid_arg.

napi_check_object_type_tag#

Added in: v14.8.0, v12.19.0
N-API version: 8

napi_status napi_check_object_type_tag(napi_env env,
                                       napi_value js_object,
                                       const napi_type_tag* type_tag,
                                       bool* result); copy

[in] env: The environment that the API is invoked under.
[in] js_object: The JavaScript object or external whose type tag to
examine.
[in] type_tag: The tag with which to compare any tag found on the object.
[out] result: Whether the type tag given matched the type tag on the
object. false is also returned if no type tag was found on the object.

Returns napi_ok if the API succeeded.
Compares the pointer given as type_tag with any that can be found on
js_object. If no tag is found on js_object or, if a tag is found but it does
not match type_tag, then result is set to false. If a tag is found and it
matches type_tag, then result is set to true.

napi_add_finalizer#

Added in: v8.0.0
N-API version: 5

napi_status napi_add_finalizer(napi_env env,
                               napi_value js_object,
                               void* finalize_data,
                               node_api_basic_finalize finalize_cb,
                               void* finalize_hint,
                               napi_ref* result); copy

[in] env: The environment that the API is invoked under.
[in] js_object: The JavaScript object to which the native data will be
attached.
[in] finalize_data: Optional data to be passed to finalize_cb.
[in] finalize_cb: Native callback that will be used to free the
native data when the JavaScript object has been garbage-collected.
napi_finalize provides more details.
[in] finalize_hint: Optional contextual hint that is passed to the
finalize callback.
[out] result: Optional reference to the JavaScript object.

Returns napi_ok if the API succeeded.
Adds a napi_finalize callback which will be called when the JavaScript object
in js_object has been garbage-collected.
This API can be called multiple times on a single JavaScript object.
Caution: The optional returned reference (if obtained) should be deleted via
napi_delete_reference ONLY in response to the finalize callback
invocation. If it is deleted before then, then the finalize callback may never
be invoked. Therefore, when obtaining a reference a finalize callback is also
required in order to enable correct disposal of the reference.

node_api_post_finalizer#

Added in: v21.0.0, v20.10.0, v18.19.0

Stability: 1 - Experimental
napi_status node_api_post_finalizer(node_api_basic_env env,
                                    napi_finalize finalize_cb,
                                    void* finalize_data,
                                    void* finalize_hint); copy

[in] env: The environment that the API is invoked under.
[in] finalize_cb: Native callback that will be used to free the
native data when the JavaScript object has been garbage-collected.
napi_finalize provides more details.
[in] finalize_data: Optional data to be passed to finalize_cb.
[in] finalize_hint: Optional contextual hint that is passed to the
finalize callback.

Returns napi_ok if the API succeeded.
Schedules a napi_finalize callback to be called asynchronously in the
event loop.
Normally, finalizers are called while the GC (garbage collector) collects
objects. At that point calling any Node-API that may cause changes in the GC
state will be disabled and will crash Node.js.
node_api_post_finalizer helps to work around this limitation by allowing the
add-on to defer calls to such Node-APIs to a point in time outside of the GC
finalization.

Simple asynchronous operations#
Addon modules often need to leverage async helpers from libuv as part of their
implementation. This allows them to schedule work to be executed asynchronously
so that their methods can return in advance of the work being completed. This
allows them to avoid blocking overall execution of the Node.js application.
Node-API provides an ABI-stable interface for these
supporting functions which covers the most common asynchronous use cases.
Node-API defines the napi_async_work structure which is used to manage
asynchronous workers. Instances are created/deleted with
napi_create_async_work and napi_delete_async_work.
The execute and complete callbacks are functions that will be
invoked when the executor is ready to execute and when it completes its
task respectively.
The execute function should avoid making any Node-API calls
that could result in the execution of JavaScript or interaction with
JavaScript objects. Most often, any code that needs to make Node-API
calls should be made in complete callback instead.
Avoid using the napi_env parameter in the execute callback as
it will likely execute JavaScript.
These functions implement the following interfaces:
typedef void (*napi_async_execute_callback)(napi_env env,
                                            void* data);
typedef void (*napi_async_complete_callback)(napi_env env,
                                             napi_status status,
                                             void* data); copy
When these methods are invoked, the data parameter passed will be the
addon-provided void* data that was passed into the
napi_create_async_work call.
Once created the async worker can be queued
for execution using the napi_queue_async_work function:
napi_status napi_queue_async_work(node_api_basic_env env,
                                  napi_async_work work); copy
napi_cancel_async_work can be used if the work needs
to be cancelled before the work has started execution.
After calling napi_cancel_async_work, the complete callback
will be invoked with a status value of napi_cancelled.
The work should not be deleted before the complete
callback invocation, even when it was cancelled.

napi_create_async_work#

History

VersionChanges
v8.6.0
Added async_resource and async_resource_name parameters.
v8.0.0
Added in: v8.0.0


N-API version: 1

napi_status napi_create_async_work(napi_env env,
                                   napi_value async_resource,
                                   napi_value async_resource_name,
                                   napi_async_execute_callback execute,
                                   napi_async_complete_callback complete,
                                   void* data,
                                   napi_async_work* result); copy

[in] env: The environment that the API is invoked under.
[in] async_resource: An optional object associated with the async work
that will be passed to possible async_hooks init hooks.
[in] async_resource_name: Identifier for the kind of resource that is being
provided for diagnostic information exposed by the async_hooks API.
[in] execute: The native function which should be called to execute the
logic asynchronously. The given function is called from a worker pool thread
and can execute in parallel with the main event loop thread.
[in] complete: The native function which will be called when the
asynchronous logic is completed or is cancelled. The given function is called
from the main event loop thread. napi_async_complete_callback provides
more details.
[in] data: User-provided data context. This will be passed back into the
execute and complete functions.
[out] result: napi_async_work* which is the handle to the newly created
async work.

Returns napi_ok if the API succeeded.
This API allocates a work object that is used to execute logic asynchronously.
It should be freed using napi_delete_async_work once the work is no longer
required.
async_resource_name should be a null-terminated, UTF-8-encoded string.
The async_resource_name identifier is provided by the user and should be
representative of the type of async work being performed. It is also recommended
to apply namespacing to the identifier, e.g. by including the module name. See
the async_hooks documentation for more information.

napi_delete_async_work#

Added in: v8.0.0
N-API version: 1

napi_status napi_delete_async_work(napi_env env,
                                   napi_async_work work); copy

[in] env: The environment that the API is invoked under.
[in] work: The handle returned by the call to napi_create_async_work.

Returns napi_ok if the API succeeded.
This API frees a previously allocated work object.
This API can be called even if there is a pending JavaScript exception.

napi_queue_async_work#

Added in: v8.0.0
N-API version: 1

napi_status napi_queue_async_work(node_api_basic_env env,
                                  napi_async_work work); copy

[in] env: The environment that the API is invoked under.
[in] work: The handle returned by the call to napi_create_async_work.

Returns napi_ok if the API succeeded.
This API requests that the previously allocated work be scheduled
for execution. Once it returns successfully, this API must not be called again
with the same napi_async_work item or the result will be undefined.

napi_cancel_async_work#

Added in: v8.0.0
N-API version: 1

napi_status napi_cancel_async_work(node_api_basic_env env,
                                   napi_async_work work); copy

[in] env: The environment that the API is invoked under.
[in] work: The handle returned by the call to napi_create_async_work.

Returns napi_ok if the API succeeded.
This API cancels queued work if it has not yet
been started. If it has already started executing, it cannot be
cancelled and napi_generic_failure will be returned. If successful,
the complete callback will be invoked with a status value of
napi_cancelled. The work should not be deleted before the complete
callback invocation, even if it has been successfully cancelled.
This API can be called even if there is a pending JavaScript exception.

Custom asynchronous operations#
The simple asynchronous work APIs above may not be appropriate for every
scenario. When using any other asynchronous mechanism, the following APIs
are necessary to ensure an asynchronous operation is properly tracked by
the runtime.

napi_async_init#

Added in: v8.6.0
N-API version: 1

napi_status napi_async_init(napi_env env,
                            napi_value async_resource,
                            napi_value async_resource_name,
                            napi_async_context* result) copy

[in] env: The environment that the API is invoked under.
[in] async_resource: Object associated with the async work
that will be passed to possible async_hooks init hooks and can be
accessed by async_hooks.executionAsyncResource().
[in] async_resource_name: Identifier for the kind of resource that is being
provided for diagnostic information exposed by the async_hooks API.
[out] result: The initialized async context.

Returns napi_ok if the API succeeded.
The async_resource object needs to be kept alive until
napi_async_destroy to keep async_hooks related API acts correctly. In
order to retain ABI compatibility with previous versions, napi_async_contexts
are not maintaining the strong reference to the async_resource objects to
avoid introducing causing memory leaks. However, if the async_resource is
garbage collected by JavaScript engine before the napi_async_context was
destroyed by napi_async_destroy, calling napi_async_context related APIs
like napi_open_callback_scope and napi_make_callback can cause
problems like loss of async context when using the AsyncLocalStorage API.
In order to retain ABI compatibility with previous versions, passing NULL
for async_resource does not result in an error. However, this is not
recommended as this will result in undesirable behavior with  async_hooks
init hooks and async_hooks.executionAsyncResource() as the resource is
now required by the underlying async_hooks implementation in order to provide
the linkage between async callbacks.

napi_async_destroy#

Added in: v8.6.0
N-API version: 1

napi_status napi_async_destroy(napi_env env,
                               napi_async_context async_context); copy

[in] env: The environment that the API is invoked under.
[in] async_context: The async context to be destroyed.

Returns napi_ok if the API succeeded.
This API can be called even if there is a pending JavaScript exception.

napi_make_callback#

History

VersionChanges
v8.6.0
Added async_context parameter.
v8.0.0
Added in: v8.0.0


N-API version: 1

NAPI_EXTERN napi_status napi_make_callback(napi_env env,
                                           napi_async_context async_context,
                                           napi_value recv,
                                           napi_value func,
                                           size_t argc,
                                           const napi_value* argv,
                                           napi_value* result); copy

[in] env: The environment that the API is invoked under.
[in] async_context: Context for the async operation that is
invoking the callback. This should normally be a value previously
obtained from napi_async_init.
In order to retain ABI compatibility with previous versions, passing NULL
for async_context does not result in an error. However, this results
in incorrect operation of async hooks. Potential issues include loss of
async context when using the AsyncLocalStorage API.
[in] recv: The this value passed to the called function.
[in] func: napi_value representing the JavaScript function to be invoked.
[in] argc: The count of elements in the argv array.
[in] argv: Array of JavaScript values as napi_value representing the
arguments to the function. If argc is zero this parameter may be
omitted by passing in NULL.
[out] result: napi_value representing the JavaScript object returned.

Returns napi_ok if the API succeeded.
This method allows a JavaScript function object to be called from a native
add-on. This API is similar to napi_call_function. However, it is used to call
from native code back into JavaScript after returning from an async
operation (when there is no other script on the stack). It is a fairly simple
wrapper around node::MakeCallback.
Note it is not necessary to use napi_make_callback from within a
napi_async_complete_callback; in that situation the callback's async
context has already been set up, so a direct call to napi_call_function
is sufficient and appropriate. Use of the napi_make_callback function
may be required when implementing custom async behavior that does not use
napi_create_async_work.
Any process.nextTicks or Promises scheduled on the microtask queue by
JavaScript during the callback are ran before returning back to C/C++.

napi_open_callback_scope#

Added in: v9.6.0
N-API version: 3

NAPI_EXTERN napi_status napi_open_callback_scope(napi_env env,
                                                 napi_value resource_object,
                                                 napi_async_context context,
                                                 napi_callback_scope* result) copy

[in] env: The environment that the API is invoked under.
[in] resource_object: An object associated with the async work
that will be passed to possible async_hooks init hooks. This
parameter has been deprecated and is ignored at runtime. Use the
async_resource parameter in napi_async_init instead.
[in] context: Context for the async operation that is invoking the callback.
This should be a value previously obtained from napi_async_init.
[out] result: The newly created scope.

There are cases (for example, resolving promises) where it is
necessary to have the equivalent of the scope associated with a callback
in place when making certain Node-API calls. If there is no other script on
the stack the napi_open_callback_scope and
napi_close_callback_scope functions can be used to open/close
the required scope.

napi_close_callback_scope#

Added in: v9.6.0
N-API version: 3

NAPI_EXTERN napi_status napi_close_callback_scope(napi_env env,
                                                  napi_callback_scope scope) copy

[in] env: The environment that the API is invoked under.
[in] scope: The scope to be closed.

This API can be called even if there is a pending JavaScript exception.

Version management#

napi_get_node_version#

Added in: v8.4.0
N-API version: 1

typedef struct {
  uint32_t major;
  uint32_t minor;
  uint32_t patch;
  const char* release;
} napi_node_version;

napi_status napi_get_node_version(node_api_basic_env env,
                                  const napi_node_version** version); copy

[in] env: The environment that the API is invoked under.
[out] version: A pointer to version information for Node.js itself.

Returns napi_ok if the API succeeded.
This function fills the version struct with the major, minor, and patch
version of Node.js that is currently running, and the release field with the
value of process.release.name.
The returned buffer is statically allocated and does not need to be freed.

napi_get_version#

Added in: v8.0.0
N-API version: 1

napi_status napi_get_version(node_api_basic_env env,
                             uint32_t* result); copy

[in] env: The environment that the API is invoked under.
[out] result: The highest version of Node-API supported.

Returns napi_ok if the API succeeded.
This API returns the highest Node-API version supported by the
Node.js runtime. Node-API is planned to be additive such that
newer releases of Node.js may support additional API functions.
In order to allow an addon to use a newer function when running with
versions of Node.js that support it, while providing
fallback behavior when running with Node.js versions that don't
support it:

Call napi_get_version() to determine if the API is available.
If available, dynamically load a pointer to the function using uv_dlsym().
Use the dynamically loaded pointer to invoke the function.
If the function is not available, provide an alternate implementation
that does not use the function.


Memory management#

napi_adjust_external_memory#

Added in: v8.5.0
N-API version: 1

NAPI_EXTERN napi_status napi_adjust_external_memory(node_api_basic_env env,
                                                    int64_t change_in_bytes,
                                                    int64_t* result); copy

[in] env: The environment that the API is invoked under.
[in] change_in_bytes: The change in externally allocated memory that is kept
alive by JavaScript objects.
[out] result: The adjusted value. This value should reflect the
total amount of external memory with the given change_in_bytes included.
The absolute value of the returned value should not  be depended on.
For example, implementations may use a single counter for all addons, or a
counter for each addon.

Returns napi_ok if the API succeeded.
This function gives the runtime an indication of the amount of externally
allocated memory that is kept alive by JavaScript objects
(i.e. a JavaScript object that points to its own memory allocated by a
native addon). Registering externally allocated memory may, but is not
guaranteed to, trigger global garbage collections more
often than it would otherwise.
This function is expected to be called in a manner such that an
addon does not decrease the external memory more than it has
increased the external memory.

Promises#
Node-API provides facilities for creating Promise objects as described in
Section 25.4 of the ECMA specification. It implements promises as a pair of
objects. When a promise is created by napi_create_promise(), a "deferred"
object is created and returned alongside the Promise. The deferred object is
bound to the created Promise and is the only means to resolve or reject the
Promise using napi_resolve_deferred() or napi_reject_deferred(). The
deferred object that is created by napi_create_promise() is freed by
napi_resolve_deferred() or napi_reject_deferred(). The Promise object may
be returned to JavaScript where it can be used in the usual fashion.
For example, to create a promise and pass it to an asynchronous worker:
napi_deferred deferred;
napi_value promise;
napi_status status;

// Create the promise.
status = napi_create_promise(env, &deferred, &promise);
if (status != napi_ok) return NULL;

// Pass the deferred to a function that performs an asynchronous action.
do_something_asynchronous(deferred);

// Return the promise to JS
return promise; copy
The above function do_something_asynchronous() would perform its asynchronous
action and then it would resolve or reject the deferred, thereby concluding the
promise and freeing the deferred:
napi_deferred deferred;
napi_value undefined;
napi_status status;

// Create a value with which to conclude the deferred.
status = napi_get_undefined(env, &undefined);
if (status != napi_ok) return NULL;

// Resolve or reject the promise associated with the deferred depending on
// whether the asynchronous action succeeded.
if (asynchronous_action_succeeded) {
  status = napi_resolve_deferred(env, deferred, undefined);
} else {
  status = napi_reject_deferred(env, deferred, undefined);
}
if (status != napi_ok) return NULL;

// At this point the deferred has been freed, so we should assign NULL to it.
deferred = NULL; copy

napi_create_promise#

Added in: v8.5.0
N-API version: 1

napi_status napi_create_promise(napi_env env,
                                napi_deferred* deferred,
                                napi_value* promise); copy

[in] env: The environment that the API is invoked under.
[out] deferred: A newly created deferred object which can later be passed to
napi_resolve_deferred() or napi_reject_deferred() to resolve resp. reject
the associated promise.
[out] promise: The JavaScript promise associated with the deferred object.

Returns napi_ok if the API succeeded.
This API creates a deferred object and a JavaScript promise.

napi_resolve_deferred#

Added in: v8.5.0
N-API version: 1

napi_status napi_resolve_deferred(napi_env env,
                                  napi_deferred deferred,
                                  napi_value resolution); copy

[in] env: The environment that the API is invoked under.
[in] deferred: The deferred object whose associated promise to resolve.
[in] resolution: The value with which to resolve the promise.

This API resolves a JavaScript promise by way of the deferred object
with which it is associated. Thus, it can only be used to resolve JavaScript
promises for which the corresponding deferred object is available. This
effectively means that the promise must have been created using
napi_create_promise() and the deferred object returned from that call must
have been retained in order to be passed to this API.
The deferred object is freed upon successful completion.

napi_reject_deferred#

Added in: v8.5.0
N-API version: 1

napi_status napi_reject_deferred(napi_env env,
                                 napi_deferred deferred,
                                 napi_value rejection); copy

[in] env: The environment that the API is invoked under.
[in] deferred: The deferred object whose associated promise to resolve.
[in] rejection: The value with which to reject the promise.

This API rejects a JavaScript promise by way of the deferred object
with which it is associated. Thus, it can only be used to reject JavaScript
promises for which the corresponding deferred object is available. This
effectively means that the promise must have been created using
napi_create_promise() and the deferred object returned from that call must
have been retained in order to be passed to this API.
The deferred object is freed upon successful completion.

napi_is_promise#

Added in: v8.5.0
N-API version: 1

napi_status napi_is_promise(napi_env env,
                            napi_value value,
                            bool* is_promise); copy

[in] env: The environment that the API is invoked under.
[in] value: The value to examine
[out] is_promise: Flag indicating whether promise is a native promise
object (that is, a promise object created by the underlying engine).


Script execution#
Node-API provides an API for executing a string containing JavaScript using the
underlying JavaScript engine.

napi_run_script#

Added in: v8.5.0
N-API version: 1

NAPI_EXTERN napi_status napi_run_script(napi_env env,
                                        napi_value script,
                                        napi_value* result); copy

[in] env: The environment that the API is invoked under.
[in] script: A JavaScript string containing the script to execute.
[out] result: The value resulting from having executed the script.

This function executes a string of JavaScript code and returns its result with
the following caveats:

Unlike eval, this function does not allow the script to access the current
lexical scope, and therefore also does not allow to access the
module scope, meaning that pseudo-globals such as require will not be
available.
The script can access the global scope. Function and var declarations
in the script will be added to the global object. Variable declarations
made using let and const will be visible globally, but will not be added
to the global object.
The value of this is global within the script.


libuv event loop#
Node-API provides a function for getting the current event loop associated with
a specific napi_env.

napi_get_uv_event_loop#

Added in: v9.3.0, v8.10.0
N-API version: 2

NAPI_EXTERN napi_status napi_get_uv_event_loop(node_api_basic_env env,
                                               struct uv_loop_s** loop); copy

[in] env: The environment that the API is invoked under.
[out] loop: The current libuv loop instance.

Note: While libuv has been relatively stable over time, it does
not provide an ABI stability guarantee. Use of this function should be avoided.
Its use may result in an addon that does not work across Node.js versions.
asynchronous-thread-safe-function-calls
are an alternative for many use cases.

Asynchronous thread-safe function calls#
JavaScript functions can normally only be called from a native addon's main
thread. If an addon creates additional threads, then Node-API functions that
require a napi_env, napi_value, or napi_ref must not be called from those
threads.
When an addon has additional threads and JavaScript functions need to be invoked
based on the processing completed by those threads, those threads must
communicate with the addon's main thread so that the main thread can invoke the
JavaScript function on their behalf. The thread-safe function APIs provide an
easy way to do this.
These APIs provide the type napi_threadsafe_function as well as APIs to
create, destroy, and call objects of this type.
napi_create_threadsafe_function() creates a persistent reference to a
napi_value that holds a JavaScript function which can be called from multiple
threads. The calls happen asynchronously. This means that values with which the
JavaScript callback is to be called will be placed in a queue, and, for each
value in the queue, a call will eventually be made to the JavaScript function.
Upon creation of a napi_threadsafe_function a napi_finalize callback can be
provided. This callback will be invoked on the main thread when the thread-safe
function is about to be destroyed. It receives the context and the finalize data
given during construction, and provides an opportunity for cleaning up after the
threads e.g. by calling uv_thread_join(). Aside from the main loop thread,
no threads should be using the thread-safe function after the finalize callback
completes.
The context given during the call to napi_create_threadsafe_function() can
be retrieved from any thread with a call to
napi_get_threadsafe_function_context().

Calling a thread-safe function#
napi_call_threadsafe_function() can be used for initiating a call into
JavaScript. napi_call_threadsafe_function() accepts a parameter which controls
whether the API behaves blockingly. If set to napi_tsfn_nonblocking, the API
behaves non-blockingly, returning napi_queue_full if the queue was full,
preventing data from being successfully added to the queue. If set to
napi_tsfn_blocking, the API blocks until space becomes available in the queue.
napi_call_threadsafe_function() never blocks if the thread-safe function was
created with a maximum queue size of 0.
napi_call_threadsafe_function() should not be called with napi_tsfn_blocking
from a JavaScript thread, because, if the queue is full, it may cause the
JavaScript thread to deadlock.
The actual call into JavaScript is controlled by the callback given via the
call_js_cb parameter. call_js_cb is invoked on the main thread once for each
value that was placed into the queue by a successful call to
napi_call_threadsafe_function(). If such a callback is not given, a default
callback will be used, and the resulting JavaScript call will have no arguments.
The call_js_cb callback receives the JavaScript function to call as a
napi_value in its parameters, as well as the void* context pointer used when
creating the napi_threadsafe_function, and the next data pointer that was
created by one of the secondary threads. The callback can then use an API such
as napi_call_function() to call into JavaScript.
The callback may also be invoked with env and call_js_cb both set to NULL
to indicate that calls into JavaScript are no longer possible, while items
remain in the queue that may need to be freed. This normally occurs when the
Node.js process exits while there is a thread-safe function still active.
It is not necessary to call into JavaScript via napi_make_callback() because
Node-API runs call_js_cb in a context appropriate for callbacks.
Zero or more queued items may be invoked in each tick of the event loop.
Applications should not depend on a specific behavior other than progress in
invoking callbacks will be made and events will be invoked
as time moves forward.

Reference counting of thread-safe functions#
Threads can be added to and removed from a napi_threadsafe_function object
during its existence. Thus, in addition to specifying an initial number of
threads upon creation, napi_acquire_threadsafe_function can be called to
indicate that a new thread will start making use of the thread-safe function.
Similarly, napi_release_threadsafe_function can be called to indicate that an
existing thread will stop making use of the thread-safe function.
napi_threadsafe_function objects are destroyed when every thread which uses
the object has called napi_release_threadsafe_function() or has received a
return status of napi_closing in response to a call to
napi_call_threadsafe_function. The queue is emptied before the
napi_threadsafe_function is destroyed. napi_release_threadsafe_function()
should be the last API call made in conjunction with a given
napi_threadsafe_function, because after the call completes, there is no
guarantee that the napi_threadsafe_function is still allocated. For the same
reason, do not use a thread-safe function
after receiving a return value of napi_closing in response to a call to
napi_call_threadsafe_function. Data associated with the
napi_threadsafe_function can be freed in its napi_finalize callback which
was passed to napi_create_threadsafe_function(). The parameter
initial_thread_count of napi_create_threadsafe_function marks the initial
number of acquisitions of the thread-safe functions, instead of calling
napi_acquire_threadsafe_function multiple times at creation.
Once the number of threads making use of a napi_threadsafe_function reaches
zero, no further threads can start making use of it by calling
napi_acquire_threadsafe_function(). In fact, all subsequent API calls
associated with it, except napi_release_threadsafe_function(), will return an
error value of napi_closing.
The thread-safe function can be "aborted" by giving a value of napi_tsfn_abort
to napi_release_threadsafe_function(). This will cause all subsequent APIs
associated with the thread-safe function except
napi_release_threadsafe_function() to return napi_closing even before its
reference count reaches zero. In particular, napi_call_threadsafe_function()
will return napi_closing, thus informing the threads that it is no longer
possible to make asynchronous calls to the thread-safe function. This can be
used as a criterion for terminating the thread. Upon receiving a return value
of napi_closing from napi_call_threadsafe_function() a thread must not use
the thread-safe function anymore because it is no longer guaranteed to
be allocated.

Deciding whether to keep the process running#
Similarly to libuv handles, thread-safe functions can be "referenced" and
"unreferenced". A "referenced" thread-safe function will cause the event loop on
the thread on which it is created to remain alive until the thread-safe function
is destroyed. In contrast, an "unreferenced" thread-safe function will not
prevent the event loop from exiting. The APIs napi_ref_threadsafe_function and
napi_unref_threadsafe_function exist for this purpose.
Neither does napi_unref_threadsafe_function mark the thread-safe functions as
able to be destroyed nor does napi_ref_threadsafe_function prevent it from
being destroyed.

napi_create_threadsafe_function#

History

VersionChanges
v12.6.0, v10.17.0
Made func parameter optional with custom call_js_cb.
v10.6.0
Added in: v10.6.0


N-API version: 4

NAPI_EXTERN napi_status
napi_create_threadsafe_function(napi_env env,
                                napi_value func,
                                napi_value async_resource,
                                napi_value async_resource_name,
                                size_t max_queue_size,
                                size_t initial_thread_count,
                                void* thread_finalize_data,
                                napi_finalize thread_finalize_cb,
                                void* context,
                                napi_threadsafe_function_call_js call_js_cb,
                                napi_threadsafe_function* result); copy

[in] env: The environment that the API is invoked under.
[in] func: An optional JavaScript function to call from another thread. It
must be provided if NULL is passed to call_js_cb.
[in] async_resource: An optional object associated with the async work that
will be passed to possible async_hooks init hooks.
[in] async_resource_name: A JavaScript string to provide an identifier for
the kind of resource that is being provided for diagnostic information exposed
by the async_hooks API.
[in] max_queue_size: Maximum size of the queue. 0 for no limit.
[in] initial_thread_count: The initial number of acquisitions, i.e. the
initial number of threads, including the main thread, which will be making use
of this function.
[in] thread_finalize_data: Optional data to be passed to thread_finalize_cb.
[in] thread_finalize_cb: Optional function to call when the
napi_threadsafe_function is being destroyed.
[in] context: Optional data to attach to the resulting
napi_threadsafe_function.
[in] call_js_cb: Optional callback which calls the JavaScript function in
response to a call on a different thread. This callback will be called on the
main thread. If not given, the JavaScript function will be called with no
parameters and with undefined as its this value.
napi_threadsafe_function_call_js provides more details.
[out] result: The asynchronous thread-safe JavaScript function.

Change History:


Version 10 (NAPI_VERSION is defined as 10 or higher):
Uncaught exceptions thrown in call_js_cb are handled with the
'uncaughtException' event, instead of being ignored.



napi_get_threadsafe_function_context#

Added in: v10.6.0
N-API version: 4

NAPI_EXTERN napi_status
napi_get_threadsafe_function_context(napi_threadsafe_function func,
                                     void** result); copy

[in] func: The thread-safe function for which to retrieve the context.
[out] result: The location where to store the context.

This API may be called from any thread which makes use of func.

napi_call_threadsafe_function#

History

VersionChanges
v14.5.0
Support for napi_would_deadlock has been reverted.
v14.1.0
Return napi_would_deadlock when called with napi_tsfn_blocking from the main thread or a worker thread and the queue is full.
v10.6.0
Added in: v10.6.0


N-API version: 4

NAPI_EXTERN napi_status
napi_call_threadsafe_function(napi_threadsafe_function func,
                              void* data,
                              napi_threadsafe_function_call_mode is_blocking); copy

[in] func: The asynchronous thread-safe JavaScript function to invoke.
[in] data: Data to send into JavaScript via the callback call_js_cb
provided during the creation of the thread-safe JavaScript function.
[in] is_blocking: Flag whose value can be either napi_tsfn_blocking to
indicate that the call should block if the queue is full or
napi_tsfn_nonblocking to indicate that the call should return immediately
with a status of napi_queue_full whenever the queue is full.

This API should not be called with napi_tsfn_blocking from a JavaScript
thread, because, if the queue is full, it may cause the JavaScript thread to
deadlock.
This API will return napi_closing if napi_release_threadsafe_function() was
called with abort set to napi_tsfn_abort from any thread. The value is only
added to the queue if the API returns napi_ok.
This API may be called from any thread which makes use of func.

napi_acquire_threadsafe_function#

Added in: v10.6.0
N-API version: 4

NAPI_EXTERN napi_status
napi_acquire_threadsafe_function(napi_threadsafe_function func); copy

[in] func: The asynchronous thread-safe JavaScript function to start making
use of.

A thread should call this API before passing func to any other thread-safe
function APIs to indicate that it will be making use of func. This prevents
func from being destroyed when all other threads have stopped making use of
it.
This API may be called from any thread which will start making use of func.

napi_release_threadsafe_function#

Added in: v10.6.0
N-API version: 4

NAPI_EXTERN napi_status
napi_release_threadsafe_function(napi_threadsafe_function func,
                                 napi_threadsafe_function_release_mode mode); copy

[in] func: The asynchronous thread-safe JavaScript function whose reference
count to decrement.
[in] mode: Flag whose value can be either napi_tsfn_release to indicate
that the current thread will make no further calls to the thread-safe
function, or napi_tsfn_abort to indicate that in addition to the current
thread, no other thread should make any further calls to the thread-safe
function. If set to napi_tsfn_abort, further calls to
napi_call_threadsafe_function() will return napi_closing, and no further
values will be placed in the queue.

A thread should call this API when it stops making use of func. Passing func
to any thread-safe APIs after having called this API has undefined results, as
func may have been destroyed.
This API may be called from any thread which will stop making use of func.

napi_ref_threadsafe_function#

Added in: v10.6.0
N-API version: 4

NAPI_EXTERN napi_status
napi_ref_threadsafe_function(node_api_basic_env env, napi_threadsafe_function func); copy

[in] env: The environment that the API is invoked under.
[in] func: The thread-safe function to reference.

This API is used to indicate that the event loop running on the main thread
should not exit until func has been destroyed. Similar to uv_ref it is
also idempotent.
Neither does napi_unref_threadsafe_function mark the thread-safe functions as
able to be destroyed nor does napi_ref_threadsafe_function prevent it from
being destroyed. napi_acquire_threadsafe_function and
napi_release_threadsafe_function are available for that purpose.
This API may only be called from the main thread.

napi_unref_threadsafe_function#

Added in: v10.6.0
N-API version: 4

NAPI_EXTERN napi_status
napi_unref_threadsafe_function(node_api_basic_env env, napi_threadsafe_function func); copy

[in] env: The environment that the API is invoked under.
[in] func: The thread-safe function to unreference.

This API is used to indicate that the event loop running on the main thread
may exit before func is destroyed. Similar to uv_unref it is also
idempotent.
This API may only be called from the main thread.

Miscellaneous utilities#

node_api_get_module_file_name#

Added in: v15.9.0, v14.18.0, v12.22.0
N-API version: 9

NAPI_EXTERN napi_status
node_api_get_module_file_name(node_api_basic_env env, const char** result);
 copy

[in] env: The environment that the API is invoked under.
[out] result: A URL containing the absolute path of the
location from which the add-on was loaded. For a file on the local
file system it will start with file://. The string is null-terminated and
owned by env and must thus not be modified or freed.

result may be an empty string if the add-on loading process fails to establish
the add-on's file name during loading.\n\n\n\nNode.js
        
      
      
About this documentation
Usage and example



Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Modules: TypeScript
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
Readline
REPL
Report
Single executable applications
SQLite
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker

    

    
      
        
          Node.js v24.0.1 documentation
          
            
            
          
        
        
          
            Node.js v24.0.1
            
    
      
        
        Table of contents
      

      
C++ embedder API

Example embedding application

Setting up a per-process state
Setting up a per-instance state





    
  
            
    
      
        
        Index
      

      
About this documentation
Usage and example

      
        Index
      
    
  


Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Modules: TypeScript
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
Readline
REPL
Report
Single executable applications
SQLite
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker

    
  
            
    
      
        
        Other versions
      
      24.x
23.x
22.x LTS
21.x
20.x LTS
19.x
18.x
17.x
16.x
15.x
14.x
13.x
12.x
    
  
            
              
                
                Options
              
        
              
                
                  
                    View on single page
                  
                  
                    View as JSON
                  
                  Edit on GitHub    
                
              
            
          
        
        
      

      Table of contents
C++ embedder API

Example embedding application

Setting up a per-process state
Setting up a per-instance state






      
        C++ embedder API#

Node.js provides a number of C++ APIs that can be used to execute JavaScript
in a Node.js environment from other C++ software.
The documentation for these APIs can be found in src/node.h in the Node.js
source tree. In addition to the APIs exposed by Node.js, some required concepts
are provided by the V8 embedder API.
Because using Node.js as an embedded library is different from writing code
that is executed by Node.js, breaking changes do not follow typical Node.js
deprecation policy and may occur on each semver-major release without prior
warning.
Example embedding application#
The following sections will provide an overview over how to use these APIs
to create an application from scratch that will perform the equivalent of
node -e <code>, i.e. that will take a piece of JavaScript and run it in
a Node.js-specific environment.
The full code can be found in the Node.js source tree.

Setting up a per-process state#
Node.js requires some per-process state management in order to run:

Arguments parsing for Node.js CLI options,
V8 per-process requirements, such as a v8::Platform instance.

The following example shows how these can be set up. Some class names are from
the node and v8 C++ namespaces, respectively.
int main(int argc, char** argv) {
  argv = uv_setup_args(argc, argv);
  std::vector<std::string> args(argv, argv + argc);
  // Parse Node.js CLI options, and print any errors that have occurred while
  // trying to parse them.
  std::unique_ptr<node::InitializationResult> result =
      node::InitializeOncePerProcess(args, {
        node::ProcessInitializationFlags::kNoInitializeV8,
        node::ProcessInitializationFlags::kNoInitializeNodeV8Platform
      });

  for (const std::string& error : result->errors())
    fprintf(stderr, "%s: %s\n", args[0].c_str(), error.c_str());
  if (result->early_return() != 0) {
    return result->exit_code();
  }

  // Create a v8::Platform instance. `MultiIsolatePlatform::Create()` is a way
  // to create a v8::Platform instance that Node.js can use when creating
  // Worker threads. When no `MultiIsolatePlatform` instance is present,
  // Worker threads are disabled.
  std::unique_ptr<MultiIsolatePlatform> platform =
      MultiIsolatePlatform::Create(4);
  V8::InitializePlatform(platform.get());
  V8::Initialize();

  // See below for the contents of this function.
  int ret = RunNodeInstance(
      platform.get(), result->args(), result->exec_args());

  V8::Dispose();
  V8::DisposePlatform();

  node::TearDownOncePerProcess();
  return ret;
} copy

Setting up a per-instance state#

History

VersionChanges
v15.0.0
The CommonEnvironmentSetup and SpinEventLoop utilities were added.



Node.js has a concept of a “Node.js instance”, that is commonly being referred
to as node::Environment. Each node::Environment is associated with:

Exactly one v8::Isolate, i.e. one JS Engine instance,
Exactly one uv_loop_t, i.e. one event loop,
A number of v8::Contexts, but exactly one main v8::Context, and
One node::IsolateData instance that contains information that could be
shared by multiple node::Environments. The embedder should make sure
that node::IsolateData is shared only among node::Environments that
use the same v8::Isolate, Node.js does not perform this check.

In order to set up a v8::Isolate, an v8::ArrayBuffer::Allocator needs
to be provided. One possible choice is the default Node.js allocator, which
can be created through node::ArrayBufferAllocator::Create(). Using the Node.js
allocator allows minor performance optimizations when addons use the Node.js
C++ Buffer API, and is required in order to track ArrayBuffer memory in
process.memoryUsage().
Additionally, each v8::Isolate that is used for a Node.js instance needs to
be registered and unregistered with the MultiIsolatePlatform instance, if one
is being used, in order for the platform to know which event loop to use
for tasks scheduled by the v8::Isolate.
The node::NewIsolate() helper function creates a v8::Isolate,
sets it up with some Node.js-specific hooks (e.g. the Node.js error handler),
and registers it with the platform automatically.
int RunNodeInstance(MultiIsolatePlatform* platform,
                    const std::vector<std::string>& args,
                    const std::vector<std::string>& exec_args) {
  int exit_code = 0;

  // Setup up a libuv event loop, v8::Isolate, and Node.js Environment.
  std::vector<std::string> errors;
  std::unique_ptr<CommonEnvironmentSetup> setup =
      CommonEnvironmentSetup::Create(platform, &errors, args, exec_args);
  if (!setup) {
    for (const std::string& err : errors)
      fprintf(stderr, "%s: %s\n", args[0].c_str(), err.c_str());
    return 1;
  }

  Isolate* isolate = setup->isolate();
  Environment* env = setup->env();

  {
    Locker locker(isolate);
    Isolate::Scope isolate_scope(isolate);
    HandleScope handle_scope(isolate);
    // The v8::Context needs to be entered when node::CreateEnvironment() and
    // node::LoadEnvironment() are being called.
    Context::Scope context_scope(setup->context());

    // Set up the Node.js instance for execution, and run code inside of it.
    // There is also a variant that takes a callback and provides it with
    // the `require` and `process` objects, so that it can manually compile
    // and run scripts as needed.
    // The `require` function inside this script does *not* access the file
    // system, and can only load built-in Node.js modules.
    // `module.createRequire()` is being used to create one that is able to
    // load files from the disk, and uses the standard CommonJS file loader
    // instead of the internal-only `require` function.
    MaybeLocal<Value> loadenv_ret = node::LoadEnvironment(
        env,
        "const publicRequire ="
        "  require('node:module').createRequire(process.cwd() + '/');"
        "globalThis.require = publicRequire;"
        "require('node:vm').runInThisContext(process.argv[1]);");

    if (loadenv_ret.IsEmpty())  // There has been a JS exception.
      return 1;

    exit_code = node::SpinEventLoop(env).FromMaybe(1);

    // node::Stop() can be used to explicitly stop the event loop and keep
    // further JavaScript from running. It can be called from any thread,
    // and will act like worker.terminate() if called from another thread.
    node::Stop(env);
  }

  return exit_code;
} copy\n\n\n\nNode.js
        
      
      
About this documentation
Usage and example



Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Modules: TypeScript
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
Readline
REPL
Report
Single executable applications
SQLite
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker

    

    
      
        
          Node.js v24.0.1 documentation
          
            
            
          
        
        
          
            Node.js v24.0.1
            
    
      
        
        Table of contents
      

      
Child process

Asynchronous process creation

Spawning .bat and .cmd files on Windows
child_process.exec(command[, options][, callback])
child_process.execFile(file[, args][, options][, callback])
child_process.fork(modulePath[, args][, options])
child_process.spawn(command[, args][, options])

options.detached
options.stdio




Synchronous process creation

child_process.execFileSync(file[, args][, options])
child_process.execSync(command[, options])
child_process.spawnSync(command[, args][, options])


Class: ChildProcess

Event: 'close'
Event: 'disconnect'
Event: 'error'
Event: 'exit'
Event: 'message'
Event: 'spawn'
subprocess.channel

subprocess.channel.ref()
subprocess.channel.unref()


subprocess.connected
subprocess.disconnect()
subprocess.exitCode
subprocess.kill([signal])
subprocess[Symbol.dispose]()
subprocess.killed
subprocess.pid
subprocess.ref()
subprocess.send(message[, sendHandle[, options]][, callback])

Example: sending a server object
Example: sending a socket object


subprocess.signalCode
subprocess.spawnargs
subprocess.spawnfile
subprocess.stderr
subprocess.stdin
subprocess.stdio
subprocess.stdout
subprocess.unref()


maxBuffer and Unicode
Shell requirements
Default Windows shell
Advanced serialization



    
  
            
    
      
        
        Index
      

      
About this documentation
Usage and example

      
        Index
      
    
  


Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Modules: TypeScript
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
Readline
REPL
Report
Single executable applications
SQLite
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker

    
  
            
    
      
        
        Other versions
      
      24.x
23.x
22.x LTS
21.x
20.x LTS
19.x
18.x
17.x
16.x
15.x
14.x
13.x
12.x
11.x
10.x
9.x
8.x
7.x
6.x
5.x
4.x
0.12.x
0.10.x
    
  
            
              
                
                Options
              
        
              
                
                  
                    View on single page
                  
                  
                    View as JSON
                  
                  Edit on GitHub    
                
              
            
          
        
        
      

      Table of contents
Child process

Asynchronous process creation

Spawning .bat and .cmd files on Windows
child_process.exec(command[, options][, callback])
child_process.execFile(file[, args][, options][, callback])
child_process.fork(modulePath[, args][, options])
child_process.spawn(command[, args][, options])

options.detached
options.stdio




Synchronous process creation

child_process.execFileSync(file[, args][, options])
child_process.execSync(command[, options])
child_process.spawnSync(command[, args][, options])


Class: ChildProcess

Event: 'close'
Event: 'disconnect'
Event: 'error'
Event: 'exit'
Event: 'message'
Event: 'spawn'
subprocess.channel

subprocess.channel.ref()
subprocess.channel.unref()


subprocess.connected
subprocess.disconnect()
subprocess.exitCode
subprocess.kill([signal])
subprocess[Symbol.dispose]()
subprocess.killed
subprocess.pid
subprocess.ref()
subprocess.send(message[, sendHandle[, options]][, callback])

Example: sending a server object
Example: sending a socket object


subprocess.signalCode
subprocess.spawnargs
subprocess.spawnfile
subprocess.stderr
subprocess.stdin
subprocess.stdio
subprocess.stdout
subprocess.unref()


maxBuffer and Unicode
Shell requirements
Default Windows shell
Advanced serialization




      
        Child process#

Stability: 2 - Stable
Source Code: lib/child_process.js
The node:child_process module provides the ability to spawn subprocesses in
a manner that is similar, but not identical, to popen(3). This capability
is primarily provided by the child_process.spawn() function:

const { spawn } = require('node:child_process');
const ls = spawn('ls', ['-lh', '/usr']);

ls.stdout.on('data', (data) => {
  console.log(`stdout: ${data}`);
});

ls.stderr.on('data', (data) => {
  console.error(`stderr: ${data}`);
});

ls.on('close', (code) => {
  console.log(`child process exited with code ${code}`);
});import { spawn } from 'node:child_process';
const ls = spawn('ls', ['-lh', '/usr']);

ls.stdout.on('data', (data) => {
  console.log(`stdout: ${data}`);
});

ls.stderr.on('data', (data) => {
  console.error(`stderr: ${data}`);
});

ls.on('close', (code) => {
  console.log(`child process exited with code ${code}`);
});copy
By default, pipes for stdin, stdout, and stderr are established between
the parent Node.js process and the spawned subprocess. These pipes have
limited (and platform-specific) capacity. If the subprocess writes to
stdout in excess of that limit without the output being captured, the
subprocess blocks waiting for the pipe buffer to accept more data. This is
identical to the behavior of pipes in the shell. Use the { stdio: 'ignore' }
option if the output will not be consumed.
The command lookup is performed using the options.env.PATH environment
variable if env is in the options object. Otherwise, process.env.PATH is
used. If options.env is set without PATH, lookup on Unix is performed
on a default search path search of /usr/bin:/bin (see your operating system's
manual for execvpe/execvp), on Windows the current processes environment
variable PATH is used.
On Windows, environment variables are case-insensitive. Node.js
lexicographically sorts the env keys and uses the first one that
case-insensitively matches. Only first (in lexicographic order) entry will be
passed to the subprocess. This might lead to issues on Windows when passing
objects to the env option that have multiple variants of the same key, such as
PATH and Path.
The child_process.spawn() method spawns the child process asynchronously,
without blocking the Node.js event loop. The child_process.spawnSync()
function provides equivalent functionality in a synchronous manner that blocks
the event loop until the spawned process either exits or is terminated.
For convenience, the node:child_process module provides a handful of
synchronous and asynchronous alternatives to child_process.spawn() and
child_process.spawnSync(). Each of these alternatives are implemented on
top of child_process.spawn() or child_process.spawnSync().

child_process.exec(): spawns a shell and runs a command within that
shell, passing the stdout and stderr to a callback function when
complete.
child_process.execFile(): similar to child_process.exec() except
that it spawns the command directly without first spawning a shell by
default.
child_process.fork(): spawns a new Node.js process and invokes a
specified module with an IPC communication channel established that allows
sending messages between parent and child.
child_process.execSync(): a synchronous version of
child_process.exec() that will block the Node.js event loop.
child_process.execFileSync(): a synchronous version of
child_process.execFile() that will block the Node.js event loop.

For certain use cases, such as automating shell scripts, the
synchronous counterparts may be more convenient. In many cases, however,
the synchronous methods can have significant impact on performance due to
stalling the event loop while spawned processes complete.
Asynchronous process creation#
The child_process.spawn(), child_process.fork(), child_process.exec(),
and child_process.execFile() methods all follow the idiomatic asynchronous
programming pattern typical of other Node.js APIs.
Each of the methods returns a ChildProcess instance. These objects
implement the Node.js EventEmitter API, allowing the parent process to
register listener functions that are called when certain events occur during
the life cycle of the child process.
The child_process.exec() and child_process.execFile() methods
additionally allow for an optional callback function to be specified that is
invoked when the child process terminates.

Spawning .bat and .cmd files on Windows#
The importance of the distinction between child_process.exec() and
child_process.execFile() can vary based on platform. On Unix-type
operating systems (Unix, Linux, macOS) child_process.execFile() can be
more efficient because it does not spawn a shell by default. On Windows,
however, .bat and .cmd files are not executable on their own without a
terminal, and therefore cannot be launched using child_process.execFile().
When running on Windows, .bat and .cmd files can be invoked using
child_process.spawn() with the shell option set, with
child_process.exec(), or by spawning cmd.exe and passing the .bat or
.cmd file as an argument (which is what the shell option and
child_process.exec() do). In any case, if the script filename contains
spaces it needs to be quoted.

// OR...
const { exec, spawn } = require('node:child_process');

exec('my.bat', (err, stdout, stderr) => {
  if (err) {
    console.error(err);
    return;
  }
  console.log(stdout);
});

// Script with spaces in the filename:
const bat = spawn('"my script.cmd" a b', { shell: true });
// or:
exec('"my script.cmd" a b', (err, stdout, stderr) => {
  // ...
});// OR...
import { exec, spawn } from 'node:child_process';

exec('my.bat', (err, stdout, stderr) => {
  if (err) {
    console.error(err);
    return;
  }
  console.log(stdout);
});

// Script with spaces in the filename:
const bat = spawn('"my script.cmd" a b', { shell: true });
// or:
exec('"my script.cmd" a b', (err, stdout, stderr) => {
  // ...
});copy

child_process.exec(command[, options][, callback])#

History

VersionChanges
v15.4.0
AbortSignal support was added.
v16.4.0, v14.18.0
The cwd option can be a WHATWG URL object using file: protocol.
v8.8.0
The windowsHide option is supported now.
v0.1.90
Added in: v0.1.90




command <string> The command to run, with space-separated arguments.
options <Object>

cwd <string> | <URL> Current working directory of the child process.
Default: process.cwd().
env <Object> Environment key-value pairs. Default: process.env.
encoding <string> Default: 'utf8'
shell <string> Shell to execute the command with. See
Shell requirements and Default Windows shell. Default:
'/bin/sh' on Unix, process.env.ComSpec on Windows.
signal <AbortSignal> allows aborting the child process using an
AbortSignal.
timeout <number> Default: 0
maxBuffer <number> Largest amount of data in bytes allowed on stdout or
stderr. If exceeded, the child process is terminated and any output is
truncated. See caveat at maxBuffer and Unicode.
Default: 1024 * 1024.
killSignal <string> | <integer> Default: 'SIGTERM'
uid <number> Sets the user identity of the process (see setuid(2)).
gid <number> Sets the group identity of the process (see setgid(2)).
windowsHide <boolean> Hide the subprocess console window that would
normally be created on Windows systems. Default: false.


callback <Function> called with the output when process terminates.

error <Error>
stdout <string> | <Buffer>
stderr <string> | <Buffer>


Returns: <ChildProcess>

Spawns a shell then executes the command within that shell, buffering any
generated output. The command string passed to the exec function is processed
directly by the shell and special characters (vary based on
shell)
need to be dealt with accordingly:

const { exec } = require('node:child_process');

exec('"/path/to/test file/test.sh" arg1 arg2');
// Double quotes are used so that the space in the path is not interpreted as
// a delimiter of multiple arguments.

exec('echo "The \\$HOME variable is $HOME"');
// The $HOME variable is escaped in the first instance, but not in the second.import { exec } from 'node:child_process';

exec('"/path/to/test file/test.sh" arg1 arg2');
// Double quotes are used so that the space in the path is not interpreted as
// a delimiter of multiple arguments.

exec('echo "The \\$HOME variable is $HOME"');
// The $HOME variable is escaped in the first instance, but not in the second.copy
Never pass unsanitized user input to this function. Any input containing shell
metacharacters may be used to trigger arbitrary command execution.
If a callback function is provided, it is called with the arguments
(error, stdout, stderr). On success, error will be null. On error,
error will be an instance of Error. The error.code property will be
the exit code of the process. By convention, any exit code other than 0
indicates an error. error.signal will be the signal that terminated the
process.
The stdout and stderr arguments passed to the callback will contain the
stdout and stderr output of the child process. By default, Node.js will decode
the output as UTF-8 and pass strings to the callback. The encoding option
can be used to specify the character encoding used to decode the stdout and
stderr output. If encoding is 'buffer', or an unrecognized character
encoding, Buffer objects will be passed to the callback instead.

const { exec } = require('node:child_process');
exec('cat *.js missing_file | wc -l', (error, stdout, stderr) => {
  if (error) {
    console.error(`exec error: ${error}`);
    return;
  }
  console.log(`stdout: ${stdout}`);
  console.error(`stderr: ${stderr}`);
});import { exec } from 'node:child_process';
exec('cat *.js missing_file | wc -l', (error, stdout, stderr) => {
  if (error) {
    console.error(`exec error: ${error}`);
    return;
  }
  console.log(`stdout: ${stdout}`);
  console.error(`stderr: ${stderr}`);
});copy
If timeout is greater than 0, the parent process will send the signal
identified by the killSignal property (the default is 'SIGTERM') if the
child process runs longer than timeout milliseconds.
Unlike the exec(3) POSIX system call, child_process.exec() does not replace
the existing process and uses a shell to execute the command.
If this method is invoked as its util.promisify()ed version, it returns
a Promise for an Object with stdout and stderr properties. The returned
ChildProcess instance is attached to the Promise as a child property. In
case of an error (including any error resulting in an exit code other than 0), a
rejected promise is returned, with the same error object given in the
callback, but with two additional properties stdout and stderr.

const util = require('node:util');
const exec = util.promisify(require('node:child_process').exec);

async function lsExample() {
  const { stdout, stderr } = await exec('ls');
  console.log('stdout:', stdout);
  console.error('stderr:', stderr);
}
lsExample();import { promisify } from 'node:util';
import child_process from 'node:child_process';
const exec = promisify(child_process.exec);

async function lsExample() {
  const { stdout, stderr } = await exec('ls');
  console.log('stdout:', stdout);
  console.error('stderr:', stderr);
}
lsExample();copy
If the signal option is enabled, calling .abort() on the corresponding
AbortController is similar to calling .kill() on the child process except
the error passed to the callback will be an AbortError:

const { exec } = require('node:child_process');
const controller = new AbortController();
const { signal } = controller;
const child = exec('grep ssh', { signal }, (error) => {
  console.error(error); // an AbortError
});
controller.abort();import { exec } from 'node:child_process';
const controller = new AbortController();
const { signal } = controller;
const child = exec('grep ssh', { signal }, (error) => {
  console.error(error); // an AbortError
});
controller.abort();copy

child_process.execFile(file[, args][, options][, callback])#

History

VersionChanges
v23.11.0, v22.15.0
Passing args when shell is set to true is deprecated.
v16.4.0, v14.18.0
The cwd option can be a WHATWG URL object using file: protocol.
v15.4.0, v14.17.0
AbortSignal support was added.
v8.8.0
The windowsHide option is supported now.
v0.1.91
Added in: v0.1.91




file <string> The name or path of the executable file to run.
args <string[]> List of string arguments.
options <Object>

cwd <string> | <URL> Current working directory of the child process.
env <Object> Environment key-value pairs. Default: process.env.
encoding <string> Default: 'utf8'
timeout <number> Default: 0
maxBuffer <number> Largest amount of data in bytes allowed on stdout or
stderr. If exceeded, the child process is terminated and any output is
truncated. See caveat at maxBuffer and Unicode.
Default: 1024 * 1024.
killSignal <string> | <integer> Default: 'SIGTERM'
uid <number> Sets the user identity of the process (see setuid(2)).
gid <number> Sets the group identity of the process (see setgid(2)).
windowsHide <boolean> Hide the subprocess console window that would
normally be created on Windows systems. Default: false.
windowsVerbatimArguments <boolean> No quoting or escaping of arguments is
done on Windows. Ignored on Unix. Default: false.
shell <boolean> | <string> If true, runs command inside of a shell. Uses
'/bin/sh' on Unix, and process.env.ComSpec on Windows. A different
shell can be specified as a string. See Shell requirements and
Default Windows shell. Default: false (no shell).
signal <AbortSignal> allows aborting the child process using an
AbortSignal.


callback <Function> Called with the output when process terminates.

error <Error>
stdout <string> | <Buffer>
stderr <string> | <Buffer>


Returns: <ChildProcess>

The child_process.execFile() function is similar to child_process.exec()
except that it does not spawn a shell by default. Rather, the specified
executable file is spawned directly as a new process making it slightly more
efficient than child_process.exec().
The same options as child_process.exec() are supported. Since a shell is
not spawned, behaviors such as I/O redirection and file globbing are not
supported.

const { execFile } = require('node:child_process');
const child = execFile('node', ['--version'], (error, stdout, stderr) => {
  if (error) {
    throw error;
  }
  console.log(stdout);
});import { execFile } from 'node:child_process';
const child = execFile('node', ['--version'], (error, stdout, stderr) => {
  if (error) {
    throw error;
  }
  console.log(stdout);
});copy
The stdout and stderr arguments passed to the callback will contain the
stdout and stderr output of the child process. By default, Node.js will decode
the output as UTF-8 and pass strings to the callback. The encoding option
can be used to specify the character encoding used to decode the stdout and
stderr output. If encoding is 'buffer', or an unrecognized character
encoding, Buffer objects will be passed to the callback instead.
If this method is invoked as its util.promisify()ed version, it returns
a Promise for an Object with stdout and stderr properties. The returned
ChildProcess instance is attached to the Promise as a child property. In
case of an error (including any error resulting in an exit code other than 0), a
rejected promise is returned, with the same error object given in the
callback, but with two additional properties stdout and stderr.

const util = require('node:util');
const execFile = util.promisify(require('node:child_process').execFile);
async function getVersion() {
  const { stdout } = await execFile('node', ['--version']);
  console.log(stdout);
}
getVersion();import { promisify } from 'node:util';
import child_process from 'node:child_process';
const execFile = promisify(child_process.execFile);
async function getVersion() {
  const { stdout } = await execFile('node', ['--version']);
  console.log(stdout);
}
getVersion();copy
If the shell option is enabled, do not pass unsanitized user input to this
function. Any input containing shell metacharacters may be used to trigger
arbitrary command execution.
If the signal option is enabled, calling .abort() on the corresponding
AbortController is similar to calling .kill() on the child process except
the error passed to the callback will be an AbortError:

const { execFile } = require('node:child_process');
const controller = new AbortController();
const { signal } = controller;
const child = execFile('node', ['--version'], { signal }, (error) => {
  console.error(error); // an AbortError
});
controller.abort();import { execFile } from 'node:child_process';
const controller = new AbortController();
const { signal } = controller;
const child = execFile('node', ['--version'], { signal }, (error) => {
  console.error(error); // an AbortError
});
controller.abort();copy

child_process.fork(modulePath[, args][, options])#

History

VersionChanges
v17.4.0, v16.14.0
The modulePath parameter can be a WHATWG URL object using file: protocol.
v16.4.0, v14.18.0
The cwd option can be a WHATWG URL object using file: protocol.
v15.13.0, v14.18.0
timeout was added.
v15.11.0, v14.18.0
killSignal for AbortSignal was added.
v15.6.0, v14.17.0
AbortSignal support was added.
v13.2.0, v12.16.0
The serialization option is supported now.
v8.0.0
The stdio option can now be a string.
v6.4.0
The stdio option is supported now.
v0.5.0
Added in: v0.5.0




modulePath <string> | <URL> The module to run in the child.
args <string[]> List of string arguments.
options <Object>

cwd <string> | <URL> Current working directory of the child process.
detached <boolean> Prepare child process to run independently of its
parent process. Specific behavior depends on the platform (see
options.detached).
env <Object> Environment key-value pairs. Default: process.env.
execPath <string> Executable used to create the child process.
execArgv <string[]> List of string arguments passed to the executable.
Default: process.execArgv.
gid <number> Sets the group identity of the process (see setgid(2)).
serialization <string> Specify the kind of serialization used for sending
messages between processes. Possible values are 'json' and 'advanced'.
See Advanced serialization for more details. Default: 'json'.
signal <AbortSignal> Allows closing the child process using an
AbortSignal.
killSignal <string> | <integer> The signal value to be used when the spawned
process will be killed by timeout or abort signal. Default: 'SIGTERM'.
silent <boolean> If true, stdin, stdout, and stderr of the child
process will be piped to the parent process, otherwise they will be inherited
from the parent process, see the 'pipe' and 'inherit' options for
child_process.spawn()'s stdio for more details.
Default: false.
stdio <Array> | <string> See child_process.spawn()'s stdio.
When this option is provided, it overrides silent. If the array variant
is used, it must contain exactly one item with value 'ipc' or an error
will be thrown. For instance [0, 1, 2, 'ipc'].
uid <number> Sets the user identity of the process (see setuid(2)).
windowsVerbatimArguments <boolean> No quoting or escaping of arguments is
done on Windows. Ignored on Unix. Default: false.
timeout <number> In milliseconds the maximum amount of time the process
is allowed to run. Default: undefined.


Returns: <ChildProcess>

The child_process.fork() method is a special case of
child_process.spawn() used specifically to spawn new Node.js processes.
Like child_process.spawn(), a ChildProcess object is returned. The
returned ChildProcess will have an additional communication channel
built-in that allows messages to be passed back and forth between the parent and
child. See subprocess.send() for details.
Keep in mind that spawned Node.js child processes are
independent of the parent with exception of the IPC communication channel
that is established between the two. Each process has its own memory, with
their own V8 instances. Because of the additional resource allocations
required, spawning a large number of child Node.js processes is not
recommended.
By default, child_process.fork() will spawn new Node.js instances using the
process.execPath of the parent process. The execPath property in the
options object allows for an alternative execution path to be used.
Node.js processes launched with a custom execPath will communicate with the
parent process using the file descriptor (fd) identified using the
environment variable NODE_CHANNEL_FD on the child process.
Unlike the fork(2) POSIX system call, child_process.fork() does not clone the
current process.
The shell option available in child_process.spawn() is not supported by
child_process.fork() and will be ignored if set.
If the signal option is enabled, calling .abort() on the corresponding
AbortController is similar to calling .kill() on the child process except
the error passed to the callback will be an AbortError:

const { fork } = require('node:child_process');
const process = require('node:process');

if (process.argv[2] === 'child') {
  setTimeout(() => {
    console.log(`Hello from ${process.argv[2]}!`);
  }, 1_000);
} else {
  const controller = new AbortController();
  const { signal } = controller;
  const child = fork(__filename, ['child'], { signal });
  child.on('error', (err) => {
    // This will be called with err being an AbortError if the controller aborts
  });
  controller.abort(); // Stops the child process
}import { fork } from 'node:child_process';
import process from 'node:process';

if (process.argv[2] === 'child') {
  setTimeout(() => {
    console.log(`Hello from ${process.argv[2]}!`);
  }, 1_000);
} else {
  const controller = new AbortController();
  const { signal } = controller;
  const child = fork(import.meta.url, ['child'], { signal });
  child.on('error', (err) => {
    // This will be called with err being an AbortError if the controller aborts
  });
  controller.abort(); // Stops the child process
}copy

child_process.spawn(command[, args][, options])#

History

VersionChanges
v23.11.0, v22.15.0
Passing args when shell is set to true is deprecated.
v16.4.0, v14.18.0
The cwd option can be a WHATWG URL object using file: protocol.
v15.13.0, v14.18.0
timeout was added.
v15.11.0, v14.18.0
killSignal for AbortSignal was added.
v15.5.0, v14.17.0
AbortSignal support was added.
v13.2.0, v12.16.0
The serialization option is supported now.
v8.8.0
The windowsHide option is supported now.
v6.4.0
The argv0 option is supported now.
v5.7.0
The shell option is supported now.
v0.1.90
Added in: v0.1.90




command <string> The command to run.
args <string[]> List of string arguments.
options <Object>

cwd <string> | <URL> Current working directory of the child process.
env <Object> Environment key-value pairs. Default: process.env.
argv0 <string> Explicitly set the value of argv[0] sent to the child
process. This will be set to command if not specified.
stdio <Array> | <string> Child's stdio configuration (see
options.stdio).
detached <boolean> Prepare child process to run independently of
its parent process. Specific behavior depends on the platform (see
options.detached).
uid <number> Sets the user identity of the process (see setuid(2)).
gid <number> Sets the group identity of the process (see setgid(2)).
serialization <string> Specify the kind of serialization used for sending
messages between processes. Possible values are 'json' and 'advanced'.
See Advanced serialization for more details. Default: 'json'.
shell <boolean> | <string> If true, runs command inside of a shell. Uses
'/bin/sh' on Unix, and process.env.ComSpec on Windows. A different
shell can be specified as a string. See Shell requirements and
Default Windows shell. Default: false (no shell).
windowsVerbatimArguments <boolean> No quoting or escaping of arguments is
done on Windows. Ignored on Unix. This is set to true automatically
when shell is specified and is CMD. Default: false.
windowsHide <boolean> Hide the subprocess console window that would
normally be created on Windows systems. Default: false.
signal <AbortSignal> allows aborting the child process using an
AbortSignal.
timeout <number> In milliseconds the maximum amount of time the process
is allowed to run. Default: undefined.
killSignal <string> | <integer> The signal value to be used when the spawned
process will be killed by timeout or abort signal. Default: 'SIGTERM'.


Returns: <ChildProcess>

The child_process.spawn() method spawns a new process using the given
command, with command-line arguments in args. If omitted, args defaults
to an empty array.
If the shell option is enabled, do not pass unsanitized user input to this
function. Any input containing shell metacharacters may be used to trigger
arbitrary command execution.
A third argument may be used to specify additional options, with these defaults:
const defaults = {
  cwd: undefined,
  env: process.env,
}; copy
Use cwd to specify the working directory from which the process is spawned.
If not given, the default is to inherit the current working directory. If given,
but the path does not exist, the child process emits an ENOENT error
and exits immediately. ENOENT is also emitted when the command
does not exist.
Use env to specify environment variables that will be visible to the new
process, the default is process.env.
undefined values in env will be ignored.
Example of running ls -lh /usr, capturing stdout, stderr, and the
exit code:

const { spawn } = require('node:child_process');
const ls = spawn('ls', ['-lh', '/usr']);

ls.stdout.on('data', (data) => {
  console.log(`stdout: ${data}`);
});

ls.stderr.on('data', (data) => {
  console.error(`stderr: ${data}`);
});

ls.on('close', (code) => {
  console.log(`child process exited with code ${code}`);
});import { spawn } from 'node:child_process';
const ls = spawn('ls', ['-lh', '/usr']);

ls.stdout.on('data', (data) => {
  console.log(`stdout: ${data}`);
});

ls.stderr.on('data', (data) => {
  console.error(`stderr: ${data}`);
});

ls.on('close', (code) => {
  console.log(`child process exited with code ${code}`);
});copy
Example: A very elaborate way to run ps ax | grep ssh

const { spawn } = require('node:child_process');
const ps = spawn('ps', ['ax']);
const grep = spawn('grep', ['ssh']);

ps.stdout.on('data', (data) => {
  grep.stdin.write(data);
});

ps.stderr.on('data', (data) => {
  console.error(`ps stderr: ${data}`);
});

ps.on('close', (code) => {
  if (code !== 0) {
    console.log(`ps process exited with code ${code}`);
  }
  grep.stdin.end();
});

grep.stdout.on('data', (data) => {
  console.log(data.toString());
});

grep.stderr.on('data', (data) => {
  console.error(`grep stderr: ${data}`);
});

grep.on('close', (code) => {
  if (code !== 0) {
    console.log(`grep process exited with code ${code}`);
  }
});import { spawn } from 'node:child_process';
const ps = spawn('ps', ['ax']);
const grep = spawn('grep', ['ssh']);

ps.stdout.on('data', (data) => {
  grep.stdin.write(data);
});

ps.stderr.on('data', (data) => {
  console.error(`ps stderr: ${data}`);
});

ps.on('close', (code) => {
  if (code !== 0) {
    console.log(`ps process exited with code ${code}`);
  }
  grep.stdin.end();
});

grep.stdout.on('data', (data) => {
  console.log(data.toString());
});

grep.stderr.on('data', (data) => {
  console.error(`grep stderr: ${data}`);
});

grep.on('close', (code) => {
  if (code !== 0) {
    console.log(`grep process exited with code ${code}`);
  }
});copy
Example of checking for failed spawn:

const { spawn } = require('node:child_process');
const subprocess = spawn('bad_command');

subprocess.on('error', (err) => {
  console.error('Failed to start subprocess.');
});import { spawn } from 'node:child_process';
const subprocess = spawn('bad_command');

subprocess.on('error', (err) => {
  console.error('Failed to start subprocess.');
});copy
Certain platforms (macOS, Linux) will use the value of argv[0] for the process
title while others (Windows, SunOS) will use command.
Node.js overwrites argv[0] with process.execPath on startup, so
process.argv[0] in a Node.js child process will not match the argv0
parameter passed to spawn from the parent. Retrieve it with the
process.argv0 property instead.
If the signal option is enabled, calling .abort() on the corresponding
AbortController is similar to calling .kill() on the child process except
the error passed to the callback will be an AbortError:

const { spawn } = require('node:child_process');
const controller = new AbortController();
const { signal } = controller;
const grep = spawn('grep', ['ssh'], { signal });
grep.on('error', (err) => {
  // This will be called with err being an AbortError if the controller aborts
});
controller.abort(); // Stops the child processimport { spawn } from 'node:child_process';
const controller = new AbortController();
const { signal } = controller;
const grep = spawn('grep', ['ssh'], { signal });
grep.on('error', (err) => {
  // This will be called with err being an AbortError if the controller aborts
});
controller.abort(); // Stops the child processcopy

options.detached#

Added in: v0.7.10

On Windows, setting options.detached to true makes it possible for the
child process to continue running after the parent exits. The child process
will have its own console window. Once enabled for a child process,
it cannot be disabled.
On non-Windows platforms, if options.detached is set to true, the child
process will be made the leader of a new process group and session. Child
processes may continue running after the parent exits regardless of whether
they are detached or not. See setsid(2) for more information.
By default, the parent will wait for the detached child process to exit.
To prevent the parent process from waiting for a given subprocess to exit, use
the subprocess.unref() method. Doing so will cause the parent process' event
loop to not include the child process in its reference count, allowing the
parent process to exit independently of the child process, unless there is an established
IPC channel between the child and the parent processes.
When using the detached option to start a long-running process, the process
will not stay running in the background after the parent exits unless it is
provided with a stdio configuration that is not connected to the parent.
If the parent process' stdio is inherited, the child process will remain attached
to the controlling terminal.
Example of a long-running process, by detaching and also ignoring its parent
stdio file descriptors, in order to ignore the parent's termination:

const { spawn } = require('node:child_process');
const process = require('node:process');

const subprocess = spawn(process.argv[0], ['child_program.js'], {
  detached: true,
  stdio: 'ignore',
});

subprocess.unref();import { spawn } from 'node:child_process';
import process from 'node:process';

const subprocess = spawn(process.argv[0], ['child_program.js'], {
  detached: true,
  stdio: 'ignore',
});

subprocess.unref();copy
Alternatively one can redirect the child process' output into files:

const { openSync } = require('node:fs');
const { spawn } = require('node:child_process');
const out = openSync('./out.log', 'a');
const err = openSync('./out.log', 'a');

const subprocess = spawn('prg', [], {
  detached: true,
  stdio: [ 'ignore', out, err ],
});

subprocess.unref();import { openSync } from 'node:fs';
import { spawn } from 'node:child_process';
const out = openSync('./out.log', 'a');
const err = openSync('./out.log', 'a');

const subprocess = spawn('prg', [], {
  detached: true,
  stdio: [ 'ignore', out, err ],
});

subprocess.unref();copy

options.stdio#

History

VersionChanges
v15.6.0, v14.18.0
Added the overlapped stdio flag.
v3.3.1
The value 0 is now accepted as a file descriptor.
v0.7.10
Added in: v0.7.10



The options.stdio option is used to configure the pipes that are established
between the parent and child process. By default, the child's stdin, stdout,
and stderr are redirected to corresponding subprocess.stdin,
subprocess.stdout, and subprocess.stderr streams on the
ChildProcess object. This is equivalent to setting the options.stdio
equal to ['pipe', 'pipe', 'pipe'].
For convenience, options.stdio may be one of the following strings:

'pipe': equivalent to ['pipe', 'pipe', 'pipe'] (the default)
'overlapped': equivalent to ['overlapped', 'overlapped', 'overlapped']
'ignore': equivalent to ['ignore', 'ignore', 'ignore']
'inherit': equivalent to ['inherit', 'inherit', 'inherit'] or [0, 1, 2]

Otherwise, the value of options.stdio is an array where each index corresponds
to an fd in the child. The fds 0, 1, and 2 correspond to stdin, stdout,
and stderr, respectively. Additional fds can be specified to create additional
pipes between the parent and child. The value is one of the following:


'pipe': Create a pipe between the child process and the parent process.
The parent end of the pipe is exposed to the parent as a property on the
child_process object as subprocess.stdio[fd]. Pipes
created for fds 0, 1, and 2 are also available as subprocess.stdin,
subprocess.stdout and subprocess.stderr, respectively.
These are not actual Unix pipes and therefore the child process
can not use them by their descriptor files,
e.g. /dev/fd/2 or /dev/stdout.


'overlapped': Same as 'pipe' except that the FILE_FLAG_OVERLAPPED flag
is set on the handle. This is necessary for overlapped I/O on the child
process's stdio handles. See the
docs
for more details. This is exactly the same as 'pipe' on non-Windows
systems.


'ipc': Create an IPC channel for passing messages/file descriptors
between parent and child. A ChildProcess may have at most one IPC
stdio file descriptor. Setting this option enables the
subprocess.send() method. If the child process is a Node.js instance,
the presence of an IPC channel will enable process.send() and
process.disconnect() methods, as well as 'disconnect' and
'message' events within the child process.
Accessing the IPC channel fd in any way other than process.send()
or using the IPC channel with a child process that is not a Node.js instance
is not supported.


'ignore': Instructs Node.js to ignore the fd in the child. While Node.js
will always open fds 0, 1, and 2 for the processes it spawns, setting the fd
to 'ignore' will cause Node.js to open /dev/null and attach it to the
child's fd.


'inherit': Pass through the corresponding stdio stream to/from the
parent process. In the first three positions, this is equivalent to
process.stdin, process.stdout, and process.stderr, respectively. In
any other position, equivalent to 'ignore'.


<Stream> object: Share a readable or writable stream that refers to a tty,
file, socket, or a pipe with the child process. The stream's underlying
file descriptor is duplicated in the child process to the fd that
corresponds to the index in the stdio array. The stream must have an
underlying descriptor (file streams do not start until the 'open' event has
occurred).
NOTE: While it is technically possible to pass stdin as a writable or
stdout/stderr as readable, it is not recommended.
Readable and writable streams are designed with distinct behaviors, and using
them incorrectly (e.g., passing a readable stream where a writable stream is
expected) can lead to unexpected results or errors. This practice is discouraged
as it may result in undefined behavior or dropped callbacks if the stream
encounters errors. Always ensure that stdin is used as writable and
stdout/stderr as readable to maintain the intended flow of data between
the parent and child processes.


Positive integer: The integer value is interpreted as a file descriptor
that is open in the parent process. It is shared with the child
process, similar to how <Stream> objects can be shared. Passing sockets
is not supported on Windows.


null, undefined: Use default value. For stdio fds 0, 1, and 2 (in other
words, stdin, stdout, and stderr) a pipe is created. For fd 3 and up, the
default is 'ignore'.



const { spawn } = require('node:child_process');
const process = require('node:process');

// Child will use parent's stdios.
spawn('prg', [], { stdio: 'inherit' });

// Spawn child sharing only stderr.
spawn('prg', [], { stdio: ['pipe', 'pipe', process.stderr] });

// Open an extra fd=4, to interact with programs presenting a
// startd-style interface.
spawn('prg', [], { stdio: ['pipe', null, null, null, 'pipe'] });import { spawn } from 'node:child_process';
import process from 'node:process';

// Child will use parent's stdios.
spawn('prg', [], { stdio: 'inherit' });

// Spawn child sharing only stderr.
spawn('prg', [], { stdio: ['pipe', 'pipe', process.stderr] });

// Open an extra fd=4, to interact with programs presenting a
// startd-style interface.
spawn('prg', [], { stdio: ['pipe', null, null, null, 'pipe'] });copy
It is worth noting that when an IPC channel is established between the
parent and child processes, and the child process is a Node.js instance,
the child process is launched with the IPC channel unreferenced (using
unref()) until the child process registers an event handler for the
'disconnect' event or the 'message' event. This allows the
child process to exit normally without the process being held open by the
open IPC channel.
See also: child_process.exec() and child_process.fork().

Synchronous process creation#
The child_process.spawnSync(), child_process.execSync(), and
child_process.execFileSync() methods are synchronous and will block the
Node.js event loop, pausing execution of any additional code until the spawned
process exits.
Blocking calls like these are mostly useful for simplifying general-purpose
scripting tasks and for simplifying the loading/processing of application
configuration at startup.

child_process.execFileSync(file[, args][, options])#

History

VersionChanges
v16.4.0, v14.18.0
The cwd option can be a WHATWG URL object using file: protocol.
v10.10.0
The input option can now be any TypedArray or a DataView.
v8.8.0
The windowsHide option is supported now.
v8.0.0
The input option can now be a Uint8Array.
v6.2.1, v4.5.0
The encoding option can now explicitly be set to buffer.
v0.11.12
Added in: v0.11.12




file <string> The name or path of the executable file to run.
args <string[]> List of string arguments.
options <Object>

cwd <string> | <URL> Current working directory of the child process.
input <string> | <Buffer> | <TypedArray> | <DataView> The value which will be passed
as stdin to the spawned process. If stdio[0] is set to 'pipe', Supplying
this value will override stdio[0].
stdio <string> | <Array> Child's stdio configuration.
See child_process.spawn()'s stdio. stderr by default will
be output to the parent process' stderr unless stdio is specified.
Default: 'pipe'.
env <Object> Environment key-value pairs. Default: process.env.
uid <number> Sets the user identity of the process (see setuid(2)).
gid <number> Sets the group identity of the process (see setgid(2)).
timeout <number> In milliseconds the maximum amount of time the process
is allowed to run. Default: undefined.
killSignal <string> | <integer> The signal value to be used when the spawned
process will be killed. Default: 'SIGTERM'.
maxBuffer <number> Largest amount of data in bytes allowed on stdout or
stderr. If exceeded, the child process is terminated. See caveat at
maxBuffer and Unicode. Default: 1024 * 1024.
encoding <string> The encoding used for all stdio inputs and outputs.
Default: 'buffer'.
windowsHide <boolean> Hide the subprocess console window that would
normally be created on Windows systems. Default: false.
shell <boolean> | <string> If true, runs command inside of a shell. Uses
'/bin/sh' on Unix, and process.env.ComSpec on Windows. A different
shell can be specified as a string. See Shell requirements and
Default Windows shell. Default: false (no shell).


Returns: <Buffer> | <string> The stdout from the command.

The child_process.execFileSync() method is generally identical to
child_process.execFile() with the exception that the method will not
return until the child process has fully closed. When a timeout has been
encountered and killSignal is sent, the method won't return until the process
has completely exited.
If the child process intercepts and handles the SIGTERM signal and
does not exit, the parent process will still wait until the child process has
exited.
If the process times out or has a non-zero exit code, this method will throw an
Error that will include the full result of the underlying
child_process.spawnSync().
If the shell option is enabled, do not pass unsanitized user input to this
function. Any input containing shell metacharacters may be used to trigger
arbitrary command execution.

const { execFileSync } = require('node:child_process');

try {
  const stdout = execFileSync('my-script.sh', ['my-arg'], {
    // Capture stdout and stderr from child process. Overrides the
    // default behavior of streaming child stderr to the parent stderr
    stdio: 'pipe',

    // Use utf8 encoding for stdio pipes
    encoding: 'utf8',
  });

  console.log(stdout);
} catch (err) {
  if (err.code) {
    // Spawning child process failed
    console.error(err.code);
  } else {
    // Child was spawned but exited with non-zero exit code
    // Error contains any stdout and stderr from the child
    const { stdout, stderr } = err;

    console.error({ stdout, stderr });
  }
}import { execFileSync } from 'node:child_process';

try {
  const stdout = execFileSync('my-script.sh', ['my-arg'], {
    // Capture stdout and stderr from child process. Overrides the
    // default behavior of streaming child stderr to the parent stderr
    stdio: 'pipe',

    // Use utf8 encoding for stdio pipes
    encoding: 'utf8',
  });

  console.log(stdout);
} catch (err) {
  if (err.code) {
    // Spawning child process failed
    console.error(err.code);
  } else {
    // Child was spawned but exited with non-zero exit code
    // Error contains any stdout and stderr from the child
    const { stdout, stderr } = err;

    console.error({ stdout, stderr });
  }
}copy

child_process.execSync(command[, options])#

History

VersionChanges
v16.4.0, v14.18.0
The cwd option can be a WHATWG URL object using file: protocol.
v10.10.0
The input option can now be any TypedArray or a DataView.
v8.8.0
The windowsHide option is supported now.
v8.0.0
The input option can now be a Uint8Array.
v0.11.12
Added in: v0.11.12




command <string> The command to run.
options <Object>

cwd <string> | <URL> Current working directory of the child process.
input <string> | <Buffer> | <TypedArray> | <DataView> The value which will be passed
as stdin to the spawned process. If stdio[0] is set to 'pipe', Supplying
this value will override stdio[0].
stdio <string> | <Array> Child's stdio configuration.
See child_process.spawn()'s stdio. stderr by default will
be output to the parent process' stderr unless stdio is specified.
Default: 'pipe'.
env <Object> Environment key-value pairs. Default: process.env.
shell <string> Shell to execute the command with. See
Shell requirements and Default Windows shell. Default:
'/bin/sh' on Unix, process.env.ComSpec on Windows.
uid <number> Sets the user identity of the process. (See setuid(2)).
gid <number> Sets the group identity of the process. (See setgid(2)).
timeout <number> In milliseconds the maximum amount of time the process
is allowed to run. Default: undefined.
killSignal <string> | <integer> The signal value to be used when the spawned
process will be killed. Default: 'SIGTERM'.
maxBuffer <number> Largest amount of data in bytes allowed on stdout or
stderr. If exceeded, the child process is terminated and any output is
truncated. See caveat at maxBuffer and Unicode.
Default: 1024 * 1024.
encoding <string> The encoding used for all stdio inputs and outputs.
Default: 'buffer'.
windowsHide <boolean> Hide the subprocess console window that would
normally be created on Windows systems. Default: false.


Returns: <Buffer> | <string> The stdout from the command.

The child_process.execSync() method is generally identical to
child_process.exec() with the exception that the method will not return
until the child process has fully closed. When a timeout has been encountered
and killSignal is sent, the method won't return until the process has
completely exited. If the child process intercepts and handles the SIGTERM
signal and doesn't exit, the parent process will wait until the child process
has exited.
If the process times out or has a non-zero exit code, this method will throw.
The Error object will contain the entire result from
child_process.spawnSync().
Never pass unsanitized user input to this function. Any input containing shell
metacharacters may be used to trigger arbitrary command execution.

child_process.spawnSync(command[, args][, options])#

History

VersionChanges
v16.4.0, v14.18.0
The cwd option can be a WHATWG URL object using file: protocol.
v10.10.0
The input option can now be any TypedArray or a DataView.
v8.8.0
The windowsHide option is supported now.
v8.0.0
The input option can now be a Uint8Array.
v5.7.0
The shell option is supported now.
v6.2.1, v4.5.0
The encoding option can now explicitly be set to buffer.
v0.11.12
Added in: v0.11.12




command <string> The command to run.
args <string[]> List of string arguments.
options <Object>

cwd <string> | <URL> Current working directory of the child process.
input <string> | <Buffer> | <TypedArray> | <DataView> The value which will be passed
as stdin to the spawned process. If stdio[0] is set to 'pipe', Supplying
this value will override stdio[0].
argv0 <string> Explicitly set the value of argv[0] sent to the child
process. This will be set to command if not specified.
stdio <string> | <Array> Child's stdio configuration.
See child_process.spawn()'s stdio. Default: 'pipe'.
env <Object> Environment key-value pairs. Default: process.env.
uid <number> Sets the user identity of the process (see setuid(2)).
gid <number> Sets the group identity of the process (see setgid(2)).
timeout <number> In milliseconds the maximum amount of time the process
is allowed to run. Default: undefined.
killSignal <string> | <integer> The signal value to be used when the spawned
process will be killed. Default: 'SIGTERM'.
maxBuffer <number> Largest amount of data in bytes allowed on stdout or
stderr. If exceeded, the child process is terminated and any output is
truncated. See caveat at maxBuffer and Unicode.
Default: 1024 * 1024.
encoding <string> The encoding used for all stdio inputs and outputs.
Default: 'buffer'.
shell <boolean> | <string> If true, runs command inside of a shell. Uses
'/bin/sh' on Unix, and process.env.ComSpec on Windows. A different
shell can be specified as a string. See Shell requirements and
Default Windows shell. Default: false (no shell).
windowsVerbatimArguments <boolean> No quoting or escaping of arguments is
done on Windows. Ignored on Unix. This is set to true automatically
when shell is specified and is CMD. Default: false.
windowsHide <boolean> Hide the subprocess console window that would
normally be created on Windows systems. Default: false.


Returns: <Object>

pid <number> Pid of the child process.
output <Array> Array of results from stdio output.
stdout <Buffer> | <string> The contents of output[1].
stderr <Buffer> | <string> The contents of output[2].
status <number> | <null> The exit code of the subprocess, or null if the
subprocess terminated due to a signal.
signal <string> | <null> The signal used to kill the subprocess, or null if
the subprocess did not terminate due to a signal.
error <Error> The error object if the child process failed or timed out.



The child_process.spawnSync() method is generally identical to
child_process.spawn() with the exception that the function will not return
until the child process has fully closed. When a timeout has been encountered
and killSignal is sent, the method won't return until the process has
completely exited. If the process intercepts and handles the SIGTERM signal
and doesn't exit, the parent process will wait until the child process has
exited.
If the shell option is enabled, do not pass unsanitized user input to this
function. Any input containing shell metacharacters may be used to trigger
arbitrary command execution.

Class: ChildProcess#

Added in: v2.2.0


Extends: <EventEmitter>

Instances of the ChildProcess represent spawned child processes.
Instances of ChildProcess are not intended to be created directly. Rather,
use the child_process.spawn(), child_process.exec(),
child_process.execFile(), or child_process.fork() methods to create
instances of ChildProcess.

Event: 'close'#

Added in: v0.7.7


code <number> The exit code if the child process exited on its own.
signal <string> The signal by which the child process was terminated.

The 'close' event is emitted after a process has ended and the stdio
streams of a child process have been closed. This is distinct from the
'exit' event, since multiple processes might share the same stdio
streams. The 'close' event will always emit after 'exit' was
already emitted, or 'error' if the child process failed to spawn.

const { spawn } = require('node:child_process');
const ls = spawn('ls', ['-lh', '/usr']);

ls.stdout.on('data', (data) => {
  console.log(`stdout: ${data}`);
});

ls.on('close', (code) => {
  console.log(`child process close all stdio with code ${code}`);
});

ls.on('exit', (code) => {
  console.log(`child process exited with code ${code}`);
});import { spawn } from 'node:child_process';
const ls = spawn('ls', ['-lh', '/usr']);

ls.stdout.on('data', (data) => {
  console.log(`stdout: ${data}`);
});

ls.on('close', (code) => {
  console.log(`child process close all stdio with code ${code}`);
});

ls.on('exit', (code) => {
  console.log(`child process exited with code ${code}`);
});copy

Event: 'disconnect'#

Added in: v0.7.2

The 'disconnect' event is emitted after calling the
subprocess.disconnect() method in parent process or
process.disconnect() in child process. After disconnecting it is no longer
possible to send or receive messages, and the subprocess.connected
property is false.

Event: 'error'#

err <Error> The error.

The 'error' event is emitted whenever:

The process could not be spawned.
The process could not be killed.
Sending a message to the child process failed.
The child process was aborted via the signal option.

The 'exit' event may or may not fire after an error has occurred. When
listening to both the 'exit' and 'error' events, guard
against accidentally invoking handler functions multiple times.
See also subprocess.kill() and subprocess.send().

Event: 'exit'#

Added in: v0.1.90


code <number> The exit code if the child process exited on its own.
signal <string> The signal by which the child process was terminated.

The 'exit' event is emitted after the child process ends. If the process
exited, code is the final exit code of the process, otherwise null. If the
process terminated due to receipt of a signal, signal is the string name of
the signal, otherwise null. One of the two will always be non-null.
When the 'exit' event is triggered, child process stdio streams might still be
open.
Node.js establishes signal handlers for SIGINT and SIGTERM and Node.js
processes will not terminate immediately due to receipt of those signals.
Rather, Node.js will perform a sequence of cleanup actions and then will
re-raise the handled signal.
See waitpid(2).

Event: 'message'#

Added in: v0.5.9


message <Object> A parsed JSON object or primitive value.
sendHandle <Handle> | <undefined> undefined or a net.Socket,
net.Server, or dgram.Socket object.

The 'message' event is triggered when a child process uses
process.send() to send messages.
The message goes through serialization and parsing. The resulting
message might not be the same as what is originally sent.
If the serialization option was set to 'advanced' used when spawning the
child process, the message argument can contain data that JSON is not able
to represent.
See Advanced serialization for more details.

Event: 'spawn'#

Added in: v15.1.0, v14.17.0

The 'spawn' event is emitted once the child process has spawned successfully.
If the child process does not spawn successfully, the 'spawn' event is not
emitted and the 'error' event is emitted instead.
If emitted, the 'spawn' event comes before all other events and before any
data is received via stdout or stderr.
The 'spawn' event will fire regardless of whether an error occurs within
the spawned process. For example, if bash some-command spawns successfully,
the 'spawn' event will fire, though bash may fail to spawn some-command.
This caveat also applies when using { shell: true }.

subprocess.channel#

History

VersionChanges
v14.0.0
The object no longer accidentally exposes native C++ bindings.
v7.1.0
Added in: v7.1.0




<Object> A pipe representing the IPC channel to the child process.

The subprocess.channel property is a reference to the child's IPC channel. If
no IPC channel exists, this property is undefined.

subprocess.channel.ref()#

Added in: v7.1.0

This method makes the IPC channel keep the event loop of the parent process
running if .unref() has been called before.

subprocess.channel.unref()#

Added in: v7.1.0

This method makes the IPC channel not keep the event loop of the parent process
running, and lets it finish even while the channel is open.

subprocess.connected#

Added in: v0.7.2


<boolean> Set to false after subprocess.disconnect() is called.

The subprocess.connected property indicates whether it is still possible to
send and receive messages from a child process. When subprocess.connected is
false, it is no longer possible to send or receive messages.

subprocess.disconnect()#

Added in: v0.7.2

Closes the IPC channel between parent and child processes, allowing the child
process to exit gracefully once there are no other connections keeping it alive.
After calling this method the subprocess.connected and
process.connected properties in both the parent and child processes
(respectively) will be set to false, and it will be no longer possible
to pass messages between the processes.
The 'disconnect' event will be emitted when there are no messages in the
process of being received. This will most often be triggered immediately after
calling subprocess.disconnect().
When the child process is a Node.js instance (e.g. spawned using
child_process.fork()), the process.disconnect() method can be invoked
within the child process to close the IPC channel as well.

subprocess.exitCode#

<integer>

The subprocess.exitCode property indicates the exit code of the child process.
If the child process is still running, the field will be null.

subprocess.kill([signal])#

Added in: v0.1.90


signal <number> | <string>
Returns: <boolean>

The subprocess.kill() method sends a signal to the child process. If no
argument is given, the process will be sent the 'SIGTERM' signal. See
signal(7) for a list of available signals. This function returns true if
kill(2) succeeds, and false otherwise.

const { spawn } = require('node:child_process');
const grep = spawn('grep', ['ssh']);

grep.on('close', (code, signal) => {
  console.log(
    `child process terminated due to receipt of signal ${signal}`);
});

// Send SIGHUP to process.
grep.kill('SIGHUP');import { spawn } from 'node:child_process';
const grep = spawn('grep', ['ssh']);

grep.on('close', (code, signal) => {
  console.log(
    `child process terminated due to receipt of signal ${signal}`);
});

// Send SIGHUP to process.
grep.kill('SIGHUP');copy
The ChildProcess object may emit an 'error' event if the signal
cannot be delivered. Sending a signal to a child process that has already exited
is not an error but may have unforeseen consequences. Specifically, if the
process identifier (PID) has been reassigned to another process, the signal will
be delivered to that process instead which can have unexpected results.
While the function is called kill, the signal delivered to the child process
may not actually terminate the process.
See kill(2) for reference.
On Windows, where POSIX signals do not exist, the signal argument will be
ignored except for 'SIGKILL', 'SIGTERM', 'SIGINT' and 'SIGQUIT', and the
process will always be killed forcefully and abruptly (similar to 'SIGKILL').
See Signal Events for more details.
On Linux, child processes of child processes will not be terminated
when attempting to kill their parent. This is likely to happen when running a
new process in a shell or with the use of the shell option of ChildProcess:

const { spawn } = require('node:child_process');

const subprocess = spawn(
  'sh',
  [
    '-c',
    `node -e "setInterval(() => {
      console.log(process.pid, 'is alive')
    }, 500);"`,
  ], {
    stdio: ['inherit', 'inherit', 'inherit'],
  },
);

setTimeout(() => {
  subprocess.kill(); // Does not terminate the Node.js process in the shell.
}, 2000);import { spawn } from 'node:child_process';

const subprocess = spawn(
  'sh',
  [
    '-c',
    `node -e "setInterval(() => {
      console.log(process.pid, 'is alive')
    }, 500);"`,
  ], {
    stdio: ['inherit', 'inherit', 'inherit'],
  },
);

setTimeout(() => {
  subprocess.kill(); // Does not terminate the Node.js process in the shell.
}, 2000);copy

subprocess[Symbol.dispose]()#

Added in: v20.5.0, v18.18.0

Stability: 1 - Experimental
Calls subprocess.kill() with 'SIGTERM'.

subprocess.killed#

Added in: v0.5.10


<boolean> Set to true after subprocess.kill() is used to successfully
send a signal to the child process.

The subprocess.killed property indicates whether the child process
successfully received a signal from subprocess.kill(). The killed property
does not indicate that the child process has been terminated.

subprocess.pid#

Added in: v0.1.90


<integer> | <undefined>

Returns the process identifier (PID) of the child process. If the child process
fails to spawn due to errors, then the value is undefined and error is
emitted.

const { spawn } = require('node:child_process');
const grep = spawn('grep', ['ssh']);

console.log(`Spawned child pid: ${grep.pid}`);
grep.stdin.end();import { spawn } from 'node:child_process';
const grep = spawn('grep', ['ssh']);

console.log(`Spawned child pid: ${grep.pid}`);
grep.stdin.end();copy

subprocess.ref()#

Added in: v0.7.10

Calling subprocess.ref() after making a call to subprocess.unref() will
restore the removed reference count for the child process, forcing the parent
process to wait for the child process to exit before exiting itself.

const { spawn } = require('node:child_process');
const process = require('node:process');

const subprocess = spawn(process.argv[0], ['child_program.js'], {
  detached: true,
  stdio: 'ignore',
});

subprocess.unref();
subprocess.ref();import { spawn } from 'node:child_process';
import process from 'node:process';

const subprocess = spawn(process.argv[0], ['child_program.js'], {
  detached: true,
  stdio: 'ignore',
});

subprocess.unref();
subprocess.ref();copy

subprocess.send(message[, sendHandle[, options]][, callback])#

History

VersionChanges
v5.8.0
The options parameter, and the keepOpen option in particular, is supported now.
v5.0.0
This method returns a boolean for flow control now.
v4.0.0
The callback parameter is supported now.
v0.5.9
Added in: v0.5.9




message <Object>
sendHandle <Handle> | <undefined> undefined, or a net.Socket,
net.Server, or dgram.Socket object.
options <Object> The options argument, if present, is an object used to
parameterize the sending of certain types of handles. options supports
the following properties:

keepOpen <boolean> A value that can be used when passing instances of
net.Socket. When true, the socket is kept open in the sending process.
Default: false.


callback <Function>
Returns: <boolean>

When an IPC channel has been established between the parent and child processes
( i.e. when using child_process.fork()), the subprocess.send() method
can be used to send messages to the child process. When the child process is a
Node.js instance, these messages can be received via the 'message' event.
The message goes through serialization and parsing. The resulting
message might not be the same as what is originally sent.
For example, in the parent script:

const { fork } = require('node:child_process');
const forkedProcess = fork(`${__dirname}/sub.js`);

forkedProcess.on('message', (message) => {
  console.log('PARENT got message:', message);
});

// Causes the child to print: CHILD got message: { hello: 'world' }
forkedProcess.send({ hello: 'world' });import { fork } from 'node:child_process';
const forkedProcess = fork(`${import.meta.dirname}/sub.js`);

forkedProcess.on('message', (message) => {
  console.log('PARENT got message:', message);
});

// Causes the child to print: CHILD got message: { hello: 'world' }
forkedProcess.send({ hello: 'world' });copy
And then the child script, 'sub.js' might look like this:
process.on('message', (message) => {
  console.log('CHILD got message:', message);
});

// Causes the parent to print: PARENT got message: { foo: 'bar', baz: null }
process.send({ foo: 'bar', baz: NaN }); copy
Child Node.js processes will have a process.send() method of their own
that allows the child process to send messages back to the parent process.
There is a special case when sending a {cmd: 'NODE_foo'} message. Messages
containing a NODE_ prefix in the cmd property are reserved for use within
Node.js core and will not be emitted in the child's 'message'
event. Rather, such messages are emitted using the
'internalMessage' event and are consumed internally by Node.js.
Applications should avoid using such messages or listening for
'internalMessage' events as it is subject to change without notice.
The optional sendHandle argument that may be passed to subprocess.send() is
for passing a TCP server or socket object to the child process. The child process will
receive the object as the second argument passed to the callback function
registered on the 'message' event. Any data that is received
and buffered in the socket will not be sent to the child. Sending IPC sockets is
not supported on Windows.
The optional callback is a function that is invoked after the message is
sent but before the child process may have received it. The function is called with a
single argument: null on success, or an Error object on failure.
If no callback function is provided and the message cannot be sent, an
'error' event will be emitted by the ChildProcess object. This can
happen, for instance, when the child process has already exited.
subprocess.send() will return false if the channel has closed or when the
backlog of unsent messages exceeds a threshold that makes it unwise to send
more. Otherwise, the method returns true. The callback function can be
used to implement flow control.

Example: sending a server object#
The sendHandle argument can be used, for instance, to pass the handle of
a TCP server object to the child process as illustrated in the example below:

const { fork } = require('node:child_process');
const { createServer } = require('node:net');

const subprocess = fork('subprocess.js');

// Open up the server object and send the handle.
const server = createServer();
server.on('connection', (socket) => {
  socket.end('handled by parent');
});
server.listen(1337, () => {
  subprocess.send('server', server);
});import { fork } from 'node:child_process';
import { createServer } from 'node:net';

const subprocess = fork('subprocess.js');

// Open up the server object and send the handle.
const server = createServer();
server.on('connection', (socket) => {
  socket.end('handled by parent');
});
server.listen(1337, () => {
  subprocess.send('server', server);
});copy
The child process would then receive the server object as:
process.on('message', (m, server) => {
  if (m === 'server') {
    server.on('connection', (socket) => {
      socket.end('handled by child');
    });
  }
}); copy
Once the server is now shared between the parent and child, some connections
can be handled by the parent and some by the child.
While the example above uses a server created using the node:net module,
node:dgram module servers use exactly the same workflow with the exceptions of
listening on a 'message' event instead of 'connection' and using
server.bind() instead of server.listen(). This is, however, only
supported on Unix platforms.

Example: sending a socket object#
Similarly, the sendHandler argument can be used to pass the handle of a
socket to the child process. The example below spawns two children that each
handle connections with "normal" or "special" priority:

const { fork } = require('node:child_process');
const { createServer } = require('node:net');

const normal = fork('subprocess.js', ['normal']);
const special = fork('subprocess.js', ['special']);

// Open up the server and send sockets to child. Use pauseOnConnect to prevent
// the sockets from being read before they are sent to the child process.
const server = createServer({ pauseOnConnect: true });
server.on('connection', (socket) => {

  // If this is special priority...
  if (socket.remoteAddress === '74.125.127.100') {
    special.send('socket', socket);
    return;
  }
  // This is normal priority.
  normal.send('socket', socket);
});
server.listen(1337);import { fork } from 'node:child_process';
import { createServer } from 'node:net';

const normal = fork('subprocess.js', ['normal']);
const special = fork('subprocess.js', ['special']);

// Open up the server and send sockets to child. Use pauseOnConnect to prevent
// the sockets from being read before they are sent to the child process.
const server = createServer({ pauseOnConnect: true });
server.on('connection', (socket) => {

  // If this is special priority...
  if (socket.remoteAddress === '74.125.127.100') {
    special.send('socket', socket);
    return;
  }
  // This is normal priority.
  normal.send('socket', socket);
});
server.listen(1337);copy
The subprocess.js would receive the socket handle as the second argument
passed to the event callback function:
process.on('message', (m, socket) => {
  if (m === 'socket') {
    if (socket) {
      // Check that the client socket exists.
      // It is possible for the socket to be closed between the time it is
      // sent and the time it is received in the child process.
      socket.end(`Request handled with ${process.argv[2]} priority`);
    }
  }
}); copy
Do not use .maxConnections on a socket that has been passed to a subprocess.
The parent cannot track when the socket is destroyed.
Any 'message' handlers in the subprocess should verify that socket exists,
as the connection may have been closed during the time it takes to send the
connection to the child.

subprocess.signalCode#

<string> | <null>

The subprocess.signalCode property indicates the signal received by
the child process if any, else null.

subprocess.spawnargs#

<Array>

The subprocess.spawnargs property represents the full list of command-line
arguments the child process was launched with.

subprocess.spawnfile#

<string>

The subprocess.spawnfile property indicates the executable file name of
the child process that is launched.
For child_process.fork(), its value will be equal to
process.execPath.
For child_process.spawn(), its value will be the name of
the executable file.
For child_process.exec(),  its value will be the name of the shell
in which the child process is launched.

subprocess.stderr#

Added in: v0.1.90


<stream.Readable> | <null> | <undefined>

A Readable Stream that represents the child process's stderr.
If the child process was spawned with stdio[2] set to anything other than 'pipe',
then this will be null.
subprocess.stderr is an alias for subprocess.stdio[2]. Both properties will
refer to the same value.
The subprocess.stderr property can be null or undefined
if the child process could not be successfully spawned.

subprocess.stdin#

Added in: v0.1.90


<stream.Writable> | <null> | <undefined>

A Writable Stream that represents the child process's stdin.
If a child process waits to read all of its input, the child process will not continue
until this stream has been closed via end().
If the child process was spawned with stdio[0] set to anything other than 'pipe',
then this will be null.
subprocess.stdin is an alias for subprocess.stdio[0]. Both properties will
refer to the same value.
The subprocess.stdin property can be null or undefined
if the child process could not be successfully spawned.

subprocess.stdio#

Added in: v0.7.10


<Array>

A sparse array of pipes to the child process, corresponding with positions in
the stdio option passed to child_process.spawn() that have been set
to the value 'pipe'. subprocess.stdio[0], subprocess.stdio[1], and
subprocess.stdio[2] are also available as subprocess.stdin,
subprocess.stdout, and subprocess.stderr, respectively.
In the following example, only the child's fd 1 (stdout) is configured as a
pipe, so only the parent's subprocess.stdio[1] is a stream, all other values
in the array are null.

const assert = require('node:assert');
const fs = require('node:fs');
const child_process = require('node:child_process');

const subprocess = child_process.spawn('ls', {
  stdio: [
    0, // Use parent's stdin for child.
    'pipe', // Pipe child's stdout to parent.
    fs.openSync('err.out', 'w'), // Direct child's stderr to a file.
  ],
});

assert.strictEqual(subprocess.stdio[0], null);
assert.strictEqual(subprocess.stdio[0], subprocess.stdin);

assert(subprocess.stdout);
assert.strictEqual(subprocess.stdio[1], subprocess.stdout);

assert.strictEqual(subprocess.stdio[2], null);
assert.strictEqual(subprocess.stdio[2], subprocess.stderr);import assert from 'node:assert';
import fs from 'node:fs';
import child_process from 'node:child_process';

const subprocess = child_process.spawn('ls', {
  stdio: [
    0, // Use parent's stdin for child.
    'pipe', // Pipe child's stdout to parent.
    fs.openSync('err.out', 'w'), // Direct child's stderr to a file.
  ],
});

assert.strictEqual(subprocess.stdio[0], null);
assert.strictEqual(subprocess.stdio[0], subprocess.stdin);

assert(subprocess.stdout);
assert.strictEqual(subprocess.stdio[1], subprocess.stdout);

assert.strictEqual(subprocess.stdio[2], null);
assert.strictEqual(subprocess.stdio[2], subprocess.stderr);copy
The subprocess.stdio property can be undefined if the child process could
not be successfully spawned.

subprocess.stdout#

Added in: v0.1.90


<stream.Readable> | <null> | <undefined>

A Readable Stream that represents the child process's stdout.
If the child process was spawned with stdio[1] set to anything other than 'pipe',
then this will be null.
subprocess.stdout is an alias for subprocess.stdio[1]. Both properties will
refer to the same value.

const { spawn } = require('node:child_process');

const subprocess = spawn('ls');

subprocess.stdout.on('data', (data) => {
  console.log(`Received chunk ${data}`);
});import { spawn } from 'node:child_process';

const subprocess = spawn('ls');

subprocess.stdout.on('data', (data) => {
  console.log(`Received chunk ${data}`);
});copy
The subprocess.stdout property can be null or undefined
if the child process could not be successfully spawned.

subprocess.unref()#

Added in: v0.7.10

By default, the parent process will wait for the detached child process to exit.
To prevent the parent process from waiting for a given subprocess to exit, use the
subprocess.unref() method. Doing so will cause the parent's event loop to not
include the child process in its reference count, allowing the parent to exit
independently of the child, unless there is an established IPC channel between
the child and the parent processes.

const { spawn } = require('node:child_process');
const process = require('node:process');

const subprocess = spawn(process.argv[0], ['child_program.js'], {
  detached: true,
  stdio: 'ignore',
});

subprocess.unref();import { spawn } from 'node:child_process';
import process from 'node:process';

const subprocess = spawn(process.argv[0], ['child_program.js'], {
  detached: true,
  stdio: 'ignore',
});

subprocess.unref();copy

maxBuffer and Unicode#
The maxBuffer option specifies the largest number of bytes allowed on stdout
or stderr. If this value is exceeded, then the child process is terminated.
This impacts output that includes multibyte character encodings such as UTF-8 or
UTF-16. For instance, console.log('中文测试') will send 13 UTF-8 encoded bytes
to stdout although there are only 4 characters.
Shell requirements#
The shell should understand the -c switch. If the shell is 'cmd.exe', it
should understand the /d /s /c switches and command-line parsing should be
compatible.
Default Windows shell#
Although Microsoft specifies %COMSPEC% must contain the path to
'cmd.exe' in the root environment, child processes are not always subject to
the same requirement. Thus, in child_process functions where a shell can be
spawned, 'cmd.exe' is used as a fallback if process.env.ComSpec is
unavailable.
Advanced serialization#

Added in: v13.2.0, v12.16.0

Child processes support a serialization mechanism for IPC that is based on the
serialization API of the node:v8 module, based on the
HTML structured clone algorithm. This is generally more powerful and
supports more built-in JavaScript object types, such as BigInt, Map
and Set, ArrayBuffer and TypedArray, Buffer, Error, RegExp etc.
However, this format is not a full superset of JSON, and e.g. properties set on
objects of such built-in types will not be passed on through the serialization
step. Additionally, performance may not be equivalent to that of JSON, depending
on the structure of the passed data.
Therefore, this feature requires opting in by setting the
serialization option to 'advanced' when calling child_process.spawn()
or child_process.fork().\n\n\n\nNode.js
        
      
      
About this documentation
Usage and example



Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Modules: TypeScript
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
Readline
REPL
Report
Single executable applications
SQLite
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker

    

    
      
        
          Node.js v24.0.1 documentation
          
            
            
          
        
        
          
            Node.js v24.0.1
            
    
      
        
        Table of contents
      

      
Cluster

How it works
Class: Worker

Event: 'disconnect'
Event: 'error'
Event: 'exit'
Event: 'listening'
Event: 'message'
Event: 'online'
worker.disconnect()
worker.exitedAfterDisconnect
worker.id
worker.isConnected()
worker.isDead()
worker.kill([signal])
worker.process
worker.send(message[, sendHandle[, options]][, callback])


Event: 'disconnect'
Event: 'exit'
Event: 'fork'
Event: 'listening'
Event: 'message'
Event: 'online'
Event: 'setup'
cluster.disconnect([callback])
cluster.fork([env])
cluster.isMaster
cluster.isPrimary
cluster.isWorker
cluster.schedulingPolicy
cluster.settings
cluster.setupMaster([settings])
cluster.setupPrimary([settings])
cluster.worker
cluster.workers



    
  
            
    
      
        
        Index
      

      
About this documentation
Usage and example

      
        Index
      
    
  


Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Modules: TypeScript
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
Readline
REPL
Report
Single executable applications
SQLite
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker

    
  
            
    
      
        
        Other versions
      
      24.x
23.x
22.x LTS
21.x
20.x LTS
19.x
18.x
17.x
16.x
15.x
14.x
13.x
12.x
11.x
10.x
9.x
8.x
7.x
6.x
5.x
4.x
0.12.x
0.10.x
    
  
            
              
                
                Options
              
        
              
                
                  
                    View on single page
                  
                  
                    View as JSON
                  
                  Edit on GitHub    
                
              
            
          
        
        
      

      Table of contents
Cluster

How it works
Class: Worker

Event: 'disconnect'
Event: 'error'
Event: 'exit'
Event: 'listening'
Event: 'message'
Event: 'online'
worker.disconnect()
worker.exitedAfterDisconnect
worker.id
worker.isConnected()
worker.isDead()
worker.kill([signal])
worker.process
worker.send(message[, sendHandle[, options]][, callback])


Event: 'disconnect'
Event: 'exit'
Event: 'fork'
Event: 'listening'
Event: 'message'
Event: 'online'
Event: 'setup'
cluster.disconnect([callback])
cluster.fork([env])
cluster.isMaster
cluster.isPrimary
cluster.isWorker
cluster.schedulingPolicy
cluster.settings
cluster.setupMaster([settings])
cluster.setupPrimary([settings])
cluster.worker
cluster.workers




      
        Cluster#

Stability: 2 - Stable
Source Code: lib/cluster.js
Clusters of Node.js processes can be used to run multiple instances of Node.js
that can distribute workloads among their application threads. When process
isolation is not needed, use the worker_threads module instead, which
allows running multiple application threads within a single Node.js instance.
The cluster module allows easy creation of child processes that all share
server ports.

import cluster from 'node:cluster';
import http from 'node:http';
import { availableParallelism } from 'node:os';
import process from 'node:process';

const numCPUs = availableParallelism();

if (cluster.isPrimary) {
  console.log(`Primary ${process.pid} is running`);

  // Fork workers.
  for (let i = 0; i < numCPUs; i++) {
    cluster.fork();
  }

  cluster.on('exit', (worker, code, signal) => {
    console.log(`worker ${worker.process.pid} died`);
  });
} else {
  // Workers can share any TCP connection
  // In this case it is an HTTP server
  http.createServer((req, res) => {
    res.writeHead(200);
    res.end('hello world\n');
  }).listen(8000);

  console.log(`Worker ${process.pid} started`);
}const cluster = require('node:cluster');
const http = require('node:http');
const numCPUs = require('node:os').availableParallelism();
const process = require('node:process');

if (cluster.isPrimary) {
  console.log(`Primary ${process.pid} is running`);

  // Fork workers.
  for (let i = 0; i < numCPUs; i++) {
    cluster.fork();
  }

  cluster.on('exit', (worker, code, signal) => {
    console.log(`worker ${worker.process.pid} died`);
  });
} else {
  // Workers can share any TCP connection
  // In this case it is an HTTP server
  http.createServer((req, res) => {
    res.writeHead(200);
    res.end('hello world\n');
  }).listen(8000);

  console.log(`Worker ${process.pid} started`);
}copy
Running Node.js will now share port 8000 between the workers:
$ node server.js
Primary 3596 is running
Worker 4324 started
Worker 4520 started
Worker 6056 started
Worker 5644 started copy
On Windows, it is not yet possible to set up a named pipe server in a worker.
How it works#

The worker processes are spawned using the child_process.fork() method,
so that they can communicate with the parent via IPC and pass server
handles back and forth.
The cluster module supports two methods of distributing incoming
connections.
The first one (and the default one on all platforms except Windows)
is the round-robin approach, where the primary process listens on a
port, accepts new connections and distributes them across the workers
in a round-robin fashion, with some built-in smarts to avoid
overloading a worker process.
The second approach is where the primary process creates the listen
socket and sends it to interested workers. The workers then accept
incoming connections directly.
The second approach should, in theory, give the best performance.
In practice however, distribution tends to be very unbalanced due
to operating system scheduler vagaries. Loads have been observed
where over 70% of all connections ended up in just two processes,
out of a total of eight.
Because server.listen() hands off most of the work to the primary
process, there are three cases where the behavior between a normal
Node.js process and a cluster worker differs:

server.listen({fd: 7}) Because the message is passed to the primary,
file descriptor 7 in the parent will be listened on, and the
handle passed to the worker, rather than listening to the worker's
idea of what the number 7 file descriptor references.
server.listen(handle) Listening on handles explicitly will cause
the worker to use the supplied handle, rather than talk to the primary
process.
server.listen(0) Normally, this will cause servers to listen on a
random port. However, in a cluster, each worker will receive the
same "random" port each time they do listen(0). In essence, the
port is random the first time, but predictable thereafter. To listen
on a unique port, generate a port number based on the cluster worker ID.

Node.js does not provide routing logic. It is therefore important to design an
application such that it does not rely too heavily on in-memory data objects for
things like sessions and login.
Because workers are all separate processes, they can be killed or
re-spawned depending on a program's needs, without affecting other
workers. As long as there are some workers still alive, the server will
continue to accept connections. If no workers are alive, existing connections
will be dropped and new connections will be refused. Node.js does not
automatically manage the number of workers, however. It is the application's
responsibility to manage the worker pool based on its own needs.
Although a primary use case for the node:cluster module is networking, it can
also be used for other use cases requiring worker processes.
Class: Worker#

Added in: v0.7.0


Extends: <EventEmitter>

A Worker object contains all public information and method about a worker.
In the primary it can be obtained using cluster.workers. In a worker
it can be obtained using cluster.worker.

Event: 'disconnect'#

Added in: v0.7.7

Similar to the cluster.on('disconnect') event, but specific to this worker.
cluster.fork().on('disconnect', () => {
  // Worker has disconnected
}); copy

Event: 'error'#

Added in: v0.7.3

This event is the same as the one provided by child_process.fork().
Within a worker, process.on('error') may also be used.

Event: 'exit'#

Added in: v0.11.2


code <number> The exit code, if it exited normally.
signal <string> The name of the signal (e.g. 'SIGHUP') that caused
the process to be killed.

Similar to the cluster.on('exit') event, but specific to this worker.

import cluster from 'node:cluster';

if (cluster.isPrimary) {
  const worker = cluster.fork();
  worker.on('exit', (code, signal) => {
    if (signal) {
      console.log(`worker was killed by signal: ${signal}`);
    } else if (code !== 0) {
      console.log(`worker exited with error code: ${code}`);
    } else {
      console.log('worker success!');
    }
  });
}const cluster = require('node:cluster');

if (cluster.isPrimary) {
  const worker = cluster.fork();
  worker.on('exit', (code, signal) => {
    if (signal) {
      console.log(`worker was killed by signal: ${signal}`);
    } else if (code !== 0) {
      console.log(`worker exited with error code: ${code}`);
    } else {
      console.log('worker success!');
    }
  });
}copy

Event: 'listening'#

Added in: v0.7.0


address <Object>

Similar to the cluster.on('listening') event, but specific to this worker.

cluster.fork().on('listening', (address) => {
  // Worker is listening
});cluster.fork().on('listening', (address) => {
  // Worker is listening
});copy
It is not emitted in the worker.

Event: 'message'#

Added in: v0.7.0


message <Object>
handle <undefined> | <Object>

Similar to the 'message' event of cluster, but specific to this worker.
Within a worker, process.on('message') may also be used.
See process event: 'message'.
Here is an example using the message system. It keeps a count in the primary
process of the number of HTTP requests received by the workers:

import cluster from 'node:cluster';
import http from 'node:http';
import { availableParallelism } from 'node:os';
import process from 'node:process';

if (cluster.isPrimary) {

  // Keep track of http requests
  let numReqs = 0;
  setInterval(() => {
    console.log(`numReqs = ${numReqs}`);
  }, 1000);

  // Count requests
  function messageHandler(msg) {
    if (msg.cmd && msg.cmd === 'notifyRequest') {
      numReqs += 1;
    }
  }

  // Start workers and listen for messages containing notifyRequest
  const numCPUs = availableParallelism();
  for (let i = 0; i < numCPUs; i++) {
    cluster.fork();
  }

  for (const id in cluster.workers) {
    cluster.workers[id].on('message', messageHandler);
  }

} else {

  // Worker processes have a http server.
  http.Server((req, res) => {
    res.writeHead(200);
    res.end('hello world\n');

    // Notify primary about the request
    process.send({ cmd: 'notifyRequest' });
  }).listen(8000);
}const cluster = require('node:cluster');
const http = require('node:http');
const numCPUs = require('node:os').availableParallelism();
const process = require('node:process');

if (cluster.isPrimary) {

  // Keep track of http requests
  let numReqs = 0;
  setInterval(() => {
    console.log(`numReqs = ${numReqs}`);
  }, 1000);

  // Count requests
  function messageHandler(msg) {
    if (msg.cmd && msg.cmd === 'notifyRequest') {
      numReqs += 1;
    }
  }

  // Start workers and listen for messages containing notifyRequest
  for (let i = 0; i < numCPUs; i++) {
    cluster.fork();
  }

  for (const id in cluster.workers) {
    cluster.workers[id].on('message', messageHandler);
  }

} else {

  // Worker processes have a http server.
  http.Server((req, res) => {
    res.writeHead(200);
    res.end('hello world\n');

    // Notify primary about the request
    process.send({ cmd: 'notifyRequest' });
  }).listen(8000);
}copy

Event: 'online'#

Added in: v0.7.0

Similar to the cluster.on('online') event, but specific to this worker.
cluster.fork().on('online', () => {
  // Worker is online
}); copy
It is not emitted in the worker.

worker.disconnect()#

History

VersionChanges
v7.3.0
This method now returns a reference to worker.
v0.7.7
Added in: v0.7.7




Returns: <cluster.Worker> A reference to worker.

In a worker, this function will close all servers, wait for the 'close' event
on those servers, and then disconnect the IPC channel.
In the primary, an internal message is sent to the worker causing it to call
.disconnect() on itself.
Causes .exitedAfterDisconnect to be set.
After a server is closed, it will no longer accept new connections,
but connections may be accepted by any other listening worker. Existing
connections will be allowed to close as usual. When no more connections exist,
see server.close(), the IPC channel to the worker will close allowing it
to die gracefully.
The above applies only to server connections, client connections are not
automatically closed by workers, and disconnect does not wait for them to close
before exiting.
In a worker, process.disconnect exists, but it is not this function;
it is disconnect().
Because long living server connections may block workers from disconnecting, it
may be useful to send a message, so application specific actions may be taken to
close them. It also may be useful to implement a timeout, killing a worker if
the 'disconnect' event has not been emitted after some time.
if (cluster.isPrimary) {
  const worker = cluster.fork();
  let timeout;

  worker.on('listening', (address) => {
    worker.send('shutdown');
    worker.disconnect();
    timeout = setTimeout(() => {
      worker.kill();
    }, 2000);
  });

  worker.on('disconnect', () => {
    clearTimeout(timeout);
  });

} else if (cluster.isWorker) {
  const net = require('node:net');
  const server = net.createServer((socket) => {
    // Connections never end
  });

  server.listen(8000);

  process.on('message', (msg) => {
    if (msg === 'shutdown') {
      // Initiate graceful close of any connections to server
    }
  });
} copy

worker.exitedAfterDisconnect#

Added in: v6.0.0


<boolean>

This property is true if the worker exited due to .disconnect().
If the worker exited any other way, it is false. If the
worker has not exited, it is undefined.
The boolean worker.exitedAfterDisconnect allows distinguishing between
voluntary and accidental exit, the primary may choose not to respawn a worker
based on this value.
cluster.on('exit', (worker, code, signal) => {
  if (worker.exitedAfterDisconnect === true) {
    console.log('Oh, it was just voluntary – no need to worry');
  }
});

// kill worker
worker.kill(); copy

worker.id#

Added in: v0.8.0


<integer>

Each new worker is given its own unique id, this id is stored in the
id.
While a worker is alive, this is the key that indexes it in
cluster.workers.

worker.isConnected()#

Added in: v0.11.14

This function returns true if the worker is connected to its primary via its
IPC channel, false otherwise. A worker is connected to its primary after it
has been created. It is disconnected after the 'disconnect' event is emitted.

worker.isDead()#

Added in: v0.11.14

This function returns true if the worker's process has terminated (either
because of exiting or being signaled). Otherwise, it returns false.

import cluster from 'node:cluster';
import http from 'node:http';
import { availableParallelism } from 'node:os';
import process from 'node:process';

const numCPUs = availableParallelism();

if (cluster.isPrimary) {
  console.log(`Primary ${process.pid} is running`);

  // Fork workers.
  for (let i = 0; i < numCPUs; i++) {
    cluster.fork();
  }

  cluster.on('fork', (worker) => {
    console.log('worker is dead:', worker.isDead());
  });

  cluster.on('exit', (worker, code, signal) => {
    console.log('worker is dead:', worker.isDead());
  });
} else {
  // Workers can share any TCP connection. In this case, it is an HTTP server.
  http.createServer((req, res) => {
    res.writeHead(200);
    res.end(`Current process\n ${process.pid}`);
    process.kill(process.pid);
  }).listen(8000);
}const cluster = require('node:cluster');
const http = require('node:http');
const numCPUs = require('node:os').availableParallelism();
const process = require('node:process');

if (cluster.isPrimary) {
  console.log(`Primary ${process.pid} is running`);

  // Fork workers.
  for (let i = 0; i < numCPUs; i++) {
    cluster.fork();
  }

  cluster.on('fork', (worker) => {
    console.log('worker is dead:', worker.isDead());
  });

  cluster.on('exit', (worker, code, signal) => {
    console.log('worker is dead:', worker.isDead());
  });
} else {
  // Workers can share any TCP connection. In this case, it is an HTTP server.
  http.createServer((req, res) => {
    res.writeHead(200);
    res.end(`Current process\n ${process.pid}`);
    process.kill(process.pid);
  }).listen(8000);
}copy

worker.kill([signal])#

Added in: v0.9.12


signal <string> Name of the kill signal to send to the worker
process. Default: 'SIGTERM'

This function will kill the worker. In the primary worker, it does this by
disconnecting the worker.process, and once disconnected, killing with
signal. In the worker, it does it by killing the process with signal.
The kill() function kills the worker process without waiting for a graceful
disconnect, it has the same behavior as worker.process.kill().
This method is aliased as worker.destroy() for backwards compatibility.
In a worker, process.kill() exists, but it is not this function;
it is kill().

worker.process#

Added in: v0.7.0


<ChildProcess>

All workers are created using child_process.fork(), the returned object
from this function is stored as .process. In a worker, the global process
is stored.
See: Child Process module.
Workers will call process.exit(0) if the 'disconnect' event occurs
on process and .exitedAfterDisconnect is not true. This protects against
accidental disconnection.

worker.send(message[, sendHandle[, options]][, callback])#

History

VersionChanges
v4.0.0
The callback parameter is supported now.
v0.7.0
Added in: v0.7.0




message <Object>
sendHandle <Handle>
options <Object> The options argument, if present, is an object used to
parameterize the sending of certain types of handles. options supports
the following properties:

keepOpen <boolean> A value that can be used when passing instances of
net.Socket. When true, the socket is kept open in the sending process.
Default: false.


callback <Function>
Returns: <boolean>

Send a message to a worker or primary, optionally with a handle.
In the primary, this sends a message to a specific worker. It is identical to
ChildProcess.send().
In a worker, this sends a message to the primary. It is identical to
process.send().
This example will echo back all messages from the primary:
if (cluster.isPrimary) {
  const worker = cluster.fork();
  worker.send('hi there');

} else if (cluster.isWorker) {
  process.on('message', (msg) => {
    process.send(msg);
  });
} copy

Event: 'disconnect'#

Added in: v0.7.9


worker <cluster.Worker>

Emitted after the worker IPC channel has disconnected. This can occur when a
worker exits gracefully, is killed, or is disconnected manually (such as with
worker.disconnect()).
There may be a delay between the 'disconnect' and 'exit' events. These
events can be used to detect if the process is stuck in a cleanup or if there
are long-living connections.
cluster.on('disconnect', (worker) => {
  console.log(`The worker #${worker.id} has disconnected`);
}); copy
Event: 'exit'#

Added in: v0.7.9


worker <cluster.Worker>
code <number> The exit code, if it exited normally.
signal <string> The name of the signal (e.g. 'SIGHUP') that caused
the process to be killed.

When any of the workers die the cluster module will emit the 'exit' event.
This can be used to restart the worker by calling .fork() again.
cluster.on('exit', (worker, code, signal) => {
  console.log('worker %d died (%s). restarting...',
              worker.process.pid, signal || code);
  cluster.fork();
}); copy
See child_process event: 'exit'.
Event: 'fork'#

Added in: v0.7.0


worker <cluster.Worker>

When a new worker is forked the cluster module will emit a 'fork' event.
This can be used to log worker activity, and create a custom timeout.
const timeouts = [];
function errorMsg() {
  console.error('Something must be wrong with the connection ...');
}

cluster.on('fork', (worker) => {
  timeouts[worker.id] = setTimeout(errorMsg, 2000);
});
cluster.on('listening', (worker, address) => {
  clearTimeout(timeouts[worker.id]);
});
cluster.on('exit', (worker, code, signal) => {
  clearTimeout(timeouts[worker.id]);
  errorMsg();
}); copy
Event: 'listening'#

Added in: v0.7.0


worker <cluster.Worker>
address <Object>

After calling listen() from a worker, when the 'listening' event is emitted
on the server, a 'listening' event will also be emitted on cluster in the
primary.
The event handler is executed with two arguments, the worker contains the
worker object and the address object contains the following connection
properties: address, port, and addressType. This is very useful if the
worker is listening on more than one address.
cluster.on('listening', (worker, address) => {
  console.log(
    `A worker is now connected to ${address.address}:${address.port}`);
}); copy
The addressType is one of:

4 (TCPv4)
6 (TCPv6)
-1 (Unix domain socket)
'udp4' or 'udp6' (UDPv4 or UDPv6)

Event: 'message'#

History

VersionChanges
v6.0.0
The worker parameter is passed now; see below for details.
v2.5.0
Added in: v2.5.0




worker <cluster.Worker>
message <Object>
handle <undefined> | <Object>

Emitted when the cluster primary receives a message from any worker.
See child_process event: 'message'.
Event: 'online'#

Added in: v0.7.0


worker <cluster.Worker>

After forking a new worker, the worker should respond with an online message.
When the primary receives an online message it will emit this event.
The difference between 'fork' and 'online' is that fork is emitted when the
primary forks a worker, and 'online' is emitted when the worker is running.
cluster.on('online', (worker) => {
  console.log('Yay, the worker responded after it was forked');
}); copy
Event: 'setup'#

Added in: v0.7.1


settings <Object>

Emitted every time .setupPrimary() is called.
The settings object is the cluster.settings object at the time
.setupPrimary() was called and is advisory only, since multiple calls to
.setupPrimary() can be made in a single tick.
If accuracy is important, use cluster.settings.
cluster.disconnect([callback])#

Added in: v0.7.7


callback <Function> Called when all workers are disconnected and handles are
closed.

Calls .disconnect() on each worker in cluster.workers.
When they are disconnected all internal handles will be closed, allowing the
primary process to die gracefully if no other event is waiting.
The method takes an optional callback argument which will be called when
finished.
This can only be called from the primary process.
cluster.fork([env])#

Added in: v0.6.0


env <Object> Key/value pairs to add to worker process environment.
Returns: <cluster.Worker>

Spawn a new worker process.
This can only be called from the primary process.
cluster.isMaster#

Added in: v0.8.1Deprecated since: v16.0.0

Stability: 0 - Deprecated
Deprecated alias for cluster.isPrimary.
cluster.isPrimary#

Added in: v16.0.0


<boolean>

True if the process is a primary. This is determined
by the process.env.NODE_UNIQUE_ID. If process.env.NODE_UNIQUE_ID is
undefined, then isPrimary is true.
cluster.isWorker#

Added in: v0.6.0


<boolean>

True if the process is not a primary (it is the negation of cluster.isPrimary).
cluster.schedulingPolicy#

Added in: v0.11.2

The scheduling policy, either cluster.SCHED_RR for round-robin or
cluster.SCHED_NONE to leave it to the operating system. This is a
global setting and effectively frozen once either the first worker is spawned,
or .setupPrimary() is called, whichever comes first.
SCHED_RR is the default on all operating systems except Windows.
Windows will change to SCHED_RR once libuv is able to effectively
distribute IOCP handles without incurring a large performance hit.
cluster.schedulingPolicy can also be set through the
NODE_CLUSTER_SCHED_POLICY environment variable. Valid
values are 'rr' and 'none'.
cluster.settings#

History

VersionChanges
v13.2.0, v12.16.0
The serialization option is supported now.
v9.5.0
The cwd option is supported now.
v9.4.0
The windowsHide option is supported now.
v8.2.0
The inspectPort option is supported now.
v6.4.0
The stdio option is supported now.
v0.7.1
Added in: v0.7.1




<Object>

execArgv <string[]> List of string arguments passed to the Node.js
executable. Default: process.execArgv.
exec <string> File path to worker file. Default: process.argv[1].
args <string[]> String arguments passed to worker.
Default: process.argv.slice(2).
cwd <string> Current working directory of the worker process. Default:
undefined (inherits from parent process).
serialization <string> Specify the kind of serialization used for sending
messages between processes. Possible values are 'json' and 'advanced'.
See Advanced serialization for child_process for more details.
Default: false.
silent <boolean> Whether or not to send output to parent's stdio.
Default: false.
stdio <Array> Configures the stdio of forked processes. Because the
cluster module relies on IPC to function, this configuration must contain an
'ipc' entry. When this option is provided, it overrides silent. See
child_process.spawn()'s stdio.
uid <number> Sets the user identity of the process. (See setuid(2).)
gid <number> Sets the group identity of the process. (See setgid(2).)
inspectPort <number> | <Function> Sets inspector port of worker.
This can be a number, or a function that takes no arguments and returns a
number. By default each worker gets its own port, incremented from the
primary's process.debugPort.
windowsHide <boolean> Hide the forked processes console window that would
normally be created on Windows systems. Default: false.



After calling .setupPrimary() (or .fork()) this settings object will
contain the settings, including the default values.
This object is not intended to be changed or set manually.
cluster.setupMaster([settings])#

History

VersionChanges
v16.0.0
Deprecated since: v16.0.0
v6.4.0
The stdio option is supported now.
v0.7.1
Added in: v0.7.1



Stability: 0 - Deprecated
Deprecated alias for .setupPrimary().
cluster.setupPrimary([settings])#

Added in: v16.0.0


settings <Object> See cluster.settings.

setupPrimary is used to change the default 'fork' behavior. Once called,
the settings will be present in cluster.settings.
Any settings changes only affect future calls to .fork() and have no
effect on workers that are already running.
The only attribute of a worker that cannot be set via .setupPrimary() is
the env passed to .fork().
The defaults above apply to the first call only; the defaults for later
calls are the current values at the time of cluster.setupPrimary() is called.

import cluster from 'node:cluster';

cluster.setupPrimary({
  exec: 'worker.js',
  args: ['--use', 'https'],
  silent: true,
});
cluster.fork(); // https worker
cluster.setupPrimary({
  exec: 'worker.js',
  args: ['--use', 'http'],
});
cluster.fork(); // http workerconst cluster = require('node:cluster');

cluster.setupPrimary({
  exec: 'worker.js',
  args: ['--use', 'https'],
  silent: true,
});
cluster.fork(); // https worker
cluster.setupPrimary({
  exec: 'worker.js',
  args: ['--use', 'http'],
});
cluster.fork(); // http workercopy
This can only be called from the primary process.
cluster.worker#

Added in: v0.7.0


<Object>

A reference to the current worker object. Not available in the primary process.

import cluster from 'node:cluster';

if (cluster.isPrimary) {
  console.log('I am primary');
  cluster.fork();
  cluster.fork();
} else if (cluster.isWorker) {
  console.log(`I am worker #${cluster.worker.id}`);
}const cluster = require('node:cluster');

if (cluster.isPrimary) {
  console.log('I am primary');
  cluster.fork();
  cluster.fork();
} else if (cluster.isWorker) {
  console.log(`I am worker #${cluster.worker.id}`);
}copy
cluster.workers#

Added in: v0.7.0


<Object>

A hash that stores the active worker objects, keyed by id field. This makes it
easy to loop through all the workers. It is only available in the primary
process.
A worker is removed from cluster.workers after the worker has disconnected
and exited. The order between these two events cannot be determined in
advance. However, it is guaranteed that the removal from the cluster.workers
list happens before the last 'disconnect' or 'exit' event is emitted.

import cluster from 'node:cluster';

for (const worker of Object.values(cluster.workers)) {
  worker.send('big announcement to all workers');
}const cluster = require('node:cluster');

for (const worker of Object.values(cluster.workers)) {
  worker.send('big announcement to all workers');
}copy\n\n\n\nNode.js
        
      
      
About this documentation
Usage and example



Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Modules: TypeScript
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
Readline
REPL
Report
Single executable applications
SQLite
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker

    

    
      
        
          Node.js v24.0.1 documentation
          
            
            
          
        
        
          
            Node.js v24.0.1
            
    
      
        
        Table of contents
      

      
Command-line API

Synopsis
Program entry point

ECMAScript modules loader entry point caveat


Options

-
--
--abort-on-uncaught-exception
--allow-addons
--allow-child-process
--allow-fs-read
--allow-fs-write
--allow-wasi
--allow-worker
--build-snapshot
--build-snapshot-config
-c, --check
--completion-bash
-C condition, --conditions=condition
--cpu-prof
--cpu-prof-dir
--cpu-prof-interval
--cpu-prof-name
--diagnostic-dir=directory
--disable-proto=mode
--disable-sigusr1
--disable-warning=code-or-type
--disable-wasm-trap-handler
--disallow-code-generation-from-strings
--dns-result-order=order
--enable-fips
--enable-network-family-autoselection
--enable-source-maps
--entry-url
--env-file-if-exists=config
--env-file=config
-e, --eval "script"
--experimental-addon-modules
--experimental-config-file=config
--experimental-default-config-file
--experimental-eventsource
--experimental-import-meta-resolve
--experimental-loader=module
--experimental-network-inspection
--experimental-print-required-tla
--experimental-require-module
--experimental-sea-config
--experimental-shadow-realm
--experimental-test-coverage
--experimental-test-module-mocks
--experimental-transform-types
--experimental-vm-modules
--experimental-wasi-unstable-preview1
--experimental-wasm-modules
--experimental-webstorage
--expose-gc
--force-context-aware
--force-fips
--force-node-api-uncaught-exceptions-policy
--frozen-intrinsics
--heap-prof
--heap-prof-dir
--heap-prof-interval
--heap-prof-name
--heapsnapshot-near-heap-limit=max_count
--heapsnapshot-signal=signal
-h, --help
--icu-data-dir=file
--import=module
--input-type=type
--insecure-http-parser

Warning: binding inspector to a public IP:port combination is insecure


--inspect-brk[=[host:]port]
--inspect-port=[host:]port
--inspect-publish-uid=stderr,http
--inspect-wait[=[host:]port]
--inspect[=[host:]port]
-i, --interactive
--jitless
--localstorage-file=file
--max-http-header-size=size
--napi-modules
--network-family-autoselection-attempt-timeout
--no-addons
--no-async-context-frame
--no-deprecation
--no-experimental-detect-module
--no-experimental-global-navigator
--no-experimental-repl-await
--no-experimental-require-module
--no-experimental-sqlite
--no-experimental-strip-types
--no-experimental-websocket
--no-extra-info-on-fatal-exception
--no-force-async-hooks-checks
--no-global-search-paths
--no-network-family-autoselection
--no-warnings
--node-memory-debug
--openssl-config=file
--openssl-legacy-provider
--openssl-shared-config
--pending-deprecation
--permission
--preserve-symlinks
--preserve-symlinks-main
-p, --print "script"
--prof
--prof-process
--redirect-warnings=file
--report-compact
--report-dir=directory, report-directory=directory
--report-exclude-env
--report-exclude-network
--report-filename=filename
--report-on-fatalerror
--report-on-signal
--report-signal=signal
--report-uncaught-exception
-r, --require module
--run

Intentional limitations
Environment variables


--secure-heap-min=n
--secure-heap=n
--snapshot-blob=path
--test
--test-concurrency
--test-coverage-branches=threshold
--test-coverage-exclude
--test-coverage-functions=threshold
--test-coverage-include
--test-coverage-lines=threshold
--test-force-exit
--test-global-setup=module
--test-isolation=mode
--test-name-pattern
--test-only
--test-reporter
--test-reporter-destination
--test-shard
--test-skip-pattern
--test-timeout
--test-update-snapshots
--throw-deprecation
--title=title
--tls-cipher-list=list
--tls-keylog=file
--tls-max-v1.2
--tls-max-v1.3
--tls-min-v1.0
--tls-min-v1.1
--tls-min-v1.2
--tls-min-v1.3
--trace-deprecation
--trace-env
--trace-env-js-stack
--trace-env-native-stack
--trace-event-categories
--trace-event-file-pattern
--trace-events-enabled
--trace-exit
--trace-require-module=mode
--trace-sigint
--trace-sync-io
--trace-tls
--trace-uncaught
--trace-warnings
--track-heap-objects
--unhandled-rejections=mode
--use-bundled-ca, --use-openssl-ca
--use-largepages=mode
--use-system-ca
--v8-options
--v8-pool-size=num
-v, --version
--watch
--watch-path
--watch-preserve-output
--zero-fill-buffers


Environment variables

FORCE_COLOR=[1, 2, 3]
NODE_COMPILE_CACHE=dir
NODE_DEBUG=module[,…]
NODE_DEBUG_NATIVE=module[,…]
NODE_DISABLE_COLORS=1
NODE_DISABLE_COMPILE_CACHE=1
NODE_EXTRA_CA_CERTS=file
NODE_ICU_DATA=file
NODE_NO_WARNINGS=1
NODE_OPTIONS=options...
NODE_PATH=path[:…]
NODE_PENDING_DEPRECATION=1
NODE_PENDING_PIPE_INSTANCES=instances
NODE_PRESERVE_SYMLINKS=1
NODE_REDIRECT_WARNINGS=file
NODE_REPL_EXTERNAL_MODULE=file
NODE_REPL_HISTORY=file
NODE_SKIP_PLATFORM_CHECK=value
NODE_TEST_CONTEXT=value
NODE_TLS_REJECT_UNAUTHORIZED=value
NODE_USE_ENV_PROXY=1
NODE_V8_COVERAGE=dir

Coverage output
Source map cache


NO_COLOR=<any>
OPENSSL_CONF=file
SSL_CERT_DIR=dir
SSL_CERT_FILE=file
TZ
UV_THREADPOOL_SIZE=size


Useful V8 options

--abort-on-uncaught-exception
--disallow-code-generation-from-strings
--enable-etw-stack-walking
--expose-gc
--harmony-shadow-realm
--interpreted-frames-native-stack
--jitless
--max-old-space-size=SIZE (in MiB)
--max-semi-space-size=SIZE (in MiB)
--perf-basic-prof
--perf-basic-prof-only-functions
--perf-prof
--perf-prof-unwinding-info
--prof
--security-revert
--stack-trace-limit=limit





    
  
            
    
      
        
        Index
      

      
About this documentation
Usage and example

      
        Index
      
    
  


Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Modules: TypeScript
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
Readline
REPL
Report
Single executable applications
SQLite
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker

    
  
            
    
      
        
        Other versions
      
      24.x
23.x
22.x LTS
21.x
20.x LTS
19.x
18.x
17.x
16.x
15.x
14.x
13.x
12.x
11.x
10.x
9.x
8.x
7.x
6.x
5.x
    
  
            
              
                
                Options
              
        
              
                
                  
                    View on single page
                  
                  
                    View as JSON
                  
                  Edit on GitHub    
                
              
            
          
        
        
      

      Table of contents
Command-line API

Synopsis
Program entry point

ECMAScript modules loader entry point caveat


Options

-
--
--abort-on-uncaught-exception
--allow-addons
--allow-child-process
--allow-fs-read
--allow-fs-write
--allow-wasi
--allow-worker
--build-snapshot
--build-snapshot-config
-c, --check
--completion-bash
-C condition, --conditions=condition
--cpu-prof
--cpu-prof-dir
--cpu-prof-interval
--cpu-prof-name
--diagnostic-dir=directory
--disable-proto=mode
--disable-sigusr1
--disable-warning=code-or-type
--disable-wasm-trap-handler
--disallow-code-generation-from-strings
--dns-result-order=order
--enable-fips
--enable-network-family-autoselection
--enable-source-maps
--entry-url
--env-file-if-exists=config
--env-file=config
-e, --eval "script"
--experimental-addon-modules
--experimental-config-file=config
--experimental-default-config-file
--experimental-eventsource
--experimental-import-meta-resolve
--experimental-loader=module
--experimental-network-inspection
--experimental-print-required-tla
--experimental-require-module
--experimental-sea-config
--experimental-shadow-realm
--experimental-test-coverage
--experimental-test-module-mocks
--experimental-transform-types
--experimental-vm-modules
--experimental-wasi-unstable-preview1
--experimental-wasm-modules
--experimental-webstorage
--expose-gc
--force-context-aware
--force-fips
--force-node-api-uncaught-exceptions-policy
--frozen-intrinsics
--heap-prof
--heap-prof-dir
--heap-prof-interval
--heap-prof-name
--heapsnapshot-near-heap-limit=max_count
--heapsnapshot-signal=signal
-h, --help
--icu-data-dir=file
--import=module
--input-type=type
--insecure-http-parser

Warning: binding inspector to a public IP:port combination is insecure


--inspect-brk[=[host:]port]
--inspect-port=[host:]port
--inspect-publish-uid=stderr,http
--inspect-wait[=[host:]port]
--inspect[=[host:]port]
-i, --interactive
--jitless
--localstorage-file=file
--max-http-header-size=size
--napi-modules
--network-family-autoselection-attempt-timeout
--no-addons
--no-async-context-frame
--no-deprecation
--no-experimental-detect-module
--no-experimental-global-navigator
--no-experimental-repl-await
--no-experimental-require-module
--no-experimental-sqlite
--no-experimental-strip-types
--no-experimental-websocket
--no-extra-info-on-fatal-exception
--no-force-async-hooks-checks
--no-global-search-paths
--no-network-family-autoselection
--no-warnings
--node-memory-debug
--openssl-config=file
--openssl-legacy-provider
--openssl-shared-config
--pending-deprecation
--permission
--preserve-symlinks
--preserve-symlinks-main
-p, --print "script"
--prof
--prof-process
--redirect-warnings=file
--report-compact
--report-dir=directory, report-directory=directory
--report-exclude-env
--report-exclude-network
--report-filename=filename
--report-on-fatalerror
--report-on-signal
--report-signal=signal
--report-uncaught-exception
-r, --require module
--run

Intentional limitations
Environment variables


--secure-heap-min=n
--secure-heap=n
--snapshot-blob=path
--test
--test-concurrency
--test-coverage-branches=threshold
--test-coverage-exclude
--test-coverage-functions=threshold
--test-coverage-include
--test-coverage-lines=threshold
--test-force-exit
--test-global-setup=module
--test-isolation=mode
--test-name-pattern
--test-only
--test-reporter
--test-reporter-destination
--test-shard
--test-skip-pattern
--test-timeout
--test-update-snapshots
--throw-deprecation
--title=title
--tls-cipher-list=list
--tls-keylog=file
--tls-max-v1.2
--tls-max-v1.3
--tls-min-v1.0
--tls-min-v1.1
--tls-min-v1.2
--tls-min-v1.3
--trace-deprecation
--trace-env
--trace-env-js-stack
--trace-env-native-stack
--trace-event-categories
--trace-event-file-pattern
--trace-events-enabled
--trace-exit
--trace-require-module=mode
--trace-sigint
--trace-sync-io
--trace-tls
--trace-uncaught
--trace-warnings
--track-heap-objects
--unhandled-rejections=mode
--use-bundled-ca, --use-openssl-ca
--use-largepages=mode
--use-system-ca
--v8-options
--v8-pool-size=num
-v, --version
--watch
--watch-path
--watch-preserve-output
--zero-fill-buffers


Environment variables

FORCE_COLOR=[1, 2, 3]
NODE_COMPILE_CACHE=dir
NODE_DEBUG=module[,…]
NODE_DEBUG_NATIVE=module[,…]
NODE_DISABLE_COLORS=1
NODE_DISABLE_COMPILE_CACHE=1
NODE_EXTRA_CA_CERTS=file
NODE_ICU_DATA=file
NODE_NO_WARNINGS=1
NODE_OPTIONS=options...
NODE_PATH=path[:…]
NODE_PENDING_DEPRECATION=1
NODE_PENDING_PIPE_INSTANCES=instances
NODE_PRESERVE_SYMLINKS=1
NODE_REDIRECT_WARNINGS=file
NODE_REPL_EXTERNAL_MODULE=file
NODE_REPL_HISTORY=file
NODE_SKIP_PLATFORM_CHECK=value
NODE_TEST_CONTEXT=value
NODE_TLS_REJECT_UNAUTHORIZED=value
NODE_USE_ENV_PROXY=1
NODE_V8_COVERAGE=dir

Coverage output
Source map cache


NO_COLOR=<any>
OPENSSL_CONF=file
SSL_CERT_DIR=dir
SSL_CERT_FILE=file
TZ
UV_THREADPOOL_SIZE=size


Useful V8 options

--abort-on-uncaught-exception
--disallow-code-generation-from-strings
--enable-etw-stack-walking
--expose-gc
--harmony-shadow-realm
--interpreted-frames-native-stack
--jitless
--max-old-space-size=SIZE (in MiB)
--max-semi-space-size=SIZE (in MiB)
--perf-basic-prof
--perf-basic-prof-only-functions
--perf-prof
--perf-prof-unwinding-info
--prof
--security-revert
--stack-trace-limit=limit






      
        Command-line API#


Node.js comes with a variety of CLI options. These options expose built-in
debugging, multiple ways to execute scripts, and other helpful runtime options.
To view this documentation as a manual page in a terminal, run man node.
Synopsis#
node [options] [V8 options] [<program-entry-point> | -e "script" | -] [--] [arguments]
node inspect [<program-entry-point> | -e "script" | <host>:<port>] …
node --v8-options
Execute without arguments to start the REPL.
For more info about node inspect, see the debugger documentation.
Program entry point#
The program entry point is a specifier-like string. If the string is not an
absolute path, it's resolved as a relative path from the current working
directory. That path is then resolved by CommonJS module loader. If no
corresponding file is found, an error is thrown.
If a file is found, its path will be passed to the
ES module loader under any of the following conditions:

The program was started with a command-line flag that forces the entry
point to be loaded with ECMAScript module loader, such as --import.
The file has an .mjs or .wasm (with --experimental-wasm-modules)
extension.
The file does not have a .cjs extension, and the nearest parent
package.json file contains a top-level "type" field with a value of
"module".

Otherwise, the file is loaded using the CommonJS module loader. See
Modules loaders for more details.

ECMAScript modules loader entry point caveat#
When loading, the ES module loader loads the program
entry point, the node command will accept as input only files with .js,
.mjs, or .cjs extensions. With the following flags, additional file
extensions are enabled:

--experimental-wasm-modules for files with .wasm extension.
--experimental-addon-modules for files with .node extension.


Options#

History

VersionChanges
v10.12.0
Underscores instead of dashes are now allowed for Node.js options as well, in addition to V8 options.



Stability: 2 - Stable
All options, including V8 options, allow words to be separated by both
dashes (-) or underscores (_). For example, --pending-deprecation is
equivalent to --pending_deprecation.
If an option that takes a single value (such as --max-http-header-size) is
passed more than once, then the last passed value is used. Options from the
command line take precedence over options passed through the NODE_OPTIONS
environment variable.

-#

Added in: v8.0.0

Alias for stdin. Analogous to the use of - in other command-line utilities,
meaning that the script is read from stdin, and the rest of the options
are passed to that script.

--#

Added in: v6.11.0

Indicate the end of node options. Pass the rest of the arguments to the script.
If no script filename or eval/print script is supplied prior to this, then
the next argument is used as a script filename.

--abort-on-uncaught-exception#

Added in: v0.10.8

Aborting instead of exiting causes a core file to be generated for post-mortem
analysis using a debugger (such as lldb, gdb, and mdb).
If this flag is passed, the behavior can still be set to not abort through
process.setUncaughtExceptionCaptureCallback() (and through usage of the
node:domain module that uses it).

--allow-addons#

Added in: v21.6.0, v20.12.0

Stability: 1.1 - Active development
When using the Permission Model, the process will not be able to use
native addons by default.
Attempts to do so will throw an ERR_DLOPEN_DISABLED unless the
user explicitly passes the --allow-addons flag when starting Node.js.
Example:
// Attempt to require an native addon
require('nodejs-addon-example'); copy
$ node --permission --allow-fs-read=* index.js
node:internal/modules/cjs/loader:1319
  return process.dlopen(module, path.toNamespacedPath(filename));
                 ^

Error: Cannot load native addon because loading addons is disabled.
    at Module._extensions..node (node:internal/modules/cjs/loader:1319:18)
    at Module.load (node:internal/modules/cjs/loader:1091:32)
    at Module._load (node:internal/modules/cjs/loader:938:12)
    at Module.require (node:internal/modules/cjs/loader:1115:19)
    at require (node:internal/modules/helpers:130:18)
    at Object.<anonymous> (/home/index.js:1:15)
    at Module._compile (node:internal/modules/cjs/loader:1233:14)
    at Module._extensions..js (node:internal/modules/cjs/loader:1287:10)
    at Module.load (node:internal/modules/cjs/loader:1091:32)
    at Module._load (node:internal/modules/cjs/loader:938:12) {
  code: 'ERR_DLOPEN_DISABLED'
} copy

--allow-child-process#

Added in: v20.0.0

Stability: 1.1 - Active development
When using the Permission Model, the process will not be able to spawn any
child process by default.
Attempts to do so will throw an ERR_ACCESS_DENIED unless the
user explicitly passes the --allow-child-process flag when starting Node.js.
Example:
const childProcess = require('node:child_process');
// Attempt to bypass the permission
childProcess.spawn('node', ['-e', 'require("fs").writeFileSync("/new-file", "example")']); copy
$ node --permission --allow-fs-read=* index.js
node:internal/child_process:388
  const err = this._handle.spawn(options);
                           ^
Error: Access to this API has been restricted
    at ChildProcess.spawn (node:internal/child_process:388:28)
    at node:internal/main/run_main_module:17:47 {
  code: 'ERR_ACCESS_DENIED',
  permission: 'ChildProcess'
} copy
Unlike child_process.spawn, the child_process.fork API copies the execution
arguments from the parent process. This means that if you start Node.js with the
Permission Model enabled and include the --allow-child-process flag, calling
child_process.fork() will propagate all Permission Model flags to the child
process.

--allow-fs-read#

History

VersionChanges
v23.5.0, v22.13.0
Permission Model and --allow-fs flags are stable.
v20.7.0
Paths delimited by comma (,) are no longer allowed.
v20.0.0
Added in: v20.0.0



This flag configures file system read permissions using
the Permission Model.
The valid arguments for the --allow-fs-read flag are:

* - To allow all FileSystemRead operations.
Multiple paths can be allowed using multiple --allow-fs-read flags.
Example --allow-fs-read=/folder1/ --allow-fs-read=/folder1/

Examples can be found in the File System Permissions documentation.
The initializer module also needs to be allowed. Consider the following example:
$ node --permission index.js

Error: Access to this API has been restricted
    at node:internal/main/run_main_module:23:47 {
  code: 'ERR_ACCESS_DENIED',
  permission: 'FileSystemRead',
  resource: '/Users/rafaelgss/repos/os/node/index.js'
} copy
The process needs to have access to the index.js module:
node --permission --allow-fs-read=/path/to/index.js index.js copy

--allow-fs-write#

History

VersionChanges
v23.5.0, v22.13.0
Permission Model and --allow-fs flags are stable.
v20.7.0
Paths delimited by comma (,) are no longer allowed.
v20.0.0
Added in: v20.0.0



This flag configures file system write permissions using
the Permission Model.
The valid arguments for the --allow-fs-write flag are:

* - To allow all FileSystemWrite operations.
Multiple paths can be allowed using multiple --allow-fs-write flags.
Example --allow-fs-write=/folder1/ --allow-fs-write=/folder1/

Paths delimited by comma (,) are no longer allowed.
When passing a single flag with a comma a warning will be displayed.
Examples can be found in the File System Permissions documentation.

--allow-wasi#

Added in: v22.3.0, v20.16.0

Stability: 1.1 - Active development
When using the Permission Model, the process will not be capable of creating
any WASI instances by default.
For security reasons, the call will throw an ERR_ACCESS_DENIED unless the
user explicitly passes the flag --allow-wasi in the main Node.js process.
Example:
const { WASI } = require('node:wasi');
// Attempt to bypass the permission
new WASI({
  version: 'preview1',
  // Attempt to mount the whole filesystem
  preopens: {
    '/': '/',
  },
}); copy
$ node --permission --allow-fs-read=* index.js

Error: Access to this API has been restricted
    at node:internal/main/run_main_module:30:49 {
  code: 'ERR_ACCESS_DENIED',
  permission: 'WASI',
} copy

--allow-worker#

Added in: v20.0.0

Stability: 1.1 - Active development
When using the Permission Model, the process will not be able to create any
worker threads by default.
For security reasons, the call will throw an ERR_ACCESS_DENIED unless the
user explicitly pass the flag --allow-worker in the main Node.js process.
Example:
const { Worker } = require('node:worker_threads');
// Attempt to bypass the permission
new Worker(__filename); copy
$ node --permission --allow-fs-read=* index.js

Error: Access to this API has been restricted
    at node:internal/main/run_main_module:17:47 {
  code: 'ERR_ACCESS_DENIED',
  permission: 'WorkerThreads'
} copy

--build-snapshot#

Added in: v18.8.0

Stability: 1 - Experimental
Generates a snapshot blob when the process exits and writes it to
disk, which can be loaded later with --snapshot-blob.
When building the snapshot, if --snapshot-blob is not specified,
the generated blob will be written, by default, to snapshot.blob
in the current working directory. Otherwise it will be written to
the path specified by --snapshot-blob.
$ echo "globalThis.foo = 'I am from the snapshot'" > snapshot.js

# Run snapshot.js to initialize the application and snapshot the
# state of it into snapshot.blob.
$ node --snapshot-blob snapshot.blob --build-snapshot snapshot.js

$ echo "console.log(globalThis.foo)" > index.js

# Load the generated snapshot and start the application from index.js.
$ node --snapshot-blob snapshot.blob index.js
I am from the snapshot copy
The v8.startupSnapshot API can be used to specify an entry point at
snapshot building time, thus avoiding the need of an additional entry
script at deserialization time:
$ echo "require('v8').startupSnapshot.setDeserializeMainFunction(() => console.log('I am from the snapshot'))" > snapshot.js
$ node --snapshot-blob snapshot.blob --build-snapshot snapshot.js
$ node --snapshot-blob snapshot.blob
I am from the snapshot copy
For more information, check out the v8.startupSnapshot API documentation.
Currently the support for run-time snapshot is experimental in that:

User-land modules are not yet supported in the snapshot, so only
one single file can be snapshotted. Users can bundle their applications
into a single script with their bundler of choice before building
a snapshot, however.
Only a subset of the built-in modules work in the snapshot, though the
Node.js core test suite checks that a few fairly complex applications
can be snapshotted. Support for more modules are being added. If any
crashes or buggy behaviors occur when building a snapshot, please file
a report in the Node.js issue tracker and link to it in the
tracking issue for user-land snapshots.


--build-snapshot-config#

Added in: v21.6.0, v20.12.0

Stability: 1 - Experimental
Specifies the path to a JSON configuration file which configures snapshot
creation behavior.
The following options are currently supported:

builder <string> Required. Provides the name to the script that is executed
before building the snapshot, as if --build-snapshot had been passed
with builder as the main script name.
withoutCodeCache <boolean> Optional. Including the code cache reduces the
time spent on compiling functions included in the snapshot at the expense
of a bigger snapshot size and potentially breaking portability of the
snapshot.

When using this flag, additional script files provided on the command line will
not be executed and instead be interpreted as regular command line arguments.

-c, --check#

History

VersionChanges
v10.0.0
The --require option is now supported when checking a file.
v5.0.0, v4.2.0
Added in: v5.0.0, v4.2.0



Syntax check the script without executing.

--completion-bash#

Added in: v10.12.0

Print source-able bash completion script for Node.js.
node --completion-bash > node_bash_completion
source node_bash_completion copy

-C condition, --conditions=condition#

History

VersionChanges
v22.9.0, v20.18.0
The flag is no longer experimental.
v14.9.0, v12.19.0
Added in: v14.9.0, v12.19.0



Provide custom conditional exports resolution conditions.
Any number of custom string condition names are permitted.
The default Node.js conditions of "node", "default", "import", and
"require" will always apply as defined.
For example, to run a module with "development" resolutions:
node -C development app.js copy

--cpu-prof#

History

VersionChanges
v22.4.0, v20.16.0
The --cpu-prof flags are now stable.
v12.0.0
Added in: v12.0.0



Starts the V8 CPU profiler on start up, and writes the CPU profile to disk
before exit.
If --cpu-prof-dir is not specified, the generated profile is placed
in the current working directory.
If --cpu-prof-name is not specified, the generated profile is
named CPU.${yyyymmdd}.${hhmmss}.${pid}.${tid}.${seq}.cpuprofile.
$ node --cpu-prof index.js
$ ls *.cpuprofile
CPU.20190409.202950.15293.0.0.cpuprofile copy
If --cpu-prof-name is specified, the provided value will be used as-is; patterns such as
${hhmmss} or ${pid} are not supported.
$ node --cpu-prof --cpu-prof-name 'CPU.${pid}.cpuprofile' index.js
$ ls *.cpuprofile
'CPU.${pid}.cpuprofile' copy

--cpu-prof-dir#

History

VersionChanges
v22.4.0, v20.16.0
The --cpu-prof flags are now stable.
v12.0.0
Added in: v12.0.0



Specify the directory where the CPU profiles generated by --cpu-prof will
be placed.
The default value is controlled by the
--diagnostic-dir command-line option.

--cpu-prof-interval#

History

VersionChanges
v22.4.0, v20.16.0
The --cpu-prof flags are now stable.
v12.2.0
Added in: v12.2.0



Specify the sampling interval in microseconds for the CPU profiles generated
by --cpu-prof. The default is 1000 microseconds.

--cpu-prof-name#

History

VersionChanges
v22.4.0, v20.16.0
The --cpu-prof flags are now stable.
v12.0.0
Added in: v12.0.0



Specify the file name of the CPU profile generated by --cpu-prof.

--diagnostic-dir=directory#
Set the directory to which all diagnostic output files are written.
Defaults to current working directory.
Affects the default output directory of:

--cpu-prof-dir
--heap-prof-dir
--redirect-warnings


--disable-proto=mode#

Added in: v13.12.0, v12.17.0

Disable the Object.prototype.__proto__ property. If mode is delete, the
property is removed entirely. If mode is throw, accesses to the
property throw an exception with the code ERR_PROTO_ACCESS.

--disable-sigusr1#

Added in: v23.7.0, v22.14.0

Stability: 1.2 - Release candidate
Disable the ability of starting a debugging session by sending a
SIGUSR1 signal to the process.

--disable-warning=code-or-type#

Added in: v21.3.0, v20.11.0

Stability: 1.1 - Active development
Disable specific process warnings by code or type.
Warnings emitted from process.emitWarning() may contain a
code and a type. This option will not-emit warnings that have a matching
code or type.
List of deprecation warnings.
The Node.js core warning types are: DeprecationWarning and
ExperimentalWarning
For example, the following script will not emit
DEP0025 require('node:sys') when executed with
node --disable-warning=DEP0025:

import sys from 'node:sys';const sys = require('node:sys');copy
For example, the following script will emit the
DEP0025 require('node:sys'), but not any Experimental
Warnings (such as
ExperimentalWarning: vm.measureMemory is an experimental feature
in <=v21) when executed with node --disable-warning=ExperimentalWarning:

import sys from 'node:sys';
import vm from 'node:vm';

vm.measureMemory();const sys = require('node:sys');
const vm = require('node:vm');

vm.measureMemory();copy

--disable-wasm-trap-handler#

Added in: v22.2.0, v20.15.0

By default, Node.js enables trap-handler-based WebAssembly bound
checks. As a result, V8 does not need to insert inline bound checks
int the code compiled from WebAssembly which may speedup WebAssembly
execution significantly, but this optimization requires allocating
a big virtual memory cage (currently 10GB). If the Node.js process
does not have access to a large enough virtual memory address space
due to system configurations or hardware limitations, users won't
be able to run any WebAssembly that involves allocation in this
virtual memory cage and will see an out-of-memory error.
$ ulimit -v 5000000
$ node -p "new WebAssembly.Memory({ initial: 10, maximum: 100 });"
[eval]:1
new WebAssembly.Memory({ initial: 10, maximum: 100 });
^

RangeError: WebAssembly.Memory(): could not allocate memory
    at [eval]:1:1
    at runScriptInThisContext (node:internal/vm:209:10)
    at node:internal/process/execution:118:14
    at [eval]-wrapper:6:24
    at runScript (node:internal/process/execution:101:62)
    at evalScript (node:internal/process/execution:136:3)
    at node:internal/main/eval_string:49:3
 copy
--disable-wasm-trap-handler disables this optimization so that
users can at least run WebAssembly (with less optimal performance)
when the virtual memory address space available to their Node.js
process is lower than what the V8 WebAssembly memory cage needs.

--disallow-code-generation-from-strings#

Added in: v9.8.0

Make built-in language features like eval and new Function that generate
code from strings throw an exception instead. This does not affect the Node.js
node:vm module.

--dns-result-order=order#

History

VersionChanges
v22.1.0, v20.13.0
The ipv6first is supported now.
v17.0.0
Changed default value to verbatim.
v16.4.0, v14.18.0
Added in: v16.4.0, v14.18.0



Set the default value of order in dns.lookup() and
dnsPromises.lookup(). The value could be:

ipv4first: sets default order to ipv4first.
ipv6first: sets default order to ipv6first.
verbatim: sets default order to verbatim.

The default is verbatim and dns.setDefaultResultOrder() have higher
priority than --dns-result-order.

--enable-fips#

Added in: v6.0.0

Enable FIPS-compliant crypto at startup. (Requires Node.js to be built
against FIPS-compatible OpenSSL.)

--enable-network-family-autoselection#

Added in: v18.18.0

Enables the family autoselection algorithm unless connection options explicitly
disables it.

--enable-source-maps#

History

VersionChanges
v15.11.0, v14.18.0
This API is no longer experimental.
v12.12.0
Added in: v12.12.0



Enable Source Map v3 support for stack traces.
When using a transpiler, such as TypeScript, stack traces thrown by an
application reference the transpiled code, not the original source position.
--enable-source-maps enables caching of Source Maps and makes a best
effort to report stack traces relative to the original source file.
Overriding Error.prepareStackTrace may prevent --enable-source-maps from
modifying the stack trace. Call and return the results of the original
Error.prepareStackTrace in the overriding function to modify the stack trace
with source maps.
const originalPrepareStackTrace = Error.prepareStackTrace;
Error.prepareStackTrace = (error, trace) => {
  // Modify error and trace and format stack trace with
  // original Error.prepareStackTrace.
  return originalPrepareStackTrace(error, trace);
}; copy
Note, enabling source maps can introduce latency to your application
when Error.stack is accessed. If you access Error.stack frequently
in your application, take into account the performance implications
of --enable-source-maps.

--entry-url#

Added in: v23.0.0, v22.10.0

Stability: 1 - Experimental
When present, Node.js will interpret the entry point as a URL, rather than a
path.
Follows ECMAScript module resolution rules.
Any query parameter or hash in the URL will be accessible via import.meta.url.
node --entry-url 'file:///path/to/file.js?queryparams=work#and-hashes-too'
node --entry-url 'file.ts?query#hash'
node --entry-url 'data:text/javascript,console.log("Hello")' copy

--env-file-if-exists=config#

Added in: v22.9.0

Stability: 1.1 - Active development
Behavior is the same as --env-file, but an error is not thrown if the file
does not exist.

--env-file=config#

History

VersionChanges
v21.7.0, v20.12.0
Add support to multi-line values.
v20.6.0
Added in: v20.6.0



Stability: 1.1 - Active development
Loads environment variables from a file relative to the current directory,
making them available to applications on process.env. The environment
variables which configure Node.js, such as NODE_OPTIONS,
are parsed and applied. If the same variable is defined in the environment and
in the file, the value from the environment takes precedence.
You can pass multiple --env-file arguments. Subsequent files override
pre-existing variables defined in previous files.
An error is thrown if the file does not exist.
node --env-file=.env --env-file=.development.env index.js copy
The format of the file should be one line per key-value pair of environment
variable name and value separated by =:
PORT=3000 copy
Any text after a # is treated as a comment:
# This is a comment
PORT=3000 # This is also a comment copy
Values can start and end with the following quotes: `, " or '.
They are omitted from the values.
USERNAME="nodejs" # will result in `nodejs` as the value. copy
Multi-line values are supported:
MULTI_LINE="THIS IS
A MULTILINE"
# will result in `THIS IS\nA MULTILINE` as the value. copy
Export keyword before a key is ignored:
export USERNAME="nodejs" # will result in `nodejs` as the value. copy
If you want to load environment variables from a file that may not exist, you
can use the --env-file-if-exists flag instead.

-e, --eval "script"#

History

VersionChanges
v22.6.0
Eval now supports experimental type-stripping.
v5.11.0
Built-in libraries are now available as predefined variables.
v0.5.2
Added in: v0.5.2



Evaluate the following argument as JavaScript. The modules which are
predefined in the REPL can also be used in script.
On Windows, using cmd.exe a single quote will not work correctly because it
only recognizes double " for quoting. In Powershell or Git bash, both '
and " are usable.
It is possible to run code containing inline types unless the
--no-experimental-strip-types flag is provided.

--experimental-addon-modules#

Added in: v23.6.0

Stability: 1.0 - Early development
Enable experimental import support for .node addons.

--experimental-config-file=config#

Added in: v23.10.0

Stability: 1.0 - Early development
If present, Node.js will look for a configuration file at the specified path.
Node.js will read the configuration file and apply the settings. The
configuration file should be a JSON file with the following structure. vX.Y.Z
in the $schema must be replaced with the version of Node.js you are using.
{
  "$schema": "https://nodejs.org/dist/vX.Y.Z/docs/node-config-schema.json",
  "nodeOptions": {
    "import": [
      "amaro/strip"
    ],
    "watch-path": "src",
    "watch-preserve-output": true
  }
} copy
In the nodeOptions field, only flags that are allowed in NODE_OPTIONS are supported.
No-op flags are not supported.
Not all V8 flags are currently supported.
It is possible to use the official JSON schema
to validate the configuration file, which may vary depending on the Node.js version.
Each key in the configuration file corresponds to a flag that can be passed
as a command-line argument. The value of the key is the value that would be
passed to the flag.
For example, the configuration file above is equivalent to
the following command-line arguments:
node --import amaro/strip --watch-path=src --watch-preserve-output copy
The priority in configuration is as follows:

NODE_OPTIONS and command-line options
Configuration file
Dotenv NODE_OPTIONS

Values in the configuration file will not override the values in the environment
variables and command-line options, but will override the values in the NODE_OPTIONS
env file parsed by the --env-file flag.
If duplicate keys are present in the configuration file, only
the first key will be used.
The configuration parser will throw an error if the configuration file contains
unknown keys or keys that cannot used in NODE_OPTIONS.
Node.js will not sanitize or perform validation on the user-provided configuration,
so NEVER use untrusted configuration files.

--experimental-default-config-file#

Added in: v23.10.0

Stability: 1.0 - Early development
If the --experimental-default-config-file flag is present, Node.js will look for a
node.config.json file in the current working directory and load it as a
as configuration file.

--experimental-eventsource#

Added in: v22.3.0, v20.18.0

Enable exposition of EventSource Web API on the global scope.

--experimental-import-meta-resolve#

History

VersionChanges
v20.6.0, v18.19.0
synchronous import.meta.resolve made available by default, with the flag retained for enabling the experimental second argument as previously supported.
v13.9.0, v12.16.2
Added in: v13.9.0, v12.16.2



Enable experimental import.meta.resolve() parent URL support, which allows
passing a second parentURL argument for contextual resolution.
Previously gated the entire import.meta.resolve feature.

--experimental-loader=module#

History

VersionChanges
v23.6.1, v22.13.1, v20.18.2
Using this feature with the permission model enabled requires passing --allow-worker.
v12.11.1
This flag was renamed from --loader to --experimental-loader.
v8.8.0
Added in: v8.8.0




This flag is discouraged and may be removed in a future version of Node.js.
Please use
--import with register() instead.

Specify the module containing exported module customization hooks.
module may be any string accepted as an import specifier.
This feature requires --allow-worker if used with the Permission Model.

--experimental-network-inspection#

Added in: v22.6.0, v20.18.0

Stability: 1 - Experimental
Enable experimental support for the network inspection with Chrome DevTools.

--experimental-print-required-tla#

Added in: v22.0.0, v20.17.0

If the ES module being require()'d contains top-level await, this flag
allows Node.js to evaluate the module, try to locate the
top-level awaits, and print their location to help users find them.

--experimental-require-module#

History

VersionChanges
v23.0.0, v22.12.0, v20.19.0
This is now true by default.
v22.0.0, v20.17.0
Added in: v22.0.0, v20.17.0



Stability: 1.1 - Active Development
Supports loading a synchronous ES module graph in require().
See Loading ECMAScript modules using require().

--experimental-sea-config#

Added in: v20.0.0

Stability: 1 - Experimental
Use this flag to generate a blob that can be injected into the Node.js
binary to produce a single executable application. See the documentation
about this configuration for details.

--experimental-shadow-realm#

Added in: v19.0.0, v18.13.0

Use this flag to enable ShadowRealm support.

--experimental-test-coverage#

History

VersionChanges
v20.1.0, v18.17.0
This option can be used with --test.
v19.7.0, v18.15.0
Added in: v19.7.0, v18.15.0



When used in conjunction with the node:test module, a code coverage report is
generated as part of the test runner output. If no tests are run, a coverage
report is not generated. See the documentation on
collecting code coverage from tests for more details.

--experimental-test-module-mocks#

History

VersionChanges
v23.6.1, v22.13.1, v20.18.2
Using this feature with the permission model enabled requires passing --allow-worker.
v22.3.0, v20.18.0
Added in: v22.3.0, v20.18.0



Stability: 1.0 - Early development
Enable module mocking in the test runner.
This feature requires --allow-worker if used with the Permission Model.

--experimental-transform-types#

Added in: v22.7.0

Stability: 1.2 - Release candidate
Enables the transformation of TypeScript-only syntax into JavaScript code.
Implies --enable-source-maps.

--experimental-vm-modules#

Added in: v9.6.0

Enable experimental ES Module support in the node:vm module.

--experimental-wasi-unstable-preview1#

History

VersionChanges
v20.0.0, v18.17.0
This option is no longer required as WASI is enabled by default, but can still be passed.
v13.6.0
changed from --experimental-wasi-unstable-preview0 to --experimental-wasi-unstable-preview1.
v13.3.0, v12.16.0
Added in: v13.3.0, v12.16.0



Enable experimental WebAssembly System Interface (WASI) support.

--experimental-wasm-modules#

Added in: v12.3.0

Enable experimental WebAssembly module support.

--experimental-webstorage#

Added in: v22.4.0

Enable experimental Web Storage support.

--expose-gc#

Added in: v22.3.0, v20.18.0

Stability: 1 - Experimental. This flag is inherited from V8 and is subject to
change upstream.
This flag will expose the gc extension from V8.
if (globalThis.gc) {
  globalThis.gc();
} copy

--force-context-aware#

Added in: v12.12.0

Disable loading native addons that are not context-aware.

--force-fips#

Added in: v6.0.0

Force FIPS-compliant crypto on startup. (Cannot be disabled from script code.)
(Same requirements as --enable-fips.)

--force-node-api-uncaught-exceptions-policy#

Added in: v18.3.0, v16.17.0

Enforces uncaughtException event on Node-API asynchronous callbacks.
To prevent from an existing add-on from crashing the process, this flag is not
enabled by default. In the future, this flag will be enabled by default to
enforce the correct behavior.

--frozen-intrinsics#

Added in: v11.12.0

Stability: 1 - Experimental
Enable experimental frozen intrinsics like Array and Object.
Only the root context is supported. There is no guarantee that
globalThis.Array is indeed the default intrinsic reference. Code may break
under this flag.
To allow polyfills to be added,
--require and --import both run before freezing intrinsics.

--heap-prof#

History

VersionChanges
v22.4.0, v20.16.0
The --heap-prof flags are now stable.
v12.4.0
Added in: v12.4.0



Starts the V8 heap profiler on start up, and writes the heap profile to disk
before exit.
If --heap-prof-dir is not specified, the generated profile is placed
in the current working directory.
If --heap-prof-name is not specified, the generated profile is
named Heap.${yyyymmdd}.${hhmmss}.${pid}.${tid}.${seq}.heapprofile.
$ node --heap-prof index.js
$ ls *.heapprofile
Heap.20190409.202950.15293.0.001.heapprofile copy

--heap-prof-dir#

History

VersionChanges
v22.4.0, v20.16.0
The --heap-prof flags are now stable.
v12.4.0
Added in: v12.4.0



Specify the directory where the heap profiles generated by --heap-prof will
be placed.
The default value is controlled by the
--diagnostic-dir command-line option.

--heap-prof-interval#

History

VersionChanges
v22.4.0, v20.16.0
The --heap-prof flags are now stable.
v12.4.0
Added in: v12.4.0



Specify the average sampling interval in bytes for the heap profiles generated
by --heap-prof. The default is 512 * 1024 bytes.

--heap-prof-name#

History

VersionChanges
v22.4.0, v20.16.0
The --heap-prof flags are now stable.
v12.4.0
Added in: v12.4.0



Specify the file name of the heap profile generated by --heap-prof.

--heapsnapshot-near-heap-limit=max_count#

Added in: v15.1.0, v14.18.0

Stability: 1 - Experimental
Writes a V8 heap snapshot to disk when the V8 heap usage is approaching the
heap limit. count should be a non-negative integer (in which case
Node.js will write no more than max_count snapshots to disk).
When generating snapshots, garbage collection may be triggered and bring
the heap usage down. Therefore multiple snapshots may be written to disk
before the Node.js instance finally runs out of memory. These heap snapshots
can be compared to determine what objects are being allocated during the
time consecutive snapshots are taken. It's not guaranteed that Node.js will
write exactly max_count snapshots to disk, but it will try
its best to generate at least one and up to max_count snapshots before the
Node.js instance runs out of memory when max_count is greater than 0.
Generating V8 snapshots takes time and memory (both memory managed by the
V8 heap and native memory outside the V8 heap). The bigger the heap is,
the more resources it needs. Node.js will adjust the V8 heap to accommodate
the additional V8 heap memory overhead, and try its best to avoid using up
all the memory available to the process. When the process uses
more memory than the system deems appropriate, the process may be terminated
abruptly by the system, depending on the system configuration.
$ node --max-old-space-size=100 --heapsnapshot-near-heap-limit=3 index.js
Wrote snapshot to Heap.20200430.100036.49580.0.001.heapsnapshot
Wrote snapshot to Heap.20200430.100037.49580.0.002.heapsnapshot
Wrote snapshot to Heap.20200430.100038.49580.0.003.heapsnapshot

<--- Last few GCs --->

[49580:0x110000000]     4826 ms: Mark-sweep 130.6 (147.8) -> 130.5 (147.8) MB, 27.4 / 0.0 ms  (average mu = 0.126, current mu = 0.034) allocation failure scavenge might not succeed
[49580:0x110000000]     4845 ms: Mark-sweep 130.6 (147.8) -> 130.6 (147.8) MB, 18.8 / 0.0 ms  (average mu = 0.088, current mu = 0.031) allocation failure scavenge might not succeed


<--- JS stacktrace --->

FATAL ERROR: Ineffective mark-compacts near heap limit Allocation failed - JavaScript heap out of memory
.... copy

--heapsnapshot-signal=signal#

Added in: v12.0.0

Enables a signal handler that causes the Node.js process to write a heap dump
when the specified signal is received. signal must be a valid signal name.
Disabled by default.
$ node --heapsnapshot-signal=SIGUSR2 index.js &
$ ps aux
USER       PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND
node         1  5.5  6.1 787252 247004 ?       Ssl  16:43   0:02 node --heapsnapshot-signal=SIGUSR2 index.js
$ kill -USR2 1
$ ls
Heap.20190718.133405.15554.0.001.heapsnapshot copy

-h, --help#

Added in: v0.1.3

Print node command-line options.
The output of this option is less detailed than this document.

--icu-data-dir=file#

Added in: v0.11.15

Specify ICU data load path. (Overrides NODE_ICU_DATA.)

--import=module#

Added in: v19.0.0, v18.18.0

Stability: 1 - Experimental
Preload the specified module at startup. If the flag is provided several times,
each module will be executed sequentially in the order they appear, starting
with the ones provided in NODE_OPTIONS.
Follows ECMAScript module resolution rules.
Use --require to load a CommonJS module.
Modules preloaded with --require will run before modules preloaded with --import.
Modules are preloaded into the main thread as well as any worker threads,
forked processes, or clustered processes.

--input-type=type#

History

VersionChanges
v23.6.0
Add support for -typescript values.
v22.7.0, v20.19.0
ESM syntax detection is enabled by default.
v12.0.0
Added in: v12.0.0



This configures Node.js to interpret --eval or STDIN input as CommonJS or
as an ES module. Valid values are "commonjs", "module", "module-typescript" and "commonjs-typescript".
The "-typescript" values are not available with the flag --no-experimental-strip-types.
The default is no value, or "commonjs" if --no-experimental-detect-module is passed.
If --input-type is not provided,
Node.js will try to detect the syntax with the following steps:

Run the input as CommonJS.
If step 1 fails, run the input as an ES module.
If step 2 fails with a SyntaxError, strip the types.
If step 3 fails with an error code ERR_UNSUPPORTED_TYPESCRIPT_SYNTAX
or ERR_INVALID_TYPESCRIPT_SYNTAX,
throw the error from step 2, including the TypeScript error in the message,
else run as CommonJS.
If step 4 fails, run the input as an ES module.

To avoid the delay of multiple syntax detection passes, the --input-type=type flag can be used to specify
how the --eval input should be interpreted.
The REPL does not support this option. Usage of --input-type=module with
--print will throw an error, as --print does not support ES module
syntax.

--insecure-http-parser#

Added in: v13.4.0, v12.15.0, v10.19.0

Enable leniency flags on the HTTP parser. This may allow
interoperability with non-conformant HTTP implementations.
When enabled, the parser will accept the following:

Invalid HTTP headers values.
Invalid HTTP versions.
Allow message containing both Transfer-Encoding
and Content-Length headers.
Allow extra data after message when Connection: close is present.
Allow extra transfer encodings after chunked has been provided.
Allow \n to be used as token separator instead of \r\n.
Allow \r\n not to be provided after a chunk.
Allow spaces to be present after a chunk size and before \r\n.

All the above will expose your application to request smuggling
or poisoning attack. Avoid using this option.



Warning: binding inspector to a public IP:port combination is insecure#
Binding the inspector to a public IP (including 0.0.0.0) with an open port is
insecure, as it allows external hosts to connect to the inspector and perform
a remote code execution attack.
If specifying a host, make sure that either:

The host is not accessible from public networks.
A firewall disallows unwanted connections on the port.

More specifically, --inspect=0.0.0.0 is insecure if the port (9229 by
default) is not firewall-protected.
See the debugging security implications section for more information.

--inspect-brk[=[host:]port]#

Added in: v7.6.0

Activate inspector on host:port and break at start of user script.
Default host:port is 127.0.0.1:9229. If port 0 is specified,
a random available port will be used.
See V8 Inspector integration for Node.js for further explanation on Node.js debugger.

--inspect-port=[host:]port#

Added in: v7.6.0

Set the host:port to be used when the inspector is activated.
Useful when activating the inspector by sending the SIGUSR1 signal.
Except when --disable-sigusr1 is passed.
Default host is 127.0.0.1. If port 0 is specified,
a random available port will be used.
See the security warning below regarding the host
parameter usage.

--inspect-publish-uid=stderr,http#
Specify ways of the inspector web socket url exposure.
By default inspector websocket url is available in stderr and under /json/list
endpoint on http://host:port/json/list.

--inspect-wait[=[host:]port]#

Added in: v22.2.0, v20.15.0

Activate inspector on host:port and wait for debugger to be attached.
Default host:port is 127.0.0.1:9229. If port 0 is specified,
a random available port will be used.
See V8 Inspector integration for Node.js for further explanation on Node.js debugger.

--inspect[=[host:]port]#

Added in: v6.3.0

Activate inspector on host:port. Default is 127.0.0.1:9229. If port 0 is
specified, a random available port will be used.
V8 inspector integration allows tools such as Chrome DevTools and IDEs to debug
and profile Node.js instances. The tools attach to Node.js instances via a
tcp port and communicate using the Chrome DevTools Protocol.
See V8 Inspector integration for Node.js for further explanation on Node.js debugger.

-i, --interactive#

Added in: v0.7.7

Opens the REPL even if stdin does not appear to be a terminal.

--jitless#

Added in: v12.0.0

Stability: 1 - Experimental. This flag is inherited from V8 and is subject to
change upstream.
Disable runtime allocation of executable memory. This may be
required on some platforms for security reasons. It can also reduce attack
surface on other platforms, but the performance impact may be severe.

--localstorage-file=file#

Added in: v22.4.0

The file used to store localStorage data. If the file does not exist, it is
created the first time localStorage is accessed. The same file may be shared
between multiple Node.js processes concurrently. This flag is a no-op unless
Node.js is started with the --experimental-webstorage flag.

--max-http-header-size=size#

History

VersionChanges
v13.13.0
Change maximum default size of HTTP headers from 8 KiB to 16 KiB.
v11.6.0, v10.15.0
Added in: v11.6.0, v10.15.0



Specify the maximum size, in bytes, of HTTP headers. Defaults to 16 KiB.

--napi-modules#

Added in: v7.10.0

This option is a no-op. It is kept for compatibility.

--network-family-autoselection-attempt-timeout#

Added in: v22.1.0, v20.13.0

Sets the default value for the network family autoselection attempt timeout.
For more information, see net.getDefaultAutoSelectFamilyAttemptTimeout().

--no-addons#

Added in: v16.10.0, v14.19.0

Disable the node-addons exports condition as well as disable loading
native addons. When --no-addons is specified, calling process.dlopen or
requiring a native C++ addon will fail and throw an exception.

--no-async-context-frame#

Added in: v24.0.0

Disables the use of AsyncLocalStorage backed by AsyncContextFrame and
uses the prior implementation which relied on async_hooks. The previous model
is retained for compatibility with Electron and for cases where the context
flow may differ. However, if a difference in flow is found please report it.

--no-deprecation#

Added in: v0.8.0

Silence deprecation warnings.

--no-experimental-detect-module#

History

VersionChanges
v22.7.0, v20.19.0
Syntax detection is enabled by default.
v21.1.0, v20.10.0
Added in: v21.1.0, v20.10.0



Disable using syntax detection to determine module type.

--no-experimental-global-navigator#

Added in: v21.2.0

Stability: 1 - Experimental
Disable exposition of Navigator API on the global scope.

--no-experimental-repl-await#

Added in: v16.6.0

Use this flag to disable top-level await in REPL.

--no-experimental-require-module#

History

VersionChanges
v23.0.0, v22.12.0, v20.19.0
This is now false by default.
v22.0.0, v20.17.0
Added in: v22.0.0, v20.17.0



Stability: 1.1 - Active Development
Disable support for loading a synchronous ES module graph in require().
See Loading ECMAScript modules using require().

--no-experimental-sqlite#

History

VersionChanges
v23.4.0, v22.13.0
SQLite is unflagged but still experimental.
v22.5.0
Added in: v22.5.0



Disable the experimental node:sqlite module.

--no-experimental-strip-types#

History

VersionChanges
v23.6.0
Type stripping is enabled by default.
v22.6.0
Added in: v22.6.0



Stability: 1.2 - Release candidate
Disable experimental type-stripping for TypeScript files.
For more information, see the TypeScript type-stripping documentation.

--no-experimental-websocket#

Added in: v22.0.0

Disable exposition of WebSocket on the global scope.

--no-extra-info-on-fatal-exception#

Added in: v17.0.0

Hide extra information on fatal exception that causes exit.

--no-force-async-hooks-checks#

Added in: v9.0.0

Disables runtime checks for async_hooks. These will still be enabled
dynamically when async_hooks is enabled.

--no-global-search-paths#

Added in: v16.10.0

Do not search modules from global paths like $HOME/.node_modules and
$NODE_PATH.

--no-network-family-autoselection#

History

VersionChanges
v20.0.0
The flag was renamed from --no-enable-network-family-autoselection to --no-network-family-autoselection. The old name can still work as an alias.
v19.4.0
Added in: v19.4.0



Disables the family autoselection algorithm unless connection options explicitly
enables it.

--no-warnings#

Added in: v6.0.0

Silence all process warnings (including deprecations).

--node-memory-debug#

Added in: v15.0.0, v14.18.0

Enable extra debug checks for memory leaks in Node.js internals. This is
usually only useful for developers debugging Node.js itself.

--openssl-config=file#

Added in: v6.9.0

Load an OpenSSL configuration file on startup. Among other uses, this can be
used to enable FIPS-compliant crypto if Node.js is built
against FIPS-enabled OpenSSL.

--openssl-legacy-provider#

Added in: v17.0.0, v16.17.0

Enable OpenSSL 3.0 legacy provider. For more information please see
OSSL_PROVIDER-legacy.

--openssl-shared-config#

Added in: v18.5.0, v16.17.0, v14.21.0

Enable OpenSSL default configuration section, openssl_conf to be read from
the OpenSSL configuration file. The default configuration file is named
openssl.cnf but this can be changed using the environment variable
OPENSSL_CONF, or by using the command line option --openssl-config.
The location of the default OpenSSL configuration file depends on how OpenSSL
is being linked to Node.js. Sharing the OpenSSL configuration may have unwanted
implications and it is recommended to use a configuration section specific to
Node.js which is nodejs_conf and is default when this option is not used.

--pending-deprecation#

Added in: v8.0.0

Emit pending deprecation warnings.
Pending deprecations are generally identical to a runtime deprecation with the
notable exception that they are turned off by default and will not be emitted
unless either the --pending-deprecation command-line flag, or the
NODE_PENDING_DEPRECATION=1 environment variable, is set. Pending deprecations
are used to provide a kind of selective "early warning" mechanism that
developers may leverage to detect deprecated API usage.

--permission#

History

VersionChanges
v23.5.0, v22.13.0
Permission Model is now stable.
v20.0.0
Added in: v20.0.0



Enable the Permission Model for current process. When enabled, the
following permissions are restricted:

File System - manageable through
--allow-fs-read, --allow-fs-write flags
Child Process - manageable through --allow-child-process flag
Worker Threads - manageable through --allow-worker flag
WASI - manageable through --allow-wasi flag
Addons - manageable through --allow-addons flag


--preserve-symlinks#

Added in: v6.3.0

Instructs the module loader to preserve symbolic links when resolving and
caching modules.
By default, when Node.js loads a module from a path that is symbolically linked
to a different on-disk location, Node.js will dereference the link and use the
actual on-disk "real path" of the module as both an identifier and as a root
path to locate other dependency modules. In most cases, this default behavior
is acceptable. However, when using symbolically linked peer dependencies, as
illustrated in the example below, the default behavior causes an exception to
be thrown if moduleA attempts to require moduleB as a peer dependency:
{appDir}
 ├── app
 │   ├── index.js
 │   └── node_modules
 │       ├── moduleA -> {appDir}/moduleA
 │       └── moduleB
 │           ├── index.js
 │           └── package.json
 └── moduleA
     ├── index.js
     └── package.json copy
The --preserve-symlinks command-line flag instructs Node.js to use the
symlink path for modules as opposed to the real path, allowing symbolically
linked peer dependencies to be found.
Note, however, that using --preserve-symlinks can have other side effects.
Specifically, symbolically linked native modules can fail to load if those
are linked from more than one location in the dependency tree (Node.js would
see those as two separate modules and would attempt to load the module multiple
times, causing an exception to be thrown).
The --preserve-symlinks flag does not apply to the main module, which allows
node --preserve-symlinks node_module/.bin/<foo> to work. To apply the same
behavior for the main module, also use --preserve-symlinks-main.

--preserve-symlinks-main#

Added in: v10.2.0

Instructs the module loader to preserve symbolic links when resolving and
caching the main module (require.main).
This flag exists so that the main module can be opted-in to the same behavior
that --preserve-symlinks gives to all other imports; they are separate flags,
however, for backward compatibility with older Node.js versions.
--preserve-symlinks-main does not imply --preserve-symlinks; use
--preserve-symlinks-main in addition to
--preserve-symlinks when it is not desirable to follow symlinks before
resolving relative paths.
See --preserve-symlinks for more information.

-p, --print "script"#

History

VersionChanges
v5.11.0
Built-in libraries are now available as predefined variables.
v0.6.4
Added in: v0.6.4



Identical to -e but prints the result.

--prof#

Added in: v2.0.0

Generate V8 profiler output.

--prof-process#

Added in: v5.2.0

Process V8 profiler output generated using the V8 option --prof.

--redirect-warnings=file#

Added in: v8.0.0

Write process warnings to the given file instead of printing to stderr. The
file will be created if it does not exist, and will be appended to if it does.
If an error occurs while attempting to write the warning to the file, the
warning will be written to stderr instead.
The file name may be an absolute path. If it is not, the default directory it
will be written to is controlled by the
--diagnostic-dir command-line option.

--report-compact#

Added in: v13.12.0, v12.17.0

Write reports in a compact format, single-line JSON, more easily consumable
by log processing systems than the default multi-line format designed for
human consumption.

--report-dir=directory, report-directory=directory#

History

VersionChanges
v13.12.0, v12.17.0
This option is no longer experimental.
v12.0.0
Changed from --diagnostic-report-directory to --report-directory.
v11.8.0
Added in: v11.8.0



Location at which the report will be generated.

--report-exclude-env#

Added in: v23.3.0, v22.13.0

When --report-exclude-env is passed the diagnostic report generated will not
contain the environmentVariables data.

--report-exclude-network#

Added in: v22.0.0, v20.13.0

Exclude header.networkInterfaces from the diagnostic report. By default
this is not set and the network interfaces are included.

--report-filename=filename#

History

VersionChanges
v13.12.0, v12.17.0
This option is no longer experimental.
v12.0.0
changed from --diagnostic-report-filename to --report-filename.
v11.8.0
Added in: v11.8.0



Name of the file to which the report will be written.
If the filename is set to 'stdout' or 'stderr', the report is written to
the stdout or stderr of the process respectively.

--report-on-fatalerror#

History

VersionChanges
v14.0.0, v13.14.0, v12.17.0
This option is no longer experimental.
v12.0.0
changed from --diagnostic-report-on-fatalerror to --report-on-fatalerror.
v11.8.0
Added in: v11.8.0



Enables the report to be triggered on fatal errors (internal errors within
the Node.js runtime such as out of memory) that lead to termination of the
application. Useful to inspect various diagnostic data elements such as heap,
stack, event loop state, resource consumption etc. to reason about the fatal
error.

--report-on-signal#

History

VersionChanges
v13.12.0, v12.17.0
This option is no longer experimental.
v12.0.0
changed from --diagnostic-report-on-signal to --report-on-signal.
v11.8.0
Added in: v11.8.0



Enables report to be generated upon receiving the specified (or predefined)
signal to the running Node.js process. The signal to trigger the report is
specified through --report-signal.

--report-signal=signal#

History

VersionChanges
v13.12.0, v12.17.0
This option is no longer experimental.
v12.0.0
changed from --diagnostic-report-signal to --report-signal.
v11.8.0
Added in: v11.8.0



Sets or resets the signal for report generation (not supported on Windows).
Default signal is SIGUSR2.

--report-uncaught-exception#

History

VersionChanges
v18.8.0, v16.18.0
Report is not generated if the uncaught exception is handled.
v13.12.0, v12.17.0
This option is no longer experimental.
v12.0.0
changed from --diagnostic-report-uncaught-exception to --report-uncaught-exception.
v11.8.0
Added in: v11.8.0



Enables report to be generated when the process exits due to an uncaught
exception. Useful when inspecting the JavaScript stack in conjunction with
native stack and other runtime environment data.

-r, --require module#

History

VersionChanges
v23.0.0, v22.12.0, v20.19.0
This option also supports ECMAScript module.
v1.6.0
Added in: v1.6.0



Preload the specified module at startup.
Follows require()'s module resolution
rules. module may be either a path to a file, or a node module name.
Modules preloaded with --require will run before modules preloaded with --import.
Modules are preloaded into the main thread as well as any worker threads,
forked processes, or clustered processes.

--run#

History

VersionChanges
v22.3.0
NODE_RUN_SCRIPT_NAME environment variable is added.
v22.3.0
NODE_RUN_PACKAGE_JSON_PATH environment variable is added.
v22.3.0
Traverses up to the root directory and finds a package.json file to run the command from, and updates PATH environment variable accordingly.
v22.0.0
Added in: v22.0.0



This runs a specified command from a package.json's "scripts" object.
If a missing "command" is provided, it will list the available scripts.
--run will traverse up to the root directory and finds a package.json
file to run the command from.
--run prepends ./node_modules/.bin for each ancestor of
the current directory, to the PATH in order to execute the binaries from
different folders where multiple node_modules directories are present, if
ancestor-folder/node_modules/.bin is a directory.
--run executes the command in the directory containing the related package.json.
For example, the following command will run the test script of
the package.json in the current folder:
$ node --run test copy
You can also pass arguments to the command. Any argument after -- will
be appended to the script:
$ node --run test -- --verbose copy

Intentional limitations#
node --run is not meant to match the behaviors of npm run or of the run
commands of other package managers. The Node.js implementation is intentionally
more limited, in order to focus on top performance for the most common use
cases.
Some features of other run implementations that are intentionally excluded
are:

Running pre or post scripts in addition to the specified script.
Defining package manager-specific environment variables.


Environment variables#
The following environment variables are set when running a script with --run:

NODE_RUN_SCRIPT_NAME: The name of the script being run. For example, if
--run is used to run test, the value of this variable will be test.
NODE_RUN_PACKAGE_JSON_PATH: The path to the package.json that is being
processed.


--secure-heap-min=n#

Added in: v15.6.0

When using --secure-heap, the --secure-heap-min flag specifies the
minimum allocation from the secure heap. The minimum value is 2.
The maximum value is the lesser of --secure-heap or 2147483647.
The value given must be a power of two.

--secure-heap=n#

Added in: v15.6.0

Initializes an OpenSSL secure heap of n bytes. When initialized, the
secure heap is used for selected types of allocations within OpenSSL
during key generation and other operations. This is useful, for instance,
to prevent sensitive information from leaking due to pointer overruns
or underruns.
The secure heap is a fixed size and cannot be resized at runtime so,
if used, it is important to select a large enough heap to cover all
application uses.
The heap size given must be a power of two. Any value less than 2
will disable the secure heap.
The secure heap is disabled by default.
The secure heap is not available on Windows.
See CRYPTO_secure_malloc_init for more details.

--snapshot-blob=path#

Added in: v18.8.0

Stability: 1 - Experimental
When used with --build-snapshot, --snapshot-blob specifies the path
where the generated snapshot blob is written to. If not specified, the
generated blob is written to snapshot.blob in the current working directory.
When used without --build-snapshot, --snapshot-blob specifies the
path to the blob that is used to restore the application state.
When loading a snapshot, Node.js checks that:

The version, architecture, and platform of the running Node.js binary
are exactly the same as that of the binary that generates the snapshot.
The V8 flags and CPU features are compatible with that of the binary
that generates the snapshot.

If they don't match, Node.js refuses to load the snapshot and exits with
status code 1.

--test#

History

VersionChanges
v20.0.0
The test runner is now stable.
v19.2.0, v18.13.0
Test runner now supports running in watch mode.
v18.1.0, v16.17.0
Added in: v18.1.0, v16.17.0



Starts the Node.js command line test runner. This flag cannot be combined with
--watch-path, --check, --eval, --interactive, or the inspector.
See the documentation on running tests from the command line
for more details.

--test-concurrency#

Added in: v21.0.0, v20.10.0, v18.19.0

The maximum number of test files that the test runner CLI will execute
concurrently. If --test-isolation is set to 'none', this flag is ignored and
concurrency is one. Otherwise, concurrency defaults to
os.availableParallelism() - 1.

--test-coverage-branches=threshold#

Added in: v22.8.0

Stability: 1 - Experimental
Require a minimum percent of covered branches. If code coverage does not reach
the threshold specified, the process will exit with code 1.

--test-coverage-exclude#

Added in: v22.5.0

Stability: 1 - Experimental
Excludes specific files from code coverage using a glob pattern, which can match
both absolute and relative file paths.
This option may be specified multiple times to exclude multiple glob patterns.
If both --test-coverage-exclude and --test-coverage-include are provided,
files must meet both criteria to be included in the coverage report.
By default all the matching test files are excluded from the coverage report.
Specifying this option will override the default behavior.

--test-coverage-functions=threshold#

Added in: v22.8.0

Stability: 1 - Experimental
Require a minimum percent of covered functions. If code coverage does not reach
the threshold specified, the process will exit with code 1.

--test-coverage-include#

Added in: v22.5.0

Stability: 1 - Experimental
Includes specific files in code coverage using a glob pattern, which can match
both absolute and relative file paths.
This option may be specified multiple times to include multiple glob patterns.
If both --test-coverage-exclude and --test-coverage-include are provided,
files must meet both criteria to be included in the coverage report.

--test-coverage-lines=threshold#

Added in: v22.8.0

Stability: 1 - Experimental
Require a minimum percent of covered lines. If code coverage does not reach
the threshold specified, the process will exit with code 1.

--test-force-exit#

Added in: v22.0.0, v20.14.0

Configures the test runner to exit the process once all known tests have
finished executing even if the event loop would otherwise remain active.

--test-global-setup=module#

Added in: v24.0.0

Stability: 1.0 - Early development
Specify a module that will be evaluated before all tests are executed and
can be used to setup global state or fixtures for tests.
See the documentation on global setup and teardown for more details.

--test-isolation=mode#

History

VersionChanges
v23.6.0
This flag was renamed from --experimental-test-isolation to --test-isolation.
v22.8.0
Added in: v22.8.0



Configures the type of test isolation used in the test runner. When mode is
'process', each test file is run in a separate child process. When mode is
'none', all test files run in the same process as the test runner. The default
isolation mode is 'process'. This flag is ignored if the --test flag is not
present. See the test runner execution model section for more information.

--test-name-pattern#

History

VersionChanges
v20.0.0
The test runner is now stable.
v18.11.0
Added in: v18.11.0



A regular expression that configures the test runner to only execute tests
whose name matches the provided pattern. See the documentation on
filtering tests by name for more details.
If both --test-name-pattern and --test-skip-pattern are supplied,
tests must satisfy both requirements in order to be executed.

--test-only#

History

VersionChanges
v20.0.0
The test runner is now stable.
v18.0.0, v16.17.0
Added in: v18.0.0, v16.17.0



Configures the test runner to only execute top level tests that have the only
option set. This flag is not necessary when test isolation is disabled.

--test-reporter#

History

VersionChanges
v20.0.0
The test runner is now stable.
v19.6.0, v18.15.0
Added in: v19.6.0, v18.15.0



A test reporter to use when running tests. See the documentation on
test reporters for more details.

--test-reporter-destination#

History

VersionChanges
v20.0.0
The test runner is now stable.
v19.6.0, v18.15.0
Added in: v19.6.0, v18.15.0



The destination for the corresponding test reporter. See the documentation on
test reporters for more details.

--test-shard#

Added in: v20.5.0, v18.19.0

Test suite shard to execute in a format of <index>/<total>, where
index is a positive integer, index of divided parts
total is a positive integer, total of divided part
This command will divide all tests files into total equal parts,
and will run only those that happen to be in an index part.
For example, to split your tests suite into three parts, use this:
node --test --test-shard=1/3
node --test --test-shard=2/3
node --test --test-shard=3/3 copy

--test-skip-pattern#

Added in: v22.1.0

A regular expression that configures the test runner to skip tests
whose name matches the provided pattern. See the documentation on
filtering tests by name for more details.
If both --test-name-pattern and --test-skip-pattern are supplied,
tests must satisfy both requirements in order to be executed.

--test-timeout#

Added in: v21.2.0, v20.11.0

A number of milliseconds the test execution will fail after. If unspecified,
subtests inherit this value from their parent. The default value is Infinity.

--test-update-snapshots#

History

VersionChanges
v23.4.0, v22.13.0
Snapsnot testing is no longer experimental.
v22.3.0
Added in: v22.3.0



Regenerates the snapshot files used by the test runner for snapshot testing.

--throw-deprecation#

Added in: v0.11.14

Throw errors for deprecations.

--title=title#

Added in: v10.7.0

Set process.title on startup.

--tls-cipher-list=list#

Added in: v4.0.0

Specify an alternative default TLS cipher list. Requires Node.js to be built
with crypto support (default).

--tls-keylog=file#

Added in: v13.2.0, v12.16.0

Log TLS key material to a file. The key material is in NSS SSLKEYLOGFILE
format and can be used by software (such as Wireshark) to decrypt the TLS
traffic.

--tls-max-v1.2#

Added in: v12.0.0, v10.20.0

Set tls.DEFAULT_MAX_VERSION to 'TLSv1.2'. Use to disable support for
TLSv1.3.

--tls-max-v1.3#

Added in: v12.0.0

Set default tls.DEFAULT_MAX_VERSION to 'TLSv1.3'. Use to enable support
for TLSv1.3.

--tls-min-v1.0#

Added in: v12.0.0, v10.20.0

Set default tls.DEFAULT_MIN_VERSION to 'TLSv1'. Use for compatibility with
old TLS clients or servers.

--tls-min-v1.1#

Added in: v12.0.0, v10.20.0

Set default tls.DEFAULT_MIN_VERSION to 'TLSv1.1'. Use for compatibility
with old TLS clients or servers.

--tls-min-v1.2#

Added in: v12.2.0, v10.20.0

Set default tls.DEFAULT_MIN_VERSION to 'TLSv1.2'. This is the default for
12.x and later, but the option is supported for compatibility with older Node.js
versions.

--tls-min-v1.3#

Added in: v12.0.0

Set default tls.DEFAULT_MIN_VERSION to 'TLSv1.3'. Use to disable support
for TLSv1.2, which is not as secure as TLSv1.3.

--trace-deprecation#

Added in: v0.8.0

Print stack traces for deprecations.

--trace-env#

Added in: v23.4.0, v22.13.0

Print information about any access to environment variables done in the current Node.js
instance to stderr, including:

The environment variable reads that Node.js does internally.
Writes in the form of process.env.KEY = "SOME VALUE".
Reads in the form of process.env.KEY.
Definitions in the form of Object.defineProperty(process.env, 'KEY', {...}).
Queries in the form of Object.hasOwn(process.env, 'KEY'),
process.env.hasOwnProperty('KEY') or 'KEY' in process.env.
Deletions in the form of delete process.env.KEY.
Enumerations inf the form of ...process.env or Object.keys(process.env).

Only the names of the environment variables being accessed are printed. The values are not printed.
To print the stack trace of the access, use --trace-env-js-stack and/or
--trace-env-native-stack.

--trace-env-js-stack#

Added in: v23.4.0, v22.13.0

In addition to what --trace-env does, this prints the JavaScript stack trace of the access.

--trace-env-native-stack#

Added in: v23.4.0, v22.13.0

In addition to what --trace-env does, this prints the native stack trace of the access.

--trace-event-categories#

Added in: v7.7.0

A comma separated list of categories that should be traced when trace event
tracing is enabled using --trace-events-enabled.

--trace-event-file-pattern#

Added in: v9.8.0

Template string specifying the filepath for the trace event data, it
supports ${rotation} and ${pid}.

--trace-events-enabled#

Added in: v7.7.0

Enables the collection of trace event tracing information.

--trace-exit#

Added in: v13.5.0, v12.16.0

Prints a stack trace whenever an environment is exited proactively,
i.e. invoking process.exit().

--trace-require-module=mode#

Added in: v23.5.0, v22.13.0, v20.19.0

Prints information about usage of Loading ECMAScript modules using require().
When mode is all, all usage is printed. When mode is no-node-modules, usage
from the node_modules folder is excluded.

--trace-sigint#

Added in: v13.9.0, v12.17.0

Prints a stack trace on SIGINT.

--trace-sync-io#

Added in: v2.1.0

Prints a stack trace whenever synchronous I/O is detected after the first turn
of the event loop.

--trace-tls#

Added in: v12.2.0

Prints TLS packet trace information to stderr. This can be used to debug TLS
connection problems.

--trace-uncaught#

Added in: v13.1.0

Print stack traces for uncaught exceptions; usually, the stack trace associated
with the creation of an Error is printed, whereas this makes Node.js also
print the stack trace associated with throwing the value (which does not need
to be an Error instance).
Enabling this option may affect garbage collection behavior negatively.

--trace-warnings#

Added in: v6.0.0

Print stack traces for process warnings (including deprecations).

--track-heap-objects#

Added in: v2.4.0

Track heap object allocations for heap snapshots.

--unhandled-rejections=mode#

History

VersionChanges
v15.0.0
Changed default mode to throw. Previously, a warning was emitted.
v12.0.0, v10.17.0
Added in: v12.0.0, v10.17.0



Using this flag allows to change what should happen when an unhandled rejection
occurs. One of the following modes can be chosen:

throw: Emit unhandledRejection. If this hook is not set, raise the
unhandled rejection as an uncaught exception. This is the default.
strict: Raise the unhandled rejection as an uncaught exception. If the
exception is handled, unhandledRejection is emitted.
warn: Always trigger a warning, no matter if the unhandledRejection
hook is set or not but do not print the deprecation warning.
warn-with-error-code: Emit unhandledRejection. If this hook is not
set, trigger a warning, and set the process exit code to 1.
none: Silence all warnings.

If a rejection happens during the command line entry point's ES module static
loading phase, it will always raise it as an uncaught exception.

--use-bundled-ca, --use-openssl-ca#

Added in: v6.11.0

Use bundled Mozilla CA store as supplied by current Node.js version
or use OpenSSL's default CA store. The default store is selectable
at build-time.
The bundled CA store, as supplied by Node.js, is a snapshot of Mozilla CA store
that is fixed at release time. It is identical on all supported platforms.
Using OpenSSL store allows for external modifications of the store. For most
Linux and BSD distributions, this store is maintained by the distribution
maintainers and system administrators. OpenSSL CA store location is dependent on
configuration of the OpenSSL library but this can be altered at runtime using
environment variables.
See SSL_CERT_DIR and SSL_CERT_FILE.

--use-largepages=mode#

Added in: v13.6.0, v12.17.0

Re-map the Node.js static code to large memory pages at startup. If supported on
the target system, this will cause the Node.js static code to be moved onto 2
MiB pages instead of 4 KiB pages.
The following values are valid for mode:

off: No mapping will be attempted. This is the default.
on: If supported by the OS, mapping will be attempted. Failure to map will
be ignored and a message will be printed to standard error.
silent: If supported by the OS, mapping will be attempted. Failure to map
will be ignored and will not be reported.


--use-system-ca#

History

VersionChanges
v23.9.0
Added support on non-Windows and non-macOS.
v23.8.0
Added in: v23.8.0



Node.js uses the trusted CA certificates present in the system store along with
the --use-bundled-ca option and the NODE_EXTRA_CA_CERTS environment variable.
On platforms other than Windows and macOS, this loads certificates from the directory
and file trusted by OpenSSL, similar to --use-openssl-ca, with the difference being
that it caches the certificates after first load.
On Windows and macOS, the certificate trust policy is planned to follow
Chromium's policy for locally trusted certificates:
On macOS, the following settings are respected:

Default and System Keychains

Trust:

Any certificate where the “When using this certificate” flag is set to “Always Trust” or
Any certificate where the “Secure Sockets Layer (SSL)” flag is set to “Always Trust.”


Distrust:

Any certificate where the “When using this certificate” flag is set to “Never Trust” or
Any certificate where the “Secure Sockets Layer (SSL)” flag is set to “Never Trust.”





On Windows, the following settings are respected (unlike Chromium's policy, distrust
and intermediate CA are not currently supported):

Local Machine (accessed via certlm.msc)

Trust:

Trusted Root Certification Authorities
Trusted People
Enterprise Trust -> Enterprise -> Trusted Root Certification Authorities
Enterprise Trust -> Enterprise -> Trusted People
Enterprise Trust -> Group Policy -> Trusted Root Certification Authorities
Enterprise Trust -> Group Policy -> Trusted People




Current User (accessed via certmgr.msc)

Trust:

Trusted Root Certification Authorities
Enterprise Trust -> Group Policy -> Trusted Root Certification Authorities





On Windows and macOS, Node.js would check that the user settings for the certificates
do not forbid them for TLS server authentication before using them.
On other systems, Node.js loads certificates from the default certificate file
(typically /etc/ssl/cert.pem) and default certificate directory (typically
/etc/ssl/certs) that the version of OpenSSL that Node.js links to respects.
This typically works with the convention on major Linux distributions and other
Unix-like systems. If the overriding OpenSSL environment variables
(typically SSL_CERT_FILE and SSL_CERT_DIR, depending on the configuration
of the OpenSSL that Node.js links to) are set, the specified paths will be used to load
certificates instead. These environment variables can be used as workarounds
if the conventional paths used by the version of OpenSSL Node.js links to are
not consistent with the system configuration that the users have for some reason.

--v8-options#

Added in: v0.1.3

Print V8 command-line options.

--v8-pool-size=num#

Added in: v5.10.0

Set V8's thread pool size which will be used to allocate background jobs.
If set to 0 then Node.js will choose an appropriate size of the thread pool
based on an estimate of the amount of parallelism.
The amount of parallelism refers to the number of computations that can be
carried out simultaneously in a given machine. In general, it's the same as the
amount of CPUs, but it may diverge in environments such as VMs or containers.

-v, --version#

Added in: v0.1.3

Print node's version.

--watch#

History

VersionChanges
v22.0.0, v20.13.0
Watch mode is now stable.
v19.2.0, v18.13.0
Test runner now supports running in watch mode.
v18.11.0, v16.19.0
Added in: v18.11.0, v16.19.0



Starts Node.js in watch mode.
When in watch mode, changes in the watched files cause the Node.js process to
restart.
By default, watch mode will watch the entry point
and any required or imported module.
Use --watch-path to specify what paths to watch.
This flag cannot be combined with
--check, --eval, --interactive, or the REPL.
node --watch index.js copy

--watch-path#

History

VersionChanges
v22.0.0, v20.13.0
Watch mode is now stable.
v18.11.0, v16.19.0
Added in: v18.11.0, v16.19.0



Starts Node.js in watch mode and specifies what paths to watch.
When in watch mode, changes in the watched paths cause the Node.js process to
restart.
This will turn off watching of required or imported modules, even when used in
combination with --watch.
This flag cannot be combined with
--check, --eval, --interactive, --test, or the REPL.
node --watch-path=./src --watch-path=./tests index.js copy
This option is only supported on macOS and Windows.
An ERR_FEATURE_UNAVAILABLE_ON_PLATFORM exception will be thrown
when the option is used on a platform that does not support it.

--watch-preserve-output#

Added in: v19.3.0, v18.13.0

Disable the clearing of the console when watch mode restarts the process.
node --watch --watch-preserve-output test.js copy

--zero-fill-buffers#

Added in: v6.0.0

Automatically zero-fills all newly allocated Buffer and SlowBuffer
instances.

Environment variables#
Stability: 2 - Stable

FORCE_COLOR=[1, 2, 3]#
The FORCE_COLOR environment variable is used to
enable ANSI colorized output. The value may be:

1, true, or the empty string '' indicate 16-color support,
2 to indicate 256-color support, or
3 to indicate 16 million-color support.

When FORCE_COLOR is used and set to a supported value, both the NO_COLOR,
and NODE_DISABLE_COLORS environment variables are ignored.
Any other value will result in colorized output being disabled.

NODE_COMPILE_CACHE=dir#

Added in: v22.1.0

Stability: 1.1 - Active Development
Enable the module compile cache for the Node.js instance. See the documentation of
module compile cache for details.

NODE_DEBUG=module[,…]#

Added in: v0.1.32

','-separated list of core modules that should print debug information.

NODE_DEBUG_NATIVE=module[,…]#
','-separated list of core C++ modules that should print debug information.

NODE_DISABLE_COLORS=1#

Added in: v0.3.0

When set, colors will not be used in the REPL.

NODE_DISABLE_COMPILE_CACHE=1#

Added in: v22.8.0

Stability: 1.1 - Active Development
Disable the module compile cache for the Node.js instance. See the documentation of
module compile cache for details.

NODE_EXTRA_CA_CERTS=file#

Added in: v7.3.0

When set, the well known "root" CAs (like VeriSign) will be extended with the
extra certificates in file. The file should consist of one or more trusted
certificates in PEM format. A message will be emitted (once) with
process.emitWarning() if the file is missing or
malformed, but any errors are otherwise ignored.
Neither the well known nor extra certificates are used when the ca
options property is explicitly specified for a TLS or HTTPS client or server.
This environment variable is ignored when node runs as setuid root or
has Linux file capabilities set.
The NODE_EXTRA_CA_CERTS environment variable is only read when the Node.js
process is first launched. Changing the value at runtime using
process.env.NODE_EXTRA_CA_CERTS has no effect on the current process.

NODE_ICU_DATA=file#

Added in: v0.11.15

Data path for ICU (Intl object) data. Will extend linked-in data when compiled
with small-icu support.

NODE_NO_WARNINGS=1#

Added in: v6.11.0

When set to 1, process warnings are silenced.

NODE_OPTIONS=options...#

Added in: v8.0.0

A space-separated list of command-line options. options... are interpreted
before command-line options, so command-line options will override or
compound after anything in options.... Node.js will exit with an error if
an option that is not allowed in the environment is used, such as -p or a
script file.
If an option value contains a space, it can be escaped using double quotes:
NODE_OPTIONS='--require "./my path/file.js"' copy
A singleton flag passed as a command-line option will override the same flag
passed into NODE_OPTIONS:
# The inspector will be available on port 5555
NODE_OPTIONS='--inspect=localhost:4444' node --inspect=localhost:5555 copy
A flag that can be passed multiple times will be treated as if its
NODE_OPTIONS instances were passed first, and then its command-line
instances afterwards:
NODE_OPTIONS='--require "./a.js"' node --require "./b.js"
# is equivalent to:
node --require "./a.js" --require "./b.js" copy
Node.js options that are allowed are in the following list. If an option
supports both --XX and --no-XX variants, they are both supported but only
one is included in the list below.


--allow-addons
--allow-child-process
--allow-fs-read
--allow-fs-write
--allow-wasi
--allow-worker
--conditions, -C
--cpu-prof-dir
--cpu-prof-interval
--cpu-prof-name
--cpu-prof
--diagnostic-dir
--disable-proto
--disable-sigusr1
--disable-warning
--disable-wasm-trap-handler
--dns-result-order
--enable-fips
--enable-network-family-autoselection
--enable-source-maps
--entry-url
--experimental-abortcontroller
--experimental-addon-modules
--experimental-detect-module
--experimental-eventsource
--experimental-import-meta-resolve
--experimental-json-modules
--experimental-loader
--experimental-modules
--experimental-print-required-tla
--experimental-require-module
--experimental-shadow-realm
--experimental-specifier-resolution
--experimental-test-isolation
--experimental-top-level-await
--experimental-transform-types
--experimental-vm-modules
--experimental-wasi-unstable-preview1
--experimental-wasm-modules
--experimental-webstorage
--force-context-aware
--force-fips
--force-node-api-uncaught-exceptions-policy
--frozen-intrinsics
--heap-prof-dir
--heap-prof-interval
--heap-prof-name
--heap-prof
--heapsnapshot-near-heap-limit
--heapsnapshot-signal
--http-parser
--icu-data-dir
--import
--input-type
--insecure-http-parser
--inspect-brk
--inspect-port, --debug-port
--inspect-publish-uid
--inspect-wait
--inspect
--localstorage-file
--max-http-header-size
--napi-modules
--network-family-autoselection-attempt-timeout
--no-addons
--no-async-context-frame
--no-deprecation
--no-experimental-global-navigator
--no-experimental-repl-await
--no-experimental-sqlite
--no-experimental-strip-types
--no-experimental-websocket
--no-extra-info-on-fatal-exception
--no-force-async-hooks-checks
--no-global-search-paths
--no-network-family-autoselection
--no-warnings
--node-memory-debug
--openssl-config
--openssl-legacy-provider
--openssl-shared-config
--pending-deprecation
--permission
--preserve-symlinks-main
--preserve-symlinks
--prof-process
--redirect-warnings
--report-compact
--report-dir, --report-directory
--report-exclude-env
--report-exclude-network
--report-filename
--report-on-fatalerror
--report-on-signal
--report-signal
--report-uncaught-exception
--require, -r
--secure-heap-min
--secure-heap
--snapshot-blob
--test-coverage-branches
--test-coverage-exclude
--test-coverage-functions
--test-coverage-include
--test-coverage-lines
--test-global-setup
--test-isolation
--test-name-pattern
--test-only
--test-reporter-destination
--test-reporter
--test-shard
--test-skip-pattern
--throw-deprecation
--title
--tls-cipher-list
--tls-keylog
--tls-max-v1.2
--tls-max-v1.3
--tls-min-v1.0
--tls-min-v1.1
--tls-min-v1.2
--tls-min-v1.3
--trace-deprecation
--trace-env-js-stack
--trace-env-native-stack
--trace-env
--trace-event-categories
--trace-event-file-pattern
--trace-events-enabled
--trace-exit
--trace-require-module
--trace-sigint
--trace-sync-io
--trace-tls
--trace-uncaught
--trace-warnings
--track-heap-objects
--unhandled-rejections
--use-bundled-ca
--use-largepages
--use-openssl-ca
--use-system-ca
--v8-pool-size
--watch-path
--watch-preserve-output
--watch
--zero-fill-buffers


V8 options that are allowed are:


--abort-on-uncaught-exception
--disallow-code-generation-from-strings
--enable-etw-stack-walking
--expose-gc
--interpreted-frames-native-stack
--jitless
--max-old-space-size
--max-semi-space-size
--perf-basic-prof-only-functions
--perf-basic-prof
--perf-prof-unwinding-info
--perf-prof
--stack-trace-limit



--perf-basic-prof-only-functions, --perf-basic-prof,
--perf-prof-unwinding-info, and --perf-prof are only available on Linux.
--enable-etw-stack-walking is only available on Windows.


NODE_PATH=path[:…]#

Added in: v0.1.32

':'-separated list of directories prefixed to the module search path.
On Windows, this is a ';'-separated list instead.

NODE_PENDING_DEPRECATION=1#

Added in: v8.0.0

When set to 1, emit pending deprecation warnings.
Pending deprecations are generally identical to a runtime deprecation with the
notable exception that they are turned off by default and will not be emitted
unless either the --pending-deprecation command-line flag, or the
NODE_PENDING_DEPRECATION=1 environment variable, is set. Pending deprecations
are used to provide a kind of selective "early warning" mechanism that
developers may leverage to detect deprecated API usage.

NODE_PENDING_PIPE_INSTANCES=instances#
Set the number of pending pipe instance handles when the pipe server is waiting
for connections. This setting applies to Windows only.

NODE_PRESERVE_SYMLINKS=1#

Added in: v7.1.0

When set to 1, instructs the module loader to preserve symbolic links when
resolving and caching modules.

NODE_REDIRECT_WARNINGS=file#

Added in: v8.0.0

When set, process warnings will be emitted to the given file instead of
printing to stderr. The file will be created if it does not exist, and will be
appended to if it does. If an error occurs while attempting to write the
warning to the file, the warning will be written to stderr instead. This is
equivalent to using the --redirect-warnings=file command-line flag.

NODE_REPL_EXTERNAL_MODULE=file#

History

VersionChanges
v22.3.0, v20.16.0
Remove the possibility to use this env var with kDisableNodeOptionsEnv for embedders.
v13.0.0, v12.16.0
Added in: v13.0.0, v12.16.0



Path to a Node.js module which will be loaded in place of the built-in REPL.
Overriding this value to an empty string ('') will use the built-in REPL.

NODE_REPL_HISTORY=file#

Added in: v3.0.0

Path to the file used to store the persistent REPL history. The default path is
~/.node_repl_history, which is overridden by this variable. Setting the value
to an empty string ('' or ' ') disables persistent REPL history.

NODE_SKIP_PLATFORM_CHECK=value#

Added in: v14.5.0

If value equals '1', the check for a supported platform is skipped during
Node.js startup. Node.js might not execute correctly. Any issues encountered
on unsupported platforms will not be fixed.

NODE_TEST_CONTEXT=value#
If value equals 'child', test reporter options will be overridden and test
output will be sent to stdout in the TAP format. If any other value is provided,
Node.js makes no guarantees about the reporter format used or its stability.

NODE_TLS_REJECT_UNAUTHORIZED=value#
If value equals '0', certificate validation is disabled for TLS connections.
This makes TLS, and HTTPS by extension, insecure. The use of this environment
variable is strongly discouraged.

NODE_USE_ENV_PROXY=1#

Added in: v24.0.0

Stability: 1.1 - Active Development
When enabled, Node.js parses the HTTP_PROXY, HTTPS_PROXY and NO_PROXY
environment variables during startup, and tunnels requests over the
specified proxy.
This currently only affects requests sent over fetch(). Support for other
built-in http and https methods is under way.

NODE_V8_COVERAGE=dir#
When set, Node.js will begin outputting V8 JavaScript code coverage and
Source Map data to the directory provided as an argument (coverage
information is written as JSON to files with a coverage prefix).
NODE_V8_COVERAGE will automatically propagate to subprocesses, making it
easier to instrument applications that call the child_process.spawn() family
of functions. NODE_V8_COVERAGE can be set to an empty string, to prevent
propagation.

Coverage output#
Coverage is output as an array of ScriptCoverage objects on the top-level
key result:
{
  "result": [
    {
      "scriptId": "67",
      "url": "internal/tty.js",
      "functions": []
    }
  ]
} copy

Source map cache#
Stability: 1 - Experimental
If found, source map data is appended to the top-level key source-map-cache
on the JSON coverage object.
source-map-cache is an object with keys representing the files source maps
were extracted from, and values which include the raw source-map URL
(in the key url), the parsed Source Map v3 information (in the key data),
and the line lengths of the source file (in the key lineLengths).
{
  "result": [
    {
      "scriptId": "68",
      "url": "file:///absolute/path/to/source.js",
      "functions": []
    }
  ],
  "source-map-cache": {
    "file:///absolute/path/to/source.js": {
      "url": "./path-to-map.json",
      "data": {
        "version": 3,
        "sources": [
          "file:///absolute/path/to/original.js"
        ],
        "names": [
          "Foo",
          "console",
          "info"
        ],
        "mappings": "MAAMA,IACJC,YAAaC",
        "sourceRoot": "./"
      },
      "lineLengths": [
        13,
        62,
        38,
        27
      ]
    }
  }
} copy

NO_COLOR=<any>#
NO_COLOR  is an alias for NODE_DISABLE_COLORS. The value of the
environment variable is arbitrary.

OPENSSL_CONF=file#

Added in: v6.11.0

Load an OpenSSL configuration file on startup. Among other uses, this can be
used to enable FIPS-compliant crypto if Node.js is built with
./configure --openssl-fips.
If the --openssl-config command-line option is used, the environment
variable is ignored.

SSL_CERT_DIR=dir#

Added in: v7.7.0

If --use-openssl-ca is enabled, or if --use-system-ca is enabled on
platforms other than macOS and Windows, this overrides and sets OpenSSL's directory
containing trusted certificates.
Be aware that unless the child environment is explicitly set, this environment
variable will be inherited by any child processes, and if they use OpenSSL, it
may cause them to trust the same CAs as node.

SSL_CERT_FILE=file#

Added in: v7.7.0

If --use-openssl-ca is enabled, or if --use-system-ca is enabled on
platforms other than macOS and Windows, this overrides and sets OpenSSL's file
containing trusted certificates.
Be aware that unless the child environment is explicitly set, this environment
variable will be inherited by any child processes, and if they use OpenSSL, it
may cause them to trust the same CAs as node.

TZ#

History

VersionChanges
v16.2.0
Changing the TZ variable using process.env.TZ = changes the timezone on Windows as well.
v13.0.0
Changing the TZ variable using process.env.TZ = changes the timezone on POSIX systems.
v0.0.1
Added in: v0.0.1



The TZ environment variable is used to specify the timezone configuration.
While Node.js does not support all of the various ways that TZ is handled in
other environments, it does support basic timezone IDs (such as
'Etc/UTC', 'Europe/Paris', or 'America/New_York').
It may support a few other abbreviations or aliases, but these are strongly
discouraged and not guaranteed.
$ TZ=Europe/Dublin node -pe "new Date().toString()"
Wed May 12 2021 20:30:48 GMT+0100 (Irish Standard Time) copy

UV_THREADPOOL_SIZE=size#
Set the number of threads used in libuv's threadpool to size threads.
Asynchronous system APIs are used by Node.js whenever possible, but where they
do not exist, libuv's threadpool is used to create asynchronous node APIs based
on synchronous system APIs. Node.js APIs that use the threadpool are:

all fs APIs, other than the file watcher APIs and those that are explicitly
synchronous
asynchronous crypto APIs such as crypto.pbkdf2(), crypto.scrypt(),
crypto.randomBytes(), crypto.randomFill(), crypto.generateKeyPair()
dns.lookup()
all zlib APIs, other than those that are explicitly synchronous

Because libuv's threadpool has a fixed size, it means that if for whatever
reason any of these APIs takes a long time, other (seemingly unrelated) APIs
that run in libuv's threadpool will experience degraded performance. In order to
mitigate this issue, one potential solution is to increase the size of libuv's
threadpool by setting the 'UV_THREADPOOL_SIZE' environment variable to a value
greater than 4 (its current default value). However, setting this from inside
the process using process.env.UV_THREADPOOL_SIZE=size is not guranteed to work
as the threadpool would have been created as part of the runtime initialisation
much before user code is run. For more information, see the libuv threadpool documentation.

Useful V8 options#
V8 has its own set of CLI options. Any V8 CLI option that is provided to node
will be passed on to V8 to handle. V8's options have no stability guarantee.
The V8 team themselves don't consider them to be part of their formal API,
and reserve the right to change them at any time. Likewise, they are not
covered by the Node.js stability guarantees. Many of the V8
options are of interest only to V8 developers. Despite this, there is a small
set of V8 options that are widely applicable to Node.js, and they are
documented here:


--abort-on-uncaught-exception#

--disallow-code-generation-from-strings#

--enable-etw-stack-walking#

--expose-gc#

--harmony-shadow-realm#

--interpreted-frames-native-stack#

--jitless#



--max-old-space-size=SIZE (in MiB)#
Sets the max memory size of V8's old memory section. As memory
consumption approaches the limit, V8 will spend more time on
garbage collection in an effort to free unused memory.
On a machine with 2 GiB of memory, consider setting this to
1536 (1.5 GiB) to leave some memory for other uses and avoid swapping.
node --max-old-space-size=1536 index.js copy



--max-semi-space-size=SIZE (in MiB)#
Sets the maximum semi-space size for V8's scavenge garbage collector in
MiB (mebibytes).
Increasing the max size of a semi-space may improve throughput for Node.js at
the cost of more memory consumption.
Since the young generation size of the V8 heap is three times (see
YoungGenerationSizeFromSemiSpaceSize in V8) the size of the semi-space,
an increase of 1 MiB to semi-space applies to each of the three individual
semi-spaces and causes the heap size to increase by 3 MiB. The throughput
improvement depends on your workload (see #42511).
The default value depends on the memory limit. For example, on 64-bit systems
with a memory limit of 512 MiB, the max size of a semi-space defaults to 1 MiB.
For memory limits up to and including 2GiB, the default max size of a
semi-space will be less than 16 MiB on 64-bit systems.
To get the best configuration for your application, you should try different
max-semi-space-size values when running benchmarks for your application.
For example, benchmark on a 64-bit systems:
for MiB in 16 32 64 128; do
    node --max-semi-space-size=$MiB index.js
done copy

--perf-basic-prof#

--perf-basic-prof-only-functions#

--perf-prof#

--perf-prof-unwinding-info#

--prof#

--security-revert#

--stack-trace-limit=limit#
The maximum number of stack frames to collect in an error's stack trace.
Setting it to 0 disables stack trace collection. The default value is 10.
node --stack-trace-limit=12 -p -e "Error.stackTraceLimit" # prints 12 copy\n\n\n\nNode.js
        
      
      
About this documentation
Usage and example



Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Modules: TypeScript
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
Readline
REPL
Report
Single executable applications
SQLite
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker

    

    
      
        
          Node.js v24.0.1 documentation
          
            
            
          
        
        
          
            Node.js v24.0.1
            
    
      
        
        Table of contents
      

      
Console

Class: Console

new Console(stdout[, stderr][, ignoreErrors])
new Console(options)
console.assert(value[, ...message])
console.clear()
console.count([label])
console.countReset([label])
console.debug(data[, ...args])
console.dir(obj[, options])
console.dirxml(...data)
console.error([data][, ...args])
console.group([...label])
console.groupCollapsed()
console.groupEnd()
console.info([data][, ...args])
console.log([data][, ...args])
console.table(tabularData[, properties])
console.time([label])
console.timeEnd([label])
console.timeLog([label][, ...data])
console.trace([message][, ...args])
console.warn([data][, ...args])


Inspector only methods

console.profile([label])
console.profileEnd([label])
console.timeStamp([label])





    
  
            
    
      
        
        Index
      

      
About this documentation
Usage and example

      
        Index
      
    
  


Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Modules: TypeScript
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
Readline
REPL
Report
Single executable applications
SQLite
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker

    
  
            
    
      
        
        Other versions
      
      24.x
23.x
22.x LTS
21.x
20.x LTS
19.x
18.x
17.x
16.x
15.x
14.x
13.x
12.x
11.x
10.x
9.x
8.x
7.x
6.x
5.x
4.x
0.12.x
0.10.x
    
  
            
              
                
                Options
              
        
              
                
                  
                    View on single page
                  
                  
                    View as JSON
                  
                  Edit on GitHub    
                
              
            
          
        
        
      

      Table of contents
Console

Class: Console

new Console(stdout[, stderr][, ignoreErrors])
new Console(options)
console.assert(value[, ...message])
console.clear()
console.count([label])
console.countReset([label])
console.debug(data[, ...args])
console.dir(obj[, options])
console.dirxml(...data)
console.error([data][, ...args])
console.group([...label])
console.groupCollapsed()
console.groupEnd()
console.info([data][, ...args])
console.log([data][, ...args])
console.table(tabularData[, properties])
console.time([label])
console.timeEnd([label])
console.timeLog([label][, ...data])
console.trace([message][, ...args])
console.warn([data][, ...args])


Inspector only methods

console.profile([label])
console.profileEnd([label])
console.timeStamp([label])






      
        Console#

Stability: 2 - Stable
Source Code: lib/console.js
The node:console module provides a simple debugging console that is similar to
the JavaScript console mechanism provided by web browsers.
The module exports two specific components:

A Console class with methods such as console.log(), console.error(), and
console.warn() that can be used to write to any Node.js stream.
A global console instance configured to write to process.stdout and
process.stderr. The global console can be used without calling
require('node:console').

Warning: The global console object's methods are neither consistently
synchronous like the browser APIs they resemble, nor are they consistently
asynchronous like all other Node.js streams. Programs that desire to depend
on the synchronous / asynchronous behavior of the console functions should
first figure out the nature of console's backing stream. This is because the
stream is dependent on the underlying platform and standard stream
configuration of the current process. See the note on process I/O for
more information.
Example using the global console:
console.log('hello world');
// Prints: hello world, to stdout
console.log('hello %s', 'world');
// Prints: hello world, to stdout
console.error(new Error('Whoops, something bad happened'));
// Prints error message and stack trace to stderr:
//   Error: Whoops, something bad happened
//     at [eval]:5:15
//     at Script.runInThisContext (node:vm:132:18)
//     at Object.runInThisContext (node:vm:309:38)
//     at node:internal/process/execution:77:19
//     at [eval]-wrapper:6:22
//     at evalScript (node:internal/process/execution:76:60)
//     at node:internal/main/eval_string:23:3

const name = 'Will Robinson';
console.warn(`Danger ${name}! Danger!`);
// Prints: Danger Will Robinson! Danger!, to stderr copy
Example using the Console class:
const out = getStreamSomehow();
const err = getStreamSomehow();
const myConsole = new console.Console(out, err);

myConsole.log('hello world');
// Prints: hello world, to out
myConsole.log('hello %s', 'world');
// Prints: hello world, to out
myConsole.error(new Error('Whoops, something bad happened'));
// Prints: [Error: Whoops, something bad happened], to err

const name = 'Will Robinson';
myConsole.warn(`Danger ${name}! Danger!`);
// Prints: Danger Will Robinson! Danger!, to err copy
Class: Console#

History

VersionChanges
v8.0.0
Errors that occur while writing to the underlying streams will now be ignored by default.




The Console class can be used to create a simple logger with configurable
output streams and can be accessed using either require('node:console').Console
or console.Console (or their destructured counterparts):

import { Console } from 'node:console';const { Console } = require('node:console');copy
const { Console } = console; copy

new Console(stdout[, stderr][, ignoreErrors])#

new Console(options)#

History

VersionChanges
v14.2.0, v12.17.0
The groupIndentation option was introduced.
v11.7.0
The inspectOptions option is introduced.
v10.0.0
The Console constructor now supports an options argument, and the colorMode option was introduced.
v8.0.0
The ignoreErrors option was introduced.




options <Object>

stdout <stream.Writable>
stderr <stream.Writable>
ignoreErrors <boolean> Ignore errors when writing to the underlying
streams. Default: true.
colorMode <boolean> | <string> Set color support for this Console instance.
Setting to true enables coloring while inspecting values. Setting to
false disables coloring while inspecting values. Setting to
'auto' makes color support depend on the value of the isTTY property
and the value returned by getColorDepth() on the respective stream. This
option can not be used, if inspectOptions.colors is set as well.
Default: 'auto'.
inspectOptions <Object> Specifies options that are passed along to
util.inspect().
groupIndentation <number> Set group indentation.
Default: 2.



Creates a new Console with one or two writable stream instances. stdout is a
writable stream to print log or info output. stderr is used for warning or
error output. If stderr is not provided, stdout is used for stderr.

import { createWriteStream } from 'node:fs';
import { Console } from 'node:console';
// Alternatively
// const { Console } = console;

const output = createWriteStream('./stdout.log');
const errorOutput = createWriteStream('./stderr.log');
// Custom simple logger
const logger = new Console({ stdout: output, stderr: errorOutput });
// use it like console
const count = 5;
logger.log('count: %d', count);
// In stdout.log: count 5const fs = require('node:fs');
const { Console } = require('node:console');
// Alternatively
// const { Console } = console;

const output = fs.createWriteStream('./stdout.log');
const errorOutput = fs.createWriteStream('./stderr.log');
// Custom simple logger
const logger = new Console({ stdout: output, stderr: errorOutput });
// use it like console
const count = 5;
logger.log('count: %d', count);
// In stdout.log: count 5copy
The global console is a special Console whose output is sent to
process.stdout and process.stderr. It is equivalent to calling:
new Console({ stdout: process.stdout, stderr: process.stderr }); copy

console.assert(value[, ...message])#

History

VersionChanges
v10.0.0
The implementation is now spec compliant and does not throw anymore.
v0.1.101
Added in: v0.1.101




value <any> The value tested for being truthy.
...message <any> All arguments besides value are used as error message.

console.assert() writes a message if value is falsy or omitted. It only
writes a message and does not otherwise affect execution. The output always
starts with "Assertion failed". If provided, message is formatted using
util.format().
If value is truthy, nothing happens.
console.assert(true, 'does nothing');

console.assert(false, 'Whoops %s work', 'didn\'t');
// Assertion failed: Whoops didn't work

console.assert();
// Assertion failed copy

console.clear()#

Added in: v8.3.0

When stdout is a TTY, calling console.clear() will attempt to clear the
TTY. When stdout is not a TTY, this method does nothing.
The specific operation of console.clear() can vary across operating systems
and terminal types. For most Linux operating systems, console.clear()
operates similarly to the clear shell command. On Windows, console.clear()
will clear only the output in the current terminal viewport for the Node.js
binary.

console.count([label])#

Added in: v8.3.0


label <string> The display label for the counter. Default: 'default'.

Maintains an internal counter specific to label and outputs to stdout the
number of times console.count() has been called with the given label.

> console.count()
default: 1
undefined
> console.count('default')
default: 2
undefined
> console.count('abc')
abc: 1
undefined
> console.count('xyz')
xyz: 1
undefined
> console.count('abc')
abc: 2
undefined
> console.count()
default: 3
undefined
> copy

console.countReset([label])#

Added in: v8.3.0


label <string> The display label for the counter. Default: 'default'.

Resets the internal counter specific to label.

> console.count('abc');
abc: 1
undefined
> console.countReset('abc');
undefined
> console.count('abc');
abc: 1
undefined
> copy

console.debug(data[, ...args])#

History

VersionChanges
v8.10.0
console.debug is now an alias for console.log.
v8.0.0
Added in: v8.0.0




data <any>
...args <any>

The console.debug() function is an alias for console.log().

console.dir(obj[, options])#

Added in: v0.1.101


obj <any>
options <Object>

showHidden <boolean> If true then the object's non-enumerable and symbol
properties will be shown too. Default: false.
depth <number> Tells util.inspect() how many times to recurse while
formatting the object. This is useful for inspecting large complicated
objects. To make it recurse indefinitely, pass null. Default: 2.
colors <boolean> If true, then the output will be styled with ANSI color
codes. Colors are customizable;
see customizing util.inspect() colors. Default: false.



Uses util.inspect() on obj and prints the resulting string to stdout.
This function bypasses any custom inspect() function defined on obj.

console.dirxml(...data)#

History

VersionChanges
v9.3.0
console.dirxml now calls console.log for its arguments.
v8.0.0
Added in: v8.0.0




...data <any>

This method calls console.log() passing it the arguments received.
This method does not produce any XML formatting.

console.error([data][, ...args])#

Added in: v0.1.100


data <any>
...args <any>

Prints to stderr with newline. Multiple arguments can be passed, with the
first used as the primary message and all additional used as substitution
values similar to printf(3) (the arguments are all passed to
util.format()).
const code = 5;
console.error('error #%d', code);
// Prints: error #5, to stderr
console.error('error', code);
// Prints: error 5, to stderr copy
If formatting elements (e.g. %d) are not found in the first string then
util.inspect() is called on each argument and the resulting string
values are concatenated. See util.format() for more information.

console.group([...label])#

Added in: v8.5.0


...label <any>

Increases indentation of subsequent lines by spaces for groupIndentation
length.
If one or more labels are provided, those are printed first without the
additional indentation.

console.groupCollapsed()#

Added in: v8.5.0

An alias for console.group().

console.groupEnd()#

Added in: v8.5.0

Decreases indentation of subsequent lines by spaces for groupIndentation
length.

console.info([data][, ...args])#

Added in: v0.1.100


data <any>
...args <any>

The console.info() function is an alias for console.log().

console.log([data][, ...args])#

Added in: v0.1.100


data <any>
...args <any>

Prints to stdout with newline. Multiple arguments can be passed, with the
first used as the primary message and all additional used as substitution
values similar to printf(3) (the arguments are all passed to
util.format()).
const count = 5;
console.log('count: %d', count);
// Prints: count: 5, to stdout
console.log('count:', count);
// Prints: count: 5, to stdout copy
See util.format() for more information.

console.table(tabularData[, properties])#

Added in: v10.0.0


tabularData <any>
properties <string[]> Alternate properties for constructing the table.

Try to construct a table with the columns of the properties of tabularData
(or use properties) and rows of tabularData and log it. Falls back to just
logging the argument if it can't be parsed as tabular.
// These can't be parsed as tabular data
console.table(Symbol());
// Symbol()

console.table(undefined);
// undefined

console.table([{ a: 1, b: 'Y' }, { a: 'Z', b: 2 }]);
// ┌─────────┬─────┬─────┐
// │ (index) │ a   │ b   │
// ├─────────┼─────┼─────┤
// │ 0       │ 1   │ 'Y' │
// │ 1       │ 'Z' │ 2   │
// └─────────┴─────┴─────┘

console.table([{ a: 1, b: 'Y' }, { a: 'Z', b: 2 }], ['a']);
// ┌─────────┬─────┐
// │ (index) │ a   │
// ├─────────┼─────┤
// │ 0       │ 1   │
// │ 1       │ 'Z' │
// └─────────┴─────┘ copy

console.time([label])#

Added in: v0.1.104


label <string> Default: 'default'

Starts a timer that can be used to compute the duration of an operation. Timers
are identified by a unique label. Use the same label when calling
console.timeEnd() to stop the timer and output the elapsed time in
suitable time units to stdout. For example, if the elapsed
time is 3869ms, console.timeEnd() displays "3.869s".

console.timeEnd([label])#

History

VersionChanges
v13.0.0
The elapsed time is displayed with a suitable time unit.
v6.0.0
This method no longer supports multiple calls that don't map to individual console.time() calls; see below for details.
v0.1.104
Added in: v0.1.104




label <string> Default: 'default'

Stops a timer that was previously started by calling console.time() and
prints the result to stdout:
console.time('bunch-of-stuff');
// Do a bunch of stuff.
console.timeEnd('bunch-of-stuff');
// Prints: bunch-of-stuff: 225.438ms copy

console.timeLog([label][, ...data])#

Added in: v10.7.0


label <string> Default: 'default'
...data <any>

For a timer that was previously started by calling console.time(), prints
the elapsed time and other data arguments to stdout:
console.time('process');
const value = expensiveProcess1(); // Returns 42
console.timeLog('process', value);
// Prints "process: 365.227ms 42".
doExpensiveProcess2(value);
console.timeEnd('process'); copy

console.trace([message][, ...args])#

Added in: v0.1.104


message <any>
...args <any>

Prints to stderr the string 'Trace: ', followed by the util.format()
formatted message and stack trace to the current position in the code.
console.trace('Show me');
// Prints: (stack trace will vary based on where trace is called)
//  Trace: Show me
//    at repl:2:9
//    at REPLServer.defaultEval (repl.js:248:27)
//    at bound (domain.js:287:14)
//    at REPLServer.runBound [as eval] (domain.js:300:12)
//    at REPLServer.<anonymous> (repl.js:412:12)
//    at emitOne (events.js:82:20)
//    at REPLServer.emit (events.js:169:7)
//    at REPLServer.Interface._onLine (readline.js:210:10)
//    at REPLServer.Interface._line (readline.js:549:8)
//    at REPLServer.Interface._ttyWrite (readline.js:826:14) copy

console.warn([data][, ...args])#

Added in: v0.1.100


data <any>
...args <any>

The console.warn() function is an alias for console.error().

Inspector only methods#
The following methods are exposed by the V8 engine in the general API but do
not display anything unless used in conjunction with the inspector
(--inspect flag).

console.profile([label])#

Added in: v8.0.0


label <string>

This method does not display anything unless used in the inspector. The
console.profile() method starts a JavaScript CPU profile with an optional
label until console.profileEnd() is called. The profile is then added to
the Profile panel of the inspector.
console.profile('MyLabel');
// Some code
console.profileEnd('MyLabel');
// Adds the profile 'MyLabel' to the Profiles panel of the inspector. copy

console.profileEnd([label])#

Added in: v8.0.0


label <string>

This method does not display anything unless used in the inspector. Stops the
current JavaScript CPU profiling session if one has been started and prints
the report to the Profiles panel of the inspector. See
console.profile() for an example.
If this method is called without a label, the most recently started profile is
stopped.

console.timeStamp([label])#

Added in: v8.0.0


label <string>

This method does not display anything unless used in the inspector. The
console.timeStamp() method adds an event with the label 'label' to the
Timeline panel of the inspector.\n\n\n\nNode.js
        
      
      
About this documentation
Usage and example



Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Modules: TypeScript
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
Readline
REPL
Report
Single executable applications
SQLite
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker

    

    
      
        
          Node.js v24.0.1 documentation
          
            
            
          
        
        
          
            Node.js v24.0.1
            
    
      
        
        Table of contents
      

      
Crypto

Determining if crypto support is unavailable
Class: Certificate

Static method: Certificate.exportChallenge(spkac[, encoding])
Static method: Certificate.exportPublicKey(spkac[, encoding])
Static method: Certificate.verifySpkac(spkac[, encoding])
Legacy API

new crypto.Certificate()
certificate.exportChallenge(spkac[, encoding])
certificate.exportPublicKey(spkac[, encoding])
certificate.verifySpkac(spkac[, encoding])




Class: Cipheriv

cipher.final([outputEncoding])
cipher.getAuthTag()
cipher.setAAD(buffer[, options])
cipher.setAutoPadding([autoPadding])
cipher.update(data[, inputEncoding][, outputEncoding])


Class: Decipheriv

decipher.final([outputEncoding])
decipher.setAAD(buffer[, options])
decipher.setAuthTag(buffer[, encoding])
decipher.setAutoPadding([autoPadding])
decipher.update(data[, inputEncoding][, outputEncoding])


Class: DiffieHellman

diffieHellman.computeSecret(otherPublicKey[, inputEncoding][, outputEncoding])
diffieHellman.generateKeys([encoding])
diffieHellman.getGenerator([encoding])
diffieHellman.getPrime([encoding])
diffieHellman.getPrivateKey([encoding])
diffieHellman.getPublicKey([encoding])
diffieHellman.setPrivateKey(privateKey[, encoding])
diffieHellman.setPublicKey(publicKey[, encoding])
diffieHellman.verifyError


Class: DiffieHellmanGroup
Class: ECDH

Static method: ECDH.convertKey(key, curve[, inputEncoding[, outputEncoding[, format]]])
ecdh.computeSecret(otherPublicKey[, inputEncoding][, outputEncoding])
ecdh.generateKeys([encoding[, format]])
ecdh.getPrivateKey([encoding])
ecdh.getPublicKey([encoding][, format])
ecdh.setPrivateKey(privateKey[, encoding])
ecdh.setPublicKey(publicKey[, encoding])


Class: Hash

hash.copy([options])
hash.digest([encoding])
hash.update(data[, inputEncoding])


Class: Hmac

hmac.digest([encoding])
hmac.update(data[, inputEncoding])


Class: KeyObject

Static method: KeyObject.from(key)
keyObject.asymmetricKeyDetails
keyObject.asymmetricKeyType
keyObject.equals(otherKeyObject)
keyObject.export([options])
keyObject.symmetricKeySize
keyObject.toCryptoKey(algorithm, extractable, keyUsages)
keyObject.type


Class: Sign

sign.sign(privateKey[, outputEncoding])
sign.update(data[, inputEncoding])


Class: Verify

verify.update(data[, inputEncoding])
verify.verify(object, signature[, signatureEncoding])


Class: X509Certificate

new X509Certificate(buffer)
x509.ca
x509.checkEmail(email[, options])
x509.checkHost(name[, options])
x509.checkIP(ip)
x509.checkIssued(otherCert)
x509.checkPrivateKey(privateKey)
x509.extKeyUsage
x509.fingerprint
x509.fingerprint256
x509.fingerprint512
x509.infoAccess
x509.issuer
x509.issuerCertificate
x509.publicKey
x509.raw
x509.serialNumber
x509.subject
x509.subjectAltName
x509.toJSON()
x509.toLegacyObject()
x509.toString()
x509.validFrom
x509.validFromDate
x509.validTo
x509.validToDate
x509.verify(publicKey)


node:crypto module methods and properties

crypto.checkPrime(candidate[, options], callback)
crypto.checkPrimeSync(candidate[, options])
crypto.constants
crypto.createCipheriv(algorithm, key, iv[, options])
crypto.createDecipheriv(algorithm, key, iv[, options])
crypto.createDiffieHellman(prime[, primeEncoding][, generator][, generatorEncoding])
crypto.createDiffieHellman(primeLength[, generator])
crypto.createDiffieHellmanGroup(name)
crypto.createECDH(curveName)
crypto.createHash(algorithm[, options])
crypto.createHmac(algorithm, key[, options])
crypto.createPrivateKey(key)
crypto.createPublicKey(key)
crypto.createSecretKey(key[, encoding])
crypto.createSign(algorithm[, options])
crypto.createVerify(algorithm[, options])
crypto.diffieHellman(options[, callback])
crypto.fips
crypto.generateKey(type, options, callback)
crypto.generateKeyPair(type, options, callback)
crypto.generateKeyPairSync(type, options)
crypto.generateKeySync(type, options)
crypto.generatePrime(size[, options[, callback]])
crypto.generatePrimeSync(size[, options])
crypto.getCipherInfo(nameOrNid[, options])
crypto.getCiphers()
crypto.getCurves()
crypto.getDiffieHellman(groupName)
crypto.getFips()
crypto.getHashes()
crypto.getRandomValues(typedArray)
crypto.hash(algorithm, data[, outputEncoding])
crypto.hkdf(digest, ikm, salt, info, keylen, callback)
crypto.hkdfSync(digest, ikm, salt, info, keylen)
crypto.pbkdf2(password, salt, iterations, keylen, digest, callback)
crypto.pbkdf2Sync(password, salt, iterations, keylen, digest)
crypto.privateDecrypt(privateKey, buffer)
crypto.privateEncrypt(privateKey, buffer)
crypto.publicDecrypt(key, buffer)
crypto.publicEncrypt(key, buffer)
crypto.randomBytes(size[, callback])
crypto.randomFill(buffer[, offset][, size], callback)
crypto.randomFillSync(buffer[, offset][, size])
crypto.randomInt([min, ]max[, callback])
crypto.randomUUID([options])
crypto.scrypt(password, salt, keylen[, options], callback)
crypto.scryptSync(password, salt, keylen[, options])
crypto.secureHeapUsed()
crypto.setEngine(engine[, flags])
crypto.setFips(bool)
crypto.sign(algorithm, data, key[, callback])
crypto.subtle
crypto.timingSafeEqual(a, b)
crypto.verify(algorithm, data, key, signature[, callback])
crypto.webcrypto


Notes

Using strings as inputs to cryptographic APIs
Legacy streams API (prior to Node.js 0.10)
Support for weak or compromised algorithms
CCM mode
FIPS mode


Crypto constants

OpenSSL options
OpenSSL engine constants
Other OpenSSL constants
Node.js crypto constants





    
  
            
    
      
        
        Index
      

      
About this documentation
Usage and example

      
        Index
      
    
  


Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Modules: TypeScript
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
Readline
REPL
Report
Single executable applications
SQLite
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker

    
  
            
    
      
        
        Other versions
      
      24.x
23.x
22.x LTS
21.x
20.x LTS
19.x
18.x
17.x
16.x
15.x
14.x
13.x
12.x
11.x
10.x
9.x
8.x
7.x
6.x
5.x
4.x
0.12.x
0.10.x
    
  
            
              
                
                Options
              
        
              
                
                  
                    View on single page
                  
                  
                    View as JSON
                  
                  Edit on GitHub    
                
              
            
          
        
        
      

      Table of contents
Crypto

Determining if crypto support is unavailable
Class: Certificate

Static method: Certificate.exportChallenge(spkac[, encoding])
Static method: Certificate.exportPublicKey(spkac[, encoding])
Static method: Certificate.verifySpkac(spkac[, encoding])
Legacy API

new crypto.Certificate()
certificate.exportChallenge(spkac[, encoding])
certificate.exportPublicKey(spkac[, encoding])
certificate.verifySpkac(spkac[, encoding])




Class: Cipheriv

cipher.final([outputEncoding])
cipher.getAuthTag()
cipher.setAAD(buffer[, options])
cipher.setAutoPadding([autoPadding])
cipher.update(data[, inputEncoding][, outputEncoding])


Class: Decipheriv

decipher.final([outputEncoding])
decipher.setAAD(buffer[, options])
decipher.setAuthTag(buffer[, encoding])
decipher.setAutoPadding([autoPadding])
decipher.update(data[, inputEncoding][, outputEncoding])


Class: DiffieHellman

diffieHellman.computeSecret(otherPublicKey[, inputEncoding][, outputEncoding])
diffieHellman.generateKeys([encoding])
diffieHellman.getGenerator([encoding])
diffieHellman.getPrime([encoding])
diffieHellman.getPrivateKey([encoding])
diffieHellman.getPublicKey([encoding])
diffieHellman.setPrivateKey(privateKey[, encoding])
diffieHellman.setPublicKey(publicKey[, encoding])
diffieHellman.verifyError


Class: DiffieHellmanGroup
Class: ECDH

Static method: ECDH.convertKey(key, curve[, inputEncoding[, outputEncoding[, format]]])
ecdh.computeSecret(otherPublicKey[, inputEncoding][, outputEncoding])
ecdh.generateKeys([encoding[, format]])
ecdh.getPrivateKey([encoding])
ecdh.getPublicKey([encoding][, format])
ecdh.setPrivateKey(privateKey[, encoding])
ecdh.setPublicKey(publicKey[, encoding])


Class: Hash

hash.copy([options])
hash.digest([encoding])
hash.update(data[, inputEncoding])


Class: Hmac

hmac.digest([encoding])
hmac.update(data[, inputEncoding])


Class: KeyObject

Static method: KeyObject.from(key)
keyObject.asymmetricKeyDetails
keyObject.asymmetricKeyType
keyObject.equals(otherKeyObject)
keyObject.export([options])
keyObject.symmetricKeySize
keyObject.toCryptoKey(algorithm, extractable, keyUsages)
keyObject.type


Class: Sign

sign.sign(privateKey[, outputEncoding])
sign.update(data[, inputEncoding])


Class: Verify

verify.update(data[, inputEncoding])
verify.verify(object, signature[, signatureEncoding])


Class: X509Certificate

new X509Certificate(buffer)
x509.ca
x509.checkEmail(email[, options])
x509.checkHost(name[, options])
x509.checkIP(ip)
x509.checkIssued(otherCert)
x509.checkPrivateKey(privateKey)
x509.extKeyUsage
x509.fingerprint
x509.fingerprint256
x509.fingerprint512
x509.infoAccess
x509.issuer
x509.issuerCertificate
x509.publicKey
x509.raw
x509.serialNumber
x509.subject
x509.subjectAltName
x509.toJSON()
x509.toLegacyObject()
x509.toString()
x509.validFrom
x509.validFromDate
x509.validTo
x509.validToDate
x509.verify(publicKey)


node:crypto module methods and properties

crypto.checkPrime(candidate[, options], callback)
crypto.checkPrimeSync(candidate[, options])
crypto.constants
crypto.createCipheriv(algorithm, key, iv[, options])
crypto.createDecipheriv(algorithm, key, iv[, options])
crypto.createDiffieHellman(prime[, primeEncoding][, generator][, generatorEncoding])
crypto.createDiffieHellman(primeLength[, generator])
crypto.createDiffieHellmanGroup(name)
crypto.createECDH(curveName)
crypto.createHash(algorithm[, options])
crypto.createHmac(algorithm, key[, options])
crypto.createPrivateKey(key)
crypto.createPublicKey(key)
crypto.createSecretKey(key[, encoding])
crypto.createSign(algorithm[, options])
crypto.createVerify(algorithm[, options])
crypto.diffieHellman(options[, callback])
crypto.fips
crypto.generateKey(type, options, callback)
crypto.generateKeyPair(type, options, callback)
crypto.generateKeyPairSync(type, options)
crypto.generateKeySync(type, options)
crypto.generatePrime(size[, options[, callback]])
crypto.generatePrimeSync(size[, options])
crypto.getCipherInfo(nameOrNid[, options])
crypto.getCiphers()
crypto.getCurves()
crypto.getDiffieHellman(groupName)
crypto.getFips()
crypto.getHashes()
crypto.getRandomValues(typedArray)
crypto.hash(algorithm, data[, outputEncoding])
crypto.hkdf(digest, ikm, salt, info, keylen, callback)
crypto.hkdfSync(digest, ikm, salt, info, keylen)
crypto.pbkdf2(password, salt, iterations, keylen, digest, callback)
crypto.pbkdf2Sync(password, salt, iterations, keylen, digest)
crypto.privateDecrypt(privateKey, buffer)
crypto.privateEncrypt(privateKey, buffer)
crypto.publicDecrypt(key, buffer)
crypto.publicEncrypt(key, buffer)
crypto.randomBytes(size[, callback])
crypto.randomFill(buffer[, offset][, size], callback)
crypto.randomFillSync(buffer[, offset][, size])
crypto.randomInt([min, ]max[, callback])
crypto.randomUUID([options])
crypto.scrypt(password, salt, keylen[, options], callback)
crypto.scryptSync(password, salt, keylen[, options])
crypto.secureHeapUsed()
crypto.setEngine(engine[, flags])
crypto.setFips(bool)
crypto.sign(algorithm, data, key[, callback])
crypto.subtle
crypto.timingSafeEqual(a, b)
crypto.verify(algorithm, data, key, signature[, callback])
crypto.webcrypto


Notes

Using strings as inputs to cryptographic APIs
Legacy streams API (prior to Node.js 0.10)
Support for weak or compromised algorithms
CCM mode
FIPS mode


Crypto constants

OpenSSL options
OpenSSL engine constants
Other OpenSSL constants
Node.js crypto constants






      
        Crypto#

Stability: 2 - Stable
Source Code: lib/crypto.js
The node:crypto module provides cryptographic functionality that includes a
set of wrappers for OpenSSL's hash, HMAC, cipher, decipher, sign, and verify
functions.

const { createHmac } = await import('node:crypto');

const secret = 'abcdefg';
const hash = createHmac('sha256', secret)
               .update('I love cupcakes')
               .digest('hex');
console.log(hash);
// Prints:
//   c0fa1bc00531bd78ef38c628449c5102aeabd49b5dc3a2a516ea6ea959d6658econst { createHmac } = require('node:crypto');

const secret = 'abcdefg';
const hash = createHmac('sha256', secret)
               .update('I love cupcakes')
               .digest('hex');
console.log(hash);
// Prints:
//   c0fa1bc00531bd78ef38c628449c5102aeabd49b5dc3a2a516ea6ea959d6658ecopy
Determining if crypto support is unavailable#
It is possible for Node.js to be built without including support for the
node:crypto module. In such cases, attempting to import from crypto or
calling require('node:crypto') will result in an error being thrown.
When using CommonJS, the error thrown can be caught using try/catch:

let crypto;
try {
  crypto = require('node:crypto');
} catch (err) {
  console.error('crypto support is disabled!');
} copy

When using the lexical ESM import keyword, the error can only be
caught if a handler for process.on('uncaughtException') is registered
before any attempt to load the module is made (using, for instance,
a preload module).
When using ESM, if there is a chance that the code may be run on a build
of Node.js where crypto support is not enabled, consider using the
import() function instead of the lexical import keyword:
let crypto;
try {
  crypto = await import('node:crypto');
} catch (err) {
  console.error('crypto support is disabled!');
} copy
Class: Certificate#

Added in: v0.11.8

SPKAC is a Certificate Signing Request mechanism originally implemented by
Netscape and was specified formally as part of HTML5's keygen element.
<keygen> is deprecated since HTML 5.2 and new projects
should not use this element anymore.
The node:crypto module provides the Certificate class for working with SPKAC
data. The most common usage is handling output generated by the HTML5
<keygen> element. Node.js uses OpenSSL's SPKAC implementation internally.

Static method: Certificate.exportChallenge(spkac[, encoding])#

History

VersionChanges
v15.0.0
The spkac argument can be an ArrayBuffer. Limited the size of the spkac argument to a maximum of 2**31 - 1 bytes.
v9.0.0
Added in: v9.0.0




spkac <string> | <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView>
encoding <string> The encoding of the spkac string.
Returns: <Buffer> The challenge component of the spkac data structure, which
includes a public key and a challenge.


const { Certificate } = await import('node:crypto');
const spkac = getSpkacSomehow();
const challenge = Certificate.exportChallenge(spkac);
console.log(challenge.toString('utf8'));
// Prints: the challenge as a UTF8 stringconst { Certificate } = require('node:crypto');
const spkac = getSpkacSomehow();
const challenge = Certificate.exportChallenge(spkac);
console.log(challenge.toString('utf8'));
// Prints: the challenge as a UTF8 stringcopy

Static method: Certificate.exportPublicKey(spkac[, encoding])#

History

VersionChanges
v15.0.0
The spkac argument can be an ArrayBuffer. Limited the size of the spkac argument to a maximum of 2**31 - 1 bytes.
v9.0.0
Added in: v9.0.0




spkac <string> | <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView>
encoding <string> The encoding of the spkac string.
Returns: <Buffer> The public key component of the spkac data structure,
which includes a public key and a challenge.


const { Certificate } = await import('node:crypto');
const spkac = getSpkacSomehow();
const publicKey = Certificate.exportPublicKey(spkac);
console.log(publicKey);
// Prints: the public key as <Buffer ...>const { Certificate } = require('node:crypto');
const spkac = getSpkacSomehow();
const publicKey = Certificate.exportPublicKey(spkac);
console.log(publicKey);
// Prints: the public key as <Buffer ...>copy

Static method: Certificate.verifySpkac(spkac[, encoding])#

History

VersionChanges
v15.0.0
The spkac argument can be an ArrayBuffer. Added encoding. Limited the size of the spkac argument to a maximum of 2**31 - 1 bytes.
v9.0.0
Added in: v9.0.0




spkac <string> | <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView>
encoding <string> The encoding of the spkac string.
Returns: <boolean> true if the given spkac data structure is valid,
false otherwise.


import { Buffer } from 'node:buffer';
const { Certificate } = await import('node:crypto');

const spkac = getSpkacSomehow();
console.log(Certificate.verifySpkac(Buffer.from(spkac)));
// Prints: true or falseconst { Buffer } = require('node:buffer');
const { Certificate } = require('node:crypto');

const spkac = getSpkacSomehow();
console.log(Certificate.verifySpkac(Buffer.from(spkac)));
// Prints: true or falsecopy

Legacy API#
Stability: 0 - Deprecated
As a legacy interface, it is possible to create new instances of
the crypto.Certificate class as illustrated in the examples below.

new crypto.Certificate()#
Instances of the Certificate class can be created using the new keyword
or by calling crypto.Certificate() as a function:

const { Certificate } = await import('node:crypto');

const cert1 = new Certificate();
const cert2 = Certificate();const { Certificate } = require('node:crypto');

const cert1 = new Certificate();
const cert2 = Certificate();copy

certificate.exportChallenge(spkac[, encoding])#

Added in: v0.11.8


spkac <string> | <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView>
encoding <string> The encoding of the spkac string.
Returns: <Buffer> The challenge component of the spkac data structure, which
includes a public key and a challenge.


const { Certificate } = await import('node:crypto');
const cert = Certificate();
const spkac = getSpkacSomehow();
const challenge = cert.exportChallenge(spkac);
console.log(challenge.toString('utf8'));
// Prints: the challenge as a UTF8 stringconst { Certificate } = require('node:crypto');
const cert = Certificate();
const spkac = getSpkacSomehow();
const challenge = cert.exportChallenge(spkac);
console.log(challenge.toString('utf8'));
// Prints: the challenge as a UTF8 stringcopy

certificate.exportPublicKey(spkac[, encoding])#

Added in: v0.11.8


spkac <string> | <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView>
encoding <string> The encoding of the spkac string.
Returns: <Buffer> The public key component of the spkac data structure,
which includes a public key and a challenge.


const { Certificate } = await import('node:crypto');
const cert = Certificate();
const spkac = getSpkacSomehow();
const publicKey = cert.exportPublicKey(spkac);
console.log(publicKey);
// Prints: the public key as <Buffer ...>const { Certificate } = require('node:crypto');
const cert = Certificate();
const spkac = getSpkacSomehow();
const publicKey = cert.exportPublicKey(spkac);
console.log(publicKey);
// Prints: the public key as <Buffer ...>copy

certificate.verifySpkac(spkac[, encoding])#

Added in: v0.11.8


spkac <string> | <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView>
encoding <string> The encoding of the spkac string.
Returns: <boolean> true if the given spkac data structure is valid,
false otherwise.


import { Buffer } from 'node:buffer';
const { Certificate } = await import('node:crypto');

const cert = Certificate();
const spkac = getSpkacSomehow();
console.log(cert.verifySpkac(Buffer.from(spkac)));
// Prints: true or falseconst { Buffer } = require('node:buffer');
const { Certificate } = require('node:crypto');

const cert = Certificate();
const spkac = getSpkacSomehow();
console.log(cert.verifySpkac(Buffer.from(spkac)));
// Prints: true or falsecopy

Class: Cipheriv#

Added in: v0.1.94


Extends: <stream.Transform>

Instances of the Cipheriv class are used to encrypt data. The class can be
used in one of two ways:

As a stream that is both readable and writable, where plain unencrypted
data is written to produce encrypted data on the readable side, or
Using the cipher.update() and cipher.final() methods to produce
the encrypted data.

The crypto.createCipheriv() method is
used to create Cipheriv instances. Cipheriv objects are not to be created
directly using the new keyword.
Example: Using Cipheriv objects as streams:

const {
  scrypt,
  randomFill,
  createCipheriv,
} = await import('node:crypto');

const algorithm = 'aes-192-cbc';
const password = 'Password used to generate key';

// First, we'll generate the key. The key length is dependent on the algorithm.
// In this case for aes192, it is 24 bytes (192 bits).
scrypt(password, 'salt', 24, (err, key) => {
  if (err) throw err;
  // Then, we'll generate a random initialization vector
  randomFill(new Uint8Array(16), (err, iv) => {
    if (err) throw err;

    // Once we have the key and iv, we can create and use the cipher...
    const cipher = createCipheriv(algorithm, key, iv);

    let encrypted = '';
    cipher.setEncoding('hex');

    cipher.on('data', (chunk) => encrypted += chunk);
    cipher.on('end', () => console.log(encrypted));

    cipher.write('some clear text data');
    cipher.end();
  });
});const {
  scrypt,
  randomFill,
  createCipheriv,
} = require('node:crypto');

const algorithm = 'aes-192-cbc';
const password = 'Password used to generate key';

// First, we'll generate the key. The key length is dependent on the algorithm.
// In this case for aes192, it is 24 bytes (192 bits).
scrypt(password, 'salt', 24, (err, key) => {
  if (err) throw err;
  // Then, we'll generate a random initialization vector
  randomFill(new Uint8Array(16), (err, iv) => {
    if (err) throw err;

    // Once we have the key and iv, we can create and use the cipher...
    const cipher = createCipheriv(algorithm, key, iv);

    let encrypted = '';
    cipher.setEncoding('hex');

    cipher.on('data', (chunk) => encrypted += chunk);
    cipher.on('end', () => console.log(encrypted));

    cipher.write('some clear text data');
    cipher.end();
  });
});copy
Example: Using Cipheriv and piped streams:

import {
  createReadStream,
  createWriteStream,
} from 'node:fs';

import {
  pipeline,
} from 'node:stream';

const {
  scrypt,
  randomFill,
  createCipheriv,
} = await import('node:crypto');

const algorithm = 'aes-192-cbc';
const password = 'Password used to generate key';

// First, we'll generate the key. The key length is dependent on the algorithm.
// In this case for aes192, it is 24 bytes (192 bits).
scrypt(password, 'salt', 24, (err, key) => {
  if (err) throw err;
  // Then, we'll generate a random initialization vector
  randomFill(new Uint8Array(16), (err, iv) => {
    if (err) throw err;

    const cipher = createCipheriv(algorithm, key, iv);

    const input = createReadStream('test.js');
    const output = createWriteStream('test.enc');

    pipeline(input, cipher, output, (err) => {
      if (err) throw err;
    });
  });
});const {
  createReadStream,
  createWriteStream,
} = require('node:fs');

const {
  pipeline,
} = require('node:stream');

const {
  scrypt,
  randomFill,
  createCipheriv,
} = require('node:crypto');

const algorithm = 'aes-192-cbc';
const password = 'Password used to generate key';

// First, we'll generate the key. The key length is dependent on the algorithm.
// In this case for aes192, it is 24 bytes (192 bits).
scrypt(password, 'salt', 24, (err, key) => {
  if (err) throw err;
  // Then, we'll generate a random initialization vector
  randomFill(new Uint8Array(16), (err, iv) => {
    if (err) throw err;

    const cipher = createCipheriv(algorithm, key, iv);

    const input = createReadStream('test.js');
    const output = createWriteStream('test.enc');

    pipeline(input, cipher, output, (err) => {
      if (err) throw err;
    });
  });
});copy
Example: Using the cipher.update() and cipher.final() methods:

const {
  scrypt,
  randomFill,
  createCipheriv,
} = await import('node:crypto');

const algorithm = 'aes-192-cbc';
const password = 'Password used to generate key';

// First, we'll generate the key. The key length is dependent on the algorithm.
// In this case for aes192, it is 24 bytes (192 bits).
scrypt(password, 'salt', 24, (err, key) => {
  if (err) throw err;
  // Then, we'll generate a random initialization vector
  randomFill(new Uint8Array(16), (err, iv) => {
    if (err) throw err;

    const cipher = createCipheriv(algorithm, key, iv);

    let encrypted = cipher.update('some clear text data', 'utf8', 'hex');
    encrypted += cipher.final('hex');
    console.log(encrypted);
  });
});const {
  scrypt,
  randomFill,
  createCipheriv,
} = require('node:crypto');

const algorithm = 'aes-192-cbc';
const password = 'Password used to generate key';

// First, we'll generate the key. The key length is dependent on the algorithm.
// In this case for aes192, it is 24 bytes (192 bits).
scrypt(password, 'salt', 24, (err, key) => {
  if (err) throw err;
  // Then, we'll generate a random initialization vector
  randomFill(new Uint8Array(16), (err, iv) => {
    if (err) throw err;

    const cipher = createCipheriv(algorithm, key, iv);

    let encrypted = cipher.update('some clear text data', 'utf8', 'hex');
    encrypted += cipher.final('hex');
    console.log(encrypted);
  });
});copy

cipher.final([outputEncoding])#

Added in: v0.1.94


outputEncoding <string> The encoding of the return value.
Returns: <Buffer> | <string> Any remaining enciphered contents.
If outputEncoding is specified, a string is
returned. If an outputEncoding is not provided, a Buffer is returned.

Once the cipher.final() method has been called, the Cipheriv object can no
longer be used to encrypt data. Attempts to call cipher.final() more than
once will result in an error being thrown.

cipher.getAuthTag()#

Added in: v1.0.0


Returns: <Buffer> When using an authenticated encryption mode (GCM, CCM,
OCB, and chacha20-poly1305 are currently supported), the
cipher.getAuthTag() method returns a
Buffer containing the authentication tag that has been computed from
the given data.

The cipher.getAuthTag() method should only be called after encryption has
been completed using the cipher.final() method.
If the authTagLength option was set during the cipher instance's creation,
this function will return exactly authTagLength bytes.

cipher.setAAD(buffer[, options])#

Added in: v1.0.0


buffer <string> | <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView>
options <Object> stream.transform options

plaintextLength <number>
encoding <string> The string encoding to use when buffer is a string.


Returns: <Cipheriv> The same Cipheriv instance for method chaining.

When using an authenticated encryption mode (GCM, CCM, OCB, and
chacha20-poly1305 are
currently supported), the cipher.setAAD() method sets the value used for the
additional authenticated data (AAD) input parameter.
The plaintextLength option is optional for GCM and OCB. When using CCM,
the plaintextLength option must be specified and its value must match the
length of the plaintext in bytes. See CCM mode.
The cipher.setAAD() method must be called before cipher.update().

cipher.setAutoPadding([autoPadding])#

Added in: v0.7.1


autoPadding <boolean> Default: true
Returns: <Cipheriv> The same Cipheriv instance for method chaining.

When using block encryption algorithms, the Cipheriv class will automatically
add padding to the input data to the appropriate block size. To disable the
default padding call cipher.setAutoPadding(false).
When autoPadding is false, the length of the entire input data must be a
multiple of the cipher's block size or cipher.final() will throw an error.
Disabling automatic padding is useful for non-standard padding, for instance
using 0x0 instead of PKCS padding.
The cipher.setAutoPadding() method must be called before
cipher.final().

cipher.update(data[, inputEncoding][, outputEncoding])#

History

VersionChanges
v6.0.0
The default inputEncoding changed from binary to utf8.
v0.1.94
Added in: v0.1.94




data <string> | <Buffer> | <TypedArray> | <DataView>
inputEncoding <string> The encoding of the data.
outputEncoding <string> The encoding of the return value.
Returns: <Buffer> | <string>

Updates the cipher with data. If the inputEncoding argument is given,
the data
argument is a string using the specified encoding. If the inputEncoding
argument is not given, data must be a Buffer, TypedArray, or
DataView. If data is a Buffer, TypedArray, or DataView, then
inputEncoding is ignored.
The outputEncoding specifies the output format of the enciphered
data. If the outputEncoding
is specified, a string using the specified encoding is returned. If no
outputEncoding is provided, a Buffer is returned.
The cipher.update() method can be called multiple times with new data until
cipher.final() is called. Calling cipher.update() after
cipher.final() will result in an error being thrown.

Class: Decipheriv#

Added in: v0.1.94


Extends: <stream.Transform>

Instances of the Decipheriv class are used to decrypt data. The class can be
used in one of two ways:

As a stream that is both readable and writable, where plain encrypted
data is written to produce unencrypted data on the readable side, or
Using the decipher.update() and decipher.final() methods to
produce the unencrypted data.

The crypto.createDecipheriv() method is
used to create Decipheriv instances. Decipheriv objects are not to be created
directly using the new keyword.
Example: Using Decipheriv objects as streams:

import { Buffer } from 'node:buffer';
const {
  scryptSync,
  createDecipheriv,
} = await import('node:crypto');

const algorithm = 'aes-192-cbc';
const password = 'Password used to generate key';
// Key length is dependent on the algorithm. In this case for aes192, it is
// 24 bytes (192 bits).
// Use the async `crypto.scrypt()` instead.
const key = scryptSync(password, 'salt', 24);
// The IV is usually passed along with the ciphertext.
const iv = Buffer.alloc(16, 0); // Initialization vector.

const decipher = createDecipheriv(algorithm, key, iv);

let decrypted = '';
decipher.on('readable', () => {
  let chunk;
  while (null !== (chunk = decipher.read())) {
    decrypted += chunk.toString('utf8');
  }
});
decipher.on('end', () => {
  console.log(decrypted);
  // Prints: some clear text data
});

// Encrypted with same algorithm, key and iv.
const encrypted =
  'e5f79c5915c02171eec6b212d5520d44480993d7d622a7c4c2da32f6efda0ffa';
decipher.write(encrypted, 'hex');
decipher.end();const {
  scryptSync,
  createDecipheriv,
} = require('node:crypto');
const { Buffer } = require('node:buffer');

const algorithm = 'aes-192-cbc';
const password = 'Password used to generate key';
// Key length is dependent on the algorithm. In this case for aes192, it is
// 24 bytes (192 bits).
// Use the async `crypto.scrypt()` instead.
const key = scryptSync(password, 'salt', 24);
// The IV is usually passed along with the ciphertext.
const iv = Buffer.alloc(16, 0); // Initialization vector.

const decipher = createDecipheriv(algorithm, key, iv);

let decrypted = '';
decipher.on('readable', () => {
  let chunk;
  while (null !== (chunk = decipher.read())) {
    decrypted += chunk.toString('utf8');
  }
});
decipher.on('end', () => {
  console.log(decrypted);
  // Prints: some clear text data
});

// Encrypted with same algorithm, key and iv.
const encrypted =
  'e5f79c5915c02171eec6b212d5520d44480993d7d622a7c4c2da32f6efda0ffa';
decipher.write(encrypted, 'hex');
decipher.end();copy
Example: Using Decipheriv and piped streams:

import {
  createReadStream,
  createWriteStream,
} from 'node:fs';
import { Buffer } from 'node:buffer';
const {
  scryptSync,
  createDecipheriv,
} = await import('node:crypto');

const algorithm = 'aes-192-cbc';
const password = 'Password used to generate key';
// Use the async `crypto.scrypt()` instead.
const key = scryptSync(password, 'salt', 24);
// The IV is usually passed along with the ciphertext.
const iv = Buffer.alloc(16, 0); // Initialization vector.

const decipher = createDecipheriv(algorithm, key, iv);

const input = createReadStream('test.enc');
const output = createWriteStream('test.js');

input.pipe(decipher).pipe(output);const {
  createReadStream,
  createWriteStream,
} = require('node:fs');
const {
  scryptSync,
  createDecipheriv,
} = require('node:crypto');
const { Buffer } = require('node:buffer');

const algorithm = 'aes-192-cbc';
const password = 'Password used to generate key';
// Use the async `crypto.scrypt()` instead.
const key = scryptSync(password, 'salt', 24);
// The IV is usually passed along with the ciphertext.
const iv = Buffer.alloc(16, 0); // Initialization vector.

const decipher = createDecipheriv(algorithm, key, iv);

const input = createReadStream('test.enc');
const output = createWriteStream('test.js');

input.pipe(decipher).pipe(output);copy
Example: Using the decipher.update() and decipher.final() methods:

import { Buffer } from 'node:buffer';
const {
  scryptSync,
  createDecipheriv,
} = await import('node:crypto');

const algorithm = 'aes-192-cbc';
const password = 'Password used to generate key';
// Use the async `crypto.scrypt()` instead.
const key = scryptSync(password, 'salt', 24);
// The IV is usually passed along with the ciphertext.
const iv = Buffer.alloc(16, 0); // Initialization vector.

const decipher = createDecipheriv(algorithm, key, iv);

// Encrypted using same algorithm, key and iv.
const encrypted =
  'e5f79c5915c02171eec6b212d5520d44480993d7d622a7c4c2da32f6efda0ffa';
let decrypted = decipher.update(encrypted, 'hex', 'utf8');
decrypted += decipher.final('utf8');
console.log(decrypted);
// Prints: some clear text dataconst {
  scryptSync,
  createDecipheriv,
} = require('node:crypto');
const { Buffer } = require('node:buffer');

const algorithm = 'aes-192-cbc';
const password = 'Password used to generate key';
// Use the async `crypto.scrypt()` instead.
const key = scryptSync(password, 'salt', 24);
// The IV is usually passed along with the ciphertext.
const iv = Buffer.alloc(16, 0); // Initialization vector.

const decipher = createDecipheriv(algorithm, key, iv);

// Encrypted using same algorithm, key and iv.
const encrypted =
  'e5f79c5915c02171eec6b212d5520d44480993d7d622a7c4c2da32f6efda0ffa';
let decrypted = decipher.update(encrypted, 'hex', 'utf8');
decrypted += decipher.final('utf8');
console.log(decrypted);
// Prints: some clear text datacopy

decipher.final([outputEncoding])#

Added in: v0.1.94


outputEncoding <string> The encoding of the return value.
Returns: <Buffer> | <string> Any remaining deciphered contents.
If outputEncoding is specified, a string is
returned. If an outputEncoding is not provided, a Buffer is returned.

Once the decipher.final() method has been called, the Decipheriv object can
no longer be used to decrypt data. Attempts to call decipher.final() more
than once will result in an error being thrown.

decipher.setAAD(buffer[, options])#

History

VersionChanges
v15.0.0
The buffer argument can be a string or ArrayBuffer and is limited to no more than 2 ** 31 - 1 bytes.
v7.2.0
This method now returns a reference to decipher.
v1.0.0
Added in: v1.0.0




buffer <string> | <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView>
options <Object> stream.transform options

plaintextLength <number>
encoding <string> String encoding to use when buffer is a string.


Returns: <Decipheriv> The same Decipher for method chaining.

When using an authenticated encryption mode (GCM, CCM, OCB, and
chacha20-poly1305 are
currently supported), the decipher.setAAD() method sets the value used for the
additional authenticated data (AAD) input parameter.
The options argument is optional for GCM. When using CCM, the
plaintextLength option must be specified and its value must match the length
of the ciphertext in bytes. See CCM mode.
The decipher.setAAD() method must be called before decipher.update().
When passing a string as the buffer, please consider
caveats when using strings as inputs to cryptographic APIs.

decipher.setAuthTag(buffer[, encoding])#

History

VersionChanges
v22.0.0, v20.13.0
Using GCM tag lengths other than 128 bits without specifying the authTagLength option when creating decipher is deprecated.
v15.0.0
The buffer argument can be a string or ArrayBuffer and is limited to no more than 2 ** 31 - 1 bytes.
v11.0.0
This method now throws if the GCM tag length is invalid.
v7.2.0
This method now returns a reference to decipher.
v1.0.0
Added in: v1.0.0




buffer <string> | <Buffer> | <ArrayBuffer> | <TypedArray> | <DataView>
encoding <string> String encoding to use when buffer is a string.
Returns: <Decipheriv> The same Decipher for method chaining.

When using an authenticated encryption mode (GCM, CCM, OCB, and
chacha20-poly1305 are
currently supported), the decipher.setAuthTag() method is used to pass in the
received authentication tag. If no tag is provided, or if the cipher text
has been tampered with, decipher.final() will throw, indicating that the
cipher text should be discarded due to failed authentication. If the tag length
is invalid according to NIST SP 800-38D or does not match the value of the
authTagLength option, decipher.setAuthTag() will throw an error.
The decipher.setAuthTag() method must be called before decipher.update()
for CCM mode or before decipher.final() for GCM and OCB modes and
chacha20-poly1305.
decipher.setAuthTag() can only be called once.
When passing a string as the authentication tag, please consider
caveats when using strings as inputs to cryptographic APIs.

decipher.setAutoPadding([autoPadding])#

Added in: v0.7.1


autoPadding <boolean> Default: true
Returns: <Decipheriv> The same Decipher for method chaining.

When data has been encrypted without standard block padding, calling
decipher.setAutoPadding(false) will disable automatic padding to prevent
decipher.final() from checking for and removing padding.
Turning auto padding off will only work if the input data's length is a
multiple of the ciphers block size.
The decipher.setAutoPadding() method must be called before
decipher.final().

decipher.update(data[, inputEncoding][, outputEncoding])#

History

VersionChanges
v6.0.0
The default inputEncoding changed from binary to utf8.
v0.1.94
Added in: v0.1.94




data <string> | <Buffer> | <TypedArray> | <DataView>
inputEncoding <string> The encoding of the data string.
outputEncoding <string> The encoding of the return value.
Returns: <Buffer> | <string>

Updates the decipher with data. If the inputEncoding argument is given,
the data
argument is a string using the specified encoding. If the inputEncoding
argument is not given, data must be a Buffer. If data is a
Buffer then inputEncoding is ignored.
The outputEncoding specifies the output format of the enciphered
data. If the outputEncoding
is specified, a string using the specified encoding is returned. If no
outputEncoding is provided, a Buffer is returned.
The decipher.update() method can be called multiple times with new data until
decipher.final() is called. Calling decipher.update() after
decipher.final() will result in an error being thrown.
Even if the underlying cipher implements authentication, the authenticity and
integrity of the plaintext returned from this function may be uncertain at this
time. For authenticated encryption algorithms, authenticity is generally only
established when the application calls decipher.final().

Class: DiffieHellman#

Added in: v0.5.0

The DiffieHellman class is a utility for creating Diffie-Hellman key
exchanges.
Instances of the DiffieHellman class can be created using the
crypto.createDiffieHellman() function.

import assert from 'node:assert';

const {
  createDiffieHellman,
} = await import('node:crypto');

// Generate Alice's keys...
const alice = createDiffieHellman(2048);
const aliceKey = alice.generateKeys();

// Generate Bob's keys...
const bob = createDiffieHellman(alice.getPrime(), alice.getGenerator());
const bobKey = bob.generateKeys();

// Exchange and generate the secret...
const aliceSecret = alice.computeSecret(bobKey);
const bobSecret = bob.computeSecret(aliceKey);

// OK
assert.strictEqual(aliceSecret.toString('hex'), bobSecret.toString('hex'));const assert = require('node:assert');

const {
  createDiffieHellman,
} = require('node:crypto');

// Generate Alice's keys...
const alice = createDiffieHellman(2048);
const aliceKey = alice.generateKeys();

// Generate Bob's keys...
const bob = createDiffieHellman(alice.getPrime(), alice.getGenerator());
const bobKey = bob.generateKeys();

// Exchange and generate the secret...
const aliceSecret = alice.computeSecret(bobKey);
const bobSecret = bob.computeSecret(aliceKey);

// OK
assert.strictEqual(aliceSecret.toString('hex'), bobSecret.toString('hex'));copy

diffieHellman.computeSecret(otherPublicKey[, inputEncoding][, outputEncoding])#

Added in: v0.5.0


otherPublicKey <string> | <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView>
inputEncoding <string> The encoding of an otherPublicKey string.
outputEncoding <string> The encoding of the return value.
Returns: <Buffer> | <string>

Computes the shared secret using otherPublicKey as the other
party's public key and returns the computed shared secret. The supplied
key is interpreted using the specified inputEncoding, and secret is
encoded using specified outputEncoding.
If the inputEncoding is not
provided, otherPublicKey is expected to be a Buffer,
TypedArray, or DataView.
If outputEncoding is given a string is returned; otherwise, a
Buffer is returned.

diffieHellman.generateKeys([encoding])#

Added in: v0.5.0


encoding <string> The encoding of the return value.
Returns: <Buffer> | <string>

Generates private and public Diffie-Hellman key values unless they have been
generated or computed already, and returns
the public key in the specified encoding. This key should be
transferred to the other party.
If encoding is provided a string is returned; otherwise a
Buffer is returned.
This function is a thin wrapper around DH_generate_key(). In particular,
once a private key has been generated or set, calling this function only updates
the public key but does not generate a new private key.

diffieHellman.getGenerator([encoding])#

Added in: v0.5.0


encoding <string> The encoding of the return value.
Returns: <Buffer> | <string>

Returns the Diffie-Hellman generator in the specified encoding.
If encoding is provided a string is
returned; otherwise a Buffer is returned.

diffieHellman.getPrime([encoding])#

Added in: v0.5.0


encoding <string> The encoding of the return value.
Returns: <Buffer> | <string>

Returns the Diffie-Hellman prime in the specified encoding.
If encoding is provided a string is
returned; otherwise a Buffer is returned.

diffieHellman.getPrivateKey([encoding])#

Added in: v0.5.0


encoding <string> The encoding of the return value.
Returns: <Buffer> | <string>

Returns the Diffie-Hellman private key in the specified encoding.
If encoding is provided a
string is returned; otherwise a Buffer is returned.

diffieHellman.getPublicKey([encoding])#

Added in: v0.5.0


encoding <string> The encoding of the return value.
Returns: <Buffer> | <string>

Returns the Diffie-Hellman public key in the specified encoding.
If encoding is provided a
string is returned; otherwise a Buffer is returned.

diffieHellman.setPrivateKey(privateKey[, encoding])#

Added in: v0.5.0


privateKey <string> | <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView>
encoding <string> The encoding of the privateKey string.

Sets the Diffie-Hellman private key. If the encoding argument is provided,
privateKey is expected
to be a string. If no encoding is provided, privateKey is expected
to be a Buffer, TypedArray, or DataView.
This function does not automatically compute the associated public key. Either
diffieHellman.setPublicKey() or diffieHellman.generateKeys() can be
used to manually provide the public key or to automatically derive it.

diffieHellman.setPublicKey(publicKey[, encoding])#

Added in: v0.5.0


publicKey <string> | <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView>
encoding <string> The encoding of the publicKey string.

Sets the Diffie-Hellman public key. If the encoding argument is provided,
publicKey is expected
to be a string. If no encoding is provided, publicKey is expected
to be a Buffer, TypedArray, or DataView.

diffieHellman.verifyError#

Added in: v0.11.12

A bit field containing any warnings and/or errors resulting from a check
performed during initialization of the DiffieHellman object.
The following values are valid for this property (as defined in node:constants module):

DH_CHECK_P_NOT_SAFE_PRIME
DH_CHECK_P_NOT_PRIME
DH_UNABLE_TO_CHECK_GENERATOR
DH_NOT_SUITABLE_GENERATOR


Class: DiffieHellmanGroup#

Added in: v0.7.5

The DiffieHellmanGroup class takes a well-known modp group as its argument.
It works the same as DiffieHellman, except that it does not allow changing
its keys after creation. In other words, it does not implement setPublicKey()
or setPrivateKey() methods.

const { createDiffieHellmanGroup } = await import('node:crypto');
const dh = createDiffieHellmanGroup('modp16');const { createDiffieHellmanGroup } = require('node:crypto');
const dh = createDiffieHellmanGroup('modp16');copy
The following groups are supported:

'modp14' (2048 bits, RFC 3526 Section 3)
'modp15' (3072 bits, RFC 3526 Section 4)
'modp16' (4096 bits, RFC 3526 Section 5)
'modp17' (6144 bits, RFC 3526 Section 6)
'modp18' (8192 bits, RFC 3526 Section 7)

The following groups are still supported but deprecated (see Caveats):

'modp1' (768 bits, RFC 2409 Section 6.1) 
'modp2' (1024 bits, RFC 2409 Section 6.2) 
'modp5' (1536 bits, RFC 3526 Section 2) 

These deprecated groups might be removed in future versions of Node.js.
Class: ECDH#

Added in: v0.11.14

The ECDH class is a utility for creating Elliptic Curve Diffie-Hellman (ECDH)
key exchanges.
Instances of the ECDH class can be created using the
crypto.createECDH() function.

import assert from 'node:assert';

const {
  createECDH,
} = await import('node:crypto');

// Generate Alice's keys...
const alice = createECDH('secp521r1');
const aliceKey = alice.generateKeys();

// Generate Bob's keys...
const bob = createECDH('secp521r1');
const bobKey = bob.generateKeys();

// Exchange and generate the secret...
const aliceSecret = alice.computeSecret(bobKey);
const bobSecret = bob.computeSecret(aliceKey);

assert.strictEqual(aliceSecret.toString('hex'), bobSecret.toString('hex'));
// OKconst assert = require('node:assert');

const {
  createECDH,
} = require('node:crypto');

// Generate Alice's keys...
const alice = createECDH('secp521r1');
const aliceKey = alice.generateKeys();

// Generate Bob's keys...
const bob = createECDH('secp521r1');
const bobKey = bob.generateKeys();

// Exchange and generate the secret...
const aliceSecret = alice.computeSecret(bobKey);
const bobSecret = bob.computeSecret(aliceKey);

assert.strictEqual(aliceSecret.toString('hex'), bobSecret.toString('hex'));
// OKcopy

Static method: ECDH.convertKey(key, curve[, inputEncoding[, outputEncoding[, format]]])#

Added in: v10.0.0


key <string> | <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView>
curve <string>
inputEncoding <string> The encoding of the key string.
outputEncoding <string> The encoding of the return value.
format <string> Default: 'uncompressed'
Returns: <Buffer> | <string>

Converts the EC Diffie-Hellman public key specified by key and curve to the
format specified by format. The format argument specifies point encoding
and can be 'compressed', 'uncompressed' or 'hybrid'. The supplied key is
interpreted using the specified inputEncoding, and the returned key is encoded
using the specified outputEncoding.
Use crypto.getCurves() to obtain a list of available curve names.
On recent OpenSSL releases, openssl ecparam -list_curves will also display
the name and description of each available elliptic curve.
If format is not specified the point will be returned in 'uncompressed'
format.
If the inputEncoding is not provided, key is expected to be a Buffer,
TypedArray, or DataView.
Example (uncompressing a key):

const {
  createECDH,
  ECDH,
} = await import('node:crypto');

const ecdh = createECDH('secp256k1');
ecdh.generateKeys();

const compressedKey = ecdh.getPublicKey('hex', 'compressed');

const uncompressedKey = ECDH.convertKey(compressedKey,
                                        'secp256k1',
                                        'hex',
                                        'hex',
                                        'uncompressed');

// The converted key and the uncompressed public key should be the same
console.log(uncompressedKey === ecdh.getPublicKey('hex'));const {
  createECDH,
  ECDH,
} = require('node:crypto');

const ecdh = createECDH('secp256k1');
ecdh.generateKeys();

const compressedKey = ecdh.getPublicKey('hex', 'compressed');

const uncompressedKey = ECDH.convertKey(compressedKey,
                                        'secp256k1',
                                        'hex',
                                        'hex',
                                        'uncompressed');

// The converted key and the uncompressed public key should be the same
console.log(uncompressedKey === ecdh.getPublicKey('hex'));copy

ecdh.computeSecret(otherPublicKey[, inputEncoding][, outputEncoding])#

History

VersionChanges
v10.0.0
Changed error format to better support invalid public key error.
v6.0.0
The default inputEncoding changed from binary to utf8.
v0.11.14
Added in: v0.11.14




otherPublicKey <string> | <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView>
inputEncoding <string> The encoding of the otherPublicKey string.
outputEncoding <string> The encoding of the return value.
Returns: <Buffer> | <string>

Computes the shared secret using otherPublicKey as the other
party's public key and returns the computed shared secret. The supplied
key is interpreted using specified inputEncoding, and the returned secret
is encoded using the specified outputEncoding.
If the inputEncoding is not
provided, otherPublicKey is expected to be a Buffer, TypedArray, or
DataView.
If outputEncoding is given a string will be returned; otherwise a
Buffer is returned.
ecdh.computeSecret will throw an
ERR_CRYPTO_ECDH_INVALID_PUBLIC_KEY error when otherPublicKey
lies outside of the elliptic curve. Since otherPublicKey is
usually supplied from a remote user over an insecure network,
be sure to handle this exception accordingly.

ecdh.generateKeys([encoding[, format]])#

Added in: v0.11.14


encoding <string> The encoding of the return value.
format <string> Default: 'uncompressed'
Returns: <Buffer> | <string>

Generates private and public EC Diffie-Hellman key values, and returns
the public key in the specified format and encoding. This key should be
transferred to the other party.
The format argument specifies point encoding and can be 'compressed' or
'uncompressed'. If format is not specified, the point will be returned in
'uncompressed' format.
If encoding is provided a string is returned; otherwise a Buffer
is returned.

ecdh.getPrivateKey([encoding])#

Added in: v0.11.14


encoding <string> The encoding of the return value.
Returns: <Buffer> | <string> The EC Diffie-Hellman in the specified encoding.

If encoding is specified, a string is returned; otherwise a Buffer is
returned.

ecdh.getPublicKey([encoding][, format])#

Added in: v0.11.14


encoding <string> The encoding of the return value.
format <string> Default: 'uncompressed'
Returns: <Buffer> | <string> The EC Diffie-Hellman public key in the specified
encoding and format.

The format argument specifies point encoding and can be 'compressed' or
'uncompressed'. If format is not specified the point will be returned in
'uncompressed' format.
If encoding is specified, a string is returned; otherwise a Buffer is
returned.

ecdh.setPrivateKey(privateKey[, encoding])#

Added in: v0.11.14


privateKey <string> | <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView>
encoding <string> The encoding of the privateKey string.

Sets the EC Diffie-Hellman private key.
If encoding is provided, privateKey is expected
to be a string; otherwise privateKey is expected to be a Buffer,
TypedArray, or DataView.
If privateKey is not valid for the curve specified when the ECDH object was
created, an error is thrown. Upon setting the private key, the associated
public point (key) is also generated and set in the ECDH object.

ecdh.setPublicKey(publicKey[, encoding])#

Added in: v0.11.14Deprecated since: v5.2.0

Stability: 0 - Deprecated

publicKey <string> | <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView>
encoding <string> The encoding of the publicKey string.

Sets the EC Diffie-Hellman public key.
If encoding is provided publicKey is expected to
be a string; otherwise a Buffer, TypedArray, or DataView is expected.
There is not normally a reason to call this method because ECDH
only requires a private key and the other party's public key to compute the
shared secret. Typically either ecdh.generateKeys() or
ecdh.setPrivateKey() will be called. The ecdh.setPrivateKey() method
attempts to generate the public point/key associated with the private key being
set.
Example (obtaining a shared secret):

const {
  createECDH,
  createHash,
} = await import('node:crypto');

const alice = createECDH('secp256k1');
const bob = createECDH('secp256k1');

// This is a shortcut way of specifying one of Alice's previous private
// keys. It would be unwise to use such a predictable private key in a real
// application.
alice.setPrivateKey(
  createHash('sha256').update('alice', 'utf8').digest(),
);

// Bob uses a newly generated cryptographically strong
// pseudorandom key pair
bob.generateKeys();

const aliceSecret = alice.computeSecret(bob.getPublicKey(), null, 'hex');
const bobSecret = bob.computeSecret(alice.getPublicKey(), null, 'hex');

// aliceSecret and bobSecret should be the same shared secret value
console.log(aliceSecret === bobSecret);const {
  createECDH,
  createHash,
} = require('node:crypto');

const alice = createECDH('secp256k1');
const bob = createECDH('secp256k1');

// This is a shortcut way of specifying one of Alice's previous private
// keys. It would be unwise to use such a predictable private key in a real
// application.
alice.setPrivateKey(
  createHash('sha256').update('alice', 'utf8').digest(),
);

// Bob uses a newly generated cryptographically strong
// pseudorandom key pair
bob.generateKeys();

const aliceSecret = alice.computeSecret(bob.getPublicKey(), null, 'hex');
const bobSecret = bob.computeSecret(alice.getPublicKey(), null, 'hex');

// aliceSecret and bobSecret should be the same shared secret value
console.log(aliceSecret === bobSecret);copy

Class: Hash#

Added in: v0.1.92


Extends: <stream.Transform>

The Hash class is a utility for creating hash digests of data. It can be
used in one of two ways:

As a stream that is both readable and writable, where data is written
to produce a computed hash digest on the readable side, or
Using the hash.update() and hash.digest() methods to produce the
computed hash.

The crypto.createHash() method is used to create Hash instances. Hash
objects are not to be created directly using the new keyword.
Example: Using Hash objects as streams:

const {
  createHash,
} = await import('node:crypto');

const hash = createHash('sha256');

hash.on('readable', () => {
  // Only one element is going to be produced by the
  // hash stream.
  const data = hash.read();
  if (data) {
    console.log(data.toString('hex'));
    // Prints:
    //   6a2da20943931e9834fc12cfe5bb47bbd9ae43489a30726962b576f4e3993e50
  }
});

hash.write('some data to hash');
hash.end();const {
  createHash,
} = require('node:crypto');

const hash = createHash('sha256');

hash.on('readable', () => {
  // Only one element is going to be produced by the
  // hash stream.
  const data = hash.read();
  if (data) {
    console.log(data.toString('hex'));
    // Prints:
    //   6a2da20943931e9834fc12cfe5bb47bbd9ae43489a30726962b576f4e3993e50
  }
});

hash.write('some data to hash');
hash.end();copy
Example: Using Hash and piped streams:

import { createReadStream } from 'node:fs';
import { stdout } from 'node:process';
const { createHash } = await import('node:crypto');

const hash = createHash('sha256');

const input = createReadStream('test.js');
input.pipe(hash).setEncoding('hex').pipe(stdout);const { createReadStream } = require('node:fs');
const { createHash } = require('node:crypto');
const { stdout } = require('node:process');

const hash = createHash('sha256');

const input = createReadStream('test.js');
input.pipe(hash).setEncoding('hex').pipe(stdout);copy
Example: Using the hash.update() and hash.digest() methods:

const {
  createHash,
} = await import('node:crypto');

const hash = createHash('sha256');

hash.update('some data to hash');
console.log(hash.digest('hex'));
// Prints:
//   6a2da20943931e9834fc12cfe5bb47bbd9ae43489a30726962b576f4e3993e50const {
  createHash,
} = require('node:crypto');

const hash = createHash('sha256');

hash.update('some data to hash');
console.log(hash.digest('hex'));
// Prints:
//   6a2da20943931e9834fc12cfe5bb47bbd9ae43489a30726962b576f4e3993e50copy

hash.copy([options])#

Added in: v13.1.0


options <Object> stream.transform options
Returns: <Hash>

Creates a new Hash object that contains a deep copy of the internal state
of the current Hash object.
The optional options argument controls stream behavior. For XOF hash
functions such as 'shake256', the outputLength option can be used to
specify the desired output length in bytes.
An error is thrown when an attempt is made to copy the Hash object after
its hash.digest() method has been called.

// Calculate a rolling hash.
const {
  createHash,
} = await import('node:crypto');

const hash = createHash('sha256');

hash.update('one');
console.log(hash.copy().digest('hex'));

hash.update('two');
console.log(hash.copy().digest('hex'));

hash.update('three');
console.log(hash.copy().digest('hex'));

// Etc.// Calculate a rolling hash.
const {
  createHash,
} = require('node:crypto');

const hash = createHash('sha256');

hash.update('one');
console.log(hash.copy().digest('hex'));

hash.update('two');
console.log(hash.copy().digest('hex'));

hash.update('three');
console.log(hash.copy().digest('hex'));

// Etc.copy

hash.digest([encoding])#

Added in: v0.1.92


encoding <string> The encoding of the return value.
Returns: <Buffer> | <string>

Calculates the digest of all of the data passed to be hashed (using the
hash.update() method).
If encoding is provided a string will be returned; otherwise
a Buffer is returned.
The Hash object can not be used again after hash.digest() method has been
called. Multiple calls will cause an error to be thrown.

hash.update(data[, inputEncoding])#

History

VersionChanges
v6.0.0
The default inputEncoding changed from binary to utf8.
v0.1.92
Added in: v0.1.92




data <string> | <Buffer> | <TypedArray> | <DataView>
inputEncoding <string> The encoding of the data string.

Updates the hash content with the given data, the encoding of which
is given in inputEncoding.
If encoding is not provided, and the data is a string, an
encoding of 'utf8' is enforced. If data is a Buffer, TypedArray, or
DataView, then inputEncoding is ignored.
This can be called many times with new data as it is streamed.

Class: Hmac#

Added in: v0.1.94


Extends: <stream.Transform>

The Hmac class is a utility for creating cryptographic HMAC digests. It can
be used in one of two ways:

As a stream that is both readable and writable, where data is written
to produce a computed HMAC digest on the readable side, or
Using the hmac.update() and hmac.digest() methods to produce the
computed HMAC digest.

The crypto.createHmac() method is used to create Hmac instances. Hmac
objects are not to be created directly using the new keyword.
Example: Using Hmac objects as streams:

const {
  createHmac,
} = await import('node:crypto');

const hmac = createHmac('sha256', 'a secret');

hmac.on('readable', () => {
  // Only one element is going to be produced by the
  // hash stream.
  const data = hmac.read();
  if (data) {
    console.log(data.toString('hex'));
    // Prints:
    //   7fd04df92f636fd450bc841c9418e5825c17f33ad9c87c518115a45971f7f77e
  }
});

hmac.write('some data to hash');
hmac.end();const {
  createHmac,
} = require('node:crypto');

const hmac = createHmac('sha256', 'a secret');

hmac.on('readable', () => {
  // Only one element is going to be produced by the
  // hash stream.
  const data = hmac.read();
  if (data) {
    console.log(data.toString('hex'));
    // Prints:
    //   7fd04df92f636fd450bc841c9418e5825c17f33ad9c87c518115a45971f7f77e
  }
});

hmac.write('some data to hash');
hmac.end();copy
Example: Using Hmac and piped streams:

import { createReadStream } from 'node:fs';
import { stdout } from 'node:process';
const {
  createHmac,
} = await import('node:crypto');

const hmac = createHmac('sha256', 'a secret');

const input = createReadStream('test.js');
input.pipe(hmac).pipe(stdout);const {
  createReadStream,
} = require('node:fs');
const {
  createHmac,
} = require('node:crypto');
const { stdout } = require('node:process');

const hmac = createHmac('sha256', 'a secret');

const input = createReadStream('test.js');
input.pipe(hmac).pipe(stdout);copy
Example: Using the hmac.update() and hmac.digest() methods:

const {
  createHmac,
} = await import('node:crypto');

const hmac = createHmac('sha256', 'a secret');

hmac.update('some data to hash');
console.log(hmac.digest('hex'));
// Prints:
//   7fd04df92f636fd450bc841c9418e5825c17f33ad9c87c518115a45971f7f77econst {
  createHmac,
} = require('node:crypto');

const hmac = createHmac('sha256', 'a secret');

hmac.update('some data to hash');
console.log(hmac.digest('hex'));
// Prints:
//   7fd04df92f636fd450bc841c9418e5825c17f33ad9c87c518115a45971f7f77ecopy

hmac.digest([encoding])#

Added in: v0.1.94


encoding <string> The encoding of the return value.
Returns: <Buffer> | <string>

Calculates the HMAC digest of all of the data passed using hmac.update().
If encoding is
provided a string is returned; otherwise a Buffer is returned;
The Hmac object can not be used again after hmac.digest() has been
called. Multiple calls to hmac.digest() will result in an error being thrown.

hmac.update(data[, inputEncoding])#

History

VersionChanges
v6.0.0
The default inputEncoding changed from binary to utf8.
v0.1.94
Added in: v0.1.94




data <string> | <Buffer> | <TypedArray> | <DataView>
inputEncoding <string> The encoding of the data string.

Updates the Hmac content with the given data, the encoding of which
is given in inputEncoding.
If encoding is not provided, and the data is a string, an
encoding of 'utf8' is enforced. If data is a Buffer, TypedArray, or
DataView, then inputEncoding is ignored.
This can be called many times with new data as it is streamed.

Class: KeyObject#

History

VersionChanges
v14.5.0, v12.19.0
Instances of this class can now be passed to worker threads using postMessage.
v11.13.0
This class is now exported.
v11.6.0
Added in: v11.6.0



Node.js uses a KeyObject class to represent a symmetric or asymmetric key,
and each kind of key exposes different functions. The
crypto.createSecretKey(), crypto.createPublicKey() and
crypto.createPrivateKey() methods are used to create KeyObject
instances. KeyObject objects are not to be created directly using the new
keyword.
Most applications should consider using the new KeyObject API instead of
passing keys as strings or Buffers due to improved security features.
KeyObject instances can be passed to other threads via postMessage().
The receiver obtains a cloned KeyObject, and the KeyObject does not need to
be listed in the transferList argument.

Static method: KeyObject.from(key)#

Added in: v15.0.0


key <CryptoKey>
Returns: <KeyObject>

Example: Converting a CryptoKey instance to a KeyObject:

const { KeyObject } = await import('node:crypto');
const { subtle } = globalThis.crypto;

const key = await subtle.generateKey({
  name: 'HMAC',
  hash: 'SHA-256',
  length: 256,
}, true, ['sign', 'verify']);

const keyObject = KeyObject.from(key);
console.log(keyObject.symmetricKeySize);
// Prints: 32 (symmetric key size in bytes)const { KeyObject } = require('node:crypto');
const { subtle } = globalThis.crypto;

(async function() {
  const key = await subtle.generateKey({
    name: 'HMAC',
    hash: 'SHA-256',
    length: 256,
  }, true, ['sign', 'verify']);

  const keyObject = KeyObject.from(key);
  console.log(keyObject.symmetricKeySize);
  // Prints: 32 (symmetric key size in bytes)
})();copy

keyObject.asymmetricKeyDetails#

History

VersionChanges
v16.9.0
Expose RSASSA-PSS-params sequence parameters for RSA-PSS keys.
v15.7.0
Added in: v15.7.0




<Object>

modulusLength: <number> Key size in bits (RSA, DSA).
publicExponent: <bigint> Public exponent (RSA).
hashAlgorithm: <string> Name of the message digest (RSA-PSS).
mgf1HashAlgorithm: <string> Name of the message digest used by
MGF1 (RSA-PSS).
saltLength: <number> Minimal salt length in bytes (RSA-PSS).
divisorLength: <number> Size of q in bits (DSA).
namedCurve: <string> Name of the curve (EC).



This property exists only on asymmetric keys. Depending on the type of the key,
this object contains information about the key. None of the information obtained
through this property can be used to uniquely identify a key or to compromise
the security of the key.
For RSA-PSS keys, if the key material contains a RSASSA-PSS-params sequence,
the hashAlgorithm, mgf1HashAlgorithm, and saltLength properties will be
set.
Other key details might be exposed via this API using additional attributes.

keyObject.asymmetricKeyType#

History

VersionChanges
v13.9.0, v12.17.0
Added support for 'dh'.
v12.0.0
Added support for 'rsa-pss'.
v12.0.0
This property now returns undefined for KeyObject instances of unrecognized type instead of aborting.
v12.0.0
Added support for 'x25519' and 'x448'.
v12.0.0
Added support for 'ed25519' and 'ed448'.
v11.6.0
Added in: v11.6.0




<string>

For asymmetric keys, this property represents the type of the key. Supported key
types are:

'rsa' (OID 1.2.840.113549.1.1.1)
'rsa-pss' (OID 1.2.840.113549.1.1.10)
'dsa' (OID 1.2.840.10040.4.1)
'ec' (OID 1.2.840.10045.2.1)
'x25519' (OID 1.3.101.110)
'x448' (OID 1.3.101.111)
'ed25519' (OID 1.3.101.112)
'ed448' (OID 1.3.101.113)
'dh' (OID 1.2.840.113549.1.3.1)

This property is undefined for unrecognized KeyObject types and symmetric
keys.

keyObject.equals(otherKeyObject)#

Added in: v17.7.0, v16.15.0


otherKeyObject: <KeyObject> A KeyObject with which to
compare keyObject.
Returns: <boolean>

Returns true or false depending on whether the keys have exactly the same
type, value, and parameters. This method is not
constant time.

keyObject.export([options])#

History

VersionChanges
v15.9.0
Added support for 'jwk' format.
v11.6.0
Added in: v11.6.0




options: <Object>
Returns: <string> | <Buffer> | <Object>

For symmetric keys, the following encoding options can be used:

format: <string> Must be 'buffer' (default) or 'jwk'.

For public keys, the following encoding options can be used:

type: <string> Must be one of 'pkcs1' (RSA only) or 'spki'.
format: <string> Must be 'pem', 'der', or 'jwk'.

For private keys, the following encoding options can be used:

type: <string> Must be one of 'pkcs1' (RSA only), 'pkcs8' or
'sec1' (EC only).
format: <string> Must be 'pem', 'der', or 'jwk'.
cipher: <string> If specified, the private key will be encrypted with
the given cipher and passphrase using PKCS#5 v2.0 password based
encryption.
passphrase: <string> | <Buffer> The passphrase to use for encryption, see
cipher.

The result type depends on the selected encoding format, when PEM the
result is a string, when DER it will be a buffer containing the data
encoded as DER, when JWK it will be an object.
When JWK encoding format was selected, all other encoding options are
ignored.
PKCS#1, SEC1, and PKCS#8 type keys can be encrypted by using a combination of
the cipher and format options. The PKCS#8 type can be used with any
format to encrypt any key algorithm (RSA, EC, or DH) by specifying a
cipher. PKCS#1 and SEC1 can only be encrypted by specifying a cipher
when the PEM format is used. For maximum compatibility, use PKCS#8 for
encrypted private keys. Since PKCS#8 defines its own
encryption mechanism, PEM-level encryption is not supported when encrypting
a PKCS#8 key. See RFC 5208 for PKCS#8 encryption and RFC 1421 for
PKCS#1 and SEC1 encryption.

keyObject.symmetricKeySize#

Added in: v11.6.0


<number>

For secret keys, this property represents the size of the key in bytes. This
property is undefined for asymmetric keys.

keyObject.toCryptoKey(algorithm, extractable, keyUsages)#

Added in: v23.0.0, v22.10.0



algorithm: <AlgorithmIdentifier> | <RsaHashedImportParams> | <EcKeyImportParams> | <HmacImportParams>



extractable: <boolean>
keyUsages: <string[]> See Key usages.
Returns: <CryptoKey>

Converts a KeyObject instance to a CryptoKey.

keyObject.type#

Added in: v11.6.0


<string>

Depending on the type of this KeyObject, this property is either
'secret' for secret (symmetric) keys, 'public' for public (asymmetric) keys
or 'private' for private (asymmetric) keys.

Class: Sign#

Added in: v0.1.92


Extends: <stream.Writable>

The Sign class is a utility for generating signatures. It can be used in one
of two ways:

As a writable stream, where data to be signed is written and the
sign.sign() method is used to generate and return the signature, or
Using the sign.update() and sign.sign() methods to produce the
signature.

The crypto.createSign() method is used to create Sign instances. The
argument is the string name of the hash function to use. Sign objects are not
to be created directly using the new keyword.
Example: Using Sign and Verify objects as streams:

const {
  generateKeyPairSync,
  createSign,
  createVerify,
} = await import('node:crypto');

const { privateKey, publicKey } = generateKeyPairSync('ec', {
  namedCurve: 'sect239k1',
});

const sign = createSign('SHA256');
sign.write('some data to sign');
sign.end();
const signature = sign.sign(privateKey, 'hex');

const verify = createVerify('SHA256');
verify.write('some data to sign');
verify.end();
console.log(verify.verify(publicKey, signature, 'hex'));
// Prints: trueconst {
  generateKeyPairSync,
  createSign,
  createVerify,
} = require('node:crypto');

const { privateKey, publicKey } = generateKeyPairSync('ec', {
  namedCurve: 'sect239k1',
});

const sign = createSign('SHA256');
sign.write('some data to sign');
sign.end();
const signature = sign.sign(privateKey, 'hex');

const verify = createVerify('SHA256');
verify.write('some data to sign');
verify.end();
console.log(verify.verify(publicKey, signature, 'hex'));
// Prints: truecopy
Example: Using the sign.update() and verify.update() methods:

const {
  generateKeyPairSync,
  createSign,
  createVerify,
} = await import('node:crypto');

const { privateKey, publicKey } = generateKeyPairSync('rsa', {
  modulusLength: 2048,
});

const sign = createSign('SHA256');
sign.update('some data to sign');
sign.end();
const signature = sign.sign(privateKey);

const verify = createVerify('SHA256');
verify.update('some data to sign');
verify.end();
console.log(verify.verify(publicKey, signature));
// Prints: trueconst {
  generateKeyPairSync,
  createSign,
  createVerify,
} = require('node:crypto');

const { privateKey, publicKey } = generateKeyPairSync('rsa', {
  modulusLength: 2048,
});

const sign = createSign('SHA256');
sign.update('some data to sign');
sign.end();
const signature = sign.sign(privateKey);

const verify = createVerify('SHA256');
verify.update('some data to sign');
verify.end();
console.log(verify.verify(publicKey, signature));
// Prints: truecopy

sign.sign(privateKey[, outputEncoding])#

History

VersionChanges
v15.0.0
The privateKey can also be an ArrayBuffer and CryptoKey.
v13.2.0, v12.16.0
This function now supports IEEE-P1363 DSA and ECDSA signatures.
v12.0.0
This function now supports RSA-PSS keys.
v11.6.0
This function now supports key objects.
v8.0.0
Support for RSASSA-PSS and additional options was added.
v0.1.92
Added in: v0.1.92





privateKey <Object> | <string> | <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView> | <KeyObject> | <CryptoKey>

dsaEncoding <string>
padding <integer>
saltLength <integer>


outputEncoding <string> The encoding of the return value.
Returns: <Buffer> | <string>


Calculates the signature on all the data passed through using either
sign.update() or sign.write().
If privateKey is not a KeyObject, this function behaves as if
privateKey had been passed to crypto.createPrivateKey(). If it is an
object, the following additional properties can be passed:


dsaEncoding <string> For DSA and ECDSA, this option specifies the
format of the generated signature. It can be one of the following:

'der' (default): DER-encoded ASN.1 signature structure encoding (r, s).
'ieee-p1363': Signature format r || s as proposed in IEEE-P1363.



padding <integer> Optional padding value for RSA, one of the following:

crypto.constants.RSA_PKCS1_PADDING (default)
crypto.constants.RSA_PKCS1_PSS_PADDING

RSA_PKCS1_PSS_PADDING will use MGF1 with the same hash function
used to sign the message as specified in section 3.1 of RFC 4055, unless
an MGF1 hash function has been specified as part of the key in compliance with
section 3.3 of RFC 4055.


saltLength <integer> Salt length for when padding is
RSA_PKCS1_PSS_PADDING. The special value
crypto.constants.RSA_PSS_SALTLEN_DIGEST sets the salt length to the digest
size, crypto.constants.RSA_PSS_SALTLEN_MAX_SIGN (default) sets it to the
maximum permissible value.


If outputEncoding is provided a string is returned; otherwise a Buffer
is returned.
The Sign object can not be again used after sign.sign() method has been
called. Multiple calls to sign.sign() will result in an error being thrown.

sign.update(data[, inputEncoding])#

History

VersionChanges
v6.0.0
The default inputEncoding changed from binary to utf8.
v0.1.92
Added in: v0.1.92




data <string> | <Buffer> | <TypedArray> | <DataView>
inputEncoding <string> The encoding of the data string.

Updates the Sign content with the given data, the encoding of which
is given in inputEncoding.
If encoding is not provided, and the data is a string, an
encoding of 'utf8' is enforced. If data is a Buffer, TypedArray, or
DataView, then inputEncoding is ignored.
This can be called many times with new data as it is streamed.

Class: Verify#

Added in: v0.1.92


Extends: <stream.Writable>

The Verify class is a utility for verifying signatures. It can be used in one
of two ways:

As a writable stream where written data is used to validate against the
supplied signature, or
Using the verify.update() and verify.verify() methods to verify
the signature.

The crypto.createVerify() method is used to create Verify instances.
Verify objects are not to be created directly using the new keyword.
See Sign for examples.

verify.update(data[, inputEncoding])#

History

VersionChanges
v6.0.0
The default inputEncoding changed from binary to utf8.
v0.1.92
Added in: v0.1.92




data <string> | <Buffer> | <TypedArray> | <DataView>
inputEncoding <string> The encoding of the data string.

Updates the Verify content with the given data, the encoding of which
is given in inputEncoding.
If inputEncoding is not provided, and the data is a string, an
encoding of 'utf8' is enforced. If data is a Buffer, TypedArray, or
DataView, then inputEncoding is ignored.
This can be called many times with new data as it is streamed.

verify.verify(object, signature[, signatureEncoding])#

History

VersionChanges
v15.0.0
The object can also be an ArrayBuffer and CryptoKey.
v13.2.0, v12.16.0
This function now supports IEEE-P1363 DSA and ECDSA signatures.
v12.0.0
This function now supports RSA-PSS keys.
v11.7.0
The key can now be a private key.
v8.0.0
Support for RSASSA-PSS and additional options was added.
v0.1.92
Added in: v0.1.92





object <Object> | <string> | <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView> | <KeyObject> | <CryptoKey>

dsaEncoding <string>
padding <integer>
saltLength <integer>


signature <string> | <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView>
signatureEncoding <string> The encoding of the signature string.
Returns: <boolean> true or false depending on the validity of the
signature for the data and public key.


Verifies the provided data using the given object and signature.
If object is not a KeyObject, this function behaves as if
object had been passed to crypto.createPublicKey(). If it is an
object, the following additional properties can be passed:


dsaEncoding <string> For DSA and ECDSA, this option specifies the
format of the signature. It can be one of the following:

'der' (default): DER-encoded ASN.1 signature structure encoding (r, s).
'ieee-p1363': Signature format r || s as proposed in IEEE-P1363.



padding <integer> Optional padding value for RSA, one of the following:

crypto.constants.RSA_PKCS1_PADDING (default)
crypto.constants.RSA_PKCS1_PSS_PADDING

RSA_PKCS1_PSS_PADDING will use MGF1 with the same hash function
used to verify the message as specified in section 3.1 of RFC 4055, unless
an MGF1 hash function has been specified as part of the key in compliance with
section 3.3 of RFC 4055.


saltLength <integer> Salt length for when padding is
RSA_PKCS1_PSS_PADDING. The special value
crypto.constants.RSA_PSS_SALTLEN_DIGEST sets the salt length to the digest
size, crypto.constants.RSA_PSS_SALTLEN_AUTO (default) causes it to be
determined automatically.


The signature argument is the previously calculated signature for the data, in
the signatureEncoding.
If a signatureEncoding is specified, the signature is expected to be a
string; otherwise signature is expected to be a Buffer,
TypedArray, or DataView.
The verify object can not be used again after verify.verify() has been
called. Multiple calls to verify.verify() will result in an error being
thrown.
Because public keys can be derived from private keys, a private key may
be passed instead of a public key.

Class: X509Certificate#

Added in: v15.6.0

Encapsulates an X509 certificate and provides read-only access to
its information.

const { X509Certificate } = await import('node:crypto');

const x509 = new X509Certificate('{... pem encoded cert ...}');

console.log(x509.subject);const { X509Certificate } = require('node:crypto');

const x509 = new X509Certificate('{... pem encoded cert ...}');

console.log(x509.subject);copy

new X509Certificate(buffer)#

Added in: v15.6.0


buffer <string> | <TypedArray> | <Buffer> | <DataView> A PEM or DER encoded
X509 Certificate.


x509.ca#

Added in: v15.6.0


Type: <boolean> Will be true if this is a Certificate Authority (CA)
certificate.


x509.checkEmail(email[, options])#

History

VersionChanges
v18.0.0
The subject option now defaults to 'default'.
v17.5.0, v16.15.0
The subject option can now be set to 'default'.
v17.5.0, v16.14.1
The wildcards, partialWildcards, multiLabelWildcards, and singleLabelSubdomains options have been removed since they had no effect.
v15.6.0
Added in: v15.6.0




email <string>
options <Object>

subject <string> 'default', 'always', or 'never'.
Default: 'default'.


Returns: <string> | <undefined> Returns email if the certificate matches,
undefined if it does not.

Checks whether the certificate matches the given email address.
If the 'subject' option is undefined or set to 'default', the certificate
subject is only considered if the subject alternative name extension either does
not exist or does not contain any email addresses.
If the 'subject' option is set to 'always' and if the subject alternative
name extension either does not exist or does not contain a matching email
address, the certificate subject is considered.
If the 'subject' option is set to 'never', the certificate subject is never
considered, even if the certificate contains no subject alternative names.

x509.checkHost(name[, options])#

History

VersionChanges
v18.0.0
The subject option now defaults to 'default'.
v17.5.0, v16.15.0
The subject option can now be set to 'default'.
v15.6.0
Added in: v15.6.0




name <string>
options <Object>

subject <string> 'default', 'always', or 'never'.
Default: 'default'.
wildcards <boolean> Default: true.
partialWildcards <boolean> Default: true.
multiLabelWildcards <boolean> Default: false.
singleLabelSubdomains <boolean> Default: false.


Returns: <string> | <undefined> Returns a subject name that matches name,
or undefined if no subject name matches name.

Checks whether the certificate matches the given host name.
If the certificate matches the given host name, the matching subject name is
returned. The returned name might be an exact match (e.g., foo.example.com)
or it might contain wildcards (e.g., *.example.com). Because host name
comparisons are case-insensitive, the returned subject name might also differ
from the given name in capitalization.
If the 'subject' option is undefined or set to 'default', the certificate
subject is only considered if the subject alternative name extension either does
not exist or does not contain any DNS names. This behavior is consistent with
RFC 2818 ("HTTP Over TLS").
If the 'subject' option is set to 'always' and if the subject alternative
name extension either does not exist or does not contain a matching DNS name,
the certificate subject is considered.
If the 'subject' option is set to 'never', the certificate subject is never
considered, even if the certificate contains no subject alternative names.

x509.checkIP(ip)#

History

VersionChanges
v17.5.0, v16.14.1
The options argument has been removed since it had no effect.
v15.6.0
Added in: v15.6.0




ip <string>
Returns: <string> | <undefined> Returns ip if the certificate matches,
undefined if it does not.

Checks whether the certificate matches the given IP address (IPv4 or IPv6).
Only RFC 5280 iPAddress subject alternative names are considered, and they
must match the given ip address exactly. Other subject alternative names as
well as the subject field of the certificate are ignored.

x509.checkIssued(otherCert)#

Added in: v15.6.0


otherCert <X509Certificate>
Returns: <boolean>

Checks whether this certificate was issued by the given otherCert.

x509.checkPrivateKey(privateKey)#

Added in: v15.6.0


privateKey <KeyObject> A private key.
Returns: <boolean>

Checks whether the public key for this certificate is consistent with
the given private key.

x509.extKeyUsage#

Added in: v15.6.0


Type: <string[]>

An array detailing the key extended usages for this certificate.

x509.fingerprint#

Added in: v15.6.0


Type: <string>

The SHA-1 fingerprint of this certificate.
Because SHA-1 is cryptographically broken and because the security of SHA-1 is
significantly worse than that of algorithms that are commonly used to sign
certificates, consider using x509.fingerprint256 instead.

x509.fingerprint256#

Added in: v15.6.0


Type: <string>

The SHA-256 fingerprint of this certificate.

x509.fingerprint512#

Added in: v17.2.0, v16.14.0


Type: <string>

The SHA-512 fingerprint of this certificate.
Because computing the SHA-256 fingerprint is usually faster and because it is
only half the size of the SHA-512 fingerprint, x509.fingerprint256 may be
a better choice. While SHA-512 presumably provides a higher level of security in
general, the security of SHA-256 matches that of most algorithms that are
commonly used to sign certificates.

x509.infoAccess#

History

VersionChanges
v17.3.1, v16.13.2
Parts of this string may be encoded as JSON string literals in response to CVE-2021-44532.
v15.6.0
Added in: v15.6.0




Type: <string>

A textual representation of the certificate's authority information access
extension.
This is a line feed separated list of access descriptions. Each line begins with
the access method and the kind of the access location, followed by a colon and
the value associated with the access location.
After the prefix denoting the access method and the kind of the access location,
the remainder of each line might be enclosed in quotes to indicate that the
value is a JSON string literal. For backward compatibility, Node.js only uses
JSON string literals within this property when necessary to avoid ambiguity.
Third-party code should be prepared to handle both possible entry formats.

x509.issuer#

Added in: v15.6.0


Type: <string>

The issuer identification included in this certificate.

x509.issuerCertificate#

Added in: v15.9.0


Type: <X509Certificate>

The issuer certificate or undefined if the issuer certificate is not
available.

x509.publicKey#

Added in: v15.6.0


Type: <KeyObject>

The public key <KeyObject> for this certificate.

x509.raw#

Added in: v15.6.0


Type: <Buffer>

A Buffer containing the DER encoding of this certificate.

x509.serialNumber#

Added in: v15.6.0


Type: <string>

The serial number of this certificate.
Serial numbers are assigned by certificate authorities and do not uniquely
identify certificates. Consider using x509.fingerprint256 as a unique
identifier instead.

x509.subject#

Added in: v15.6.0


Type: <string>

The complete subject of this certificate.

x509.subjectAltName#

History

VersionChanges
v17.3.1, v16.13.2
Parts of this string may be encoded as JSON string literals in response to CVE-2021-44532.
v15.6.0
Added in: v15.6.0




Type: <string>

The subject alternative name specified for this certificate.
This is a comma-separated list of subject alternative names. Each entry begins
with a string identifying the kind of the subject alternative name followed by
a colon and the value associated with the entry.
Earlier versions of Node.js incorrectly assumed that it is safe to split this
property at the two-character sequence ', ' (see CVE-2021-44532). However,
both malicious and legitimate certificates can contain subject alternative names
that include this sequence when represented as a string.
After the prefix denoting the type of the entry, the remainder of each entry
might be enclosed in quotes to indicate that the value is a JSON string literal.
For backward compatibility, Node.js only uses JSON string literals within this
property when necessary to avoid ambiguity. Third-party code should be prepared
to handle both possible entry formats.

x509.toJSON()#

Added in: v15.6.0


Type: <string>

There is no standard JSON encoding for X509 certificates. The
toJSON() method returns a string containing the PEM encoded
certificate.

x509.toLegacyObject()#

Added in: v15.6.0


Type: <Object>

Returns information about this certificate using the legacy
certificate object encoding.

x509.toString()#

Added in: v15.6.0


Type: <string>

Returns the PEM-encoded certificate.

x509.validFrom#

Added in: v15.6.0


Type: <string>

The date/time from which this certificate is valid.

x509.validFromDate#

Added in: v23.0.0, v22.10.0


Type: <Date>

The date/time from which this certificate is valid, encapsulated in a Date object.

x509.validTo#

Added in: v15.6.0


Type: <string>

The date/time until which this certificate is valid.

x509.validToDate#

Added in: v23.0.0, v22.10.0


Type: <Date>

The date/time until which this certificate is valid, encapsulated in a Date object.

x509.verify(publicKey)#

Added in: v15.6.0


publicKey <KeyObject> A public key.
Returns: <boolean>

Verifies that this certificate was signed by the given public key.
Does not perform any other validation checks on the certificate.

node:crypto module methods and properties#

crypto.checkPrime(candidate[, options], callback)#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v15.8.0
Added in: v15.8.0




candidate <ArrayBuffer> | <SharedArrayBuffer> | <TypedArray> | <Buffer> | <DataView> | <bigint>
A possible prime encoded as a sequence of big endian octets of arbitrary
length.
options <Object>

checks <number> The number of Miller-Rabin probabilistic primality
iterations to perform. When the value is 0 (zero), a number of checks
is used that yields a false positive rate of at most 2-64 for
random input. Care must be used when selecting a number of checks. Refer
to the OpenSSL documentation for the BN_is_prime_ex function nchecks
options for more details. Default: 0


callback <Function>

err <Error> Set to an <Error> object if an error occurred during check.
result <boolean> true if the candidate is a prime with an error
probability less than 0.25 ** options.checks.



Checks the primality of the candidate.

crypto.checkPrimeSync(candidate[, options])#

Added in: v15.8.0


candidate <ArrayBuffer> | <SharedArrayBuffer> | <TypedArray> | <Buffer> | <DataView> | <bigint>
A possible prime encoded as a sequence of big endian octets of arbitrary
length.
options <Object>

checks <number> The number of Miller-Rabin probabilistic primality
iterations to perform. When the value is 0 (zero), a number of checks
is used that yields a false positive rate of at most 2-64 for
random input. Care must be used when selecting a number of checks. Refer
to the OpenSSL documentation for the BN_is_prime_ex function nchecks
options for more details. Default: 0


Returns: <boolean> true if the candidate is a prime with an error
probability less than 0.25 ** options.checks.

Checks the primality of the candidate.

crypto.constants#

Added in: v6.3.0


<Object>

An object containing commonly used constants for crypto and security related
operations. The specific constants currently defined are described in
Crypto constants.

crypto.createCipheriv(algorithm, key, iv[, options])#

History

VersionChanges
v17.9.0, v16.17.0
The authTagLength option is now optional when using the chacha20-poly1305 cipher and defaults to 16 bytes.
v15.0.0
The password and iv arguments can be an ArrayBuffer and are each limited to a maximum of 2 ** 31 - 1 bytes.
v11.6.0
The key argument can now be a KeyObject.
v11.2.0, v10.17.0
The cipher chacha20-poly1305 (the IETF variant of ChaCha20-Poly1305) is now supported.
v10.10.0
Ciphers in OCB mode are now supported.
v10.2.0
The authTagLength option can now be used to produce shorter authentication tags in GCM mode and defaults to 16 bytes.
v9.9.0
The iv parameter may now be null for ciphers which do not need an initialization vector.
v0.1.94
Added in: v0.1.94




algorithm <string>
key <string> | <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView> | <KeyObject> | <CryptoKey>
iv <string> | <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView> | <null>
options <Object> stream.transform options
Returns: <Cipheriv>

Creates and returns a Cipheriv object, with the given algorithm, key and
initialization vector (iv).
The options argument controls stream behavior and is optional except when a
cipher in CCM or OCB mode (e.g. 'aes-128-ccm') is used. In that case, the
authTagLength option is required and specifies the length of the
authentication tag in bytes, see CCM mode. In GCM mode, the authTagLength
option is not required but can be used to set the length of the authentication
tag that will be returned by getAuthTag() and defaults to 16 bytes.
For chacha20-poly1305, the authTagLength option defaults to 16 bytes.
The algorithm is dependent on OpenSSL, examples are 'aes192', etc. On
recent OpenSSL releases, openssl list -cipher-algorithms will
display the available cipher algorithms.
The key is the raw key used by the algorithm and iv is an
initialization vector. Both arguments must be 'utf8' encoded strings,
Buffers, TypedArray, or DataViews. The key may optionally be
a KeyObject of type secret. If the cipher does not need
an initialization vector, iv may be null.
When passing strings for key or iv, please consider
caveats when using strings as inputs to cryptographic APIs.
Initialization vectors should be unpredictable and unique; ideally, they will be
cryptographically random. They do not have to be secret: IVs are typically just
added to ciphertext messages unencrypted. It may sound contradictory that
something has to be unpredictable and unique, but does not have to be secret;
remember that an attacker must not be able to predict ahead of time what a
given IV will be.

crypto.createDecipheriv(algorithm, key, iv[, options])#

History

VersionChanges
v17.9.0, v16.17.0
The authTagLength option is now optional when using the chacha20-poly1305 cipher and defaults to 16 bytes.
v11.6.0
The key argument can now be a KeyObject.
v11.2.0, v10.17.0
The cipher chacha20-poly1305 (the IETF variant of ChaCha20-Poly1305) is now supported.
v10.10.0
Ciphers in OCB mode are now supported.
v10.2.0
The authTagLength option can now be used to restrict accepted GCM authentication tag lengths.
v9.9.0
The iv parameter may now be null for ciphers which do not need an initialization vector.
v0.1.94
Added in: v0.1.94




algorithm <string>
key <string> | <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView> | <KeyObject> | <CryptoKey>
iv <string> | <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView> | <null>
options <Object> stream.transform options
Returns: <Decipheriv>

Creates and returns a Decipheriv object that uses the given algorithm, key
and initialization vector (iv).
The options argument controls stream behavior and is optional except when a
cipher in CCM or OCB mode (e.g. 'aes-128-ccm') is used. In that case, the
authTagLength option is required and specifies the length of the
authentication tag in bytes, see CCM mode.
For AES-GCM and chacha20-poly1305, the authTagLength option defaults to 16
bytes and must be set to a different value if a different length is used.
The algorithm is dependent on OpenSSL, examples are 'aes192', etc. On
recent OpenSSL releases, openssl list -cipher-algorithms will
display the available cipher algorithms.
The key is the raw key used by the algorithm and iv is an
initialization vector. Both arguments must be 'utf8' encoded strings,
Buffers, TypedArray, or DataViews. The key may optionally be
a KeyObject of type secret. If the cipher does not need
an initialization vector, iv may be null.
When passing strings for key or iv, please consider
caveats when using strings as inputs to cryptographic APIs.
Initialization vectors should be unpredictable and unique; ideally, they will be
cryptographically random. They do not have to be secret: IVs are typically just
added to ciphertext messages unencrypted. It may sound contradictory that
something has to be unpredictable and unique, but does not have to be secret;
remember that an attacker must not be able to predict ahead of time what a given
IV will be.

crypto.createDiffieHellman(prime[, primeEncoding][, generator][, generatorEncoding])#

History

VersionChanges
v8.0.0
The prime argument can be any TypedArray or DataView now.
v8.0.0
The prime argument can be a Uint8Array now.
v6.0.0
The default for the encoding parameters changed from binary to utf8.
v0.11.12
Added in: v0.11.12




prime <string> | <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView>
primeEncoding <string> The encoding of the prime string.
generator <number> | <string> | <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView>
Default: 2
generatorEncoding <string> The encoding of the generator string.
Returns: <DiffieHellman>

Creates a DiffieHellman key exchange object using the supplied prime and an
optional specific generator.
The generator argument can be a number, string, or Buffer. If
generator is not specified, the value 2 is used.
If primeEncoding is specified, prime is expected to be a string; otherwise
a Buffer, TypedArray, or DataView is expected.
If generatorEncoding is specified, generator is expected to be a string;
otherwise a number, Buffer, TypedArray, or DataView is expected.

crypto.createDiffieHellman(primeLength[, generator])#

Added in: v0.5.0


primeLength <number>
generator <number> Default: 2
Returns: <DiffieHellman>

Creates a DiffieHellman key exchange object and generates a prime of
primeLength bits using an optional specific numeric generator.
If generator is not specified, the value 2 is used.

crypto.createDiffieHellmanGroup(name)#

Added in: v0.9.3


name <string>
Returns: <DiffieHellmanGroup>

An alias for crypto.getDiffieHellman()

crypto.createECDH(curveName)#

Added in: v0.11.14


curveName <string>
Returns: <ECDH>

Creates an Elliptic Curve Diffie-Hellman (ECDH) key exchange object using a
predefined curve specified by the curveName string. Use
crypto.getCurves() to obtain a list of available curve names. On recent
OpenSSL releases, openssl ecparam -list_curves will also display the name
and description of each available elliptic curve.

crypto.createHash(algorithm[, options])#

History

VersionChanges
v12.8.0
The outputLength option was added for XOF hash functions.
v0.1.92
Added in: v0.1.92




algorithm <string>
options <Object> stream.transform options
Returns: <Hash>

Creates and returns a Hash object that can be used to generate hash digests
using the given algorithm. Optional options argument controls stream
behavior. For XOF hash functions such as 'shake256', the outputLength option
can be used to specify the desired output length in bytes.
The algorithm is dependent on the available algorithms supported by the
version of OpenSSL on the platform. Examples are 'sha256', 'sha512', etc.
On recent releases of OpenSSL, openssl list -digest-algorithms will
display the available digest algorithms.
Example: generating the sha256 sum of a file

import {
  createReadStream,
} from 'node:fs';
import { argv } from 'node:process';
const {
  createHash,
} = await import('node:crypto');

const filename = argv[2];

const hash = createHash('sha256');

const input = createReadStream(filename);
input.on('readable', () => {
  // Only one element is going to be produced by the
  // hash stream.
  const data = input.read();
  if (data)
    hash.update(data);
  else {
    console.log(`${hash.digest('hex')} ${filename}`);
  }
});const {
  createReadStream,
} = require('node:fs');
const {
  createHash,
} = require('node:crypto');
const { argv } = require('node:process');

const filename = argv[2];

const hash = createHash('sha256');

const input = createReadStream(filename);
input.on('readable', () => {
  // Only one element is going to be produced by the
  // hash stream.
  const data = input.read();
  if (data)
    hash.update(data);
  else {
    console.log(`${hash.digest('hex')} ${filename}`);
  }
});copy

crypto.createHmac(algorithm, key[, options])#

History

VersionChanges
v15.0.0
The key can also be an ArrayBuffer or CryptoKey. The encoding option was added. The key cannot contain more than 2 ** 32 - 1 bytes.
v11.6.0
The key argument can now be a KeyObject.
v0.1.94
Added in: v0.1.94




algorithm <string>
key <string> | <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView> | <KeyObject> | <CryptoKey>
options <Object> stream.transform options

encoding <string> The string encoding to use when key is a string.


Returns: <Hmac>

Creates and returns an Hmac object that uses the given algorithm and key.
Optional options argument controls stream behavior.
The algorithm is dependent on the available algorithms supported by the
version of OpenSSL on the platform. Examples are 'sha256', 'sha512', etc.
On recent releases of OpenSSL, openssl list -digest-algorithms will
display the available digest algorithms.
The key is the HMAC key used to generate the cryptographic HMAC hash. If it is
a KeyObject, its type must be secret. If it is a string, please consider
caveats when using strings as inputs to cryptographic APIs. If it was
obtained from a cryptographically secure source of entropy, such as
crypto.randomBytes() or crypto.generateKey(), its length should not
exceed the block size of algorithm (e.g., 512 bits for SHA-256).
Example: generating the sha256 HMAC of a file

import {
  createReadStream,
} from 'node:fs';
import { argv } from 'node:process';
const {
  createHmac,
} = await import('node:crypto');

const filename = argv[2];

const hmac = createHmac('sha256', 'a secret');

const input = createReadStream(filename);
input.on('readable', () => {
  // Only one element is going to be produced by the
  // hash stream.
  const data = input.read();
  if (data)
    hmac.update(data);
  else {
    console.log(`${hmac.digest('hex')} ${filename}`);
  }
});const {
  createReadStream,
} = require('node:fs');
const {
  createHmac,
} = require('node:crypto');
const { argv } = require('node:process');

const filename = argv[2];

const hmac = createHmac('sha256', 'a secret');

const input = createReadStream(filename);
input.on('readable', () => {
  // Only one element is going to be produced by the
  // hash stream.
  const data = input.read();
  if (data)
    hmac.update(data);
  else {
    console.log(`${hmac.digest('hex')} ${filename}`);
  }
});copy

crypto.createPrivateKey(key)#

History

VersionChanges
v15.12.0
The key can also be a JWK object.
v15.0.0
The key can also be an ArrayBuffer. The encoding option was added. The key cannot contain more than 2 ** 32 - 1 bytes.
v11.6.0
Added in: v11.6.0





key <Object> | <string> | <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView>

key: <string> | <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView> | <Object> The key
material, either in PEM, DER, or JWK format.
format: <string> Must be 'pem', 'der', or ''jwk'.
Default: 'pem'.
type: <string> Must be 'pkcs1', 'pkcs8' or 'sec1'. This option is
required only if the format is 'der' and ignored otherwise.
passphrase: <string> | <Buffer> The passphrase to use for decryption.
encoding: <string> The string encoding to use when key is a string.


Returns: <KeyObject>


Creates and returns a new key object containing a private key. If key is a
string or Buffer, format is assumed to be 'pem'; otherwise, key
must be an object with the properties described above.
If the private key is encrypted, a passphrase must be specified. The length
of the passphrase is limited to 1024 bytes.

crypto.createPublicKey(key)#

History

VersionChanges
v15.12.0
The key can also be a JWK object.
v15.0.0
The key can also be an ArrayBuffer. The encoding option was added. The key cannot contain more than 2 ** 32 - 1 bytes.
v11.13.0
The key argument can now be a KeyObject with type private.
v11.7.0
The key argument can now be a private key.
v11.6.0
Added in: v11.6.0





key <Object> | <string> | <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView>

key: <string> | <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView> | <Object> The key
material, either in PEM, DER, or JWK format.
format: <string> Must be 'pem', 'der', or 'jwk'.
Default: 'pem'.
type: <string> Must be 'pkcs1' or 'spki'. This option is
required only if the format is 'der' and ignored otherwise.
encoding <string> The string encoding to use when key is a string.


Returns: <KeyObject>


Creates and returns a new key object containing a public key. If key is a
string or Buffer, format is assumed to be 'pem'; if key is a KeyObject
with type 'private', the public key is derived from the given private key;
otherwise, key must be an object with the properties described above.
If the format is 'pem', the 'key' may also be an X.509 certificate.
Because public keys can be derived from private keys, a private key may be
passed instead of a public key. In that case, this function behaves as if
crypto.createPrivateKey() had been called, except that the type of the
returned KeyObject will be 'public' and that the private key cannot be
extracted from the returned KeyObject. Similarly, if a KeyObject with type
'private' is given, a new KeyObject with type 'public' will be returned
and it will be impossible to extract the private key from the returned object.

crypto.createSecretKey(key[, encoding])#

History

VersionChanges
v18.8.0, v16.18.0
The key can now be zero-length.
v15.0.0
The key can also be an ArrayBuffer or string. The encoding argument was added. The key cannot contain more than 2 ** 32 - 1 bytes.
v11.6.0
Added in: v11.6.0




key <string> | <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView>
encoding <string> The string encoding when key is a string.
Returns: <KeyObject>

Creates and returns a new key object containing a secret key for symmetric
encryption or Hmac.

crypto.createSign(algorithm[, options])#

Added in: v0.1.92


algorithm <string>
options <Object> stream.Writable options
Returns: <Sign>

Creates and returns a Sign object that uses the given algorithm. Use
crypto.getHashes() to obtain the names of the available digest algorithms.
Optional options argument controls the stream.Writable behavior.
In some cases, a Sign instance can be created using the name of a signature
algorithm, such as 'RSA-SHA256', instead of a digest algorithm. This will use
the corresponding digest algorithm. This does not work for all signature
algorithms, such as 'ecdsa-with-SHA256', so it is best to always use digest
algorithm names.

crypto.createVerify(algorithm[, options])#

Added in: v0.1.92


algorithm <string>
options <Object> stream.Writable options
Returns: <Verify>

Creates and returns a Verify object that uses the given algorithm.
Use crypto.getHashes() to obtain an array of names of the available
signing algorithms. Optional options argument controls the
stream.Writable behavior.
In some cases, a Verify instance can be created using the name of a signature
algorithm, such as 'RSA-SHA256', instead of a digest algorithm. This will use
the corresponding digest algorithm. This does not work for all signature
algorithms, such as 'ecdsa-with-SHA256', so it is best to always use digest
algorithm names.

crypto.diffieHellman(options[, callback])#

History

VersionChanges
v23.11.0
Optional callback argument added.
v13.9.0, v12.17.0
Added in: v13.9.0, v12.17.0




options: <Object>

privateKey: <KeyObject>
publicKey: <KeyObject>


callback <Function>

err <Error>
secret <Buffer>


Returns: <Buffer> if the callback function is not provided.

Computes the Diffie-Hellman secret based on a privateKey and a publicKey.
Both keys must have the same asymmetricKeyType, which must be one of 'dh'
(for Diffie-Hellman), 'ec', 'x448', or 'x25519' (for ECDH).
If the callback function is provided this function uses libuv's threadpool.

crypto.fips#

Added in: v6.0.0Deprecated since: v10.0.0

Stability: 0 - Deprecated
Property for checking and controlling whether a FIPS compliant crypto provider
is currently in use. Setting to true requires a FIPS build of Node.js.
This property is deprecated. Please use crypto.setFips() and
crypto.getFips() instead.

crypto.generateKey(type, options, callback)#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v15.0.0
Added in: v15.0.0




type: <string> The intended use of the generated secret key. Currently
accepted values are 'hmac' and 'aes'.
options: <Object>

length: <number> The bit length of the key to generate. This must be a
value greater than 0.

If type is 'hmac', the minimum is 8, and the maximum length is
231-1. If the value is not a multiple of 8, the generated
key will be truncated to Math.floor(length / 8).
If type is 'aes', the length must be one of 128, 192, or 256.




callback: <Function>

err: <Error>
key: <KeyObject>



Asynchronously generates a new random secret key of the given length. The
type will determine which validations will be performed on the length.

const {
  generateKey,
} = await import('node:crypto');

generateKey('hmac', { length: 512 }, (err, key) => {
  if (err) throw err;
  console.log(key.export().toString('hex'));  // 46e..........620
});const {
  generateKey,
} = require('node:crypto');

generateKey('hmac', { length: 512 }, (err, key) => {
  if (err) throw err;
  console.log(key.export().toString('hex'));  // 46e..........620
});copy
The size of a generated HMAC key should not exceed the block size of the
underlying hash function. See crypto.createHmac() for more information.

crypto.generateKeyPair(type, options, callback)#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v16.10.0
Add ability to define RSASSA-PSS-params sequence parameters for RSA-PSS keys pairs.
v13.9.0, v12.17.0
Add support for Diffie-Hellman.
v12.0.0
Add support for RSA-PSS key pairs.
v12.0.0
Add ability to generate X25519 and X448 key pairs.
v12.0.0
Add ability to generate Ed25519 and Ed448 key pairs.
v11.6.0
The generateKeyPair and generateKeyPairSync functions now produce key objects if no encoding was specified.
v10.12.0
Added in: v10.12.0




type: <string> Must be 'rsa', 'rsa-pss', 'dsa', 'ec', 'ed25519',
'ed448', 'x25519', 'x448', or 'dh'.
options: <Object>

modulusLength: <number> Key size in bits (RSA, DSA).
publicExponent: <number> Public exponent (RSA). Default: 0x10001.
hashAlgorithm: <string> Name of the message digest (RSA-PSS).
mgf1HashAlgorithm: <string> Name of the message digest used by
MGF1 (RSA-PSS).
saltLength: <number> Minimal salt length in bytes (RSA-PSS).
divisorLength: <number> Size of q in bits (DSA).
namedCurve: <string> Name of the curve to use (EC).
prime: <Buffer> The prime parameter (DH).
primeLength: <number> Prime length in bits (DH).
generator: <number> Custom generator (DH). Default: 2.
groupName: <string> Diffie-Hellman group name (DH). See
crypto.getDiffieHellman().
paramEncoding: <string> Must be 'named' or 'explicit' (EC).
Default: 'named'.
publicKeyEncoding: <Object> See keyObject.export().
privateKeyEncoding: <Object> See keyObject.export().


callback: <Function>

err: <Error>
publicKey: <string> | <Buffer> | <KeyObject>
privateKey: <string> | <Buffer> | <KeyObject>



Generates a new asymmetric key pair of the given type. RSA, RSA-PSS, DSA, EC,
Ed25519, Ed448, X25519, X448, and DH are currently supported.
If a publicKeyEncoding or privateKeyEncoding was specified, this function
behaves as if keyObject.export() had been called on its result. Otherwise,
the respective part of the key is returned as a KeyObject.
It is recommended to encode public keys as 'spki' and private keys as
'pkcs8' with encryption for long-term storage:

const {
  generateKeyPair,
} = await import('node:crypto');

generateKeyPair('rsa', {
  modulusLength: 4096,
  publicKeyEncoding: {
    type: 'spki',
    format: 'pem',
  },
  privateKeyEncoding: {
    type: 'pkcs8',
    format: 'pem',
    cipher: 'aes-256-cbc',
    passphrase: 'top secret',
  },
}, (err, publicKey, privateKey) => {
  // Handle errors and use the generated key pair.
});const {
  generateKeyPair,
} = require('node:crypto');

generateKeyPair('rsa', {
  modulusLength: 4096,
  publicKeyEncoding: {
    type: 'spki',
    format: 'pem',
  },
  privateKeyEncoding: {
    type: 'pkcs8',
    format: 'pem',
    cipher: 'aes-256-cbc',
    passphrase: 'top secret',
  },
}, (err, publicKey, privateKey) => {
  // Handle errors and use the generated key pair.
});copy
On completion, callback will be called with err set to undefined and
publicKey / privateKey representing the generated key pair.
If this method is invoked as its util.promisify()ed version, it returns
a Promise for an Object with publicKey and privateKey properties.

crypto.generateKeyPairSync(type, options)#

History

VersionChanges
v16.10.0
Add ability to define RSASSA-PSS-params sequence parameters for RSA-PSS keys pairs.
v13.9.0, v12.17.0
Add support for Diffie-Hellman.
v12.0.0
Add support for RSA-PSS key pairs.
v12.0.0
Add ability to generate X25519 and X448 key pairs.
v12.0.0
Add ability to generate Ed25519 and Ed448 key pairs.
v11.6.0
The generateKeyPair and generateKeyPairSync functions now produce key objects if no encoding was specified.
v10.12.0
Added in: v10.12.0




type: <string> Must be 'rsa', 'rsa-pss', 'dsa', 'ec', 'ed25519',
'ed448', 'x25519', 'x448', or 'dh'.
options: <Object>

modulusLength: <number> Key size in bits (RSA, DSA).
publicExponent: <number> Public exponent (RSA). Default: 0x10001.
hashAlgorithm: <string> Name of the message digest (RSA-PSS).
mgf1HashAlgorithm: <string> Name of the message digest used by
MGF1 (RSA-PSS).
saltLength: <number> Minimal salt length in bytes (RSA-PSS).
divisorLength: <number> Size of q in bits (DSA).
namedCurve: <string> Name of the curve to use (EC).
prime: <Buffer> The prime parameter (DH).
primeLength: <number> Prime length in bits (DH).
generator: <number> Custom generator (DH). Default: 2.
groupName: <string> Diffie-Hellman group name (DH). See
crypto.getDiffieHellman().
paramEncoding: <string> Must be 'named' or 'explicit' (EC).
Default: 'named'.
publicKeyEncoding: <Object> See keyObject.export().
privateKeyEncoding: <Object> See keyObject.export().


Returns: <Object>

publicKey: <string> | <Buffer> | <KeyObject>
privateKey: <string> | <Buffer> | <KeyObject>



Generates a new asymmetric key pair of the given type. RSA, RSA-PSS, DSA, EC,
Ed25519, Ed448, X25519, X448, and DH are currently supported.
If a publicKeyEncoding or privateKeyEncoding was specified, this function
behaves as if keyObject.export() had been called on its result. Otherwise,
the respective part of the key is returned as a KeyObject.
When encoding public keys, it is recommended to use 'spki'. When encoding
private keys, it is recommended to use 'pkcs8' with a strong passphrase,
and to keep the passphrase confidential.

const {
  generateKeyPairSync,
} = await import('node:crypto');

const {
  publicKey,
  privateKey,
} = generateKeyPairSync('rsa', {
  modulusLength: 4096,
  publicKeyEncoding: {
    type: 'spki',
    format: 'pem',
  },
  privateKeyEncoding: {
    type: 'pkcs8',
    format: 'pem',
    cipher: 'aes-256-cbc',
    passphrase: 'top secret',
  },
});const {
  generateKeyPairSync,
} = require('node:crypto');

const {
  publicKey,
  privateKey,
} = generateKeyPairSync('rsa', {
  modulusLength: 4096,
  publicKeyEncoding: {
    type: 'spki',
    format: 'pem',
  },
  privateKeyEncoding: {
    type: 'pkcs8',
    format: 'pem',
    cipher: 'aes-256-cbc',
    passphrase: 'top secret',
  },
});copy
The return value { publicKey, privateKey } represents the generated key pair.
When PEM encoding was selected, the respective key will be a string, otherwise
it will be a buffer containing the data encoded as DER.

crypto.generateKeySync(type, options)#

Added in: v15.0.0


type: <string> The intended use of the generated secret key. Currently
accepted values are 'hmac' and 'aes'.
options: <Object>

length: <number> The bit length of the key to generate.

If type is 'hmac', the minimum is 8, and the maximum length is
231-1. If the value is not a multiple of 8, the generated
key will be truncated to Math.floor(length / 8).
If type is 'aes', the length must be one of 128, 192, or 256.




Returns: <KeyObject>

Synchronously generates a new random secret key of the given length. The
type will determine which validations will be performed on the length.

const {
  generateKeySync,
} = await import('node:crypto');

const key = generateKeySync('hmac', { length: 512 });
console.log(key.export().toString('hex'));  // e89..........41econst {
  generateKeySync,
} = require('node:crypto');

const key = generateKeySync('hmac', { length: 512 });
console.log(key.export().toString('hex'));  // e89..........41ecopy
The size of a generated HMAC key should not exceed the block size of the
underlying hash function. See crypto.createHmac() for more information.

crypto.generatePrime(size[, options[, callback]])#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v15.8.0
Added in: v15.8.0




size <number> The size (in bits) of the prime to generate.
options <Object>

add <ArrayBuffer> | <SharedArrayBuffer> | <TypedArray> | <Buffer> | <DataView> | <bigint>
rem <ArrayBuffer> | <SharedArrayBuffer> | <TypedArray> | <Buffer> | <DataView> | <bigint>
safe <boolean> Default: false.
bigint <boolean> When true, the generated prime is returned
as a bigint.


callback <Function>

err <Error>
prime <ArrayBuffer> | <bigint>



Generates a pseudorandom prime of size bits.
If options.safe is true, the prime will be a safe prime -- that is,
(prime - 1) / 2 will also be a prime.
The options.add and options.rem parameters can be used to enforce additional
requirements, e.g., for Diffie-Hellman:

If options.add and options.rem are both set, the prime will satisfy the
condition that prime % add = rem.
If only options.add is set and options.safe is not true, the prime will
satisfy the condition that prime % add = 1.
If only options.add is set and options.safe is set to true, the prime
will instead satisfy the condition that prime % add = 3. This is necessary
because prime % add = 1 for options.add > 2 would contradict the condition
enforced by options.safe.
options.rem is ignored if options.add is not given.

Both options.add and options.rem must be encoded as big-endian sequences
if given as an ArrayBuffer, SharedArrayBuffer, TypedArray, Buffer, or
DataView.
By default, the prime is encoded as a big-endian sequence of octets
in an <ArrayBuffer>. If the bigint option is true, then a <bigint>
is provided.
The size of the prime will have a direct impact on how long it takes to
generate the prime. The larger the size, the longer it will take. Because
we use OpenSSL's BN_generate_prime_ex function, which provides only
minimal control over our ability to interrupt the generation process,
it is not recommended to generate overly large primes, as doing so may make
the process unresponsive.

crypto.generatePrimeSync(size[, options])#

Added in: v15.8.0


size <number> The size (in bits) of the prime to generate.
options <Object>

add <ArrayBuffer> | <SharedArrayBuffer> | <TypedArray> | <Buffer> | <DataView> | <bigint>
rem <ArrayBuffer> | <SharedArrayBuffer> | <TypedArray> | <Buffer> | <DataView> | <bigint>
safe <boolean> Default: false.
bigint <boolean> When true, the generated prime is returned
as a bigint.


Returns: <ArrayBuffer> | <bigint>

Generates a pseudorandom prime of size bits.
If options.safe is true, the prime will be a safe prime -- that is,
(prime - 1) / 2 will also be a prime.
The options.add and options.rem parameters can be used to enforce additional
requirements, e.g., for Diffie-Hellman:

If options.add and options.rem are both set, the prime will satisfy the
condition that prime % add = rem.
If only options.add is set and options.safe is not true, the prime will
satisfy the condition that prime % add = 1.
If only options.add is set and options.safe is set to true, the prime
will instead satisfy the condition that prime % add = 3. This is necessary
because prime % add = 1 for options.add > 2 would contradict the condition
enforced by options.safe.
options.rem is ignored if options.add is not given.

Both options.add and options.rem must be encoded as big-endian sequences
if given as an ArrayBuffer, SharedArrayBuffer, TypedArray, Buffer, or
DataView.
By default, the prime is encoded as a big-endian sequence of octets
in an <ArrayBuffer>. If the bigint option is true, then a <bigint>
is provided.
The size of the prime will have a direct impact on how long it takes to
generate the prime. The larger the size, the longer it will take. Because
we use OpenSSL's BN_generate_prime_ex function, which provides only
minimal control over our ability to interrupt the generation process,
it is not recommended to generate overly large primes, as doing so may make
the process unresponsive.

crypto.getCipherInfo(nameOrNid[, options])#

Added in: v15.0.0


nameOrNid: <string> | <number> The name or nid of the cipher to query.
options: <Object>

keyLength: <number> A test key length.
ivLength: <number> A test IV length.


Returns: <Object>

name <string> The name of the cipher
nid <number> The nid of the cipher
blockSize <number> The block size of the cipher in bytes. This property
is omitted when mode is 'stream'.
ivLength <number> The expected or default initialization vector length in
bytes. This property is omitted if the cipher does not use an initialization
vector.
keyLength <number> The expected or default key length in bytes.
mode <string> The cipher mode. One of 'cbc', 'ccm', 'cfb', 'ctr',
'ecb', 'gcm', 'ocb', 'ofb', 'stream', 'wrap', 'xts'.



Returns information about a given cipher.
Some ciphers accept variable length keys and initialization vectors. By default,
the crypto.getCipherInfo() method will return the default values for these
ciphers. To test if a given key length or iv length is acceptable for given
cipher, use the keyLength and ivLength options. If the given values are
unacceptable, undefined will be returned.

crypto.getCiphers()#

Added in: v0.9.3


Returns: <string[]> An array with the names of the supported cipher
algorithms.


const {
  getCiphers,
} = await import('node:crypto');

console.log(getCiphers()); // ['aes-128-cbc', 'aes-128-ccm', ...]const {
  getCiphers,
} = require('node:crypto');

console.log(getCiphers()); // ['aes-128-cbc', 'aes-128-ccm', ...]copy

crypto.getCurves()#

Added in: v2.3.0


Returns: <string[]> An array with the names of the supported elliptic curves.


const {
  getCurves,
} = await import('node:crypto');

console.log(getCurves()); // ['Oakley-EC2N-3', 'Oakley-EC2N-4', ...]const {
  getCurves,
} = require('node:crypto');

console.log(getCurves()); // ['Oakley-EC2N-3', 'Oakley-EC2N-4', ...]copy

crypto.getDiffieHellman(groupName)#

Added in: v0.7.5


groupName <string>
Returns: <DiffieHellmanGroup>

Creates a predefined DiffieHellmanGroup key exchange object. The
supported groups are listed in the documentation for DiffieHellmanGroup.
The returned object mimics the interface of objects created by
crypto.createDiffieHellman(), but will not allow changing
the keys (with diffieHellman.setPublicKey(), for example). The
advantage of using this method is that the parties do not have to
generate nor exchange a group modulus beforehand, saving both processor
and communication time.
Example (obtaining a shared secret):

const {
  getDiffieHellman,
} = await import('node:crypto');
const alice = getDiffieHellman('modp14');
const bob = getDiffieHellman('modp14');

alice.generateKeys();
bob.generateKeys();

const aliceSecret = alice.computeSecret(bob.getPublicKey(), null, 'hex');
const bobSecret = bob.computeSecret(alice.getPublicKey(), null, 'hex');

/* aliceSecret and bobSecret should be the same */
console.log(aliceSecret === bobSecret);const {
  getDiffieHellman,
} = require('node:crypto');

const alice = getDiffieHellman('modp14');
const bob = getDiffieHellman('modp14');

alice.generateKeys();
bob.generateKeys();

const aliceSecret = alice.computeSecret(bob.getPublicKey(), null, 'hex');
const bobSecret = bob.computeSecret(alice.getPublicKey(), null, 'hex');

/* aliceSecret and bobSecret should be the same */
console.log(aliceSecret === bobSecret);copy

crypto.getFips()#

Added in: v10.0.0


Returns: <number> 1 if and only if a FIPS compliant crypto provider is
currently in use, 0 otherwise. A future semver-major release may change
the return type of this API to a <boolean>.


crypto.getHashes()#

Added in: v0.9.3


Returns: <string[]> An array of the names of the supported hash algorithms,
such as 'RSA-SHA256'. Hash algorithms are also called "digest" algorithms.


const {
  getHashes,
} = await import('node:crypto');

console.log(getHashes()); // ['DSA', 'DSA-SHA', 'DSA-SHA1', ...]const {
  getHashes,
} = require('node:crypto');

console.log(getHashes()); // ['DSA', 'DSA-SHA', 'DSA-SHA1', ...]copy

crypto.getRandomValues(typedArray)#

Added in: v17.4.0


typedArray <Buffer> | <TypedArray> | <DataView> | <ArrayBuffer>
Returns: <Buffer> | <TypedArray> | <DataView> | <ArrayBuffer> Returns typedArray.

A convenient alias for crypto.webcrypto.getRandomValues(). This
implementation is not compliant with the Web Crypto spec, to write
web-compatible code use crypto.webcrypto.getRandomValues() instead.

crypto.hash(algorithm, data[, outputEncoding])#

Added in: v21.7.0, v20.12.0

Stability: 1.2 - Release candidate

algorithm <string> | <undefined>
data <string> | <Buffer> | <TypedArray> | <DataView> When data is a
string, it will be encoded as UTF-8 before being hashed. If a different
input encoding is desired for a string input, user could encode the string
into a TypedArray using either TextEncoder or Buffer.from() and passing
the encoded TypedArray into this API instead.
outputEncoding <string> | <undefined>  Encoding used to encode the
returned digest. Default: 'hex'.
Returns: <string> | <Buffer>

A utility for creating one-shot hash digests of data. It can be faster than
the object-based crypto.createHash() when hashing a smaller amount of data
(<= 5MB) that's readily available. If the data can be big or if it is streamed,
it's still recommended to use crypto.createHash() instead.
The algorithm is dependent on the available algorithms supported by the
version of OpenSSL on the platform. Examples are 'sha256', 'sha512', etc.
On recent releases of OpenSSL, openssl list -digest-algorithms will
display the available digest algorithms.
Example:

const crypto = require('node:crypto');
const { Buffer } = require('node:buffer');

// Hashing a string and return the result as a hex-encoded string.
const string = 'Node.js';
// 10b3493287f831e81a438811a1ffba01f8cec4b7
console.log(crypto.hash('sha1', string));

// Encode a base64-encoded string into a Buffer, hash it and return
// the result as a buffer.
const base64 = 'Tm9kZS5qcw==';
// <Buffer 10 b3 49 32 87 f8 31 e8 1a 43 88 11 a1 ff ba 01 f8 ce c4 b7>
console.log(crypto.hash('sha1', Buffer.from(base64, 'base64'), 'buffer'));import crypto from 'node:crypto';
import { Buffer } from 'node:buffer';

// Hashing a string and return the result as a hex-encoded string.
const string = 'Node.js';
// 10b3493287f831e81a438811a1ffba01f8cec4b7
console.log(crypto.hash('sha1', string));

// Encode a base64-encoded string into a Buffer, hash it and return
// the result as a buffer.
const base64 = 'Tm9kZS5qcw==';
// <Buffer 10 b3 49 32 87 f8 31 e8 1a 43 88 11 a1 ff ba 01 f8 ce c4 b7>
console.log(crypto.hash('sha1', Buffer.from(base64, 'base64'), 'buffer'));copy

crypto.hkdf(digest, ikm, salt, info, keylen, callback)#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v18.8.0, v16.18.0
The input keying material can now be zero-length.
v15.0.0
Added in: v15.0.0




digest <string> The digest algorithm to use.
ikm <string> | <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView> | <KeyObject> The input
keying material. Must be provided but can be zero-length.
salt <string> | <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView> The salt value. Must
be provided but can be zero-length.
info <string> | <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView> Additional info value.
Must be provided but can be zero-length, and cannot be more than 1024 bytes.
keylen <number> The length of the key to generate. Must be greater than 0.
The maximum allowable value is 255 times the number of bytes produced by
the selected digest function (e.g. sha512 generates 64-byte hashes, making
the maximum HKDF output 16320 bytes).
callback <Function>

err <Error>
derivedKey <ArrayBuffer>



HKDF is a simple key derivation function defined in RFC 5869. The given ikm,
salt and info are used with the digest to derive a key of keylen bytes.
The supplied callback function is called with two arguments: err and
derivedKey. If an errors occurs while deriving the key, err will be set;
otherwise err will be null. The successfully generated derivedKey will
be passed to the callback as an <ArrayBuffer>. An error will be thrown if any
of the input arguments specify invalid values or types.

import { Buffer } from 'node:buffer';
const {
  hkdf,
} = await import('node:crypto');

hkdf('sha512', 'key', 'salt', 'info', 64, (err, derivedKey) => {
  if (err) throw err;
  console.log(Buffer.from(derivedKey).toString('hex'));  // '24156e2...5391653'
});const {
  hkdf,
} = require('node:crypto');
const { Buffer } = require('node:buffer');

hkdf('sha512', 'key', 'salt', 'info', 64, (err, derivedKey) => {
  if (err) throw err;
  console.log(Buffer.from(derivedKey).toString('hex'));  // '24156e2...5391653'
});copy

crypto.hkdfSync(digest, ikm, salt, info, keylen)#

History

VersionChanges
v18.8.0, v16.18.0
The input keying material can now be zero-length.
v15.0.0
Added in: v15.0.0




digest <string> The digest algorithm to use.
ikm <string> | <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView> | <KeyObject> The input
keying material. Must be provided but can be zero-length.
salt <string> | <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView> The salt value. Must
be provided but can be zero-length.
info <string> | <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView> Additional info value.
Must be provided but can be zero-length, and cannot be more than 1024 bytes.
keylen <number> The length of the key to generate. Must be greater than 0.
The maximum allowable value is 255 times the number of bytes produced by
the selected digest function (e.g. sha512 generates 64-byte hashes, making
the maximum HKDF output 16320 bytes).
Returns: <ArrayBuffer>

Provides a synchronous HKDF key derivation function as defined in RFC 5869. The
given ikm, salt and info are used with the digest to derive a key of
keylen bytes.
The successfully generated derivedKey will be returned as an <ArrayBuffer>.
An error will be thrown if any of the input arguments specify invalid values or
types, or if the derived key cannot be generated.

import { Buffer } from 'node:buffer';
const {
  hkdfSync,
} = await import('node:crypto');

const derivedKey = hkdfSync('sha512', 'key', 'salt', 'info', 64);
console.log(Buffer.from(derivedKey).toString('hex'));  // '24156e2...5391653'const {
  hkdfSync,
} = require('node:crypto');
const { Buffer } = require('node:buffer');

const derivedKey = hkdfSync('sha512', 'key', 'salt', 'info', 64);
console.log(Buffer.from(derivedKey).toString('hex'));  // '24156e2...5391653'copy

crypto.pbkdf2(password, salt, iterations, keylen, digest, callback)#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v15.0.0
The password and salt arguments can also be ArrayBuffer instances.
v14.0.0
The iterations parameter is now restricted to positive values. Earlier releases treated other values as one.
v8.0.0
The digest parameter is always required now.
v6.0.0
Calling this function without passing the digest parameter is deprecated now and will emit a warning.
v6.0.0
The default encoding for password if it is a string changed from binary to utf8.
v0.5.5
Added in: v0.5.5




password <string> | <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView>
salt <string> | <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView>
iterations <number>
keylen <number>
digest <string>
callback <Function>

err <Error>
derivedKey <Buffer>



Provides an asynchronous Password-Based Key Derivation Function 2 (PBKDF2)
implementation. A selected HMAC digest algorithm specified by digest is
applied to derive a key of the requested byte length (keylen) from the
password, salt and iterations.
The supplied callback function is called with two arguments: err and
derivedKey. If an error occurs while deriving the key, err will be set;
otherwise err will be null. By default, the successfully generated
derivedKey will be passed to the callback as a Buffer. An error will be
thrown if any of the input arguments specify invalid values or types.
The iterations argument must be a number set as high as possible. The
higher the number of iterations, the more secure the derived key will be,
but will take a longer amount of time to complete.
The salt should be as unique as possible. It is recommended that a salt is
random and at least 16 bytes long. See NIST SP 800-132 for details.
When passing strings for password or salt, please consider
caveats when using strings as inputs to cryptographic APIs.

const {
  pbkdf2,
} = await import('node:crypto');

pbkdf2('secret', 'salt', 100000, 64, 'sha512', (err, derivedKey) => {
  if (err) throw err;
  console.log(derivedKey.toString('hex'));  // '3745e48...08d59ae'
});const {
  pbkdf2,
} = require('node:crypto');

pbkdf2('secret', 'salt', 100000, 64, 'sha512', (err, derivedKey) => {
  if (err) throw err;
  console.log(derivedKey.toString('hex'));  // '3745e48...08d59ae'
});copy
An array of supported digest functions can be retrieved using
crypto.getHashes().
This API uses libuv's threadpool, which can have surprising and
negative performance implications for some applications; see the
UV_THREADPOOL_SIZE documentation for more information.

crypto.pbkdf2Sync(password, salt, iterations, keylen, digest)#

History

VersionChanges
v14.0.0
The iterations parameter is now restricted to positive values. Earlier releases treated other values as one.
v6.0.0
Calling this function without passing the digest parameter is deprecated now and will emit a warning.
v6.0.0
The default encoding for password if it is a string changed from binary to utf8.
v0.9.3
Added in: v0.9.3




password <string> | <Buffer> | <TypedArray> | <DataView>
salt <string> | <Buffer> | <TypedArray> | <DataView>
iterations <number>
keylen <number>
digest <string>
Returns: <Buffer>

Provides a synchronous Password-Based Key Derivation Function 2 (PBKDF2)
implementation. A selected HMAC digest algorithm specified by digest is
applied to derive a key of the requested byte length (keylen) from the
password, salt and iterations.
If an error occurs an Error will be thrown, otherwise the derived key will be
returned as a Buffer.
The iterations argument must be a number set as high as possible. The
higher the number of iterations, the more secure the derived key will be,
but will take a longer amount of time to complete.
The salt should be as unique as possible. It is recommended that a salt is
random and at least 16 bytes long. See NIST SP 800-132 for details.
When passing strings for password or salt, please consider
caveats when using strings as inputs to cryptographic APIs.

const {
  pbkdf2Sync,
} = await import('node:crypto');

const key = pbkdf2Sync('secret', 'salt', 100000, 64, 'sha512');
console.log(key.toString('hex'));  // '3745e48...08d59ae'const {
  pbkdf2Sync,
} = require('node:crypto');

const key = pbkdf2Sync('secret', 'salt', 100000, 64, 'sha512');
console.log(key.toString('hex'));  // '3745e48...08d59ae'copy
An array of supported digest functions can be retrieved using
crypto.getHashes().

crypto.privateDecrypt(privateKey, buffer)#

History

VersionChanges
v21.6.2, v20.11.1, v18.19.1
The RSA_PKCS1_PADDING padding was disabled unless the OpenSSL build supports implicit rejection.
v15.0.0
Added string, ArrayBuffer, and CryptoKey as allowable key types. The oaepLabel can be an ArrayBuffer. The buffer can be a string or ArrayBuffer. All types that accept buffers are limited to a maximum of 2 ** 31 - 1 bytes.
v12.11.0
The oaepLabel option was added.
v12.9.0
The oaepHash option was added.
v11.6.0
This function now supports key objects.
v0.11.14
Added in: v0.11.14





privateKey <Object> | <string> | <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView> | <KeyObject> | <CryptoKey>

oaepHash <string> The hash function to use for OAEP padding and MGF1.
Default: 'sha1'
oaepLabel <string> | <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView> The label to
use for OAEP padding. If not specified, no label is used.
padding <crypto.constants> An optional padding value defined in
crypto.constants, which may be: crypto.constants.RSA_NO_PADDING,
crypto.constants.RSA_PKCS1_PADDING, or
crypto.constants.RSA_PKCS1_OAEP_PADDING.


buffer <string> | <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView>
Returns: <Buffer> A new Buffer with the decrypted content.


Decrypts buffer with privateKey. buffer was previously encrypted using
the corresponding public key, for example using crypto.publicEncrypt().
If privateKey is not a KeyObject, this function behaves as if
privateKey had been passed to crypto.createPrivateKey(). If it is an
object, the padding property can be passed. Otherwise, this function uses
RSA_PKCS1_OAEP_PADDING.
Using crypto.constants.RSA_PKCS1_PADDING in crypto.privateDecrypt()
requires OpenSSL to support implicit rejection (rsa_pkcs1_implicit_rejection).
If the version of OpenSSL used by Node.js does not support this feature,
attempting to use RSA_PKCS1_PADDING will fail.

crypto.privateEncrypt(privateKey, buffer)#

History

VersionChanges
v15.0.0
Added string, ArrayBuffer, and CryptoKey as allowable key types. The passphrase can be an ArrayBuffer. The buffer can be a string or ArrayBuffer. All types that accept buffers are limited to a maximum of 2 ** 31 - 1 bytes.
v11.6.0
This function now supports key objects.
v1.1.0
Added in: v1.1.0





privateKey <Object> | <string> | <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView> | <KeyObject> | <CryptoKey>

key <string> | <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView> | <KeyObject> | <CryptoKey>
A PEM encoded private key.
passphrase <string> | <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView> An optional
passphrase for the private key.
padding <crypto.constants> An optional padding value defined in
crypto.constants, which may be: crypto.constants.RSA_NO_PADDING or
crypto.constants.RSA_PKCS1_PADDING.
encoding <string> The string encoding to use when buffer, key,
or passphrase are strings.


buffer <string> | <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView>
Returns: <Buffer> A new Buffer with the encrypted content.


Encrypts buffer with privateKey. The returned data can be decrypted using
the corresponding public key, for example using crypto.publicDecrypt().
If privateKey is not a KeyObject, this function behaves as if
privateKey had been passed to crypto.createPrivateKey(). If it is an
object, the padding property can be passed. Otherwise, this function uses
RSA_PKCS1_PADDING.

crypto.publicDecrypt(key, buffer)#

History

VersionChanges
v15.0.0
Added string, ArrayBuffer, and CryptoKey as allowable key types. The passphrase can be an ArrayBuffer. The buffer can be a string or ArrayBuffer. All types that accept buffers are limited to a maximum of 2 ** 31 - 1 bytes.
v11.6.0
This function now supports key objects.
v1.1.0
Added in: v1.1.0





key <Object> | <string> | <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView> | <KeyObject> | <CryptoKey>

passphrase <string> | <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView> An optional
passphrase for the private key.
padding <crypto.constants> An optional padding value defined in
crypto.constants, which may be: crypto.constants.RSA_NO_PADDING or
crypto.constants.RSA_PKCS1_PADDING.
encoding <string> The string encoding to use when buffer, key,
or passphrase are strings.


buffer <string> | <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView>
Returns: <Buffer> A new Buffer with the decrypted content.


Decrypts buffer with key.buffer was previously encrypted using
the corresponding private key, for example using crypto.privateEncrypt().
If key is not a KeyObject, this function behaves as if
key had been passed to crypto.createPublicKey(). If it is an
object, the padding property can be passed. Otherwise, this function uses
RSA_PKCS1_PADDING.
Because RSA public keys can be derived from private keys, a private key may
be passed instead of a public key.

crypto.publicEncrypt(key, buffer)#

History

VersionChanges
v15.0.0
Added string, ArrayBuffer, and CryptoKey as allowable key types. The oaepLabel and passphrase can be ArrayBuffers. The buffer can be a string or ArrayBuffer. All types that accept buffers are limited to a maximum of 2 ** 31 - 1 bytes.
v12.11.0
The oaepLabel option was added.
v12.9.0
The oaepHash option was added.
v11.6.0
This function now supports key objects.
v0.11.14
Added in: v0.11.14





key <Object> | <string> | <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView> | <KeyObject> | <CryptoKey>

key <string> | <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView> | <KeyObject> | <CryptoKey>
A PEM encoded public or private key, <KeyObject>, or <CryptoKey>.
oaepHash <string> The hash function to use for OAEP padding and MGF1.
Default: 'sha1'
oaepLabel <string> | <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView> The label to
use for OAEP padding. If not specified, no label is used.
passphrase <string> | <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView> An optional
passphrase for the private key.
padding <crypto.constants> An optional padding value defined in
crypto.constants, which may be: crypto.constants.RSA_NO_PADDING,
crypto.constants.RSA_PKCS1_PADDING, or
crypto.constants.RSA_PKCS1_OAEP_PADDING.
encoding <string> The string encoding to use when buffer, key,
oaepLabel, or passphrase are strings.


buffer <string> | <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView>
Returns: <Buffer> A new Buffer with the encrypted content.


Encrypts the content of buffer with key and returns a new
Buffer with encrypted content. The returned data can be decrypted using
the corresponding private key, for example using crypto.privateDecrypt().
If key is not a KeyObject, this function behaves as if
key had been passed to crypto.createPublicKey(). If it is an
object, the padding property can be passed. Otherwise, this function uses
RSA_PKCS1_OAEP_PADDING.
Because RSA public keys can be derived from private keys, a private key may
be passed instead of a public key.

crypto.randomBytes(size[, callback])#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v9.0.0
Passing null as the callback argument now throws ERR_INVALID_CALLBACK.
v0.5.8
Added in: v0.5.8




size <number> The number of bytes to generate.  The size must
not be larger than 2**31 - 1.
callback <Function>

err <Error>
buf <Buffer>


Returns: <Buffer> if the callback function is not provided.

Generates cryptographically strong pseudorandom data. The size argument
is a number indicating the number of bytes to generate.
If a callback function is provided, the bytes are generated asynchronously
and the callback function is invoked with two arguments: err and buf.
If an error occurs, err will be an Error object; otherwise it is null. The
buf argument is a Buffer containing the generated bytes.

// Asynchronous
const {
  randomBytes,
} = await import('node:crypto');

randomBytes(256, (err, buf) => {
  if (err) throw err;
  console.log(`${buf.length} bytes of random data: ${buf.toString('hex')}`);
});// Asynchronous
const {
  randomBytes,
} = require('node:crypto');

randomBytes(256, (err, buf) => {
  if (err) throw err;
  console.log(`${buf.length} bytes of random data: ${buf.toString('hex')}`);
});copy
If the callback function is not provided, the random bytes are generated
synchronously and returned as a Buffer. An error will be thrown if
there is a problem generating the bytes.

// Synchronous
const {
  randomBytes,
} = await import('node:crypto');

const buf = randomBytes(256);
console.log(
  `${buf.length} bytes of random data: ${buf.toString('hex')}`);// Synchronous
const {
  randomBytes,
} = require('node:crypto');

const buf = randomBytes(256);
console.log(
  `${buf.length} bytes of random data: ${buf.toString('hex')}`);copy
The crypto.randomBytes() method will not complete until there is
sufficient entropy available.
This should normally never take longer than a few milliseconds. The only time
when generating the random bytes may conceivably block for a longer period of
time is right after boot, when the whole system is still low on entropy.
This API uses libuv's threadpool, which can have surprising and
negative performance implications for some applications; see the
UV_THREADPOOL_SIZE documentation for more information.
The asynchronous version of crypto.randomBytes() is carried out in a single
threadpool request. To minimize threadpool task length variation, partition
large randomBytes requests when doing so as part of fulfilling a client
request.

crypto.randomFill(buffer[, offset][, size], callback)#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v9.0.0
The buffer argument may be any TypedArray or DataView.
v7.10.0, v6.13.0
Added in: v7.10.0, v6.13.0




buffer <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView> Must be supplied. The
size of the provided buffer must not be larger than 2**31 - 1.
offset <number> Default: 0
size <number> Default: buffer.length - offset. The size must
not be larger than 2**31 - 1.
callback <Function> function(err, buf) {}.

This function is similar to crypto.randomBytes() but requires the first
argument to be a Buffer that will be filled. It also
requires that a callback is passed in.
If the callback function is not provided, an error will be thrown.

import { Buffer } from 'node:buffer';
const { randomFill } = await import('node:crypto');

const buf = Buffer.alloc(10);
randomFill(buf, (err, buf) => {
  if (err) throw err;
  console.log(buf.toString('hex'));
});

randomFill(buf, 5, (err, buf) => {
  if (err) throw err;
  console.log(buf.toString('hex'));
});

// The above is equivalent to the following:
randomFill(buf, 5, 5, (err, buf) => {
  if (err) throw err;
  console.log(buf.toString('hex'));
});const { randomFill } = require('node:crypto');
const { Buffer } = require('node:buffer');

const buf = Buffer.alloc(10);
randomFill(buf, (err, buf) => {
  if (err) throw err;
  console.log(buf.toString('hex'));
});

randomFill(buf, 5, (err, buf) => {
  if (err) throw err;
  console.log(buf.toString('hex'));
});

// The above is equivalent to the following:
randomFill(buf, 5, 5, (err, buf) => {
  if (err) throw err;
  console.log(buf.toString('hex'));
});copy
Any ArrayBuffer, TypedArray, or DataView instance may be passed as
buffer.
While this includes instances of Float32Array and Float64Array, this
function should not be used to generate random floating-point numbers. The
result may contain +Infinity, -Infinity, and NaN, and even if the array
contains finite numbers only, they are not drawn from a uniform random
distribution and have no meaningful lower or upper bounds.

import { Buffer } from 'node:buffer';
const { randomFill } = await import('node:crypto');

const a = new Uint32Array(10);
randomFill(a, (err, buf) => {
  if (err) throw err;
  console.log(Buffer.from(buf.buffer, buf.byteOffset, buf.byteLength)
    .toString('hex'));
});

const b = new DataView(new ArrayBuffer(10));
randomFill(b, (err, buf) => {
  if (err) throw err;
  console.log(Buffer.from(buf.buffer, buf.byteOffset, buf.byteLength)
    .toString('hex'));
});

const c = new ArrayBuffer(10);
randomFill(c, (err, buf) => {
  if (err) throw err;
  console.log(Buffer.from(buf).toString('hex'));
});const { randomFill } = require('node:crypto');
const { Buffer } = require('node:buffer');

const a = new Uint32Array(10);
randomFill(a, (err, buf) => {
  if (err) throw err;
  console.log(Buffer.from(buf.buffer, buf.byteOffset, buf.byteLength)
    .toString('hex'));
});

const b = new DataView(new ArrayBuffer(10));
randomFill(b, (err, buf) => {
  if (err) throw err;
  console.log(Buffer.from(buf.buffer, buf.byteOffset, buf.byteLength)
    .toString('hex'));
});

const c = new ArrayBuffer(10);
randomFill(c, (err, buf) => {
  if (err) throw err;
  console.log(Buffer.from(buf).toString('hex'));
});copy
This API uses libuv's threadpool, which can have surprising and
negative performance implications for some applications; see the
UV_THREADPOOL_SIZE documentation for more information.
The asynchronous version of crypto.randomFill() is carried out in a single
threadpool request. To minimize threadpool task length variation, partition
large randomFill requests when doing so as part of fulfilling a client
request.

crypto.randomFillSync(buffer[, offset][, size])#

History

VersionChanges
v9.0.0
The buffer argument may be any TypedArray or DataView.
v7.10.0, v6.13.0
Added in: v7.10.0, v6.13.0




buffer <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView> Must be supplied. The
size of the provided buffer must not be larger than 2**31 - 1.
offset <number> Default: 0
size <number> Default: buffer.length - offset. The size must
not be larger than 2**31 - 1.
Returns: <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView> The object passed as
buffer argument.

Synchronous version of crypto.randomFill().

import { Buffer } from 'node:buffer';
const { randomFillSync } = await import('node:crypto');

const buf = Buffer.alloc(10);
console.log(randomFillSync(buf).toString('hex'));

randomFillSync(buf, 5);
console.log(buf.toString('hex'));

// The above is equivalent to the following:
randomFillSync(buf, 5, 5);
console.log(buf.toString('hex'));const { randomFillSync } = require('node:crypto');
const { Buffer } = require('node:buffer');

const buf = Buffer.alloc(10);
console.log(randomFillSync(buf).toString('hex'));

randomFillSync(buf, 5);
console.log(buf.toString('hex'));

// The above is equivalent to the following:
randomFillSync(buf, 5, 5);
console.log(buf.toString('hex'));copy
Any ArrayBuffer, TypedArray or DataView instance may be passed as
buffer.

import { Buffer } from 'node:buffer';
const { randomFillSync } = await import('node:crypto');

const a = new Uint32Array(10);
console.log(Buffer.from(randomFillSync(a).buffer,
                        a.byteOffset, a.byteLength).toString('hex'));

const b = new DataView(new ArrayBuffer(10));
console.log(Buffer.from(randomFillSync(b).buffer,
                        b.byteOffset, b.byteLength).toString('hex'));

const c = new ArrayBuffer(10);
console.log(Buffer.from(randomFillSync(c)).toString('hex'));const { randomFillSync } = require('node:crypto');
const { Buffer } = require('node:buffer');

const a = new Uint32Array(10);
console.log(Buffer.from(randomFillSync(a).buffer,
                        a.byteOffset, a.byteLength).toString('hex'));

const b = new DataView(new ArrayBuffer(10));
console.log(Buffer.from(randomFillSync(b).buffer,
                        b.byteOffset, b.byteLength).toString('hex'));

const c = new ArrayBuffer(10);
console.log(Buffer.from(randomFillSync(c)).toString('hex'));copy

crypto.randomInt([min, ]max[, callback])#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v14.10.0, v12.19.0
Added in: v14.10.0, v12.19.0




min <integer> Start of random range (inclusive). Default: 0.
max <integer> End of random range (exclusive).
callback <Function> function(err, n) {}.

Return a random integer n such that min <= n < max.  This
implementation avoids modulo bias.
The range (max - min) must be less than 248. min and max must
be safe integers.
If the callback function is not provided, the random integer is
generated synchronously.

// Asynchronous
const {
  randomInt,
} = await import('node:crypto');

randomInt(3, (err, n) => {
  if (err) throw err;
  console.log(`Random number chosen from (0, 1, 2): ${n}`);
});// Asynchronous
const {
  randomInt,
} = require('node:crypto');

randomInt(3, (err, n) => {
  if (err) throw err;
  console.log(`Random number chosen from (0, 1, 2): ${n}`);
});copy

// Synchronous
const {
  randomInt,
} = await import('node:crypto');

const n = randomInt(3);
console.log(`Random number chosen from (0, 1, 2): ${n}`);// Synchronous
const {
  randomInt,
} = require('node:crypto');

const n = randomInt(3);
console.log(`Random number chosen from (0, 1, 2): ${n}`);copy

// With `min` argument
const {
  randomInt,
} = await import('node:crypto');

const n = randomInt(1, 7);
console.log(`The dice rolled: ${n}`);// With `min` argument
const {
  randomInt,
} = require('node:crypto');

const n = randomInt(1, 7);
console.log(`The dice rolled: ${n}`);copy

crypto.randomUUID([options])#

Added in: v15.6.0, v14.17.0


options <Object>

disableEntropyCache <boolean> By default, to improve performance,
Node.js generates and caches enough
random data to generate up to 128 random UUIDs. To generate a UUID
without using the cache, set disableEntropyCache to true.
Default: false.


Returns: <string>

Generates a random RFC 4122 version 4 UUID. The UUID is generated using a
cryptographic pseudorandom number generator.

crypto.scrypt(password, salt, keylen[, options], callback)#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v15.0.0
The password and salt arguments can also be ArrayBuffer instances.
v12.8.0, v10.17.0
The maxmem value can now be any safe integer.
v10.9.0
The cost, blockSize and parallelization option names have been added.
v10.5.0
Added in: v10.5.0




password <string> | <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView>
salt <string> | <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView>
keylen <number>
options <Object>

cost <number> CPU/memory cost parameter. Must be a power of two greater
than one. Default: 16384.
blockSize <number> Block size parameter. Default: 8.
parallelization <number> Parallelization parameter. Default: 1.
N <number> Alias for cost. Only one of both may be specified.
r <number> Alias for blockSize. Only one of both may be specified.
p <number> Alias for parallelization. Only one of both may be specified.
maxmem <number> Memory upper bound. It is an error when (approximately)
128 * N * r > maxmem. Default: 32 * 1024 * 1024.


callback <Function>

err <Error>
derivedKey <Buffer>



Provides an asynchronous scrypt implementation. Scrypt is a password-based
key derivation function that is designed to be expensive computationally and
memory-wise in order to make brute-force attacks unrewarding.
The salt should be as unique as possible. It is recommended that a salt is
random and at least 16 bytes long. See NIST SP 800-132 for details.
When passing strings for password or salt, please consider
caveats when using strings as inputs to cryptographic APIs.
The callback function is called with two arguments: err and derivedKey.
err is an exception object when key derivation fails, otherwise err is
null. derivedKey is passed to the callback as a Buffer.
An exception is thrown when any of the input arguments specify invalid values
or types.

const {
  scrypt,
} = await import('node:crypto');

// Using the factory defaults.
scrypt('password', 'salt', 64, (err, derivedKey) => {
  if (err) throw err;
  console.log(derivedKey.toString('hex'));  // '3745e48...08d59ae'
});
// Using a custom N parameter. Must be a power of two.
scrypt('password', 'salt', 64, { N: 1024 }, (err, derivedKey) => {
  if (err) throw err;
  console.log(derivedKey.toString('hex'));  // '3745e48...aa39b34'
});const {
  scrypt,
} = require('node:crypto');

// Using the factory defaults.
scrypt('password', 'salt', 64, (err, derivedKey) => {
  if (err) throw err;
  console.log(derivedKey.toString('hex'));  // '3745e48...08d59ae'
});
// Using a custom N parameter. Must be a power of two.
scrypt('password', 'salt', 64, { N: 1024 }, (err, derivedKey) => {
  if (err) throw err;
  console.log(derivedKey.toString('hex'));  // '3745e48...aa39b34'
});copy

crypto.scryptSync(password, salt, keylen[, options])#

History

VersionChanges
v12.8.0, v10.17.0
The maxmem value can now be any safe integer.
v10.9.0
The cost, blockSize and parallelization option names have been added.
v10.5.0
Added in: v10.5.0




password <string> | <Buffer> | <TypedArray> | <DataView>
salt <string> | <Buffer> | <TypedArray> | <DataView>
keylen <number>
options <Object>

cost <number> CPU/memory cost parameter. Must be a power of two greater
than one. Default: 16384.
blockSize <number> Block size parameter. Default: 8.
parallelization <number> Parallelization parameter. Default: 1.
N <number> Alias for cost. Only one of both may be specified.
r <number> Alias for blockSize. Only one of both may be specified.
p <number> Alias for parallelization. Only one of both may be specified.
maxmem <number> Memory upper bound. It is an error when (approximately)
128 * N * r > maxmem. Default: 32 * 1024 * 1024.


Returns: <Buffer>

Provides a synchronous scrypt implementation. Scrypt is a password-based
key derivation function that is designed to be expensive computationally and
memory-wise in order to make brute-force attacks unrewarding.
The salt should be as unique as possible. It is recommended that a salt is
random and at least 16 bytes long. See NIST SP 800-132 for details.
When passing strings for password or salt, please consider
caveats when using strings as inputs to cryptographic APIs.
An exception is thrown when key derivation fails, otherwise the derived key is
returned as a Buffer.
An exception is thrown when any of the input arguments specify invalid values
or types.

const {
  scryptSync,
} = await import('node:crypto');
// Using the factory defaults.

const key1 = scryptSync('password', 'salt', 64);
console.log(key1.toString('hex'));  // '3745e48...08d59ae'
// Using a custom N parameter. Must be a power of two.
const key2 = scryptSync('password', 'salt', 64, { N: 1024 });
console.log(key2.toString('hex'));  // '3745e48...aa39b34'const {
  scryptSync,
} = require('node:crypto');
// Using the factory defaults.

const key1 = scryptSync('password', 'salt', 64);
console.log(key1.toString('hex'));  // '3745e48...08d59ae'
// Using a custom N parameter. Must be a power of two.
const key2 = scryptSync('password', 'salt', 64, { N: 1024 });
console.log(key2.toString('hex'));  // '3745e48...aa39b34'copy

crypto.secureHeapUsed()#

Added in: v15.6.0


Returns: <Object>

total <number> The total allocated secure heap size as specified
using the --secure-heap=n command-line flag.
min <number> The minimum allocation from the secure heap as
specified using the --secure-heap-min command-line flag.
used <number> The total number of bytes currently allocated from
the secure heap.
utilization <number> The calculated ratio of used to total
allocated bytes.




crypto.setEngine(engine[, flags])#

History

VersionChanges
v22.4.0, v20.16.0
Custom engine support in OpenSSL 3 is deprecated.
v0.11.11
Added in: v0.11.11




engine <string>
flags <crypto.constants> Default: crypto.constants.ENGINE_METHOD_ALL

Load and set the engine for some or all OpenSSL functions (selected by flags).
Support for custom engines in OpenSSL is deprecated from OpenSSL 3.
engine could be either an id or a path to the engine's shared library.
The optional flags argument uses ENGINE_METHOD_ALL by default. The flags
is a bit field taking one of or a mix of the following flags (defined in
crypto.constants):

crypto.constants.ENGINE_METHOD_RSA
crypto.constants.ENGINE_METHOD_DSA
crypto.constants.ENGINE_METHOD_DH
crypto.constants.ENGINE_METHOD_RAND
crypto.constants.ENGINE_METHOD_EC
crypto.constants.ENGINE_METHOD_CIPHERS
crypto.constants.ENGINE_METHOD_DIGESTS
crypto.constants.ENGINE_METHOD_PKEY_METHS
crypto.constants.ENGINE_METHOD_PKEY_ASN1_METHS
crypto.constants.ENGINE_METHOD_ALL
crypto.constants.ENGINE_METHOD_NONE


crypto.setFips(bool)#

Added in: v10.0.0


bool <boolean> true to enable FIPS mode.

Enables the FIPS compliant crypto provider in a FIPS-enabled Node.js build.
Throws an error if FIPS mode is not available.

crypto.sign(algorithm, data, key[, callback])#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v15.12.0
Optional callback argument added.
v13.2.0, v12.16.0
This function now supports IEEE-P1363 DSA and ECDSA signatures.
v12.0.0
Added in: v12.0.0





algorithm <string> | <null> | <undefined>
data <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView>
key <Object> | <string> | <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView> | <KeyObject> | <CryptoKey>
callback <Function>

err <Error>
signature <Buffer>


Returns: <Buffer> if the callback function is not provided.


Calculates and returns the signature for data using the given private key and
algorithm. If algorithm is null or undefined, then the algorithm is
dependent upon the key type (especially Ed25519 and Ed448).
If key is not a KeyObject, this function behaves as if key had been
passed to crypto.createPrivateKey(). If it is an object, the following
additional properties can be passed:


dsaEncoding <string> For DSA and ECDSA, this option specifies the
format of the generated signature. It can be one of the following:

'der' (default): DER-encoded ASN.1 signature structure encoding (r, s).
'ieee-p1363': Signature format r || s as proposed in IEEE-P1363.



padding <integer> Optional padding value for RSA, one of the following:

crypto.constants.RSA_PKCS1_PADDING (default)
crypto.constants.RSA_PKCS1_PSS_PADDING

RSA_PKCS1_PSS_PADDING will use MGF1 with the same hash function
used to sign the message as specified in section 3.1 of RFC 4055.


saltLength <integer> Salt length for when padding is
RSA_PKCS1_PSS_PADDING. The special value
crypto.constants.RSA_PSS_SALTLEN_DIGEST sets the salt length to the digest
size, crypto.constants.RSA_PSS_SALTLEN_MAX_SIGN (default) sets it to the
maximum permissible value.


If the callback function is provided this function uses libuv's threadpool.

crypto.subtle#

Added in: v17.4.0


Type: <SubtleCrypto>

A convenient alias for crypto.webcrypto.subtle.

crypto.timingSafeEqual(a, b)#

History

VersionChanges
v15.0.0
The a and b arguments can also be ArrayBuffer.
v6.6.0
Added in: v6.6.0




a <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView>
b <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView>
Returns: <boolean>

This function compares the underlying bytes that represent the given
ArrayBuffer, TypedArray, or DataView instances using a constant-time
algorithm.
This function does not leak timing information that
would allow an attacker to guess one of the values. This is suitable for
comparing HMAC digests or secret values like authentication cookies or
capability urls.
a and b must both be Buffers, TypedArrays, or DataViews, and they
must have the same byte length. An error is thrown if a and b have
different byte lengths.
If at least one of a and b is a TypedArray with more than one byte per
entry, such as Uint16Array, the result will be computed using the platform
byte order.
When both of the inputs are Float32Arrays or
Float64Arrays, this function might return unexpected results due to IEEE 754
encoding of floating-point numbers. In particular, neither x === y nor
Object.is(x, y) implies that the byte representations of two floating-point
numbers x and y are equal.
Use of crypto.timingSafeEqual does not guarantee that the surrounding code
is timing-safe. Care should be taken to ensure that the surrounding code does
not introduce timing vulnerabilities.

crypto.verify(algorithm, data, key, signature[, callback])#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v15.12.0
Optional callback argument added.
v15.0.0
The data, key, and signature arguments can also be ArrayBuffer.
v13.2.0, v12.16.0
This function now supports IEEE-P1363 DSA and ECDSA signatures.
v12.0.0
Added in: v12.0.0





algorithm <string> | <null> | <undefined>
data <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView>
key <Object> | <string> | <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView> | <KeyObject> | <CryptoKey>
signature <ArrayBuffer> | <Buffer> | <TypedArray> | <DataView>
callback <Function>

err <Error>
result <boolean>


Returns: <boolean> true or false depending on the validity of the
signature for the data and public key if the callback function is not
provided.


Verifies the given signature for data using the given key and algorithm. If
algorithm is null or undefined, then the algorithm is dependent upon the
key type (especially Ed25519 and Ed448).
If key is not a KeyObject, this function behaves as if key had been
passed to crypto.createPublicKey(). If it is an object, the following
additional properties can be passed:


dsaEncoding <string> For DSA and ECDSA, this option specifies the
format of the signature. It can be one of the following:

'der' (default): DER-encoded ASN.1 signature structure encoding (r, s).
'ieee-p1363': Signature format r || s as proposed in IEEE-P1363.



padding <integer> Optional padding value for RSA, one of the following:

crypto.constants.RSA_PKCS1_PADDING (default)
crypto.constants.RSA_PKCS1_PSS_PADDING

RSA_PKCS1_PSS_PADDING will use MGF1 with the same hash function
used to sign the message as specified in section 3.1 of RFC 4055.


saltLength <integer> Salt length for when padding is
RSA_PKCS1_PSS_PADDING. The special value
crypto.constants.RSA_PSS_SALTLEN_DIGEST sets the salt length to the digest
size, crypto.constants.RSA_PSS_SALTLEN_MAX_SIGN (default) sets it to the
maximum permissible value.


The signature argument is the previously calculated signature for the data.
Because public keys can be derived from private keys, a private key or a public
key may be passed for key.
If the callback function is provided this function uses libuv's threadpool.

crypto.webcrypto#

Added in: v15.0.0

Type: <Crypto> An implementation of the Web Crypto API standard.
See the Web Crypto API documentation for details.

Notes#

Using strings as inputs to cryptographic APIs#
For historical reasons, many cryptographic APIs provided by Node.js accept
strings as inputs where the underlying cryptographic algorithm works on byte
sequences. These instances include plaintexts, ciphertexts, symmetric keys,
initialization vectors, passphrases, salts, authentication tags,
and additional authenticated data.
When passing strings to cryptographic APIs, consider the following factors.


Not all byte sequences are valid UTF-8 strings. Therefore, when a byte
sequence of length n is derived from a string, its entropy is generally
lower than the entropy of a random or pseudorandom n byte sequence.
For example, no UTF-8 string will result in the byte sequence c0 af. Secret
keys should almost exclusively be random or pseudorandom byte sequences.


Similarly, when converting random or pseudorandom byte sequences to UTF-8
strings, subsequences that do not represent valid code points may be replaced
by the Unicode replacement character (U+FFFD). The byte representation of
the resulting Unicode string may, therefore, not be equal to the byte sequence
that the string was created from.
const original = [0xc0, 0xaf];
const bytesAsString = Buffer.from(original).toString('utf8');
const stringAsBytes = Buffer.from(bytesAsString, 'utf8');
console.log(stringAsBytes);
// Prints '<Buffer ef bf bd ef bf bd>'. copy
The outputs of ciphers, hash functions, signature algorithms, and key
derivation functions are pseudorandom byte sequences and should not be
used as Unicode strings.


When strings are obtained from user input, some Unicode characters can be
represented in multiple equivalent ways that result in different byte
sequences. For example, when passing a user passphrase to a key derivation
function, such as PBKDF2 or scrypt, the result of the key derivation function
depends on whether the string uses composed or decomposed characters. Node.js
does not normalize character representations. Developers should consider using
String.prototype.normalize() on user inputs before passing them to
cryptographic APIs.



Legacy streams API (prior to Node.js 0.10)#
The Crypto module was added to Node.js before there was the concept of a
unified Stream API, and before there were Buffer objects for handling
binary data. As such, many crypto classes have methods not
typically found on other Node.js classes that implement the streams
API (e.g. update(), final(), or digest()). Also, many methods accepted
and returned 'latin1' encoded strings by default rather than Buffers. This
default was changed after Node.js v0.8 to use Buffer objects by default
instead.

Support for weak or compromised algorithms#
The node:crypto module still supports some algorithms which are already
compromised and are not recommended for use. The API also allows
the use of ciphers and hashes with a small key size that are too weak for safe
use.
Users should take full responsibility for selecting the crypto
algorithm and key size according to their security requirements.
Based on the recommendations of NIST SP 800-131A:

MD5 and SHA-1 are no longer acceptable where collision resistance is
required such as digital signatures.
The key used with RSA, DSA, and DH algorithms is recommended to have
at least 2048 bits and that of the curve of ECDSA and ECDH at least
224 bits, to be safe to use for several years.
The DH groups of modp1, modp2 and modp5 have a key size
smaller than 2048 bits and are not recommended.

See the reference for other recommendations and details.
Some algorithms that have known weaknesses and are of little relevance in
practice are only available through the legacy provider, which is not
enabled by default.

CCM mode#
CCM is one of the supported AEAD algorithms. Applications which use this
mode must adhere to certain restrictions when using the cipher API:

The authentication tag length must be specified during cipher creation by
setting the authTagLength option and must be one of 4, 6, 8, 10, 12, 14 or
16 bytes.
The length of the initialization vector (nonce) N must be between 7 and 13
bytes (7 ≤ N ≤ 13).
The length of the plaintext is limited to 2 ** (8 * (15 - N)) bytes.
When decrypting, the authentication tag must be set via setAuthTag() before
calling update().
Otherwise, decryption will fail and final() will throw an error in
compliance with section 2.6 of RFC 3610.
Using stream methods such as write(data), end(data) or pipe() in CCM
mode might fail as CCM cannot handle more than one chunk of data per instance.
When passing additional authenticated data (AAD), the length of the actual
message in bytes must be passed to setAAD() via the plaintextLength
option.
Many crypto libraries include the authentication tag in the ciphertext,
which means that they produce ciphertexts of the length
plaintextLength + authTagLength. Node.js does not include the authentication
tag, so the ciphertext length is always plaintextLength.
This is not necessary if no AAD is used.
As CCM processes the whole message at once, update() must be called exactly
once.
Even though calling update() is sufficient to encrypt/decrypt the message,
applications must call final() to compute or verify the
authentication tag.


import { Buffer } from 'node:buffer';
const {
  createCipheriv,
  createDecipheriv,
  randomBytes,
} = await import('node:crypto');

const key = 'keykeykeykeykeykeykeykey';
const nonce = randomBytes(12);

const aad = Buffer.from('0123456789', 'hex');

const cipher = createCipheriv('aes-192-ccm', key, nonce, {
  authTagLength: 16,
});
const plaintext = 'Hello world';
cipher.setAAD(aad, {
  plaintextLength: Buffer.byteLength(plaintext),
});
const ciphertext = cipher.update(plaintext, 'utf8');
cipher.final();
const tag = cipher.getAuthTag();

// Now transmit { ciphertext, nonce, tag }.

const decipher = createDecipheriv('aes-192-ccm', key, nonce, {
  authTagLength: 16,
});
decipher.setAuthTag(tag);
decipher.setAAD(aad, {
  plaintextLength: ciphertext.length,
});
const receivedPlaintext = decipher.update(ciphertext, null, 'utf8');

try {
  decipher.final();
} catch (err) {
  throw new Error('Authentication failed!', { cause: err });
}

console.log(receivedPlaintext);const { Buffer } = require('node:buffer');
const {
  createCipheriv,
  createDecipheriv,
  randomBytes,
} = require('node:crypto');

const key = 'keykeykeykeykeykeykeykey';
const nonce = randomBytes(12);

const aad = Buffer.from('0123456789', 'hex');

const cipher = createCipheriv('aes-192-ccm', key, nonce, {
  authTagLength: 16,
});
const plaintext = 'Hello world';
cipher.setAAD(aad, {
  plaintextLength: Buffer.byteLength(plaintext),
});
const ciphertext = cipher.update(plaintext, 'utf8');
cipher.final();
const tag = cipher.getAuthTag();

// Now transmit { ciphertext, nonce, tag }.

const decipher = createDecipheriv('aes-192-ccm', key, nonce, {
  authTagLength: 16,
});
decipher.setAuthTag(tag);
decipher.setAAD(aad, {
  plaintextLength: ciphertext.length,
});
const receivedPlaintext = decipher.update(ciphertext, null, 'utf8');

try {
  decipher.final();
} catch (err) {
  throw new Error('Authentication failed!', { cause: err });
}

console.log(receivedPlaintext);copy

FIPS mode#
When using OpenSSL 3, Node.js supports FIPS 140-2 when used with an appropriate
OpenSSL 3 provider, such as the FIPS provider from OpenSSL 3 which can be
installed by following the instructions in OpenSSL's FIPS README file.
For FIPS support in Node.js you will need:

A correctly installed OpenSSL 3 FIPS provider.
An OpenSSL 3 FIPS module configuration file.
An OpenSSL 3 configuration file that references the FIPS module
configuration file.

Node.js will need to be configured with an OpenSSL configuration file that
points to the FIPS provider. An example configuration file looks like this:
nodejs_conf = nodejs_init

.include /<absolute path>/fipsmodule.cnf

[nodejs_init]
providers = provider_sect

[provider_sect]
default = default_sect
# The fips section name should match the section name inside the
# included fipsmodule.cnf.
fips = fips_sect

[default_sect]
activate = 1 copy
where fipsmodule.cnf is the FIPS module configuration file generated from the
FIPS provider installation step:
openssl fipsinstall copy
Set the OPENSSL_CONF environment variable to point to
your configuration file and OPENSSL_MODULES to the location of the FIPS
provider dynamic library. e.g.
export OPENSSL_CONF=/<path to configuration file>/nodejs.cnf
export OPENSSL_MODULES=/<path to openssl lib>/ossl-modules copy
FIPS mode can then be enabled in Node.js either by:

Starting Node.js with --enable-fips or --force-fips command line flags.
Programmatically calling crypto.setFips(true).

Optionally FIPS mode can be enabled in Node.js via the OpenSSL configuration
file. e.g.
nodejs_conf = nodejs_init

.include /<absolute path>/fipsmodule.cnf

[nodejs_init]
providers = provider_sect
alg_section = algorithm_sect

[provider_sect]
default = default_sect
# The fips section name should match the section name inside the
# included fipsmodule.cnf.
fips = fips_sect

[default_sect]
activate = 1

[algorithm_sect]
default_properties = fips=yes copy

Crypto constants#
The following constants exported by crypto.constants apply to various uses of
the node:crypto, node:tls, and node:https modules and are generally
specific to OpenSSL.

OpenSSL options#
See the list of SSL OP Flags for details.

  
    Constant
    Description
  
  
    SSL_OP_ALL
    Applies multiple bug workarounds within OpenSSL. See
    https://www.openssl.org/docs/man3.0/man3/SSL_CTX_set_options.html
    for detail.
  
  
    SSL_OP_ALLOW_NO_DHE_KEX
    Instructs OpenSSL to allow a non-[EC]DHE-based key exchange mode
    for TLS v1.3
  
  
    SSL_OP_ALLOW_UNSAFE_LEGACY_RENEGOTIATION
    Allows legacy insecure renegotiation between OpenSSL and unpatched
    clients or servers. See
    https://www.openssl.org/docs/man3.0/man3/SSL_CTX_set_options.html.
  
  
    SSL_OP_CIPHER_SERVER_PREFERENCE
    Attempts to use the server's preferences instead of the client's when
    selecting a cipher. Behavior depends on protocol version. See
    https://www.openssl.org/docs/man3.0/man3/SSL_CTX_set_options.html.
  
  
    SSL_OP_CISCO_ANYCONNECT
    Instructs OpenSSL to use Cisco's version identifier of DTLS_BAD_VER.
  
  
    SSL_OP_COOKIE_EXCHANGE
    Instructs OpenSSL to turn on cookie exchange.
  
  
    SSL_OP_CRYPTOPRO_TLSEXT_BUG
    Instructs OpenSSL to add server-hello extension from an early version
    of the cryptopro draft.
  
  
    SSL_OP_DONT_INSERT_EMPTY_FRAGMENTS
    Instructs OpenSSL to disable a SSL 3.0/TLS 1.0 vulnerability
    workaround added in OpenSSL 0.9.6d.
  
  
    SSL_OP_LEGACY_SERVER_CONNECT
    Allows initial connection to servers that do not support RI.
  
  
    SSL_OP_NO_COMPRESSION
    Instructs OpenSSL to disable support for SSL/TLS compression.
  
  
    SSL_OP_NO_ENCRYPT_THEN_MAC
    Instructs OpenSSL to disable encrypt-then-MAC.
  
  
    SSL_OP_NO_QUERY_MTU
    
  
  
    SSL_OP_NO_RENEGOTIATION
    Instructs OpenSSL to disable renegotiation.
  
  
    SSL_OP_NO_SESSION_RESUMPTION_ON_RENEGOTIATION
    Instructs OpenSSL to always start a new session when performing
    renegotiation.
  
  
    SSL_OP_NO_SSLv2
    Instructs OpenSSL to turn off SSL v2
  
  
    SSL_OP_NO_SSLv3
    Instructs OpenSSL to turn off SSL v3
  
  
    SSL_OP_NO_TICKET
    Instructs OpenSSL to disable use of RFC4507bis tickets.
  
  
    SSL_OP_NO_TLSv1
    Instructs OpenSSL to turn off TLS v1
  
  
    SSL_OP_NO_TLSv1_1
    Instructs OpenSSL to turn off TLS v1.1
  
  
    SSL_OP_NO_TLSv1_2
    Instructs OpenSSL to turn off TLS v1.2
  
  
    SSL_OP_NO_TLSv1_3
    Instructs OpenSSL to turn off TLS v1.3
  
  
    SSL_OP_PRIORITIZE_CHACHA
    Instructs OpenSSL server to prioritize ChaCha20-Poly1305
    when the client does.
    This option has no effect if
    SSL_OP_CIPHER_SERVER_PREFERENCE
    is not enabled.
  
  
    SSL_OP_TLS_ROLLBACK_BUG
    Instructs OpenSSL to disable version rollback attack detection.
  


OpenSSL engine constants#

  
    Constant
    Description
  
  
    ENGINE_METHOD_RSA
    Limit engine usage to RSA
  
  
    ENGINE_METHOD_DSA
    Limit engine usage to DSA
  
  
    ENGINE_METHOD_DH
    Limit engine usage to DH
  
  
    ENGINE_METHOD_RAND
    Limit engine usage to RAND
  
  
    ENGINE_METHOD_EC
    Limit engine usage to EC
  
  
    ENGINE_METHOD_CIPHERS
    Limit engine usage to CIPHERS
  
  
    ENGINE_METHOD_DIGESTS
    Limit engine usage to DIGESTS
  
  
    ENGINE_METHOD_PKEY_METHS
    Limit engine usage to PKEY_METHS
  
  
    ENGINE_METHOD_PKEY_ASN1_METHS
    Limit engine usage to PKEY_ASN1_METHS
  
  
    ENGINE_METHOD_ALL
    
  
  
    ENGINE_METHOD_NONE
    
  


Other OpenSSL constants#

  
    Constant
    Description
  
  
    DH_CHECK_P_NOT_SAFE_PRIME
    
  
  
    DH_CHECK_P_NOT_PRIME
    
  
  
    DH_UNABLE_TO_CHECK_GENERATOR
    
  
  
    DH_NOT_SUITABLE_GENERATOR
    
  
  
    RSA_PKCS1_PADDING
    
  
  
    RSA_SSLV23_PADDING
    
  
  
    RSA_NO_PADDING
    
  
  
    RSA_PKCS1_OAEP_PADDING
    
  
  
    RSA_X931_PADDING
    
  
  
    RSA_PKCS1_PSS_PADDING
    
  
  
    RSA_PSS_SALTLEN_DIGEST
    Sets the salt length for RSA_PKCS1_PSS_PADDING to the
        digest size when signing or verifying.
  
  
    RSA_PSS_SALTLEN_MAX_SIGN
    Sets the salt length for RSA_PKCS1_PSS_PADDING to the
        maximum permissible value when signing data.
  
  
    RSA_PSS_SALTLEN_AUTO
    Causes the salt length for RSA_PKCS1_PSS_PADDING to be
        determined automatically when verifying a signature.
  
  
    POINT_CONVERSION_COMPRESSED
    
  
  
    POINT_CONVERSION_UNCOMPRESSED
    
  
  
    POINT_CONVERSION_HYBRID
    
  


Node.js crypto constants#

  
    Constant
    Description
  
  
    defaultCoreCipherList
    Specifies the built-in default cipher list used by Node.js.
  
  
    defaultCipherList
    Specifies the active default cipher list used by the current Node.js
    process.\n\n\n\nNode.js
        
      
      
About this documentation
Usage and example



Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Modules: TypeScript
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
Readline
REPL
Report
Single executable applications
SQLite
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker

    

    
      
        
          Node.js v24.0.1 documentation
          
            
            
          
        
        
          
            Node.js v24.0.1
            
    
      
        
        Table of contents
      

      
Debugger

Watchers
Command reference

Stepping
Breakpoints
Information
Execution control
Various


Advanced usage

V8 inspector integration for Node.js





    
  
            
    
      
        
        Index
      

      
About this documentation
Usage and example

      
        Index
      
    
  


Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Modules: TypeScript
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
Readline
REPL
Report
Single executable applications
SQLite
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker

    
  
            
    
      
        
        Other versions
      
      24.x
23.x
22.x LTS
21.x
20.x LTS
19.x
18.x
17.x
16.x
15.x
14.x
13.x
12.x
11.x
10.x
9.x
8.x
7.x
6.x
5.x
4.x
0.12.x
0.10.x
    
  
            
              
                
                Options
              
        
              
                
                  
                    View on single page
                  
                  
                    View as JSON
                  
                  Edit on GitHub    
                
              
            
          
        
        
      

      Table of contents
Debugger

Watchers
Command reference

Stepping
Breakpoints
Information
Execution control
Various


Advanced usage

V8 inspector integration for Node.js






      
        Debugger#

Stability: 2 - Stable

Node.js includes a command-line debugging utility. The Node.js debugger client
is not a full-featured debugger, but simple stepping and inspection are
possible.
To use it, start Node.js with the inspect argument followed by the path to the
script to debug.
$ node inspect myscript.js
< Debugger listening on ws://127.0.0.1:9229/621111f9-ffcb-4e82-b718-48a145fa5db8
< For help, see: https://nodejs.org/en/docs/inspector
<
connecting to 127.0.0.1:9229 ... ok
< Debugger attached.
<
 ok
Break on start in myscript.js:2
  1 // myscript.js
> 2 global.x = 5;
  3 setTimeout(() => {
  4   debugger;
debug> copy
The debugger automatically breaks on the first executable line. To instead
run until the first breakpoint (specified by a debugger statement), set
the NODE_INSPECT_RESUME_ON_START environment variable to 1.
$ cat myscript.js
// myscript.js
global.x = 5;
setTimeout(() => {
  debugger;
  console.log('world');
}, 1000);
console.log('hello');
$ NODE_INSPECT_RESUME_ON_START=1 node inspect myscript.js
< Debugger listening on ws://127.0.0.1:9229/f1ed133e-7876-495b-83ae-c32c6fc319c2
< For help, see: https://nodejs.org/en/docs/inspector
<
connecting to 127.0.0.1:9229 ... ok
< Debugger attached.
<
< hello
<
break in myscript.js:4
  2 global.x = 5;
  3 setTimeout(() => {
> 4   debugger;
  5   console.log('world');
  6 }, 1000);
debug> next
break in myscript.js:5
  3 setTimeout(() => {
  4   debugger;
> 5   console.log('world');
  6 }, 1000);
  7 console.log('hello');
debug> repl
Press Ctrl+C to leave debug repl
> x
5
> 2 + 2
4
debug> next
< world
<
break in myscript.js:6
  4   debugger;
  5   console.log('world');
> 6 }, 1000);
  7 console.log('hello');
  8
debug> .exit
$ copy
The repl command allows code to be evaluated remotely. The next command
steps to the next line. Type help to see what other commands are available.
Pressing enter without typing a command will repeat the previous debugger
command.
Watchers#
It is possible to watch expression and variable values while debugging. On
every breakpoint, each expression from the watchers list will be evaluated
in the current context and displayed immediately before the breakpoint's
source code listing.
To begin watching an expression, type watch('my_expression'). The command
watchers will print the active watchers. To remove a watcher, type
unwatch('my_expression').
Command reference#

Stepping#

cont, c: Continue execution
next, n: Step next
step, s: Step in
out, o: Step out
pause: Pause running code (like pause button in Developer Tools)


Breakpoints#

setBreakpoint(), sb(): Set breakpoint on current line
setBreakpoint(line), sb(line): Set breakpoint on specific line
setBreakpoint('fn()'), sb(...): Set breakpoint on a first statement in
function's body
setBreakpoint('script.js', 1), sb(...): Set breakpoint on first line of
script.js
setBreakpoint('script.js', 1, 'num < 4'), sb(...): Set conditional
breakpoint on first line of script.js that only breaks when num < 4
evaluates to true
clearBreakpoint('script.js', 1), cb(...): Clear breakpoint in script.js
on line 1

It is also possible to set a breakpoint in a file (module) that
is not loaded yet:
$ node inspect main.js
< Debugger listening on ws://127.0.0.1:9229/48a5b28a-550c-471b-b5e1-d13dd7165df9
< For help, see: https://nodejs.org/en/docs/inspector
<
connecting to 127.0.0.1:9229 ... ok
< Debugger attached.
<
Break on start in main.js:1
> 1 const mod = require('./mod.js');
  2 mod.hello();
  3 mod.hello();
debug> setBreakpoint('mod.js', 22)
Warning: script 'mod.js' was not loaded yet.
debug> c
break in mod.js:22
 20 // USE OR OTHER DEALINGS IN THE SOFTWARE.
 21
>22 exports.hello = function() {
 23   return 'hello from module';
 24 };
debug> copy
It is also possible to set a conditional breakpoint that only breaks when a
given expression evaluates to true:
$ node inspect main.js
< Debugger listening on ws://127.0.0.1:9229/ce24daa8-3816-44d4-b8ab-8273c8a66d35
< For help, see: https://nodejs.org/en/docs/inspector
<
connecting to 127.0.0.1:9229 ... ok
< Debugger attached.
Break on start in main.js:7
  5 }
  6
> 7 addOne(10);
  8 addOne(-1);
  9
debug> setBreakpoint('main.js', 4, 'num < 0')
  1 'use strict';
  2
  3 function addOne(num) {
> 4   return num + 1;
  5 }
  6
  7 addOne(10);
  8 addOne(-1);
  9
debug> cont
break in main.js:4
  2
  3 function addOne(num) {
> 4   return num + 1;
  5 }
  6
debug> exec('num')
-1
debug> copy

Information#

backtrace, bt: Print backtrace of current execution frame
list(5): List scripts source code with 5 line context (5 lines before and
after)
watch(expr): Add expression to watch list
unwatch(expr): Remove expression from watch list
unwatch(index): Remove expression at specific index from watch list
watchers: List all watchers and their values (automatically listed on each
breakpoint)
repl: Open debugger's repl for evaluation in debugging script's context
exec expr, p expr: Execute an expression in debugging script's context and
print its value
profile: Start CPU profiling session
profileEnd: Stop current CPU profiling session
profiles: List all completed CPU profiling sessions
profiles[n].save(filepath = 'node.cpuprofile'): Save CPU profiling session
to disk as JSON
takeHeapSnapshot(filepath = 'node.heapsnapshot'): Take a heap snapshot
and save to disk as JSON


Execution control#

run: Run script (automatically runs on debugger's start)
restart: Restart script
kill: Kill script


Various#

scripts: List all loaded scripts
version: Display V8's version


Advanced usage#

V8 inspector integration for Node.js#
V8 Inspector integration allows attaching Chrome DevTools to Node.js
instances for debugging and profiling. It uses the
Chrome DevTools Protocol.
V8 Inspector can be enabled by passing the --inspect flag when starting a
Node.js application. It is also possible to supply a custom port with that flag,
e.g. --inspect=9222 will accept DevTools connections on port 9222.
Using the --inspect flag will execute the code immediately before debugger is connected.
This means that the code will start running before you can start debugging, which might
not be ideal if you want to debug from the very beginning.
In such cases, you have two alternatives:

--inspect-wait flag: This flag will wait for debugger to be attached before executing the code.
This allows you to start debugging right from the beginning of the execution.
--inspect-brk flag: Unlike --inspect, this flag will break on the first line of the code
as soon as debugger is attached. This is useful when you want to debug the code step by step
from the very beginning, without any code execution prior to debugging.

So, when deciding between --inspect, --inspect-wait, and --inspect-brk, consider whether you want
the code to start executing immediately, wait for debugger to be attached before execution,
or break on the first line for step-by-step debugging.
$ node --inspect index.js
Debugger listening on ws://127.0.0.1:9229/dc9010dd-f8b8-4ac5-a510-c1a114ec7d29
For help, see: https://nodejs.org/en/docs/inspector copy
(In the example above, the UUID dc9010dd-f8b8-4ac5-a510-c1a114ec7d29
at the end of the URL is generated on the fly, it varies in different
debugging sessions.)
If the Chrome browser is older than 66.0.3345.0,
use inspector.html instead of js_app.html in the above URL.
Chrome DevTools doesn't support debugging worker threads yet.
ndb can be used to debug them.\n\n\n\nNode.js
        
      
      
About this documentation
Usage and example



Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Modules: TypeScript
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
Readline
REPL
Report
Single executable applications
SQLite
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker

    

    
      
        
          Node.js v24.0.1 documentation
          
            
            
          
        
        
          
            Node.js v24.0.1
            
    
      
        
        Table of contents
      

      
Deprecated APIs

Revoking deprecations
List of deprecated APIs

DEP0001: http.OutgoingMessage.prototype.flush
DEP0002: require('_linklist')
DEP0003: _writableState.buffer
DEP0004: CryptoStream.prototype.readyState
DEP0005: Buffer() constructor
DEP0006: child_process options.customFds
DEP0007: Replace cluster worker.suicide with worker.exitedAfterDisconnect
DEP0008: require('node:constants')
DEP0009: crypto.pbkdf2 without digest
DEP0010: crypto.createCredentials
DEP0011: crypto.Credentials
DEP0012: Domain.dispose
DEP0013: fs asynchronous function without callback
DEP0014: fs.read legacy String interface
DEP0015: fs.readSync legacy String interface
DEP0016: GLOBAL/root
DEP0017: Intl.v8BreakIterator
DEP0018: Unhandled promise rejections
DEP0019: require('.') resolved outside directory
DEP0020: Server.connections
DEP0021: Server.listenFD
DEP0022: os.tmpDir()
DEP0023: os.getNetworkInterfaces()
DEP0024: REPLServer.prototype.convertToContext()
DEP0025: require('node:sys')
DEP0026: util.print()
DEP0027: util.puts()
DEP0028: util.debug()
DEP0029: util.error()
DEP0030: SlowBuffer
DEP0031: ecdh.setPublicKey()
DEP0032: node:domain module
DEP0033: EventEmitter.listenerCount()
DEP0034: fs.exists(path, callback)
DEP0035: fs.lchmod(path, mode, callback)
DEP0036: fs.lchmodSync(path, mode)
DEP0037: fs.lchown(path, uid, gid, callback)
DEP0038: fs.lchownSync(path, uid, gid)
DEP0039: require.extensions
DEP0040: node:punycode module
DEP0041: NODE_REPL_HISTORY_FILE environment variable
DEP0042: tls.CryptoStream
DEP0043: tls.SecurePair
DEP0044: util.isArray()
DEP0045: util.isBoolean()
DEP0046: util.isBuffer()
DEP0047: util.isDate()
DEP0048: util.isError()
DEP0049: util.isFunction()
DEP0050: util.isNull()
DEP0051: util.isNullOrUndefined()
DEP0052: util.isNumber()
DEP0053: util.isObject()
DEP0054: util.isPrimitive()
DEP0055: util.isRegExp()
DEP0056: util.isString()
DEP0057: util.isSymbol()
DEP0058: util.isUndefined()
DEP0059: util.log()
DEP0060: util._extend()
DEP0061: fs.SyncWriteStream
DEP0062: node --debug
DEP0063: ServerResponse.prototype.writeHeader()
DEP0064: tls.createSecurePair()
DEP0065: repl.REPL_MODE_MAGIC and NODE_REPL_MODE=magic
DEP0066: OutgoingMessage.prototype._headers, OutgoingMessage.prototype._headerNames
DEP0067: OutgoingMessage.prototype._renderHeaders
DEP0068: node debug
DEP0069: vm.runInDebugContext(string)
DEP0070: async_hooks.currentId()
DEP0071: async_hooks.triggerId()
DEP0072: async_hooks.AsyncResource.triggerId()
DEP0073: Several internal properties of net.Server
DEP0074: REPLServer.bufferedCommand
DEP0075: REPLServer.parseREPLKeyword()
DEP0076: tls.parseCertString()
DEP0077: Module._debug()
DEP0078: REPLServer.turnOffEditorMode()
DEP0079: Custom inspection function on objects via .inspect()
DEP0080: path._makeLong()
DEP0081: fs.truncate() using a file descriptor
DEP0082: REPLServer.prototype.memory()
DEP0083: Disabling ECDH by setting ecdhCurve to false
DEP0084: requiring bundled internal dependencies
DEP0085: AsyncHooks sensitive API
DEP0086: Remove runInAsyncIdScope
DEP0089: require('node:assert')
DEP0090: Invalid GCM authentication tag lengths
DEP0091: crypto.DEFAULT_ENCODING
DEP0092: Top-level this bound to module.exports
DEP0093: crypto.fips is deprecated and replaced
DEP0094: Using assert.fail() with more than one argument
DEP0095: timers.enroll()
DEP0096: timers.unenroll()
DEP0097: MakeCallback with domain property
DEP0098: AsyncHooks embedder AsyncResource.emitBefore and AsyncResource.emitAfter APIs
DEP0099: Async context-unaware node::MakeCallback C++ APIs
DEP0100: process.assert()
DEP0101: --with-lttng
DEP0102: Using noAssert in Buffer#(read|write) operations
DEP0103: process.binding('util').is[...] typechecks
DEP0104: process.env string coercion
DEP0105: decipher.finaltol
DEP0106: crypto.createCipher and crypto.createDecipher
DEP0107: tls.convertNPNProtocols()
DEP0108: zlib.bytesRead
DEP0109: http, https, and tls support for invalid URLs
DEP0110: vm.Script cached data
DEP0111: process.binding()
DEP0112: dgram private APIs
DEP0113: Cipher.setAuthTag(), Decipher.getAuthTag()
DEP0114: crypto._toBuf()
DEP0115: crypto.prng(), crypto.pseudoRandomBytes(), crypto.rng()
DEP0116: Legacy URL API
DEP0117: Native crypto handles
DEP0118: dns.lookup() support for a falsy host name
DEP0119: process.binding('uv').errname() private API
DEP0120: Windows Performance Counter support
DEP0121: net._setSimultaneousAccepts()
DEP0122: tls Server.prototype.setOptions()
DEP0123: setting the TLS ServerName to an IP address
DEP0124: using REPLServer.rli
DEP0125: require('node:_stream_wrap')
DEP0126: timers.active()
DEP0127: timers._unrefActive()
DEP0128: modules with an invalid main entry and an index.js file
DEP0129: ChildProcess._channel
DEP0130: Module.createRequireFromPath()
DEP0131: Legacy HTTP parser
DEP0132: worker.terminate() with callback
DEP0133: http connection
DEP0134: process._tickCallback
DEP0135: WriteStream.open() and ReadStream.open() are internal
DEP0136: http finished
DEP0137: Closing fs.FileHandle on garbage collection
DEP0138: process.mainModule
DEP0139: process.umask() with no arguments
DEP0140: Use request.destroy() instead of request.abort()
DEP0141: repl.inputStream and repl.outputStream
DEP0142: repl._builtinLibs
DEP0143: Transform._transformState
DEP0144: module.parent
DEP0145: socket.bufferSize
DEP0146: new crypto.Certificate()
DEP0147: fs.rmdir(path, { recursive: true })
DEP0148: Folder mappings in "exports" (trailing "/")
DEP0149: http.IncomingMessage#connection
DEP0150: Changing the value of process.config
DEP0151: Main index lookup and extension searching
DEP0152: Extension PerformanceEntry properties
DEP0153: dns.lookup and dnsPromises.lookup options type coercion
DEP0154: RSA-PSS generate key pair options
DEP0155: Trailing slashes in pattern specifier resolutions
DEP0156: .aborted property and 'abort', 'aborted' event in http
DEP0157: Thenable support in streams
DEP0158: buffer.slice(start, end)
DEP0159: ERR_INVALID_CALLBACK
DEP0160: process.on('multipleResolves', handler)
DEP0161: process._getActiveRequests() and process._getActiveHandles()
DEP0162: fs.write(), fs.writeFileSync() coercion to string
DEP0163: channel.subscribe(onMessage), channel.unsubscribe(onMessage)
DEP0164: process.exit(code), process.exitCode coercion to integer
DEP0165: --trace-atomics-wait
DEP0166: Double slashes in imports and exports targets
DEP0167: Weak DiffieHellmanGroup instances (modp1, modp2, modp5)
DEP0168: Unhandled exception in Node-API callbacks
DEP0169: Insecure url.parse()
DEP0170: Invalid port when using url.parse()
DEP0171: Setters for http.IncomingMessage headers and trailers
DEP0172: The asyncResource property of AsyncResource bound functions
DEP0173: the assert.CallTracker class
DEP0174: calling promisify on a function that returns a Promise
DEP0175: util.toUSVString
DEP0176: fs.F_OK, fs.R_OK, fs.W_OK, fs.X_OK
DEP0177: util.types.isWebAssemblyCompiledModule
DEP0178: dirent.path
DEP0179: Hash constructor
DEP0180: fs.Stats constructor
DEP0181: Hmac constructor
DEP0182: Short GCM authentication tags without explicit authTagLength
DEP0183: OpenSSL engine-based APIs
DEP0184: Instantiating node:zlib classes without new
DEP0185: Instantiating node:repl classes without new
DEP0187: Passing invalid argument types to fs.existsSync
DEP0188: process.features.ipv6 and process.features.uv
DEP0189: process.features.tls_*
DEP0190: Passing args to node:child_process execFile/spawn with shell option true
DEP0191: repl.builtinModules





    
  
            
    
      
        
        Index
      

      
About this documentation
Usage and example

      
        Index
      
    
  


Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Modules: TypeScript
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
Readline
REPL
Report
Single executable applications
SQLite
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker

    
  
            
    
      
        
        Other versions
      
      24.x
23.x
22.x LTS
21.x
20.x LTS
19.x
18.x
17.x
16.x
15.x
14.x
13.x
12.x
11.x
10.x
9.x
8.x
7.x
    
  
            
              
                
                Options
              
        
              
                
                  
                    View on single page
                  
                  
                    View as JSON
                  
                  Edit on GitHub    
                
              
            
          
        
        
      

      Table of contents
Deprecated APIs

Revoking deprecations
List of deprecated APIs

DEP0001: http.OutgoingMessage.prototype.flush
DEP0002: require('_linklist')
DEP0003: _writableState.buffer
DEP0004: CryptoStream.prototype.readyState
DEP0005: Buffer() constructor
DEP0006: child_process options.customFds
DEP0007: Replace cluster worker.suicide with worker.exitedAfterDisconnect
DEP0008: require('node:constants')
DEP0009: crypto.pbkdf2 without digest
DEP0010: crypto.createCredentials
DEP0011: crypto.Credentials
DEP0012: Domain.dispose
DEP0013: fs asynchronous function without callback
DEP0014: fs.read legacy String interface
DEP0015: fs.readSync legacy String interface
DEP0016: GLOBAL/root
DEP0017: Intl.v8BreakIterator
DEP0018: Unhandled promise rejections
DEP0019: require('.') resolved outside directory
DEP0020: Server.connections
DEP0021: Server.listenFD
DEP0022: os.tmpDir()
DEP0023: os.getNetworkInterfaces()
DEP0024: REPLServer.prototype.convertToContext()
DEP0025: require('node:sys')
DEP0026: util.print()
DEP0027: util.puts()
DEP0028: util.debug()
DEP0029: util.error()
DEP0030: SlowBuffer
DEP0031: ecdh.setPublicKey()
DEP0032: node:domain module
DEP0033: EventEmitter.listenerCount()
DEP0034: fs.exists(path, callback)
DEP0035: fs.lchmod(path, mode, callback)
DEP0036: fs.lchmodSync(path, mode)
DEP0037: fs.lchown(path, uid, gid, callback)
DEP0038: fs.lchownSync(path, uid, gid)
DEP0039: require.extensions
DEP0040: node:punycode module
DEP0041: NODE_REPL_HISTORY_FILE environment variable
DEP0042: tls.CryptoStream
DEP0043: tls.SecurePair
DEP0044: util.isArray()
DEP0045: util.isBoolean()
DEP0046: util.isBuffer()
DEP0047: util.isDate()
DEP0048: util.isError()
DEP0049: util.isFunction()
DEP0050: util.isNull()
DEP0051: util.isNullOrUndefined()
DEP0052: util.isNumber()
DEP0053: util.isObject()
DEP0054: util.isPrimitive()
DEP0055: util.isRegExp()
DEP0056: util.isString()
DEP0057: util.isSymbol()
DEP0058: util.isUndefined()
DEP0059: util.log()
DEP0060: util._extend()
DEP0061: fs.SyncWriteStream
DEP0062: node --debug
DEP0063: ServerResponse.prototype.writeHeader()
DEP0064: tls.createSecurePair()
DEP0065: repl.REPL_MODE_MAGIC and NODE_REPL_MODE=magic
DEP0066: OutgoingMessage.prototype._headers, OutgoingMessage.prototype._headerNames
DEP0067: OutgoingMessage.prototype._renderHeaders
DEP0068: node debug
DEP0069: vm.runInDebugContext(string)
DEP0070: async_hooks.currentId()
DEP0071: async_hooks.triggerId()
DEP0072: async_hooks.AsyncResource.triggerId()
DEP0073: Several internal properties of net.Server
DEP0074: REPLServer.bufferedCommand
DEP0075: REPLServer.parseREPLKeyword()
DEP0076: tls.parseCertString()
DEP0077: Module._debug()
DEP0078: REPLServer.turnOffEditorMode()
DEP0079: Custom inspection function on objects via .inspect()
DEP0080: path._makeLong()
DEP0081: fs.truncate() using a file descriptor
DEP0082: REPLServer.prototype.memory()
DEP0083: Disabling ECDH by setting ecdhCurve to false
DEP0084: requiring bundled internal dependencies
DEP0085: AsyncHooks sensitive API
DEP0086: Remove runInAsyncIdScope
DEP0089: require('node:assert')
DEP0090: Invalid GCM authentication tag lengths
DEP0091: crypto.DEFAULT_ENCODING
DEP0092: Top-level this bound to module.exports
DEP0093: crypto.fips is deprecated and replaced
DEP0094: Using assert.fail() with more than one argument
DEP0095: timers.enroll()
DEP0096: timers.unenroll()
DEP0097: MakeCallback with domain property
DEP0098: AsyncHooks embedder AsyncResource.emitBefore and AsyncResource.emitAfter APIs
DEP0099: Async context-unaware node::MakeCallback C++ APIs
DEP0100: process.assert()
DEP0101: --with-lttng
DEP0102: Using noAssert in Buffer#(read|write) operations
DEP0103: process.binding('util').is[...] typechecks
DEP0104: process.env string coercion
DEP0105: decipher.finaltol
DEP0106: crypto.createCipher and crypto.createDecipher
DEP0107: tls.convertNPNProtocols()
DEP0108: zlib.bytesRead
DEP0109: http, https, and tls support for invalid URLs
DEP0110: vm.Script cached data
DEP0111: process.binding()
DEP0112: dgram private APIs
DEP0113: Cipher.setAuthTag(), Decipher.getAuthTag()
DEP0114: crypto._toBuf()
DEP0115: crypto.prng(), crypto.pseudoRandomBytes(), crypto.rng()
DEP0116: Legacy URL API
DEP0117: Native crypto handles
DEP0118: dns.lookup() support for a falsy host name
DEP0119: process.binding('uv').errname() private API
DEP0120: Windows Performance Counter support
DEP0121: net._setSimultaneousAccepts()
DEP0122: tls Server.prototype.setOptions()
DEP0123: setting the TLS ServerName to an IP address
DEP0124: using REPLServer.rli
DEP0125: require('node:_stream_wrap')
DEP0126: timers.active()
DEP0127: timers._unrefActive()
DEP0128: modules with an invalid main entry and an index.js file
DEP0129: ChildProcess._channel
DEP0130: Module.createRequireFromPath()
DEP0131: Legacy HTTP parser
DEP0132: worker.terminate() with callback
DEP0133: http connection
DEP0134: process._tickCallback
DEP0135: WriteStream.open() and ReadStream.open() are internal
DEP0136: http finished
DEP0137: Closing fs.FileHandle on garbage collection
DEP0138: process.mainModule
DEP0139: process.umask() with no arguments
DEP0140: Use request.destroy() instead of request.abort()
DEP0141: repl.inputStream and repl.outputStream
DEP0142: repl._builtinLibs
DEP0143: Transform._transformState
DEP0144: module.parent
DEP0145: socket.bufferSize
DEP0146: new crypto.Certificate()
DEP0147: fs.rmdir(path, { recursive: true })
DEP0148: Folder mappings in "exports" (trailing "/")
DEP0149: http.IncomingMessage#connection
DEP0150: Changing the value of process.config
DEP0151: Main index lookup and extension searching
DEP0152: Extension PerformanceEntry properties
DEP0153: dns.lookup and dnsPromises.lookup options type coercion
DEP0154: RSA-PSS generate key pair options
DEP0155: Trailing slashes in pattern specifier resolutions
DEP0156: .aborted property and 'abort', 'aborted' event in http
DEP0157: Thenable support in streams
DEP0158: buffer.slice(start, end)
DEP0159: ERR_INVALID_CALLBACK
DEP0160: process.on('multipleResolves', handler)
DEP0161: process._getActiveRequests() and process._getActiveHandles()
DEP0162: fs.write(), fs.writeFileSync() coercion to string
DEP0163: channel.subscribe(onMessage), channel.unsubscribe(onMessage)
DEP0164: process.exit(code), process.exitCode coercion to integer
DEP0165: --trace-atomics-wait
DEP0166: Double slashes in imports and exports targets
DEP0167: Weak DiffieHellmanGroup instances (modp1, modp2, modp5)
DEP0168: Unhandled exception in Node-API callbacks
DEP0169: Insecure url.parse()
DEP0170: Invalid port when using url.parse()
DEP0171: Setters for http.IncomingMessage headers and trailers
DEP0172: The asyncResource property of AsyncResource bound functions
DEP0173: the assert.CallTracker class
DEP0174: calling promisify on a function that returns a Promise
DEP0175: util.toUSVString
DEP0176: fs.F_OK, fs.R_OK, fs.W_OK, fs.X_OK
DEP0177: util.types.isWebAssemblyCompiledModule
DEP0178: dirent.path
DEP0179: Hash constructor
DEP0180: fs.Stats constructor
DEP0181: Hmac constructor
DEP0182: Short GCM authentication tags without explicit authTagLength
DEP0183: OpenSSL engine-based APIs
DEP0184: Instantiating node:zlib classes without new
DEP0185: Instantiating node:repl classes without new
DEP0187: Passing invalid argument types to fs.existsSync
DEP0188: process.features.ipv6 and process.features.uv
DEP0189: process.features.tls_*
DEP0190: Passing args to node:child_process execFile/spawn with shell option true
DEP0191: repl.builtinModules






      
        Deprecated APIs#


Node.js APIs might be deprecated for any of the following reasons:

Use of the API is unsafe.
An improved alternative API is available.
Breaking changes to the API are expected in a future major release.

Node.js uses four kinds of deprecations:

Documentation-only
Application (non-node_modules code only)
Runtime (all code)
End-of-Life

A Documentation-only deprecation is one that is expressed only within the
Node.js API docs. These generate no side-effects while running Node.js.
Some Documentation-only deprecations trigger a runtime warning when launched
with --pending-deprecation flag (or its alternative,
NODE_PENDING_DEPRECATION=1 environment variable), similarly to Runtime
deprecations below. Documentation-only deprecations that support that flag
are explicitly labeled as such in the
list of Deprecated APIs.
An Application deprecation for only non-node_modules code will, by default,
generate a process warning that will be printed to stderr the first time
the deprecated API is used in code that's not loaded from node_modules.
When the --throw-deprecation command-line flag is used, a Runtime
deprecation will cause an error to be thrown. When
--pending-deprecation is used, warnings will also be emitted for
code loaded from node_modules.
A runtime deprecation for all code is similar to the runtime deprecation
for non-node_modules code, except that it also emits a warning for
code loaded from node_modules.
An End-of-Life deprecation is used when functionality is or will soon be removed
from Node.js.
Revoking deprecations#
Occasionally, the deprecation of an API might be reversed. In such situations,
this document will be updated with information relevant to the decision.
However, the deprecation identifier will not be modified.
List of deprecated APIs#

DEP0001: http.OutgoingMessage.prototype.flush#

History

VersionChanges
v14.0.0
End-of-Life.
v6.12.0, v4.8.6
A deprecation code has been assigned.
v1.6.0
Runtime deprecation.



Type: End-of-Life
OutgoingMessage.prototype.flush() has been removed. Use
OutgoingMessage.prototype.flushHeaders() instead.

DEP0002: require('_linklist')#

History

VersionChanges
v8.0.0
End-of-Life.
v6.12.0
A deprecation code has been assigned.
v5.0.0
Runtime deprecation.



Type: End-of-Life
The _linklist module is deprecated. Please use a userland alternative.

DEP0003: _writableState.buffer#

History

VersionChanges
v14.0.0
End-of-Life.
v6.12.0, v4.8.6
A deprecation code has been assigned.
v0.11.15
Runtime deprecation.



Type: End-of-Life
The _writableState.buffer has been removed. Use _writableState.getBuffer()
instead.

DEP0004: CryptoStream.prototype.readyState#

History

VersionChanges
v10.0.0
End-of-Life.
v6.12.0, v4.8.6
A deprecation code has been assigned.
v0.4.0
Documentation-only deprecation.



Type: End-of-Life
The CryptoStream.prototype.readyState property was removed.

DEP0005: Buffer() constructor#

History

VersionChanges
v10.0.0
Runtime deprecation.
v6.12.0
A deprecation code has been assigned.
v6.0.0
Documentation-only deprecation.



Type: Application (non-node_modules code only)
The Buffer() function and new Buffer() constructor are deprecated due to
API usability issues that can lead to accidental security issues.
As an alternative, use one of the following methods of constructing Buffer
objects:

Buffer.alloc(size[, fill[, encoding]]): Create a Buffer with
initialized memory.
Buffer.allocUnsafe(size): Create a Buffer with
uninitialized memory.
Buffer.allocUnsafeSlow(size): Create a Buffer with uninitialized
memory.
Buffer.from(array): Create a Buffer with a copy of array
Buffer.from(arrayBuffer[, byteOffset[, length]]) -
Create a Buffer that wraps the given arrayBuffer.
Buffer.from(buffer): Create a Buffer that copies buffer.
Buffer.from(string[, encoding]): Create a Buffer
that copies string.

Without --pending-deprecation, runtime warnings occur only for code not in
node_modules. This means there will not be deprecation warnings for
Buffer() usage in dependencies. With --pending-deprecation, a runtime
warning results no matter where the Buffer() usage occurs.

DEP0006: child_process options.customFds#

History

VersionChanges
v12.0.0
End-of-Life.
v6.12.0, v4.8.6
A deprecation code has been assigned.
v0.11.14
Runtime deprecation.
v0.5.10
Documentation-only deprecation.



Type: End-of-Life
Within the child_process module's spawn(), fork(), and exec()
methods, the options.customFds option is deprecated. The options.stdio
option should be used instead.

DEP0007: Replace cluster worker.suicide with worker.exitedAfterDisconnect#

History

VersionChanges
v9.0.0
End-of-Life.
v7.0.0
Runtime deprecation.
v6.12.0
A deprecation code has been assigned.
v6.0.0
Documentation-only deprecation.



Type: End-of-Life
In an earlier version of the Node.js cluster, a boolean property with the name
suicide was added to the Worker object. The intent of this property was to
provide an indication of how and why the Worker instance exited. In Node.js
6.0.0, the old property was deprecated and replaced with a new
worker.exitedAfterDisconnect property. The old property name did not
precisely describe the actual semantics and was unnecessarily emotion-laden.

DEP0008: require('node:constants')#

History

VersionChanges
v6.12.0
A deprecation code has been assigned.
v6.3.0
Documentation-only deprecation.



Type: Documentation-only
The node:constants module is deprecated. When requiring access to constants
relevant to specific Node.js builtin modules, developers should instead refer
to the constants property exposed by the relevant module. For instance,
require('node:fs').constants and require('node:os').constants.

DEP0009: crypto.pbkdf2 without digest#

History

VersionChanges
v14.0.0
End-of-Life (for digest === null).
v11.0.0
Runtime deprecation (for digest === null).
v8.0.0
End-of-Life (for digest === undefined).
v6.12.0
A deprecation code has been assigned.
v6.0.0
Runtime deprecation (for digest === undefined).



Type: End-of-Life
Use of the crypto.pbkdf2() API without specifying a digest was deprecated
in Node.js 6.0 because the method defaulted to using the non-recommended
'SHA1' digest. Previously, a deprecation warning was printed. Starting in
Node.js 8.0.0, calling crypto.pbkdf2() or crypto.pbkdf2Sync() with
digest set to undefined will throw a TypeError.
Beginning in Node.js v11.0.0, calling these functions with digest set to
null would print a deprecation warning to align with the behavior when digest
is undefined.
Now, however, passing either undefined or null will throw a TypeError.

DEP0010: crypto.createCredentials#

History

VersionChanges
v11.0.0
End-of-Life.
v6.12.0, v4.8.6
A deprecation code has been assigned.
v0.11.13
Runtime deprecation.



Type: End-of-Life
The crypto.createCredentials() API was removed. Please use
tls.createSecureContext() instead.

DEP0011: crypto.Credentials#

History

VersionChanges
v11.0.0
End-of-Life.
v6.12.0, v4.8.6
A deprecation code has been assigned.
v0.11.13
Runtime deprecation.



Type: End-of-Life
The crypto.Credentials class was removed. Please use tls.SecureContext
instead.

DEP0012: Domain.dispose#

History

VersionChanges
v9.0.0
End-of-Life.
v6.12.0, v4.8.6
A deprecation code has been assigned.
v0.11.7
Runtime deprecation.



Type: End-of-Life
Domain.dispose() has been removed. Recover from failed I/O actions
explicitly via error event handlers set on the domain instead.

DEP0013: fs asynchronous function without callback#

History

VersionChanges
v10.0.0
End-of-Life.
v7.0.0
Runtime deprecation.



Type: End-of-Life
Calling an asynchronous function without a callback throws a TypeError
in Node.js 10.0.0 onwards. See https://github.com/nodejs/node/pull/12562.

DEP0014: fs.read legacy String interface#

History

VersionChanges
v8.0.0
End-of-Life.
v6.0.0
Runtime deprecation.
v6.12.0, v4.8.6
A deprecation code has been assigned.
v0.1.96
Documentation-only deprecation.



Type: End-of-Life
The fs.read() legacy String interface is deprecated. Use the Buffer
API as mentioned in the documentation instead.

DEP0015: fs.readSync legacy String interface#

History

VersionChanges
v8.0.0
End-of-Life.
v6.0.0
Runtime deprecation.
v6.12.0, v4.8.6
A deprecation code has been assigned.
v0.1.96
Documentation-only deprecation.



Type: End-of-Life
The fs.readSync() legacy String interface is deprecated. Use the
Buffer API as mentioned in the documentation instead.

DEP0016: GLOBAL/root#

History

VersionChanges
v14.0.0
End-of-Life.
v6.12.0
A deprecation code has been assigned.
v6.0.0
Runtime deprecation.



Type: End-of-Life
The GLOBAL and root aliases for the global property were deprecated
in Node.js 6.0.0 and have since been removed.

DEP0017: Intl.v8BreakIterator#

History

VersionChanges
v9.0.0
End-of-Life.
v7.0.0
Runtime deprecation.



Type: End-of-Life
Intl.v8BreakIterator was a non-standard extension and has been removed.
See Intl.Segmenter.

DEP0018: Unhandled promise rejections#

History

VersionChanges
v15.0.0
End-of-Life.
v7.0.0
Runtime deprecation.



Type: End-of-Life
Unhandled promise rejections are deprecated. By default, promise rejections
that are not handled terminate the Node.js process with a non-zero exit
code. To change the way Node.js treats unhandled rejections, use the
--unhandled-rejections command-line option.

DEP0019: require('.') resolved outside directory#

History

VersionChanges
v12.0.0
Removed functionality.
v6.12.0, v4.8.6
A deprecation code has been assigned.
v1.8.1
Runtime deprecation.



Type: End-of-Life
In certain cases, require('.') could resolve outside the package directory.
This behavior has been removed.

DEP0020: Server.connections#

History

VersionChanges
v15.0.0
Server.connections has been removed.
v6.12.0, v4.8.6
A deprecation code has been assigned.
v0.9.7
Runtime deprecation.



Type: End-of-Life
The Server.connections property was deprecated in Node.js v0.9.7 and has
been removed. Please use the Server.getConnections() method instead.

DEP0021: Server.listenFD#

History

VersionChanges
v12.0.0
End-of-Life.
v6.12.0, v4.8.6
A deprecation code has been assigned.
v0.7.12
Runtime deprecation.



Type: End-of-Life
The Server.listenFD() method was deprecated and removed. Please use
Server.listen({fd: <number>}) instead.

DEP0022: os.tmpDir()#

History

VersionChanges
v14.0.0
End-of-Life.
v7.0.0
Runtime deprecation.



Type: End-of-Life
The os.tmpDir() API was deprecated in Node.js 7.0.0 and has since been
removed. Please use os.tmpdir() instead.

DEP0023: os.getNetworkInterfaces()#

History

VersionChanges
v12.0.0
End-of-Life.
v6.12.0, v4.8.6
A deprecation code has been assigned.
v0.6.0
Runtime deprecation.



Type: End-of-Life
The os.getNetworkInterfaces() method is deprecated. Please use the
os.networkInterfaces() method instead.

DEP0024: REPLServer.prototype.convertToContext()#

History

VersionChanges
v9.0.0
End-of-Life.
v7.0.0
Runtime deprecation.



Type: End-of-Life
The REPLServer.prototype.convertToContext() API has been removed.

DEP0025: require('node:sys')#

History

VersionChanges
v6.12.0, v4.8.6
A deprecation code has been assigned.
v1.0.0
Runtime deprecation.



Type: Runtime
The node:sys module is deprecated. Please use the util module instead.

DEP0026: util.print()#

History

VersionChanges
v12.0.0
End-of-Life.
v6.12.0, v4.8.6
A deprecation code has been assigned.
v0.11.3
Runtime deprecation.



Type: End-of-Life
util.print() has been removed. Please use console.log() instead.

DEP0027: util.puts()#

History

VersionChanges
v12.0.0
End-of-Life.
v6.12.0, v4.8.6
A deprecation code has been assigned.
v0.11.3
Runtime deprecation.



Type: End-of-Life
util.puts() has been removed. Please use console.log() instead.

DEP0028: util.debug()#

History

VersionChanges
v12.0.0
End-of-Life.
v6.12.0, v4.8.6
A deprecation code has been assigned.
v0.11.3
Runtime deprecation.



Type: End-of-Life
util.debug() has been removed. Please use console.error() instead.

DEP0029: util.error()#

History

VersionChanges
v12.0.0
End-of-Life.
v6.12.0, v4.8.6
A deprecation code has been assigned.
v0.11.3
Runtime deprecation.



Type: End-of-Life
util.error() has been removed. Please use console.error() instead.

DEP0030: SlowBuffer#

History

VersionChanges
v24.0.0
Runtime deprecation.
v6.12.0
A deprecation code has been assigned.
v6.0.0
Documentation-only deprecation.



Type: Runtime
The SlowBuffer class is deprecated. Please use
Buffer.allocUnsafeSlow(size) instead.

DEP0031: ecdh.setPublicKey()#

History

VersionChanges
v6.12.0
A deprecation code has been assigned.
v5.2.0
Documentation-only deprecation.



Type: Documentation-only
The ecdh.setPublicKey() method is now deprecated as its inclusion in the
API is not useful.

DEP0032: node:domain module#

History

VersionChanges
v6.12.0, v4.8.6
A deprecation code has been assigned.
v1.4.2
Documentation-only deprecation.



Type: Documentation-only
The domain module is deprecated and should not be used.

DEP0033: EventEmitter.listenerCount()#

History

VersionChanges
v6.12.0, v4.8.6
A deprecation code has been assigned.
v3.2.0
Documentation-only deprecation.



Type: Documentation-only
The events.listenerCount(emitter, eventName) API is
deprecated. Please use emitter.listenerCount(eventName) instead.

DEP0034: fs.exists(path, callback)#

History

VersionChanges
v6.12.0, v4.8.6
A deprecation code has been assigned.
v1.0.0
Documentation-only deprecation.



Type: Documentation-only
The fs.exists(path, callback) API is deprecated. Please use
fs.stat() or fs.access() instead.

DEP0035: fs.lchmod(path, mode, callback)#

History

VersionChanges
v6.12.0, v4.8.6
A deprecation code has been assigned.
v0.4.7
Documentation-only deprecation.



Type: Documentation-only
The fs.lchmod(path, mode, callback) API is deprecated.

DEP0036: fs.lchmodSync(path, mode)#

History

VersionChanges
v6.12.0, v4.8.6
A deprecation code has been assigned.
v0.4.7
Documentation-only deprecation.



Type: Documentation-only
The fs.lchmodSync(path, mode) API is deprecated.

DEP0037: fs.lchown(path, uid, gid, callback)#

History

VersionChanges
v10.6.0
Deprecation revoked.
v6.12.0, v4.8.6
A deprecation code has been assigned.
v0.4.7
Documentation-only deprecation.



Type: Deprecation revoked
The fs.lchown(path, uid, gid, callback) API was deprecated. The
deprecation was revoked because the requisite supporting APIs were added in
libuv.

DEP0038: fs.lchownSync(path, uid, gid)#

History

VersionChanges
v10.6.0
Deprecation revoked.
v6.12.0, v4.8.6
A deprecation code has been assigned.
v0.4.7
Documentation-only deprecation.



Type: Deprecation revoked
The fs.lchownSync(path, uid, gid) API was deprecated. The deprecation was
revoked because the requisite supporting APIs were added in libuv.

DEP0039: require.extensions#

History

VersionChanges
v6.12.0, v4.8.6
A deprecation code has been assigned.
v0.10.6
Documentation-only deprecation.



Type: Documentation-only
The require.extensions property is deprecated.

DEP0040: node:punycode module#

History

VersionChanges
v21.0.0
Runtime deprecation.
v16.6.0
Added support for --pending-deprecation.
v7.0.0
Documentation-only deprecation.



Type: Runtime
The punycode module is deprecated. Please use a userland alternative
instead.

DEP0041: NODE_REPL_HISTORY_FILE environment variable#

History

VersionChanges
v10.0.0
End-of-Life.
v6.12.0, v4.8.6
A deprecation code has been assigned.
v3.0.0
Documentation-only deprecation.



Type: End-of-Life
The NODE_REPL_HISTORY_FILE environment variable was removed. Please use
NODE_REPL_HISTORY instead.

DEP0042: tls.CryptoStream#

History

VersionChanges
v10.0.0
End-of-Life.
v6.12.0, v4.8.6
A deprecation code has been assigned.
v0.11.3
Documentation-only deprecation.



Type: End-of-Life
The tls.CryptoStream class was removed. Please use
tls.TLSSocket instead.

DEP0043: tls.SecurePair#

History

VersionChanges
v24.0.0
End-of-Life.
v8.0.0
Runtime deprecation.
v6.12.0
A deprecation code has been assigned.
v6.0.0
Documentation-only deprecation.
v0.11.15
Deprecation revoked.
v0.11.3
Runtime deprecation.



Type: End-of-Life
The tls.SecurePair class is deprecated. Please use
tls.TLSSocket instead.

DEP0044: util.isArray()#

History

VersionChanges
v22.0.0
Runtime deprecation.
v6.12.0, v4.8.6
A deprecation code has been assigned.
v4.0.0, v3.3.1
Documentation-only deprecation.



Type: Runtime
The util.isArray() API is deprecated. Please use Array.isArray()
instead.

DEP0045: util.isBoolean()#

History

VersionChanges
v23.0.0
End-of-Life deprecation.
v22.0.0
Runtime deprecation.
v6.12.0, v4.8.6
A deprecation code has been assigned.
v4.0.0, v3.3.1
Documentation-only deprecation.



Type: End-of-Life
The util.isBoolean() API has been removed. Please use
typeof arg === 'boolean' instead.

DEP0046: util.isBuffer()#

History

VersionChanges
v23.0.0
End-of-Life deprecation.
v22.0.0
Runtime deprecation.
v6.12.0, v4.8.6
A deprecation code has been assigned.
v4.0.0, v3.3.1
Documentation-only deprecation.



Type: End-of-Life
The util.isBuffer() API has been removed. Please use
Buffer.isBuffer() instead.

DEP0047: util.isDate()#

History

VersionChanges
v23.0.0
End-of-Life deprecation.
v22.0.0
Runtime deprecation.
v6.12.0, v4.8.6
A deprecation code has been assigned.
v4.0.0, v3.3.1
Documentation-only deprecation.



Type: End-of-Life
The util.isDate() API has been removed. Please use
arg instanceof Date instead.

DEP0048: util.isError()#

History

VersionChanges
v23.0.0
End-of-Life deprecation.
v22.0.0
Runtime deprecation.
v6.12.0, v4.8.6
A deprecation code has been assigned.
v4.0.0, v3.3.1
Documentation-only deprecation.



Type: End-of-Life
The util.isError() API has been removed. Please use
Object.prototype.toString(arg) === '[object Error]' || arg instanceof Error
instead.

DEP0049: util.isFunction()#

History

VersionChanges
v23.0.0
End-of-Life deprecation.
v22.0.0
Runtime deprecation.
v6.12.0, v4.8.6
A deprecation code has been assigned.
v4.0.0, v3.3.1
Documentation-only deprecation.



Type: End-of-Life
The util.isFunction() API has been removed. Please use
typeof arg === 'function' instead.

DEP0050: util.isNull()#

History

VersionChanges
v23.0.0
End-of-Life deprecation.
v22.0.0
Runtime deprecation.
v6.12.0, v4.8.6
A deprecation code has been assigned.
v4.0.0, v3.3.1
Documentation-only deprecation.



Type: End-of-Life
The util.isNull() API has been removed. Please use
arg === null instead.

DEP0051: util.isNullOrUndefined()#

History

VersionChanges
v23.0.0
End-of-Life deprecation.
v22.0.0
Runtime deprecation.
v6.12.0, v4.8.6
A deprecation code has been assigned.
v4.0.0, v3.3.1
Documentation-only deprecation.



Type: End-of-Life
The util.isNullOrUndefined() API has been removed. Please use
arg === null || arg === undefined instead.

DEP0052: util.isNumber()#

History

VersionChanges
v23.0.0
End-of-Life deprecation.
v22.0.0
Runtime deprecation.
v6.12.0, v4.8.6
A deprecation code has been assigned.
v4.0.0, v3.3.1
Documentation-only deprecation.



Type: End-of-Life
The util.isNumber() API has been removed. Please use
typeof arg === 'number' instead.

DEP0053: util.isObject()#

History

VersionChanges
v23.0.0
End-of-Life deprecation.
v22.0.0
Runtime deprecation.
v6.12.0, v4.8.6
A deprecation code has been assigned.
v4.0.0, v3.3.1
Documentation-only deprecation.



Type: End-of-Life
The util.isObject() API has been removed. Please use
arg && typeof arg === 'object' instead.

DEP0054: util.isPrimitive()#

History

VersionChanges
v23.0.0
End-of-Life deprecation.
v22.0.0
Runtime deprecation.
v6.12.0, v4.8.6
A deprecation code has been assigned.
v4.0.0, v3.3.1
Documentation-only deprecation.



Type: End-of-Life
The util.isPrimitive() API has been removed. Please use
arg === null || (typeof arg !=='object' && typeof arg !== 'function')
instead.

DEP0055: util.isRegExp()#

History

VersionChanges
v23.0.0
End-of-Life deprecation.
v22.0.0
Runtime deprecation.
v6.12.0, v4.8.6
A deprecation code has been assigned.
v4.0.0, v3.3.1
Documentation-only deprecation.



Type: End-of-Life
The util.isRegExp() API has been removed. Please use
arg instanceof RegExp instead.

DEP0056: util.isString()#

History

VersionChanges
v23.0.0
End-of-Life deprecation.
v22.0.0
Runtime deprecation.
v6.12.0, v4.8.6
A deprecation code has been assigned.
v4.0.0, v3.3.1
Documentation-only deprecation.



Type: End-of-Life
The util.isString() API has been removed. Please use
typeof arg === 'string' instead.

DEP0057: util.isSymbol()#

History

VersionChanges
v23.0.0
End-of-Life deprecation.
v22.0.0
Runtime deprecation.
v6.12.0, v4.8.6
A deprecation code has been assigned.
v4.0.0, v3.3.1
Documentation-only deprecation.



Type: End-of-Life
The util.isSymbol() API has been removed. Please use
typeof arg === 'symbol' instead.

DEP0058: util.isUndefined()#

History

VersionChanges
v23.0.0
End-of-Life deprecation.
v22.0.0
Runtime deprecation.
v6.12.0, v4.8.6
A deprecation code has been assigned.
v4.0.0, v3.3.1
Documentation-only deprecation.



Type: End-of-Life
The util.isUndefined() API has been removed. Please use
arg === undefined instead.

DEP0059: util.log()#

History

VersionChanges
v23.0.0
End-of-Life deprecation.
v22.0.0
Runtime deprecation.
v6.12.0
A deprecation code has been assigned.
v6.0.0
Documentation-only deprecation.



Type: End-of-Life
The util.log() API has been removed because it's an unmaintained
legacy API that was exposed to user land by accident. Instead,
consider the following alternatives based on your specific needs:


Third-Party Logging Libraries


Use console.log(new Date().toLocaleString(), message)


By adopting one of these alternatives, you can transition away from util.log()
and choose a logging strategy that aligns with the specific
requirements and complexity of your application.

DEP0060: util._extend()#

History

VersionChanges
v22.0.0
Runtime deprecation.
v6.12.0
A deprecation code has been assigned.
v6.0.0
Documentation-only deprecation.



Type: Runtime
The util._extend() API is deprecated because it's an unmaintained
legacy API that was exposed to user land by accident.
Please use target = Object.assign(target, source) instead.

DEP0061: fs.SyncWriteStream#

History

VersionChanges
v11.0.0
End-of-Life.
v8.0.0
Runtime deprecation.
v7.0.0
Documentation-only deprecation.



Type: End-of-Life
The fs.SyncWriteStream class was never intended to be a publicly accessible
API and has been removed. No alternative API is available. Please use a userland
alternative.

DEP0062: node --debug#

History

VersionChanges
v12.0.0
End-of-Life.
v8.0.0
Runtime deprecation.



Type: End-of-Life
--debug activates the legacy V8 debugger interface, which was removed as
of V8 5.8. It is replaced by Inspector which is activated with --inspect
instead.

DEP0063: ServerResponse.prototype.writeHeader()#

History

VersionChanges
v8.0.0
Documentation-only deprecation.



Type: Documentation-only
The node:http module ServerResponse.prototype.writeHeader() API is
deprecated. Please use ServerResponse.prototype.writeHead() instead.
The ServerResponse.prototype.writeHeader() method was never documented as an
officially supported API.

DEP0064: tls.createSecurePair()#

History

VersionChanges
v24.0.0
End-of-Life.
v8.0.0
Runtime deprecation.
v6.12.0
A deprecation code has been assigned.
v6.0.0
Documentation-only deprecation.
v0.11.15
Deprecation revoked.
v0.11.3
Runtime deprecation.



Type: End-of-Life
The tls.createSecurePair() API was deprecated in documentation in Node.js
0.11.3. Users should use tls.Socket instead.

DEP0065: repl.REPL_MODE_MAGIC and NODE_REPL_MODE=magic#

History

VersionChanges
v10.0.0
End-of-Life.
v8.0.0
Documentation-only deprecation.



Type: End-of-Life
The node:repl module's REPL_MODE_MAGIC constant, used for replMode option,
has been removed. Its behavior has been functionally identical to that of
REPL_MODE_SLOPPY since Node.js 6.0.0, when V8 5.0 was imported. Please use
REPL_MODE_SLOPPY instead.
The NODE_REPL_MODE environment variable is used to set the underlying
replMode of an interactive node session. Its value, magic, is also
removed. Please use sloppy instead.

DEP0066: OutgoingMessage.prototype._headers, OutgoingMessage.prototype._headerNames#

History

VersionChanges
v24.0.0
End-of-Life.
v12.0.0
Runtime deprecation.
v8.0.0
Documentation-only deprecation.



Type: End-of-Life
The node:http module OutgoingMessage.prototype._headers and
OutgoingMessage.prototype._headerNames properties are deprecated. Use one of
the public methods (e.g. OutgoingMessage.prototype.getHeader(),
OutgoingMessage.prototype.getHeaders(),
OutgoingMessage.prototype.getHeaderNames(),
OutgoingMessage.prototype.getRawHeaderNames(),
OutgoingMessage.prototype.hasHeader(),
OutgoingMessage.prototype.removeHeader(),
OutgoingMessage.prototype.setHeader()) for working with outgoing headers.
The OutgoingMessage.prototype._headers and
OutgoingMessage.prototype._headerNames properties were never documented as
officially supported properties.

DEP0067: OutgoingMessage.prototype._renderHeaders#

History

VersionChanges
v8.0.0
Documentation-only deprecation.



Type: Documentation-only
The node:http module OutgoingMessage.prototype._renderHeaders() API is
deprecated.
The OutgoingMessage.prototype._renderHeaders property was never documented as
an officially supported API.

DEP0068: node debug#

History

VersionChanges
v15.0.0
The legacy node debug command was removed.
v8.0.0
Runtime deprecation.



Type: End-of-Life
node debug corresponds to the legacy CLI debugger which has been replaced with
a V8-inspector based CLI debugger available through node inspect.

DEP0069: vm.runInDebugContext(string)#

History

VersionChanges
v10.0.0
End-of-Life.
v9.0.0
Runtime deprecation.
v8.0.0
Documentation-only deprecation.



Type: End-of-Life
DebugContext has been removed in V8 and is not available in Node.js 10+.
DebugContext was an experimental API.

DEP0070: async_hooks.currentId()#

History

VersionChanges
v9.0.0
End-of-Life.
v8.2.0
Runtime deprecation.



Type: End-of-Life
async_hooks.currentId() was renamed to async_hooks.executionAsyncId() for
clarity.
This change was made while async_hooks was an experimental API.

DEP0071: async_hooks.triggerId()#

History

VersionChanges
v9.0.0
End-of-Life.
v8.2.0
Runtime deprecation.



Type: End-of-Life
async_hooks.triggerId() was renamed to async_hooks.triggerAsyncId() for
clarity.
This change was made while async_hooks was an experimental API.

DEP0072: async_hooks.AsyncResource.triggerId()#

History

VersionChanges
v9.0.0
End-of-Life.
v8.2.0
Runtime deprecation.



Type: End-of-Life
async_hooks.AsyncResource.triggerId() was renamed to
async_hooks.AsyncResource.triggerAsyncId() for clarity.
This change was made while async_hooks was an experimental API.

DEP0073: Several internal properties of net.Server#

History

VersionChanges
v10.0.0
End-of-Life.
v9.0.0
Runtime deprecation.



Type: End-of-Life
Accessing several internal, undocumented properties of net.Server instances
with inappropriate names is deprecated.
As the original API was undocumented and not generally useful for non-internal
code, no replacement API is provided.

DEP0074: REPLServer.bufferedCommand#

History

VersionChanges
v15.0.0
End-of-Life.
v9.0.0
Runtime deprecation.



Type: End-of-Life
The REPLServer.bufferedCommand property was deprecated in favor of
REPLServer.clearBufferedCommand().

DEP0075: REPLServer.parseREPLKeyword()#

History

VersionChanges
v15.0.0
End-of-Life.
v9.0.0
Runtime deprecation.



Type: End-of-Life
REPLServer.parseREPLKeyword() was removed from userland visibility.

DEP0076: tls.parseCertString()#

History

VersionChanges
v18.0.0
End-of-Life.
v9.0.0
Runtime deprecation.
v8.6.0
Documentation-only deprecation.



Type: End-of-Life
tls.parseCertString() was a trivial parsing helper that was made public by
mistake. While it was supposed to parse certificate subject and issuer strings,
it never handled multi-value Relative Distinguished Names correctly.
Earlier versions of this document suggested using querystring.parse() as an
alternative to tls.parseCertString(). However, querystring.parse() also does
not handle all certificate subjects correctly and should not be used.

DEP0077: Module._debug()#

History

VersionChanges
v9.0.0
Runtime deprecation.



Type: Runtime
Module._debug() is deprecated.
The Module._debug() function was never documented as an officially
supported API.

DEP0078: REPLServer.turnOffEditorMode()#

History

VersionChanges
v15.0.0
End-of-Life.
v9.0.0
Runtime deprecation.



Type: End-of-Life
REPLServer.turnOffEditorMode() was removed from userland visibility.

DEP0079: Custom inspection function on objects via .inspect()#

History

VersionChanges
v11.0.0
End-of-Life.
v10.0.0
Runtime deprecation.
v8.7.0
Documentation-only deprecation.



Type: End-of-Life
Using a property named inspect on an object to specify a custom inspection
function for util.inspect() is deprecated. Use util.inspect.custom
instead. For backward compatibility with Node.js prior to version 6.4.0, both
can be specified.

DEP0080: path._makeLong()#

History

VersionChanges
v9.0.0
Documentation-only deprecation.



Type: Documentation-only
The internal path._makeLong() was not intended for public use. However,
userland modules have found it useful. The internal API is deprecated
and replaced with an identical, public path.toNamespacedPath() method.

DEP0081: fs.truncate() using a file descriptor#

History

VersionChanges
v24.0.0
End-of-Life.
v9.0.0
Runtime deprecation.



Type: End-of-Life
fs.truncate() fs.truncateSync() usage with a file descriptor is
deprecated. Please use fs.ftruncate() or fs.ftruncateSync() to work with
file descriptors.

DEP0082: REPLServer.prototype.memory()#

History

VersionChanges
v15.0.0
End-of-Life.
v9.0.0
Runtime deprecation.



Type: End-of-Life
REPLServer.prototype.memory() is only necessary for the internal mechanics of
the REPLServer itself. Do not use this function.

DEP0083: Disabling ECDH by setting ecdhCurve to false#

History

VersionChanges
v10.0.0
End-of-Life.
v9.2.0
Runtime deprecation.



Type: End-of-Life
The ecdhCurve option to tls.createSecureContext() and tls.TLSSocket could
be set to false to disable ECDH entirely on the server only. This mode was
deprecated in preparation for migrating to OpenSSL 1.1.0 and consistency with
the client and is now unsupported. Use the ciphers parameter instead.

DEP0084: requiring bundled internal dependencies#

History

VersionChanges
v12.0.0
This functionality has been removed.
v10.0.0
Runtime deprecation.



Type: End-of-Life
Since Node.js versions 4.4.0 and 5.2.0, several modules only intended for
internal usage were mistakenly exposed to user code through require(). These
modules were:

v8/tools/codemap
v8/tools/consarray
v8/tools/csvparser
v8/tools/logreader
v8/tools/profile_view
v8/tools/profile
v8/tools/SourceMap
v8/tools/splaytree
v8/tools/tickprocessor-driver
v8/tools/tickprocessor
node-inspect/lib/_inspect (from 7.6.0)
node-inspect/lib/internal/inspect_client (from 7.6.0)
node-inspect/lib/internal/inspect_repl (from 7.6.0)

The v8/* modules do not have any exports, and if not imported in a specific
order would in fact throw errors. As such there are virtually no legitimate use
cases for importing them through require().
On the other hand, node-inspect can be installed locally through a package
manager, as it is published on the npm registry under the same name. No source
code modification is necessary if that is done.

DEP0085: AsyncHooks sensitive API#

History

VersionChanges
v10.0.0
End-of-Life.
v9.4.0, v8.10.0
Runtime deprecation.



Type: End-of-Life
The AsyncHooks sensitive API was never documented and had various minor issues.
Use the AsyncResource API instead. See
https://github.com/nodejs/node/issues/15572.

DEP0086: Remove runInAsyncIdScope#

History

VersionChanges
v10.0.0
End-of-Life.
v9.4.0, v8.10.0
Runtime deprecation.



Type: End-of-Life
runInAsyncIdScope doesn't emit the 'before' or 'after' event and can thus
cause a lot of issues. See https://github.com/nodejs/node/issues/14328.



DEP0089: require('node:assert')#

History

VersionChanges
v12.8.0
Deprecation revoked.
v9.9.0, v8.13.0
Documentation-only deprecation.



Type: Deprecation revoked
Importing assert directly was not recommended as the exposed functions use
loose equality checks. The deprecation was revoked because use of the
node:assert module is not discouraged, and the deprecation caused developer
confusion.

DEP0090: Invalid GCM authentication tag lengths#

History

VersionChanges
v11.0.0
End-of-Life.
v10.0.0
Runtime deprecation.



Type: End-of-Life
Node.js used to support all GCM authentication tag lengths which are accepted by
OpenSSL when calling decipher.setAuthTag(). Beginning with Node.js
v11.0.0, only authentication tag lengths of 128, 120, 112, 104, 96, 64, and 32
bits are allowed. Authentication tags of other lengths are invalid per
NIST SP 800-38D.

DEP0091: crypto.DEFAULT_ENCODING#

History

VersionChanges
v20.0.0
End-of-Life.
v10.0.0
Runtime deprecation.



Type: End-of-Life
The crypto.DEFAULT_ENCODING property only existed for compatibility with
Node.js releases prior to versions 0.9.3 and has been removed.

DEP0092: Top-level this bound to module.exports#

History

VersionChanges
v10.0.0
Documentation-only deprecation.



Type: Documentation-only
Assigning properties to the top-level this as an alternative
to module.exports is deprecated. Developers should use exports
or module.exports instead.

DEP0093: crypto.fips is deprecated and replaced#

History

VersionChanges
v23.0.0
Runtime deprecation.
v10.0.0
Documentation-only deprecation.



Type: Runtime
The crypto.fips property is deprecated. Please use crypto.setFips()
and crypto.getFips() instead.

DEP0094: Using assert.fail() with more than one argument#

History

VersionChanges
v10.0.0
Runtime deprecation.



Type: Runtime
Using assert.fail() with more than one argument is deprecated. Use
assert.fail() with only one argument or use a different node:assert module
method.

DEP0095: timers.enroll()#

History

VersionChanges
v24.0.0
End-of-Life.
v10.0.0
Runtime deprecation.



Type: End-of-Life
timers.enroll() has been removed. Please use the publicly documented
setTimeout() or setInterval() instead.

DEP0096: timers.unenroll()#

History

VersionChanges
v24.0.0
End-of-Life.
v10.0.0
Runtime deprecation.



Type: End-of-Life
timers.unenroll() has been removed. Please use the publicly documented
clearTimeout() or clearInterval() instead.

DEP0097: MakeCallback with domain property#

History

VersionChanges
v10.0.0
Runtime deprecation.



Type: Runtime
Users of MakeCallback that add the domain property to carry context,
should start using the async_context variant of MakeCallback or
CallbackScope, or the high-level AsyncResource class.

DEP0098: AsyncHooks embedder AsyncResource.emitBefore and AsyncResource.emitAfter APIs#

History

VersionChanges
v12.0.0
End-of-Life.
v10.0.0, v9.6.0, v8.12.0
Runtime deprecation.



Type: End-of-Life
The embedded API provided by AsyncHooks exposes .emitBefore() and
.emitAfter() methods which are very easy to use incorrectly which can lead
to unrecoverable errors.
Use asyncResource.runInAsyncScope() API instead which provides a much
safer, and more convenient, alternative. See
https://github.com/nodejs/node/pull/18513.

DEP0099: Async context-unaware node::MakeCallback C++ APIs#

History

VersionChanges
v10.0.0
Compile-time deprecation.



Type: Compile-time
Certain versions of node::MakeCallback APIs available to native addons are
deprecated. Please use the versions of the API that accept an async_context
parameter.

DEP0100: process.assert()#

History

VersionChanges
v23.0.0
End-of-Life.
v10.0.0
Runtime deprecation.
v0.3.7
Documentation-only deprecation.



Type: End-of-Life
process.assert() is deprecated. Please use the assert module instead.
This was never a documented feature.

DEP0101: --with-lttng#

History

VersionChanges
v10.0.0
End-of-Life.



Type: End-of-Life
The --with-lttng compile-time option has been removed.

DEP0102: Using noAssert in Buffer#(read|write) operations#

History

VersionChanges
v10.0.0
End-of-Life.



Type: End-of-Life
Using the noAssert argument has no functionality anymore. All input is
verified regardless of the value of noAssert. Skipping the verification
could lead to hard-to-find errors and crashes.

DEP0103: process.binding('util').is[...] typechecks#

History

VersionChanges
v10.9.0
Superseded by DEP0111.
v10.0.0
Documentation-only deprecation.



Type: Documentation-only (supports --pending-deprecation)
Using process.binding() in general should be avoided. The type checking
methods in particular can be replaced by using util.types.
This deprecation has been superseded by the deprecation of the
process.binding() API (DEP0111).

DEP0104: process.env string coercion#

History

VersionChanges
v10.0.0
Documentation-only deprecation with --pending-deprecation support.



Type: Documentation-only (supports --pending-deprecation)
When assigning a non-string property to process.env, the assigned value is
implicitly converted to a string. This behavior is deprecated if the assigned
value is not a string, boolean, or number. In the future, such assignment might
result in a thrown error. Please convert the property to a string before
assigning it to process.env.

DEP0105: decipher.finaltol#

History

VersionChanges
v11.0.0
End-of-Life.
v10.0.0
Runtime deprecation.



Type: End-of-Life
decipher.finaltol() has never been documented and was an alias for
decipher.final(). This API has been removed, and it is recommended to use
decipher.final() instead.

DEP0106: crypto.createCipher and crypto.createDecipher#

History

VersionChanges
v22.0.0
End-of-Life.
v11.0.0
Runtime deprecation.
v10.0.0
Documentation-only deprecation.



Type: End-of-Life
crypto.createCipher() and crypto.createDecipher() have been removed
as they use a weak key derivation function (MD5 with no salt) and static
initialization vectors.
It is recommended to derive a key using
crypto.pbkdf2() or crypto.scrypt() with random salts and to use
crypto.createCipheriv() and crypto.createDecipheriv() to obtain the
Cipheriv and Decipheriv objects respectively.

DEP0107: tls.convertNPNProtocols()#

History

VersionChanges
v11.0.0
End-of-Life.
v10.0.0
Runtime deprecation.



Type: End-of-Life
This was an undocumented helper function not intended for use outside Node.js
core and obsoleted by the removal of NPN (Next Protocol Negotiation) support.

DEP0108: zlib.bytesRead#

History

VersionChanges
v23.0.0
End-of-Life.
v11.0.0
Runtime deprecation.
v10.0.0
Documentation-only deprecation.



Type: End-of-Life
Deprecated alias for zlib.bytesWritten. This original name was chosen
because it also made sense to interpret the value as the number of bytes
read by the engine, but is inconsistent with other streams in Node.js that
expose values under these names.

DEP0109: http, https, and tls support for invalid URLs#

History

VersionChanges
v16.0.0
End-of-Life.
v11.0.0
Runtime deprecation.



Type: End-of-Life
Some previously supported (but strictly invalid) URLs were accepted through the
http.request(), http.get(), https.request(),
https.get(), and tls.checkServerIdentity() APIs because those were
accepted by the legacy url.parse() API. The mentioned APIs now use the WHATWG
URL parser that requires strictly valid URLs. Passing an invalid URL is
deprecated and support will be removed in the future.

DEP0110: vm.Script cached data#

History

VersionChanges
v10.6.0
Documentation-only deprecation.



Type: Documentation-only
The produceCachedData option is deprecated. Use
script.createCachedData() instead.

DEP0111: process.binding()#

History

VersionChanges
v11.12.0
Added support for --pending-deprecation.
v10.9.0
Documentation-only deprecation.



Type: Documentation-only (supports --pending-deprecation)
process.binding() is for use by Node.js internal code only.
While process.binding() has not reached End-of-Life status in general, it is
unavailable when the permission model is enabled.

DEP0112: dgram private APIs#

History

VersionChanges
v11.0.0
Runtime deprecation.



Type: Runtime
The node:dgram module previously contained several APIs that were never meant
to accessed outside of Node.js core: Socket.prototype._handle,
Socket.prototype._receiving, Socket.prototype._bindState,
Socket.prototype._queue, Socket.prototype._reuseAddr,
Socket.prototype._healthCheck(), Socket.prototype._stopReceiving(), and
dgram._createSocketHandle().

DEP0113: Cipher.setAuthTag(), Decipher.getAuthTag()#

History

VersionChanges
v12.0.0
End-of-Life.
v11.0.0
Runtime deprecation.



Type: End-of-Life
Cipher.setAuthTag() and Decipher.getAuthTag() are no longer available. They
were never documented and would throw when called.

DEP0114: crypto._toBuf()#

History

VersionChanges
v12.0.0
End-of-Life.
v11.0.0
Runtime deprecation.



Type: End-of-Life
The crypto._toBuf() function was not designed to be used by modules outside
of Node.js core and was removed.


DEP0115: crypto.prng(), crypto.pseudoRandomBytes(), crypto.rng()#

History

VersionChanges
v11.0.0
Documentation-only deprecation with --pending-deprecation support.



Type: Documentation-only (supports --pending-deprecation)

In recent versions of Node.js, there is no difference between
crypto.randomBytes() and crypto.pseudoRandomBytes(). The latter is
deprecated along with the undocumented aliases crypto.prng() and
crypto.rng() in favor of crypto.randomBytes() and might be removed in a
future release.

DEP0116: Legacy URL API#

History

VersionChanges
v19.0.0, v18.13.0
`url.parse()` is deprecated again in DEP0169.
v15.13.0, v14.17.0
Deprecation revoked. Status changed to "Legacy".
v11.0.0
Documentation-only deprecation.



Type: Deprecation revoked
The legacy URL API is deprecated. This includes url.format(),
url.parse(), url.resolve(), and the legacy urlObject. Please
use the WHATWG URL API instead.

DEP0117: Native crypto handles#

History

VersionChanges
v12.0.0
End-of-Life.
v11.0.0
Runtime deprecation.



Type: End-of-Life
Previous versions of Node.js exposed handles to internal native objects through
the _handle property of the Cipher, Decipher, DiffieHellman,
DiffieHellmanGroup, ECDH, Hash, Hmac, Sign, and Verify classes.
The _handle property has been removed because improper use of the native
object can lead to crashing the application.

DEP0118: dns.lookup() support for a falsy host name#

History

VersionChanges
v11.0.0
Runtime deprecation.



Type: Runtime
Previous versions of Node.js supported dns.lookup() with a falsy host name
like dns.lookup(false) due to backward compatibility.
This behavior is undocumented and is thought to be unused in real world apps.
It will become an error in future versions of Node.js.

DEP0119: process.binding('uv').errname() private API#

History

VersionChanges
v11.0.0
Documentation-only deprecation with --pending-deprecation support.



Type: Documentation-only (supports --pending-deprecation)
process.binding('uv').errname() is deprecated. Please use
util.getSystemErrorName() instead.

DEP0120: Windows Performance Counter support#

History

VersionChanges
v12.0.0
End-of-Life.
v11.0.0
Runtime deprecation.



Type: End-of-Life
Windows Performance Counter support has been removed from Node.js. The
undocumented COUNTER_NET_SERVER_CONNECTION(),
COUNTER_NET_SERVER_CONNECTION_CLOSE(), COUNTER_HTTP_SERVER_REQUEST(),
COUNTER_HTTP_SERVER_RESPONSE(), COUNTER_HTTP_CLIENT_REQUEST(), and
COUNTER_HTTP_CLIENT_RESPONSE() functions have been deprecated.

DEP0121: net._setSimultaneousAccepts()#

History

VersionChanges
v24.0.0
End-of-Life.
v12.0.0
Runtime deprecation.



Type: End-of-Life
The undocumented net._setSimultaneousAccepts() function was originally
intended for debugging and performance tuning when using the
node:child_process and node:cluster modules on Windows. The function is not
generally useful and is being removed. See discussion here:
https://github.com/nodejs/node/issues/18391

DEP0122: tls Server.prototype.setOptions()#

History

VersionChanges
v24.0.0
End-of-Life.
v12.0.0
Runtime deprecation.



Type: End-of-Life
Please use Server.prototype.setSecureContext() instead.

DEP0123: setting the TLS ServerName to an IP address#

History

VersionChanges
v12.0.0
Runtime deprecation.



Type: Runtime
Setting the TLS ServerName to an IP address is not permitted by
RFC 6066. This will be ignored in a future version.

DEP0124: using REPLServer.rli#

History

VersionChanges
v15.0.0
End-of-Life.
v12.0.0
Runtime deprecation.



Type: End-of-Life
This property is a reference to the instance itself.

DEP0125: require('node:_stream_wrap')#

History

VersionChanges
v12.0.0
Runtime deprecation.



Type: Runtime
The node:_stream_wrap module is deprecated.

DEP0126: timers.active()#

History

VersionChanges
v24.0.0
End-of-Life.
v11.14.0
Runtime deprecation.



Type: End-of-Life
The previously undocumented timers.active() has been removed.
Please use the publicly documented timeout.refresh() instead.
If re-referencing the timeout is necessary, timeout.ref() can be used
with no performance impact since Node.js 10.

DEP0127: timers._unrefActive()#

History

VersionChanges
v24.0.0
End-of-Life.
v11.14.0
Runtime deprecation.



Type: End-of-Life
The previously undocumented and "private" timers._unrefActive() has been removed.
Please use the publicly documented timeout.refresh() instead.
If unreferencing the timeout is necessary, timeout.unref() can be used
with no performance impact since Node.js 10.

DEP0128: modules with an invalid main entry and an index.js file#

History

VersionChanges
v16.0.0
Runtime deprecation.
v12.0.0
Documentation-only.



Type: Runtime
Modules that have an invalid main entry (e.g., ./does-not-exist.js) and
also have an index.js file in the top level directory will resolve the
index.js file. That is deprecated and is going to throw an error in future
Node.js versions.

DEP0129: ChildProcess._channel#

History

VersionChanges
v13.0.0
Runtime deprecation.
v11.14.0
Documentation-only.



Type: Runtime
The _channel property of child process objects returned by spawn() and
similar functions is not intended for public use. Use ChildProcess.channel
instead.

DEP0130: Module.createRequireFromPath()#

History

VersionChanges
v16.0.0
End-of-life.
v13.0.0
Runtime deprecation.
v12.2.0
Documentation-only.



Type: End-of-Life
Use module.createRequire() instead.

DEP0131: Legacy HTTP parser#

History

VersionChanges
v13.0.0
This feature has been removed.
v12.22.0
Runtime deprecation.
v12.3.0
Documentation-only.



Type: End-of-Life
The legacy HTTP parser, used by default in versions of Node.js prior to 12.0.0,
is deprecated and has been removed in v13.0.0. Prior to v13.0.0, the
--http-parser=legacy command-line flag could be used to revert to using the
legacy parser.

DEP0132: worker.terminate() with callback#

History

VersionChanges
v12.5.0
Runtime deprecation.



Type: Runtime
Passing a callback to worker.terminate() is deprecated. Use the returned
Promise instead, or a listener to the worker's 'exit' event.

DEP0133: http connection#

History

VersionChanges
v12.12.0
Documentation-only deprecation.



Type: Documentation-only
Prefer response.socket over response.connection and
request.socket over request.connection.

DEP0134: process._tickCallback#

History

VersionChanges
v12.12.0
Documentation-only deprecation with --pending-deprecation support.



Type: Documentation-only (supports --pending-deprecation)
The process._tickCallback property was never documented as
an officially supported API.

DEP0135: WriteStream.open() and ReadStream.open() are internal#

History

VersionChanges
v13.0.0
Runtime deprecation.



Type: Runtime
WriteStream.open() and ReadStream.open() are undocumented internal
APIs that do not make sense to use in userland. File streams should always be
opened through their corresponding factory methods fs.createWriteStream()
and fs.createReadStream()) or by passing a file descriptor in options.

DEP0136: http finished#

History

VersionChanges
v13.4.0, v12.16.0
Documentation-only deprecation.



Type: Documentation-only
response.finished indicates whether response.end() has been
called, not whether 'finish' has been emitted and the underlying data
is flushed.
Use response.writableFinished or response.writableEnded
accordingly instead to avoid the ambiguity.
To maintain existing behavior response.finished should be replaced with
response.writableEnded.

DEP0137: Closing fs.FileHandle on garbage collection#

History

VersionChanges
v14.0.0
Runtime deprecation.



Type: Runtime
Allowing a fs.FileHandle object to be closed on garbage collection is
deprecated. In the future, doing so might result in a thrown error that will
terminate the process.
Please ensure that all fs.FileHandle objects are explicitly closed using
FileHandle.prototype.close() when the fs.FileHandle is no longer needed:
const fsPromises = require('node:fs').promises;
async function openAndClose() {
  let filehandle;
  try {
    filehandle = await fsPromises.open('thefile.txt', 'r');
  } finally {
    if (filehandle !== undefined)
      await filehandle.close();
  }
} copy

DEP0138: process.mainModule#

History

VersionChanges
v14.0.0
Documentation-only deprecation.



Type: Documentation-only
process.mainModule is a CommonJS-only feature while process global
object is shared with non-CommonJS environment. Its use within ECMAScript
modules is unsupported.
It is deprecated in favor of require.main, because it serves the same
purpose and is only available on CommonJS environment.

DEP0139: process.umask() with no arguments#

History

VersionChanges
v14.0.0, v12.19.0
Documentation-only deprecation.



Type: Documentation-only
Calling process.umask() with no argument causes the process-wide umask to be
written twice. This introduces a race condition between threads, and is a
potential security vulnerability. There is no safe, cross-platform alternative
API.

DEP0140: Use request.destroy() instead of request.abort()#

History

VersionChanges
v14.1.0, v13.14.0
Documentation-only deprecation.



Type: Documentation-only
Use request.destroy() instead of request.abort().

DEP0141: repl.inputStream and repl.outputStream#

History

VersionChanges
v14.3.0
Documentation-only deprecation with --pending-deprecation support.



Type: Documentation-only (supports --pending-deprecation)
The node:repl module exported the input and output stream twice. Use .input
instead of .inputStream and .output instead of .outputStream.

DEP0142: repl._builtinLibs#

History

VersionChanges
v14.3.0
Documentation-only deprecation with --pending-deprecation support.



Type: Documentation-only (supports --pending-deprecation)
The node:repl module exports a _builtinLibs property that contains an array
of built-in modules. It was incomplete so far and instead it's better to rely
upon require('node:module').builtinModules.

DEP0143: Transform._transformState#

History

VersionChanges
v14.5.0
Runtime deprecation.



Type: Runtime
Transform._transformState will be removed in future versions where it is
no longer required due to simplification of the implementation.

DEP0144: module.parent#

History

VersionChanges
v14.6.0, v12.19.0
Documentation-only deprecation.



Type: Documentation-only (supports --pending-deprecation)
A CommonJS module can access the first module that required it using
module.parent. This feature is deprecated because it does not work
consistently in the presence of ECMAScript modules and because it gives an
inaccurate representation of the CommonJS module graph.
Some modules use it to check if they are the entry point of the current process.
Instead, it is recommended to compare require.main and module:
if (require.main === module) {
  // Code section that will run only if current file is the entry point.
} copy
When looking for the CommonJS modules that have required the current one,
require.cache and module.children can be used:
const moduleParents = Object.values(require.cache)
  .filter((m) => m.children.includes(module)); copy

DEP0145: socket.bufferSize#

History

VersionChanges
v14.6.0
Documentation-only deprecation.



Type: Documentation-only
socket.bufferSize is just an alias for writable.writableLength.

DEP0146: new crypto.Certificate()#

History

VersionChanges
v14.9.0
Documentation-only deprecation.



Type: Documentation-only
The crypto.Certificate() constructor is deprecated. Use
static methods of crypto.Certificate() instead.

DEP0147: fs.rmdir(path, { recursive: true })#

History

VersionChanges
v16.0.0
Runtime deprecation.
v15.0.0
Runtime deprecation for permissive behavior.
v14.14.0
Documentation-only deprecation.



Type: Runtime
In future versions of Node.js, recursive option will be ignored for
fs.rmdir, fs.rmdirSync, and fs.promises.rmdir.
Use fs.rm(path, { recursive: true, force: true }),
fs.rmSync(path, { recursive: true, force: true }) or
fs.promises.rm(path, { recursive: true, force: true }) instead.

DEP0148: Folder mappings in "exports" (trailing "/")#

History

VersionChanges
v17.0.0
End-of-Life.
v16.0.0
Runtime deprecation.
v15.1.0
Runtime deprecation for self-referencing imports.
v14.13.0
Documentation-only deprecation.



Type: End-of-Life
Using a trailing "/" to define subpath folder mappings in the
subpath exports or subpath imports fields is no longer supported.
Use subpath patterns instead.

DEP0149: http.IncomingMessage#connection#

History

VersionChanges
v16.0.0
Documentation-only deprecation.



Type: Documentation-only
Prefer message.socket over message.connection.

DEP0150: Changing the value of process.config#

History

VersionChanges
v19.0.0
End-of-Life.
v16.0.0
Runtime deprecation.



Type: End-of-Life
The process.config property provides access to Node.js compile-time settings.
However, the property is mutable and therefore subject to tampering. The ability
to change the value will be removed in a future version of Node.js.

DEP0151: Main index lookup and extension searching#

History

VersionChanges
v16.0.0
Runtime deprecation.
v15.8.0, v14.18.0
Documentation-only deprecation with --pending-deprecation support.



Type: Runtime
Previously, index.js and extension searching lookups would apply to
import 'pkg' main entry point resolution, even when resolving ES modules.
With this deprecation, all ES module main entry point resolutions require
an explicit "exports" or "main" entry with the exact file extension.

DEP0152: Extension PerformanceEntry properties#

History

VersionChanges
v16.0.0
Runtime deprecation.



Type: Runtime
The 'gc', 'http2', and 'http' <PerformanceEntry> object types have
additional properties assigned to them that provide additional information.
These properties are now available within the standard detail property
of the PerformanceEntry object. The existing accessors have been
deprecated and should no longer be used.

DEP0153: dns.lookup and dnsPromises.lookup options type coercion#

History

VersionChanges
v18.0.0
End-of-Life.
v17.0.0
Runtime deprecation.
v16.8.0
Documentation-only deprecation.



Type: End-of-Life
Using a non-nullish non-integer value for family option, a non-nullish
non-number value for hints option, a non-nullish non-boolean value for all
option, or a non-nullish non-boolean value for verbatim option in
dns.lookup() and dnsPromises.lookup() throws an
ERR_INVALID_ARG_TYPE error.

DEP0154: RSA-PSS generate key pair options#

History

VersionChanges
v20.0.0
Runtime deprecation.
v16.10.0
Documentation-only deprecation.



Type: Runtime
The 'hash' and 'mgf1Hash' options are replaced with 'hashAlgorithm'
and 'mgf1HashAlgorithm'.

DEP0155: Trailing slashes in pattern specifier resolutions#

History

VersionChanges
v17.0.0
Runtime deprecation.
v16.10.0
Documentation-only deprecation with --pending-deprecation support.



Type: Runtime
The remapping of specifiers ending in "/" like import 'pkg/x/' is deprecated
for package "exports" and "imports" pattern resolutions.

DEP0156: .aborted property and 'abort', 'aborted' event in http#

History

VersionChanges
v17.0.0, v16.12.0
Documentation-only deprecation.



Type: Documentation-only
Move to <Stream> API instead, as the http.ClientRequest,
http.ServerResponse, and http.IncomingMessage are all stream-based.
Check stream.destroyed instead of the .aborted property, and listen for
'close' instead of 'abort', 'aborted' event.
The .aborted property and 'abort' event are only useful for detecting
.abort() calls. For closing a request early, use the Stream
.destroy([error]) then check the .destroyed property and 'close' event
should have the same effect. The receiving end should also check the
readable.readableEnded value on http.IncomingMessage to get whether
it was an aborted or graceful destroy.

DEP0157: Thenable support in streams#

History

VersionChanges
v18.0.0
End-of-life.
v17.2.0, v16.14.0
Documentation-only deprecation.



Type: End-of-Life
An undocumented feature of Node.js streams was to support thenables in
implementation methods. This is now deprecated, use callbacks instead and avoid
use of async function for streams implementation methods.
This feature caused users to encounter unexpected problems where the user
implements the function in callback style but uses e.g. an async method which
would cause an error since mixing promise and callback semantics is not valid.
const w = new Writable({
  async final(callback) {
    await someOp();
    callback();
  },
}); copy

DEP0158: buffer.slice(start, end)#

History

VersionChanges
v17.5.0, v16.15.0
Documentation-only deprecation.



Type: Documentation-only
This method was deprecated because it is not compatible with
Uint8Array.prototype.slice(), which is a superclass of Buffer.
Use buffer.subarray which does the same thing instead.

DEP0159: ERR_INVALID_CALLBACK#

History

VersionChanges
v18.0.0
End-of-Life.



Type: End-of-Life
This error code was removed due to adding more confusion to
the errors used for value type validation.

DEP0160: process.on('multipleResolves', handler)#

History

VersionChanges
v18.0.0
Runtime deprecation.
v17.6.0, v16.15.0
Documentation-only deprecation.



Type: Runtime
This event was deprecated because it did not work with V8 promise combinators
which diminished its usefulness.

DEP0161: process._getActiveRequests() and process._getActiveHandles()#

History

VersionChanges
v17.6.0, v16.15.0
Documentation-only deprecation.



Type: Documentation-only
The process._getActiveHandles() and process._getActiveRequests()
functions are not intended for public use and can be removed in future
releases.
Use process.getActiveResourcesInfo() to get a list of types of active
resources and not the actual references.

DEP0162: fs.write(), fs.writeFileSync() coercion to string#

History

VersionChanges
v19.0.0
End-of-Life.
v18.0.0
Runtime deprecation.
v17.8.0, v16.15.0
Documentation-only deprecation.



Type: End-of-Life
Implicit coercion of objects with own toString property, passed as second
parameter in fs.write(), fs.writeFile(), fs.appendFile(),
fs.writeFileSync(), and fs.appendFileSync() is deprecated.
Convert them to primitive strings.

DEP0163: channel.subscribe(onMessage), channel.unsubscribe(onMessage)#

History

VersionChanges
v18.7.0, v16.17.0
Documentation-only deprecation.



Type: Documentation-only
These methods were deprecated because they can be used in a way which does not
hold the channel reference alive long enough to receive the events.
Use diagnostics_channel.subscribe(name, onMessage) or
diagnostics_channel.unsubscribe(name, onMessage) which does the same
thing instead.

DEP0164: process.exit(code), process.exitCode coercion to integer#

History

VersionChanges
v20.0.0
End-of-Life.
v19.0.0
Runtime deprecation.
v18.10.0, v16.18.0
Documentation-only deprecation of process.exitCode integer coercion.
v18.7.0, v16.17.0
Documentation-only deprecation of process.exit(code) integer coercion.



Type: End-of-Life
Values other than undefined, null, integer numbers, and integer strings
(e.g., '1') are deprecated as value for the code parameter in
process.exit() and as value to assign to process.exitCode.

DEP0165: --trace-atomics-wait#

History

VersionChanges
v23.0.0
End-of-Life.
v22.0.0
Runtime deprecation.
v18.8.0, v16.18.0
Documentation-only deprecation.



Type: End-of-Life
The --trace-atomics-wait flag has been removed because
it uses the V8 hook SetAtomicsWaitCallback,
that will be removed in a future V8 release.

DEP0166: Double slashes in imports and exports targets#

History

VersionChanges
v19.0.0
Runtime deprecation.
v18.10.0
Documentation-only deprecation with --pending-deprecation support.



Type: Runtime
Package imports and exports targets mapping into paths including a double slash
(of "/" or "\") are deprecated and will fail with a resolution validation
error in a future release. This same deprecation also applies to pattern matches
starting or ending in a slash.

DEP0167: Weak DiffieHellmanGroup instances (modp1, modp2, modp5)#

History

VersionChanges
v18.10.0, v16.18.0
Documentation-only deprecation.



Type: Documentation-only
The well-known MODP groups modp1, modp2, and modp5 are deprecated because
they are not secure against practical attacks. See RFC 8247 Section 2.4 for
details.
These groups might be removed in future versions of Node.js. Applications that
rely on these groups should evaluate using stronger MODP groups instead.

DEP0168: Unhandled exception in Node-API callbacks#

History

VersionChanges
v18.3.0, v16.17.0
Runtime deprecation.



Type: Runtime
The implicit suppression of uncaught exceptions in Node-API callbacks is now
deprecated.
Set the flag --force-node-api-uncaught-exceptions-policy to force Node.js
to emit an 'uncaughtException' event if the exception is not handled in
Node-API callbacks.

DEP0169: Insecure url.parse()#

History

VersionChanges
v24.0.0
Application deprecation.
v19.9.0, v18.17.0
Added support for --pending-deprecation.
v19.0.0, v18.13.0
Documentation-only deprecation.



Type: Application (non-node_modules code only)
url.parse() behavior is not standardized and prone to errors that
have security implications. Use the WHATWG URL API instead. CVEs are not
issued for url.parse() vulnerabilities.

DEP0170: Invalid port when using url.parse()#

History

VersionChanges
v20.0.0
Runtime deprecation.
v19.2.0, v18.13.0
Documentation-only deprecation.



Type: Runtime
url.parse() accepts URLs with ports that are not numbers. This behavior
might result in host name spoofing with unexpected input. These URLs will throw
an error in future versions of Node.js, as the WHATWG URL API does already.

DEP0171: Setters for http.IncomingMessage headers and trailers#

History

VersionChanges
v19.3.0, v18.13.0
Documentation-only deprecation.



Type: Documentation-only
In a future version of Node.js, message.headers,
message.headersDistinct, message.trailers, and
message.trailersDistinct will be read-only.

DEP0172: The asyncResource property of AsyncResource bound functions#

History

VersionChanges
v20.0.0
Runtime-deprecation.



Type: Runtime
In a future version of Node.js, the asyncResource property will no longer
be added when a function is bound to an AsyncResource.

DEP0173: the assert.CallTracker class#

History

VersionChanges
v20.1.0
Runtime deprecation.



Type: Runtime
In a future version of Node.js, assert.CallTracker,
will be removed.
Consider using alternatives such as the mock helper function.

DEP0174: calling promisify on a function that returns a Promise#

History

VersionChanges
v21.0.0
Runtime deprecation.
v20.8.0
Documentation-only deprecation.



Type: Runtime
Calling util.promisify on a function that returns a Promise will ignore
the result of said promise, which can lead to unhandled promise rejections.

DEP0175: util.toUSVString#

History

VersionChanges
v20.8.0
Documentation-only deprecation.



Type: Documentation-only
The util.toUSVString() API is deprecated. Please use
String.prototype.toWellFormed instead.

DEP0176: fs.F_OK, fs.R_OK, fs.W_OK, fs.X_OK#

History

VersionChanges
v24.0.0
Runtime deprecation.
v20.8.0
Documentation-only deprecation.



Type: Runtime
F_OK, R_OK, W_OK and X_OK getters exposed directly on node:fs are
deprecated. Get them from fs.constants or fs.promises.constants instead.

DEP0177: util.types.isWebAssemblyCompiledModule#

History

VersionChanges
v21.7.0, v20.12.0
End-of-Life.
v21.3.0, v20.11.0
A deprecation code has been assigned.
v14.0.0
Documentation-only deprecation.



Type: End-of-Life
The util.types.isWebAssemblyCompiledModule API has been removed.
Please use value instanceof WebAssembly.Module instead.

DEP0178: dirent.path#

History

VersionChanges
v24.0.0
End-of-Life.
v23.0.0
Runtime deprecation.
v21.5.0, v20.12.0, v18.20.0
Documentation-only deprecation.



Type: End-of-Life
The dirent.path property has been removed due to its lack of consistency across
release lines. Please use dirent.parentPath instead.

DEP0179: Hash constructor#

History

VersionChanges
v22.0.0
Runtime deprecation.
v21.5.0, v20.12.0
Documentation-only deprecation.



Type: Runtime
Calling Hash class directly with Hash() or new Hash() is
deprecated due to being internals, not intended for public use.
Please use the crypto.createHash() method to create Hash instances.

DEP0180: fs.Stats constructor#

History

VersionChanges
v22.0.0
Runtime deprecation.
v20.13.0
Documentation-only deprecation.



Type: Runtime
Calling fs.Stats class directly with Stats() or new Stats() is
deprecated due to being internals, not intended for public use.

DEP0181: Hmac constructor#

History

VersionChanges
v22.0.0
Runtime deprecation.
v20.13.0
Documentation-only deprecation.



Type: Runtime
Calling Hmac class directly with Hmac() or new Hmac() is
deprecated due to being internals, not intended for public use.
Please use the crypto.createHmac() method to create Hmac instances.

DEP0182: Short GCM authentication tags without explicit authTagLength#

History

VersionChanges
v23.0.0
Runtime deprecation.
v20.13.0
Documentation-only deprecation.



Type: Runtime
Applications that intend to use authentication tags that are shorter than the
default authentication tag length must set the authTagLength option of the
crypto.createDecipheriv() function to the appropriate length.
For ciphers in GCM mode, the decipher.setAuthTag() function accepts
authentication tags of any valid length (see DEP0090). This behavior
is deprecated to better align with recommendations per NIST SP 800-38D.

DEP0183: OpenSSL engine-based APIs#

History

VersionChanges
v22.4.0, v20.16.0
Documentation-only deprecation.



Type: Documentation-only
OpenSSL 3 has deprecated support for custom engines with a recommendation to
switch to its new provider model. The clientCertEngine option for
https.request(), tls.createSecureContext(), and tls.createServer();
the privateKeyEngine and privateKeyIdentifier for tls.createSecureContext();
and crypto.setEngine() all depend on this functionality from OpenSSL.

DEP0184: Instantiating node:zlib classes without new#

History

VersionChanges
v24.0.0
Runtime deprecation.
v22.9.0, v20.18.0
Documentation-only deprecation.



Type: Runtime
Instantiating classes without the new qualifier exported by the node:zlib module is deprecated.
It is recommended to use the new qualifier instead. This applies to all Zlib classes, such as Deflate,
DeflateRaw, Gunzip, Inflate, InflateRaw, Unzip, and Zlib.

DEP0185: Instantiating node:repl classes without new#

History

VersionChanges
v24.0.0
Runtime deprecation.
v22.9.0, v20.18.0
Documentation-only deprecation.



Type: Runtime
Instantiating classes without the new qualifier exported by the node:repl module is deprecated.
It is recommended to use the new qualifier instead. This applies to all REPL classes, including
REPLServer and Recoverable.


DEP0187: Passing invalid argument types to fs.existsSync#

History

VersionChanges
v24.0.0
Runtime deprecation.
v23.4.0, v22.13.0
Documentation-only.



Type: Runtime
Passing non-supported argument types is deprecated and, instead of returning false,
will throw an error in a future version.

DEP0188: process.features.ipv6 and process.features.uv#

History

VersionChanges
v23.4.0, v22.13.0
Documentation-only deprecation.



Type: Documentation-only
These properties are unconditionally true. Any checks based on these properties are redundant.

DEP0189: process.features.tls_*#

History

VersionChanges
v23.4.0, v22.13.0
Documentation-only deprecation.



Type: Documentation-only
process.features.tls_alpn, process.features.tls_ocsp, and process.features.tls_sni are
deprecated, as their values are guaranteed to be identical to that of process.features.tls.

DEP0190: Passing args to node:child_process execFile/spawn with shell option true#

History

VersionChanges
v24.0.0
Runtime deprecation.
v23.11.0, v22.15.0
Documentation-only deprecation.



Type: Runtime
When an args array is passed to child_process.execFile or child_process.spawn with the option
{ shell: true }, the values are not escaped, only space-separated, which can lead to shell injection.

DEP0191: repl.builtinModules#

History

VersionChanges
v24.0.0
Documentation-only deprecation with --pending-deprecation support.



Type: Documentation-only (supports --pending-deprecation)
The node:repl module exports a builtinModules property that contains an array
of built-in modules. This was incomplete and matched the already deprecated
repl._builtinLibs (DEP0142) instead it's better to rely
upon require('node:module').builtinModules.\n\n\n\nNode.js
        
      
      
About this documentation
Usage and example



Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Modules: TypeScript
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
Readline
REPL
Report
Single executable applications
SQLite
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker

    

    
      
        
          Node.js v24.0.1 documentation
          
            
            
          
        
        
          
            Node.js v24.0.1
            
    
      
        
        Table of contents
      

      
Diagnostics Channel

Public API

Overview

diagnostics_channel.hasSubscribers(name)
diagnostics_channel.channel(name)
diagnostics_channel.subscribe(name, onMessage)
diagnostics_channel.unsubscribe(name, onMessage)
diagnostics_channel.tracingChannel(nameOrChannels)


Class: Channel

channel.hasSubscribers
channel.publish(message)
channel.subscribe(onMessage)
channel.unsubscribe(onMessage)
channel.bindStore(store[, transform])
channel.unbindStore(store)
channel.runStores(context, fn[, thisArg[, ...args]])


Class: TracingChannel

tracingChannel.subscribe(subscribers)
tracingChannel.unsubscribe(subscribers)
tracingChannel.traceSync(fn[, context[, thisArg[, ...args]]])
tracingChannel.tracePromise(fn[, context[, thisArg[, ...args]]])
tracingChannel.traceCallback(fn[, position[, context[, thisArg[, ...args]]]])
tracingChannel.hasSubscribers


TracingChannel Channels

start(event)
end(event)
asyncStart(event)
asyncEnd(event)
error(event)


Built-in Channels

Console
HTTP
Modules
NET
UDP
Process
Worker Thread







    
  
            
    
      
        
        Index
      

      
About this documentation
Usage and example

      
        Index
      
    
  


Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Modules: TypeScript
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
Readline
REPL
Report
Single executable applications
SQLite
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker

    
  
            
    
      
        
        Other versions
      
      24.x
23.x
22.x LTS
21.x
20.x LTS
19.x
18.x
17.x
16.x
15.x
    
  
            
              
                
                Options
              
        
              
                
                  
                    View on single page
                  
                  
                    View as JSON
                  
                  Edit on GitHub    
                
              
            
          
        
        
      

      Table of contents
Diagnostics Channel

Public API

Overview

diagnostics_channel.hasSubscribers(name)
diagnostics_channel.channel(name)
diagnostics_channel.subscribe(name, onMessage)
diagnostics_channel.unsubscribe(name, onMessage)
diagnostics_channel.tracingChannel(nameOrChannels)


Class: Channel

channel.hasSubscribers
channel.publish(message)
channel.subscribe(onMessage)
channel.unsubscribe(onMessage)
channel.bindStore(store[, transform])
channel.unbindStore(store)
channel.runStores(context, fn[, thisArg[, ...args]])


Class: TracingChannel

tracingChannel.subscribe(subscribers)
tracingChannel.unsubscribe(subscribers)
tracingChannel.traceSync(fn[, context[, thisArg[, ...args]]])
tracingChannel.tracePromise(fn[, context[, thisArg[, ...args]]])
tracingChannel.traceCallback(fn[, position[, context[, thisArg[, ...args]]]])
tracingChannel.hasSubscribers


TracingChannel Channels

start(event)
end(event)
asyncStart(event)
asyncEnd(event)
error(event)


Built-in Channels

Console
HTTP
Modules
NET
UDP
Process
Worker Thread








      
        Diagnostics Channel#

History

VersionChanges
v19.2.0, v18.13.0
diagnostics_channel is now Stable.
v15.1.0, v14.17.0
Added in: v15.1.0, v14.17.0




Stability: 2 - Stable
Source Code: lib/diagnostics_channel.js
The node:diagnostics_channel module provides an API to create named channels
to report arbitrary message data for diagnostics purposes.
It can be accessed using:

import diagnostics_channel from 'node:diagnostics_channel';const diagnostics_channel = require('node:diagnostics_channel');copy
It is intended that a module writer wanting to report diagnostics messages
will create one or many top-level channels to report messages through.
Channels may also be acquired at runtime but it is not encouraged
due to the additional overhead of doing so. Channels may be exported for
convenience, but as long as the name is known it can be acquired anywhere.
If you intend for your module to produce diagnostics data for others to
consume it is recommended that you include documentation of what named
channels are used along with the shape of the message data. Channel names
should generally include the module name to avoid collisions with data from
other modules.
Public API#

Overview#
Following is a simple overview of the public API.

import diagnostics_channel from 'node:diagnostics_channel';

// Get a reusable channel object
const channel = diagnostics_channel.channel('my-channel');

function onMessage(message, name) {
  // Received data
}

// Subscribe to the channel
diagnostics_channel.subscribe('my-channel', onMessage);

// Check if the channel has an active subscriber
if (channel.hasSubscribers) {
  // Publish data to the channel
  channel.publish({
    some: 'data',
  });
}

// Unsubscribe from the channel
diagnostics_channel.unsubscribe('my-channel', onMessage);const diagnostics_channel = require('node:diagnostics_channel');

// Get a reusable channel object
const channel = diagnostics_channel.channel('my-channel');

function onMessage(message, name) {
  // Received data
}

// Subscribe to the channel
diagnostics_channel.subscribe('my-channel', onMessage);

// Check if the channel has an active subscriber
if (channel.hasSubscribers) {
  // Publish data to the channel
  channel.publish({
    some: 'data',
  });
}

// Unsubscribe from the channel
diagnostics_channel.unsubscribe('my-channel', onMessage);copy

diagnostics_channel.hasSubscribers(name)#

Added in: v15.1.0, v14.17.0


name <string> | <symbol> The channel name
Returns: <boolean> If there are active subscribers

Check if there are active subscribers to the named channel. This is helpful if
the message you want to send might be expensive to prepare.
This API is optional but helpful when trying to publish messages from very
performance-sensitive code.

import diagnostics_channel from 'node:diagnostics_channel';

if (diagnostics_channel.hasSubscribers('my-channel')) {
  // There are subscribers, prepare and publish message
}const diagnostics_channel = require('node:diagnostics_channel');

if (diagnostics_channel.hasSubscribers('my-channel')) {
  // There are subscribers, prepare and publish message
}copy

diagnostics_channel.channel(name)#

Added in: v15.1.0, v14.17.0


name <string> | <symbol> The channel name
Returns: <Channel> The named channel object

This is the primary entry-point for anyone wanting to publish to a named
channel. It produces a channel object which is optimized to reduce overhead at
publish time as much as possible.

import diagnostics_channel from 'node:diagnostics_channel';

const channel = diagnostics_channel.channel('my-channel');const diagnostics_channel = require('node:diagnostics_channel');

const channel = diagnostics_channel.channel('my-channel');copy

diagnostics_channel.subscribe(name, onMessage)#

Added in: v18.7.0, v16.17.0


name <string> | <symbol> The channel name
onMessage <Function> The handler to receive channel messages

message <any> The message data
name <string> | <symbol> The name of the channel



Register a message handler to subscribe to this channel. This message handler
will be run synchronously whenever a message is published to the channel. Any
errors thrown in the message handler will trigger an 'uncaughtException'.

import diagnostics_channel from 'node:diagnostics_channel';

diagnostics_channel.subscribe('my-channel', (message, name) => {
  // Received data
});const diagnostics_channel = require('node:diagnostics_channel');

diagnostics_channel.subscribe('my-channel', (message, name) => {
  // Received data
});copy

diagnostics_channel.unsubscribe(name, onMessage)#

Added in: v18.7.0, v16.17.0


name <string> | <symbol> The channel name
onMessage <Function> The previous subscribed handler to remove
Returns: <boolean> true if the handler was found, false otherwise.

Remove a message handler previously registered to this channel with
diagnostics_channel.subscribe(name, onMessage).

import diagnostics_channel from 'node:diagnostics_channel';

function onMessage(message, name) {
  // Received data
}

diagnostics_channel.subscribe('my-channel', onMessage);

diagnostics_channel.unsubscribe('my-channel', onMessage);const diagnostics_channel = require('node:diagnostics_channel');

function onMessage(message, name) {
  // Received data
}

diagnostics_channel.subscribe('my-channel', onMessage);

diagnostics_channel.unsubscribe('my-channel', onMessage);copy

diagnostics_channel.tracingChannel(nameOrChannels)#

Added in: v19.9.0, v18.19.0

Stability: 1 - Experimental

nameOrChannels <string> | <TracingChannel> Channel name or
object containing all the TracingChannel Channels
Returns: <TracingChannel> Collection of channels to trace with

Creates a TracingChannel wrapper for the given
TracingChannel Channels. If a name is given, the corresponding tracing
channels will be created in the form of tracing:${name}:${eventType} where
eventType corresponds to the types of TracingChannel Channels.

import diagnostics_channel from 'node:diagnostics_channel';

const channelsByName = diagnostics_channel.tracingChannel('my-channel');

// or...

const channelsByCollection = diagnostics_channel.tracingChannel({
  start: diagnostics_channel.channel('tracing:my-channel:start'),
  end: diagnostics_channel.channel('tracing:my-channel:end'),
  asyncStart: diagnostics_channel.channel('tracing:my-channel:asyncStart'),
  asyncEnd: diagnostics_channel.channel('tracing:my-channel:asyncEnd'),
  error: diagnostics_channel.channel('tracing:my-channel:error'),
});const diagnostics_channel = require('node:diagnostics_channel');

const channelsByName = diagnostics_channel.tracingChannel('my-channel');

// or...

const channelsByCollection = diagnostics_channel.tracingChannel({
  start: diagnostics_channel.channel('tracing:my-channel:start'),
  end: diagnostics_channel.channel('tracing:my-channel:end'),
  asyncStart: diagnostics_channel.channel('tracing:my-channel:asyncStart'),
  asyncEnd: diagnostics_channel.channel('tracing:my-channel:asyncEnd'),
  error: diagnostics_channel.channel('tracing:my-channel:error'),
});copy

Class: Channel#

Added in: v15.1.0, v14.17.0

The class Channel represents an individual named channel within the data
pipeline. It is used to track subscribers and to publish messages when there
are subscribers present. It exists as a separate object to avoid channel
lookups at publish time, enabling very fast publish speeds and allowing
for heavy use while incurring very minimal cost. Channels are created with
diagnostics_channel.channel(name), constructing a channel directly
with new Channel(name) is not supported.

channel.hasSubscribers#

Added in: v15.1.0, v14.17.0


Returns: <boolean> If there are active subscribers

Check if there are active subscribers to this channel. This is helpful if
the message you want to send might be expensive to prepare.
This API is optional but helpful when trying to publish messages from very
performance-sensitive code.

import diagnostics_channel from 'node:diagnostics_channel';

const channel = diagnostics_channel.channel('my-channel');

if (channel.hasSubscribers) {
  // There are subscribers, prepare and publish message
}const diagnostics_channel = require('node:diagnostics_channel');

const channel = diagnostics_channel.channel('my-channel');

if (channel.hasSubscribers) {
  // There are subscribers, prepare and publish message
}copy

channel.publish(message)#

Added in: v15.1.0, v14.17.0


message <any> The message to send to the channel subscribers

Publish a message to any subscribers to the channel. This will trigger
message handlers synchronously so they will execute within the same context.

import diagnostics_channel from 'node:diagnostics_channel';

const channel = diagnostics_channel.channel('my-channel');

channel.publish({
  some: 'message',
});const diagnostics_channel = require('node:diagnostics_channel');

const channel = diagnostics_channel.channel('my-channel');

channel.publish({
  some: 'message',
});copy

channel.subscribe(onMessage)#

Added in: v15.1.0, v14.17.0Deprecated since: v18.7.0, v16.17.0

Stability: 0 - Deprecated: Use diagnostics_channel.subscribe(name, onMessage)

onMessage <Function> The handler to receive channel messages

message <any> The message data
name <string> | <symbol> The name of the channel



Register a message handler to subscribe to this channel. This message handler
will be run synchronously whenever a message is published to the channel. Any
errors thrown in the message handler will trigger an 'uncaughtException'.

import diagnostics_channel from 'node:diagnostics_channel';

const channel = diagnostics_channel.channel('my-channel');

channel.subscribe((message, name) => {
  // Received data
});const diagnostics_channel = require('node:diagnostics_channel');

const channel = diagnostics_channel.channel('my-channel');

channel.subscribe((message, name) => {
  // Received data
});copy

channel.unsubscribe(onMessage)#

History

VersionChanges
v18.7.0, v16.17.0
Deprecated since: v18.7.0, v16.17.0
v17.1.0, v16.14.0, v14.19.0
Added return value. Added to channels without subscribers.
v15.1.0, v14.17.0
Added in: v15.1.0, v14.17.0



Stability: 0 - Deprecated: Use diagnostics_channel.unsubscribe(name, onMessage)

onMessage <Function> The previous subscribed handler to remove
Returns: <boolean> true if the handler was found, false otherwise.

Remove a message handler previously registered to this channel with
channel.subscribe(onMessage).

import diagnostics_channel from 'node:diagnostics_channel';

const channel = diagnostics_channel.channel('my-channel');

function onMessage(message, name) {
  // Received data
}

channel.subscribe(onMessage);

channel.unsubscribe(onMessage);const diagnostics_channel = require('node:diagnostics_channel');

const channel = diagnostics_channel.channel('my-channel');

function onMessage(message, name) {
  // Received data
}

channel.subscribe(onMessage);

channel.unsubscribe(onMessage);copy

channel.bindStore(store[, transform])#

Added in: v19.9.0, v18.19.0

Stability: 1 - Experimental

store <AsyncLocalStorage> The store to which to bind the context data
transform <Function> Transform context data before setting the store context

When channel.runStores(context, ...) is called, the given context data
will be applied to any store bound to the channel. If the store has already been
bound the previous transform function will be replaced with the new one.
The transform function may be omitted to set the given context data as the
context directly.

import diagnostics_channel from 'node:diagnostics_channel';
import { AsyncLocalStorage } from 'node:async_hooks';

const store = new AsyncLocalStorage();

const channel = diagnostics_channel.channel('my-channel');

channel.bindStore(store, (data) => {
  return { data };
});const diagnostics_channel = require('node:diagnostics_channel');
const { AsyncLocalStorage } = require('node:async_hooks');

const store = new AsyncLocalStorage();

const channel = diagnostics_channel.channel('my-channel');

channel.bindStore(store, (data) => {
  return { data };
});copy

channel.unbindStore(store)#

Added in: v19.9.0, v18.19.0

Stability: 1 - Experimental

store <AsyncLocalStorage> The store to unbind from the channel.
Returns: <boolean> true if the store was found, false otherwise.

Remove a message handler previously registered to this channel with
channel.bindStore(store).

import diagnostics_channel from 'node:diagnostics_channel';
import { AsyncLocalStorage } from 'node:async_hooks';

const store = new AsyncLocalStorage();

const channel = diagnostics_channel.channel('my-channel');

channel.bindStore(store);
channel.unbindStore(store);const diagnostics_channel = require('node:diagnostics_channel');
const { AsyncLocalStorage } = require('node:async_hooks');

const store = new AsyncLocalStorage();

const channel = diagnostics_channel.channel('my-channel');

channel.bindStore(store);
channel.unbindStore(store);copy

channel.runStores(context, fn[, thisArg[, ...args]])#

Added in: v19.9.0, v18.19.0

Stability: 1 - Experimental

context <any> Message to send to subscribers and bind to stores
fn <Function> Handler to run within the entered storage context
thisArg <any> The receiver to be used for the function call.
...args <any> Optional arguments to pass to the function.

Applies the given data to any AsyncLocalStorage instances bound to the channel
for the duration of the given function, then publishes to the channel within
the scope of that data is applied to the stores.
If a transform function was given to channel.bindStore(store) it will be
applied to transform the message data before it becomes the context value for
the store. The prior storage context is accessible from within the transform
function in cases where context linking is required.
The context applied to the store should be accessible in any async code which
continues from execution which began during the given function, however
there are some situations in which context loss may occur.

import diagnostics_channel from 'node:diagnostics_channel';
import { AsyncLocalStorage } from 'node:async_hooks';

const store = new AsyncLocalStorage();

const channel = diagnostics_channel.channel('my-channel');

channel.bindStore(store, (message) => {
  const parent = store.getStore();
  return new Span(message, parent);
});
channel.runStores({ some: 'message' }, () => {
  store.getStore(); // Span({ some: 'message' })
});const diagnostics_channel = require('node:diagnostics_channel');
const { AsyncLocalStorage } = require('node:async_hooks');

const store = new AsyncLocalStorage();

const channel = diagnostics_channel.channel('my-channel');

channel.bindStore(store, (message) => {
  const parent = store.getStore();
  return new Span(message, parent);
});
channel.runStores({ some: 'message' }, () => {
  store.getStore(); // Span({ some: 'message' })
});copy

Class: TracingChannel#

Added in: v19.9.0, v18.19.0

Stability: 1 - Experimental
The class TracingChannel is a collection of TracingChannel Channels which
together express a single traceable action. It is used to formalize and
simplify the process of producing events for tracing application flow.
diagnostics_channel.tracingChannel() is used to construct a
TracingChannel. As with Channel it is recommended to create and reuse a
single TracingChannel at the top-level of the file rather than creating them
dynamically.

tracingChannel.subscribe(subscribers)#

Added in: v19.9.0, v18.19.0


subscribers <Object> Set of TracingChannel Channels subscribers

start <Function> The start event subscriber
end <Function> The end event subscriber
asyncStart <Function> The asyncStart event subscriber
asyncEnd <Function> The asyncEnd event subscriber
error <Function> The error event subscriber



Helper to subscribe a collection of functions to the corresponding channels.
This is the same as calling channel.subscribe(onMessage) on each channel
individually.

import diagnostics_channel from 'node:diagnostics_channel';

const channels = diagnostics_channel.tracingChannel('my-channel');

channels.subscribe({
  start(message) {
    // Handle start message
  },
  end(message) {
    // Handle end message
  },
  asyncStart(message) {
    // Handle asyncStart message
  },
  asyncEnd(message) {
    // Handle asyncEnd message
  },
  error(message) {
    // Handle error message
  },
});const diagnostics_channel = require('node:diagnostics_channel');

const channels = diagnostics_channel.tracingChannel('my-channel');

channels.subscribe({
  start(message) {
    // Handle start message
  },
  end(message) {
    // Handle end message
  },
  asyncStart(message) {
    // Handle asyncStart message
  },
  asyncEnd(message) {
    // Handle asyncEnd message
  },
  error(message) {
    // Handle error message
  },
});copy

tracingChannel.unsubscribe(subscribers)#

Added in: v19.9.0, v18.19.0


subscribers <Object> Set of TracingChannel Channels subscribers

start <Function> The start event subscriber
end <Function> The end event subscriber
asyncStart <Function> The asyncStart event subscriber
asyncEnd <Function> The asyncEnd event subscriber
error <Function> The error event subscriber


Returns: <boolean> true if all handlers were successfully unsubscribed,
and false otherwise.

Helper to unsubscribe a collection of functions from the corresponding channels.
This is the same as calling channel.unsubscribe(onMessage) on each channel
individually.

import diagnostics_channel from 'node:diagnostics_channel';

const channels = diagnostics_channel.tracingChannel('my-channel');

channels.unsubscribe({
  start(message) {
    // Handle start message
  },
  end(message) {
    // Handle end message
  },
  asyncStart(message) {
    // Handle asyncStart message
  },
  asyncEnd(message) {
    // Handle asyncEnd message
  },
  error(message) {
    // Handle error message
  },
});const diagnostics_channel = require('node:diagnostics_channel');

const channels = diagnostics_channel.tracingChannel('my-channel');

channels.unsubscribe({
  start(message) {
    // Handle start message
  },
  end(message) {
    // Handle end message
  },
  asyncStart(message) {
    // Handle asyncStart message
  },
  asyncEnd(message) {
    // Handle asyncEnd message
  },
  error(message) {
    // Handle error message
  },
});copy

tracingChannel.traceSync(fn[, context[, thisArg[, ...args]]])#

Added in: v19.9.0, v18.19.0


fn <Function> Function to wrap a trace around
context <Object> Shared object to correlate events through
thisArg <any> The receiver to be used for the function call
...args <any> Optional arguments to pass to the function
Returns: <any> The return value of the given function

Trace a synchronous function call. This will always produce a start event
and end event around the execution and may produce an error event
if the given function throws an error. This will run the given function using
channel.runStores(context, ...) on the start channel which ensures all
events should have any bound stores set to match this trace context.
To ensure only correct trace graphs are formed, events will only be published
if subscribers are present prior to starting the trace. Subscriptions which are
added after the trace begins will not receive future events from that trace,
only future traces will be seen.

import diagnostics_channel from 'node:diagnostics_channel';

const channels = diagnostics_channel.tracingChannel('my-channel');

channels.traceSync(() => {
  // Do something
}, {
  some: 'thing',
});const diagnostics_channel = require('node:diagnostics_channel');

const channels = diagnostics_channel.tracingChannel('my-channel');

channels.traceSync(() => {
  // Do something
}, {
  some: 'thing',
});copy

tracingChannel.tracePromise(fn[, context[, thisArg[, ...args]]])#

Added in: v19.9.0, v18.19.0


fn <Function> Promise-returning function to wrap a trace around
context <Object> Shared object to correlate trace events through
thisArg <any> The receiver to be used for the function call
...args <any> Optional arguments to pass to the function
Returns: <Promise> Chained from promise returned by the given function

Trace a promise-returning function call. This will always produce a
start event and end event around the synchronous portion of the
function execution, and will produce an asyncStart event and
asyncEnd event when a promise continuation is reached. It may also
produce an error event if the given function throws an error or the
returned promise rejects. This will run the given function using
channel.runStores(context, ...) on the start channel which ensures all
events should have any bound stores set to match this trace context.
To ensure only correct trace graphs are formed, events will only be published
if subscribers are present prior to starting the trace. Subscriptions which are
added after the trace begins will not receive future events from that trace,
only future traces will be seen.

import diagnostics_channel from 'node:diagnostics_channel';

const channels = diagnostics_channel.tracingChannel('my-channel');

channels.tracePromise(async () => {
  // Do something
}, {
  some: 'thing',
});const diagnostics_channel = require('node:diagnostics_channel');

const channels = diagnostics_channel.tracingChannel('my-channel');

channels.tracePromise(async () => {
  // Do something
}, {
  some: 'thing',
});copy

tracingChannel.traceCallback(fn[, position[, context[, thisArg[, ...args]]]])#

Added in: v19.9.0, v18.19.0


fn <Function> callback using function to wrap a trace around
position <number> Zero-indexed argument position of expected callback
(defaults to last argument if undefined is passed)
context <Object> Shared object to correlate trace events through (defaults
to {} if undefined is passed)
thisArg <any> The receiver to be used for the function call
...args <any> arguments to pass to the function (must include the callback)
Returns: <any> The return value of the given function

Trace a callback-receiving function call. The callback is expected to follow
the error as first arg convention typically used. This will always produce a
start event and end event around the synchronous portion of the
function execution, and will produce a asyncStart event and
asyncEnd event around the callback execution. It may also produce an
error event if the given function throws or the first argument passed to
the callback is set. This will run the given function using
channel.runStores(context, ...) on the start channel which ensures all
events should have any bound stores set to match this trace context.
To ensure only correct trace graphs are formed, events will only be published
if subscribers are present prior to starting the trace. Subscriptions which are
added after the trace begins will not receive future events from that trace,
only future traces will be seen.

import diagnostics_channel from 'node:diagnostics_channel';

const channels = diagnostics_channel.tracingChannel('my-channel');

channels.traceCallback((arg1, callback) => {
  // Do something
  callback(null, 'result');
}, 1, {
  some: 'thing',
}, thisArg, arg1, callback);const diagnostics_channel = require('node:diagnostics_channel');

const channels = diagnostics_channel.tracingChannel('my-channel');

channels.traceCallback((arg1, callback) => {
  // Do something
  callback(null, 'result');
}, 1, {
  some: 'thing',
}, thisArg, arg1, callback);copy
The callback will also be run with channel.runStores(context, ...) which
enables context loss recovery in some cases.

import diagnostics_channel from 'node:diagnostics_channel';
import { AsyncLocalStorage } from 'node:async_hooks';

const channels = diagnostics_channel.tracingChannel('my-channel');
const myStore = new AsyncLocalStorage();

// The start channel sets the initial store data to something
// and stores that store data value on the trace context object
channels.start.bindStore(myStore, (data) => {
  const span = new Span(data);
  data.span = span;
  return span;
});

// Then asyncStart can restore from that data it stored previously
channels.asyncStart.bindStore(myStore, (data) => {
  return data.span;
});const diagnostics_channel = require('node:diagnostics_channel');
const { AsyncLocalStorage } = require('node:async_hooks');

const channels = diagnostics_channel.tracingChannel('my-channel');
const myStore = new AsyncLocalStorage();

// The start channel sets the initial store data to something
// and stores that store data value on the trace context object
channels.start.bindStore(myStore, (data) => {
  const span = new Span(data);
  data.span = span;
  return span;
});

// Then asyncStart can restore from that data it stored previously
channels.asyncStart.bindStore(myStore, (data) => {
  return data.span;
});copy

tracingChannel.hasSubscribers#

Added in: v22.0.0, v20.13.0


Returns: <boolean> true if any of the individual channels has a subscriber,
false if not.

This is a helper method available on a TracingChannel instance to check if
any of the TracingChannel Channels have subscribers. A true is returned if
any of them have at least one subscriber, a false is returned otherwise.

import diagnostics_channel from 'node:diagnostics_channel';

const channels = diagnostics_channel.tracingChannel('my-channel');

if (channels.hasSubscribers) {
  // Do something
}const diagnostics_channel = require('node:diagnostics_channel');

const channels = diagnostics_channel.tracingChannel('my-channel');

if (channels.hasSubscribers) {
  // Do something
}copy

TracingChannel Channels#
A TracingChannel is a collection of several diagnostics_channels representing
specific points in the execution lifecycle of a single traceable action. The
behavior is split into five diagnostics_channels consisting of start,
end, asyncStart, asyncEnd, and error. A single traceable action will
share the same event object between all events, this can be helpful for
managing correlation through a weakmap.
These event objects will be extended with result or error values when
the task "completes". In the case of a synchronous task the result will be
the return value and the error will be anything thrown from the function.
With callback-based async functions the result will be the second argument
of the callback while the error will either be a thrown error visible in the
end event or the first callback argument in either of the asyncStart or
asyncEnd events.
To ensure only correct trace graphs are formed, events should only be published
if subscribers are present prior to starting the trace. Subscriptions which are
added after the trace begins should not receive future events from that trace,
only future traces will be seen.
Tracing channels should follow a naming pattern of:

tracing:module.class.method:start or tracing:module.function:start
tracing:module.class.method:end or tracing:module.function:end
tracing:module.class.method:asyncStart or tracing:module.function:asyncStart
tracing:module.class.method:asyncEnd or tracing:module.function:asyncEnd
tracing:module.class.method:error or tracing:module.function:error


start(event)#

Name: tracing:${name}:start

The start event represents the point at which a function is called. At this
point the event data may contain function arguments or anything else available
at the very start of the execution of the function.

end(event)#

Name: tracing:${name}:end

The end event represents the point at which a function call returns a value.
In the case of an async function this is when the promise returned not when the
function itself makes a return statement internally. At this point, if the
traced function was synchronous the result field will be set to the return
value of the function. Alternatively, the error field may be present to
represent any thrown errors.
It is recommended to listen specifically to the error event to track errors
as it may be possible for a traceable action to produce multiple errors. For
example, an async task which fails may be started internally before the sync
part of the task then throws an error.

asyncStart(event)#

Name: tracing:${name}:asyncStart

The asyncStart event represents the callback or continuation of a traceable
function being reached. At this point things like callback arguments may be
available, or anything else expressing the "result" of the action.
For callbacks-based functions, the first argument of the callback will be
assigned to the error field, if not undefined or null, and the second
argument will be assigned to the result field.
For promises, the argument to the resolve path will be assigned to result
or the argument to the reject path will be assign to error.
It is recommended to listen specifically to the error event to track errors
as it may be possible for a traceable action to produce multiple errors. For
example, an async task which fails may be started internally before the sync
part of the task then throws an error.

asyncEnd(event)#

Name: tracing:${name}:asyncEnd

The asyncEnd event represents the callback of an asynchronous function
returning. It's not likely event data will change after the asyncStart event,
however it may be useful to see the point where the callback completes.

error(event)#

Name: tracing:${name}:error

The error event represents any error produced by the traceable function
either synchronously or asynchronously. If an error is thrown in the
synchronous portion of the traced function the error will be assigned to the
error field of the event and the error event will be triggered. If an error
is received asynchronously through a callback or promise rejection it will also
be assigned to the error field of the event and trigger the error event.
It is possible for a single traceable function call to produce errors multiple
times so this should be considered when consuming this event. For example, if
another async task is triggered internally which fails and then the sync part
of the function then throws and error two error events will be emitted, one
for the sync error and one for the async error.

Built-in Channels#
Stability: 1 - Experimental
While the diagnostics_channel API is now considered stable, the built-in
channels currently available are not. Each channel must be declared stable
independently.

Console#
console.log

args <any[]>

Emitted when console.log() is called. Receives and array of the arguments
passed to console.log().
console.info

args <any[]>

Emitted when console.info() is called. Receives and array of the arguments
passed to console.info().
console.debug

args <any[]>

Emitted when console.debug() is called. Receives and array of the arguments
passed to console.debug().
console.warn

args <any[]>

Emitted when console.warn() is called. Receives and array of the arguments
passed to console.warn().
console.error

args <any[]>

Emitted when console.error() is called. Receives and array of the arguments
passed to console.error().

HTTP#
http.client.request.created

request <http.ClientRequest>

Emitted when client creates a request object.
Unlike http.client.request.start, this event is emitted before the request has been sent.
http.client.request.start

request <http.ClientRequest>

Emitted when client starts a request.
http.client.request.error

request <http.ClientRequest>
error <Error>

Emitted when an error occurs during a client request.
http.client.response.finish

request <http.ClientRequest>
response <http.IncomingMessage>

Emitted when client receives a response.
http.server.request.start

request <http.IncomingMessage>
response <http.ServerResponse>
socket <net.Socket>
server <http.Server>

Emitted when server receives a request.
http.server.response.created

request <http.IncomingMessage>
response <http.ServerResponse>

Emitted when server creates a response.
The event is emitted before the response is sent.
http.server.response.finish

request <http.IncomingMessage>
response <http.ServerResponse>
socket <net.Socket>
server <http.Server>

Emitted when server sends a response.

Modules#
module.require.start

event <Object> containing the following properties

id - Argument passed to require(). Module name.
parentFilename - Name of the module that attempted to require(id).



Emitted when require() is executed. See start event.
module.require.end

event <Object> containing the following properties

id - Argument passed to require(). Module name.
parentFilename - Name of the module that attempted to require(id).



Emitted when a require() call returns. See end event.
module.require.error

event <Object> containing the following properties

id - Argument passed to require(). Module name.
parentFilename - Name of the module that attempted to require(id).


error <Error>

Emitted when a require() throws an error. See error event.
module.import.asyncStart

event <Object> containing the following properties

id - Argument passed to import(). Module name.
parentURL - URL object of the module that attempted to import(id).



Emitted when import() is invoked. See asyncStart event.
module.import.asyncEnd

event <Object> containing the following properties

id - Argument passed to import(). Module name.
parentURL - URL object of the module that attempted to import(id).



Emitted when import() has completed. See asyncEnd event.
module.import.error

event <Object> containing the following properties

id - Argument passed to import(). Module name.
parentURL - URL object of the module that attempted to import(id).


error <Error>

Emitted when a import() throws an error. See error event.

NET#
net.client.socket

socket <net.Socket>

Emitted when a new TCP or pipe client socket is created.
net.server.socket

socket <net.Socket>

Emitted when a new TCP or pipe connection is received.
tracing:net.server.listen:asyncStart

server <net.Server>
options <Object>

Emitted when net.Server.listen() is invoked, before the port or pipe is actually setup.
tracing:net.server.listen:asyncEnd

server <net.Server>

Emitted when net.Server.listen() has completed and thus the server is ready to accept connection.
tracing:net.server.listen:error

server <net.Server>
error <Error>

Emitted when net.Server.listen() is returning an error.

UDP#
udp.socket

socket <dgram.Socket>

Emitted when a new UDP socket is created.

Process#

Added in: v16.18.0

child_process

process <ChildProcess>

Emitted when a new process is created.
execve

execPath <string>
args <string[]>
env <string[]>

Emitted when process.execve() is invoked.

Worker Thread#

Added in: v16.18.0

worker_threads

worker Worker

Emitted when a new thread is created.\n\n\n\nNode.js
        
      
      
About this documentation
Usage and example



Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Modules: TypeScript
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
Readline
REPL
Report
Single executable applications
SQLite
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker

    

    
      
        
          Node.js v24.0.1 documentation
          
            
            
          
        
        
          
            Node.js v24.0.1
            
    
      
        
        Table of contents
      

      
DNS

Class: dns.Resolver

Resolver([options])
resolver.cancel()
resolver.setLocalAddress([ipv4][, ipv6])


dns.getServers()
dns.lookup(hostname[, options], callback)

Supported getaddrinfo flags


dns.lookupService(address, port, callback)
dns.resolve(hostname[, rrtype], callback)
dns.resolve4(hostname[, options], callback)
dns.resolve6(hostname[, options], callback)
dns.resolveAny(hostname, callback)
dns.resolveCname(hostname, callback)
dns.resolveCaa(hostname, callback)
dns.resolveMx(hostname, callback)
dns.resolveNaptr(hostname, callback)
dns.resolveNs(hostname, callback)
dns.resolvePtr(hostname, callback)
dns.resolveSoa(hostname, callback)
dns.resolveSrv(hostname, callback)
dns.resolveTlsa(hostname, callback)
dns.resolveTxt(hostname, callback)
dns.reverse(ip, callback)
dns.setDefaultResultOrder(order)
dns.getDefaultResultOrder()
dns.setServers(servers)
DNS promises API

Class: dnsPromises.Resolver
resolver.cancel()
dnsPromises.getServers()
dnsPromises.lookup(hostname[, options])
dnsPromises.lookupService(address, port)
dnsPromises.resolve(hostname[, rrtype])
dnsPromises.resolve4(hostname[, options])
dnsPromises.resolve6(hostname[, options])
dnsPromises.resolveAny(hostname)
dnsPromises.resolveCaa(hostname)
dnsPromises.resolveCname(hostname)
dnsPromises.resolveMx(hostname)
dnsPromises.resolveNaptr(hostname)
dnsPromises.resolveNs(hostname)
dnsPromises.resolvePtr(hostname)
dnsPromises.resolveSoa(hostname)
dnsPromises.resolveSrv(hostname)
dnsPromises.resolveTlsa(hostname)
dnsPromises.resolveTxt(hostname)
dnsPromises.reverse(ip)
dnsPromises.setDefaultResultOrder(order)
dnsPromises.getDefaultResultOrder()
dnsPromises.setServers(servers)


Error codes
Implementation considerations

dns.lookup()
dns.resolve(), dns.resolve*(), and dns.reverse()





    
  
            
    
      
        
        Index
      

      
About this documentation
Usage and example

      
        Index
      
    
  


Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Modules: TypeScript
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
Readline
REPL
Report
Single executable applications
SQLite
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker

    
  
            
    
      
        
        Other versions
      
      24.x
23.x
22.x LTS
21.x
20.x LTS
19.x
18.x
17.x
16.x
15.x
14.x
13.x
12.x
11.x
10.x
9.x
8.x
7.x
6.x
5.x
4.x
0.12.x
0.10.x
    
  
            
              
                
                Options
              
        
              
                
                  
                    View on single page
                  
                  
                    View as JSON
                  
                  Edit on GitHub    
                
              
            
          
        
        
      

      Table of contents
DNS

Class: dns.Resolver

Resolver([options])
resolver.cancel()
resolver.setLocalAddress([ipv4][, ipv6])


dns.getServers()
dns.lookup(hostname[, options], callback)

Supported getaddrinfo flags


dns.lookupService(address, port, callback)
dns.resolve(hostname[, rrtype], callback)
dns.resolve4(hostname[, options], callback)
dns.resolve6(hostname[, options], callback)
dns.resolveAny(hostname, callback)
dns.resolveCname(hostname, callback)
dns.resolveCaa(hostname, callback)
dns.resolveMx(hostname, callback)
dns.resolveNaptr(hostname, callback)
dns.resolveNs(hostname, callback)
dns.resolvePtr(hostname, callback)
dns.resolveSoa(hostname, callback)
dns.resolveSrv(hostname, callback)
dns.resolveTlsa(hostname, callback)
dns.resolveTxt(hostname, callback)
dns.reverse(ip, callback)
dns.setDefaultResultOrder(order)
dns.getDefaultResultOrder()
dns.setServers(servers)
DNS promises API

Class: dnsPromises.Resolver
resolver.cancel()
dnsPromises.getServers()
dnsPromises.lookup(hostname[, options])
dnsPromises.lookupService(address, port)
dnsPromises.resolve(hostname[, rrtype])
dnsPromises.resolve4(hostname[, options])
dnsPromises.resolve6(hostname[, options])
dnsPromises.resolveAny(hostname)
dnsPromises.resolveCaa(hostname)
dnsPromises.resolveCname(hostname)
dnsPromises.resolveMx(hostname)
dnsPromises.resolveNaptr(hostname)
dnsPromises.resolveNs(hostname)
dnsPromises.resolvePtr(hostname)
dnsPromises.resolveSoa(hostname)
dnsPromises.resolveSrv(hostname)
dnsPromises.resolveTlsa(hostname)
dnsPromises.resolveTxt(hostname)
dnsPromises.reverse(ip)
dnsPromises.setDefaultResultOrder(order)
dnsPromises.getDefaultResultOrder()
dnsPromises.setServers(servers)


Error codes
Implementation considerations

dns.lookup()
dns.resolve(), dns.resolve*(), and dns.reverse()






      
        DNS#

Stability: 2 - Stable
Source Code: lib/dns.js
The node:dns module enables name resolution. For example, use it to look up IP
addresses of host names.
Although named for the Domain Name System (DNS), it does not always use the
DNS protocol for lookups. dns.lookup() uses the operating system
facilities to perform name resolution. It may not need to perform any network
communication. To perform name resolution the way other applications on the same
system do, use dns.lookup().

import dns from 'node:dns';

dns.lookup('example.org', (err, address, family) => {
  console.log('address: %j family: IPv%s', address, family);
});
// address: "2606:2800:21f:cb07:6820:80da:af6b:8b2c" family: IPv6const dns = require('node:dns');

dns.lookup('example.org', (err, address, family) => {
  console.log('address: %j family: IPv%s', address, family);
});
// address: "2606:2800:21f:cb07:6820:80da:af6b:8b2c" family: IPv6copy
All other functions in the node:dns module connect to an actual DNS server to
perform name resolution. They will always use the network to perform DNS
queries. These functions do not use the same set of configuration files used by
dns.lookup() (e.g. /etc/hosts). Use these functions to always perform
DNS queries, bypassing other name-resolution facilities.

import dns from 'node:dns';

dns.resolve4('archive.org', (err, addresses) => {
  if (err) throw err;

  console.log(`addresses: ${JSON.stringify(addresses)}`);

  addresses.forEach((a) => {
    dns.reverse(a, (err, hostnames) => {
      if (err) {
        throw err;
      }
      console.log(`reverse for ${a}: ${JSON.stringify(hostnames)}`);
    });
  });
});const dns = require('node:dns');

dns.resolve4('archive.org', (err, addresses) => {
  if (err) throw err;

  console.log(`addresses: ${JSON.stringify(addresses)}`);

  addresses.forEach((a) => {
    dns.reverse(a, (err, hostnames) => {
      if (err) {
        throw err;
      }
      console.log(`reverse for ${a}: ${JSON.stringify(hostnames)}`);
    });
  });
});copy
See the Implementation considerations section for more information.
Class: dns.Resolver#

Added in: v8.3.0

An independent resolver for DNS requests.
Creating a new resolver uses the default server settings. Setting
the servers used for a resolver using
resolver.setServers() does not affect
other resolvers:

import { Resolver } from 'node:dns';
const resolver = new Resolver();
resolver.setServers(['4.4.4.4']);

// This request will use the server at 4.4.4.4, independent of global settings.
resolver.resolve4('example.org', (err, addresses) => {
  // ...
});const { Resolver } = require('node:dns');
const resolver = new Resolver();
resolver.setServers(['4.4.4.4']);

// This request will use the server at 4.4.4.4, independent of global settings.
resolver.resolve4('example.org', (err, addresses) => {
  // ...
});copy
The following methods from the node:dns module are available:

resolver.getServers()
resolver.resolve()
resolver.resolve4()
resolver.resolve6()
resolver.resolveAny()
resolver.resolveCaa()
resolver.resolveCname()
resolver.resolveMx()
resolver.resolveNaptr()
resolver.resolveNs()
resolver.resolvePtr()
resolver.resolveSoa()
resolver.resolveSrv()
resolver.resolveTlsa()
resolver.resolveTxt()
resolver.reverse()
resolver.setServers()


Resolver([options])#

History

VersionChanges
v16.7.0, v14.18.0
The options object now accepts a tries option.
v12.18.3
The constructor now accepts an options object. The single supported option is timeout.
v8.3.0
Added in: v8.3.0



Create a new resolver.

options <Object>

timeout <integer> Query timeout in milliseconds, or -1 to use the
default timeout.
tries <integer> The number of tries the resolver will try contacting
each name server before giving up. Default: 4




resolver.cancel()#

Added in: v8.3.0

Cancel all outstanding DNS queries made by this resolver. The corresponding
callbacks will be called with an error with code ECANCELLED.

resolver.setLocalAddress([ipv4][, ipv6])#

Added in: v15.1.0, v14.17.0


ipv4 <string> A string representation of an IPv4 address.
Default: '0.0.0.0'
ipv6 <string> A string representation of an IPv6 address.
Default: '::0'

The resolver instance will send its requests from the specified IP address.
This allows programs to specify outbound interfaces when used on multi-homed
systems.
If a v4 or v6 address is not specified, it is set to the default and the
operating system will choose a local address automatically.
The resolver will use the v4 local address when making requests to IPv4 DNS
servers, and the v6 local address when making requests to IPv6 DNS servers.
The rrtype of resolution requests has no impact on the local address used.

dns.getServers()#

Added in: v0.11.3


Returns: <string[]>

Returns an array of IP address strings, formatted according to RFC 5952,
that are currently configured for DNS resolution. A string will include a port
section if a custom port is used.

[
  '8.8.8.8',
  '2001:4860:4860::8888',
  '8.8.8.8:1053',
  '[2001:4860:4860::8888]:1053',
] copy
dns.lookup(hostname[, options], callback)#

History

VersionChanges
v22.1.0, v20.13.0
The verbatim option is now deprecated in favor of the new order option.
v18.4.0
For compatibility with node:net, when passing an option object the family option can be the string 'IPv4' or the string 'IPv6'.
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v17.0.0
The verbatim options defaults to true now.
v8.5.0
The verbatim option is supported now.
v1.2.0
The all option is supported now.
v0.1.90
Added in: v0.1.90




hostname <string>
options <integer> | <Object>

family <integer> | <string> The record family. Must be 4, 6, or 0. For
backward compatibility reasons,'IPv4' and 'IPv6' are interpreted as 4
and 6 respectively. The value 0 indicates that either an IPv4 or IPv6
address is returned. If the value 0 is used with { all: true } (see
below), either one of or both IPv4 and IPv6 addresses are returned,
depending on the system's DNS resolver. Default: 0.
hints <number> One or more supported getaddrinfo flags. Multiple
flags may be passed by bitwise ORing their values.
all <boolean> When true, the callback returns all resolved addresses in
an array. Otherwise, returns a single address. Default: false.
order <string> When verbatim, the resolved addresses are return
unsorted. When ipv4first, the resolved addresses are sorted by placing
IPv4 addresses before IPv6 addresses. When ipv6first, the resolved
addresses are sorted by placing IPv6 addresses before IPv4 addresses.
Default: verbatim (addresses are not reordered).
Default value is configurable using dns.setDefaultResultOrder() or
--dns-result-order.
verbatim <boolean> When true, the callback receives IPv4 and IPv6
addresses in the order the DNS resolver returned them. When false,
IPv4 addresses are placed before IPv6 addresses.
This option will be deprecated in favor of order. When both are specified,
order has higher precedence. New code should only use order.
Default: true (addresses are not reordered). Default value is
configurable using dns.setDefaultResultOrder() or
--dns-result-order.


callback <Function>

err <Error>
address <string> A string representation of an IPv4 or IPv6 address.
family <integer> 4 or 6, denoting the family of address, or 0 if
the address is not an IPv4 or IPv6 address. 0 is a likely indicator of a
bug in the name resolution service used by the operating system.



Resolves a host name (e.g. 'nodejs.org') into the first found A (IPv4) or
AAAA (IPv6) record. All option properties are optional. If options is an
integer, then it must be 4 or 6 – if options is not provided, then
either IPv4 or IPv6 addresses, or both, are returned if found.
With the all option set to true, the arguments for callback change to
(err, addresses), with addresses being an array of objects with the
properties address and family.
On error, err is an Error object, where err.code is the error code.
Keep in mind that err.code will be set to 'ENOTFOUND' not only when
the host name does not exist but also when the lookup fails in other ways
such as no available file descriptors.
dns.lookup() does not necessarily have anything to do with the DNS protocol.
The implementation uses an operating system facility that can associate names
with addresses and vice versa. This implementation can have subtle but
important consequences on the behavior of any Node.js program. Please take some
time to consult the Implementation considerations section before using
dns.lookup().
Example usage:

import dns from 'node:dns';
const options = {
  family: 6,
  hints: dns.ADDRCONFIG | dns.V4MAPPED,
};
dns.lookup('example.org', options, (err, address, family) =>
  console.log('address: %j family: IPv%s', address, family));
// address: "2606:2800:21f:cb07:6820:80da:af6b:8b2c" family: IPv6

// When options.all is true, the result will be an Array.
options.all = true;
dns.lookup('example.org', options, (err, addresses) =>
  console.log('addresses: %j', addresses));
// addresses: [{"address":"2606:2800:21f:cb07:6820:80da:af6b:8b2c","family":6}]const dns = require('node:dns');
const options = {
  family: 6,
  hints: dns.ADDRCONFIG | dns.V4MAPPED,
};
dns.lookup('example.org', options, (err, address, family) =>
  console.log('address: %j family: IPv%s', address, family));
// address: "2606:2800:21f:cb07:6820:80da:af6b:8b2c" family: IPv6

// When options.all is true, the result will be an Array.
options.all = true;
dns.lookup('example.org', options, (err, addresses) =>
  console.log('addresses: %j', addresses));
// addresses: [{"address":"2606:2800:21f:cb07:6820:80da:af6b:8b2c","family":6}]copy
If this method is invoked as its util.promisify()ed version, and all
is not set to true, it returns a Promise for an Object with address and
family properties.

Supported getaddrinfo flags#

History

VersionChanges
v13.13.0, v12.17.0
Added support for the dns.ALL flag.



The following flags can be passed as hints to dns.lookup().

dns.ADDRCONFIG: Limits returned address types to the types of non-loopback
addresses configured on the system. For example, IPv4 addresses are only
returned if the current system has at least one IPv4 address configured.
dns.V4MAPPED: If the IPv6 family was specified, but no IPv6 addresses were
found, then return IPv4 mapped IPv6 addresses. It is not supported
on some operating systems (e.g. FreeBSD 10.1).
dns.ALL: If dns.V4MAPPED is specified, return resolved IPv6 addresses as
well as IPv4 mapped IPv6 addresses.


dns.lookupService(address, port, callback)#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v0.11.14
Added in: v0.11.14




address <string>
port <number>
callback <Function>

err <Error>
hostname <string> e.g. example.com
service <string> e.g. http



Resolves the given address and port into a host name and service using
the operating system's underlying getnameinfo implementation.
If address is not a valid IP address, a TypeError will be thrown.
The port will be coerced to a number. If it is not a legal port, a TypeError
will be thrown.
On an error, err is an Error object, where err.code is the error code.

import dns from 'node:dns';
dns.lookupService('127.0.0.1', 22, (err, hostname, service) => {
  console.log(hostname, service);
  // Prints: localhost ssh
});const dns = require('node:dns');
dns.lookupService('127.0.0.1', 22, (err, hostname, service) => {
  console.log(hostname, service);
  // Prints: localhost ssh
});copy
If this method is invoked as its util.promisify()ed version, it returns a
Promise for an Object with hostname and service properties.
dns.resolve(hostname[, rrtype], callback)#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v0.1.27
Added in: v0.1.27




hostname <string> Host name to resolve.
rrtype <string> Resource record type. Default: 'A'.
callback <Function>

err <Error>
records <string[]> | <Object[]> | <Object>



Uses the DNS protocol to resolve a host name (e.g. 'nodejs.org') into an array
of the resource records. The callback function has arguments
(err, records). When successful, records will be an array of resource
records. The type and structure of individual results varies based on rrtype:

























































































rrtyperecords containsResult typeShorthand method'A'IPv4 addresses (default)<string>dns.resolve4()'AAAA'IPv6 addresses<string>dns.resolve6()'ANY'any records<Object>dns.resolveAny()'CAA'CA authorization records<Object>dns.resolveCaa()'CNAME'canonical name records<string>dns.resolveCname()'MX'mail exchange records<Object>dns.resolveMx()'NAPTR'name authority pointer records<Object>dns.resolveNaptr()'NS'name server records<string>dns.resolveNs()'PTR'pointer records<string>dns.resolvePtr()'SOA'start of authority records<Object>dns.resolveSoa()'SRV'service records<Object>dns.resolveSrv()'TLSA'certificate associations<Object>dns.resolveTlsa()'TXT'text records<string[]>dns.resolveTxt()
On error, err is an Error object, where err.code is one of the
DNS error codes.
dns.resolve4(hostname[, options], callback)#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v7.2.0
This method now supports passing options, specifically options.ttl.
v0.1.16
Added in: v0.1.16




hostname <string> Host name to resolve.
options <Object>

ttl <boolean> Retrieves the Time-To-Live value (TTL) of each record.
When true, the callback receives an array of
{ address: '1.2.3.4', ttl: 60 } objects rather than an array of strings,
with the TTL expressed in seconds.


callback <Function>

err <Error>
addresses <string[]> | <Object[]>



Uses the DNS protocol to resolve a IPv4 addresses (A records) for the
hostname. The addresses argument passed to the callback function
will contain an array of IPv4 addresses (e.g.
['74.125.79.104', '74.125.79.105', '74.125.79.106']).
dns.resolve6(hostname[, options], callback)#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v7.2.0
This method now supports passing options, specifically options.ttl.
v0.1.16
Added in: v0.1.16




hostname <string> Host name to resolve.
options <Object>

ttl <boolean> Retrieve the Time-To-Live value (TTL) of each record.
When true, the callback receives an array of
{ address: '0:1:2:3:4:5:6:7', ttl: 60 } objects rather than an array of
strings, with the TTL expressed in seconds.


callback <Function>

err <Error>
addresses <string[]> | <Object[]>



Uses the DNS protocol to resolve IPv6 addresses (AAAA records) for the
hostname. The addresses argument passed to the callback function
will contain an array of IPv6 addresses.
dns.resolveAny(hostname, callback)#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.




hostname <string>
callback <Function>

err <Error>
ret <Object[]>



Uses the DNS protocol to resolve all records (also known as ANY or * query).
The ret argument passed to the callback function will be an array containing
various types of records. Each object has a property type that indicates the
type of the current record. And depending on the type, additional properties
will be present on the object:





















































TypeProperties'A'address/ttl'AAAA'address/ttl'CNAME'value'MX'Refer to dns.resolveMx()'NAPTR'Refer to dns.resolveNaptr()'NS'value'PTR'value'SOA'Refer to dns.resolveSoa()'SRV'Refer to dns.resolveSrv()'TLSA'Refer to dns.resolveTlsa()'TXT'This type of record contains an array property called entries which refers to dns.resolveTxt(), e.g. { entries: ['...'], type: 'TXT' }
Here is an example of the ret object passed to the callback:

[ { type: 'A', address: '127.0.0.1', ttl: 299 },
  { type: 'CNAME', value: 'example.com' },
  { type: 'MX', exchange: 'alt4.aspmx.l.example.com', priority: 50 },
  { type: 'NS', value: 'ns1.example.com' },
  { type: 'TXT', entries: [ 'v=spf1 include:_spf.example.com ~all' ] },
  { type: 'SOA',
    nsname: 'ns1.example.com',
    hostmaster: 'admin.example.com',
    serial: 156696742,
    refresh: 900,
    retry: 900,
    expire: 1800,
    minttl: 60 } ] copy
DNS server operators may choose not to respond to ANY
queries. It may be better to call individual methods like dns.resolve4(),
dns.resolveMx(), and so on. For more details, see RFC 8482.
dns.resolveCname(hostname, callback)#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v0.3.2
Added in: v0.3.2




hostname <string>
callback <Function>

err <Error>
addresses <string[]>



Uses the DNS protocol to resolve CNAME records for the hostname. The
addresses argument passed to the callback function
will contain an array of canonical name records available for the hostname
(e.g. ['bar.example.com']).
dns.resolveCaa(hostname, callback)#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v15.0.0, v14.17.0
Added in: v15.0.0, v14.17.0




hostname <string>
callback <Function>

err <Error>
records <Object[]>



Uses the DNS protocol to resolve CAA records for the hostname. The
addresses argument passed to the callback function
will contain an array of certification authority authorization records
available for the hostname (e.g. [{critical: 0, iodef: 'mailto:pki@example.com'}, {critical: 128, issue: 'pki.example.com'}]).
dns.resolveMx(hostname, callback)#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v0.1.27
Added in: v0.1.27




hostname <string>
callback <Function>

err <Error>
addresses <Object[]>



Uses the DNS protocol to resolve mail exchange records (MX records) for the
hostname. The addresses argument passed to the callback function will
contain an array of objects containing both a priority and exchange
property (e.g. [{priority: 10, exchange: 'mx.example.com'}, ...]).
dns.resolveNaptr(hostname, callback)#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v0.9.12
Added in: v0.9.12




hostname <string>
callback <Function>

err <Error>
addresses <Object[]>



Uses the DNS protocol to resolve regular expression-based records (NAPTR
records) for the hostname. The addresses argument passed to the callback
function will contain an array of objects with the following properties:

flags
service
regexp
replacement
order
preference


{
  flags: 's',
  service: 'SIP+D2U',
  regexp: '',
  replacement: '_sip._udp.example.com',
  order: 30,
  preference: 100
} copy
dns.resolveNs(hostname, callback)#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v0.1.90
Added in: v0.1.90




hostname <string>
callback <Function>

err <Error>
addresses <string[]>



Uses the DNS protocol to resolve name server records (NS records) for the
hostname. The addresses argument passed to the callback function will
contain an array of name server records available for hostname
(e.g. ['ns1.example.com', 'ns2.example.com']).
dns.resolvePtr(hostname, callback)#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v6.0.0
Added in: v6.0.0




hostname <string>
callback <Function>

err <Error>
addresses <string[]>



Uses the DNS protocol to resolve pointer records (PTR records) for the
hostname. The addresses argument passed to the callback function will
be an array of strings containing the reply records.
dns.resolveSoa(hostname, callback)#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v0.11.10
Added in: v0.11.10




hostname <string>
callback <Function>

err <Error>
address <Object>



Uses the DNS protocol to resolve a start of authority record (SOA record) for
the hostname. The address argument passed to the callback function will
be an object with the following properties:

nsname
hostmaster
serial
refresh
retry
expire
minttl


{
  nsname: 'ns.example.com',
  hostmaster: 'root.example.com',
  serial: 2013101809,
  refresh: 10000,
  retry: 2400,
  expire: 604800,
  minttl: 3600
} copy
dns.resolveSrv(hostname, callback)#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v0.1.27
Added in: v0.1.27




hostname <string>
callback <Function>

err <Error>
addresses <Object[]>



Uses the DNS protocol to resolve service records (SRV records) for the
hostname. The addresses argument passed to the callback function will
be an array of objects with the following properties:

priority
weight
port
name


{
  priority: 10,
  weight: 5,
  port: 21223,
  name: 'service.example.com'
} copy
dns.resolveTlsa(hostname, callback)#

Added in: v23.9.0, v22.15.0



hostname <string>
callback <Function>

err <Error>
records <Object[]>




Uses the DNS protocol to resolve certificate associations (TLSA records) for
the hostname. The records argument passed to the callback function is an
array of objects with these properties:

certUsage
selector
match
data


{
  certUsage: 3,
  selector: 1,
  match: 1,
  data: [ArrayBuffer]
} copy
dns.resolveTxt(hostname, callback)#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v0.1.27
Added in: v0.1.27





hostname <string>
callback <Function>

err <Error>
records <string[][]>




Uses the DNS protocol to resolve text queries (TXT records) for the
hostname. The records argument passed to the callback function is a
two-dimensional array of the text records available for hostname (e.g.
[ ['v=spf1 ip4:0.0.0.0 ', '~all' ] ]). Each sub-array contains TXT chunks of
one record. Depending on the use case, these could be either joined together or
treated separately.
dns.reverse(ip, callback)#

Added in: v0.1.16


ip <string>
callback <Function>

err <Error>
hostnames <string[]>



Performs a reverse DNS query that resolves an IPv4 or IPv6 address to an
array of host names.
On error, err is an Error object, where err.code is
one of the DNS error codes.
dns.setDefaultResultOrder(order)#

History

VersionChanges
v22.1.0, v20.13.0
The ipv6first value is supported now.
v17.0.0
Changed default value to verbatim.
v16.4.0, v14.18.0
Added in: v16.4.0, v14.18.0




order <string> must be 'ipv4first', 'ipv6first' or 'verbatim'.

Set the default value of order in dns.lookup() and
dnsPromises.lookup(). The value could be:

ipv4first: sets default order to ipv4first.
ipv6first: sets default order to ipv6first.
verbatim: sets default order to verbatim.

The default is verbatim and dns.setDefaultResultOrder() have higher
priority than --dns-result-order. When using worker threads,
dns.setDefaultResultOrder() from the main thread won't affect the default
dns orders in workers.
dns.getDefaultResultOrder()#

History

VersionChanges
v22.1.0, v20.13.0
The ipv6first value is supported now.
v20.1.0, v18.17.0
Added in: v20.1.0, v18.17.0



Get the default value for order in dns.lookup() and
dnsPromises.lookup(). The value could be:

ipv4first: for order defaulting to ipv4first.
ipv6first: for order defaulting to ipv6first.
verbatim: for order defaulting to verbatim.

dns.setServers(servers)#

Added in: v0.11.3


servers <string[]> array of RFC 5952 formatted addresses

Sets the IP address and port of servers to be used when performing DNS
resolution. The servers argument is an array of RFC 5952 formatted
addresses. If the port is the IANA default DNS port (53) it can be omitted.
dns.setServers([
  '8.8.8.8',
  '[2001:4860:4860::8888]',
  '8.8.8.8:1053',
  '[2001:4860:4860::8888]:1053',
]); copy
An error will be thrown if an invalid address is provided.
The dns.setServers() method must not be called while a DNS query is in
progress.
The dns.setServers() method affects only dns.resolve(),
dns.resolve*() and dns.reverse() (and specifically not
dns.lookup()).
This method works much like
resolve.conf.
That is, if attempting to resolve with the first server provided results in a
NOTFOUND error, the resolve() method will not attempt to resolve with
subsequent servers provided. Fallback DNS servers will only be used if the
earlier ones time out or result in some other error.
DNS promises API#

History

VersionChanges
v15.0.0
Exposed as require('dns/promises').
v11.14.0, v10.17.0
This API is no longer experimental.
v10.6.0
Added in: v10.6.0



The dns.promises API provides an alternative set of asynchronous DNS methods
that return Promise objects rather than using callbacks. The API is accessible
via require('node:dns').promises or require('node:dns/promises').

Class: dnsPromises.Resolver#

Added in: v10.6.0

An independent resolver for DNS requests.
Creating a new resolver uses the default server settings. Setting
the servers used for a resolver using
resolver.setServers() does not affect
other resolvers:

import { Resolver } from 'node:dns/promises';
const resolver = new Resolver();
resolver.setServers(['4.4.4.4']);

// This request will use the server at 4.4.4.4, independent of global settings.
const addresses = await resolver.resolve4('example.org');const { Resolver } = require('node:dns').promises;
const resolver = new Resolver();
resolver.setServers(['4.4.4.4']);

// This request will use the server at 4.4.4.4, independent of global settings.
resolver.resolve4('example.org').then((addresses) => {
  // ...
});

// Alternatively, the same code can be written using async-await style.
(async function() {
  const addresses = await resolver.resolve4('example.org');
})();copy
The following methods from the dnsPromises API are available:

resolver.getServers()
resolver.resolve()
resolver.resolve4()
resolver.resolve6()
resolver.resolveAny()
resolver.resolveCaa()
resolver.resolveCname()
resolver.resolveMx()
resolver.resolveNaptr()
resolver.resolveNs()
resolver.resolvePtr()
resolver.resolveSoa()
resolver.resolveSrv()
resolver.resolveTlsa()
resolver.resolveTxt()
resolver.reverse()
resolver.setServers()


resolver.cancel()#

Added in: v15.3.0, v14.17.0

Cancel all outstanding DNS queries made by this resolver. The corresponding
promises will be rejected with an error with the code ECANCELLED.

dnsPromises.getServers()#

Added in: v10.6.0


Returns: <string[]>

Returns an array of IP address strings, formatted according to RFC 5952,
that are currently configured for DNS resolution. A string will include a port
section if a custom port is used.

[
  '8.8.8.8',
  '2001:4860:4860::8888',
  '8.8.8.8:1053',
  '[2001:4860:4860::8888]:1053',
] copy

dnsPromises.lookup(hostname[, options])#

History

VersionChanges
v22.1.0, v20.13.0
The verbatim option is now deprecated in favor of the new order option.
v10.6.0
Added in: v10.6.0




hostname <string>
options <integer> | <Object>

family <integer> The record family. Must be 4, 6, or 0. The value
0 indicates that either an IPv4 or IPv6 address is returned. If the
value 0 is used with { all: true } (see below), either one of or both
IPv4 and IPv6 addresses are returned, depending on the system's DNS
resolver. Default: 0.
hints <number> One or more supported getaddrinfo flags. Multiple
flags may be passed by bitwise ORing their values.
all <boolean> When true, the Promise is resolved with all addresses in
an array. Otherwise, returns a single address. Default: false.
order <string> When verbatim, the Promise is resolved with IPv4 and
IPv6 addresses in the order the DNS resolver returned them. When ipv4first,
IPv4 addresses are placed before IPv6 addresses. When ipv6first,
IPv6 addresses are placed before IPv4 addresses.
Default: verbatim (addresses are not reordered).
Default value is configurable using dns.setDefaultResultOrder() or
--dns-result-order. New code should use { order: 'verbatim' }.
verbatim <boolean> When true, the Promise is resolved with IPv4 and
IPv6 addresses in the order the DNS resolver returned them. When false,
IPv4 addresses are placed before IPv6 addresses.
This option will be deprecated in favor of order. When both are specified,
order has higher precedence. New code should only use order.
Default: currently false (addresses are reordered) but this is
expected to change in the not too distant future. Default value is
configurable using dns.setDefaultResultOrder() or
--dns-result-order.



Resolves a host name (e.g. 'nodejs.org') into the first found A (IPv4) or
AAAA (IPv6) record. All option properties are optional. If options is an
integer, then it must be 4 or 6 – if options is not provided, then
either IPv4 or IPv6 addresses, or both, are returned if found.
With the all option set to true, the Promise is resolved with addresses
being an array of objects with the properties address and family.
On error, the Promise is rejected with an Error object, where err.code
is the error code.
Keep in mind that err.code will be set to 'ENOTFOUND' not only when
the host name does not exist but also when the lookup fails in other ways
such as no available file descriptors.
dnsPromises.lookup() does not necessarily have anything to do with the DNS
protocol. The implementation uses an operating system facility that can
associate names with addresses and vice versa. This implementation can have
subtle but important consequences on the behavior of any Node.js program. Please
take some time to consult the Implementation considerations section before
using dnsPromises.lookup().
Example usage:

import dns from 'node:dns';
const dnsPromises = dns.promises;
const options = {
  family: 6,
  hints: dns.ADDRCONFIG | dns.V4MAPPED,
};

await dnsPromises.lookup('example.org', options).then((result) => {
  console.log('address: %j family: IPv%s', result.address, result.family);
  // address: "2606:2800:21f:cb07:6820:80da:af6b:8b2c" family: IPv6
});

// When options.all is true, the result will be an Array.
options.all = true;
await dnsPromises.lookup('example.org', options).then((result) => {
  console.log('addresses: %j', result);
  // addresses: [{"address":"2606:2800:21f:cb07:6820:80da:af6b:8b2c","family":6}]
});const dns = require('node:dns');
const dnsPromises = dns.promises;
const options = {
  family: 6,
  hints: dns.ADDRCONFIG | dns.V4MAPPED,
};

dnsPromises.lookup('example.org', options).then((result) => {
  console.log('address: %j family: IPv%s', result.address, result.family);
  // address: "2606:2800:21f:cb07:6820:80da:af6b:8b2c" family: IPv6
});

// When options.all is true, the result will be an Array.
options.all = true;
dnsPromises.lookup('example.org', options).then((result) => {
  console.log('addresses: %j', result);
  // addresses: [{"address":"2606:2800:21f:cb07:6820:80da:af6b:8b2c","family":6}]
});copy

dnsPromises.lookupService(address, port)#

Added in: v10.6.0


address <string>
port <number>

Resolves the given address and port into a host name and service using
the operating system's underlying getnameinfo implementation.
If address is not a valid IP address, a TypeError will be thrown.
The port will be coerced to a number. If it is not a legal port, a TypeError
will be thrown.
On error, the Promise is rejected with an Error object, where err.code
is the error code.

import dnsPromises from 'node:dns/promises';
const result = await dnsPromises.lookupService('127.0.0.1', 22);

console.log(result.hostname, result.service); // Prints: localhost sshconst dnsPromises = require('node:dns').promises;
dnsPromises.lookupService('127.0.0.1', 22).then((result) => {
  console.log(result.hostname, result.service);
  // Prints: localhost ssh
});copy

dnsPromises.resolve(hostname[, rrtype])#

Added in: v10.6.0


hostname <string> Host name to resolve.
rrtype <string> Resource record type. Default: 'A'.

Uses the DNS protocol to resolve a host name (e.g. 'nodejs.org') into an array
of the resource records. When successful, the Promise is resolved with an
array of resource records. The type and structure of individual results vary
based on rrtype:

























































































rrtyperecords containsResult typeShorthand method'A'IPv4 addresses (default)<string>dnsPromises.resolve4()'AAAA'IPv6 addresses<string>dnsPromises.resolve6()'ANY'any records<Object>dnsPromises.resolveAny()'CAA'CA authorization records<Object>dnsPromises.resolveCaa()'CNAME'canonical name records<string>dnsPromises.resolveCname()'MX'mail exchange records<Object>dnsPromises.resolveMx()'NAPTR'name authority pointer records<Object>dnsPromises.resolveNaptr()'NS'name server records<string>dnsPromises.resolveNs()'PTR'pointer records<string>dnsPromises.resolvePtr()'SOA'start of authority records<Object>dnsPromises.resolveSoa()'SRV'service records<Object>dnsPromises.resolveSrv()'TLSA'certificate associations<Object>dnsPromises.resolveTlsa()'TXT'text records<string[]>dnsPromises.resolveTxt()
On error, the Promise is rejected with an Error object, where err.code
is one of the DNS error codes.

dnsPromises.resolve4(hostname[, options])#

Added in: v10.6.0


hostname <string> Host name to resolve.
options <Object>

ttl <boolean> Retrieve the Time-To-Live value (TTL) of each record.
When true, the Promise is resolved with an array of
{ address: '1.2.3.4', ttl: 60 } objects rather than an array of strings,
with the TTL expressed in seconds.



Uses the DNS protocol to resolve IPv4 addresses (A records) for the
hostname. On success, the Promise is resolved with an array of IPv4
addresses (e.g. ['74.125.79.104', '74.125.79.105', '74.125.79.106']).

dnsPromises.resolve6(hostname[, options])#

Added in: v10.6.0


hostname <string> Host name to resolve.
options <Object>

ttl <boolean> Retrieve the Time-To-Live value (TTL) of each record.
When true, the Promise is resolved with an array of
{ address: '0:1:2:3:4:5:6:7', ttl: 60 } objects rather than an array of
strings, with the TTL expressed in seconds.



Uses the DNS protocol to resolve IPv6 addresses (AAAA records) for the
hostname. On success, the Promise is resolved with an array of IPv6
addresses.

dnsPromises.resolveAny(hostname)#

Added in: v10.6.0


hostname <string>

Uses the DNS protocol to resolve all records (also known as ANY or * query).
On success, the Promise is resolved with an array containing various types of
records. Each object has a property type that indicates the type of the
current record. And depending on the type, additional properties will be
present on the object:





















































TypeProperties'A'address/ttl'AAAA'address/ttl'CNAME'value'MX'Refer to dnsPromises.resolveMx()'NAPTR'Refer to dnsPromises.resolveNaptr()'NS'value'PTR'value'SOA'Refer to dnsPromises.resolveSoa()'SRV'Refer to dnsPromises.resolveSrv()'TLSA'Refer to dnsPromises.resolveTlsa()'TXT'This type of record contains an array property called entries which refers to dnsPromises.resolveTxt(), e.g. { entries: ['...'], type: 'TXT' }
Here is an example of the result object:

[ { type: 'A', address: '127.0.0.1', ttl: 299 },
  { type: 'CNAME', value: 'example.com' },
  { type: 'MX', exchange: 'alt4.aspmx.l.example.com', priority: 50 },
  { type: 'NS', value: 'ns1.example.com' },
  { type: 'TXT', entries: [ 'v=spf1 include:_spf.example.com ~all' ] },
  { type: 'SOA',
    nsname: 'ns1.example.com',
    hostmaster: 'admin.example.com',
    serial: 156696742,
    refresh: 900,
    retry: 900,
    expire: 1800,
    minttl: 60 } ] copy

dnsPromises.resolveCaa(hostname)#

Added in: v15.0.0, v14.17.0


hostname <string>

Uses the DNS protocol to resolve CAA records for the hostname. On success,
the Promise is resolved with an array of objects containing available
certification authority authorization records available for the hostname
(e.g. [{critical: 0, iodef: 'mailto:pki@example.com'},{critical: 128, issue: 'pki.example.com'}]).

dnsPromises.resolveCname(hostname)#

Added in: v10.6.0


hostname <string>

Uses the DNS protocol to resolve CNAME records for the hostname. On success,
the Promise is resolved with an array of canonical name records available for
the hostname (e.g. ['bar.example.com']).

dnsPromises.resolveMx(hostname)#

Added in: v10.6.0


hostname <string>

Uses the DNS protocol to resolve mail exchange records (MX records) for the
hostname. On success, the Promise is resolved with an array of objects
containing both a priority and exchange property (e.g.
[{priority: 10, exchange: 'mx.example.com'}, ...]).

dnsPromises.resolveNaptr(hostname)#

Added in: v10.6.0


hostname <string>

Uses the DNS protocol to resolve regular expression-based records (NAPTR
records) for the hostname. On success, the Promise is resolved with an array
of objects with the following properties:

flags
service
regexp
replacement
order
preference


{
  flags: 's',
  service: 'SIP+D2U',
  regexp: '',
  replacement: '_sip._udp.example.com',
  order: 30,
  preference: 100
} copy

dnsPromises.resolveNs(hostname)#

Added in: v10.6.0


hostname <string>

Uses the DNS protocol to resolve name server records (NS records) for the
hostname. On success, the Promise is resolved with an array of name server
records available for hostname (e.g.
['ns1.example.com', 'ns2.example.com']).

dnsPromises.resolvePtr(hostname)#

Added in: v10.6.0


hostname <string>

Uses the DNS protocol to resolve pointer records (PTR records) for the
hostname. On success, the Promise is resolved with an array of strings
containing the reply records.

dnsPromises.resolveSoa(hostname)#

Added in: v10.6.0


hostname <string>

Uses the DNS protocol to resolve a start of authority record (SOA record) for
the hostname. On success, the Promise is resolved with an object with the
following properties:

nsname
hostmaster
serial
refresh
retry
expire
minttl


{
  nsname: 'ns.example.com',
  hostmaster: 'root.example.com',
  serial: 2013101809,
  refresh: 10000,
  retry: 2400,
  expire: 604800,
  minttl: 3600
} copy

dnsPromises.resolveSrv(hostname)#

Added in: v10.6.0


hostname <string>

Uses the DNS protocol to resolve service records (SRV records) for the
hostname. On success, the Promise is resolved with an array of objects with
the following properties:

priority
weight
port
name


{
  priority: 10,
  weight: 5,
  port: 21223,
  name: 'service.example.com'
} copy

dnsPromises.resolveTlsa(hostname)#

Added in: v23.9.0, v22.15.0


hostname <string>

Uses the DNS protocol to resolve certificate associations (TLSA records) for
the hostname. On success, the Promise is resolved with an array of objects
with these properties:

certUsage
selector
match
data


{
  certUsage: 3,
  selector: 1,
  match: 1,
  data: [ArrayBuffer]
} copy

dnsPromises.resolveTxt(hostname)#

Added in: v10.6.0


hostname <string>

Uses the DNS protocol to resolve text queries (TXT records) for the
hostname. On success, the Promise is resolved with a two-dimensional array
of the text records available for hostname (e.g.
[ ['v=spf1 ip4:0.0.0.0 ', '~all' ] ]). Each sub-array contains TXT chunks of
one record. Depending on the use case, these could be either joined together or
treated separately.

dnsPromises.reverse(ip)#

Added in: v10.6.0


ip <string>

Performs a reverse DNS query that resolves an IPv4 or IPv6 address to an
array of host names.
On error, the Promise is rejected with an Error object, where err.code
is one of the DNS error codes.

dnsPromises.setDefaultResultOrder(order)#

History

VersionChanges
v22.1.0, v20.13.0
The ipv6first value is supported now.
v17.0.0
Changed default value to verbatim.
v16.4.0, v14.18.0
Added in: v16.4.0, v14.18.0




order <string> must be 'ipv4first', 'ipv6first' or 'verbatim'.

Set the default value of order in dns.lookup() and
dnsPromises.lookup(). The value could be:

ipv4first: sets default order to ipv4first.
ipv6first: sets default order to ipv6first.
verbatim: sets default order to verbatim.

The default is verbatim and dnsPromises.setDefaultResultOrder() have
higher priority than --dns-result-order. When using worker threads,
dnsPromises.setDefaultResultOrder() from the main thread won't affect the
default dns orders in workers.

dnsPromises.getDefaultResultOrder()#

Added in: v20.1.0, v18.17.0

Get the value of dnsOrder.

dnsPromises.setServers(servers)#

Added in: v10.6.0


servers <string[]> array of RFC 5952 formatted addresses

Sets the IP address and port of servers to be used when performing DNS
resolution. The servers argument is an array of RFC 5952 formatted
addresses. If the port is the IANA default DNS port (53) it can be omitted.
dnsPromises.setServers([
  '8.8.8.8',
  '[2001:4860:4860::8888]',
  '8.8.8.8:1053',
  '[2001:4860:4860::8888]:1053',
]); copy
An error will be thrown if an invalid address is provided.
The dnsPromises.setServers() method must not be called while a DNS query is in
progress.
This method works much like
resolve.conf.
That is, if attempting to resolve with the first server provided results in a
NOTFOUND error, the resolve() method will not attempt to resolve with
subsequent servers provided. Fallback DNS servers will only be used if the
earlier ones time out or result in some other error.

Error codes#
Each DNS query can return one of the following error codes:

dns.NODATA: DNS server returned an answer with no data.
dns.FORMERR: DNS server claims query was misformatted.
dns.SERVFAIL: DNS server returned general failure.
dns.NOTFOUND: Domain name not found.
dns.NOTIMP: DNS server does not implement the requested operation.
dns.REFUSED: DNS server refused query.
dns.BADQUERY: Misformatted DNS query.
dns.BADNAME: Misformatted host name.
dns.BADFAMILY: Unsupported address family.
dns.BADRESP: Misformatted DNS reply.
dns.CONNREFUSED: Could not contact DNS servers.
dns.TIMEOUT: Timeout while contacting DNS servers.
dns.EOF: End of file.
dns.FILE: Error reading file.
dns.NOMEM: Out of memory.
dns.DESTRUCTION: Channel is being destroyed.
dns.BADSTR: Misformatted string.
dns.BADFLAGS: Illegal flags specified.
dns.NONAME: Given host name is not numeric.
dns.BADHINTS: Illegal hints flags specified.
dns.NOTINITIALIZED: c-ares library initialization not yet performed.
dns.LOADIPHLPAPI: Error loading iphlpapi.dll.
dns.ADDRGETNETWORKPARAMS: Could not find GetNetworkParams function.
dns.CANCELLED: DNS query cancelled.

The dnsPromises API also exports the above error codes, e.g., dnsPromises.NODATA.
Implementation considerations#
Although dns.lookup() and the various dns.resolve*()/dns.reverse()
functions have the same goal of associating a network name with a network
address (or vice versa), their behavior is quite different. These differences
can have subtle but significant consequences on the behavior of Node.js
programs.

dns.lookup()#
Under the hood, dns.lookup() uses the same operating system facilities
as most other programs. For instance, dns.lookup() will almost always
resolve a given name the same way as the ping command. On most POSIX-like
operating systems, the behavior of the dns.lookup() function can be
modified by changing settings in nsswitch.conf(5) and/or resolv.conf(5),
but changing these files will change the behavior of all other
programs running on the same operating system.
Though the call to dns.lookup() will be asynchronous from JavaScript's
perspective, it is implemented as a synchronous call to getaddrinfo(3) that runs
on libuv's threadpool. This can have surprising negative performance
implications for some applications, see the UV_THREADPOOL_SIZE
documentation for more information.
Various networking APIs will call dns.lookup() internally to resolve
host names. If that is an issue, consider resolving the host name to an address
using dns.resolve() and using the address instead of a host name. Also, some
networking APIs (such as socket.connect() and dgram.createSocket())
allow the default resolver, dns.lookup(), to be replaced.

dns.resolve(), dns.resolve*(), and dns.reverse()#
These functions are implemented quite differently than dns.lookup(). They
do not use getaddrinfo(3) and they always perform a DNS query on the
network. This network communication is always done asynchronously and does not
use libuv's threadpool.
As a result, these functions cannot have the same negative impact on other
processing that happens on libuv's threadpool that dns.lookup() can have.
They do not use the same set of configuration files that dns.lookup()
uses. For instance, they do not use the configuration from /etc/hosts.\n\n\n\nNode.js
        
      
      
About this documentation
Usage and example



Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Modules: TypeScript
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
Readline
REPL
Report
Single executable applications
SQLite
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker

    

    
      
        
          Node.js v24.0.1 documentation
          
            
            
          
        
        
          
            Node.js v24.0.1
            
    
      
        
        Table of contents
      

      
Domain

Warning: Don't ignore errors!
Additions to Error objects
Implicit binding
Explicit binding
domain.create()
Class: Domain

domain.members
domain.add(emitter)
domain.bind(callback)
domain.enter()
domain.exit()
domain.intercept(callback)
domain.remove(emitter)
domain.run(fn[, ...args])


Domains and promises



    
  
            
    
      
        
        Index
      

      
About this documentation
Usage and example

      
        Index
      
    
  


Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Modules: TypeScript
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
Readline
REPL
Report
Single executable applications
SQLite
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker

    
  
            
    
      
        
        Other versions
      
      24.x
23.x
22.x LTS
21.x
20.x LTS
19.x
18.x
17.x
16.x
15.x
14.x
13.x
12.x
11.x
10.x
9.x
8.x
7.x
6.x
5.x
4.x
0.12.x
0.10.x
    
  
            
              
                
                Options
              
        
              
                
                  
                    View on single page
                  
                  
                    View as JSON
                  
                  Edit on GitHub    
                
              
            
          
        
        
      

      Table of contents
Domain

Warning: Don't ignore errors!
Additions to Error objects
Implicit binding
Explicit binding
domain.create()
Class: Domain

domain.members
domain.add(emitter)
domain.bind(callback)
domain.enter()
domain.exit()
domain.intercept(callback)
domain.remove(emitter)
domain.run(fn[, ...args])


Domains and promises




      
        Domain#

History

VersionChanges
v8.8.0
Any Promises created in VM contexts no longer have a .domain property. Their handlers are still executed in the proper domain, however, and Promises created in the main context still possess a .domain property.
v8.0.0
Handlers for Promises are now invoked in the domain in which the first promise of a chain was created.
v1.4.2
Deprecated since: v1.4.2




Stability: 0 - Deprecated
Source Code: lib/domain.js
This module is pending deprecation. Once a replacement API has been
finalized, this module will be fully deprecated. Most developers should
not have cause to use this module. Users who absolutely must have
the functionality that domains provide may rely on it for the time being
but should expect to have to migrate to a different solution
in the future.
Domains provide a way to handle multiple different IO operations as a
single group. If any of the event emitters or callbacks registered to a
domain emit an 'error' event, or throw an error, then the domain object
will be notified, rather than losing the context of the error in the
process.on('uncaughtException') handler, or causing the program to
exit immediately with an error code.
Warning: Don't ignore errors!#

Domain error handlers are not a substitute for closing down a
process when an error occurs.
By the very nature of how throw works in JavaScript, there is almost
never any way to safely "pick up where it left off", without leaking
references, or creating some other sort of undefined brittle state.
The safest way to respond to a thrown error is to shut down the
process. Of course, in a normal web server, there may be many
open connections, and it is not reasonable to abruptly shut those down
because an error was triggered by someone else.
The better approach is to send an error response to the request that
triggered the error, while letting the others finish in their normal
time, and stop listening for new requests in that worker.
In this way, domain usage goes hand-in-hand with the cluster module,
since the primary process can fork a new worker when a worker
encounters an error. For Node.js programs that scale to multiple
machines, the terminating proxy or service registry can take note of
the failure, and react accordingly.
For example, this is not a good idea:
// XXX WARNING! BAD IDEA!

const d = require('node:domain').create();
d.on('error', (er) => {
  // The error won't crash the process, but what it does is worse!
  // Though we've prevented abrupt process restarting, we are leaking
  // a lot of resources if this ever happens.
  // This is no better than process.on('uncaughtException')!
  console.log(`error, but oh well ${er.message}`);
});
d.run(() => {
  require('node:http').createServer((req, res) => {
    handleRequest(req, res);
  }).listen(PORT);
}); copy
By using the context of a domain, and the resilience of separating our
program into multiple worker processes, we can react more
appropriately, and handle errors with much greater safety.
// Much better!

const cluster = require('node:cluster');
const PORT = +process.env.PORT || 1337;

if (cluster.isPrimary) {
  // A more realistic scenario would have more than 2 workers,
  // and perhaps not put the primary and worker in the same file.
  //
  // It is also possible to get a bit fancier about logging, and
  // implement whatever custom logic is needed to prevent DoS
  // attacks and other bad behavior.
  //
  // See the options in the cluster documentation.
  //
  // The important thing is that the primary does very little,
  // increasing our resilience to unexpected errors.

  cluster.fork();
  cluster.fork();

  cluster.on('disconnect', (worker) => {
    console.error('disconnect!');
    cluster.fork();
  });

} else {
  // the worker
  //
  // This is where we put our bugs!

  const domain = require('node:domain');

  // See the cluster documentation for more details about using
  // worker processes to serve requests. How it works, caveats, etc.

  const server = require('node:http').createServer((req, res) => {
    const d = domain.create();
    d.on('error', (er) => {
      console.error(`error ${er.stack}`);

      // We're in dangerous territory!
      // By definition, something unexpected occurred,
      // which we probably didn't want.
      // Anything can happen now! Be very careful!

      try {
        // Make sure we close down within 30 seconds
        const killtimer = setTimeout(() => {
          process.exit(1);
        }, 30000);
        // But don't keep the process open just for that!
        killtimer.unref();

        // Stop taking new requests.
        server.close();

        // Let the primary know we're dead. This will trigger a
        // 'disconnect' in the cluster primary, and then it will fork
        // a new worker.
        cluster.worker.disconnect();

        // Try to send an error to the request that triggered the problem
        res.statusCode = 500;
        res.setHeader('content-type', 'text/plain');
        res.end('Oops, there was a problem!\n');
      } catch (er2) {
        // Oh well, not much we can do at this point.
        console.error(`Error sending 500! ${er2.stack}`);
      }
    });

    // Because req and res were created before this domain existed,
    // we need to explicitly add them.
    // See the explanation of implicit vs explicit binding below.
    d.add(req);
    d.add(res);

    // Now run the handler function in the domain.
    d.run(() => {
      handleRequest(req, res);
    });
  });
  server.listen(PORT);
}

// This part is not important. Just an example routing thing.
// Put fancy application logic here.
function handleRequest(req, res) {
  switch (req.url) {
    case '/error':
      // We do some async stuff, and then...
      setTimeout(() => {
        // Whoops!
        flerb.bark();
      }, timeout);
      break;
    default:
      res.end('ok');
  }
} copy
Additions to Error objects#

Any time an Error object is routed through a domain, a few extra fields
are added to it.

error.domain The domain that first handled the error.
error.domainEmitter The event emitter that emitted an 'error' event
with the error object.
error.domainBound The callback function which was bound to the
domain, and passed an error as its first argument.
error.domainThrown A boolean indicating whether the error was
thrown, emitted, or passed to a bound callback function.

Implicit binding#

If domains are in use, then all new EventEmitter objects (including
Stream objects, requests, responses, etc.) will be implicitly bound to
the active domain at the time of their creation.
Additionally, callbacks passed to low-level event loop requests (such as
to fs.open(), or other callback-taking methods) will automatically be
bound to the active domain. If they throw, then the domain will catch
the error.
In order to prevent excessive memory usage, Domain objects themselves
are not implicitly added as children of the active domain. If they
were, then it would be too easy to prevent request and response objects
from being properly garbage collected.
To nest Domain objects as children of a parent Domain they must be
explicitly added.
Implicit binding routes thrown errors and 'error' events to the
Domain's 'error' event, but does not register the EventEmitter on the
Domain.
Implicit binding only takes care of thrown errors and 'error' events.
Explicit binding#

Sometimes, the domain in use is not the one that ought to be used for a
specific event emitter. Or, the event emitter could have been created
in the context of one domain, but ought to instead be bound to some
other domain.
For example, there could be one domain in use for an HTTP server, but
perhaps we would like to have a separate domain to use for each request.
That is possible via explicit binding.
// Create a top-level domain for the server
const domain = require('node:domain');
const http = require('node:http');
const serverDomain = domain.create();

serverDomain.run(() => {
  // Server is created in the scope of serverDomain
  http.createServer((req, res) => {
    // Req and res are also created in the scope of serverDomain
    // however, we'd prefer to have a separate domain for each request.
    // create it first thing, and add req and res to it.
    const reqd = domain.create();
    reqd.add(req);
    reqd.add(res);
    reqd.on('error', (er) => {
      console.error('Error', er, req.url);
      try {
        res.writeHead(500);
        res.end('Error occurred, sorry.');
      } catch (er2) {
        console.error('Error sending 500', er2, req.url);
      }
    });
  }).listen(1337);
}); copy
domain.create()#

Returns: <Domain>

Class: Domain#

Extends: <EventEmitter>

The Domain class encapsulates the functionality of routing errors and
uncaught exceptions to the active Domain object.
To handle the errors that it catches, listen to its 'error' event.

domain.members#

<Array>

An array of timers and event emitters that have been explicitly added
to the domain.

domain.add(emitter)#

emitter <EventEmitter> | <Timer> emitter or timer to be added to the domain

Explicitly adds an emitter to the domain. If any event handlers called by
the emitter throw an error, or if the emitter emits an 'error' event, it
will be routed to the domain's 'error' event, just like with implicit
binding.
This also works with timers that are returned from setInterval() and
setTimeout(). If their callback function throws, it will be caught by
the domain 'error' handler.
If the Timer or EventEmitter was already bound to a domain, it is removed
from that one, and bound to this one instead.

domain.bind(callback)#

callback <Function> The callback function
Returns: <Function> The bound function

The returned function will be a wrapper around the supplied callback
function. When the returned function is called, any errors that are
thrown will be routed to the domain's 'error' event.
const d = domain.create();

function readSomeFile(filename, cb) {
  fs.readFile(filename, 'utf8', d.bind((er, data) => {
    // If this throws, it will also be passed to the domain.
    return cb(er, data ? JSON.parse(data) : null);
  }));
}

d.on('error', (er) => {
  // An error occurred somewhere. If we throw it now, it will crash the program
  // with the normal line number and stack message.
}); copy

domain.enter()#
The enter() method is plumbing used by the run(), bind(), and
intercept() methods to set the active domain. It sets domain.active and
process.domain to the domain, and implicitly pushes the domain onto the domain
stack managed by the domain module (see domain.exit() for details on the
domain stack). The call to enter() delimits the beginning of a chain of
asynchronous calls and I/O operations bound to a domain.
Calling enter() changes only the active domain, and does not alter the domain
itself. enter() and exit() can be called an arbitrary number of times on a
single domain.

domain.exit()#
The exit() method exits the current domain, popping it off the domain stack.
Any time execution is going to switch to the context of a different chain of
asynchronous calls, it's important to ensure that the current domain is exited.
The call to exit() delimits either the end of or an interruption to the chain
of asynchronous calls and I/O operations bound to a domain.
If there are multiple, nested domains bound to the current execution context,
exit() will exit any domains nested within this domain.
Calling exit() changes only the active domain, and does not alter the domain
itself. enter() and exit() can be called an arbitrary number of times on a
single domain.

domain.intercept(callback)#

callback <Function> The callback function
Returns: <Function> The intercepted function

This method is almost identical to domain.bind(callback). However, in
addition to catching thrown errors, it will also intercept Error
objects sent as the first argument to the function.
In this way, the common if (err) return callback(err); pattern can be replaced
with a single error handler in a single place.
const d = domain.create();

function readSomeFile(filename, cb) {
  fs.readFile(filename, 'utf8', d.intercept((data) => {
    // Note, the first argument is never passed to the
    // callback since it is assumed to be the 'Error' argument
    // and thus intercepted by the domain.

    // If this throws, it will also be passed to the domain
    // so the error-handling logic can be moved to the 'error'
    // event on the domain instead of being repeated throughout
    // the program.
    return cb(null, JSON.parse(data));
  }));
}

d.on('error', (er) => {
  // An error occurred somewhere. If we throw it now, it will crash the program
  // with the normal line number and stack message.
}); copy

domain.remove(emitter)#

emitter <EventEmitter> | <Timer> emitter or timer to be removed from the domain

The opposite of domain.add(emitter). Removes domain handling from the
specified emitter.

domain.run(fn[, ...args])#

fn <Function>
...args <any>

Run the supplied function in the context of the domain, implicitly
binding all event emitters, timers, and low-level requests that are
created in that context. Optionally, arguments can be passed to
the function.
This is the most basic way to use a domain.
const domain = require('node:domain');
const fs = require('node:fs');
const d = domain.create();
d.on('error', (er) => {
  console.error('Caught error!', er);
});
d.run(() => {
  process.nextTick(() => {
    setTimeout(() => { // Simulating some various async stuff
      fs.open('non-existent file', 'r', (er, fd) => {
        if (er) throw er;
        // proceed...
      });
    }, 100);
  });
}); copy
In this example, the d.on('error') handler will be triggered, rather
than crashing the program.

Domains and promises#
As of Node.js 8.0.0, the handlers of promises are run inside the domain in
which the call to .then() or .catch() itself was made:
const d1 = domain.create();
const d2 = domain.create();

let p;
d1.run(() => {
  p = Promise.resolve(42);
});

d2.run(() => {
  p.then((v) => {
    // running in d2
  });
}); copy
A callback may be bound to a specific domain using domain.bind(callback):
const d1 = domain.create();
const d2 = domain.create();

let p;
d1.run(() => {
  p = Promise.resolve(42);
});

d2.run(() => {
  p.then(p.domain.bind((v) => {
    // running in d1
  }));
}); copy
Domains will not interfere with the error handling mechanisms for
promises. In other words, no 'error' event will be emitted for unhandled
Promise rejections.\n\n\n\nNode.js
        
      
      
About this documentation
Usage and example



Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Modules: TypeScript
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
Readline
REPL
Report
Single executable applications
SQLite
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker

    

    
      
        
          Node.js v24.0.1 documentation
          
            
            
          
        
        
          
            Node.js v24.0.1
            
    
      
        
        Table of contents
      

      
Errors

Error propagation and interception
Class: Error

new Error(message[, options])
Error.captureStackTrace(targetObject[, constructorOpt])
Error.stackTraceLimit
error.cause
error.code
error.message
error.stack


Class: AssertionError
Class: RangeError
Class: ReferenceError
Class: SyntaxError
Class: SystemError

error.address
error.code
error.dest
error.errno
error.info
error.message
error.path
error.port
error.syscall
Common system errors


Class: TypeError
Exceptions vs. errors
OpenSSL errors

error.opensslErrorStack
error.function
error.library
error.reason


Node.js error codes

ABORT_ERR
ERR_ACCESS_DENIED
ERR_AMBIGUOUS_ARGUMENT
ERR_ARG_NOT_ITERABLE
ERR_ASSERTION
ERR_ASYNC_CALLBACK
ERR_ASYNC_TYPE
ERR_BROTLI_COMPRESSION_FAILED
ERR_BROTLI_INVALID_PARAM
ERR_BUFFER_CONTEXT_NOT_AVAILABLE
ERR_BUFFER_OUT_OF_BOUNDS
ERR_BUFFER_TOO_LARGE
ERR_CANNOT_WATCH_SIGINT
ERR_CHILD_CLOSED_BEFORE_REPLY
ERR_CHILD_PROCESS_IPC_REQUIRED
ERR_CHILD_PROCESS_STDIO_MAXBUFFER
ERR_CLOSED_MESSAGE_PORT
ERR_CONSOLE_WRITABLE_STREAM
ERR_CONSTRUCT_CALL_INVALID
ERR_CONSTRUCT_CALL_REQUIRED
ERR_CONTEXT_NOT_INITIALIZED
ERR_CRYPTO_CUSTOM_ENGINE_NOT_SUPPORTED
ERR_CRYPTO_ECDH_INVALID_FORMAT
ERR_CRYPTO_ECDH_INVALID_PUBLIC_KEY
ERR_CRYPTO_ENGINE_UNKNOWN
ERR_CRYPTO_FIPS_FORCED
ERR_CRYPTO_FIPS_UNAVAILABLE
ERR_CRYPTO_HASH_FINALIZED
ERR_CRYPTO_HASH_UPDATE_FAILED
ERR_CRYPTO_INCOMPATIBLE_KEY
ERR_CRYPTO_INCOMPATIBLE_KEY_OPTIONS
ERR_CRYPTO_INITIALIZATION_FAILED
ERR_CRYPTO_INVALID_AUTH_TAG
ERR_CRYPTO_INVALID_COUNTER
ERR_CRYPTO_INVALID_CURVE
ERR_CRYPTO_INVALID_DIGEST
ERR_CRYPTO_INVALID_IV
ERR_CRYPTO_INVALID_JWK
ERR_CRYPTO_INVALID_KEYLEN
ERR_CRYPTO_INVALID_KEYPAIR
ERR_CRYPTO_INVALID_KEYTYPE
ERR_CRYPTO_INVALID_KEY_OBJECT_TYPE
ERR_CRYPTO_INVALID_MESSAGELEN
ERR_CRYPTO_INVALID_SCRYPT_PARAMS
ERR_CRYPTO_INVALID_STATE
ERR_CRYPTO_INVALID_TAG_LENGTH
ERR_CRYPTO_JOB_INIT_FAILED
ERR_CRYPTO_JWK_UNSUPPORTED_CURVE
ERR_CRYPTO_JWK_UNSUPPORTED_KEY_TYPE
ERR_CRYPTO_OPERATION_FAILED
ERR_CRYPTO_PBKDF2_ERROR
ERR_CRYPTO_SCRYPT_NOT_SUPPORTED
ERR_CRYPTO_SIGN_KEY_REQUIRED
ERR_CRYPTO_TIMING_SAFE_EQUAL_LENGTH
ERR_CRYPTO_UNKNOWN_CIPHER
ERR_CRYPTO_UNKNOWN_DH_GROUP
ERR_CRYPTO_UNSUPPORTED_OPERATION
ERR_DEBUGGER_ERROR
ERR_DEBUGGER_STARTUP_ERROR
ERR_DIR_CLOSED
ERR_DIR_CONCURRENT_OPERATION
ERR_DLOPEN_DISABLED
ERR_DLOPEN_FAILED
ERR_DNS_SET_SERVERS_FAILED
ERR_DOMAIN_CALLBACK_NOT_AVAILABLE
ERR_DOMAIN_CANNOT_SET_UNCAUGHT_EXCEPTION_CAPTURE
ERR_DUPLICATE_STARTUP_SNAPSHOT_MAIN_FUNCTION
ERR_ENCODING_INVALID_ENCODED_DATA
ERR_ENCODING_NOT_SUPPORTED
ERR_EVAL_ESM_CANNOT_PRINT
ERR_EVENT_RECURSION
ERR_EXECUTION_ENVIRONMENT_NOT_AVAILABLE
ERR_FALSY_VALUE_REJECTION
ERR_FEATURE_UNAVAILABLE_ON_PLATFORM
ERR_FS_CP_DIR_TO_NON_DIR
ERR_FS_CP_EEXIST
ERR_FS_CP_EINVAL
ERR_FS_CP_FIFO_PIPE
ERR_FS_CP_NON_DIR_TO_DIR
ERR_FS_CP_SOCKET
ERR_FS_CP_SYMLINK_TO_SUBDIRECTORY
ERR_FS_CP_UNKNOWN
ERR_FS_EISDIR
ERR_FS_FILE_TOO_LARGE
ERR_HTTP2_ALTSVC_INVALID_ORIGIN
ERR_HTTP2_ALTSVC_LENGTH
ERR_HTTP2_CONNECT_AUTHORITY
ERR_HTTP2_CONNECT_PATH
ERR_HTTP2_CONNECT_SCHEME
ERR_HTTP2_ERROR
ERR_HTTP2_GOAWAY_SESSION
ERR_HTTP2_HEADERS_AFTER_RESPOND
ERR_HTTP2_HEADERS_SENT
ERR_HTTP2_HEADER_SINGLE_VALUE
ERR_HTTP2_INFO_STATUS_NOT_ALLOWED
ERR_HTTP2_INVALID_CONNECTION_HEADERS
ERR_HTTP2_INVALID_HEADER_VALUE
ERR_HTTP2_INVALID_INFO_STATUS
ERR_HTTP2_INVALID_ORIGIN
ERR_HTTP2_INVALID_PACKED_SETTINGS_LENGTH
ERR_HTTP2_INVALID_PSEUDOHEADER
ERR_HTTP2_INVALID_SESSION
ERR_HTTP2_INVALID_SETTING_VALUE
ERR_HTTP2_INVALID_STREAM
ERR_HTTP2_MAX_PENDING_SETTINGS_ACK
ERR_HTTP2_NESTED_PUSH
ERR_HTTP2_NO_MEM
ERR_HTTP2_NO_SOCKET_MANIPULATION
ERR_HTTP2_ORIGIN_LENGTH
ERR_HTTP2_OUT_OF_STREAMS
ERR_HTTP2_PAYLOAD_FORBIDDEN
ERR_HTTP2_PING_CANCEL
ERR_HTTP2_PING_LENGTH
ERR_HTTP2_PSEUDOHEADER_NOT_ALLOWED
ERR_HTTP2_PUSH_DISABLED
ERR_HTTP2_SEND_FILE
ERR_HTTP2_SEND_FILE_NOSEEK
ERR_HTTP2_SESSION_ERROR
ERR_HTTP2_SETTINGS_CANCEL
ERR_HTTP2_SOCKET_BOUND
ERR_HTTP2_SOCKET_UNBOUND
ERR_HTTP2_STATUS_101
ERR_HTTP2_STATUS_INVALID
ERR_HTTP2_STREAM_CANCEL
ERR_HTTP2_STREAM_ERROR
ERR_HTTP2_STREAM_SELF_DEPENDENCY
ERR_HTTP2_TOO_MANY_CUSTOM_SETTINGS
ERR_HTTP2_TOO_MANY_INVALID_FRAMES
ERR_HTTP2_TRAILERS_ALREADY_SENT
ERR_HTTP2_TRAILERS_NOT_READY
ERR_HTTP2_UNSUPPORTED_PROTOCOL
ERR_HTTP_BODY_NOT_ALLOWED
ERR_HTTP_CONTENT_LENGTH_MISMATCH
ERR_HTTP_HEADERS_SENT
ERR_HTTP_INVALID_HEADER_VALUE
ERR_HTTP_INVALID_STATUS_CODE
ERR_HTTP_REQUEST_TIMEOUT
ERR_HTTP_SOCKET_ASSIGNED
ERR_HTTP_SOCKET_ENCODING
ERR_HTTP_TRAILER_INVALID
ERR_ILLEGAL_CONSTRUCTOR
ERR_IMPORT_ATTRIBUTE_MISSING
ERR_IMPORT_ATTRIBUTE_TYPE_INCOMPATIBLE
ERR_IMPORT_ATTRIBUTE_UNSUPPORTED
ERR_INCOMPATIBLE_OPTION_PAIR
ERR_INPUT_TYPE_NOT_ALLOWED
ERR_INSPECTOR_ALREADY_ACTIVATED
ERR_INSPECTOR_ALREADY_CONNECTED
ERR_INSPECTOR_CLOSED
ERR_INSPECTOR_COMMAND
ERR_INSPECTOR_NOT_ACTIVE
ERR_INSPECTOR_NOT_AVAILABLE
ERR_INSPECTOR_NOT_CONNECTED
ERR_INSPECTOR_NOT_WORKER
ERR_INTERNAL_ASSERTION
ERR_INVALID_ADDRESS
ERR_INVALID_ADDRESS_FAMILY
ERR_INVALID_ARG_TYPE
ERR_INVALID_ARG_VALUE
ERR_INVALID_ASYNC_ID
ERR_INVALID_BUFFER_SIZE
ERR_INVALID_CHAR
ERR_INVALID_CURSOR_POS
ERR_INVALID_FD
ERR_INVALID_FD_TYPE
ERR_INVALID_FILE_URL_HOST
ERR_INVALID_FILE_URL_PATH
ERR_INVALID_HANDLE_TYPE
ERR_INVALID_HTTP_TOKEN
ERR_INVALID_IP_ADDRESS
ERR_INVALID_MIME_SYNTAX
ERR_INVALID_MODULE
ERR_INVALID_MODULE_SPECIFIER
ERR_INVALID_OBJECT_DEFINE_PROPERTY
ERR_INVALID_PACKAGE_CONFIG
ERR_INVALID_PACKAGE_TARGET
ERR_INVALID_PROTOCOL
ERR_INVALID_REPL_EVAL_CONFIG
ERR_INVALID_REPL_INPUT
ERR_INVALID_RETURN_PROPERTY
ERR_INVALID_RETURN_PROPERTY_VALUE
ERR_INVALID_RETURN_VALUE
ERR_INVALID_STATE
ERR_INVALID_SYNC_FORK_INPUT
ERR_INVALID_THIS
ERR_INVALID_TUPLE
ERR_INVALID_TYPESCRIPT_SYNTAX
ERR_INVALID_URI
ERR_INVALID_URL
ERR_INVALID_URL_PATTERN
ERR_INVALID_URL_SCHEME
ERR_IPC_CHANNEL_CLOSED
ERR_IPC_DISCONNECTED
ERR_IPC_ONE_PIPE
ERR_IPC_SYNC_FORK
ERR_IP_BLOCKED
ERR_LOADER_CHAIN_INCOMPLETE
ERR_LOAD_SQLITE_EXTENSION
ERR_MEMORY_ALLOCATION_FAILED
ERR_MESSAGE_TARGET_CONTEXT_UNAVAILABLE
ERR_METHOD_NOT_IMPLEMENTED
ERR_MISSING_ARGS
ERR_MISSING_OPTION
ERR_MISSING_PASSPHRASE
ERR_MISSING_PLATFORM_FOR_WORKER
ERR_MODULE_NOT_FOUND
ERR_MULTIPLE_CALLBACK
ERR_NAPI_CONS_FUNCTION
ERR_NAPI_INVALID_DATAVIEW_ARGS
ERR_NAPI_INVALID_TYPEDARRAY_ALIGNMENT
ERR_NAPI_INVALID_TYPEDARRAY_LENGTH
ERR_NAPI_TSFN_CALL_JS
ERR_NAPI_TSFN_GET_UNDEFINED
ERR_NON_CONTEXT_AWARE_DISABLED
ERR_NOT_BUILDING_SNAPSHOT
ERR_NOT_IN_SINGLE_EXECUTABLE_APPLICATION
ERR_NOT_SUPPORTED_IN_SNAPSHOT
ERR_NO_CRYPTO
ERR_NO_ICU
ERR_NO_TYPESCRIPT
ERR_OPERATION_FAILED
ERR_OPTIONS_BEFORE_BOOTSTRAPPING
ERR_OUT_OF_RANGE
ERR_PACKAGE_IMPORT_NOT_DEFINED
ERR_PACKAGE_PATH_NOT_EXPORTED
ERR_PARSE_ARGS_INVALID_OPTION_VALUE
ERR_PARSE_ARGS_UNEXPECTED_POSITIONAL
ERR_PARSE_ARGS_UNKNOWN_OPTION
ERR_PERFORMANCE_INVALID_TIMESTAMP
ERR_PERFORMANCE_MEASURE_INVALID_OPTIONS
ERR_PROTO_ACCESS
ERR_QUIC_APPLICATION_ERROR
ERR_QUIC_CONNECTION_FAILED
ERR_QUIC_ENDPOINT_CLOSED
ERR_QUIC_OPEN_STREAM_FAILED
ERR_QUIC_TRANSPORT_ERROR
ERR_QUIC_VERSION_NEGOTIATION_ERROR
ERR_REQUIRE_ASYNC_MODULE
ERR_REQUIRE_CYCLE_MODULE
ERR_REQUIRE_ESM
ERR_SCRIPT_EXECUTION_INTERRUPTED
ERR_SCRIPT_EXECUTION_TIMEOUT
ERR_SERVER_ALREADY_LISTEN
ERR_SERVER_NOT_RUNNING
ERR_SINGLE_EXECUTABLE_APPLICATION_ASSET_NOT_FOUND
ERR_SOCKET_ALREADY_BOUND
ERR_SOCKET_BAD_BUFFER_SIZE
ERR_SOCKET_BAD_PORT
ERR_SOCKET_BAD_TYPE
ERR_SOCKET_BUFFER_SIZE
ERR_SOCKET_CLOSED
ERR_SOCKET_CLOSED_BEFORE_CONNECTION
ERR_SOCKET_CONNECTION_TIMEOUT
ERR_SOCKET_DGRAM_IS_CONNECTED
ERR_SOCKET_DGRAM_NOT_CONNECTED
ERR_SOCKET_DGRAM_NOT_RUNNING
ERR_SOURCE_MAP_CORRUPT
ERR_SOURCE_MAP_MISSING_SOURCE
ERR_SOURCE_PHASE_NOT_DEFINED
ERR_SQLITE_ERROR
ERR_SRI_PARSE
ERR_STREAM_ALREADY_FINISHED
ERR_STREAM_CANNOT_PIPE
ERR_STREAM_DESTROYED
ERR_STREAM_NULL_VALUES
ERR_STREAM_PREMATURE_CLOSE
ERR_STREAM_PUSH_AFTER_EOF
ERR_STREAM_UNABLE_TO_PIPE
ERR_STREAM_UNSHIFT_AFTER_END_EVENT
ERR_STREAM_WRAP
ERR_STREAM_WRITE_AFTER_END
ERR_STRING_TOO_LONG
ERR_SYNTHETIC
ERR_SYSTEM_ERROR
ERR_TEST_FAILURE
ERR_TLS_ALPN_CALLBACK_INVALID_RESULT
ERR_TLS_ALPN_CALLBACK_WITH_PROTOCOLS
ERR_TLS_CERT_ALTNAME_FORMAT
ERR_TLS_CERT_ALTNAME_INVALID
ERR_TLS_DH_PARAM_SIZE
ERR_TLS_HANDSHAKE_TIMEOUT
ERR_TLS_INVALID_CONTEXT
ERR_TLS_INVALID_PROTOCOL_METHOD
ERR_TLS_INVALID_PROTOCOL_VERSION
ERR_TLS_INVALID_STATE
ERR_TLS_PROTOCOL_VERSION_CONFLICT
ERR_TLS_PSK_SET_IDENTITY_HINT_FAILED
ERR_TLS_RENEGOTIATION_DISABLED
ERR_TLS_REQUIRED_SERVER_NAME
ERR_TLS_SESSION_ATTACK
ERR_TLS_SNI_FROM_SERVER
ERR_TRACE_EVENTS_CATEGORY_REQUIRED
ERR_TRACE_EVENTS_UNAVAILABLE
ERR_TRANSFORM_ALREADY_TRANSFORMING
ERR_TRANSFORM_WITH_LENGTH_0
ERR_TTY_INIT_FAILED
ERR_UNAVAILABLE_DURING_EXIT
ERR_UNCAUGHT_EXCEPTION_CAPTURE_ALREADY_SET
ERR_UNESCAPED_CHARACTERS
ERR_UNHANDLED_ERROR
ERR_UNKNOWN_BUILTIN_MODULE
ERR_UNKNOWN_CREDENTIAL
ERR_UNKNOWN_ENCODING
ERR_UNKNOWN_FILE_EXTENSION
ERR_UNKNOWN_MODULE_FORMAT
ERR_UNKNOWN_SIGNAL
ERR_UNSUPPORTED_DIR_IMPORT
ERR_UNSUPPORTED_ESM_URL_SCHEME
ERR_UNSUPPORTED_NODE_MODULES_TYPE_STRIPPING
ERR_UNSUPPORTED_RESOLVE_REQUEST
ERR_UNSUPPORTED_TYPESCRIPT_SYNTAX
ERR_USE_AFTER_CLOSE
ERR_VALID_PERFORMANCE_ENTRY_TYPE
ERR_VM_DYNAMIC_IMPORT_CALLBACK_MISSING
ERR_VM_DYNAMIC_IMPORT_CALLBACK_MISSING_FLAG
ERR_VM_MODULE_ALREADY_LINKED
ERR_VM_MODULE_CACHED_DATA_REJECTED
ERR_VM_MODULE_CANNOT_CREATE_CACHED_DATA
ERR_VM_MODULE_DIFFERENT_CONTEXT
ERR_VM_MODULE_LINK_FAILURE
ERR_VM_MODULE_NOT_MODULE
ERR_VM_MODULE_STATUS
ERR_WASI_ALREADY_STARTED
ERR_WASI_NOT_STARTED
ERR_WEBASSEMBLY_RESPONSE
ERR_WORKER_INIT_FAILED
ERR_WORKER_INVALID_EXEC_ARGV
ERR_WORKER_MESSAGING_ERRORED
ERR_WORKER_MESSAGING_FAILED
ERR_WORKER_MESSAGING_SAME_THREAD
ERR_WORKER_MESSAGING_TIMEOUT
ERR_WORKER_NOT_RUNNING
ERR_WORKER_OUT_OF_MEMORY
ERR_WORKER_PATH
ERR_WORKER_UNSERIALIZABLE_ERROR
ERR_WORKER_UNSUPPORTED_OPERATION
ERR_ZLIB_INITIALIZATION_FAILED
ERR_ZSTD_INVALID_PARAM
HPE_CHUNK_EXTENSIONS_OVERFLOW
HPE_HEADER_OVERFLOW
HPE_UNEXPECTED_CONTENT_LENGTH
MODULE_NOT_FOUND


Legacy Node.js error codes

ERR_CANNOT_TRANSFER_OBJECT
ERR_CPU_USAGE
ERR_CRYPTO_HASH_DIGEST_NO_UTF16
ERR_CRYPTO_SCRYPT_INVALID_PARAMETER
ERR_FS_INVALID_SYMLINK_TYPE
ERR_HTTP2_FRAME_ERROR
ERR_HTTP2_HEADERS_OBJECT
ERR_HTTP2_HEADER_REQUIRED
ERR_HTTP2_INFO_HEADERS_AFTER_RESPOND
ERR_HTTP2_STREAM_CLOSED
ERR_HTTP_INVALID_CHAR
ERR_IMPORT_ASSERTION_TYPE_FAILED
ERR_IMPORT_ASSERTION_TYPE_MISSING
ERR_IMPORT_ASSERTION_TYPE_UNSUPPORTED
ERR_INDEX_OUT_OF_RANGE
ERR_INVALID_OPT_VALUE
ERR_INVALID_OPT_VALUE_ENCODING
ERR_INVALID_PERFORMANCE_MARK
ERR_INVALID_TRANSFER_OBJECT
ERR_MANIFEST_ASSERT_INTEGRITY
ERR_MANIFEST_DEPENDENCY_MISSING
ERR_MANIFEST_INTEGRITY_MISMATCH
ERR_MANIFEST_INVALID_RESOURCE_FIELD
ERR_MANIFEST_INVALID_SPECIFIER
ERR_MANIFEST_PARSE_POLICY
ERR_MANIFEST_TDZ
ERR_MANIFEST_UNKNOWN_ONERROR
ERR_MISSING_MESSAGE_PORT_IN_TRANSFER_LIST
ERR_MISSING_TRANSFERABLE_IN_TRANSFER_LIST
ERR_NAPI_CONS_PROTOTYPE_OBJECT
ERR_NAPI_TSFN_START_IDLE_LOOP
ERR_NAPI_TSFN_STOP_IDLE_LOOP
ERR_NO_LONGER_SUPPORTED
ERR_OUTOFMEMORY
ERR_PARSE_HISTORY_DATA
ERR_SOCKET_CANNOT_SEND
ERR_STDERR_CLOSE
ERR_STDOUT_CLOSE
ERR_STREAM_READ_NOT_IMPLEMENTED
ERR_TAP_LEXER_ERROR
ERR_TAP_PARSER_ERROR
ERR_TAP_VALIDATION_ERROR
ERR_TLS_RENEGOTIATION_FAILED
ERR_TRANSFERRING_EXTERNALIZED_SHAREDARRAYBUFFER
ERR_UNKNOWN_STDIN_TYPE
ERR_UNKNOWN_STREAM_TYPE
ERR_V8BREAKITERATOR
ERR_VALUE_OUT_OF_RANGE
ERR_VM_MODULE_LINKING_ERRORED
ERR_VM_MODULE_NOT_LINKED
ERR_WORKER_UNSUPPORTED_EXTENSION
ERR_ZLIB_BINDING_CLOSED


OpenSSL Error Codes

Time Validity Errors

CERT_NOT_YET_VALID
CERT_HAS_EXPIRED
CRL_NOT_YET_VALID
CRL_HAS_EXPIRED
CERT_REVOKED


Trust or Chain Related Errors

UNABLE_TO_GET_ISSUER_CERT
UNABLE_TO_GET_ISSUER_CERT_LOCALLY
DEPTH_ZERO_SELF_SIGNED_CERT
SELF_SIGNED_CERT_IN_CHAIN
CERT_CHAIN_TOO_LONG
UNABLE_TO_GET_CRL
UNABLE_TO_VERIFY_LEAF_SIGNATURE
CERT_UNTRUSTED


Basic Extension Errors

INVALID_CA
PATH_LENGTH_EXCEEDED


Name Related Errors

HOSTNAME_MISMATCH


Usage and Policy Errors

INVALID_PURPOSE
CERT_REJECTED


Formatting Errors

CERT_SIGNATURE_FAILURE
CRL_SIGNATURE_FAILURE
ERROR_IN_CERT_NOT_BEFORE_FIELD
ERROR_IN_CERT_NOT_AFTER_FIELD
ERROR_IN_CRL_LAST_UPDATE_FIELD
ERROR_IN_CRL_NEXT_UPDATE_FIELD
UNABLE_TO_DECRYPT_CERT_SIGNATURE
UNABLE_TO_DECRYPT_CRL_SIGNATURE
UNABLE_TO_DECODE_ISSUER_PUBLIC_KEY


Other OpenSSL Errors

OUT_OF_MEM







    
  
            
    
      
        
        Index
      

      
About this documentation
Usage and example

      
        Index
      
    
  


Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Modules: TypeScript
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
Readline
REPL
Report
Single executable applications
SQLite
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker

    
  
            
    
      
        
        Other versions
      
      24.x
23.x
22.x LTS
21.x
20.x LTS
19.x
18.x
17.x
16.x
15.x
14.x
13.x
12.x
11.x
10.x
9.x
8.x
7.x
6.x
5.x
4.x
    
  
            
              
                
                Options
              
        
              
                
                  
                    View on single page
                  
                  
                    View as JSON
                  
                  Edit on GitHub    
                
              
            
          
        
        
      

      Table of contents
Errors

Error propagation and interception
Class: Error

new Error(message[, options])
Error.captureStackTrace(targetObject[, constructorOpt])
Error.stackTraceLimit
error.cause
error.code
error.message
error.stack


Class: AssertionError
Class: RangeError
Class: ReferenceError
Class: SyntaxError
Class: SystemError

error.address
error.code
error.dest
error.errno
error.info
error.message
error.path
error.port
error.syscall
Common system errors


Class: TypeError
Exceptions vs. errors
OpenSSL errors

error.opensslErrorStack
error.function
error.library
error.reason


Node.js error codes

ABORT_ERR
ERR_ACCESS_DENIED
ERR_AMBIGUOUS_ARGUMENT
ERR_ARG_NOT_ITERABLE
ERR_ASSERTION
ERR_ASYNC_CALLBACK
ERR_ASYNC_TYPE
ERR_BROTLI_COMPRESSION_FAILED
ERR_BROTLI_INVALID_PARAM
ERR_BUFFER_CONTEXT_NOT_AVAILABLE
ERR_BUFFER_OUT_OF_BOUNDS
ERR_BUFFER_TOO_LARGE
ERR_CANNOT_WATCH_SIGINT
ERR_CHILD_CLOSED_BEFORE_REPLY
ERR_CHILD_PROCESS_IPC_REQUIRED
ERR_CHILD_PROCESS_STDIO_MAXBUFFER
ERR_CLOSED_MESSAGE_PORT
ERR_CONSOLE_WRITABLE_STREAM
ERR_CONSTRUCT_CALL_INVALID
ERR_CONSTRUCT_CALL_REQUIRED
ERR_CONTEXT_NOT_INITIALIZED
ERR_CRYPTO_CUSTOM_ENGINE_NOT_SUPPORTED
ERR_CRYPTO_ECDH_INVALID_FORMAT
ERR_CRYPTO_ECDH_INVALID_PUBLIC_KEY
ERR_CRYPTO_ENGINE_UNKNOWN
ERR_CRYPTO_FIPS_FORCED
ERR_CRYPTO_FIPS_UNAVAILABLE
ERR_CRYPTO_HASH_FINALIZED
ERR_CRYPTO_HASH_UPDATE_FAILED
ERR_CRYPTO_INCOMPATIBLE_KEY
ERR_CRYPTO_INCOMPATIBLE_KEY_OPTIONS
ERR_CRYPTO_INITIALIZATION_FAILED
ERR_CRYPTO_INVALID_AUTH_TAG
ERR_CRYPTO_INVALID_COUNTER
ERR_CRYPTO_INVALID_CURVE
ERR_CRYPTO_INVALID_DIGEST
ERR_CRYPTO_INVALID_IV
ERR_CRYPTO_INVALID_JWK
ERR_CRYPTO_INVALID_KEYLEN
ERR_CRYPTO_INVALID_KEYPAIR
ERR_CRYPTO_INVALID_KEYTYPE
ERR_CRYPTO_INVALID_KEY_OBJECT_TYPE
ERR_CRYPTO_INVALID_MESSAGELEN
ERR_CRYPTO_INVALID_SCRYPT_PARAMS
ERR_CRYPTO_INVALID_STATE
ERR_CRYPTO_INVALID_TAG_LENGTH
ERR_CRYPTO_JOB_INIT_FAILED
ERR_CRYPTO_JWK_UNSUPPORTED_CURVE
ERR_CRYPTO_JWK_UNSUPPORTED_KEY_TYPE
ERR_CRYPTO_OPERATION_FAILED
ERR_CRYPTO_PBKDF2_ERROR
ERR_CRYPTO_SCRYPT_NOT_SUPPORTED
ERR_CRYPTO_SIGN_KEY_REQUIRED
ERR_CRYPTO_TIMING_SAFE_EQUAL_LENGTH
ERR_CRYPTO_UNKNOWN_CIPHER
ERR_CRYPTO_UNKNOWN_DH_GROUP
ERR_CRYPTO_UNSUPPORTED_OPERATION
ERR_DEBUGGER_ERROR
ERR_DEBUGGER_STARTUP_ERROR
ERR_DIR_CLOSED
ERR_DIR_CONCURRENT_OPERATION
ERR_DLOPEN_DISABLED
ERR_DLOPEN_FAILED
ERR_DNS_SET_SERVERS_FAILED
ERR_DOMAIN_CALLBACK_NOT_AVAILABLE
ERR_DOMAIN_CANNOT_SET_UNCAUGHT_EXCEPTION_CAPTURE
ERR_DUPLICATE_STARTUP_SNAPSHOT_MAIN_FUNCTION
ERR_ENCODING_INVALID_ENCODED_DATA
ERR_ENCODING_NOT_SUPPORTED
ERR_EVAL_ESM_CANNOT_PRINT
ERR_EVENT_RECURSION
ERR_EXECUTION_ENVIRONMENT_NOT_AVAILABLE
ERR_FALSY_VALUE_REJECTION
ERR_FEATURE_UNAVAILABLE_ON_PLATFORM
ERR_FS_CP_DIR_TO_NON_DIR
ERR_FS_CP_EEXIST
ERR_FS_CP_EINVAL
ERR_FS_CP_FIFO_PIPE
ERR_FS_CP_NON_DIR_TO_DIR
ERR_FS_CP_SOCKET
ERR_FS_CP_SYMLINK_TO_SUBDIRECTORY
ERR_FS_CP_UNKNOWN
ERR_FS_EISDIR
ERR_FS_FILE_TOO_LARGE
ERR_HTTP2_ALTSVC_INVALID_ORIGIN
ERR_HTTP2_ALTSVC_LENGTH
ERR_HTTP2_CONNECT_AUTHORITY
ERR_HTTP2_CONNECT_PATH
ERR_HTTP2_CONNECT_SCHEME
ERR_HTTP2_ERROR
ERR_HTTP2_GOAWAY_SESSION
ERR_HTTP2_HEADERS_AFTER_RESPOND
ERR_HTTP2_HEADERS_SENT
ERR_HTTP2_HEADER_SINGLE_VALUE
ERR_HTTP2_INFO_STATUS_NOT_ALLOWED
ERR_HTTP2_INVALID_CONNECTION_HEADERS
ERR_HTTP2_INVALID_HEADER_VALUE
ERR_HTTP2_INVALID_INFO_STATUS
ERR_HTTP2_INVALID_ORIGIN
ERR_HTTP2_INVALID_PACKED_SETTINGS_LENGTH
ERR_HTTP2_INVALID_PSEUDOHEADER
ERR_HTTP2_INVALID_SESSION
ERR_HTTP2_INVALID_SETTING_VALUE
ERR_HTTP2_INVALID_STREAM
ERR_HTTP2_MAX_PENDING_SETTINGS_ACK
ERR_HTTP2_NESTED_PUSH
ERR_HTTP2_NO_MEM
ERR_HTTP2_NO_SOCKET_MANIPULATION
ERR_HTTP2_ORIGIN_LENGTH
ERR_HTTP2_OUT_OF_STREAMS
ERR_HTTP2_PAYLOAD_FORBIDDEN
ERR_HTTP2_PING_CANCEL
ERR_HTTP2_PING_LENGTH
ERR_HTTP2_PSEUDOHEADER_NOT_ALLOWED
ERR_HTTP2_PUSH_DISABLED
ERR_HTTP2_SEND_FILE
ERR_HTTP2_SEND_FILE_NOSEEK
ERR_HTTP2_SESSION_ERROR
ERR_HTTP2_SETTINGS_CANCEL
ERR_HTTP2_SOCKET_BOUND
ERR_HTTP2_SOCKET_UNBOUND
ERR_HTTP2_STATUS_101
ERR_HTTP2_STATUS_INVALID
ERR_HTTP2_STREAM_CANCEL
ERR_HTTP2_STREAM_ERROR
ERR_HTTP2_STREAM_SELF_DEPENDENCY
ERR_HTTP2_TOO_MANY_CUSTOM_SETTINGS
ERR_HTTP2_TOO_MANY_INVALID_FRAMES
ERR_HTTP2_TRAILERS_ALREADY_SENT
ERR_HTTP2_TRAILERS_NOT_READY
ERR_HTTP2_UNSUPPORTED_PROTOCOL
ERR_HTTP_BODY_NOT_ALLOWED
ERR_HTTP_CONTENT_LENGTH_MISMATCH
ERR_HTTP_HEADERS_SENT
ERR_HTTP_INVALID_HEADER_VALUE
ERR_HTTP_INVALID_STATUS_CODE
ERR_HTTP_REQUEST_TIMEOUT
ERR_HTTP_SOCKET_ASSIGNED
ERR_HTTP_SOCKET_ENCODING
ERR_HTTP_TRAILER_INVALID
ERR_ILLEGAL_CONSTRUCTOR
ERR_IMPORT_ATTRIBUTE_MISSING
ERR_IMPORT_ATTRIBUTE_TYPE_INCOMPATIBLE
ERR_IMPORT_ATTRIBUTE_UNSUPPORTED
ERR_INCOMPATIBLE_OPTION_PAIR
ERR_INPUT_TYPE_NOT_ALLOWED
ERR_INSPECTOR_ALREADY_ACTIVATED
ERR_INSPECTOR_ALREADY_CONNECTED
ERR_INSPECTOR_CLOSED
ERR_INSPECTOR_COMMAND
ERR_INSPECTOR_NOT_ACTIVE
ERR_INSPECTOR_NOT_AVAILABLE
ERR_INSPECTOR_NOT_CONNECTED
ERR_INSPECTOR_NOT_WORKER
ERR_INTERNAL_ASSERTION
ERR_INVALID_ADDRESS
ERR_INVALID_ADDRESS_FAMILY
ERR_INVALID_ARG_TYPE
ERR_INVALID_ARG_VALUE
ERR_INVALID_ASYNC_ID
ERR_INVALID_BUFFER_SIZE
ERR_INVALID_CHAR
ERR_INVALID_CURSOR_POS
ERR_INVALID_FD
ERR_INVALID_FD_TYPE
ERR_INVALID_FILE_URL_HOST
ERR_INVALID_FILE_URL_PATH
ERR_INVALID_HANDLE_TYPE
ERR_INVALID_HTTP_TOKEN
ERR_INVALID_IP_ADDRESS
ERR_INVALID_MIME_SYNTAX
ERR_INVALID_MODULE
ERR_INVALID_MODULE_SPECIFIER
ERR_INVALID_OBJECT_DEFINE_PROPERTY
ERR_INVALID_PACKAGE_CONFIG
ERR_INVALID_PACKAGE_TARGET
ERR_INVALID_PROTOCOL
ERR_INVALID_REPL_EVAL_CONFIG
ERR_INVALID_REPL_INPUT
ERR_INVALID_RETURN_PROPERTY
ERR_INVALID_RETURN_PROPERTY_VALUE
ERR_INVALID_RETURN_VALUE
ERR_INVALID_STATE
ERR_INVALID_SYNC_FORK_INPUT
ERR_INVALID_THIS
ERR_INVALID_TUPLE
ERR_INVALID_TYPESCRIPT_SYNTAX
ERR_INVALID_URI
ERR_INVALID_URL
ERR_INVALID_URL_PATTERN
ERR_INVALID_URL_SCHEME
ERR_IPC_CHANNEL_CLOSED
ERR_IPC_DISCONNECTED
ERR_IPC_ONE_PIPE
ERR_IPC_SYNC_FORK
ERR_IP_BLOCKED
ERR_LOADER_CHAIN_INCOMPLETE
ERR_LOAD_SQLITE_EXTENSION
ERR_MEMORY_ALLOCATION_FAILED
ERR_MESSAGE_TARGET_CONTEXT_UNAVAILABLE
ERR_METHOD_NOT_IMPLEMENTED
ERR_MISSING_ARGS
ERR_MISSING_OPTION
ERR_MISSING_PASSPHRASE
ERR_MISSING_PLATFORM_FOR_WORKER
ERR_MODULE_NOT_FOUND
ERR_MULTIPLE_CALLBACK
ERR_NAPI_CONS_FUNCTION
ERR_NAPI_INVALID_DATAVIEW_ARGS
ERR_NAPI_INVALID_TYPEDARRAY_ALIGNMENT
ERR_NAPI_INVALID_TYPEDARRAY_LENGTH
ERR_NAPI_TSFN_CALL_JS
ERR_NAPI_TSFN_GET_UNDEFINED
ERR_NON_CONTEXT_AWARE_DISABLED
ERR_NOT_BUILDING_SNAPSHOT
ERR_NOT_IN_SINGLE_EXECUTABLE_APPLICATION
ERR_NOT_SUPPORTED_IN_SNAPSHOT
ERR_NO_CRYPTO
ERR_NO_ICU
ERR_NO_TYPESCRIPT
ERR_OPERATION_FAILED
ERR_OPTIONS_BEFORE_BOOTSTRAPPING
ERR_OUT_OF_RANGE
ERR_PACKAGE_IMPORT_NOT_DEFINED
ERR_PACKAGE_PATH_NOT_EXPORTED
ERR_PARSE_ARGS_INVALID_OPTION_VALUE
ERR_PARSE_ARGS_UNEXPECTED_POSITIONAL
ERR_PARSE_ARGS_UNKNOWN_OPTION
ERR_PERFORMANCE_INVALID_TIMESTAMP
ERR_PERFORMANCE_MEASURE_INVALID_OPTIONS
ERR_PROTO_ACCESS
ERR_QUIC_APPLICATION_ERROR
ERR_QUIC_CONNECTION_FAILED
ERR_QUIC_ENDPOINT_CLOSED
ERR_QUIC_OPEN_STREAM_FAILED
ERR_QUIC_TRANSPORT_ERROR
ERR_QUIC_VERSION_NEGOTIATION_ERROR
ERR_REQUIRE_ASYNC_MODULE
ERR_REQUIRE_CYCLE_MODULE
ERR_REQUIRE_ESM
ERR_SCRIPT_EXECUTION_INTERRUPTED
ERR_SCRIPT_EXECUTION_TIMEOUT
ERR_SERVER_ALREADY_LISTEN
ERR_SERVER_NOT_RUNNING
ERR_SINGLE_EXECUTABLE_APPLICATION_ASSET_NOT_FOUND
ERR_SOCKET_ALREADY_BOUND
ERR_SOCKET_BAD_BUFFER_SIZE
ERR_SOCKET_BAD_PORT
ERR_SOCKET_BAD_TYPE
ERR_SOCKET_BUFFER_SIZE
ERR_SOCKET_CLOSED
ERR_SOCKET_CLOSED_BEFORE_CONNECTION
ERR_SOCKET_CONNECTION_TIMEOUT
ERR_SOCKET_DGRAM_IS_CONNECTED
ERR_SOCKET_DGRAM_NOT_CONNECTED
ERR_SOCKET_DGRAM_NOT_RUNNING
ERR_SOURCE_MAP_CORRUPT
ERR_SOURCE_MAP_MISSING_SOURCE
ERR_SOURCE_PHASE_NOT_DEFINED
ERR_SQLITE_ERROR
ERR_SRI_PARSE
ERR_STREAM_ALREADY_FINISHED
ERR_STREAM_CANNOT_PIPE
ERR_STREAM_DESTROYED
ERR_STREAM_NULL_VALUES
ERR_STREAM_PREMATURE_CLOSE
ERR_STREAM_PUSH_AFTER_EOF
ERR_STREAM_UNABLE_TO_PIPE
ERR_STREAM_UNSHIFT_AFTER_END_EVENT
ERR_STREAM_WRAP
ERR_STREAM_WRITE_AFTER_END
ERR_STRING_TOO_LONG
ERR_SYNTHETIC
ERR_SYSTEM_ERROR
ERR_TEST_FAILURE
ERR_TLS_ALPN_CALLBACK_INVALID_RESULT
ERR_TLS_ALPN_CALLBACK_WITH_PROTOCOLS
ERR_TLS_CERT_ALTNAME_FORMAT
ERR_TLS_CERT_ALTNAME_INVALID
ERR_TLS_DH_PARAM_SIZE
ERR_TLS_HANDSHAKE_TIMEOUT
ERR_TLS_INVALID_CONTEXT
ERR_TLS_INVALID_PROTOCOL_METHOD
ERR_TLS_INVALID_PROTOCOL_VERSION
ERR_TLS_INVALID_STATE
ERR_TLS_PROTOCOL_VERSION_CONFLICT
ERR_TLS_PSK_SET_IDENTITY_HINT_FAILED
ERR_TLS_RENEGOTIATION_DISABLED
ERR_TLS_REQUIRED_SERVER_NAME
ERR_TLS_SESSION_ATTACK
ERR_TLS_SNI_FROM_SERVER
ERR_TRACE_EVENTS_CATEGORY_REQUIRED
ERR_TRACE_EVENTS_UNAVAILABLE
ERR_TRANSFORM_ALREADY_TRANSFORMING
ERR_TRANSFORM_WITH_LENGTH_0
ERR_TTY_INIT_FAILED
ERR_UNAVAILABLE_DURING_EXIT
ERR_UNCAUGHT_EXCEPTION_CAPTURE_ALREADY_SET
ERR_UNESCAPED_CHARACTERS
ERR_UNHANDLED_ERROR
ERR_UNKNOWN_BUILTIN_MODULE
ERR_UNKNOWN_CREDENTIAL
ERR_UNKNOWN_ENCODING
ERR_UNKNOWN_FILE_EXTENSION
ERR_UNKNOWN_MODULE_FORMAT
ERR_UNKNOWN_SIGNAL
ERR_UNSUPPORTED_DIR_IMPORT
ERR_UNSUPPORTED_ESM_URL_SCHEME
ERR_UNSUPPORTED_NODE_MODULES_TYPE_STRIPPING
ERR_UNSUPPORTED_RESOLVE_REQUEST
ERR_UNSUPPORTED_TYPESCRIPT_SYNTAX
ERR_USE_AFTER_CLOSE
ERR_VALID_PERFORMANCE_ENTRY_TYPE
ERR_VM_DYNAMIC_IMPORT_CALLBACK_MISSING
ERR_VM_DYNAMIC_IMPORT_CALLBACK_MISSING_FLAG
ERR_VM_MODULE_ALREADY_LINKED
ERR_VM_MODULE_CACHED_DATA_REJECTED
ERR_VM_MODULE_CANNOT_CREATE_CACHED_DATA
ERR_VM_MODULE_DIFFERENT_CONTEXT
ERR_VM_MODULE_LINK_FAILURE
ERR_VM_MODULE_NOT_MODULE
ERR_VM_MODULE_STATUS
ERR_WASI_ALREADY_STARTED
ERR_WASI_NOT_STARTED
ERR_WEBASSEMBLY_RESPONSE
ERR_WORKER_INIT_FAILED
ERR_WORKER_INVALID_EXEC_ARGV
ERR_WORKER_MESSAGING_ERRORED
ERR_WORKER_MESSAGING_FAILED
ERR_WORKER_MESSAGING_SAME_THREAD
ERR_WORKER_MESSAGING_TIMEOUT
ERR_WORKER_NOT_RUNNING
ERR_WORKER_OUT_OF_MEMORY
ERR_WORKER_PATH
ERR_WORKER_UNSERIALIZABLE_ERROR
ERR_WORKER_UNSUPPORTED_OPERATION
ERR_ZLIB_INITIALIZATION_FAILED
ERR_ZSTD_INVALID_PARAM
HPE_CHUNK_EXTENSIONS_OVERFLOW
HPE_HEADER_OVERFLOW
HPE_UNEXPECTED_CONTENT_LENGTH
MODULE_NOT_FOUND


Legacy Node.js error codes

ERR_CANNOT_TRANSFER_OBJECT
ERR_CPU_USAGE
ERR_CRYPTO_HASH_DIGEST_NO_UTF16
ERR_CRYPTO_SCRYPT_INVALID_PARAMETER
ERR_FS_INVALID_SYMLINK_TYPE
ERR_HTTP2_FRAME_ERROR
ERR_HTTP2_HEADERS_OBJECT
ERR_HTTP2_HEADER_REQUIRED
ERR_HTTP2_INFO_HEADERS_AFTER_RESPOND
ERR_HTTP2_STREAM_CLOSED
ERR_HTTP_INVALID_CHAR
ERR_IMPORT_ASSERTION_TYPE_FAILED
ERR_IMPORT_ASSERTION_TYPE_MISSING
ERR_IMPORT_ASSERTION_TYPE_UNSUPPORTED
ERR_INDEX_OUT_OF_RANGE
ERR_INVALID_OPT_VALUE
ERR_INVALID_OPT_VALUE_ENCODING
ERR_INVALID_PERFORMANCE_MARK
ERR_INVALID_TRANSFER_OBJECT
ERR_MANIFEST_ASSERT_INTEGRITY
ERR_MANIFEST_DEPENDENCY_MISSING
ERR_MANIFEST_INTEGRITY_MISMATCH
ERR_MANIFEST_INVALID_RESOURCE_FIELD
ERR_MANIFEST_INVALID_SPECIFIER
ERR_MANIFEST_PARSE_POLICY
ERR_MANIFEST_TDZ
ERR_MANIFEST_UNKNOWN_ONERROR
ERR_MISSING_MESSAGE_PORT_IN_TRANSFER_LIST
ERR_MISSING_TRANSFERABLE_IN_TRANSFER_LIST
ERR_NAPI_CONS_PROTOTYPE_OBJECT
ERR_NAPI_TSFN_START_IDLE_LOOP
ERR_NAPI_TSFN_STOP_IDLE_LOOP
ERR_NO_LONGER_SUPPORTED
ERR_OUTOFMEMORY
ERR_PARSE_HISTORY_DATA
ERR_SOCKET_CANNOT_SEND
ERR_STDERR_CLOSE
ERR_STDOUT_CLOSE
ERR_STREAM_READ_NOT_IMPLEMENTED
ERR_TAP_LEXER_ERROR
ERR_TAP_PARSER_ERROR
ERR_TAP_VALIDATION_ERROR
ERR_TLS_RENEGOTIATION_FAILED
ERR_TRANSFERRING_EXTERNALIZED_SHAREDARRAYBUFFER
ERR_UNKNOWN_STDIN_TYPE
ERR_UNKNOWN_STREAM_TYPE
ERR_V8BREAKITERATOR
ERR_VALUE_OUT_OF_RANGE
ERR_VM_MODULE_LINKING_ERRORED
ERR_VM_MODULE_NOT_LINKED
ERR_WORKER_UNSUPPORTED_EXTENSION
ERR_ZLIB_BINDING_CLOSED


OpenSSL Error Codes

Time Validity Errors

CERT_NOT_YET_VALID
CERT_HAS_EXPIRED
CRL_NOT_YET_VALID
CRL_HAS_EXPIRED
CERT_REVOKED


Trust or Chain Related Errors

UNABLE_TO_GET_ISSUER_CERT
UNABLE_TO_GET_ISSUER_CERT_LOCALLY
DEPTH_ZERO_SELF_SIGNED_CERT
SELF_SIGNED_CERT_IN_CHAIN
CERT_CHAIN_TOO_LONG
UNABLE_TO_GET_CRL
UNABLE_TO_VERIFY_LEAF_SIGNATURE
CERT_UNTRUSTED


Basic Extension Errors

INVALID_CA
PATH_LENGTH_EXCEEDED


Name Related Errors

HOSTNAME_MISMATCH


Usage and Policy Errors

INVALID_PURPOSE
CERT_REJECTED


Formatting Errors

CERT_SIGNATURE_FAILURE
CRL_SIGNATURE_FAILURE
ERROR_IN_CERT_NOT_BEFORE_FIELD
ERROR_IN_CERT_NOT_AFTER_FIELD
ERROR_IN_CRL_LAST_UPDATE_FIELD
ERROR_IN_CRL_NEXT_UPDATE_FIELD
UNABLE_TO_DECRYPT_CERT_SIGNATURE
UNABLE_TO_DECRYPT_CRL_SIGNATURE
UNABLE_TO_DECODE_ISSUER_PUBLIC_KEY


Other OpenSSL Errors

OUT_OF_MEM








      
        Errors#


Applications running in Node.js will generally experience the following
categories of errors:

Standard JavaScript errors such as <EvalError>, <SyntaxError>, <RangeError>,
<ReferenceError>, <TypeError>, and <URIError>.
Standard DOMExceptions.
System errors triggered by underlying operating system constraints such
as attempting to open a file that does not exist or attempting to send data
over a closed socket.
AssertionErrors are a special class of error that can be triggered when
Node.js detects an exceptional logic violation that should never occur. These
are raised typically by the node:assert module.
User-specified errors triggered by application code.

All JavaScript and system errors raised by Node.js inherit from, or are
instances of, the standard JavaScript <Error> class and are guaranteed
to provide at least the properties available on that class.
The error.message property of errors raised by Node.js may be changed in
any versions. Use error.code to identify an error instead. For a
DOMException, use domException.name to identify its type.
Error propagation and interception#

Node.js supports several mechanisms for propagating and handling errors that
occur while an application is running. How these errors are reported and
handled depends entirely on the type of Error and the style of the API that is
called.
All JavaScript errors are handled as exceptions that immediately generate
and throw an error using the standard JavaScript throw mechanism. These
are handled using the try…catch construct provided by the
JavaScript language.
// Throws with a ReferenceError because z is not defined.
try {
  const m = 1;
  const n = m + z;
} catch (err) {
  // Handle the error here.
} copy
Any use of the JavaScript throw mechanism will raise an exception that
must be handled or the Node.js process will exit immediately.
With few exceptions, Synchronous APIs (any blocking method that does not
return a <Promise> nor accept a callback function, such as
fs.readFileSync), will use throw to report errors.
Errors that occur within Asynchronous APIs may be reported in multiple ways:


Some asynchronous methods returns a <Promise>, you should always take into
account that it might be rejected. See --unhandled-rejections flag for
how the process will react to an unhandled promise rejection.

const fs = require('node:fs/promises');

(async () => {
  let data;
  try {
    data = await fs.readFile('a file that does not exist');
  } catch (err) {
    console.error('There was an error reading the file!', err);
    return;
  }
  // Otherwise handle the data
})(); copy


Most asynchronous methods that accept a callback function will accept an
Error object passed as the first argument to that function. If that first
argument is not null and is an instance of Error, then an error occurred
that should be handled.

const fs = require('node:fs');
fs.readFile('a file that does not exist', (err, data) => {
  if (err) {
    console.error('There was an error reading the file!', err);
    return;
  }
  // Otherwise handle the data
}); copy


When an asynchronous method is called on an object that is an
EventEmitter, errors can be routed to that object's 'error' event.
const net = require('node:net');
const connection = net.connect('localhost');

// Adding an 'error' event handler to a stream:
connection.on('error', (err) => {
  // If the connection is reset by the server, or if it can't
  // connect at all, or on any sort of error encountered by
  // the connection, the error will be sent here.
  console.error(err);
});

connection.pipe(process.stdout); copy


A handful of typically asynchronous methods in the Node.js API may still
use the throw mechanism to raise exceptions that must be handled using
try…catch. There is no comprehensive list of such methods; please
refer to the documentation of each method to determine the appropriate
error handling mechanism required.


The use of the 'error' event mechanism is most common for stream-based
and event emitter-based APIs, which themselves represent a series of
asynchronous operations over time (as opposed to a single operation that may
pass or fail).
For all EventEmitter objects, if an 'error' event handler is not
provided, the error will be thrown, causing the Node.js process to report an
uncaught exception and crash unless either: a handler has been registered for
the 'uncaughtException' event, or the deprecated node:domain
module is used.
const EventEmitter = require('node:events');
const ee = new EventEmitter();

setImmediate(() => {
  // This will crash the process because no 'error' event
  // handler has been added.
  ee.emit('error', new Error('This will crash'));
}); copy
Errors generated in this way cannot be intercepted using try…catch as
they are thrown after the calling code has already exited.
Developers must refer to the documentation for each method to determine
exactly how errors raised by those methods are propagated.
Class: Error#

A generic JavaScript <Error> object that does not denote any specific
circumstance of why the error occurred. Error objects capture a "stack trace"
detailing the point in the code at which the Error was instantiated, and may
provide a text description of the error.
All errors generated by Node.js, including all system and JavaScript errors,
will either be instances of, or inherit from, the Error class.

new Error(message[, options])#

message <string>
options <Object>

cause <any> The error that caused the newly created error.



Creates a new Error object and sets the error.message property to the
provided text message. If an object is passed as message, the text message
is generated by calling String(message). If the cause option is provided,
it is assigned to the error.cause property. The error.stack property will
represent the point in the code at which new Error() was called. Stack traces
are dependent on V8's stack trace API. Stack traces extend only to either
(a) the beginning of synchronous code execution, or (b) the number of frames
given by the property Error.stackTraceLimit, whichever is smaller.

Error.captureStackTrace(targetObject[, constructorOpt])#

targetObject <Object>
constructorOpt <Function>

Creates a .stack property on targetObject, which when accessed returns
a string representing the location in the code at which
Error.captureStackTrace() was called.
const myObject = {};
Error.captureStackTrace(myObject);
myObject.stack;  // Similar to `new Error().stack` copy
The first line of the trace will be prefixed with
${myObject.name}: ${myObject.message}.
The optional constructorOpt argument accepts a function. If given, all frames
above constructorOpt, including constructorOpt, will be omitted from the
generated stack trace.
The constructorOpt argument is useful for hiding implementation
details of error generation from the user. For instance:
function a() {
  b();
}

function b() {
  c();
}

function c() {
  // Create an error without stack trace to avoid calculating the stack trace twice.
  const { stackTraceLimit } = Error;
  Error.stackTraceLimit = 0;
  const error = new Error();
  Error.stackTraceLimit = stackTraceLimit;

  // Capture the stack trace above function b
  Error.captureStackTrace(error, b); // Neither function c, nor b is included in the stack trace
  throw error;
}

a(); copy

Error.stackTraceLimit#

<number>

The Error.stackTraceLimit property specifies the number of stack frames
collected by a stack trace (whether generated by new Error().stack or
Error.captureStackTrace(obj)).
The default value is 10 but may be set to any valid JavaScript number. Changes
will affect any stack trace captured after the value has been changed.
If set to a non-number value, or set to a negative number, stack traces will
not capture any frames.

error.cause#

Added in: v16.9.0


<any>

If present, the error.cause property is the underlying cause of the Error.
It is used when catching an error and throwing a new one with a different
message or code in order to still have access to the original error.
The error.cause property is typically set by calling
new Error(message, { cause }). It is not set by the constructor if the
cause option is not provided.
This property allows errors to be chained. When serializing Error objects,
util.inspect() recursively serializes error.cause if it is set.
const cause = new Error('The remote HTTP server responded with a 500 status');
const symptom = new Error('The message failed to send', { cause });

console.log(symptom);
// Prints:
//   Error: The message failed to send
//       at REPL2:1:17
//       at Script.runInThisContext (node:vm:130:12)
//       ... 7 lines matching cause stack trace ...
//       at [_line] [as _line] (node:internal/readline/interface:886:18) {
//     [cause]: Error: The remote HTTP server responded with a 500 status
//         at REPL1:1:15
//         at Script.runInThisContext (node:vm:130:12)
//         at REPLServer.defaultEval (node:repl:574:29)
//         at bound (node:domain:426:15)
//         at REPLServer.runBound [as eval] (node:domain:437:12)
//         at REPLServer.onLine (node:repl:902:10)
//         at REPLServer.emit (node:events:549:35)
//         at REPLServer.emit (node:domain:482:12)
//         at [_onLine] [as _onLine] (node:internal/readline/interface:425:12)
//         at [_line] [as _line] (node:internal/readline/interface:886:18) copy

error.code#

<string>

The error.code property is a string label that identifies the kind of error.
error.code is the most stable way to identify an error. It will only change
between major versions of Node.js. In contrast, error.message strings may
change between any versions of Node.js. See Node.js error codes for details
about specific codes.

error.message#

<string>

The error.message property is the string description of the error as set by
calling new Error(message). The message passed to the constructor will also
appear in the first line of the stack trace of the Error, however changing
this property after the Error object is created may not change the first
line of the stack trace (for example, when error.stack is read before this
property is changed).
const err = new Error('The message');
console.error(err.message);
// Prints: The message copy

error.stack#

<string>

The error.stack property is a string describing the point in the code at which
the Error was instantiated.
Error: Things keep happening!
   at /home/gbusey/file.js:525:2
   at Frobnicator.refrobulate (/home/gbusey/business-logic.js:424:21)
   at Actor.<anonymous> (/home/gbusey/actors.js:400:8)
   at increaseSynergy (/home/gbusey/actors.js:701:6) copy
The first line is formatted as <error class name>: <error message>, and
is followed by a series of stack frames (each line beginning with "at ").
Each frame describes a call site within the code that lead to the error being
generated. V8 attempts to display a name for each function (by variable name,
function name, or object method name), but occasionally it will not be able to
find a suitable name. If V8 cannot determine a name for the function, only
location information will be displayed for that frame. Otherwise, the
determined function name will be displayed with location information appended
in parentheses.
Frames are only generated for JavaScript functions. If, for example, execution
synchronously passes through a C++ addon function called cheetahify which
itself calls a JavaScript function, the frame representing the cheetahify call
will not be present in the stack traces:
const cheetahify = require('./native-binding.node');

function makeFaster() {
  // `cheetahify()` *synchronously* calls speedy.
  cheetahify(function speedy() {
    throw new Error('oh no!');
  });
}

makeFaster();
// will throw:
//   /home/gbusey/file.js:6
//       throw new Error('oh no!');
//           ^
//   Error: oh no!
//       at speedy (/home/gbusey/file.js:6:11)
//       at makeFaster (/home/gbusey/file.js:5:3)
//       at Object.<anonymous> (/home/gbusey/file.js:10:1)
//       at Module._compile (module.js:456:26)
//       at Object.Module._extensions..js (module.js:474:10)
//       at Module.load (module.js:356:32)
//       at Function.Module._load (module.js:312:12)
//       at Function.Module.runMain (module.js:497:10)
//       at startup (node.js:119:16)
//       at node.js:906:3 copy
The location information will be one of:

native, if the frame represents a call internal to V8 (as in [].forEach).
plain-filename.js:line:column, if the frame represents a call internal
to Node.js.
/absolute/path/to/file.js:line:column, if the frame represents a call in
a user program (using CommonJS module system), or its dependencies.
<transport-protocol>:///url/to/module/file.mjs:line:column, if the frame
represents a call in a user program (using ES module system), or
its dependencies.

The string representing the stack trace is lazily generated when the
error.stack property is accessed.
The number of frames captured by the stack trace is bounded by the smaller of
Error.stackTraceLimit or the number of available frames on the current event
loop tick.

Class: AssertionError#

Extends: <errors.Error>

Indicates the failure of an assertion. For details, see
Class: assert.AssertionError.
Class: RangeError#

Extends: <errors.Error>

Indicates that a provided argument was not within the set or range of
acceptable values for a function; whether that is a numeric range, or
outside the set of options for a given function parameter.
require('node:net').connect(-1);
// Throws "RangeError: "port" option should be >= 0 and < 65536: -1" copy
Node.js will generate and throw RangeError instances immediately as a form
of argument validation.
Class: ReferenceError#

Extends: <errors.Error>

Indicates that an attempt is being made to access a variable that is not
defined. Such errors commonly indicate typos in code, or an otherwise broken
program.
While client code may generate and propagate these errors, in practice, only V8
will do so.
doesNotExist;
// Throws ReferenceError, doesNotExist is not a variable in this program. copy
Unless an application is dynamically generating and running code,
ReferenceError instances indicate a bug in the code or its dependencies.
Class: SyntaxError#

Extends: <errors.Error>

Indicates that a program is not valid JavaScript. These errors may only be
generated and propagated as a result of code evaluation. Code evaluation may
happen as a result of eval, Function, require, or vm. These errors
are almost always indicative of a broken program.
try {
  require('node:vm').runInThisContext('binary ! isNotOk');
} catch (err) {
  // 'err' will be a SyntaxError.
} copy
SyntaxError instances are unrecoverable in the context that created them –
they may only be caught by other contexts.
Class: SystemError#

Extends: <errors.Error>

Node.js generates system errors when exceptions occur within its runtime
environment. These usually occur when an application violates an operating
system constraint. For example, a system error will occur if an application
attempts to read a file that does not exist.

address <string> If present, the address to which a network connection
failed
code <string> The string error code
dest <string> If present, the file path destination when reporting a file
system error
errno <number> The system-provided error number
info <Object> If present, extra details about the error condition
message <string> A system-provided human-readable description of the error
path <string> If present, the file path when reporting a file system error
port <number> If present, the network connection port that is not available
syscall <string> The name of the system call that triggered the error


error.address#

<string>

If present, error.address is a string describing the address to which a
network connection failed.

error.code#

<string>

The error.code property is a string representing the error code.

error.dest#

<string>

If present, error.dest is the file path destination when reporting a file
system error.

error.errno#

<number>

The error.errno property is a negative number which corresponds
to the error code defined in libuv Error handling.
On Windows the error number provided by the system will be normalized by libuv.
To get the string representation of the error code, use
util.getSystemErrorName(error.errno).

error.info#

<Object>

If present, error.info is an object with details about the error condition.

error.message#

<string>

error.message is a system-provided human-readable description of the error.

error.path#

<string>

If present, error.path is a string containing a relevant invalid pathname.

error.port#

<number>

If present, error.port is the network connection port that is not available.

error.syscall#

<string>

The error.syscall property is a string describing the syscall that failed.

Common system errors#
This is a list of system errors commonly-encountered when writing a Node.js
program. For a comprehensive list, see the errno(3) man page.


EACCES (Permission denied): An attempt was made to access a file in a way
forbidden by its file access permissions.


EADDRINUSE (Address already in use): An attempt to bind a server
(net, http, or https) to a local address failed due to
another server on the local system already occupying that address.


ECONNREFUSED (Connection refused): No connection could be made because the
target machine actively refused it. This usually results from trying to
connect to a service that is inactive on the foreign host.


ECONNRESET (Connection reset by peer): A connection was forcibly closed by
a peer. This normally results from a loss of the connection on the remote
socket due to a timeout or reboot. Commonly encountered via the http
and net modules.


EEXIST (File exists): An existing file was the target of an operation that
required that the target not exist.


EISDIR (Is a directory): An operation expected a file, but the given
pathname was a directory.


EMFILE (Too many open files in system): Maximum number of
file descriptors allowable on the system has been reached, and
requests for another descriptor cannot be fulfilled until at least one
has been closed. This is encountered when opening many files at once in
parallel, especially on systems (in particular, macOS) where there is a low
file descriptor limit for processes. To remedy a low limit, run
ulimit -n 2048 in the same shell that will run the Node.js process.


ENOENT (No such file or directory): Commonly raised by fs operations
to indicate that a component of the specified pathname does not exist. No
entity (file or directory) could be found by the given path.


ENOTDIR (Not a directory): A component of the given pathname existed, but
was not a directory as expected. Commonly raised by fs.readdir.


ENOTEMPTY (Directory not empty): A directory with entries was the target
of an operation that requires an empty directory, usually fs.unlink.


ENOTFOUND (DNS lookup failed): Indicates a DNS failure of either
EAI_NODATA or EAI_NONAME. This is not a standard POSIX error.


EPERM (Operation not permitted): An attempt was made to perform an
operation that requires elevated privileges.


EPIPE (Broken pipe): A write on a pipe, socket, or FIFO for which there is
no process to read the data. Commonly encountered at the net and
http layers, indicative that the remote side of the stream being
written to has been closed.


ETIMEDOUT (Operation timed out): A connect or send request failed because
the connected party did not properly respond after a period of time. Usually
encountered by http or net. Often a sign that a socket.end()
was not properly called.



Class: TypeError#

Extends <errors.Error>

Indicates that a provided argument is not an allowable type. For example,
passing a function to a parameter which expects a string would be a TypeError.
require('node:url').parse(() => { });
// Throws TypeError, since it expected a string. copy
Node.js will generate and throw TypeError instances immediately as a form
of argument validation.
Exceptions vs. errors#

A JavaScript exception is a value that is thrown as a result of an invalid
operation or as the target of a throw statement. While it is not required
that these values are instances of Error or classes which inherit from
Error, all exceptions thrown by Node.js or the JavaScript runtime will be
instances of Error.
Some exceptions are unrecoverable at the JavaScript layer. Such exceptions
will always cause the Node.js process to crash. Examples include assert()
checks or abort() calls in the C++ layer.
OpenSSL errors#
Errors originating in crypto or tls are of class Error, and in addition to
the standard .code and .message properties, may have some additional
OpenSSL-specific properties.

error.opensslErrorStack#
An array of errors that can give context to where in the OpenSSL library an
error originates from.

error.function#
The OpenSSL function the error originates in.

error.library#
The OpenSSL library the error originates in.

error.reason#
A human-readable string describing the reason for the error.


Node.js error codes#


ABORT_ERR#

Added in: v15.0.0

Used when an operation has been aborted (typically using an AbortController).
APIs not using AbortSignals typically do not raise an error with this code.
This code does not use the regular ERR_* convention Node.js errors use in
order to be compatible with the web platform's AbortError.


ERR_ACCESS_DENIED#
A special type of error that is triggered whenever Node.js tries to get access
to a resource restricted by the Permission Model.


ERR_AMBIGUOUS_ARGUMENT#
A function argument is being used in a way that suggests that the function
signature may be misunderstood. This is thrown by the node:assert module when
the message parameter in assert.throws(block, message) matches the error
message thrown by block because that usage suggests that the user believes
message is the expected message rather than the message the AssertionError
will display if block does not throw.


ERR_ARG_NOT_ITERABLE#
An iterable argument (i.e. a value that works with for...of loops) was
required, but not provided to a Node.js API.


ERR_ASSERTION#
A special type of error that can be triggered whenever Node.js detects an
exceptional logic violation that should never occur. These are raised typically
by the node:assert module.


ERR_ASYNC_CALLBACK#
An attempt was made to register something that is not a function as an
AsyncHooks callback.


ERR_ASYNC_TYPE#
The type of an asynchronous resource was invalid. Users are also able
to define their own types if using the public embedder API.


ERR_BROTLI_COMPRESSION_FAILED#
Data passed to a Brotli stream was not successfully compressed.


ERR_BROTLI_INVALID_PARAM#
An invalid parameter key was passed during construction of a Brotli stream.


ERR_BUFFER_CONTEXT_NOT_AVAILABLE#
An attempt was made to create a Node.js Buffer instance from addon or embedder
code, while in a JS engine Context that is not associated with a Node.js
instance. The data passed to the Buffer method will have been released
by the time the method returns.
When encountering this error, a possible alternative to creating a Buffer
instance is to create a normal Uint8Array, which only differs in the
prototype of the resulting object. Uint8Arrays are generally accepted in all
Node.js core APIs where Buffers are; they are available in all Contexts.


ERR_BUFFER_OUT_OF_BOUNDS#
An operation outside the bounds of a Buffer was attempted.


ERR_BUFFER_TOO_LARGE#
An attempt has been made to create a Buffer larger than the maximum allowed
size.


ERR_CANNOT_WATCH_SIGINT#
Node.js was unable to watch for the SIGINT signal.


ERR_CHILD_CLOSED_BEFORE_REPLY#
A child process was closed before the parent received a reply.


ERR_CHILD_PROCESS_IPC_REQUIRED#
Used when a child process is being forked without specifying an IPC channel.


ERR_CHILD_PROCESS_STDIO_MAXBUFFER#
Used when the main process is trying to read data from the child process's
STDERR/STDOUT, and the data's length is longer than the maxBuffer option.


ERR_CLOSED_MESSAGE_PORT#

History

VersionChanges
v16.2.0, v14.17.1
The error message was reintroduced.
v11.12.0
The error message was removed.
v10.5.0
Added in: v10.5.0



There was an attempt to use a MessagePort instance in a closed
state, usually after .close() has been called.


ERR_CONSOLE_WRITABLE_STREAM#
Console was instantiated without stdout stream, or Console has a
non-writable stdout or stderr stream.


ERR_CONSTRUCT_CALL_INVALID#

Added in: v12.5.0

A class constructor was called that is not callable.


ERR_CONSTRUCT_CALL_REQUIRED#
A constructor for a class was called without new.


ERR_CONTEXT_NOT_INITIALIZED#
The vm context passed into the API is not yet initialized. This could happen
when an error occurs (and is caught) during the creation of the
context, for example, when the allocation fails or the maximum call stack
size is reached when the context is created.


ERR_CRYPTO_CUSTOM_ENGINE_NOT_SUPPORTED#
An OpenSSL engine was requested (for example, through the clientCertEngine or
privateKeyEngine TLS options) that is not supported by the version of OpenSSL
being used, likely due to the compile-time flag OPENSSL_NO_ENGINE.


ERR_CRYPTO_ECDH_INVALID_FORMAT#
An invalid value for the format argument was passed to the crypto.ECDH()
class getPublicKey() method.


ERR_CRYPTO_ECDH_INVALID_PUBLIC_KEY#
An invalid value for the key argument has been passed to the
crypto.ECDH() class computeSecret() method. It means that the public
key lies outside of the elliptic curve.


ERR_CRYPTO_ENGINE_UNKNOWN#
An invalid crypto engine identifier was passed to
require('node:crypto').setEngine().


ERR_CRYPTO_FIPS_FORCED#
The --force-fips command-line argument was used but there was an attempt
to enable or disable FIPS mode in the node:crypto module.


ERR_CRYPTO_FIPS_UNAVAILABLE#
An attempt was made to enable or disable FIPS mode, but FIPS mode was not
available.


ERR_CRYPTO_HASH_FINALIZED#
hash.digest() was called multiple times. The hash.digest() method must
be called no more than one time per instance of a Hash object.


ERR_CRYPTO_HASH_UPDATE_FAILED#
hash.update() failed for any reason. This should rarely, if ever, happen.


ERR_CRYPTO_INCOMPATIBLE_KEY#
The given crypto keys are incompatible with the attempted operation.


ERR_CRYPTO_INCOMPATIBLE_KEY_OPTIONS#
The selected public or private key encoding is incompatible with other options.


ERR_CRYPTO_INITIALIZATION_FAILED#

Added in: v15.0.0

Initialization of the crypto subsystem failed.


ERR_CRYPTO_INVALID_AUTH_TAG#

Added in: v15.0.0

An invalid authentication tag was provided.


ERR_CRYPTO_INVALID_COUNTER#

Added in: v15.0.0

An invalid counter was provided for a counter-mode cipher.


ERR_CRYPTO_INVALID_CURVE#

Added in: v15.0.0

An invalid elliptic-curve was provided.


ERR_CRYPTO_INVALID_DIGEST#
An invalid crypto digest algorithm was specified.


ERR_CRYPTO_INVALID_IV#

Added in: v15.0.0

An invalid initialization vector was provided.


ERR_CRYPTO_INVALID_JWK#

Added in: v15.0.0

An invalid JSON Web Key was provided.


ERR_CRYPTO_INVALID_KEYLEN#

Added in: v15.0.0

An invalid key length was provided.


ERR_CRYPTO_INVALID_KEYPAIR#

Added in: v15.0.0

An invalid key pair was provided.


ERR_CRYPTO_INVALID_KEYTYPE#

Added in: v15.0.0

An invalid key type was provided.


ERR_CRYPTO_INVALID_KEY_OBJECT_TYPE#
The given crypto key object's type is invalid for the attempted operation.


ERR_CRYPTO_INVALID_MESSAGELEN#

Added in: v15.0.0

An invalid message length was provided.


ERR_CRYPTO_INVALID_SCRYPT_PARAMS#

Added in: v15.0.0

One or more crypto.scrypt() or crypto.scryptSync() parameters are
outside their legal range.


ERR_CRYPTO_INVALID_STATE#
A crypto method was used on an object that was in an invalid state. For
instance, calling cipher.getAuthTag() before calling cipher.final().


ERR_CRYPTO_INVALID_TAG_LENGTH#

Added in: v15.0.0

An invalid authentication tag length was provided.


ERR_CRYPTO_JOB_INIT_FAILED#

Added in: v15.0.0

Initialization of an asynchronous crypto operation failed.


ERR_CRYPTO_JWK_UNSUPPORTED_CURVE#
Key's Elliptic Curve is not registered for use in the
JSON Web Key Elliptic Curve Registry.


ERR_CRYPTO_JWK_UNSUPPORTED_KEY_TYPE#
Key's Asymmetric Key Type is not registered for use in the
JSON Web Key Types Registry.


ERR_CRYPTO_OPERATION_FAILED#

Added in: v15.0.0

A crypto operation failed for an otherwise unspecified reason.


ERR_CRYPTO_PBKDF2_ERROR#
The PBKDF2 algorithm failed for unspecified reasons. OpenSSL does not provide
more details and therefore neither does Node.js.


ERR_CRYPTO_SCRYPT_NOT_SUPPORTED#
Node.js was compiled without scrypt support. Not possible with the official
release binaries but can happen with custom builds, including distro builds.


ERR_CRYPTO_SIGN_KEY_REQUIRED#
A signing key was not provided to the sign.sign() method.


ERR_CRYPTO_TIMING_SAFE_EQUAL_LENGTH#
crypto.timingSafeEqual() was called with Buffer, TypedArray, or
DataView arguments of different lengths.


ERR_CRYPTO_UNKNOWN_CIPHER#
An unknown cipher was specified.


ERR_CRYPTO_UNKNOWN_DH_GROUP#
An unknown Diffie-Hellman group name was given. See
crypto.getDiffieHellman() for a list of valid group names.


ERR_CRYPTO_UNSUPPORTED_OPERATION#

Added in: v15.0.0, v14.18.0

An attempt to invoke an unsupported crypto operation was made.


ERR_DEBUGGER_ERROR#

Added in: v16.4.0, v14.17.4

An error occurred with the debugger.


ERR_DEBUGGER_STARTUP_ERROR#

Added in: v16.4.0, v14.17.4

The debugger timed out waiting for the required host/port to be free.


ERR_DIR_CLOSED#
The fs.Dir was previously closed.


ERR_DIR_CONCURRENT_OPERATION#

Added in: v14.3.0

A synchronous read or close call was attempted on an fs.Dir which has
ongoing asynchronous operations.


ERR_DLOPEN_DISABLED#

Added in: v16.10.0, v14.19.0

Loading native addons has been disabled using --no-addons.


ERR_DLOPEN_FAILED#

Added in: v15.0.0

A call to process.dlopen() failed.


ERR_DNS_SET_SERVERS_FAILED#
c-ares failed to set the DNS server.


ERR_DOMAIN_CALLBACK_NOT_AVAILABLE#
The node:domain module was not usable since it could not establish the
required error handling hooks, because
process.setUncaughtExceptionCaptureCallback() had been called at an
earlier point in time.


ERR_DOMAIN_CANNOT_SET_UNCAUGHT_EXCEPTION_CAPTURE#
process.setUncaughtExceptionCaptureCallback() could not be called
because the node:domain module has been loaded at an earlier point in time.
The stack trace is extended to include the point in time at which the
node:domain module had been loaded.


ERR_DUPLICATE_STARTUP_SNAPSHOT_MAIN_FUNCTION#
v8.startupSnapshot.setDeserializeMainFunction() could not be called
because it had already been called before.


ERR_ENCODING_INVALID_ENCODED_DATA#
Data provided to TextDecoder() API was invalid according to the encoding
provided.


ERR_ENCODING_NOT_SUPPORTED#
Encoding provided to TextDecoder() API was not one of the
WHATWG Supported Encodings.


ERR_EVAL_ESM_CANNOT_PRINT#
--print cannot be used with ESM input.


ERR_EVENT_RECURSION#
Thrown when an attempt is made to recursively dispatch an event on EventTarget.


ERR_EXECUTION_ENVIRONMENT_NOT_AVAILABLE#
The JS execution context is not associated with a Node.js environment.
This may occur when Node.js is used as an embedded library and some hooks
for the JS engine are not set up properly.


ERR_FALSY_VALUE_REJECTION#
A Promise that was callbackified via util.callbackify() was rejected with a
falsy value.


ERR_FEATURE_UNAVAILABLE_ON_PLATFORM#

Added in: v14.0.0

Used when a feature that is not available
to the current platform which is running Node.js is used.


ERR_FS_CP_DIR_TO_NON_DIR#

Added in: v16.7.0

An attempt was made to copy a directory to a non-directory (file, symlink,
etc.) using fs.cp().


ERR_FS_CP_EEXIST#

Added in: v16.7.0

An attempt was made to copy over a file that already existed with
fs.cp(), with the force and errorOnExist set to true.


ERR_FS_CP_EINVAL#

Added in: v16.7.0

When using fs.cp(), src or dest pointed to an invalid path.


ERR_FS_CP_FIFO_PIPE#

Added in: v16.7.0

An attempt was made to copy a named pipe with fs.cp().


ERR_FS_CP_NON_DIR_TO_DIR#

Added in: v16.7.0

An attempt was made to copy a non-directory (file, symlink, etc.) to a directory
using fs.cp().


ERR_FS_CP_SOCKET#

Added in: v16.7.0

An attempt was made to copy to a socket with fs.cp().


ERR_FS_CP_SYMLINK_TO_SUBDIRECTORY#

Added in: v16.7.0

When using fs.cp(), a symlink in dest pointed to a subdirectory
of src.


ERR_FS_CP_UNKNOWN#

Added in: v16.7.0

An attempt was made to copy to an unknown file type with fs.cp().


ERR_FS_EISDIR#
Path is a directory.


ERR_FS_FILE_TOO_LARGE#
An attempt has been made to read a file whose size is larger than the maximum
allowed size for a Buffer.


ERR_HTTP2_ALTSVC_INVALID_ORIGIN#
HTTP/2 ALTSVC frames require a valid origin.


ERR_HTTP2_ALTSVC_LENGTH#
HTTP/2 ALTSVC frames are limited to a maximum of 16,382 payload bytes.


ERR_HTTP2_CONNECT_AUTHORITY#
For HTTP/2 requests using the CONNECT method, the :authority pseudo-header
is required.


ERR_HTTP2_CONNECT_PATH#
For HTTP/2 requests using the CONNECT method, the :path pseudo-header is
forbidden.


ERR_HTTP2_CONNECT_SCHEME#
For HTTP/2 requests using the CONNECT method, the :scheme pseudo-header is
forbidden.


ERR_HTTP2_ERROR#
A non-specific HTTP/2 error has occurred.


ERR_HTTP2_GOAWAY_SESSION#
New HTTP/2 Streams may not be opened after the Http2Session has received a
GOAWAY frame from the connected peer.


ERR_HTTP2_HEADERS_AFTER_RESPOND#
An additional headers was specified after an HTTP/2 response was initiated.


ERR_HTTP2_HEADERS_SENT#
An attempt was made to send multiple response headers.


ERR_HTTP2_HEADER_SINGLE_VALUE#
Multiple values were provided for an HTTP/2 header field that was required to
have only a single value.


ERR_HTTP2_INFO_STATUS_NOT_ALLOWED#
Informational HTTP status codes (1xx) may not be set as the response status
code on HTTP/2 responses.


ERR_HTTP2_INVALID_CONNECTION_HEADERS#
HTTP/1 connection specific headers are forbidden to be used in HTTP/2
requests and responses.


ERR_HTTP2_INVALID_HEADER_VALUE#
An invalid HTTP/2 header value was specified.


ERR_HTTP2_INVALID_INFO_STATUS#
An invalid HTTP informational status code has been specified. Informational
status codes must be an integer between 100 and 199 (inclusive).


ERR_HTTP2_INVALID_ORIGIN#
HTTP/2 ORIGIN frames require a valid origin.


ERR_HTTP2_INVALID_PACKED_SETTINGS_LENGTH#
Input Buffer and Uint8Array instances passed to the
http2.getUnpackedSettings() API must have a length that is a multiple of
six.


ERR_HTTP2_INVALID_PSEUDOHEADER#
Only valid HTTP/2 pseudoheaders (:status, :path, :authority, :scheme,
and :method) may be used.


ERR_HTTP2_INVALID_SESSION#
An action was performed on an Http2Session object that had already been
destroyed.


ERR_HTTP2_INVALID_SETTING_VALUE#
An invalid value has been specified for an HTTP/2 setting.


ERR_HTTP2_INVALID_STREAM#
An operation was performed on a stream that had already been destroyed.


ERR_HTTP2_MAX_PENDING_SETTINGS_ACK#
Whenever an HTTP/2 SETTINGS frame is sent to a connected peer, the peer is
required to send an acknowledgment that it has received and applied the new
SETTINGS. By default, a maximum number of unacknowledged SETTINGS frames may
be sent at any given time. This error code is used when that limit has been
reached.


ERR_HTTP2_NESTED_PUSH#
An attempt was made to initiate a new push stream from within a push stream.
Nested push streams are not permitted.


ERR_HTTP2_NO_MEM#
Out of memory when using the http2session.setLocalWindowSize(windowSize) API.


ERR_HTTP2_NO_SOCKET_MANIPULATION#
An attempt was made to directly manipulate (read, write, pause, resume, etc.) a
socket attached to an Http2Session.


ERR_HTTP2_ORIGIN_LENGTH#
HTTP/2 ORIGIN frames are limited to a length of 16382 bytes.


ERR_HTTP2_OUT_OF_STREAMS#
The number of streams created on a single HTTP/2 session reached the maximum
limit.


ERR_HTTP2_PAYLOAD_FORBIDDEN#
A message payload was specified for an HTTP response code for which a payload is
forbidden.


ERR_HTTP2_PING_CANCEL#
An HTTP/2 ping was canceled.


ERR_HTTP2_PING_LENGTH#
HTTP/2 ping payloads must be exactly 8 bytes in length.


ERR_HTTP2_PSEUDOHEADER_NOT_ALLOWED#
An HTTP/2 pseudo-header has been used inappropriately. Pseudo-headers are header
key names that begin with the : prefix.


ERR_HTTP2_PUSH_DISABLED#
An attempt was made to create a push stream, which had been disabled by the
client.


ERR_HTTP2_SEND_FILE#
An attempt was made to use the Http2Stream.prototype.responseWithFile() API to
send a directory.


ERR_HTTP2_SEND_FILE_NOSEEK#
An attempt was made to use the Http2Stream.prototype.responseWithFile() API to
send something other than a regular file, but offset or length options were
provided.


ERR_HTTP2_SESSION_ERROR#
The Http2Session closed with a non-zero error code.


ERR_HTTP2_SETTINGS_CANCEL#
The Http2Session settings canceled.


ERR_HTTP2_SOCKET_BOUND#
An attempt was made to connect a Http2Session object to a net.Socket or
tls.TLSSocket that had already been bound to another Http2Session object.


ERR_HTTP2_SOCKET_UNBOUND#
An attempt was made to use the socket property of an Http2Session that
has already been closed.


ERR_HTTP2_STATUS_101#
Use of the 101 Informational status code is forbidden in HTTP/2.


ERR_HTTP2_STATUS_INVALID#
An invalid HTTP status code has been specified. Status codes must be an integer
between 100 and 599 (inclusive).


ERR_HTTP2_STREAM_CANCEL#
An Http2Stream was destroyed before any data was transmitted to the connected
peer.


ERR_HTTP2_STREAM_ERROR#
A non-zero error code was been specified in an RST_STREAM frame.


ERR_HTTP2_STREAM_SELF_DEPENDENCY#
When setting the priority for an HTTP/2 stream, the stream may be marked as
a dependency for a parent stream. This error code is used when an attempt is
made to mark a stream and dependent of itself.


ERR_HTTP2_TOO_MANY_CUSTOM_SETTINGS#
The number of supported custom settings (10) has been exceeded.


ERR_HTTP2_TOO_MANY_INVALID_FRAMES#

Added in: v15.14.0

The limit of acceptable invalid HTTP/2 protocol frames sent by the peer,
as specified through the maxSessionInvalidFrames option, has been exceeded.


ERR_HTTP2_TRAILERS_ALREADY_SENT#
Trailing headers have already been sent on the Http2Stream.


ERR_HTTP2_TRAILERS_NOT_READY#
The http2stream.sendTrailers() method cannot be called until after the
'wantTrailers' event is emitted on an Http2Stream object. The
'wantTrailers' event will only be emitted if the waitForTrailers option
is set for the Http2Stream.


ERR_HTTP2_UNSUPPORTED_PROTOCOL#
http2.connect() was passed a URL that uses any protocol other than http: or
https:.


ERR_HTTP_BODY_NOT_ALLOWED#
An error is thrown when writing to an HTTP response which does not allow
contents.


ERR_HTTP_CONTENT_LENGTH_MISMATCH#
Response body size doesn't match with the specified content-length header value.


ERR_HTTP_HEADERS_SENT#
An attempt was made to add more headers after the headers had already been sent.


ERR_HTTP_INVALID_HEADER_VALUE#
An invalid HTTP header value was specified.


ERR_HTTP_INVALID_STATUS_CODE#
Status code was outside the regular status code range (100-999).


ERR_HTTP_REQUEST_TIMEOUT#
The client has not sent the entire request within the allowed time.


ERR_HTTP_SOCKET_ASSIGNED#
The given ServerResponse was already assigned a socket.


ERR_HTTP_SOCKET_ENCODING#
Changing the socket encoding is not allowed per RFC 7230 Section 3.


ERR_HTTP_TRAILER_INVALID#
The Trailer header was set even though the transfer encoding does not support
that.


ERR_ILLEGAL_CONSTRUCTOR#
An attempt was made to construct an object using a non-public constructor.


ERR_IMPORT_ATTRIBUTE_MISSING#

Added in: v21.1.0

An import attribute is missing, preventing the specified module to be imported.


ERR_IMPORT_ATTRIBUTE_TYPE_INCOMPATIBLE#

Added in: v21.1.0

An import type attribute was provided, but the specified module is of a
different type.


ERR_IMPORT_ATTRIBUTE_UNSUPPORTED#

Added in: v21.0.0, v20.10.0, v18.19.0

An import attribute is not supported by this version of Node.js.


ERR_INCOMPATIBLE_OPTION_PAIR#
An option pair is incompatible with each other and cannot be used at the same
time.


ERR_INPUT_TYPE_NOT_ALLOWED#
Stability: 1 - Experimental
The --input-type flag was used to attempt to execute a file. This flag can
only be used with input via --eval, --print, or STDIN.


ERR_INSPECTOR_ALREADY_ACTIVATED#
While using the node:inspector module, an attempt was made to activate the
inspector when it already started to listen on a port. Use inspector.close()
before activating it on a different address.


ERR_INSPECTOR_ALREADY_CONNECTED#
While using the node:inspector module, an attempt was made to connect when the
inspector was already connected.


ERR_INSPECTOR_CLOSED#
While using the node:inspector module, an attempt was made to use the
inspector after the session had already closed.


ERR_INSPECTOR_COMMAND#
An error occurred while issuing a command via the node:inspector module.


ERR_INSPECTOR_NOT_ACTIVE#
The inspector is not active when inspector.waitForDebugger() is called.


ERR_INSPECTOR_NOT_AVAILABLE#
The node:inspector module is not available for use.


ERR_INSPECTOR_NOT_CONNECTED#
While using the node:inspector module, an attempt was made to use the
inspector before it was connected.


ERR_INSPECTOR_NOT_WORKER#
An API was called on the main thread that can only be used from
the worker thread.


ERR_INTERNAL_ASSERTION#
There was a bug in Node.js or incorrect usage of Node.js internals.
To fix the error, open an issue at https://github.com/nodejs/node/issues.


ERR_INVALID_ADDRESS#
The provided address is not understood by the Node.js API.


ERR_INVALID_ADDRESS_FAMILY#
The provided address family is not understood by the Node.js API.


ERR_INVALID_ARG_TYPE#
An argument of the wrong type was passed to a Node.js API.


ERR_INVALID_ARG_VALUE#
An invalid or unsupported value was passed for a given argument.


ERR_INVALID_ASYNC_ID#
An invalid asyncId or triggerAsyncId was passed using AsyncHooks. An id
less than -1 should never happen.


ERR_INVALID_BUFFER_SIZE#
A swap was performed on a Buffer but its size was not compatible with the
operation.


ERR_INVALID_CHAR#
Invalid characters were detected in headers.


ERR_INVALID_CURSOR_POS#
A cursor on a given stream cannot be moved to a specified row without a
specified column.


ERR_INVALID_FD#
A file descriptor ('fd') was not valid (e.g. it was a negative value).


ERR_INVALID_FD_TYPE#
A file descriptor ('fd') type was not valid.


ERR_INVALID_FILE_URL_HOST#
A Node.js API that consumes file: URLs (such as certain functions in the
fs module) encountered a file URL with an incompatible host. This
situation can only occur on Unix-like systems where only localhost or an empty
host is supported.


ERR_INVALID_FILE_URL_PATH#
A Node.js API that consumes file: URLs (such as certain functions in the
fs module) encountered a file URL with an incompatible path. The exact
semantics for determining whether a path can be used is platform-dependent.


ERR_INVALID_HANDLE_TYPE#
An attempt was made to send an unsupported "handle" over an IPC communication
channel to a child process. See subprocess.send() and process.send()
for more information.


ERR_INVALID_HTTP_TOKEN#
An invalid HTTP token was supplied.


ERR_INVALID_IP_ADDRESS#
An IP address is not valid.


ERR_INVALID_MIME_SYNTAX#
The syntax of a MIME is not valid.


ERR_INVALID_MODULE#

Added in: v15.0.0, v14.18.0

An attempt was made to load a module that does not exist or was otherwise not
valid.


ERR_INVALID_MODULE_SPECIFIER#
The imported module string is an invalid URL, package name, or package subpath
specifier.


ERR_INVALID_OBJECT_DEFINE_PROPERTY#
An error occurred while setting an invalid attribute on the property of
an object.


ERR_INVALID_PACKAGE_CONFIG#
An invalid package.json file failed parsing.


ERR_INVALID_PACKAGE_TARGET#
The package.json "exports" field contains an invalid target mapping
value for the attempted module resolution.


ERR_INVALID_PROTOCOL#
An invalid options.protocol was passed to http.request().


ERR_INVALID_REPL_EVAL_CONFIG#
Both breakEvalOnSigint and eval options were set in the REPL config,
which is not supported.


ERR_INVALID_REPL_INPUT#
The input may not be used in the REPL. The conditions under which this
error is used are described in the REPL documentation.


ERR_INVALID_RETURN_PROPERTY#
Thrown in case a function option does not provide a valid value for one of its
returned object properties on execution.


ERR_INVALID_RETURN_PROPERTY_VALUE#
Thrown in case a function option does not provide an expected value
type for one of its returned object properties on execution.


ERR_INVALID_RETURN_VALUE#
Thrown in case a function option does not return an expected value
type on execution, such as when a function is expected to return a promise.


ERR_INVALID_STATE#

Added in: v15.0.0

Indicates that an operation cannot be completed due to an invalid state.
For instance, an object may have already been destroyed, or may be
performing another operation.


ERR_INVALID_SYNC_FORK_INPUT#
A Buffer, TypedArray, DataView, or string was provided as stdio input to
an asynchronous fork. See the documentation for the child_process module
for more information.


ERR_INVALID_THIS#
A Node.js API function was called with an incompatible this value.
const urlSearchParams = new URLSearchParams('foo=bar&baz=new');

const buf = Buffer.alloc(1);
urlSearchParams.has.call(buf, 'foo');
// Throws a TypeError with code 'ERR_INVALID_THIS' copy


ERR_INVALID_TUPLE#
An element in the iterable provided to the WHATWG
URLSearchParams constructor did not
represent a [name, value] tuple – that is, if an element is not iterable, or
does not consist of exactly two elements.


ERR_INVALID_TYPESCRIPT_SYNTAX#

History

VersionChanges
v23.7.0, v22.14.0
This error is no longer thrown on valid yet unsupported syntax.
v23.0.0, v22.10.0
Added in: v23.0.0, v22.10.0



The provided TypeScript syntax is not valid.


ERR_INVALID_URI#
An invalid URI was passed.


ERR_INVALID_URL#
An invalid URL was passed to the WHATWG URL
constructor or the legacy url.parse() to be parsed.
The thrown error object typically has an additional property 'input' that
contains the URL that failed to parse.


ERR_INVALID_URL_PATTERN#
An invalid URLPattern was passed to the WHATWG [URLPattern
constructor][new URLPattern(input)] to be parsed.


ERR_INVALID_URL_SCHEME#
An attempt was made to use a URL of an incompatible scheme (protocol) for a
specific purpose. It is only used in the WHATWG URL API support in the
fs module (which only accepts URLs with 'file' scheme), but may be used
in other Node.js APIs as well in the future.


ERR_IPC_CHANNEL_CLOSED#
An attempt was made to use an IPC communication channel that was already closed.


ERR_IPC_DISCONNECTED#
An attempt was made to disconnect an IPC communication channel that was already
disconnected. See the documentation for the child_process module
for more information.


ERR_IPC_ONE_PIPE#
An attempt was made to create a child Node.js process using more than one IPC
communication channel. See the documentation for the child_process module
for more information.


ERR_IPC_SYNC_FORK#
An attempt was made to open an IPC communication channel with a synchronously
forked Node.js process. See the documentation for the child_process module
for more information.


ERR_IP_BLOCKED#
IP is blocked by net.BlockList.


ERR_LOADER_CHAIN_INCOMPLETE#

Added in: v18.6.0, v16.17.0

An ESM loader hook returned without calling next() and without explicitly
signaling a short circuit.


ERR_LOAD_SQLITE_EXTENSION#

Added in: v23.5.0, v22.13.0

An error occurred while loading a SQLite extension.


ERR_MEMORY_ALLOCATION_FAILED#
An attempt was made to allocate memory (usually in the C++ layer) but it
failed.


ERR_MESSAGE_TARGET_CONTEXT_UNAVAILABLE#

Added in: v14.5.0, v12.19.0

A message posted to a MessagePort could not be deserialized in the target
vm Context. Not all Node.js objects can be successfully instantiated in
any context at this time, and attempting to transfer them using postMessage()
can fail on the receiving side in that case.


ERR_METHOD_NOT_IMPLEMENTED#
A method is required but not implemented.


ERR_MISSING_ARGS#
A required argument of a Node.js API was not passed. This is only used for
strict compliance with the API specification (which in some cases may accept
func(undefined) but not func()). In most native Node.js APIs,
func(undefined) and func() are treated identically, and the
ERR_INVALID_ARG_TYPE error code may be used instead.


ERR_MISSING_OPTION#
For APIs that accept options objects, some options might be mandatory. This code
is thrown if a required option is missing.


ERR_MISSING_PASSPHRASE#
An attempt was made to read an encrypted key without specifying a passphrase.


ERR_MISSING_PLATFORM_FOR_WORKER#
The V8 platform used by this instance of Node.js does not support creating
Workers. This is caused by lack of embedder support for Workers. In particular,
this error will not occur with standard builds of Node.js.


ERR_MODULE_NOT_FOUND#
A module file could not be resolved by the ECMAScript modules loader while
attempting an import operation or when loading the program entry point.


ERR_MULTIPLE_CALLBACK#
A callback was called more than once.
A callback is almost always meant to only be called once as the query
can either be fulfilled or rejected but not both at the same time. The latter
would be possible by calling a callback more than once.


ERR_NAPI_CONS_FUNCTION#
While using Node-API, a constructor passed was not a function.


ERR_NAPI_INVALID_DATAVIEW_ARGS#
While calling napi_create_dataview(), a given offset was outside the bounds
of the dataview or offset + length was larger than a length of given buffer.


ERR_NAPI_INVALID_TYPEDARRAY_ALIGNMENT#
While calling napi_create_typedarray(), the provided offset was not a
multiple of the element size.


ERR_NAPI_INVALID_TYPEDARRAY_LENGTH#
While calling napi_create_typedarray(), (length * size_of_element) + byte_offset was larger than the length of given buffer.


ERR_NAPI_TSFN_CALL_JS#
An error occurred while invoking the JavaScript portion of the thread-safe
function.


ERR_NAPI_TSFN_GET_UNDEFINED#
An error occurred while attempting to retrieve the JavaScript undefined
value.


ERR_NON_CONTEXT_AWARE_DISABLED#
A non-context-aware native addon was loaded in a process that disallows them.


ERR_NOT_BUILDING_SNAPSHOT#
An attempt was made to use operations that can only be used when building
V8 startup snapshot even though Node.js isn't building one.


ERR_NOT_IN_SINGLE_EXECUTABLE_APPLICATION#

Added in: v21.7.0, v20.12.0

The operation cannot be performed when it's not in a single-executable
application.


ERR_NOT_SUPPORTED_IN_SNAPSHOT#
An attempt was made to perform operations that are not supported when
building a startup snapshot.


ERR_NO_CRYPTO#
An attempt was made to use crypto features while Node.js was not compiled with
OpenSSL crypto support.


ERR_NO_ICU#
An attempt was made to use features that require ICU, but Node.js was not
compiled with ICU support.


ERR_NO_TYPESCRIPT#

Added in: v23.0.0, v22.12.0

An attempt was made to use features that require Native TypeScript support, but Node.js was not
compiled with TypeScript support.


ERR_OPERATION_FAILED#

Added in: v15.0.0

An operation failed. This is typically used to signal the general failure
of an asynchronous operation.


ERR_OPTIONS_BEFORE_BOOTSTRAPPING#

Added in: v23.10.0

An attempt was made to get options before the bootstrapping was completed.


ERR_OUT_OF_RANGE#
A given value is out of the accepted range.


ERR_PACKAGE_IMPORT_NOT_DEFINED#
The package.json "imports" field does not define the given internal
package specifier mapping.


ERR_PACKAGE_PATH_NOT_EXPORTED#
The package.json "exports" field does not export the requested subpath.
Because exports are encapsulated, private internal modules that are not exported
cannot be imported through the package resolution, unless using an absolute URL.


ERR_PARSE_ARGS_INVALID_OPTION_VALUE#

Added in: v18.3.0, v16.17.0

When strict set to true, thrown by util.parseArgs() if a <boolean>
value is provided for an option of type <string>, or if a <string>
value is provided for an option of type <boolean>.


ERR_PARSE_ARGS_UNEXPECTED_POSITIONAL#

Added in: v18.3.0, v16.17.0

Thrown by util.parseArgs(), when a positional argument is provided and
allowPositionals is set to false.


ERR_PARSE_ARGS_UNKNOWN_OPTION#

Added in: v18.3.0, v16.17.0

When strict set to true, thrown by util.parseArgs() if an argument
is not configured in options.


ERR_PERFORMANCE_INVALID_TIMESTAMP#
An invalid timestamp value was provided for a performance mark or measure.


ERR_PERFORMANCE_MEASURE_INVALID_OPTIONS#
Invalid options were provided for a performance measure.


ERR_PROTO_ACCESS#
Accessing Object.prototype.__proto__ has been forbidden using
--disable-proto=throw. Object.getPrototypeOf and
Object.setPrototypeOf should be used to get and set the prototype of an
object.


ERR_QUIC_APPLICATION_ERROR#

Added in: v23.4.0, v22.13.0

Stability: 1 - Experimental
A QUIC application error occurred.


ERR_QUIC_CONNECTION_FAILED#

Added in: v23.0.0, v22.10.0

Stability: 1 - Experimental
Establishing a QUIC connection failed.


ERR_QUIC_ENDPOINT_CLOSED#

Added in: v23.0.0, v22.10.0

Stability: 1 - Experimental
A QUIC Endpoint closed with an error.


ERR_QUIC_OPEN_STREAM_FAILED#

Added in: v23.0.0, v22.10.0

Stability: 1 - Experimental
Opening a QUIC stream failed.


ERR_QUIC_TRANSPORT_ERROR#

Added in: v23.4.0, v22.13.0

Stability: 1 - Experimental
A QUIC transport error occurred.


ERR_QUIC_VERSION_NEGOTIATION_ERROR#

Added in: v23.4.0, v22.13.0

Stability: 1 - Experimental
A QUIC session failed because version negotiation is required.


ERR_REQUIRE_ASYNC_MODULE#
Stability: 1 - Experimental
When trying to require() a ES Module, the module turns out to be asynchronous.
That is, it contains top-level await.
To see where the top-level await is, use
--experimental-print-required-tla (this would execute the modules
before looking for the top-level awaits).


ERR_REQUIRE_CYCLE_MODULE#
Stability: 1 - Experimental
When trying to require() a ES Module, a CommonJS to ESM or ESM to CommonJS edge
participates in an immediate cycle.
This is not allowed because ES Modules cannot be evaluated while they are
already being evaluated.
To avoid the cycle, the require() call involved in a cycle should not happen
at the top-level of either an ES Module (via createRequire()) or a CommonJS
module, and should be done lazily in an inner function.


ERR_REQUIRE_ESM#

History

VersionChanges
v23.0.0, v22.12.0, v20.19.0
require() now supports loading synchronous ES modules by default.



Stability: 0 - Deprecated
An attempt was made to require() an ES Module.
This error has been deprecated since require() now supports loading synchronous
ES modules. When require() encounters an ES module that contains top-level
await, it will throw ERR_REQUIRE_ASYNC_MODULE instead.


ERR_SCRIPT_EXECUTION_INTERRUPTED#
Script execution was interrupted by SIGINT (For
example, Ctrl+C was pressed.)


ERR_SCRIPT_EXECUTION_TIMEOUT#
Script execution timed out, possibly due to bugs in the script being executed.


ERR_SERVER_ALREADY_LISTEN#
The server.listen() method was called while a net.Server was already
listening. This applies to all instances of net.Server, including HTTP, HTTPS,
and HTTP/2 Server instances.


ERR_SERVER_NOT_RUNNING#
The server.close() method was called when a net.Server was not
running. This applies to all instances of net.Server, including HTTP, HTTPS,
and HTTP/2 Server instances.


ERR_SINGLE_EXECUTABLE_APPLICATION_ASSET_NOT_FOUND#

Added in: v21.7.0, v20.12.0

A key was passed to single executable application APIs to identify an asset,
but no match could be found.


ERR_SOCKET_ALREADY_BOUND#
An attempt was made to bind a socket that has already been bound.


ERR_SOCKET_BAD_BUFFER_SIZE#
An invalid (negative) size was passed for either the recvBufferSize or
sendBufferSize options in dgram.createSocket().


ERR_SOCKET_BAD_PORT#
An API function expecting a port >= 0 and < 65536 received an invalid value.


ERR_SOCKET_BAD_TYPE#
An API function expecting a socket type (udp4 or udp6) received an invalid
value.


ERR_SOCKET_BUFFER_SIZE#
While using dgram.createSocket(), the size of the receive or send Buffer
could not be determined.


ERR_SOCKET_CLOSED#
An attempt was made to operate on an already closed socket.


ERR_SOCKET_CLOSED_BEFORE_CONNECTION#
When calling net.Socket.write() on a connecting socket and the socket was
closed before the connection was established.


ERR_SOCKET_CONNECTION_TIMEOUT#
The socket was unable to connect to any address returned by the DNS within the
allowed timeout when using the family autoselection algorithm.


ERR_SOCKET_DGRAM_IS_CONNECTED#
A dgram.connect() call was made on an already connected socket.


ERR_SOCKET_DGRAM_NOT_CONNECTED#
A dgram.disconnect() or dgram.remoteAddress() call was made on a
disconnected socket.


ERR_SOCKET_DGRAM_NOT_RUNNING#
A call was made and the UDP subsystem was not running.


ERR_SOURCE_MAP_CORRUPT#
The source map could not be parsed because it does not exist, or is corrupt.


ERR_SOURCE_MAP_MISSING_SOURCE#
A file imported from a source map was not found.


ERR_SOURCE_PHASE_NOT_DEFINED#

Added in: v24.0.0

The provided module import does not provide a source phase imports representation for source phase
import syntax import source x from 'x' or import.source(x).


ERR_SQLITE_ERROR#

Added in: v22.5.0

An error was returned from SQLite.


ERR_SRI_PARSE#
A string was provided for a Subresource Integrity check, but was unable to be
parsed. Check the format of integrity attributes by looking at the
Subresource Integrity specification.


ERR_STREAM_ALREADY_FINISHED#
A stream method was called that cannot complete because the stream was
finished.


ERR_STREAM_CANNOT_PIPE#
An attempt was made to call stream.pipe() on a Writable stream.


ERR_STREAM_DESTROYED#
A stream method was called that cannot complete because the stream was
destroyed using stream.destroy().


ERR_STREAM_NULL_VALUES#
An attempt was made to call stream.write() with a null chunk.


ERR_STREAM_PREMATURE_CLOSE#
An error returned by stream.finished() and stream.pipeline(), when a stream
or a pipeline ends non gracefully with no explicit error.


ERR_STREAM_PUSH_AFTER_EOF#
An attempt was made to call stream.push() after a null(EOF) had been
pushed to the stream.


ERR_STREAM_UNABLE_TO_PIPE#
An attempt was made to pipe to a closed or destroyed stream in a pipeline.


ERR_STREAM_UNSHIFT_AFTER_END_EVENT#
An attempt was made to call stream.unshift() after the 'end' event was
emitted.


ERR_STREAM_WRAP#
Prevents an abort if a string decoder was set on the Socket or if the decoder
is in objectMode.
const Socket = require('node:net').Socket;
const instance = new Socket();

instance.setEncoding('utf8'); copy


ERR_STREAM_WRITE_AFTER_END#
An attempt was made to call stream.write() after stream.end() has been
called.


ERR_STRING_TOO_LONG#
An attempt has been made to create a string longer than the maximum allowed
length.


ERR_SYNTHETIC#
An artificial error object used to capture the call stack for diagnostic
reports.


ERR_SYSTEM_ERROR#
An unspecified or non-specific system error has occurred within the Node.js
process. The error object will have an err.info object property with
additional details.


ERR_TEST_FAILURE#
This error represents a failed test. Additional information about the failure
is available via the cause property. The failureType property specifies
what the test was doing when the failure occurred.


ERR_TLS_ALPN_CALLBACK_INVALID_RESULT#
This error is thrown when an ALPNCallback returns a value that is not in the
list of ALPN protocols offered by the client.


ERR_TLS_ALPN_CALLBACK_WITH_PROTOCOLS#
This error is thrown when creating a TLSServer if the TLS options include
both ALPNProtocols and ALPNCallback. These options are mutually exclusive.


ERR_TLS_CERT_ALTNAME_FORMAT#
This error is thrown by checkServerIdentity if a user-supplied
subjectaltname property violates encoding rules. Certificate objects produced
by Node.js itself always comply with encoding rules and will never cause
this error.


ERR_TLS_CERT_ALTNAME_INVALID#
While using TLS, the host name/IP of the peer did not match any of the
subjectAltNames in its certificate.


ERR_TLS_DH_PARAM_SIZE#
While using TLS, the parameter offered for the Diffie-Hellman (DH)
key-agreement protocol is too small. By default, the key length must be greater
than or equal to 1024 bits to avoid vulnerabilities, even though it is strongly
recommended to use 2048 bits or larger for stronger security.


ERR_TLS_HANDSHAKE_TIMEOUT#
A TLS/SSL handshake timed out. In this case, the server must also abort the
connection.


ERR_TLS_INVALID_CONTEXT#

Added in: v13.3.0

The context must be a SecureContext.


ERR_TLS_INVALID_PROTOCOL_METHOD#
The specified  secureProtocol method is invalid. It is  either unknown, or
disabled because it is insecure.


ERR_TLS_INVALID_PROTOCOL_VERSION#
Valid TLS protocol versions are 'TLSv1', 'TLSv1.1', or 'TLSv1.2'.


ERR_TLS_INVALID_STATE#

Added in: v13.10.0, v12.17.0

The TLS socket must be connected and securely established. Ensure the 'secure'
event is emitted before continuing.


ERR_TLS_PROTOCOL_VERSION_CONFLICT#
Attempting to set a TLS protocol minVersion or maxVersion conflicts with an
attempt to set the secureProtocol explicitly. Use one mechanism or the other.


ERR_TLS_PSK_SET_IDENTITY_HINT_FAILED#
Failed to set PSK identity hint. Hint may be too long.


ERR_TLS_RENEGOTIATION_DISABLED#
An attempt was made to renegotiate TLS on a socket instance with renegotiation
disabled.


ERR_TLS_REQUIRED_SERVER_NAME#
While using TLS, the server.addContext() method was called without providing
a host name in the first parameter.


ERR_TLS_SESSION_ATTACK#
An excessive amount of TLS renegotiations is detected, which is a potential
vector for denial-of-service attacks.


ERR_TLS_SNI_FROM_SERVER#
An attempt was made to issue Server Name Indication from a TLS server-side
socket, which is only valid from a client.


ERR_TRACE_EVENTS_CATEGORY_REQUIRED#
The trace_events.createTracing() method requires at least one trace event
category.


ERR_TRACE_EVENTS_UNAVAILABLE#
The node:trace_events module could not be loaded because Node.js was compiled
with the --without-v8-platform flag.


ERR_TRANSFORM_ALREADY_TRANSFORMING#
A Transform stream finished while it was still transforming.


ERR_TRANSFORM_WITH_LENGTH_0#
A Transform stream finished with data still in the write buffer.


ERR_TTY_INIT_FAILED#
The initialization of a TTY failed due to a system error.


ERR_UNAVAILABLE_DURING_EXIT#
Function was called within a process.on('exit') handler that shouldn't be
called within process.on('exit') handler.


ERR_UNCAUGHT_EXCEPTION_CAPTURE_ALREADY_SET#
process.setUncaughtExceptionCaptureCallback() was called twice,
without first resetting the callback to null.
This error is designed to prevent accidentally overwriting a callback registered
from another module.


ERR_UNESCAPED_CHARACTERS#
A string that contained unescaped characters was received.


ERR_UNHANDLED_ERROR#
An unhandled error occurred (for instance, when an 'error' event is emitted
by an EventEmitter but an 'error' handler is not registered).


ERR_UNKNOWN_BUILTIN_MODULE#
Used to identify a specific kind of internal Node.js error that should not
typically be triggered by user code. Instances of this error point to an
internal bug within the Node.js binary itself.


ERR_UNKNOWN_CREDENTIAL#
A Unix group or user identifier that does not exist was passed.


ERR_UNKNOWN_ENCODING#
An invalid or unknown encoding option was passed to an API.


ERR_UNKNOWN_FILE_EXTENSION#
Stability: 1 - Experimental
An attempt was made to load a module with an unknown or unsupported file
extension.


ERR_UNKNOWN_MODULE_FORMAT#
Stability: 1 - Experimental
An attempt was made to load a module with an unknown or unsupported format.


ERR_UNKNOWN_SIGNAL#
An invalid or unknown process signal was passed to an API expecting a valid
signal (such as subprocess.kill()).


ERR_UNSUPPORTED_DIR_IMPORT#
import a directory URL is unsupported. Instead,
self-reference a package using its name and define a custom subpath in
the "exports" field of the package.json file.
import './'; // unsupported
import './index.js'; // supported
import 'package-name'; // supported copy


ERR_UNSUPPORTED_ESM_URL_SCHEME#
import with URL schemes other than file and data is unsupported.


ERR_UNSUPPORTED_NODE_MODULES_TYPE_STRIPPING#

Added in: v22.6.0

Type stripping is not supported for files descendent of a node_modules directory.


ERR_UNSUPPORTED_RESOLVE_REQUEST#
An attempt was made to resolve an invalid module referrer. This can happen when
importing or calling import.meta.resolve() with either:

a bare specifier that is not a builtin module from a module whose URL scheme
is not file.
a relative URL from a module whose URL scheme is not a special scheme.

try {
  // Trying to import the package 'bare-specifier' from a `data:` URL module:
  await import('data:text/javascript,import "bare-specifier"');
} catch (e) {
  console.log(e.code); // ERR_UNSUPPORTED_RESOLVE_REQUEST
} copy


ERR_UNSUPPORTED_TYPESCRIPT_SYNTAX#

Added in: v23.7.0, v22.14.0

The provided TypeScript syntax is unsupported.
This could happen when using TypeScript syntax that requires
transformation with type-stripping.


ERR_USE_AFTER_CLOSE#
Stability: 1 - Experimental
An attempt was made to use something that was already closed.


ERR_VALID_PERFORMANCE_ENTRY_TYPE#
While using the Performance Timing API (perf_hooks), no valid performance
entry types are found.


ERR_VM_DYNAMIC_IMPORT_CALLBACK_MISSING#
A dynamic import callback was not specified.


ERR_VM_DYNAMIC_IMPORT_CALLBACK_MISSING_FLAG#
A dynamic import callback was invoked without --experimental-vm-modules.


ERR_VM_MODULE_ALREADY_LINKED#
The module attempted to be linked is not eligible for linking, because of one of
the following reasons:

It has already been linked (linkingStatus is 'linked')
It is being linked (linkingStatus is 'linking')
Linking has failed for this module (linkingStatus is 'errored')



ERR_VM_MODULE_CACHED_DATA_REJECTED#
The cachedData option passed to a module constructor is invalid.


ERR_VM_MODULE_CANNOT_CREATE_CACHED_DATA#
Cached data cannot be created for modules which have already been evaluated.


ERR_VM_MODULE_DIFFERENT_CONTEXT#
The module being returned from the linker function is from a different context
than the parent module. Linked modules must share the same context.


ERR_VM_MODULE_LINK_FAILURE#
The module was unable to be linked due to a failure.


ERR_VM_MODULE_NOT_MODULE#
The fulfilled value of a linking promise is not a vm.Module object.


ERR_VM_MODULE_STATUS#
The current module's status does not allow for this operation. The specific
meaning of the error depends on the specific function.


ERR_WASI_ALREADY_STARTED#
The WASI instance has already started.


ERR_WASI_NOT_STARTED#
The WASI instance has not been started.


ERR_WEBASSEMBLY_RESPONSE#

Added in: v18.1.0

The Response that has been passed to WebAssembly.compileStreaming or to
WebAssembly.instantiateStreaming is not a valid WebAssembly response.


ERR_WORKER_INIT_FAILED#
The Worker initialization failed.


ERR_WORKER_INVALID_EXEC_ARGV#
The execArgv option passed to the Worker constructor contains
invalid flags.


ERR_WORKER_MESSAGING_ERRORED#

Added in: v22.5.0

Stability: 1.1 - Active development
The destination thread threw an error while processing a message sent via postMessageToThread().


ERR_WORKER_MESSAGING_FAILED#

Added in: v22.5.0

Stability: 1.1 - Active development
The thread requested in postMessageToThread() is invalid or has no workerMessage listener.


ERR_WORKER_MESSAGING_SAME_THREAD#

Added in: v22.5.0

Stability: 1.1 - Active development
The thread id requested in postMessageToThread() is the current thread id.


ERR_WORKER_MESSAGING_TIMEOUT#

Added in: v22.5.0

Stability: 1.1 - Active development
Sending a message via postMessageToThread() timed out.


ERR_WORKER_NOT_RUNNING#
An operation failed because the Worker instance is not currently running.


ERR_WORKER_OUT_OF_MEMORY#
The Worker instance terminated because it reached its memory limit.


ERR_WORKER_PATH#
The path for the main script of a worker is neither an absolute path
nor a relative path starting with ./ or ../.


ERR_WORKER_UNSERIALIZABLE_ERROR#
All attempts at serializing an uncaught exception from a worker thread failed.


ERR_WORKER_UNSUPPORTED_OPERATION#
The requested functionality is not supported in worker threads.


ERR_ZLIB_INITIALIZATION_FAILED#
Creation of a zlib object failed due to incorrect configuration.


ERR_ZSTD_INVALID_PARAM#
An invalid parameter key was passed during construction of a Zstd stream.


HPE_CHUNK_EXTENSIONS_OVERFLOW#

Added in: v21.6.2, v20.11.1, v18.19.1

Too much data was received for a chunk extensions. In order to protect against
malicious or malconfigured clients, if more than 16 KiB of data is received
then an Error with this code will be emitted.


HPE_HEADER_OVERFLOW#

History

VersionChanges
v11.4.0, v10.15.0
Max header size in http_parser was set to 8 KiB.



Too much HTTP header data was received. In order to protect against malicious or
malconfigured clients, if more than maxHeaderSize of HTTP header data is received then
HTTP parsing will abort without a request or response object being created, and
an Error with this code will be emitted.


HPE_UNEXPECTED_CONTENT_LENGTH#
Server is sending both a Content-Length header and Transfer-Encoding: chunked.
Transfer-Encoding: chunked allows the server to maintain an HTTP persistent
connection for dynamically generated content.
In this case, the Content-Length HTTP header cannot be used.
Use Content-Length or Transfer-Encoding: chunked.


MODULE_NOT_FOUND#

History

VersionChanges
v12.0.0
Added requireStack property.



A module file could not be resolved by the CommonJS modules loader while
attempting a require() operation or when loading the program entry point.

Legacy Node.js error codes#
Stability: 0 - Deprecated. These error codes are either inconsistent, or have
been removed.


ERR_CANNOT_TRANSFER_OBJECT#

Added in: v10.5.0Removed in: v12.5.0

The value passed to postMessage() contained an object that is not supported
for transferring.


ERR_CPU_USAGE#

Removed in: v15.0.0

The native call from process.cpuUsage could not be processed.


ERR_CRYPTO_HASH_DIGEST_NO_UTF16#

Added in: v9.0.0Removed in: v12.12.0

The UTF-16 encoding was used with hash.digest(). While the
hash.digest() method does allow an encoding argument to be passed in,
causing the method to return a string rather than a Buffer, the UTF-16
encoding (e.g. ucs or utf16le) is not supported.


ERR_CRYPTO_SCRYPT_INVALID_PARAMETER#

Removed in: v23.0.0

An incompatible combination of options was passed to crypto.scrypt() or
crypto.scryptSync(). New versions of Node.js use the error code
ERR_INCOMPATIBLE_OPTION_PAIR instead, which is consistent with other APIs.


ERR_FS_INVALID_SYMLINK_TYPE#

Removed in: v23.0.0

An invalid symlink type was passed to the fs.symlink() or
fs.symlinkSync() methods.


ERR_HTTP2_FRAME_ERROR#

Added in: v9.0.0Removed in: v10.0.0

Used when a failure occurs sending an individual frame on the HTTP/2
session.


ERR_HTTP2_HEADERS_OBJECT#

Added in: v9.0.0Removed in: v10.0.0

Used when an HTTP/2 Headers Object is expected.


ERR_HTTP2_HEADER_REQUIRED#

Added in: v9.0.0Removed in: v10.0.0

Used when a required header is missing in an HTTP/2 message.


ERR_HTTP2_INFO_HEADERS_AFTER_RESPOND#

Added in: v9.0.0Removed in: v10.0.0

HTTP/2 informational headers must only be sent prior to calling the
Http2Stream.prototype.respond() method.


ERR_HTTP2_STREAM_CLOSED#

Added in: v9.0.0Removed in: v10.0.0

Used when an action has been performed on an HTTP/2 Stream that has already
been closed.


ERR_HTTP_INVALID_CHAR#

Added in: v9.0.0Removed in: v10.0.0

Used when an invalid character is found in an HTTP response status message
(reason phrase).


ERR_IMPORT_ASSERTION_TYPE_FAILED#

Added in: v17.1.0, v16.14.0Removed in: v21.1.0

An import assertion has failed, preventing the specified module to be imported.


ERR_IMPORT_ASSERTION_TYPE_MISSING#

Added in: v17.1.0, v16.14.0Removed in: v21.1.0

An import assertion is missing, preventing the specified module to be imported.


ERR_IMPORT_ASSERTION_TYPE_UNSUPPORTED#

Added in: v17.1.0, v16.14.0Removed in: v21.1.0

An import attribute is not supported by this version of Node.js.


ERR_INDEX_OUT_OF_RANGE#

Added in: v10.0.0Removed in: v11.0.0

A given index was out of the accepted range (e.g. negative offsets).


ERR_INVALID_OPT_VALUE#

Added in: v8.0.0Removed in: v15.0.0

An invalid or unexpected value was passed in an options object.


ERR_INVALID_OPT_VALUE_ENCODING#

Added in: v9.0.0Removed in: v15.0.0

An invalid or unknown file encoding was passed.


ERR_INVALID_PERFORMANCE_MARK#

Added in: v8.5.0Removed in: v16.7.0

While using the Performance Timing API (perf_hooks), a performance mark is
invalid.


ERR_INVALID_TRANSFER_OBJECT#

History

VersionChanges
v21.0.0
A DOMException is thrown instead.
v21.0.0
Removed in: v21.0.0



An invalid transfer object was passed to postMessage().


ERR_MANIFEST_ASSERT_INTEGRITY#

Removed in: v22.2.0

An attempt was made to load a resource, but the resource did not match the
integrity defined by the policy manifest. See the documentation for policy
manifests for more information.


ERR_MANIFEST_DEPENDENCY_MISSING#

Removed in: v22.2.0

An attempt was made to load a resource, but the resource was not listed as a
dependency from the location that attempted to load it. See the documentation
for policy manifests for more information.


ERR_MANIFEST_INTEGRITY_MISMATCH#

Removed in: v22.2.0

An attempt was made to load a policy manifest, but the manifest had multiple
entries for a resource which did not match each other. Update the manifest
entries to match in order to resolve this error. See the documentation for
policy manifests for more information.


ERR_MANIFEST_INVALID_RESOURCE_FIELD#

Removed in: v22.2.0

A policy manifest resource had an invalid value for one of its fields. Update
the manifest entry to match in order to resolve this error. See the
documentation for policy manifests for more information.


ERR_MANIFEST_INVALID_SPECIFIER#

Removed in: v22.2.0

A policy manifest resource had an invalid value for one of its dependency
mappings. Update the manifest entry to match to resolve this error. See the
documentation for policy manifests for more information.


ERR_MANIFEST_PARSE_POLICY#

Removed in: v22.2.0

An attempt was made to load a policy manifest, but the manifest was unable to
be parsed. See the documentation for policy manifests for more information.


ERR_MANIFEST_TDZ#

Removed in: v22.2.0

An attempt was made to read from a policy manifest, but the manifest
initialization has not yet taken place. This is likely a bug in Node.js.


ERR_MANIFEST_UNKNOWN_ONERROR#

Removed in: v22.2.0

A policy manifest was loaded, but had an unknown value for its "onerror"
behavior. See the documentation for policy manifests for more information.


ERR_MISSING_MESSAGE_PORT_IN_TRANSFER_LIST#

Removed in: v15.0.0

This error code was replaced by ERR_MISSING_TRANSFERABLE_IN_TRANSFER_LIST
in Node.js v15.0.0, because it is no longer accurate as other types of
transferable objects also exist now.


ERR_MISSING_TRANSFERABLE_IN_TRANSFER_LIST#

History

VersionChanges
v21.0.0
A DOMException is thrown instead.
v21.0.0
Removed in: v21.0.0
v15.0.0
Added in: v15.0.0



An object that needs to be explicitly listed in the transferList argument
is in the object passed to a postMessage() call, but is not provided
in the transferList for that call. Usually, this is a MessagePort.
In Node.js versions prior to v15.0.0, the error code being used here was
ERR_MISSING_MESSAGE_PORT_IN_TRANSFER_LIST. However, the set of
transferable object types has been expanded to cover more types than
MessagePort.


ERR_NAPI_CONS_PROTOTYPE_OBJECT#

Added in: v9.0.0Removed in: v10.0.0

Used by the Node-API when Constructor.prototype is not an object.


ERR_NAPI_TSFN_START_IDLE_LOOP#

Added in: v10.6.0, v8.16.0Removed in: v14.2.0, v12.17.0

On the main thread, values are removed from the queue associated with the
thread-safe function in an idle loop. This error indicates that an error
has occurred when attempting to start the loop.


ERR_NAPI_TSFN_STOP_IDLE_LOOP#

Added in: v10.6.0, v8.16.0Removed in: v14.2.0, v12.17.0

Once no more items are left in the queue, the idle loop must be suspended. This
error indicates that the idle loop has failed to stop.


ERR_NO_LONGER_SUPPORTED#
A Node.js API was called in an unsupported manner, such as
Buffer.write(string, encoding, offset[, length]).


ERR_OUTOFMEMORY#

Added in: v9.0.0Removed in: v10.0.0

Used generically to identify that an operation caused an out of memory
condition.


ERR_PARSE_HISTORY_DATA#

Added in: v9.0.0Removed in: v10.0.0

The node:repl module was unable to parse data from the REPL history file.


ERR_SOCKET_CANNOT_SEND#

Added in: v9.0.0Removed in: v14.0.0

Data could not be sent on a socket.


ERR_STDERR_CLOSE#

History

VersionChanges
v10.12.0
Rather than emitting an error, process.stderr.end() now only closes the stream side but not the underlying resource, making this error obsolete.
v10.12.0
Removed in: v10.12.0



An attempt was made to close the process.stderr stream. By design, Node.js
does not allow stdout or stderr streams to be closed by user code.


ERR_STDOUT_CLOSE#

History

VersionChanges
v10.12.0
Rather than emitting an error, process.stderr.end() now only closes the stream side but not the underlying resource, making this error obsolete.
v10.12.0
Removed in: v10.12.0



An attempt was made to close the process.stdout stream. By design, Node.js
does not allow stdout or stderr streams to be closed by user code.


ERR_STREAM_READ_NOT_IMPLEMENTED#

Added in: v9.0.0Removed in: v10.0.0

Used when an attempt is made to use a readable stream that has not implemented
readable._read().


ERR_TAP_LEXER_ERROR#
An error representing a failing lexer state.


ERR_TAP_PARSER_ERROR#
An error representing a failing parser state. Additional information about
the token causing the error is available via the cause property.


ERR_TAP_VALIDATION_ERROR#
This error represents a failed TAP validation.


ERR_TLS_RENEGOTIATION_FAILED#

Added in: v9.0.0Removed in: v10.0.0

Used when a TLS renegotiation request has failed in a non-specific way.


ERR_TRANSFERRING_EXTERNALIZED_SHAREDARRAYBUFFER#

Added in: v10.5.0Removed in: v14.0.0

A SharedArrayBuffer whose memory is not managed by the JavaScript engine
or by Node.js was encountered during serialization. Such a SharedArrayBuffer
cannot be serialized.
This can only happen when native addons create SharedArrayBuffers in
"externalized" mode, or put existing SharedArrayBuffer into externalized mode.


ERR_UNKNOWN_STDIN_TYPE#

Added in: v8.0.0Removed in: v11.7.0

An attempt was made to launch a Node.js process with an unknown stdin file
type. This error is usually an indication of a bug within Node.js itself,
although it is possible for user code to trigger it.


ERR_UNKNOWN_STREAM_TYPE#

Added in: v8.0.0Removed in: v11.7.0

An attempt was made to launch a Node.js process with an unknown stdout or
stderr file type. This error is usually an indication of a bug within Node.js
itself, although it is possible for user code to trigger it.


ERR_V8BREAKITERATOR#
The V8 BreakIterator API was used but the full ICU data set is not installed.


ERR_VALUE_OUT_OF_RANGE#

Added in: v9.0.0Removed in: v10.0.0

Used when a given value is out of the accepted range.


ERR_VM_MODULE_LINKING_ERRORED#

Added in: v10.0.0Removed in: v18.1.0, v16.17.0

The linker function returned a module for which linking has failed.


ERR_VM_MODULE_NOT_LINKED#
The module must be successfully linked before instantiation.


ERR_WORKER_UNSUPPORTED_EXTENSION#

Added in: v11.0.0Removed in: v16.9.0

The pathname used for the main script of a worker has an
unknown file extension.


ERR_ZLIB_BINDING_CLOSED#

Added in: v9.0.0Removed in: v10.0.0

Used when an attempt is made to use a zlib object after it has already been
closed.


OpenSSL Error Codes#


Time Validity Errors#


CERT_NOT_YET_VALID#
The certificate is not yet valid: the notBefore date is after the current time.


CERT_HAS_EXPIRED#
The certificate has expired: the notAfter date is before the current time.


CRL_NOT_YET_VALID#
The certificate revocation list (CRL) has a future issue date.


CRL_HAS_EXPIRED#
The certificate revocation list (CRL) has expired.


CERT_REVOKED#
The certificate has been revoked; it is on a certificate revocation list (CRL).


Trust or Chain Related Errors#


UNABLE_TO_GET_ISSUER_CERT#
The issuer certificate of a looked up certificate could not be found. This
normally means the list of trusted certificates is not complete.


UNABLE_TO_GET_ISSUER_CERT_LOCALLY#
The certificate’s issuer is not known. This is the case if the issuer is not
included in the trusted certificate list.


DEPTH_ZERO_SELF_SIGNED_CERT#
The passed certificate is self-signed and the same certificate cannot be found
in the list of trusted certificates.


SELF_SIGNED_CERT_IN_CHAIN#
The certificate’s issuer is not known. This is the case if the issuer is not
included in the trusted certificate list.


CERT_CHAIN_TOO_LONG#
The certificate chain length is greater than the maximum depth.


UNABLE_TO_GET_CRL#
The CRL reference by the certificate could not be found.


UNABLE_TO_VERIFY_LEAF_SIGNATURE#
No signatures could be verified because the chain contains only one certificate
and it is not self signed.


CERT_UNTRUSTED#
The root certificate authority (CA) is not marked as trusted for the specified
purpose.


Basic Extension Errors#


INVALID_CA#
A CA certificate is invalid. Either it is not a CA or its extensions are not
consistent with the supplied purpose.


PATH_LENGTH_EXCEEDED#
The basicConstraints pathlength parameter has been exceeded.


Name Related Errors#


HOSTNAME_MISMATCH#
Certificate does not match provided name.


Usage and Policy Errors#


INVALID_PURPOSE#
The supplied certificate cannot be used for the specified purpose.


CERT_REJECTED#
The root CA is marked to reject the specified purpose.


Formatting Errors#


CERT_SIGNATURE_FAILURE#
The signature of the certificate is invalid.


CRL_SIGNATURE_FAILURE#
The signature of the certificate revocation list (CRL) is invalid.


ERROR_IN_CERT_NOT_BEFORE_FIELD#
The certificate notBefore field contains an invalid time.


ERROR_IN_CERT_NOT_AFTER_FIELD#
The certificate notAfter field contains an invalid time.


ERROR_IN_CRL_LAST_UPDATE_FIELD#
The CRL lastUpdate field contains an invalid time.


ERROR_IN_CRL_NEXT_UPDATE_FIELD#
The CRL nextUpdate field contains an invalid time.


UNABLE_TO_DECRYPT_CERT_SIGNATURE#
The certificate signature could not be decrypted. This means that the actual
signature value could not be determined rather than it not matching the expected
value, this is only meaningful for RSA keys.


UNABLE_TO_DECRYPT_CRL_SIGNATURE#
The certificate revocation list (CRL) signature could not be decrypted: this
means that the actual signature value could not be determined rather than it not
matching the expected value.


UNABLE_TO_DECODE_ISSUER_PUBLIC_KEY#
The public key in the certificate SubjectPublicKeyInfo could not be read.


Other OpenSSL Errors#


OUT_OF_MEM#
An error occurred trying to allocate memory. This should never happen.\n\n\n\nNode.js
        
      
      
About this documentation
Usage and example



Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Modules: TypeScript
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
Readline
REPL
Report
Single executable applications
SQLite
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker

    

    
      
        
          Node.js v24.0.1 documentation
          
            
            
          
        
        
          
            Node.js v24.0.1
            
    
      
        
        Table of contents
      

      
Events

Passing arguments and this to listeners
Asynchronous vs. synchronous
Handling events only once
Error events
Capture rejections of promises
Class: EventEmitter

Event: 'newListener'
Event: 'removeListener'
emitter.addListener(eventName, listener)
emitter.emit(eventName[, ...args])
emitter.eventNames()
emitter.getMaxListeners()
emitter.listenerCount(eventName[, listener])
emitter.listeners(eventName)
emitter.off(eventName, listener)
emitter.on(eventName, listener)
emitter.once(eventName, listener)
emitter.prependListener(eventName, listener)
emitter.prependOnceListener(eventName, listener)
emitter.removeAllListeners([eventName])
emitter.removeListener(eventName, listener)
emitter.setMaxListeners(n)
emitter.rawListeners(eventName)
emitter[Symbol.for('nodejs.rejection')](err, eventName[, ...args])


events.defaultMaxListeners
events.errorMonitor
events.getEventListeners(emitterOrTarget, eventName)
events.getMaxListeners(emitterOrTarget)
events.once(emitter, name[, options])

Awaiting multiple events emitted on process.nextTick()


events.captureRejections
events.captureRejectionSymbol
events.listenerCount(emitter, eventName)
events.on(emitter, eventName[, options])
events.setMaxListeners(n[, ...eventTargets])
events.addAbortListener(signal, listener)
Class: events.EventEmitterAsyncResource extends EventEmitter

new events.EventEmitterAsyncResource([options])
eventemitterasyncresource.asyncId
eventemitterasyncresource.asyncResource
eventemitterasyncresource.emitDestroy()
eventemitterasyncresource.triggerAsyncId


EventTarget and Event API

Node.js EventTarget vs. DOM EventTarget
NodeEventTarget vs. EventEmitter
Event listener
EventTarget error handling
Class: Event

event.bubbles
event.cancelBubble
event.cancelable
event.composed
event.composedPath()
event.currentTarget
event.defaultPrevented
event.eventPhase
event.initEvent(type[, bubbles[, cancelable]])
event.isTrusted
event.preventDefault()
event.returnValue
event.srcElement
event.stopImmediatePropagation()
event.stopPropagation()
event.target
event.timeStamp
event.type


Class: EventTarget

eventTarget.addEventListener(type, listener[, options])
eventTarget.dispatchEvent(event)
eventTarget.removeEventListener(type, listener[, options])


Class: CustomEvent

event.detail


Class: NodeEventTarget

nodeEventTarget.addListener(type, listener)
nodeEventTarget.emit(type, arg)
nodeEventTarget.eventNames()
nodeEventTarget.listenerCount(type)
nodeEventTarget.setMaxListeners(n)
nodeEventTarget.getMaxListeners()
nodeEventTarget.off(type, listener[, options])
nodeEventTarget.on(type, listener)
nodeEventTarget.once(type, listener)
nodeEventTarget.removeAllListeners([type])
nodeEventTarget.removeListener(type, listener[, options])







    
  
            
    
      
        
        Index
      

      
About this documentation
Usage and example

      
        Index
      
    
  


Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Modules: TypeScript
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
Readline
REPL
Report
Single executable applications
SQLite
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker

    
  
            
    
      
        
        Other versions
      
      24.x
23.x
22.x LTS
21.x
20.x LTS
19.x
18.x
17.x
16.x
15.x
14.x
13.x
12.x
11.x
10.x
9.x
8.x
7.x
6.x
5.x
4.x
0.12.x
0.10.x
    
  
            
              
                
                Options
              
        
              
                
                  
                    View on single page
                  
                  
                    View as JSON
                  
                  Edit on GitHub    
                
              
            
          
        
        
      

      Table of contents
Events

Passing arguments and this to listeners
Asynchronous vs. synchronous
Handling events only once
Error events
Capture rejections of promises
Class: EventEmitter

Event: 'newListener'
Event: 'removeListener'
emitter.addListener(eventName, listener)
emitter.emit(eventName[, ...args])
emitter.eventNames()
emitter.getMaxListeners()
emitter.listenerCount(eventName[, listener])
emitter.listeners(eventName)
emitter.off(eventName, listener)
emitter.on(eventName, listener)
emitter.once(eventName, listener)
emitter.prependListener(eventName, listener)
emitter.prependOnceListener(eventName, listener)
emitter.removeAllListeners([eventName])
emitter.removeListener(eventName, listener)
emitter.setMaxListeners(n)
emitter.rawListeners(eventName)
emitter[Symbol.for('nodejs.rejection')](err, eventName[, ...args])


events.defaultMaxListeners
events.errorMonitor
events.getEventListeners(emitterOrTarget, eventName)
events.getMaxListeners(emitterOrTarget)
events.once(emitter, name[, options])

Awaiting multiple events emitted on process.nextTick()


events.captureRejections
events.captureRejectionSymbol
events.listenerCount(emitter, eventName)
events.on(emitter, eventName[, options])
events.setMaxListeners(n[, ...eventTargets])
events.addAbortListener(signal, listener)
Class: events.EventEmitterAsyncResource extends EventEmitter

new events.EventEmitterAsyncResource([options])
eventemitterasyncresource.asyncId
eventemitterasyncresource.asyncResource
eventemitterasyncresource.emitDestroy()
eventemitterasyncresource.triggerAsyncId


EventTarget and Event API

Node.js EventTarget vs. DOM EventTarget
NodeEventTarget vs. EventEmitter
Event listener
EventTarget error handling
Class: Event

event.bubbles
event.cancelBubble
event.cancelable
event.composed
event.composedPath()
event.currentTarget
event.defaultPrevented
event.eventPhase
event.initEvent(type[, bubbles[, cancelable]])
event.isTrusted
event.preventDefault()
event.returnValue
event.srcElement
event.stopImmediatePropagation()
event.stopPropagation()
event.target
event.timeStamp
event.type


Class: EventTarget

eventTarget.addEventListener(type, listener[, options])
eventTarget.dispatchEvent(event)
eventTarget.removeEventListener(type, listener[, options])


Class: CustomEvent

event.detail


Class: NodeEventTarget

nodeEventTarget.addListener(type, listener)
nodeEventTarget.emit(type, arg)
nodeEventTarget.eventNames()
nodeEventTarget.listenerCount(type)
nodeEventTarget.setMaxListeners(n)
nodeEventTarget.getMaxListeners()
nodeEventTarget.off(type, listener[, options])
nodeEventTarget.on(type, listener)
nodeEventTarget.once(type, listener)
nodeEventTarget.removeAllListeners([type])
nodeEventTarget.removeListener(type, listener[, options])








      
        Events#

Stability: 2 - Stable

Source Code: lib/events.js
Much of the Node.js core API is built around an idiomatic asynchronous
event-driven architecture in which certain kinds of objects (called "emitters")
emit named events that cause Function objects ("listeners") to be called.
For instance: a net.Server object emits an event each time a peer
connects to it; a fs.ReadStream emits an event when the file is opened;
a stream emits an event whenever data is available to be read.
All objects that emit events are instances of the EventEmitter class. These
objects expose an eventEmitter.on() function that allows one or more
functions to be attached to named events emitted by the object. Typically,
event names are camel-cased strings but any valid JavaScript property key
can be used.
When the EventEmitter object emits an event, all of the functions attached
to that specific event are called synchronously. Any values returned by the
called listeners are ignored and discarded.
The following example shows a simple EventEmitter instance with a single
listener. The eventEmitter.on() method is used to register listeners, while
the eventEmitter.emit() method is used to trigger the event.

import { EventEmitter } from 'node:events';

class MyEmitter extends EventEmitter {}

const myEmitter = new MyEmitter();
myEmitter.on('event', () => {
  console.log('an event occurred!');
});
myEmitter.emit('event');const EventEmitter = require('node:events');

class MyEmitter extends EventEmitter {}

const myEmitter = new MyEmitter();
myEmitter.on('event', () => {
  console.log('an event occurred!');
});
myEmitter.emit('event');copy
Passing arguments and this to listeners#
The eventEmitter.emit() method allows an arbitrary set of arguments to be
passed to the listener functions. Keep in mind that when
an ordinary listener function is called, the standard this keyword
is intentionally set to reference the EventEmitter instance to which the
listener is attached.

import { EventEmitter } from 'node:events';
class MyEmitter extends EventEmitter {}
const myEmitter = new MyEmitter();
myEmitter.on('event', function(a, b) {
  console.log(a, b, this, this === myEmitter);
  // Prints:
  //   a b MyEmitter {
  //     _events: [Object: null prototype] { event: [Function (anonymous)] },
  //     _eventsCount: 1,
  //     _maxListeners: undefined,
  //     Symbol(shapeMode): false,
  //     Symbol(kCapture): false
  //   } true
});
myEmitter.emit('event', 'a', 'b');const EventEmitter = require('node:events');
class MyEmitter extends EventEmitter {}
const myEmitter = new MyEmitter();
myEmitter.on('event', function(a, b) {
  console.log(a, b, this, this === myEmitter);
  // Prints:
  //   a b MyEmitter {
  //     _events: [Object: null prototype] { event: [Function (anonymous)] },
  //     _eventsCount: 1,
  //     _maxListeners: undefined,
  //     Symbol(shapeMode): false,
  //     Symbol(kCapture): false
  //   } true
});
myEmitter.emit('event', 'a', 'b');copy
It is possible to use ES6 Arrow Functions as listeners, however, when doing so,
the this keyword will no longer reference the EventEmitter instance:

import { EventEmitter } from 'node:events';
class MyEmitter extends EventEmitter {}
const myEmitter = new MyEmitter();
myEmitter.on('event', (a, b) => {
  console.log(a, b, this);
  // Prints: a b undefined
});
myEmitter.emit('event', 'a', 'b');const EventEmitter = require('node:events');
class MyEmitter extends EventEmitter {}
const myEmitter = new MyEmitter();
myEmitter.on('event', (a, b) => {
  console.log(a, b, this);
  // Prints: a b {}
});
myEmitter.emit('event', 'a', 'b');copy
Asynchronous vs. synchronous#
The EventEmitter calls all listeners synchronously in the order in which
they were registered. This ensures the proper sequencing of
events and helps avoid race conditions and logic errors. When appropriate,
listener functions can switch to an asynchronous mode of operation using
the setImmediate() or process.nextTick() methods:

import { EventEmitter } from 'node:events';
class MyEmitter extends EventEmitter {}
const myEmitter = new MyEmitter();
myEmitter.on('event', (a, b) => {
  setImmediate(() => {
    console.log('this happens asynchronously');
  });
});
myEmitter.emit('event', 'a', 'b');const EventEmitter = require('node:events');
class MyEmitter extends EventEmitter {}
const myEmitter = new MyEmitter();
myEmitter.on('event', (a, b) => {
  setImmediate(() => {
    console.log('this happens asynchronously');
  });
});
myEmitter.emit('event', 'a', 'b');copy
Handling events only once#
When a listener is registered using the eventEmitter.on() method, that
listener is invoked every time the named event is emitted.

import { EventEmitter } from 'node:events';
class MyEmitter extends EventEmitter {}
const myEmitter = new MyEmitter();
let m = 0;
myEmitter.on('event', () => {
  console.log(++m);
});
myEmitter.emit('event');
// Prints: 1
myEmitter.emit('event');
// Prints: 2const EventEmitter = require('node:events');
class MyEmitter extends EventEmitter {}
const myEmitter = new MyEmitter();
let m = 0;
myEmitter.on('event', () => {
  console.log(++m);
});
myEmitter.emit('event');
// Prints: 1
myEmitter.emit('event');
// Prints: 2copy
Using the eventEmitter.once() method, it is possible to register a listener
that is called at most once for a particular event. Once the event is emitted,
the listener is unregistered and then called.

import { EventEmitter } from 'node:events';
class MyEmitter extends EventEmitter {}
const myEmitter = new MyEmitter();
let m = 0;
myEmitter.once('event', () => {
  console.log(++m);
});
myEmitter.emit('event');
// Prints: 1
myEmitter.emit('event');
// Ignoredconst EventEmitter = require('node:events');
class MyEmitter extends EventEmitter {}
const myEmitter = new MyEmitter();
let m = 0;
myEmitter.once('event', () => {
  console.log(++m);
});
myEmitter.emit('event');
// Prints: 1
myEmitter.emit('event');
// Ignoredcopy
Error events#
When an error occurs within an EventEmitter instance, the typical action is
for an 'error' event to be emitted. These are treated as special cases
within Node.js.
If an EventEmitter does not have at least one listener registered for the
'error' event, and an 'error' event is emitted, the error is thrown, a
stack trace is printed, and the Node.js process exits.

import { EventEmitter } from 'node:events';
class MyEmitter extends EventEmitter {}
const myEmitter = new MyEmitter();
myEmitter.emit('error', new Error('whoops!'));
// Throws and crashes Node.jsconst EventEmitter = require('node:events');
class MyEmitter extends EventEmitter {}
const myEmitter = new MyEmitter();
myEmitter.emit('error', new Error('whoops!'));
// Throws and crashes Node.jscopy
To guard against crashing the Node.js process the domain module can be
used. (Note, however, that the node:domain module is deprecated.)
As a best practice, listeners should always be added for the 'error' events.

import { EventEmitter } from 'node:events';
class MyEmitter extends EventEmitter {}
const myEmitter = new MyEmitter();
myEmitter.on('error', (err) => {
  console.error('whoops! there was an error');
});
myEmitter.emit('error', new Error('whoops!'));
// Prints: whoops! there was an errorconst EventEmitter = require('node:events');
class MyEmitter extends EventEmitter {}
const myEmitter = new MyEmitter();
myEmitter.on('error', (err) => {
  console.error('whoops! there was an error');
});
myEmitter.emit('error', new Error('whoops!'));
// Prints: whoops! there was an errorcopy
It is possible to monitor 'error' events without consuming the emitted error
by installing a listener using the symbol events.errorMonitor.

import { EventEmitter, errorMonitor } from 'node:events';

const myEmitter = new EventEmitter();
myEmitter.on(errorMonitor, (err) => {
  MyMonitoringTool.log(err);
});
myEmitter.emit('error', new Error('whoops!'));
// Still throws and crashes Node.jsconst { EventEmitter, errorMonitor } = require('node:events');

const myEmitter = new EventEmitter();
myEmitter.on(errorMonitor, (err) => {
  MyMonitoringTool.log(err);
});
myEmitter.emit('error', new Error('whoops!'));
// Still throws and crashes Node.jscopy
Capture rejections of promises#
Using async functions with event handlers is problematic, because it
can lead to an unhandled rejection in case of a thrown exception:

import { EventEmitter } from 'node:events';
const ee = new EventEmitter();
ee.on('something', async (value) => {
  throw new Error('kaboom');
});const EventEmitter = require('node:events');
const ee = new EventEmitter();
ee.on('something', async (value) => {
  throw new Error('kaboom');
});copy
The captureRejections option in the EventEmitter constructor or the global
setting change this behavior, installing a .then(undefined, handler)
handler on the Promise. This handler routes the exception
asynchronously to the Symbol.for('nodejs.rejection') method
if there is one, or to 'error' event handler if there is none.

import { EventEmitter } from 'node:events';
const ee1 = new EventEmitter({ captureRejections: true });
ee1.on('something', async (value) => {
  throw new Error('kaboom');
});

ee1.on('error', console.log);

const ee2 = new EventEmitter({ captureRejections: true });
ee2.on('something', async (value) => {
  throw new Error('kaboom');
});

ee2[Symbol.for('nodejs.rejection')] = console.log;const EventEmitter = require('node:events');
const ee1 = new EventEmitter({ captureRejections: true });
ee1.on('something', async (value) => {
  throw new Error('kaboom');
});

ee1.on('error', console.log);

const ee2 = new EventEmitter({ captureRejections: true });
ee2.on('something', async (value) => {
  throw new Error('kaboom');
});

ee2[Symbol.for('nodejs.rejection')] = console.log;copy
Setting events.captureRejections = true will change the default for all
new instances of EventEmitter.

import { EventEmitter } from 'node:events';

EventEmitter.captureRejections = true;
const ee1 = new EventEmitter();
ee1.on('something', async (value) => {
  throw new Error('kaboom');
});

ee1.on('error', console.log);const events = require('node:events');
events.captureRejections = true;
const ee1 = new events.EventEmitter();
ee1.on('something', async (value) => {
  throw new Error('kaboom');
});

ee1.on('error', console.log);copy
The 'error' events that are generated by the captureRejections behavior
do not have a catch handler to avoid infinite error loops: the
recommendation is to not use async functions as 'error' event handlers.
Class: EventEmitter#

History

VersionChanges
v13.4.0, v12.16.0
Added captureRejections option.
v0.1.26
Added in: v0.1.26



The EventEmitter class is defined and exposed by the node:events module:

import { EventEmitter } from 'node:events';const EventEmitter = require('node:events');copy
All EventEmitters emit the event 'newListener' when new listeners are
added and 'removeListener' when existing listeners are removed.
It supports the following option:

captureRejections <boolean> It enables
automatic capturing of promise rejection.
Default: false.


Event: 'newListener'#

Added in: v0.1.26


eventName <string> | <symbol> The name of the event being listened for
listener <Function> The event handler function

The EventEmitter instance will emit its own 'newListener' event before
a listener is added to its internal array of listeners.
Listeners registered for the 'newListener' event are passed the event
name and a reference to the listener being added.
The fact that the event is triggered before adding the listener has a subtle
but important side effect: any additional listeners registered to the same
name within the 'newListener' callback are inserted before the
listener that is in the process of being added.

import { EventEmitter } from 'node:events';
class MyEmitter extends EventEmitter {}

const myEmitter = new MyEmitter();
// Only do this once so we don't loop forever
myEmitter.once('newListener', (event, listener) => {
  if (event === 'event') {
    // Insert a new listener in front
    myEmitter.on('event', () => {
      console.log('B');
    });
  }
});
myEmitter.on('event', () => {
  console.log('A');
});
myEmitter.emit('event');
// Prints:
//   B
//   Aconst EventEmitter = require('node:events');
class MyEmitter extends EventEmitter {}

const myEmitter = new MyEmitter();
// Only do this once so we don't loop forever
myEmitter.once('newListener', (event, listener) => {
  if (event === 'event') {
    // Insert a new listener in front
    myEmitter.on('event', () => {
      console.log('B');
    });
  }
});
myEmitter.on('event', () => {
  console.log('A');
});
myEmitter.emit('event');
// Prints:
//   B
//   Acopy

Event: 'removeListener'#

History

VersionChanges
v6.1.0, v4.7.0
For listeners attached using .once(), the listener argument now yields the original listener function.
v0.9.3
Added in: v0.9.3




eventName <string> | <symbol> The event name
listener <Function> The event handler function

The 'removeListener' event is emitted after the listener is removed.

emitter.addListener(eventName, listener)#

Added in: v0.1.26


eventName <string> | <symbol>
listener <Function>

Alias for emitter.on(eventName, listener).

emitter.emit(eventName[, ...args])#

Added in: v0.1.26


eventName <string> | <symbol>
...args <any>
Returns: <boolean>

Synchronously calls each of the listeners registered for the event named
eventName, in the order they were registered, passing the supplied arguments
to each.
Returns true if the event had listeners, false otherwise.

import { EventEmitter } from 'node:events';
const myEmitter = new EventEmitter();

// First listener
myEmitter.on('event', function firstListener() {
  console.log('Helloooo! first listener');
});
// Second listener
myEmitter.on('event', function secondListener(arg1, arg2) {
  console.log(`event with parameters ${arg1}, ${arg2} in second listener`);
});
// Third listener
myEmitter.on('event', function thirdListener(...args) {
  const parameters = args.join(', ');
  console.log(`event with parameters ${parameters} in third listener`);
});

console.log(myEmitter.listeners('event'));

myEmitter.emit('event', 1, 2, 3, 4, 5);

// Prints:
// [
//   [Function: firstListener],
//   [Function: secondListener],
//   [Function: thirdListener]
// ]
// Helloooo! first listener
// event with parameters 1, 2 in second listener
// event with parameters 1, 2, 3, 4, 5 in third listenerconst EventEmitter = require('node:events');
const myEmitter = new EventEmitter();

// First listener
myEmitter.on('event', function firstListener() {
  console.log('Helloooo! first listener');
});
// Second listener
myEmitter.on('event', function secondListener(arg1, arg2) {
  console.log(`event with parameters ${arg1}, ${arg2} in second listener`);
});
// Third listener
myEmitter.on('event', function thirdListener(...args) {
  const parameters = args.join(', ');
  console.log(`event with parameters ${parameters} in third listener`);
});

console.log(myEmitter.listeners('event'));

myEmitter.emit('event', 1, 2, 3, 4, 5);

// Prints:
// [
//   [Function: firstListener],
//   [Function: secondListener],
//   [Function: thirdListener]
// ]
// Helloooo! first listener
// event with parameters 1, 2 in second listener
// event with parameters 1, 2, 3, 4, 5 in third listenercopy

emitter.eventNames()#

Added in: v6.0.0


Returns: <Array>

Returns an array listing the events for which the emitter has registered
listeners. The values in the array are strings or Symbols.

import { EventEmitter } from 'node:events';

const myEE = new EventEmitter();
myEE.on('foo', () => {});
myEE.on('bar', () => {});

const sym = Symbol('symbol');
myEE.on(sym, () => {});

console.log(myEE.eventNames());
// Prints: [ 'foo', 'bar', Symbol(symbol) ]const EventEmitter = require('node:events');

const myEE = new EventEmitter();
myEE.on('foo', () => {});
myEE.on('bar', () => {});

const sym = Symbol('symbol');
myEE.on(sym, () => {});

console.log(myEE.eventNames());
// Prints: [ 'foo', 'bar', Symbol(symbol) ]copy

emitter.getMaxListeners()#

Added in: v1.0.0


Returns: <integer>

Returns the current max listener value for the EventEmitter which is either
set by emitter.setMaxListeners(n) or defaults to
events.defaultMaxListeners.

emitter.listenerCount(eventName[, listener])#

History

VersionChanges
v19.8.0, v18.16.0
Added the listener argument.
v3.2.0
Added in: v3.2.0




eventName <string> | <symbol> The name of the event being listened for
listener <Function> The event handler function
Returns: <integer>

Returns the number of listeners listening for the event named eventName.
If listener is provided, it will return how many times the listener is found
in the list of the listeners of the event.

emitter.listeners(eventName)#

History

VersionChanges
v7.0.0
For listeners attached using .once() this returns the original listeners instead of wrapper functions now.
v0.1.26
Added in: v0.1.26




eventName <string> | <symbol>
Returns: <Function[]>

Returns a copy of the array of listeners for the event named eventName.
server.on('connection', (stream) => {
  console.log('someone connected!');
});
console.log(util.inspect(server.listeners('connection')));
// Prints: [ [Function] ] copy

emitter.off(eventName, listener)#

Added in: v10.0.0


eventName <string> | <symbol>
listener <Function>
Returns: <EventEmitter>

Alias for emitter.removeListener().

emitter.on(eventName, listener)#

Added in: v0.1.101


eventName <string> | <symbol> The name of the event.
listener <Function> The callback function
Returns: <EventEmitter>

Adds the listener function to the end of the listeners array for the
event named eventName. No checks are made to see if the listener has
already been added. Multiple calls passing the same combination of eventName
and listener will result in the listener being added, and called, multiple
times.
server.on('connection', (stream) => {
  console.log('someone connected!');
}); copy
Returns a reference to the EventEmitter, so that calls can be chained.
By default, event listeners are invoked in the order they are added. The
emitter.prependListener() method can be used as an alternative to add the
event listener to the beginning of the listeners array.

import { EventEmitter } from 'node:events';
const myEE = new EventEmitter();
myEE.on('foo', () => console.log('a'));
myEE.prependListener('foo', () => console.log('b'));
myEE.emit('foo');
// Prints:
//   b
//   aconst EventEmitter = require('node:events');
const myEE = new EventEmitter();
myEE.on('foo', () => console.log('a'));
myEE.prependListener('foo', () => console.log('b'));
myEE.emit('foo');
// Prints:
//   b
//   acopy

emitter.once(eventName, listener)#

Added in: v0.3.0


eventName <string> | <symbol> The name of the event.
listener <Function> The callback function
Returns: <EventEmitter>

Adds a one-time listener function for the event named eventName. The
next time eventName is triggered, this listener is removed and then invoked.
server.once('connection', (stream) => {
  console.log('Ah, we have our first user!');
}); copy
Returns a reference to the EventEmitter, so that calls can be chained.
By default, event listeners are invoked in the order they are added. The
emitter.prependOnceListener() method can be used as an alternative to add the
event listener to the beginning of the listeners array.

import { EventEmitter } from 'node:events';
const myEE = new EventEmitter();
myEE.once('foo', () => console.log('a'));
myEE.prependOnceListener('foo', () => console.log('b'));
myEE.emit('foo');
// Prints:
//   b
//   aconst EventEmitter = require('node:events');
const myEE = new EventEmitter();
myEE.once('foo', () => console.log('a'));
myEE.prependOnceListener('foo', () => console.log('b'));
myEE.emit('foo');
// Prints:
//   b
//   acopy

emitter.prependListener(eventName, listener)#

Added in: v6.0.0


eventName <string> | <symbol> The name of the event.
listener <Function> The callback function
Returns: <EventEmitter>

Adds the listener function to the beginning of the listeners array for the
event named eventName. No checks are made to see if the listener has
already been added. Multiple calls passing the same combination of eventName
and listener will result in the listener being added, and called, multiple
times.
server.prependListener('connection', (stream) => {
  console.log('someone connected!');
}); copy
Returns a reference to the EventEmitter, so that calls can be chained.

emitter.prependOnceListener(eventName, listener)#

Added in: v6.0.0


eventName <string> | <symbol> The name of the event.
listener <Function> The callback function
Returns: <EventEmitter>

Adds a one-time listener function for the event named eventName to the
beginning of the listeners array. The next time eventName is triggered, this
listener is removed, and then invoked.
server.prependOnceListener('connection', (stream) => {
  console.log('Ah, we have our first user!');
}); copy
Returns a reference to the EventEmitter, so that calls can be chained.

emitter.removeAllListeners([eventName])#

Added in: v0.1.26


eventName <string> | <symbol>
Returns: <EventEmitter>

Removes all listeners, or those of the specified eventName.
It is bad practice to remove listeners added elsewhere in the code,
particularly when the EventEmitter instance was created by some other
component or module (e.g. sockets or file streams).
Returns a reference to the EventEmitter, so that calls can be chained.

emitter.removeListener(eventName, listener)#

Added in: v0.1.26


eventName <string> | <symbol>
listener <Function>
Returns: <EventEmitter>

Removes the specified listener from the listener array for the event named
eventName.
const callback = (stream) => {
  console.log('someone connected!');
};
server.on('connection', callback);
// ...
server.removeListener('connection', callback); copy
removeListener() will remove, at most, one instance of a listener from the
listener array. If any single listener has been added multiple times to the
listener array for the specified eventName, then removeListener() must be
called multiple times to remove each instance.
Once an event is emitted, all listeners attached to it at the
time of emitting are called in order. This implies that any
removeListener() or removeAllListeners() calls after emitting and
before the last listener finishes execution will not remove them from
emit() in progress. Subsequent events behave as expected.

import { EventEmitter } from 'node:events';
class MyEmitter extends EventEmitter {}
const myEmitter = new MyEmitter();

const callbackA = () => {
  console.log('A');
  myEmitter.removeListener('event', callbackB);
};

const callbackB = () => {
  console.log('B');
};

myEmitter.on('event', callbackA);

myEmitter.on('event', callbackB);

// callbackA removes listener callbackB but it will still be called.
// Internal listener array at time of emit [callbackA, callbackB]
myEmitter.emit('event');
// Prints:
//   A
//   B

// callbackB is now removed.
// Internal listener array [callbackA]
myEmitter.emit('event');
// Prints:
//   Aconst EventEmitter = require('node:events');
class MyEmitter extends EventEmitter {}
const myEmitter = new MyEmitter();

const callbackA = () => {
  console.log('A');
  myEmitter.removeListener('event', callbackB);
};

const callbackB = () => {
  console.log('B');
};

myEmitter.on('event', callbackA);

myEmitter.on('event', callbackB);

// callbackA removes listener callbackB but it will still be called.
// Internal listener array at time of emit [callbackA, callbackB]
myEmitter.emit('event');
// Prints:
//   A
//   B

// callbackB is now removed.
// Internal listener array [callbackA]
myEmitter.emit('event');
// Prints:
//   Acopy
Because listeners are managed using an internal array, calling this will
change the position indexes of any listener registered after the listener
being removed. This will not impact the order in which listeners are called,
but it means that any copies of the listener array as returned by
the emitter.listeners() method will need to be recreated.
When a single function has been added as a handler multiple times for a single
event (as in the example below), removeListener() will remove the most
recently added instance. In the example the once('ping')
listener is removed:

import { EventEmitter } from 'node:events';
const ee = new EventEmitter();

function pong() {
  console.log('pong');
}

ee.on('ping', pong);
ee.once('ping', pong);
ee.removeListener('ping', pong);

ee.emit('ping');
ee.emit('ping');const EventEmitter = require('node:events');
const ee = new EventEmitter();

function pong() {
  console.log('pong');
}

ee.on('ping', pong);
ee.once('ping', pong);
ee.removeListener('ping', pong);

ee.emit('ping');
ee.emit('ping');copy
Returns a reference to the EventEmitter, so that calls can be chained.

emitter.setMaxListeners(n)#

Added in: v0.3.5


n <integer>
Returns: <EventEmitter>

By default EventEmitters will print a warning if more than 10 listeners are
added for a particular event. This is a useful default that helps finding
memory leaks. The emitter.setMaxListeners() method allows the limit to be
modified for this specific EventEmitter instance. The value can be set to
Infinity (or 0) to indicate an unlimited number of listeners.
Returns a reference to the EventEmitter, so that calls can be chained.

emitter.rawListeners(eventName)#

Added in: v9.4.0


eventName <string> | <symbol>
Returns: <Function[]>

Returns a copy of the array of listeners for the event named eventName,
including any wrappers (such as those created by .once()).

import { EventEmitter } from 'node:events';
const emitter = new EventEmitter();
emitter.once('log', () => console.log('log once'));

// Returns a new Array with a function `onceWrapper` which has a property
// `listener` which contains the original listener bound above
const listeners = emitter.rawListeners('log');
const logFnWrapper = listeners[0];

// Logs "log once" to the console and does not unbind the `once` event
logFnWrapper.listener();

// Logs "log once" to the console and removes the listener
logFnWrapper();

emitter.on('log', () => console.log('log persistently'));
// Will return a new Array with a single function bound by `.on()` above
const newListeners = emitter.rawListeners('log');

// Logs "log persistently" twice
newListeners[0]();
emitter.emit('log');const EventEmitter = require('node:events');
const emitter = new EventEmitter();
emitter.once('log', () => console.log('log once'));

// Returns a new Array with a function `onceWrapper` which has a property
// `listener` which contains the original listener bound above
const listeners = emitter.rawListeners('log');
const logFnWrapper = listeners[0];

// Logs "log once" to the console and does not unbind the `once` event
logFnWrapper.listener();

// Logs "log once" to the console and removes the listener
logFnWrapper();

emitter.on('log', () => console.log('log persistently'));
// Will return a new Array with a single function bound by `.on()` above
const newListeners = emitter.rawListeners('log');

// Logs "log persistently" twice
newListeners[0]();
emitter.emit('log');copy

emitter[Symbol.for('nodejs.rejection')](err, eventName[, ...args])#

History

VersionChanges
v17.4.0, v16.14.0
No longer experimental.
v13.4.0, v12.16.0
Added in: v13.4.0, v12.16.0




err Error
eventName <string> | <symbol>
...args <any>

The Symbol.for('nodejs.rejection') method is called in case a
promise rejection happens when emitting an event and
captureRejections is enabled on the emitter.
It is possible to use events.captureRejectionSymbol in
place of Symbol.for('nodejs.rejection').

import { EventEmitter, captureRejectionSymbol } from 'node:events';

class MyClass extends EventEmitter {
  constructor() {
    super({ captureRejections: true });
  }

  [captureRejectionSymbol](err, event, ...args) {
    console.log('rejection happened for', event, 'with', err, ...args);
    this.destroy(err);
  }

  destroy(err) {
    // Tear the resource down here.
  }
}const { EventEmitter, captureRejectionSymbol } = require('node:events');

class MyClass extends EventEmitter {
  constructor() {
    super({ captureRejections: true });
  }

  [captureRejectionSymbol](err, event, ...args) {
    console.log('rejection happened for', event, 'with', err, ...args);
    this.destroy(err);
  }

  destroy(err) {
    // Tear the resource down here.
  }
}copy

events.defaultMaxListeners#

Added in: v0.11.2

By default, a maximum of 10 listeners can be registered for any single
event. This limit can be changed for individual EventEmitter instances
using the emitter.setMaxListeners(n) method. To change the default
for all EventEmitter instances, the events.defaultMaxListeners
property can be used. If this value is not a positive number, a RangeError
is thrown.
Take caution when setting the events.defaultMaxListeners because the
change affects all EventEmitter instances, including those created before
the change is made. However, calling emitter.setMaxListeners(n) still has
precedence over events.defaultMaxListeners.
This is not a hard limit. The EventEmitter instance will allow
more listeners to be added but will output a trace warning to stderr indicating
that a "possible EventEmitter memory leak" has been detected. For any single
EventEmitter, the emitter.getMaxListeners() and emitter.setMaxListeners()
methods can be used to temporarily avoid this warning:
defaultMaxListeners has no effect on AbortSignal instances. While it is
still possible to use emitter.setMaxListeners(n) to set a warning limit
for individual AbortSignal instances, per default AbortSignal instances will not warn.

import { EventEmitter } from 'node:events';
const emitter = new EventEmitter();
emitter.setMaxListeners(emitter.getMaxListeners() + 1);
emitter.once('event', () => {
  // do stuff
  emitter.setMaxListeners(Math.max(emitter.getMaxListeners() - 1, 0));
});const EventEmitter = require('node:events');
const emitter = new EventEmitter();
emitter.setMaxListeners(emitter.getMaxListeners() + 1);
emitter.once('event', () => {
  // do stuff
  emitter.setMaxListeners(Math.max(emitter.getMaxListeners() - 1, 0));
});copy
The --trace-warnings command-line flag can be used to display the
stack trace for such warnings.
The emitted warning can be inspected with process.on('warning') and will
have the additional emitter, type, and count properties, referring to
the event emitter instance, the event's name and the number of attached
listeners, respectively.
Its name property is set to 'MaxListenersExceededWarning'.
events.errorMonitor#

Added in: v13.6.0, v12.17.0

This symbol shall be used to install a listener for only monitoring 'error'
events. Listeners installed using this symbol are called before the regular
'error' listeners are called.
Installing a listener using this symbol does not change the behavior once an
'error' event is emitted. Therefore, the process will still crash if no
regular 'error' listener is installed.
events.getEventListeners(emitterOrTarget, eventName)#

Added in: v15.2.0, v14.17.0


emitterOrTarget <EventEmitter> | <EventTarget>
eventName <string> | <symbol>
Returns: <Function[]>

Returns a copy of the array of listeners for the event named eventName.
For EventEmitters this behaves exactly the same as calling .listeners on
the emitter.
For EventTargets this is the only way to get the event listeners for the
event target. This is useful for debugging and diagnostic purposes.

import { getEventListeners, EventEmitter } from 'node:events';

{
  const ee = new EventEmitter();
  const listener = () => console.log('Events are fun');
  ee.on('foo', listener);
  console.log(getEventListeners(ee, 'foo')); // [ [Function: listener] ]
}
{
  const et = new EventTarget();
  const listener = () => console.log('Events are fun');
  et.addEventListener('foo', listener);
  console.log(getEventListeners(et, 'foo')); // [ [Function: listener] ]
}const { getEventListeners, EventEmitter } = require('node:events');

{
  const ee = new EventEmitter();
  const listener = () => console.log('Events are fun');
  ee.on('foo', listener);
  console.log(getEventListeners(ee, 'foo')); // [ [Function: listener] ]
}
{
  const et = new EventTarget();
  const listener = () => console.log('Events are fun');
  et.addEventListener('foo', listener);
  console.log(getEventListeners(et, 'foo')); // [ [Function: listener] ]
}copy
events.getMaxListeners(emitterOrTarget)#

Added in: v19.9.0, v18.17.0


emitterOrTarget <EventEmitter> | <EventTarget>
Returns: <number>

Returns the currently set max amount of listeners.
For EventEmitters this behaves exactly the same as calling .getMaxListeners on
the emitter.
For EventTargets this is the only way to get the max event listeners for the
event target. If the number of event handlers on a single EventTarget exceeds
the max set, the EventTarget will print a warning.

import { getMaxListeners, setMaxListeners, EventEmitter } from 'node:events';

{
  const ee = new EventEmitter();
  console.log(getMaxListeners(ee)); // 10
  setMaxListeners(11, ee);
  console.log(getMaxListeners(ee)); // 11
}
{
  const et = new EventTarget();
  console.log(getMaxListeners(et)); // 10
  setMaxListeners(11, et);
  console.log(getMaxListeners(et)); // 11
}const { getMaxListeners, setMaxListeners, EventEmitter } = require('node:events');

{
  const ee = new EventEmitter();
  console.log(getMaxListeners(ee)); // 10
  setMaxListeners(11, ee);
  console.log(getMaxListeners(ee)); // 11
}
{
  const et = new EventTarget();
  console.log(getMaxListeners(et)); // 10
  setMaxListeners(11, et);
  console.log(getMaxListeners(et)); // 11
}copy
events.once(emitter, name[, options])#

History

VersionChanges
v15.0.0
The signal option is supported now.
v11.13.0, v10.16.0
Added in: v11.13.0, v10.16.0




emitter <EventEmitter>
name <string> | <symbol>
options <Object>

signal <AbortSignal> Can be used to cancel waiting for the event.


Returns: <Promise>

Creates a Promise that is fulfilled when the EventEmitter emits the given
event or that is rejected if the EventEmitter emits 'error' while waiting.
The Promise will resolve with an array of all the arguments emitted to the
given event.
This method is intentionally generic and works with the web platform
EventTarget interface, which has no special
'error' event semantics and does not listen to the 'error' event.

import { once, EventEmitter } from 'node:events';
import process from 'node:process';

const ee = new EventEmitter();

process.nextTick(() => {
  ee.emit('myevent', 42);
});

const [value] = await once(ee, 'myevent');
console.log(value);

const err = new Error('kaboom');
process.nextTick(() => {
  ee.emit('error', err);
});

try {
  await once(ee, 'myevent');
} catch (err) {
  console.error('error happened', err);
}const { once, EventEmitter } = require('node:events');

async function run() {
  const ee = new EventEmitter();

  process.nextTick(() => {
    ee.emit('myevent', 42);
  });

  const [value] = await once(ee, 'myevent');
  console.log(value);

  const err = new Error('kaboom');
  process.nextTick(() => {
    ee.emit('error', err);
  });

  try {
    await once(ee, 'myevent');
  } catch (err) {
    console.error('error happened', err);
  }
}

run();copy
The special handling of the 'error' event is only used when events.once()
is used to wait for another event. If events.once() is used to wait for the
'error' event itself, then it is treated as any other kind of event without
special handling:

import { EventEmitter, once } from 'node:events';

const ee = new EventEmitter();

once(ee, 'error')
  .then(([err]) => console.log('ok', err.message))
  .catch((err) => console.error('error', err.message));

ee.emit('error', new Error('boom'));

// Prints: ok boomconst { EventEmitter, once } = require('node:events');

const ee = new EventEmitter();

once(ee, 'error')
  .then(([err]) => console.log('ok', err.message))
  .catch((err) => console.error('error', err.message));

ee.emit('error', new Error('boom'));

// Prints: ok boomcopy
An <AbortSignal> can be used to cancel waiting for the event:

import { EventEmitter, once } from 'node:events';

const ee = new EventEmitter();
const ac = new AbortController();

async function foo(emitter, event, signal) {
  try {
    await once(emitter, event, { signal });
    console.log('event emitted!');
  } catch (error) {
    if (error.name === 'AbortError') {
      console.error('Waiting for the event was canceled!');
    } else {
      console.error('There was an error', error.message);
    }
  }
}

foo(ee, 'foo', ac.signal);
ac.abort(); // Prints: Waiting for the event was canceled!const { EventEmitter, once } = require('node:events');

const ee = new EventEmitter();
const ac = new AbortController();

async function foo(emitter, event, signal) {
  try {
    await once(emitter, event, { signal });
    console.log('event emitted!');
  } catch (error) {
    if (error.name === 'AbortError') {
      console.error('Waiting for the event was canceled!');
    } else {
      console.error('There was an error', error.message);
    }
  }
}

foo(ee, 'foo', ac.signal);
ac.abort(); // Prints: Waiting for the event was canceled!copy

Awaiting multiple events emitted on process.nextTick()#
There is an edge case worth noting when using the events.once() function
to await multiple events emitted on in the same batch of process.nextTick()
operations, or whenever multiple events are emitted synchronously. Specifically,
because the process.nextTick() queue is drained before the Promise microtask
queue, and because EventEmitter emits all events synchronously, it is possible
for events.once() to miss an event.

import { EventEmitter, once } from 'node:events';
import process from 'node:process';

const myEE = new EventEmitter();

async function foo() {
  await once(myEE, 'bar');
  console.log('bar');

  // This Promise will never resolve because the 'foo' event will
  // have already been emitted before the Promise is created.
  await once(myEE, 'foo');
  console.log('foo');
}

process.nextTick(() => {
  myEE.emit('bar');
  myEE.emit('foo');
});

foo().then(() => console.log('done'));const { EventEmitter, once } = require('node:events');

const myEE = new EventEmitter();

async function foo() {
  await once(myEE, 'bar');
  console.log('bar');

  // This Promise will never resolve because the 'foo' event will
  // have already been emitted before the Promise is created.
  await once(myEE, 'foo');
  console.log('foo');
}

process.nextTick(() => {
  myEE.emit('bar');
  myEE.emit('foo');
});

foo().then(() => console.log('done'));copy
To catch both events, create each of the Promises before awaiting either
of them, then it becomes possible to use Promise.all(), Promise.race(),
or Promise.allSettled():

import { EventEmitter, once } from 'node:events';
import process from 'node:process';

const myEE = new EventEmitter();

async function foo() {
  await Promise.all([once(myEE, 'bar'), once(myEE, 'foo')]);
  console.log('foo', 'bar');
}

process.nextTick(() => {
  myEE.emit('bar');
  myEE.emit('foo');
});

foo().then(() => console.log('done'));const { EventEmitter, once } = require('node:events');

const myEE = new EventEmitter();

async function foo() {
  await Promise.all([once(myEE, 'bar'), once(myEE, 'foo')]);
  console.log('foo', 'bar');
}

process.nextTick(() => {
  myEE.emit('bar');
  myEE.emit('foo');
});

foo().then(() => console.log('done'));copy

events.captureRejections#

History

VersionChanges
v17.4.0, v16.14.0
No longer experimental.
v13.4.0, v12.16.0
Added in: v13.4.0, v12.16.0



Value: <boolean>
Change the default captureRejections option on all new EventEmitter objects.
events.captureRejectionSymbol#

History

VersionChanges
v17.4.0, v16.14.0
No longer experimental.
v13.4.0, v12.16.0
Added in: v13.4.0, v12.16.0



Value: Symbol.for('nodejs.rejection')
See how to write a custom rejection handler.
events.listenerCount(emitter, eventName)#

Added in: v0.9.12Deprecated since: v3.2.0

Stability: 0 - Deprecated: Use emitter.listenerCount() instead.

emitter <EventEmitter> The emitter to query
eventName <string> | <symbol> The event name

A class method that returns the number of listeners for the given eventName
registered on the given emitter.

import { EventEmitter, listenerCount } from 'node:events';

const myEmitter = new EventEmitter();
myEmitter.on('event', () => {});
myEmitter.on('event', () => {});
console.log(listenerCount(myEmitter, 'event'));
// Prints: 2const { EventEmitter, listenerCount } = require('node:events');

const myEmitter = new EventEmitter();
myEmitter.on('event', () => {});
myEmitter.on('event', () => {});
console.log(listenerCount(myEmitter, 'event'));
// Prints: 2copy
events.on(emitter, eventName[, options])#

History

VersionChanges
v22.0.0, v20.13.0
Support highWaterMark and lowWaterMark options, For consistency. Old options are still supported.
v20.0.0
The close, highWatermark, and lowWatermark options are supported now.
v13.6.0, v12.16.0
Added in: v13.6.0, v12.16.0




emitter <EventEmitter>
eventName <string> | <symbol> The name of the event being listened for
options <Object>

signal <AbortSignal> Can be used to cancel awaiting events.
close - <string[]> Names of events that will end the iteration.
highWaterMark - <integer> Default: Number.MAX_SAFE_INTEGER
The high watermark. The emitter is paused every time the size of events
being buffered is higher than it. Supported only on emitters implementing
pause() and resume() methods.
lowWaterMark - <integer> Default: 1
The low watermark. The emitter is resumed every time the size of events
being buffered is lower than it. Supported only on emitters implementing
pause() and resume() methods.


Returns: <AsyncIterator> that iterates eventName events emitted by the emitter


import { on, EventEmitter } from 'node:events';
import process from 'node:process';

const ee = new EventEmitter();

// Emit later on
process.nextTick(() => {
  ee.emit('foo', 'bar');
  ee.emit('foo', 42);
});

for await (const event of on(ee, 'foo')) {
  // The execution of this inner block is synchronous and it
  // processes one event at a time (even with await). Do not use
  // if concurrent execution is required.
  console.log(event); // prints ['bar'] [42]
}
// Unreachable hereconst { on, EventEmitter } = require('node:events');

(async () => {
  const ee = new EventEmitter();

  // Emit later on
  process.nextTick(() => {
    ee.emit('foo', 'bar');
    ee.emit('foo', 42);
  });

  for await (const event of on(ee, 'foo')) {
    // The execution of this inner block is synchronous and it
    // processes one event at a time (even with await). Do not use
    // if concurrent execution is required.
    console.log(event); // prints ['bar'] [42]
  }
  // Unreachable here
})();copy
Returns an AsyncIterator that iterates eventName events. It will throw
if the EventEmitter emits 'error'. It removes all listeners when
exiting the loop. The value returned by each iteration is an array
composed of the emitted event arguments.
An <AbortSignal> can be used to cancel waiting on events:

import { on, EventEmitter } from 'node:events';
import process from 'node:process';

const ac = new AbortController();

(async () => {
  const ee = new EventEmitter();

  // Emit later on
  process.nextTick(() => {
    ee.emit('foo', 'bar');
    ee.emit('foo', 42);
  });

  for await (const event of on(ee, 'foo', { signal: ac.signal })) {
    // The execution of this inner block is synchronous and it
    // processes one event at a time (even with await). Do not use
    // if concurrent execution is required.
    console.log(event); // prints ['bar'] [42]
  }
  // Unreachable here
})();

process.nextTick(() => ac.abort());const { on, EventEmitter } = require('node:events');

const ac = new AbortController();

(async () => {
  const ee = new EventEmitter();

  // Emit later on
  process.nextTick(() => {
    ee.emit('foo', 'bar');
    ee.emit('foo', 42);
  });

  for await (const event of on(ee, 'foo', { signal: ac.signal })) {
    // The execution of this inner block is synchronous and it
    // processes one event at a time (even with await). Do not use
    // if concurrent execution is required.
    console.log(event); // prints ['bar'] [42]
  }
  // Unreachable here
})();

process.nextTick(() => ac.abort());copy
events.setMaxListeners(n[, ...eventTargets])#

Added in: v15.4.0


n <number> A non-negative number. The maximum number of listeners per
EventTarget event.
...eventsTargets <EventTarget[]> | <EventEmitter[]> Zero or more <EventTarget>
or <EventEmitter> instances. If none are specified, n is set as the default
max for all newly created <EventTarget> and <EventEmitter> objects.


import { setMaxListeners, EventEmitter } from 'node:events';

const target = new EventTarget();
const emitter = new EventEmitter();

setMaxListeners(5, target, emitter);const {
  setMaxListeners,
  EventEmitter,
} = require('node:events');

const target = new EventTarget();
const emitter = new EventEmitter();

setMaxListeners(5, target, emitter);copy
events.addAbortListener(signal, listener)#

History

VersionChanges
v24.0.0
Change stability index for this feature from Experimental to Stable.
v20.5.0, v18.18.0
Added in: v20.5.0, v18.18.0




signal <AbortSignal>
listener <Function> | <EventListener>
Returns: <Disposable> A Disposable that removes the abort listener.

Listens once to the abort event on the provided signal.
Listening to the abort event on abort signals is unsafe and may
lead to resource leaks since another third party with the signal can
call e.stopImmediatePropagation(). Unfortunately Node.js cannot change
this since it would violate the web standard. Additionally, the original
API makes it easy to forget to remove listeners.
This API allows safely using AbortSignals in Node.js APIs by solving these
two issues by listening to the event such that stopImmediatePropagation does
not prevent the listener from running.
Returns a disposable so that it may be unsubscribed from more easily.

const { addAbortListener } = require('node:events');

function example(signal) {
  let disposable;
  try {
    signal.addEventListener('abort', (e) => e.stopImmediatePropagation());
    disposable = addAbortListener(signal, (e) => {
      // Do something when signal is aborted.
    });
  } finally {
    disposable?.[Symbol.dispose]();
  }
}import { addAbortListener } from 'node:events';

function example(signal) {
  let disposable;
  try {
    signal.addEventListener('abort', (e) => e.stopImmediatePropagation());
    disposable = addAbortListener(signal, (e) => {
      // Do something when signal is aborted.
    });
  } finally {
    disposable?.[Symbol.dispose]();
  }
}copy
Class: events.EventEmitterAsyncResource extends EventEmitter#

Added in: v17.4.0, v16.14.0

Integrates EventEmitter with <AsyncResource> for EventEmitters that
require manual async tracking. Specifically, all events emitted by instances
of events.EventEmitterAsyncResource will run within its async context.

import { EventEmitterAsyncResource, EventEmitter } from 'node:events';
import { notStrictEqual, strictEqual } from 'node:assert';
import { executionAsyncId, triggerAsyncId } from 'node:async_hooks';

// Async tracking tooling will identify this as 'Q'.
const ee1 = new EventEmitterAsyncResource({ name: 'Q' });

// 'foo' listeners will run in the EventEmitters async context.
ee1.on('foo', () => {
  strictEqual(executionAsyncId(), ee1.asyncId);
  strictEqual(triggerAsyncId(), ee1.triggerAsyncId);
});

const ee2 = new EventEmitter();

// 'foo' listeners on ordinary EventEmitters that do not track async
// context, however, run in the same async context as the emit().
ee2.on('foo', () => {
  notStrictEqual(executionAsyncId(), ee2.asyncId);
  notStrictEqual(triggerAsyncId(), ee2.triggerAsyncId);
});

Promise.resolve().then(() => {
  ee1.emit('foo');
  ee2.emit('foo');
});const { EventEmitterAsyncResource, EventEmitter } = require('node:events');
const { notStrictEqual, strictEqual } = require('node:assert');
const { executionAsyncId, triggerAsyncId } = require('node:async_hooks');

// Async tracking tooling will identify this as 'Q'.
const ee1 = new EventEmitterAsyncResource({ name: 'Q' });

// 'foo' listeners will run in the EventEmitters async context.
ee1.on('foo', () => {
  strictEqual(executionAsyncId(), ee1.asyncId);
  strictEqual(triggerAsyncId(), ee1.triggerAsyncId);
});

const ee2 = new EventEmitter();

// 'foo' listeners on ordinary EventEmitters that do not track async
// context, however, run in the same async context as the emit().
ee2.on('foo', () => {
  notStrictEqual(executionAsyncId(), ee2.asyncId);
  notStrictEqual(triggerAsyncId(), ee2.triggerAsyncId);
});

Promise.resolve().then(() => {
  ee1.emit('foo');
  ee2.emit('foo');
});copy
The EventEmitterAsyncResource class has the same methods and takes the
same options as EventEmitter and AsyncResource themselves.

new events.EventEmitterAsyncResource([options])#

options <Object>

captureRejections <boolean> It enables
automatic capturing of promise rejection.
Default: false.
name <string> The type of async event. Default: new.target.name.
triggerAsyncId <number> The ID of the execution context that created this
async event. Default: executionAsyncId().
requireManualDestroy <boolean> If set to true, disables emitDestroy
when the object is garbage collected. This usually does not need to be set
(even if emitDestroy is called manually), unless the resource's asyncId
is retrieved and the sensitive API's emitDestroy is called with it.
When set to false, the emitDestroy call on garbage collection
will only take place if there is at least one active destroy hook.
Default: false.




eventemitterasyncresource.asyncId#

Type: <number> The unique asyncId assigned to the resource.


eventemitterasyncresource.asyncResource#

Type: The underlying <AsyncResource>.

The returned AsyncResource object has an additional eventEmitter property
that provides a reference to this EventEmitterAsyncResource.

eventemitterasyncresource.emitDestroy()#
Call all destroy hooks. This should only ever be called once. An error will
be thrown if it is called more than once. This must be manually called. If
the resource is left to be collected by the GC then the destroy hooks will
never be called.

eventemitterasyncresource.triggerAsyncId#

Type: <number> The same triggerAsyncId that is passed to the
AsyncResource constructor.



EventTarget and Event API#

History

VersionChanges
v16.0.0
changed EventTarget error handling.
v15.4.0
No longer experimental.
v15.0.0
The EventTarget and Event classes are now available as globals.
v14.5.0
Added in: v14.5.0



The EventTarget and Event objects are a Node.js-specific implementation
of the EventTarget Web API that are exposed by some Node.js core APIs.
const target = new EventTarget();

target.addEventListener('foo', (event) => {
  console.log('foo event happened!');
}); copy

Node.js EventTarget vs. DOM EventTarget#
There are two key differences between the Node.js EventTarget and the
EventTarget Web API:

Whereas DOM EventTarget instances may be hierarchical, there is no
concept of hierarchy and event propagation in Node.js. That is, an event
dispatched to an EventTarget does not propagate through a hierarchy of
nested target objects that may each have their own set of handlers for the
event.
In the Node.js EventTarget, if an event listener is an async function
or returns a Promise, and the returned Promise rejects, the rejection
is automatically captured and handled the same way as a listener that
throws synchronously (see EventTarget error handling for details).


NodeEventTarget vs. EventEmitter#
The NodeEventTarget object implements a modified subset of the
EventEmitter API that allows it to closely emulate an EventEmitter in
certain situations. A NodeEventTarget is not an instance of EventEmitter
and cannot be used in place of an EventEmitter in most cases.

Unlike EventEmitter, any given listener can be registered at most once
per event type. Attempts to register a listener multiple times are
ignored.
The NodeEventTarget does not emulate the full EventEmitter API.
Specifically the prependListener(), prependOnceListener(),
rawListeners(), and errorMonitor APIs are not emulated.
The 'newListener' and 'removeListener' events will also not be emitted.
The NodeEventTarget does not implement any special default behavior
for events with type 'error'.
The NodeEventTarget supports EventListener objects as well as
functions as handlers for all event types.


Event listener#
Event listeners registered for an event type may either be JavaScript
functions or objects with a handleEvent property whose value is a function.
In either case, the handler function is invoked with the event argument
passed to the eventTarget.dispatchEvent() function.
Async functions may be used as event listeners. If an async handler function
rejects, the rejection is captured and handled as described in
EventTarget error handling.
An error thrown by one handler function does not prevent the other handlers
from being invoked.
The return value of a handler function is ignored.
Handlers are always invoked in the order they were added.
Handler functions may mutate the event object.
function handler1(event) {
  console.log(event.type);  // Prints 'foo'
  event.a = 1;
}

async function handler2(event) {
  console.log(event.type);  // Prints 'foo'
  console.log(event.a);  // Prints 1
}

const handler3 = {
  handleEvent(event) {
    console.log(event.type);  // Prints 'foo'
  },
};

const handler4 = {
  async handleEvent(event) {
    console.log(event.type);  // Prints 'foo'
  },
};

const target = new EventTarget();

target.addEventListener('foo', handler1);
target.addEventListener('foo', handler2);
target.addEventListener('foo', handler3);
target.addEventListener('foo', handler4, { once: true }); copy

EventTarget error handling#
When a registered event listener throws (or returns a Promise that rejects),
by default the error is treated as an uncaught exception on
process.nextTick(). This means uncaught exceptions in EventTargets will
terminate the Node.js process by default.
Throwing within an event listener will not stop the other registered handlers
from being invoked.
The EventTarget does not implement any special default handling for 'error'
type events like EventEmitter.
Currently errors are first forwarded to the process.on('error') event
before reaching process.on('uncaughtException'). This behavior is
deprecated and will change in a future release to align EventTarget with
other Node.js APIs. Any code relying on the process.on('error') event should
be aligned with the new behavior.

Class: Event#

History

VersionChanges
v15.0.0
The Event class is now available through the global object.
v14.5.0
Added in: v14.5.0



The Event object is an adaptation of the Event Web API. Instances
are created internally by Node.js.

event.bubbles#

Added in: v14.5.0


Type: <boolean> Always returns false.

This is not used in Node.js and is provided purely for completeness.

event.cancelBubble#

Added in: v14.5.0

Stability: 3 - Legacy: Use event.stopPropagation() instead.

Type: <boolean>

Alias for event.stopPropagation() if set to true. This is not used
in Node.js and is provided purely for completeness.

event.cancelable#

Added in: v14.5.0


Type: <boolean> True if the event was created with the cancelable option.


event.composed#

Added in: v14.5.0


Type: <boolean> Always returns false.

This is not used in Node.js and is provided purely for completeness.

event.composedPath()#

Added in: v14.5.0

Returns an array containing the current EventTarget as the only entry or
empty if the event is not being dispatched. This is not used in
Node.js and is provided purely for completeness.

event.currentTarget#

Added in: v14.5.0


Type: <EventTarget> The EventTarget dispatching the event.

Alias for event.target.

event.defaultPrevented#

Added in: v14.5.0


Type: <boolean>

Is true if cancelable is true and event.preventDefault() has been
called.

event.eventPhase#

Added in: v14.5.0


Type: <number> Returns 0 while an event is not being dispatched, 2 while
it is being dispatched.

This is not used in Node.js and is provided purely for completeness.

event.initEvent(type[, bubbles[, cancelable]])#

Added in: v19.5.0

Stability: 3 - Legacy: The WHATWG spec considers it deprecated and users
shouldn't use it at all.

type <string>
bubbles <boolean>
cancelable <boolean>

Redundant with event constructors and incapable of setting composed.
This is not used in Node.js and is provided purely for completeness.

event.isTrusted#

Added in: v14.5.0


Type: <boolean>

The <AbortSignal> "abort" event is emitted with isTrusted set to true. The
value is false in all other cases.

event.preventDefault()#

Added in: v14.5.0

Sets the defaultPrevented property to true if cancelable is true.

event.returnValue#

Added in: v14.5.0

Stability: 3 - Legacy: Use event.defaultPrevented instead.

Type: <boolean> True if the event has not been canceled.

The value of event.returnValue is always the opposite of event.defaultPrevented.
This is not used in Node.js and is provided purely for completeness.

event.srcElement#

Added in: v14.5.0

Stability: 3 - Legacy: Use event.target instead.

Type: <EventTarget> The EventTarget dispatching the event.

Alias for event.target.

event.stopImmediatePropagation()#

Added in: v14.5.0

Stops the invocation of event listeners after the current one completes.

event.stopPropagation()#

Added in: v14.5.0

This is not used in Node.js and is provided purely for completeness.

event.target#

Added in: v14.5.0


Type: <EventTarget> The EventTarget dispatching the event.


event.timeStamp#

Added in: v14.5.0


Type: <number>

The millisecond timestamp when the Event object was created.

event.type#

Added in: v14.5.0


Type: <string>

The event type identifier.

Class: EventTarget#

History

VersionChanges
v15.0.0
The EventTarget class is now available through the global object.
v14.5.0
Added in: v14.5.0




eventTarget.addEventListener(type, listener[, options])#

History

VersionChanges
v15.4.0
add support for signal option.
v14.5.0
Added in: v14.5.0




type <string>
listener <Function> | <EventListener>
options <Object>

once <boolean> When true, the listener is automatically removed
when it is first invoked. Default: false.
passive <boolean> When true, serves as a hint that the listener will
not call the Event object's preventDefault() method.
Default: false.
capture <boolean> Not directly used by Node.js. Added for API
completeness. Default: false.
signal <AbortSignal> The listener will be removed when the given
AbortSignal object's abort() method is called.



Adds a new handler for the type event. Any given listener is added
only once per type and per capture option value.
If the once option is true, the listener is removed after the
next time a type event is dispatched.
The capture option is not used by Node.js in any functional way other than
tracking registered event listeners per the EventTarget specification.
Specifically, the capture option is used as part of the key when registering
a listener. Any individual listener may be added once with
capture = false, and once with capture = true.
function handler(event) {}

const target = new EventTarget();
target.addEventListener('foo', handler, { capture: true });  // first
target.addEventListener('foo', handler, { capture: false }); // second

// Removes the second instance of handler
target.removeEventListener('foo', handler);

// Removes the first instance of handler
target.removeEventListener('foo', handler, { capture: true }); copy

eventTarget.dispatchEvent(event)#

Added in: v14.5.0


event <Event>
Returns: <boolean> true if either event's cancelable attribute value is
false or its preventDefault() method was not invoked, otherwise false.

Dispatches the event to the list of handlers for event.type.
The registered event listeners is synchronously invoked in the order they
were registered.

eventTarget.removeEventListener(type, listener[, options])#

Added in: v14.5.0


type <string>
listener <Function> | <EventListener>
options <Object>

capture <boolean>



Removes the listener from the list of handlers for event type.

Class: CustomEvent#

History

VersionChanges
v23.0.0
No longer experimental.
v22.1.0, v20.13.0
CustomEvent is now stable.
v19.0.0
No longer behind --experimental-global-customevent CLI flag.
v18.7.0, v16.17.0
Added in: v18.7.0, v16.17.0




Extends: <Event>

The CustomEvent object is an adaptation of the CustomEvent Web API.
Instances are created internally by Node.js.

event.detail#

History

VersionChanges
v22.1.0, v20.13.0
CustomEvent is now stable.
v18.7.0, v16.17.0
Added in: v18.7.0, v16.17.0




Type: <any> Returns custom data passed when initializing.

Read-only.

Class: NodeEventTarget#

Added in: v14.5.0


Extends: <EventTarget>

The NodeEventTarget is a Node.js-specific extension to EventTarget
that emulates a subset of the EventEmitter API.

nodeEventTarget.addListener(type, listener)#

Added in: v14.5.0



type <string>


listener <Function> | <EventListener>


Returns: <EventTarget> this


Node.js-specific extension to the EventTarget class that emulates the
equivalent EventEmitter API. The only difference between addListener() and
addEventListener() is that addListener() will return a reference to the
EventTarget.

nodeEventTarget.emit(type, arg)#

Added in: v15.2.0


type <string>
arg <any>
Returns: <boolean> true if event listeners registered for the type exist,
otherwise false.

Node.js-specific extension to the EventTarget class that dispatches the
arg to the list of handlers for type.

nodeEventTarget.eventNames()#

Added in: v14.5.0


Returns: <string[]>

Node.js-specific extension to the EventTarget class that returns an array
of event type names for which event listeners are registered.

nodeEventTarget.listenerCount(type)#

Added in: v14.5.0



type <string>


Returns: <number>


Node.js-specific extension to the EventTarget class that returns the number
of event listeners registered for the type.

nodeEventTarget.setMaxListeners(n)#

Added in: v14.5.0


n <number>

Node.js-specific extension to the EventTarget class that sets the number
of max event listeners as n.

nodeEventTarget.getMaxListeners()#

Added in: v14.5.0


Returns: <number>

Node.js-specific extension to the EventTarget class that returns the number
of max event listeners.

nodeEventTarget.off(type, listener[, options])#

Added in: v14.5.0



type <string>


listener <Function> | <EventListener>


options <Object>

capture <boolean>



Returns: <EventTarget> this


Node.js-specific alias for eventTarget.removeEventListener().

nodeEventTarget.on(type, listener)#

Added in: v14.5.0



type <string>


listener <Function> | <EventListener>


Returns: <EventTarget> this


Node.js-specific alias for eventTarget.addEventListener().

nodeEventTarget.once(type, listener)#

Added in: v14.5.0



type <string>


listener <Function> | <EventListener>


Returns: <EventTarget> this


Node.js-specific extension to the EventTarget class that adds a once
listener for the given event type. This is equivalent to calling on
with the once option set to true.

nodeEventTarget.removeAllListeners([type])#

Added in: v14.5.0



type <string>


Returns: <EventTarget> this


Node.js-specific extension to the EventTarget class. If type is specified,
removes all registered listeners for type, otherwise removes all registered
listeners.

nodeEventTarget.removeListener(type, listener[, options])#

Added in: v14.5.0



type <string>


listener <Function> | <EventListener>


options <Object>

capture <boolean>



Returns: <EventTarget> this


Node.js-specific extension to the EventTarget class that removes the
listener for the given type. The only difference between removeListener()
and removeEventListener() is that removeListener() will return a reference
to the EventTarget.\n\n\n\nNode.js
        
      
      
About this documentation
Usage and example



Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Modules: TypeScript
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
Readline
REPL
Report
Single executable applications
SQLite
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker

    

    
      
        
          Node.js v24.0.1 documentation
          
            
            
          
        
        
          
            Node.js v24.0.1
            
    
      
        
        Table of contents
      

      
File system

Promise example
Callback example
Synchronous example
Promises API

Class: FileHandle

Event: 'close'
filehandle.appendFile(data[, options])
filehandle.chmod(mode)
filehandle.chown(uid, gid)
filehandle.close()
filehandle.createReadStream([options])
filehandle.createWriteStream([options])
filehandle.datasync()
filehandle.fd
filehandle.read(buffer, offset, length, position)
filehandle.read([options])
filehandle.read(buffer[, options])
filehandle.readableWebStream()
filehandle.readFile(options)
filehandle.readLines([options])
filehandle.readv(buffers[, position])
filehandle.stat([options])
filehandle.sync()
filehandle.truncate(len)
filehandle.utimes(atime, mtime)
filehandle.write(buffer, offset[, length[, position]])
filehandle.write(buffer[, options])
filehandle.write(string[, position[, encoding]])
filehandle.writeFile(data, options)
filehandle.writev(buffers[, position])
filehandle[Symbol.asyncDispose]()


fsPromises.access(path[, mode])
fsPromises.appendFile(path, data[, options])
fsPromises.chmod(path, mode)
fsPromises.chown(path, uid, gid)
fsPromises.copyFile(src, dest[, mode])
fsPromises.cp(src, dest[, options])
fsPromises.glob(pattern[, options])
fsPromises.lchmod(path, mode)
fsPromises.lchown(path, uid, gid)
fsPromises.lutimes(path, atime, mtime)
fsPromises.link(existingPath, newPath)
fsPromises.lstat(path[, options])
fsPromises.mkdir(path[, options])
fsPromises.mkdtemp(prefix[, options])
fsPromises.open(path, flags[, mode])
fsPromises.opendir(path[, options])
fsPromises.readdir(path[, options])
fsPromises.readFile(path[, options])
fsPromises.readlink(path[, options])
fsPromises.realpath(path[, options])
fsPromises.rename(oldPath, newPath)
fsPromises.rmdir(path[, options])
fsPromises.rm(path[, options])
fsPromises.stat(path[, options])
fsPromises.statfs(path[, options])
fsPromises.symlink(target, path[, type])
fsPromises.truncate(path[, len])
fsPromises.unlink(path)
fsPromises.utimes(path, atime, mtime)
fsPromises.watch(filename[, options])
fsPromises.writeFile(file, data[, options])
fsPromises.constants


Callback API

fs.access(path[, mode], callback)
fs.appendFile(path, data[, options], callback)
fs.chmod(path, mode, callback)

File modes


fs.chown(path, uid, gid, callback)
fs.close(fd[, callback])
fs.copyFile(src, dest[, mode], callback)
fs.cp(src, dest[, options], callback)
fs.createReadStream(path[, options])
fs.createWriteStream(path[, options])
fs.exists(path, callback)
fs.fchmod(fd, mode, callback)
fs.fchown(fd, uid, gid, callback)
fs.fdatasync(fd, callback)
fs.fstat(fd[, options], callback)
fs.fsync(fd, callback)
fs.ftruncate(fd[, len], callback)
fs.futimes(fd, atime, mtime, callback)
fs.glob(pattern[, options], callback)
fs.lchmod(path, mode, callback)
fs.lchown(path, uid, gid, callback)
fs.lutimes(path, atime, mtime, callback)
fs.link(existingPath, newPath, callback)
fs.lstat(path[, options], callback)
fs.mkdir(path[, options], callback)
fs.mkdtemp(prefix[, options], callback)
fs.open(path[, flags[, mode]], callback)
fs.openAsBlob(path[, options])
fs.opendir(path[, options], callback)
fs.read(fd, buffer, offset, length, position, callback)
fs.read(fd[, options], callback)
fs.read(fd, buffer[, options], callback)
fs.readdir(path[, options], callback)
fs.readFile(path[, options], callback)

File descriptors
Performance Considerations


fs.readlink(path[, options], callback)
fs.readv(fd, buffers[, position], callback)
fs.realpath(path[, options], callback)
fs.realpath.native(path[, options], callback)
fs.rename(oldPath, newPath, callback)
fs.rmdir(path[, options], callback)
fs.rm(path[, options], callback)
fs.stat(path[, options], callback)
fs.statfs(path[, options], callback)
fs.symlink(target, path[, type], callback)
fs.truncate(path[, len], callback)
fs.unlink(path, callback)
fs.unwatchFile(filename[, listener])
fs.utimes(path, atime, mtime, callback)
fs.watch(filename[, options][, listener])

Caveats

Availability
Inodes
Filename argument




fs.watchFile(filename[, options], listener)
fs.write(fd, buffer, offset[, length[, position]], callback)
fs.write(fd, buffer[, options], callback)
fs.write(fd, string[, position[, encoding]], callback)
fs.writeFile(file, data[, options], callback)

Using fs.writeFile() with file descriptors


fs.writev(fd, buffers[, position], callback)


Synchronous API

fs.accessSync(path[, mode])
fs.appendFileSync(path, data[, options])
fs.chmodSync(path, mode)
fs.chownSync(path, uid, gid)
fs.closeSync(fd)
fs.copyFileSync(src, dest[, mode])
fs.cpSync(src, dest[, options])
fs.existsSync(path)
fs.fchmodSync(fd, mode)
fs.fchownSync(fd, uid, gid)
fs.fdatasyncSync(fd)
fs.fstatSync(fd[, options])
fs.fsyncSync(fd)
fs.ftruncateSync(fd[, len])
fs.futimesSync(fd, atime, mtime)
fs.globSync(pattern[, options])
fs.lchmodSync(path, mode)
fs.lchownSync(path, uid, gid)
fs.lutimesSync(path, atime, mtime)
fs.linkSync(existingPath, newPath)
fs.lstatSync(path[, options])
fs.mkdirSync(path[, options])
fs.mkdtempSync(prefix[, options])
fs.opendirSync(path[, options])
fs.openSync(path[, flags[, mode]])
fs.readdirSync(path[, options])
fs.readFileSync(path[, options])
fs.readlinkSync(path[, options])
fs.readSync(fd, buffer, offset, length[, position])
fs.readSync(fd, buffer[, options])
fs.readvSync(fd, buffers[, position])
fs.realpathSync(path[, options])
fs.realpathSync.native(path[, options])
fs.renameSync(oldPath, newPath)
fs.rmdirSync(path[, options])
fs.rmSync(path[, options])
fs.statSync(path[, options])
fs.statfsSync(path[, options])
fs.symlinkSync(target, path[, type])
fs.truncateSync(path[, len])
fs.unlinkSync(path)
fs.utimesSync(path, atime, mtime)
fs.writeFileSync(file, data[, options])
fs.writeSync(fd, buffer, offset[, length[, position]])
fs.writeSync(fd, buffer[, options])
fs.writeSync(fd, string[, position[, encoding]])
fs.writevSync(fd, buffers[, position])


Common Objects

Class: fs.Dir

dir.close()
dir.close(callback)
dir.closeSync()
dir.path
dir.read()
dir.read(callback)
dir.readSync()
dir[Symbol.asyncIterator]()


Class: fs.Dirent

dirent.isBlockDevice()
dirent.isCharacterDevice()
dirent.isDirectory()
dirent.isFIFO()
dirent.isFile()
dirent.isSocket()
dirent.isSymbolicLink()
dirent.name
dirent.parentPath


Class: fs.FSWatcher

Event: 'change'
Event: 'close'
Event: 'error'
watcher.close()
watcher.ref()
watcher.unref()


Class: fs.StatWatcher

watcher.ref()
watcher.unref()


Class: fs.ReadStream

Event: 'close'
Event: 'open'
Event: 'ready'
readStream.bytesRead
readStream.path
readStream.pending


Class: fs.Stats

stats.isBlockDevice()
stats.isCharacterDevice()
stats.isDirectory()
stats.isFIFO()
stats.isFile()
stats.isSocket()
stats.isSymbolicLink()
stats.dev
stats.ino
stats.mode
stats.nlink
stats.uid
stats.gid
stats.rdev
stats.size
stats.blksize
stats.blocks
stats.atimeMs
stats.mtimeMs
stats.ctimeMs
stats.birthtimeMs
stats.atimeNs
stats.mtimeNs
stats.ctimeNs
stats.birthtimeNs
stats.atime
stats.mtime
stats.ctime
stats.birthtime
Stat time values


Class: fs.StatFs

statfs.bavail
statfs.bfree
statfs.blocks
statfs.bsize
statfs.ffree
statfs.files
statfs.type


Class: fs.WriteStream

Event: 'close'
Event: 'open'
Event: 'ready'
writeStream.bytesWritten
writeStream.close([callback])
writeStream.path
writeStream.pending


fs.constants

FS constants

File access constants
File copy constants
File open constants
File type constants
File mode constants






Notes

Ordering of callback and promise-based operations
File paths

String paths
File URL paths

Platform-specific considerations


Buffer paths
Per-drive working directories on Windows


File descriptors
Threadpool usage
File system flags





    
  
            
    
      
        
        Index
      

      
About this documentation
Usage and example

      
        Index
      
    
  


Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Modules: TypeScript
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
Readline
REPL
Report
Single executable applications
SQLite
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker

    
  
            
    
      
        
        Other versions
      
      24.x
23.x
22.x LTS
21.x
20.x LTS
19.x
18.x
17.x
16.x
15.x
14.x
13.x
12.x
11.x
10.x
9.x
8.x
7.x
6.x
5.x
4.x
0.12.x
0.10.x
    
  
            
              
                
                Options
              
        
              
                
                  
                    View on single page
                  
                  
                    View as JSON
                  
                  Edit on GitHub    
                
              
            
          
        
        
      

      Table of contents
File system

Promise example
Callback example
Synchronous example
Promises API

Class: FileHandle

Event: 'close'
filehandle.appendFile(data[, options])
filehandle.chmod(mode)
filehandle.chown(uid, gid)
filehandle.close()
filehandle.createReadStream([options])
filehandle.createWriteStream([options])
filehandle.datasync()
filehandle.fd
filehandle.read(buffer, offset, length, position)
filehandle.read([options])
filehandle.read(buffer[, options])
filehandle.readableWebStream()
filehandle.readFile(options)
filehandle.readLines([options])
filehandle.readv(buffers[, position])
filehandle.stat([options])
filehandle.sync()
filehandle.truncate(len)
filehandle.utimes(atime, mtime)
filehandle.write(buffer, offset[, length[, position]])
filehandle.write(buffer[, options])
filehandle.write(string[, position[, encoding]])
filehandle.writeFile(data, options)
filehandle.writev(buffers[, position])
filehandle[Symbol.asyncDispose]()


fsPromises.access(path[, mode])
fsPromises.appendFile(path, data[, options])
fsPromises.chmod(path, mode)
fsPromises.chown(path, uid, gid)
fsPromises.copyFile(src, dest[, mode])
fsPromises.cp(src, dest[, options])
fsPromises.glob(pattern[, options])
fsPromises.lchmod(path, mode)
fsPromises.lchown(path, uid, gid)
fsPromises.lutimes(path, atime, mtime)
fsPromises.link(existingPath, newPath)
fsPromises.lstat(path[, options])
fsPromises.mkdir(path[, options])
fsPromises.mkdtemp(prefix[, options])
fsPromises.open(path, flags[, mode])
fsPromises.opendir(path[, options])
fsPromises.readdir(path[, options])
fsPromises.readFile(path[, options])
fsPromises.readlink(path[, options])
fsPromises.realpath(path[, options])
fsPromises.rename(oldPath, newPath)
fsPromises.rmdir(path[, options])
fsPromises.rm(path[, options])
fsPromises.stat(path[, options])
fsPromises.statfs(path[, options])
fsPromises.symlink(target, path[, type])
fsPromises.truncate(path[, len])
fsPromises.unlink(path)
fsPromises.utimes(path, atime, mtime)
fsPromises.watch(filename[, options])
fsPromises.writeFile(file, data[, options])
fsPromises.constants


Callback API

fs.access(path[, mode], callback)
fs.appendFile(path, data[, options], callback)
fs.chmod(path, mode, callback)

File modes


fs.chown(path, uid, gid, callback)
fs.close(fd[, callback])
fs.copyFile(src, dest[, mode], callback)
fs.cp(src, dest[, options], callback)
fs.createReadStream(path[, options])
fs.createWriteStream(path[, options])
fs.exists(path, callback)
fs.fchmod(fd, mode, callback)
fs.fchown(fd, uid, gid, callback)
fs.fdatasync(fd, callback)
fs.fstat(fd[, options], callback)
fs.fsync(fd, callback)
fs.ftruncate(fd[, len], callback)
fs.futimes(fd, atime, mtime, callback)
fs.glob(pattern[, options], callback)
fs.lchmod(path, mode, callback)
fs.lchown(path, uid, gid, callback)
fs.lutimes(path, atime, mtime, callback)
fs.link(existingPath, newPath, callback)
fs.lstat(path[, options], callback)
fs.mkdir(path[, options], callback)
fs.mkdtemp(prefix[, options], callback)
fs.open(path[, flags[, mode]], callback)
fs.openAsBlob(path[, options])
fs.opendir(path[, options], callback)
fs.read(fd, buffer, offset, length, position, callback)
fs.read(fd[, options], callback)
fs.read(fd, buffer[, options], callback)
fs.readdir(path[, options], callback)
fs.readFile(path[, options], callback)

File descriptors
Performance Considerations


fs.readlink(path[, options], callback)
fs.readv(fd, buffers[, position], callback)
fs.realpath(path[, options], callback)
fs.realpath.native(path[, options], callback)
fs.rename(oldPath, newPath, callback)
fs.rmdir(path[, options], callback)
fs.rm(path[, options], callback)
fs.stat(path[, options], callback)
fs.statfs(path[, options], callback)
fs.symlink(target, path[, type], callback)
fs.truncate(path[, len], callback)
fs.unlink(path, callback)
fs.unwatchFile(filename[, listener])
fs.utimes(path, atime, mtime, callback)
fs.watch(filename[, options][, listener])

Caveats

Availability
Inodes
Filename argument




fs.watchFile(filename[, options], listener)
fs.write(fd, buffer, offset[, length[, position]], callback)
fs.write(fd, buffer[, options], callback)
fs.write(fd, string[, position[, encoding]], callback)
fs.writeFile(file, data[, options], callback)

Using fs.writeFile() with file descriptors


fs.writev(fd, buffers[, position], callback)


Synchronous API

fs.accessSync(path[, mode])
fs.appendFileSync(path, data[, options])
fs.chmodSync(path, mode)
fs.chownSync(path, uid, gid)
fs.closeSync(fd)
fs.copyFileSync(src, dest[, mode])
fs.cpSync(src, dest[, options])
fs.existsSync(path)
fs.fchmodSync(fd, mode)
fs.fchownSync(fd, uid, gid)
fs.fdatasyncSync(fd)
fs.fstatSync(fd[, options])
fs.fsyncSync(fd)
fs.ftruncateSync(fd[, len])
fs.futimesSync(fd, atime, mtime)
fs.globSync(pattern[, options])
fs.lchmodSync(path, mode)
fs.lchownSync(path, uid, gid)
fs.lutimesSync(path, atime, mtime)
fs.linkSync(existingPath, newPath)
fs.lstatSync(path[, options])
fs.mkdirSync(path[, options])
fs.mkdtempSync(prefix[, options])
fs.opendirSync(path[, options])
fs.openSync(path[, flags[, mode]])
fs.readdirSync(path[, options])
fs.readFileSync(path[, options])
fs.readlinkSync(path[, options])
fs.readSync(fd, buffer, offset, length[, position])
fs.readSync(fd, buffer[, options])
fs.readvSync(fd, buffers[, position])
fs.realpathSync(path[, options])
fs.realpathSync.native(path[, options])
fs.renameSync(oldPath, newPath)
fs.rmdirSync(path[, options])
fs.rmSync(path[, options])
fs.statSync(path[, options])
fs.statfsSync(path[, options])
fs.symlinkSync(target, path[, type])
fs.truncateSync(path[, len])
fs.unlinkSync(path)
fs.utimesSync(path, atime, mtime)
fs.writeFileSync(file, data[, options])
fs.writeSync(fd, buffer, offset[, length[, position]])
fs.writeSync(fd, buffer[, options])
fs.writeSync(fd, string[, position[, encoding]])
fs.writevSync(fd, buffers[, position])


Common Objects

Class: fs.Dir

dir.close()
dir.close(callback)
dir.closeSync()
dir.path
dir.read()
dir.read(callback)
dir.readSync()
dir[Symbol.asyncIterator]()


Class: fs.Dirent

dirent.isBlockDevice()
dirent.isCharacterDevice()
dirent.isDirectory()
dirent.isFIFO()
dirent.isFile()
dirent.isSocket()
dirent.isSymbolicLink()
dirent.name
dirent.parentPath


Class: fs.FSWatcher

Event: 'change'
Event: 'close'
Event: 'error'
watcher.close()
watcher.ref()
watcher.unref()


Class: fs.StatWatcher

watcher.ref()
watcher.unref()


Class: fs.ReadStream

Event: 'close'
Event: 'open'
Event: 'ready'
readStream.bytesRead
readStream.path
readStream.pending


Class: fs.Stats

stats.isBlockDevice()
stats.isCharacterDevice()
stats.isDirectory()
stats.isFIFO()
stats.isFile()
stats.isSocket()
stats.isSymbolicLink()
stats.dev
stats.ino
stats.mode
stats.nlink
stats.uid
stats.gid
stats.rdev
stats.size
stats.blksize
stats.blocks
stats.atimeMs
stats.mtimeMs
stats.ctimeMs
stats.birthtimeMs
stats.atimeNs
stats.mtimeNs
stats.ctimeNs
stats.birthtimeNs
stats.atime
stats.mtime
stats.ctime
stats.birthtime
Stat time values


Class: fs.StatFs

statfs.bavail
statfs.bfree
statfs.blocks
statfs.bsize
statfs.ffree
statfs.files
statfs.type


Class: fs.WriteStream

Event: 'close'
Event: 'open'
Event: 'ready'
writeStream.bytesWritten
writeStream.close([callback])
writeStream.path
writeStream.pending


fs.constants

FS constants

File access constants
File copy constants
File open constants
File type constants
File mode constants






Notes

Ordering of callback and promise-based operations
File paths

String paths
File URL paths

Platform-specific considerations


Buffer paths
Per-drive working directories on Windows


File descriptors
Threadpool usage
File system flags






      
        File system#

Stability: 2 - Stable

Source Code: lib/fs.js
The node:fs module enables interacting with the file system in a
way modeled on standard POSIX functions.
To use the promise-based APIs:

import * as fs from 'node:fs/promises';const fs = require('node:fs/promises');copy
To use the callback and sync APIs:

import * as fs from 'node:fs';const fs = require('node:fs');copy
All file system operations have synchronous, callback, and promise-based
forms, and are accessible using both CommonJS syntax and ES6 Modules (ESM).
Promise example#
Promise-based operations return a promise that is fulfilled when the
asynchronous operation is complete.

import { unlink } from 'node:fs/promises';

try {
  await unlink('/tmp/hello');
  console.log('successfully deleted /tmp/hello');
} catch (error) {
  console.error('there was an error:', error.message);
}const { unlink } = require('node:fs/promises');

(async function(path) {
  try {
    await unlink(path);
    console.log(`successfully deleted ${path}`);
  } catch (error) {
    console.error('there was an error:', error.message);
  }
})('/tmp/hello');copy
Callback example#
The callback form takes a completion callback function as its last
argument and invokes the operation asynchronously. The arguments passed to
the completion callback depend on the method, but the first argument is always
reserved for an exception. If the operation is completed successfully, then
the first argument is null or undefined.

import { unlink } from 'node:fs';

unlink('/tmp/hello', (err) => {
  if (err) throw err;
  console.log('successfully deleted /tmp/hello');
});const { unlink } = require('node:fs');

unlink('/tmp/hello', (err) => {
  if (err) throw err;
  console.log('successfully deleted /tmp/hello');
});copy
The callback-based versions of the node:fs module APIs are preferable over
the use of the promise APIs when maximal performance (both in terms of
execution time and memory allocation) is required.
Synchronous example#
The synchronous APIs block the Node.js event loop and further JavaScript
execution until the operation is complete. Exceptions are thrown immediately
and can be handled using try…catch, or can be allowed to bubble up.

import { unlinkSync } from 'node:fs';

try {
  unlinkSync('/tmp/hello');
  console.log('successfully deleted /tmp/hello');
} catch (err) {
  // handle the error
}const { unlinkSync } = require('node:fs');

try {
  unlinkSync('/tmp/hello');
  console.log('successfully deleted /tmp/hello');
} catch (err) {
  // handle the error
}copy
Promises API#

History

VersionChanges
v14.0.0
Exposed as require('fs/promises').
v11.14.0, v10.17.0
This API is no longer experimental.
v10.1.0
The API is accessible via require('fs').promises only.
v10.0.0
Added in: v10.0.0



The fs/promises API provides asynchronous file system methods that return
promises.
The promise APIs use the underlying Node.js threadpool to perform file
system operations off the event loop thread. These operations are not
synchronized or threadsafe. Care must be taken when performing multiple
concurrent modifications on the same file or data corruption may occur.

Class: FileHandle#

Added in: v10.0.0

A <FileHandle> object is an object wrapper for a numeric file descriptor.
Instances of the <FileHandle> object are created by the fsPromises.open()
method.
All <FileHandle> objects are <EventEmitter>s.
If a <FileHandle> is not closed using the filehandle.close() method, it will
try to automatically close the file descriptor and emit a process warning,
helping to prevent memory leaks. Please do not rely on this behavior because
it can be unreliable and the file may not be closed. Instead, always explicitly
close <FileHandle>s. Node.js may change this behavior in the future.

Event: 'close'#

Added in: v15.4.0

The 'close' event is emitted when the <FileHandle> has been closed and can no
longer be used.

filehandle.appendFile(data[, options])#

History

VersionChanges
v21.1.0, v20.10.0
The flush option is now supported.
v15.14.0, v14.18.0
The data argument supports AsyncIterable, Iterable, and Stream.
v14.0.0
The data parameter won't coerce unsupported input to strings anymore.
v10.0.0
Added in: v10.0.0




data <string> | <Buffer> | <TypedArray> | <DataView> | <AsyncIterable> | <Iterable> | <Stream>
options <Object> | <string>

encoding <string> | <null> Default: 'utf8'
signal <AbortSignal> | <undefined> allows aborting an in-progress writeFile. Default: undefined


Returns: <Promise> Fulfills with undefined upon success.

Alias of filehandle.writeFile().
When operating on file handles, the mode cannot be changed from what it was set
to with fsPromises.open(). Therefore, this is equivalent to
filehandle.writeFile().

filehandle.chmod(mode)#

Added in: v10.0.0


mode <integer> the file mode bit mask.
Returns: <Promise> Fulfills with undefined upon success.

Modifies the permissions on the file. See chmod(2).

filehandle.chown(uid, gid)#

Added in: v10.0.0


uid <integer> The file's new owner's user id.
gid <integer> The file's new group's group id.
Returns: <Promise> Fulfills with undefined upon success.

Changes the ownership of the file. A wrapper for chown(2).

filehandle.close()#

Added in: v10.0.0


Returns: <Promise> Fulfills with undefined upon success.

Closes the file handle after waiting for any pending operation on the handle to
complete.
import { open } from 'node:fs/promises';

let filehandle;
try {
  filehandle = await open('thefile.txt', 'r');
} finally {
  await filehandle?.close();
} copy

filehandle.createReadStream([options])#

Added in: v16.11.0


options <Object>

encoding <string> Default: null
autoClose <boolean> Default: true
emitClose <boolean> Default: true
start <integer>
end <integer> Default: Infinity
highWaterMark <integer> Default: 64 * 1024
signal <AbortSignal> | <undefined> Default: undefined


Returns: <fs.ReadStream>

options can include start and end values to read a range of bytes from
the file instead of the entire file. Both start and end are inclusive and
start counting at 0, allowed values are in the
[0, Number.MAX_SAFE_INTEGER] range. If start is
omitted or undefined, filehandle.createReadStream() reads sequentially from
the current file position. The encoding can be any one of those accepted by
<Buffer>.
If the FileHandle points to a character device that only supports blocking
reads (such as keyboard or sound card), read operations do not finish until data
is available. This can prevent the process from exiting and the stream from
closing naturally.
By default, the stream will emit a 'close' event after it has been
destroyed.  Set the emitClose option to false to change this behavior.
import { open } from 'node:fs/promises';

const fd = await open('/dev/input/event0');
// Create a stream from some character device.
const stream = fd.createReadStream();
setTimeout(() => {
  stream.close(); // This may not close the stream.
  // Artificially marking end-of-stream, as if the underlying resource had
  // indicated end-of-file by itself, allows the stream to close.
  // This does not cancel pending read operations, and if there is such an
  // operation, the process may still not be able to exit successfully
  // until it finishes.
  stream.push(null);
  stream.read(0);
}, 100); copy
If autoClose is false, then the file descriptor won't be closed, even if
there's an error. It is the application's responsibility to close it and make
sure there's no file descriptor leak. If autoClose is set to true (default
behavior), on 'error' or 'end' the file descriptor will be closed
automatically.
An example to read the last 10 bytes of a file which is 100 bytes long:
import { open } from 'node:fs/promises';

const fd = await open('sample.txt');
fd.createReadStream({ start: 90, end: 99 }); copy

filehandle.createWriteStream([options])#

History

VersionChanges
v21.0.0, v20.10.0
The flush option is now supported.
v16.11.0
Added in: v16.11.0




options <Object>

encoding <string> Default: 'utf8'
autoClose <boolean> Default: true
emitClose <boolean> Default: true
start <integer>
highWaterMark <number> Default: 16384
flush <boolean> If true, the underlying file descriptor is flushed
prior to closing it. Default: false.


Returns: <fs.WriteStream>

options may also include a start option to allow writing data at some
position past the beginning of the file, allowed values are in the
[0, Number.MAX_SAFE_INTEGER] range. Modifying a file rather than
replacing it may require the flags open option to be set to r+ rather than
the default r. The encoding can be any one of those accepted by <Buffer>.
If autoClose is set to true (default behavior) on 'error' or 'finish'
the file descriptor will be closed automatically. If autoClose is false,
then the file descriptor won't be closed, even if there's an error.
It is the application's responsibility to close it and make sure there's no
file descriptor leak.
By default, the stream will emit a 'close' event after it has been
destroyed.  Set the emitClose option to false to change this behavior.

filehandle.datasync()#

Added in: v10.0.0


Returns: <Promise> Fulfills with undefined upon success.

Forces all currently queued I/O operations associated with the file to the
operating system's synchronized I/O completion state. Refer to the POSIX
fdatasync(2) documentation for details.
Unlike filehandle.sync this method does not flush modified metadata.

filehandle.fd#

Added in: v10.0.0


<number> The numeric file descriptor managed by the <FileHandle> object.


filehandle.read(buffer, offset, length, position)#

History

VersionChanges
v21.0.0
Accepts bigint values as position.
v10.0.0
Added in: v10.0.0




buffer <Buffer> | <TypedArray> | <DataView> A buffer that will be filled with the
file data read.
offset <integer> The location in the buffer at which to start filling.
Default: 0
length <integer> The number of bytes to read. Default:
buffer.byteLength - offset
position <integer> | <bigint> | <null> The location where to begin reading data
from the file. If null or -1, data will be read from the current file
position, and the position will be updated. If position is a non-negative
integer, the current file position will remain unchanged.
Default:: null
Returns: <Promise> Fulfills upon success with an object with two properties:

bytesRead <integer> The number of bytes read
buffer <Buffer> | <TypedArray> | <DataView> A reference to the passed in buffer
argument.



Reads data from the file and stores that in the given buffer.
If the file is not modified concurrently, the end-of-file is reached when the
number of bytes read is zero.

filehandle.read([options])#

History

VersionChanges
v21.0.0
Accepts bigint values as position.
v13.11.0, v12.17.0
Added in: v13.11.0, v12.17.0




options <Object>

buffer <Buffer> | <TypedArray> | <DataView> A buffer that will be filled with the
file data read. Default: Buffer.alloc(16384)
offset <integer> The location in the buffer at which to start filling.
Default: 0
length <integer> The number of bytes to read. Default:
buffer.byteLength - offset
position <integer> | <bigint> | <null> The location where to begin reading data
from the file. If null or -1, data will be read from the current file
position, and the position will be updated. If position is a non-negative
integer, the current file position will remain unchanged.
Default:: null


Returns: <Promise> Fulfills upon success with an object with two properties:

bytesRead <integer> The number of bytes read
buffer <Buffer> | <TypedArray> | <DataView> A reference to the passed in buffer
argument.



Reads data from the file and stores that in the given buffer.
If the file is not modified concurrently, the end-of-file is reached when the
number of bytes read is zero.

filehandle.read(buffer[, options])#

History

VersionChanges
v21.0.0
Accepts bigint values as position.
v18.2.0, v16.17.0
Added in: v18.2.0, v16.17.0




buffer <Buffer> | <TypedArray> | <DataView> A buffer that will be filled with the
file data read.
options <Object>

offset <integer> The location in the buffer at which to start filling.
Default: 0
length <integer> The number of bytes to read. Default:
buffer.byteLength - offset
position <integer> | <bigint> | <null> The location where to begin reading data
from the file. If null or -1, data will be read from the current file
position, and the position will be updated. If position is a non-negative
integer, the current file position will remain unchanged.
Default:: null


Returns: <Promise> Fulfills upon success with an object with two properties:

bytesRead <integer> The number of bytes read
buffer <Buffer> | <TypedArray> | <DataView> A reference to the passed in buffer
argument.



Reads data from the file and stores that in the given buffer.
If the file is not modified concurrently, the end-of-file is reached when the
number of bytes read is zero.

filehandle.readableWebStream()#

History

VersionChanges
v24.0.0
Marking the API stable.
v23.8.0, v22.15.0
Removed option to create a 'bytes' stream. Streams are now always 'bytes' streams.
v20.0.0, v18.17.0
Added option to create a 'bytes' stream.
v17.0.0
Added in: v17.0.0




Returns: <ReadableStream>

Returns a byte-oriented ReadableStream that may be used to read the file's
contents.
An error will be thrown if this method is called more than once or is called
after the FileHandle is closed or closing.

import {
  open,
} from 'node:fs/promises';

const file = await open('./some/file/to/read');

for await (const chunk of file.readableWebStream())
  console.log(chunk);

await file.close();const {
  open,
} = require('node:fs/promises');

(async () => {
  const file = await open('./some/file/to/read');

  for await (const chunk of file.readableWebStream())
    console.log(chunk);

  await file.close();
})();copy
While the ReadableStream will read the file to completion, it will not
close the FileHandle automatically. User code must still call the
fileHandle.close() method.

filehandle.readFile(options)#

Added in: v10.0.0


options <Object> | <string>

encoding <string> | <null> Default: null
signal <AbortSignal> allows aborting an in-progress readFile


Returns: <Promise> Fulfills upon a successful read with the contents of the
file. If no encoding is specified (using options.encoding), the data is
returned as a <Buffer> object. Otherwise, the data will be a string.

Asynchronously reads the entire contents of a file.
If options is a string, then it specifies the encoding.
The <FileHandle> has to support reading.
If one or more filehandle.read() calls are made on a file handle and then a
filehandle.readFile() call is made, the data will be read from the current
position till the end of the file. It doesn't always read from the beginning
of the file.

filehandle.readLines([options])#

Added in: v18.11.0


options <Object>

encoding <string> Default: null
autoClose <boolean> Default: true
emitClose <boolean> Default: true
start <integer>
end <integer> Default: Infinity
highWaterMark <integer> Default: 64 * 1024


Returns: <readline.InterfaceConstructor>

Convenience method to create a readline interface and stream over the file.
See filehandle.createReadStream() for the options.

import { open } from 'node:fs/promises';

const file = await open('./some/file/to/read');

for await (const line of file.readLines()) {
  console.log(line);
}const { open } = require('node:fs/promises');

(async () => {
  const file = await open('./some/file/to/read');

  for await (const line of file.readLines()) {
    console.log(line);
  }
})();copy

filehandle.readv(buffers[, position])#

Added in: v13.13.0, v12.17.0


buffers <Buffer[]> | <TypedArray[]> | <DataView[]>
position <integer> | <null> The offset from the beginning of the file where
the data should be read from. If position is not a number, the data will
be read from the current position. Default: null
Returns: <Promise> Fulfills upon success an object containing two properties:

bytesRead <integer> the number of bytes read
buffers <Buffer[]> | <TypedArray[]> | <DataView[]> property containing
a reference to the buffers input.



Read from a file and write to an array of <ArrayBufferView>s

filehandle.stat([options])#

History

VersionChanges
v10.5.0
Accepts an additional options object to specify whether the numeric values returned should be bigint.
v10.0.0
Added in: v10.0.0




options <Object>

bigint <boolean> Whether the numeric values in the returned
<fs.Stats> object should be bigint. Default: false.


Returns: <Promise> Fulfills with an <fs.Stats> for the file.


filehandle.sync()#

Added in: v10.0.0


Returns: <Promise> Fulfills with undefined upon success.

Request that all data for the open file descriptor is flushed to the storage
device. The specific implementation is operating system and device specific.
Refer to the POSIX fsync(2) documentation for more detail.

filehandle.truncate(len)#

Added in: v10.0.0


len <integer> Default: 0
Returns: <Promise> Fulfills with undefined upon success.

Truncates the file.
If the file was larger than len bytes, only the first len bytes will be
retained in the file.
The following example retains only the first four bytes of the file:
import { open } from 'node:fs/promises';

let filehandle = null;
try {
  filehandle = await open('temp.txt', 'r+');
  await filehandle.truncate(4);
} finally {
  await filehandle?.close();
} copy
If the file previously was shorter than len bytes, it is extended, and the
extended part is filled with null bytes ('\0'):
If len is negative then 0 will be used.

filehandle.utimes(atime, mtime)#

Added in: v10.0.0


atime <number> | <string> | <Date>
mtime <number> | <string> | <Date>
Returns: <Promise>

Change the file system timestamps of the object referenced by the <FileHandle>
then fulfills the promise with no arguments upon success.

filehandle.write(buffer, offset[, length[, position]])#

History

VersionChanges
v14.0.0
The buffer parameter won't coerce unsupported input to buffers anymore.
v10.0.0
Added in: v10.0.0




buffer <Buffer> | <TypedArray> | <DataView>
offset <integer> The start position from within buffer where the data
to write begins.
length <integer> The number of bytes from buffer to write. Default:
buffer.byteLength - offset
position <integer> | <null> The offset from the beginning of the file where the
data from buffer should be written. If position is not a number,
the data will be written at the current position. See the POSIX pwrite(2)
documentation for more detail. Default: null
Returns: <Promise>

Write buffer to the file.
The promise is fulfilled with an object containing two properties:

bytesWritten <integer> the number of bytes written
buffer <Buffer> | <TypedArray> | <DataView> a reference to the
buffer written.

It is unsafe to use filehandle.write() multiple times on the same file
without waiting for the promise to be fulfilled (or rejected). For this
scenario, use filehandle.createWriteStream().
On Linux, positional writes do not work when the file is opened in append mode.
The kernel ignores the position argument and always appends the data to
the end of the file.

filehandle.write(buffer[, options])#

Added in: v18.3.0, v16.17.0


buffer <Buffer> | <TypedArray> | <DataView>
options <Object>

offset <integer> Default: 0
length <integer> Default: buffer.byteLength - offset
position <integer> | <null> Default: null


Returns: <Promise>

Write buffer to the file.
Similar to the above filehandle.write function, this version takes an
optional options object. If no options object is specified, it will
default with the above values.

filehandle.write(string[, position[, encoding]])#

History

VersionChanges
v14.0.0
The string parameter won't coerce unsupported input to strings anymore.
v10.0.0
Added in: v10.0.0




string <string>
position <integer> | <null> The offset from the beginning of the file where the
data from string should be written. If position is not a number the
data will be written at the current position. See the POSIX pwrite(2)
documentation for more detail. Default: null
encoding <string> The expected string encoding. Default: 'utf8'
Returns: <Promise>

Write string to the file. If string is not a string, the promise is
rejected with an error.
The promise is fulfilled with an object containing two properties:

bytesWritten <integer> the number of bytes written
buffer <string> a reference to the string written.

It is unsafe to use filehandle.write() multiple times on the same file
without waiting for the promise to be fulfilled (or rejected). For this
scenario, use filehandle.createWriteStream().
On Linux, positional writes do not work when the file is opened in append mode.
The kernel ignores the position argument and always appends the data to
the end of the file.

filehandle.writeFile(data, options)#

History

VersionChanges
v15.14.0, v14.18.0
The data argument supports AsyncIterable, Iterable, and Stream.
v14.0.0
The data parameter won't coerce unsupported input to strings anymore.
v10.0.0
Added in: v10.0.0




data <string> | <Buffer> | <TypedArray> | <DataView> | <AsyncIterable> | <Iterable> | <Stream>
options <Object> | <string>

encoding <string> | <null> The expected character encoding when data is a
string. Default: 'utf8'
signal <AbortSignal> | <undefined> allows aborting an in-progress writeFile. Default: undefined


Returns: <Promise>

Asynchronously writes data to a file, replacing the file if it already exists.
data can be a string, a buffer, an <AsyncIterable>, or an <Iterable> object.
The promise is fulfilled with no arguments upon success.
If options is a string, then it specifies the encoding.
The <FileHandle> has to support writing.
It is unsafe to use filehandle.writeFile() multiple times on the same file
without waiting for the promise to be fulfilled (or rejected).
If one or more filehandle.write() calls are made on a file handle and then a
filehandle.writeFile() call is made, the data will be written from the
current position till the end of the file. It doesn't always write from the
beginning of the file.

filehandle.writev(buffers[, position])#

Added in: v12.9.0


buffers <Buffer[]> | <TypedArray[]> | <DataView[]>
position <integer> | <null> The offset from the beginning of the file where the
data from buffers should be written. If position is not a number,
the data will be written at the current position. Default: null
Returns: <Promise>

Write an array of <ArrayBufferView>s to the file.
The promise is fulfilled with an object containing a two properties:

bytesWritten <integer> the number of bytes written
buffers <Buffer[]> | <TypedArray[]> | <DataView[]> a reference to the buffers
input.

It is unsafe to call writev() multiple times on the same file without waiting
for the promise to be fulfilled (or rejected).
On Linux, positional writes don't work when the file is opened in append mode.
The kernel ignores the position argument and always appends the data to
the end of the file.

filehandle[Symbol.asyncDispose]()#

Added in: v20.4.0, v18.18.0

Stability: 1 - Experimental
An alias for filehandle.close().

fsPromises.access(path[, mode])#

Added in: v10.0.0


path <string> | <Buffer> | <URL>
mode <integer> Default: fs.constants.F_OK
Returns: <Promise> Fulfills with undefined upon success.

Tests a user's permissions for the file or directory specified by path.
The mode argument is an optional integer that specifies the accessibility
checks to be performed. mode should be either the value fs.constants.F_OK
or a mask consisting of the bitwise OR of any of fs.constants.R_OK,
fs.constants.W_OK, and fs.constants.X_OK (e.g.
fs.constants.W_OK | fs.constants.R_OK). Check File access constants for
possible values of mode.
If the accessibility check is successful, the promise is fulfilled with no
value. If any of the accessibility checks fail, the promise is rejected
with an <Error> object. The following example checks if the file
/etc/passwd can be read and written by the current process.
import { access, constants } from 'node:fs/promises';

try {
  await access('/etc/passwd', constants.R_OK | constants.W_OK);
  console.log('can access');
} catch {
  console.error('cannot access');
} copy
Using fsPromises.access() to check for the accessibility of a file before
calling fsPromises.open() is not recommended. Doing so introduces a race
condition, since other processes may change the file's state between the two
calls. Instead, user code should open/read/write the file directly and handle
the error raised if the file is not accessible.

fsPromises.appendFile(path, data[, options])#

History

VersionChanges
v21.1.0, v20.10.0
The flush option is now supported.
v10.0.0
Added in: v10.0.0




path <string> | <Buffer> | <URL> | <FileHandle> filename or <FileHandle>
data <string> | <Buffer>
options <Object> | <string>

encoding <string> | <null> Default: 'utf8'
mode <integer> Default: 0o666
flag <string> See support of file system flags. Default: 'a'.
flush <boolean> If true, the underlying file descriptor is flushed
prior to closing it. Default: false.


Returns: <Promise> Fulfills with undefined upon success.

Asynchronously append data to a file, creating the file if it does not yet
exist. data can be a string or a <Buffer>.
If options is a string, then it specifies the encoding.
The mode option only affects the newly created file. See fs.open()
for more details.
The path may be specified as a <FileHandle> that has been opened
for appending (using fsPromises.open()).

fsPromises.chmod(path, mode)#

Added in: v10.0.0


path <string> | <Buffer> | <URL>
mode <string> | <integer>
Returns: <Promise> Fulfills with undefined upon success.

Changes the permissions of a file.

fsPromises.chown(path, uid, gid)#

Added in: v10.0.0


path <string> | <Buffer> | <URL>
uid <integer>
gid <integer>
Returns: <Promise> Fulfills with undefined upon success.

Changes the ownership of a file.

fsPromises.copyFile(src, dest[, mode])#

History

VersionChanges
v14.0.0
Changed flags argument to mode and imposed stricter type validation.
v10.0.0
Added in: v10.0.0




src <string> | <Buffer> | <URL> source filename to copy
dest <string> | <Buffer> | <URL> destination filename of the copy operation
mode <integer> Optional modifiers that specify the behavior of the copy
operation. It is possible to create a mask consisting of the bitwise OR of
two or more values (e.g.
fs.constants.COPYFILE_EXCL | fs.constants.COPYFILE_FICLONE)
Default: 0.

fs.constants.COPYFILE_EXCL: The copy operation will fail if dest
already exists.
fs.constants.COPYFILE_FICLONE: The copy operation will attempt to create
a copy-on-write reflink. If the platform does not support copy-on-write,
then a fallback copy mechanism is used.
fs.constants.COPYFILE_FICLONE_FORCE: The copy operation will attempt to
create a copy-on-write reflink. If the platform does not support
copy-on-write, then the operation will fail.


Returns: <Promise> Fulfills with undefined upon success.

Asynchronously copies src to dest. By default, dest is overwritten if it
already exists.
No guarantees are made about the atomicity of the copy operation. If an
error occurs after the destination file has been opened for writing, an attempt
will be made to remove the destination.
import { copyFile, constants } from 'node:fs/promises';

try {
  await copyFile('source.txt', 'destination.txt');
  console.log('source.txt was copied to destination.txt');
} catch {
  console.error('The file could not be copied');
}

// By using COPYFILE_EXCL, the operation will fail if destination.txt exists.
try {
  await copyFile('source.txt', 'destination.txt', constants.COPYFILE_EXCL);
  console.log('source.txt was copied to destination.txt');
} catch {
  console.error('The file could not be copied');
} copy

fsPromises.cp(src, dest[, options])#

History

VersionChanges
v22.3.0
This API is no longer experimental.
v20.1.0, v18.17.0
Accept an additional mode option to specify the copy behavior as the mode argument of fs.copyFile().
v17.6.0, v16.15.0
Accepts an additional verbatimSymlinks option to specify whether to perform path resolution for symlinks.
v16.7.0
Added in: v16.7.0




src <string> | <URL> source path to copy.
dest <string> | <URL> destination path to copy to.
options <Object>

dereference <boolean> dereference symlinks. Default: false.
errorOnExist <boolean> when force is false, and the destination
exists, throw an error. Default: false.
filter <Function> Function to filter copied files/directories. Return
true to copy the item, false to ignore it. When ignoring a directory,
all of its contents will be skipped as well. Can also return a Promise
that resolves to true or false Default: undefined.

src <string> source path to copy.
dest <string> destination path to copy to.
Returns: <boolean> | <Promise> A value that is coercible to boolean or
a Promise that fulfils with such value.


force <boolean> overwrite existing file or directory. The copy
operation will ignore errors if you set this to false and the destination
exists. Use the errorOnExist option to change this behavior.
Default: true.
mode <integer> modifiers for copy operation. Default: 0.
See mode flag of fsPromises.copyFile().
preserveTimestamps <boolean> When true timestamps from src will
be preserved. Default: false.
recursive <boolean> copy directories recursively Default: false
verbatimSymlinks <boolean> When true, path resolution for symlinks will
be skipped. Default: false


Returns: <Promise> Fulfills with undefined upon success.

Asynchronously copies the entire directory structure from src to dest,
including subdirectories and files.
When copying a directory to another directory, globs are not supported and
behavior is similar to cp dir1/ dir2/.

fsPromises.glob(pattern[, options])#

History

VersionChanges
v24.0.0
Marking the API stable.
v23.7.0, v22.14.0
Add support for exclude option to accept glob patterns.
v22.2.0
Add support for withFileTypes as an option.
v22.0.0
Added in: v22.0.0




pattern <string> | <string[]>
options <Object>

cwd <string> current working directory. Default: process.cwd()
exclude <Function> | <string[]> Function to filter out files/directories or a
list of glob patterns to be excluded. If a function is provided, return
true to exclude the item, false to include it. Default: undefined.
withFileTypes <boolean> true if the glob should return paths as Dirents,
false otherwise. Default: false.


Returns: <AsyncIterator> An AsyncIterator that yields the paths of files
that match the pattern.


import { glob } from 'node:fs/promises';

for await (const entry of glob('**/*.js'))
  console.log(entry);const { glob } = require('node:fs/promises');

(async () => {
  for await (const entry of glob('**/*.js'))
    console.log(entry);
})();copy

fsPromises.lchmod(path, mode)#

Deprecated since: v10.0.0

Stability: 0 - Deprecated

path <string> | <Buffer> | <URL>
mode <integer>
Returns: <Promise> Fulfills with undefined upon success.

Changes the permissions on a symbolic link.
This method is only implemented on macOS.

fsPromises.lchown(path, uid, gid)#

History

VersionChanges
v10.6.0
This API is no longer deprecated.
v10.0.0
Added in: v10.0.0




path <string> | <Buffer> | <URL>
uid <integer>
gid <integer>
Returns: <Promise>  Fulfills with undefined upon success.

Changes the ownership on a symbolic link.

fsPromises.lutimes(path, atime, mtime)#

Added in: v14.5.0, v12.19.0


path <string> | <Buffer> | <URL>
atime <number> | <string> | <Date>
mtime <number> | <string> | <Date>
Returns: <Promise>  Fulfills with undefined upon success.

Changes the access and modification times of a file in the same way as
fsPromises.utimes(), with the difference that if the path refers to a
symbolic link, then the link is not dereferenced: instead, the timestamps of
the symbolic link itself are changed.

fsPromises.link(existingPath, newPath)#

Added in: v10.0.0


existingPath <string> | <Buffer> | <URL>
newPath <string> | <Buffer> | <URL>
Returns: <Promise>  Fulfills with undefined upon success.

Creates a new link from the existingPath to the newPath. See the POSIX
link(2) documentation for more detail.

fsPromises.lstat(path[, options])#

History

VersionChanges
v10.5.0
Accepts an additional options object to specify whether the numeric values returned should be bigint.
v10.0.0
Added in: v10.0.0




path <string> | <Buffer> | <URL>
options <Object>

bigint <boolean> Whether the numeric values in the returned
<fs.Stats> object should be bigint. Default: false.


Returns: <Promise>  Fulfills with the <fs.Stats> object for the given
symbolic link path.

Equivalent to fsPromises.stat() unless path refers to a symbolic link,
in which case the link itself is stat-ed, not the file that it refers to.
Refer to the POSIX lstat(2) document for more detail.

fsPromises.mkdir(path[, options])#

Added in: v10.0.0


path <string> | <Buffer> | <URL>
options <Object> | <integer>

recursive <boolean> Default: false
mode <string> | <integer> Not supported on Windows. Default: 0o777.


Returns: <Promise> Upon success, fulfills with undefined if recursive
is false, or the first directory path created if recursive is true.

Asynchronously creates a directory.
The optional options argument can be an integer specifying mode (permission
and sticky bits), or an object with a mode property and a recursive
property indicating whether parent directories should be created. Calling
fsPromises.mkdir() when path is a directory that exists results in a
rejection only when recursive is false.

import { mkdir } from 'node:fs/promises';

try {
  const projectFolder = new URL('./test/project/', import.meta.url);
  const createDir = await mkdir(projectFolder, { recursive: true });

  console.log(`created ${createDir}`);
} catch (err) {
  console.error(err.message);
}const { mkdir } = require('node:fs/promises');
const { join } = require('node:path');

async function makeDirectory() {
  const projectFolder = join(__dirname, 'test', 'project');
  const dirCreation = await mkdir(projectFolder, { recursive: true });

  console.log(dirCreation);
  return dirCreation;
}

makeDirectory().catch(console.error);copy

fsPromises.mkdtemp(prefix[, options])#

History

VersionChanges
v20.6.0, v18.19.0
The prefix parameter now accepts buffers and URL.
v16.5.0, v14.18.0
The prefix parameter now accepts an empty string.
v10.0.0
Added in: v10.0.0




prefix <string> | <Buffer> | <URL>
options <string> | <Object>

encoding <string> Default: 'utf8'


Returns: <Promise>  Fulfills with a string containing the file system path
of the newly created temporary directory.

Creates a unique temporary directory. A unique directory name is generated by
appending six random characters to the end of the provided prefix. Due to
platform inconsistencies, avoid trailing X characters in prefix. Some
platforms, notably the BSDs, can return more than six random characters, and
replace trailing X characters in prefix with random characters.
The optional options argument can be a string specifying an encoding, or an
object with an encoding property specifying the character encoding to use.
import { mkdtemp } from 'node:fs/promises';
import { join } from 'node:path';
import { tmpdir } from 'node:os';

try {
  await mkdtemp(join(tmpdir(), 'foo-'));
} catch (err) {
  console.error(err);
} copy
The fsPromises.mkdtemp() method will append the six randomly selected
characters directly to the prefix string. For instance, given a directory
/tmp, if the intention is to create a temporary directory within /tmp, the
prefix must end with a trailing platform-specific path separator
(require('node:path').sep).

fsPromises.open(path, flags[, mode])#

History

VersionChanges
v11.1.0
The flags argument is now optional and defaults to 'r'.
v10.0.0
Added in: v10.0.0




path <string> | <Buffer> | <URL>
flags <string> | <number> See support of file system flags.
Default: 'r'.
mode <string> | <integer> Sets the file mode (permission and sticky bits)
if the file is created. Default: 0o666 (readable and writable)
Returns: <Promise> Fulfills with a <FileHandle> object.

Opens a <FileHandle>.
Refer to the POSIX open(2) documentation for more detail.
Some characters (< > : " / \ | ? *) are reserved under Windows as documented
by Naming Files, Paths, and Namespaces. Under NTFS, if the filename contains
a colon, Node.js will open a file system stream, as described by
this MSDN page.

fsPromises.opendir(path[, options])#

History

VersionChanges
v20.1.0, v18.17.0
Added recursive option.
v13.1.0, v12.16.0
The bufferSize option was introduced.
v12.12.0
Added in: v12.12.0




path <string> | <Buffer> | <URL>
options <Object>

encoding <string> | <null> Default: 'utf8'
bufferSize <number> Number of directory entries that are buffered
internally when reading from the directory. Higher values lead to better
performance but higher memory usage. Default: 32
recursive <boolean> Resolved Dir will be an <AsyncIterable>
containing all sub files and directories. Default: false


Returns: <Promise>  Fulfills with an <fs.Dir>.

Asynchronously open a directory for iterative scanning. See the POSIX
opendir(3) documentation for more detail.
Creates an <fs.Dir>, which contains all further functions for reading from
and cleaning up the directory.
The encoding option sets the encoding for the path while opening the
directory and subsequent read operations.
Example using async iteration:
import { opendir } from 'node:fs/promises';

try {
  const dir = await opendir('./');
  for await (const dirent of dir)
    console.log(dirent.name);
} catch (err) {
  console.error(err);
} copy
When using the async iterator, the <fs.Dir> object will be automatically
closed after the iterator exits.

fsPromises.readdir(path[, options])#

History

VersionChanges
v20.1.0, v18.17.0
Added recursive option.
v10.11.0
New option withFileTypes was added.
v10.0.0
Added in: v10.0.0




path <string> | <Buffer> | <URL>
options <string> | <Object>

encoding <string> Default: 'utf8'
withFileTypes <boolean> Default: false
recursive <boolean> If true, reads the contents of a directory
recursively. In recursive mode, it will list all files, sub files, and
directories. Default: false.


Returns: <Promise>  Fulfills with an array of the names of the files in
the directory excluding '.' and '..'.

Reads the contents of a directory.
The optional options argument can be a string specifying an encoding, or an
object with an encoding property specifying the character encoding to use for
the filenames. If the encoding is set to 'buffer', the filenames returned
will be passed as <Buffer> objects.
If options.withFileTypes is set to true, the returned array will contain
<fs.Dirent> objects.
import { readdir } from 'node:fs/promises';

try {
  const files = await readdir(path);
  for (const file of files)
    console.log(file);
} catch (err) {
  console.error(err);
} copy

fsPromises.readFile(path[, options])#

History

VersionChanges
v15.2.0, v14.17.0
The options argument may include an AbortSignal to abort an ongoing readFile request.
v10.0.0
Added in: v10.0.0




path <string> | <Buffer> | <URL> | <FileHandle> filename or FileHandle
options <Object> | <string>

encoding <string> | <null> Default: null
flag <string> See support of file system flags. Default: 'r'.
signal <AbortSignal> allows aborting an in-progress readFile


Returns: <Promise>  Fulfills with the contents of the file.

Asynchronously reads the entire contents of a file.
If no encoding is specified (using options.encoding), the data is returned
as a <Buffer> object. Otherwise, the data will be a string.
If options is a string, then it specifies the encoding.
When the path is a directory, the behavior of fsPromises.readFile() is
platform-specific. On macOS, Linux, and Windows, the promise will be rejected
with an error. On FreeBSD, a representation of the directory's contents will be
returned.
An example of reading a package.json file located in the same directory of the
running code:

import { readFile } from 'node:fs/promises';
try {
  const filePath = new URL('./package.json', import.meta.url);
  const contents = await readFile(filePath, { encoding: 'utf8' });
  console.log(contents);
} catch (err) {
  console.error(err.message);
}const { readFile } = require('node:fs/promises');
const { resolve } = require('node:path');
async function logFile() {
  try {
    const filePath = resolve('./package.json');
    const contents = await readFile(filePath, { encoding: 'utf8' });
    console.log(contents);
  } catch (err) {
    console.error(err.message);
  }
}
logFile();copy
It is possible to abort an ongoing readFile using an <AbortSignal>. If a
request is aborted the promise returned is rejected with an AbortError:
import { readFile } from 'node:fs/promises';

try {
  const controller = new AbortController();
  const { signal } = controller;
  const promise = readFile(fileName, { signal });

  // Abort the request before the promise settles.
  controller.abort();

  await promise;
} catch (err) {
  // When a request is aborted - err is an AbortError
  console.error(err);
} copy
Aborting an ongoing request does not abort individual operating
system requests but rather the internal buffering fs.readFile performs.
Any specified <FileHandle> has to support reading.

fsPromises.readlink(path[, options])#

Added in: v10.0.0


path <string> | <Buffer> | <URL>
options <string> | <Object>

encoding <string> Default: 'utf8'


Returns: <Promise> Fulfills with the linkString upon success.

Reads the contents of the symbolic link referred to by path. See the POSIX
readlink(2) documentation for more detail. The promise is fulfilled with the
linkString upon success.
The optional options argument can be a string specifying an encoding, or an
object with an encoding property specifying the character encoding to use for
the link path returned. If the encoding is set to 'buffer', the link path
returned will be passed as a <Buffer> object.

fsPromises.realpath(path[, options])#

Added in: v10.0.0


path <string> | <Buffer> | <URL>
options <string> | <Object>

encoding <string> Default: 'utf8'


Returns: <Promise>  Fulfills with the resolved path upon success.

Determines the actual location of path using the same semantics as the
fs.realpath.native() function.
Only paths that can be converted to UTF8 strings are supported.
The optional options argument can be a string specifying an encoding, or an
object with an encoding property specifying the character encoding to use for
the path. If the encoding is set to 'buffer', the path returned will be
passed as a <Buffer> object.
On Linux, when Node.js is linked against musl libc, the procfs file system must
be mounted on /proc in order for this function to work. Glibc does not have
this restriction.

fsPromises.rename(oldPath, newPath)#

Added in: v10.0.0


oldPath <string> | <Buffer> | <URL>
newPath <string> | <Buffer> | <URL>
Returns: <Promise> Fulfills with undefined upon success.

Renames oldPath to newPath.

fsPromises.rmdir(path[, options])#

History

VersionChanges
v16.0.0
Using fsPromises.rmdir(path, { recursive: true }) on a path that is a file is no longer permitted and results in an ENOENT error on Windows and an ENOTDIR error on POSIX.
v16.0.0
Using fsPromises.rmdir(path, { recursive: true }) on a path that does not exist is no longer permitted and results in a ENOENT error.
v16.0.0
The recursive option is deprecated, using it triggers a deprecation warning.
v14.14.0
The recursive option is deprecated, use fsPromises.rm instead.
v13.3.0, v12.16.0
The maxBusyTries option is renamed to maxRetries, and its default is 0. The emfileWait option has been removed, and EMFILE errors use the same retry logic as other errors. The retryDelay option is now supported. ENFILE errors are now retried.
v12.10.0
The recursive, maxBusyTries, and emfileWait options are now supported.
v10.0.0
Added in: v10.0.0




path <string> | <Buffer> | <URL>
options <Object>

maxRetries <integer> If an EBUSY, EMFILE, ENFILE, ENOTEMPTY, or
EPERM error is encountered, Node.js retries the operation with a linear
backoff wait of retryDelay milliseconds longer on each try. This option
represents the number of retries. This option is ignored if the recursive
option is not true. Default: 0.
recursive <boolean> If true, perform a recursive directory removal. In
recursive mode, operations are retried on failure. Default: false.
Deprecated.
retryDelay <integer> The amount of time in milliseconds to wait between
retries. This option is ignored if the recursive option is not true.
Default: 100.


Returns: <Promise> Fulfills with undefined upon success.

Removes the directory identified by path.
Using fsPromises.rmdir() on a file (not a directory) results in the
promise being rejected with an ENOENT error on Windows and an ENOTDIR
error on POSIX.
To get a behavior similar to the rm -rf Unix command, use
fsPromises.rm() with options { recursive: true, force: true }.

fsPromises.rm(path[, options])#

Added in: v14.14.0


path <string> | <Buffer> | <URL>
options <Object>

force <boolean> When true, exceptions will be ignored if path does
not exist. Default: false.
maxRetries <integer> If an EBUSY, EMFILE, ENFILE, ENOTEMPTY, or
EPERM error is encountered, Node.js will retry the operation with a linear
backoff wait of retryDelay milliseconds longer on each try. This option
represents the number of retries. This option is ignored if the recursive
option is not true. Default: 0.
recursive <boolean> If true, perform a recursive directory removal. In
recursive mode operations are retried on failure. Default: false.
retryDelay <integer> The amount of time in milliseconds to wait between
retries. This option is ignored if the recursive option is not true.
Default: 100.


Returns: <Promise> Fulfills with undefined upon success.

Removes files and directories (modeled on the standard POSIX rm utility).

fsPromises.stat(path[, options])#

History

VersionChanges
v10.5.0
Accepts an additional options object to specify whether the numeric values returned should be bigint.
v10.0.0
Added in: v10.0.0




path <string> | <Buffer> | <URL>
options <Object>

bigint <boolean> Whether the numeric values in the returned
<fs.Stats> object should be bigint. Default: false.


Returns: <Promise>  Fulfills with the <fs.Stats> object for the
given path.


fsPromises.statfs(path[, options])#

Added in: v19.6.0, v18.15.0


path <string> | <Buffer> | <URL>
options <Object>

bigint <boolean> Whether the numeric values in the returned
<fs.StatFs> object should be bigint. Default: false.


Returns: <Promise> Fulfills with the <fs.StatFs> object for the
given path.


fsPromises.symlink(target, path[, type])#

History

VersionChanges
v19.0.0
If the type argument is null or omitted, Node.js will autodetect target type and automatically select dir or file.
v10.0.0
Added in: v10.0.0




target <string> | <Buffer> | <URL>
path <string> | <Buffer> | <URL>
type <string> | <null> Default: null
Returns: <Promise> Fulfills with undefined upon success.

Creates a symbolic link.
The type argument is only used on Windows platforms and can be one of 'dir',
'file', or 'junction'. If the type argument is null, Node.js will
autodetect target type and use 'file' or 'dir'. If the target does not
exist, 'file' will be used. Windows junction points require the destination
path to be absolute. When using 'junction', the target argument will
automatically be normalized to absolute path. Junction points on NTFS volumes
can only point to directories.

fsPromises.truncate(path[, len])#

Added in: v10.0.0


path <string> | <Buffer> | <URL>
len <integer> Default: 0
Returns: <Promise> Fulfills with undefined upon success.

Truncates (shortens or extends the length) of the content at path to len
bytes.

fsPromises.unlink(path)#

Added in: v10.0.0


path <string> | <Buffer> | <URL>
Returns: <Promise> Fulfills with undefined upon success.

If path refers to a symbolic link, then the link is removed without affecting
the file or directory to which that link refers. If the path refers to a file
path that is not a symbolic link, the file is deleted. See the POSIX unlink(2)
documentation for more detail.

fsPromises.utimes(path, atime, mtime)#

Added in: v10.0.0


path <string> | <Buffer> | <URL>
atime <number> | <string> | <Date>
mtime <number> | <string> | <Date>
Returns: <Promise> Fulfills with undefined upon success.

Change the file system timestamps of the object referenced by path.
The atime and mtime arguments follow these rules:

Values can be either numbers representing Unix epoch time, Dates, or a
numeric string like '123456789.0'.
If the value can not be converted to a number, or is NaN, Infinity, or
-Infinity, an Error will be thrown.


fsPromises.watch(filename[, options])#

Added in: v15.9.0, v14.18.0


filename <string> | <Buffer> | <URL>
options <string> | <Object>

persistent <boolean> Indicates whether the process should continue to run
as long as files are being watched. Default: true.
recursive <boolean> Indicates whether all subdirectories should be
watched, or only the current directory. This applies when a directory is
specified, and only on supported platforms (See caveats). Default:
false.
encoding <string> Specifies the character encoding to be used for the
filename passed to the listener. Default: 'utf8'.
signal <AbortSignal> An <AbortSignal> used to signal when the watcher
should stop.


Returns: <AsyncIterator> of objects with the properties:

eventType <string> The type of change
filename <string> | <Buffer> | <null> The name of the file changed.



Returns an async iterator that watches for changes on filename, where filename
is either a file or a directory.
const { watch } = require('node:fs/promises');

const ac = new AbortController();
const { signal } = ac;
setTimeout(() => ac.abort(), 10000);

(async () => {
  try {
    const watcher = watch(__filename, { signal });
    for await (const event of watcher)
      console.log(event);
  } catch (err) {
    if (err.name === 'AbortError')
      return;
    throw err;
  }
})(); copy
On most platforms, 'rename' is emitted whenever a filename appears or
disappears in the directory.
All the caveats for fs.watch() also apply to fsPromises.watch().

fsPromises.writeFile(file, data[, options])#

History

VersionChanges
v21.0.0, v20.10.0
The flush option is now supported.
v15.14.0, v14.18.0
The data argument supports AsyncIterable, Iterable, and Stream.
v15.2.0, v14.17.0
The options argument may include an AbortSignal to abort an ongoing writeFile request.
v14.0.0
The data parameter won't coerce unsupported input to strings anymore.
v10.0.0
Added in: v10.0.0




file <string> | <Buffer> | <URL> | <FileHandle> filename or FileHandle
data <string> | <Buffer> | <TypedArray> | <DataView> | <AsyncIterable> | <Iterable> | <Stream>
options <Object> | <string>

encoding <string> | <null> Default: 'utf8'
mode <integer> Default: 0o666
flag <string> See support of file system flags. Default: 'w'.
flush <boolean> If all data is successfully written to the file, and
flush is true, filehandle.sync() is used to flush the data.
Default: false.
signal <AbortSignal> allows aborting an in-progress writeFile


Returns: <Promise> Fulfills with undefined upon success.

Asynchronously writes data to a file, replacing the file if it already exists.
data can be a string, a buffer, an <AsyncIterable>, or an <Iterable> object.
The encoding option is ignored if data is a buffer.
If options is a string, then it specifies the encoding.
The mode option only affects the newly created file. See fs.open()
for more details.
Any specified <FileHandle> has to support writing.
It is unsafe to use fsPromises.writeFile() multiple times on the same file
without waiting for the promise to be settled.
Similarly to fsPromises.readFile - fsPromises.writeFile is a convenience
method that performs multiple write calls internally to write the buffer
passed to it. For performance sensitive code consider using
fs.createWriteStream() or filehandle.createWriteStream().
It is possible to use an <AbortSignal> to cancel an fsPromises.writeFile().
Cancelation is "best effort", and some amount of data is likely still
to be written.
import { writeFile } from 'node:fs/promises';
import { Buffer } from 'node:buffer';

try {
  const controller = new AbortController();
  const { signal } = controller;
  const data = new Uint8Array(Buffer.from('Hello Node.js'));
  const promise = writeFile('message.txt', data, { signal });

  // Abort the request before the promise settles.
  controller.abort();

  await promise;
} catch (err) {
  // When a request is aborted - err is an AbortError
  console.error(err);
} copy
Aborting an ongoing request does not abort individual operating
system requests but rather the internal buffering fs.writeFile performs.

fsPromises.constants#

Added in: v18.4.0, v16.17.0


<Object>

Returns an object containing commonly used constants for file system
operations. The object is the same as fs.constants. See FS constants
for more details.

Callback API#
The callback APIs perform all operations asynchronously, without blocking the
event loop, then invoke a callback function upon completion or error.
The callback APIs use the underlying Node.js threadpool to perform file
system operations off the event loop thread. These operations are not
synchronized or threadsafe. Care must be taken when performing multiple
concurrent modifications on the same file or data corruption may occur.

fs.access(path[, mode], callback)#

History

VersionChanges
v20.8.0
The constants fs.F_OK, fs.R_OK, fs.W_OK and fs.X_OK which were present directly on fs are deprecated.
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v7.6.0
The path parameter can be a WHATWG URL object using file: protocol.
v6.3.0
The constants like fs.R_OK, etc which were present directly on fs were moved into fs.constants as a soft deprecation. Thus for Node.js < v6.3.0 use fs to access those constants, or do something like (fs.constants || fs).R_OK to work with all versions.
v0.11.15
Added in: v0.11.15




path <string> | <Buffer> | <URL>
mode <integer> Default: fs.constants.F_OK
callback <Function>

err <Error>



Tests a user's permissions for the file or directory specified by path.
The mode argument is an optional integer that specifies the accessibility
checks to be performed. mode should be either the value fs.constants.F_OK
or a mask consisting of the bitwise OR of any of fs.constants.R_OK,
fs.constants.W_OK, and fs.constants.X_OK (e.g.
fs.constants.W_OK | fs.constants.R_OK). Check File access constants for
possible values of mode.
The final argument, callback, is a callback function that is invoked with
a possible error argument. If any of the accessibility checks fail, the error
argument will be an Error object. The following examples check if
package.json exists, and if it is readable or writable.
import { access, constants } from 'node:fs';

const file = 'package.json';

// Check if the file exists in the current directory.
access(file, constants.F_OK, (err) => {
  console.log(`${file} ${err ? 'does not exist' : 'exists'}`);
});

// Check if the file is readable.
access(file, constants.R_OK, (err) => {
  console.log(`${file} ${err ? 'is not readable' : 'is readable'}`);
});

// Check if the file is writable.
access(file, constants.W_OK, (err) => {
  console.log(`${file} ${err ? 'is not writable' : 'is writable'}`);
});

// Check if the file is readable and writable.
access(file, constants.R_OK | constants.W_OK, (err) => {
  console.log(`${file} ${err ? 'is not' : 'is'} readable and writable`);
}); copy
Do not use fs.access() to check for the accessibility of a file before calling
fs.open(), fs.readFile(), or fs.writeFile(). Doing
so introduces a race condition, since other processes may change the file's
state between the two calls. Instead, user code should open/read/write the
file directly and handle the error raised if the file is not accessible.
write (NOT RECOMMENDED)
import { access, open, close } from 'node:fs';

access('myfile', (err) => {
  if (!err) {
    console.error('myfile already exists');
    return;
  }

  open('myfile', 'wx', (err, fd) => {
    if (err) throw err;

    try {
      writeMyData(fd);
    } finally {
      close(fd, (err) => {
        if (err) throw err;
      });
    }
  });
}); copy
write (RECOMMENDED)
import { open, close } from 'node:fs';

open('myfile', 'wx', (err, fd) => {
  if (err) {
    if (err.code === 'EEXIST') {
      console.error('myfile already exists');
      return;
    }

    throw err;
  }

  try {
    writeMyData(fd);
  } finally {
    close(fd, (err) => {
      if (err) throw err;
    });
  }
}); copy
read (NOT RECOMMENDED)
import { access, open, close } from 'node:fs';
access('myfile', (err) => {
  if (err) {
    if (err.code === 'ENOENT') {
      console.error('myfile does not exist');
      return;
    }

    throw err;
  }

  open('myfile', 'r', (err, fd) => {
    if (err) throw err;

    try {
      readMyData(fd);
    } finally {
      close(fd, (err) => {
        if (err) throw err;
      });
    }
  });
}); copy
read (RECOMMENDED)
import { open, close } from 'node:fs';

open('myfile', 'r', (err, fd) => {
  if (err) {
    if (err.code === 'ENOENT') {
      console.error('myfile does not exist');
      return;
    }

    throw err;
  }

  try {
    readMyData(fd);
  } finally {
    close(fd, (err) => {
      if (err) throw err;
    });
  }
}); copy
The "not recommended" examples above check for accessibility and then use the
file; the "recommended" examples are better because they use the file directly
and handle the error, if any.
In general, check for the accessibility of a file only if the file will not be
used directly, for example when its accessibility is a signal from another
process.
On Windows, access-control policies (ACLs) on a directory may limit access to
a file or directory. The fs.access() function, however, does not check the
ACL and therefore may report that a path is accessible even if the ACL restricts
the user from reading or writing to it.

fs.appendFile(path, data[, options], callback)#

History

VersionChanges
v21.1.0, v20.10.0
The flush option is now supported.
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v10.0.0
The callback parameter is no longer optional. Not passing it will throw a TypeError at runtime.
v7.0.0
The callback parameter is no longer optional. Not passing it will emit a deprecation warning with id DEP0013.
v7.0.0
The passed options object will never be modified.
v5.0.0
The file parameter can be a file descriptor now.
v0.6.7
Added in: v0.6.7




path <string> | <Buffer> | <URL> | <number> filename or file descriptor
data <string> | <Buffer>
options <Object> | <string>

encoding <string> | <null> Default: 'utf8'
mode <integer> Default: 0o666
flag <string> See support of file system flags. Default: 'a'.
flush <boolean> If true, the underlying file descriptor is flushed
prior to closing it. Default: false.


callback <Function>

err <Error>



Asynchronously append data to a file, creating the file if it does not yet
exist. data can be a string or a <Buffer>.
The mode option only affects the newly created file. See fs.open()
for more details.
import { appendFile } from 'node:fs';

appendFile('message.txt', 'data to append', (err) => {
  if (err) throw err;
  console.log('The "data to append" was appended to file!');
}); copy
If options is a string, then it specifies the encoding:
import { appendFile } from 'node:fs';

appendFile('message.txt', 'data to append', 'utf8', callback); copy
The path may be specified as a numeric file descriptor that has been opened
for appending (using fs.open() or fs.openSync()). The file descriptor will
not be closed automatically.
import { open, close, appendFile } from 'node:fs';

function closeFd(fd) {
  close(fd, (err) => {
    if (err) throw err;
  });
}

open('message.txt', 'a', (err, fd) => {
  if (err) throw err;

  try {
    appendFile(fd, 'data to append', 'utf8', (err) => {
      closeFd(fd);
      if (err) throw err;
    });
  } catch (err) {
    closeFd(fd);
    throw err;
  }
}); copy

fs.chmod(path, mode, callback)#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v10.0.0
The callback parameter is no longer optional. Not passing it will throw a TypeError at runtime.
v7.6.0
The path parameter can be a WHATWG URL object using file: protocol.
v7.0.0
The callback parameter is no longer optional. Not passing it will emit a deprecation warning with id DEP0013.
v0.1.30
Added in: v0.1.30




path <string> | <Buffer> | <URL>
mode <string> | <integer>
callback <Function>

err <Error>



Asynchronously changes the permissions of a file. No arguments other than a
possible exception are given to the completion callback.
See the POSIX chmod(2) documentation for more detail.
import { chmod } from 'node:fs';

chmod('my_file.txt', 0o775, (err) => {
  if (err) throw err;
  console.log('The permissions for file "my_file.txt" have been changed!');
}); copy

File modes#
The mode argument used in both the fs.chmod() and fs.chmodSync()
methods is a numeric bitmask created using a logical OR of the following
constants:























































ConstantOctalDescriptionfs.constants.S_IRUSR0o400read by ownerfs.constants.S_IWUSR0o200write by ownerfs.constants.S_IXUSR0o100execute/search by ownerfs.constants.S_IRGRP0o40read by groupfs.constants.S_IWGRP0o20write by groupfs.constants.S_IXGRP0o10execute/search by groupfs.constants.S_IROTH0o4read by othersfs.constants.S_IWOTH0o2write by othersfs.constants.S_IXOTH0o1execute/search by others
An easier method of constructing the mode is to use a sequence of three
octal digits (e.g. 765). The left-most digit (7 in the example), specifies
the permissions for the file owner. The middle digit (6 in the example),
specifies permissions for the group. The right-most digit (5 in the example),
specifies the permissions for others.









































NumberDescription7read, write, and execute6read and write5read and execute4read only3write and execute2write only1execute only0no permission
For example, the octal value 0o765 means:

The owner may read, write, and execute the file.
The group may read and write the file.
Others may read and execute the file.

When using raw numbers where file modes are expected, any value larger than
0o777 may result in platform-specific behaviors that are not supported to work
consistently. Therefore constants like S_ISVTX, S_ISGID, or S_ISUID are
not exposed in fs.constants.
Caveats: on Windows only the write permission can be changed, and the
distinction among the permissions of group, owner, or others is not
implemented.

fs.chown(path, uid, gid, callback)#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v10.0.0
The callback parameter is no longer optional. Not passing it will throw a TypeError at runtime.
v7.6.0
The path parameter can be a WHATWG URL object using file: protocol.
v7.0.0
The callback parameter is no longer optional. Not passing it will emit a deprecation warning with id DEP0013.
v0.1.97
Added in: v0.1.97




path <string> | <Buffer> | <URL>
uid <integer>
gid <integer>
callback <Function>

err <Error>



Asynchronously changes owner and group of a file. No arguments other than a
possible exception are given to the completion callback.
See the POSIX chown(2) documentation for more detail.

fs.close(fd[, callback])#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v15.9.0, v14.17.0
A default callback is now used if one is not provided.
v10.0.0
The callback parameter is no longer optional. Not passing it will throw a TypeError at runtime.
v7.0.0
The callback parameter is no longer optional. Not passing it will emit a deprecation warning with id DEP0013.
v0.0.2
Added in: v0.0.2




fd <integer>
callback <Function>

err <Error>



Closes the file descriptor. No arguments other than a possible exception are
given to the completion callback.
Calling fs.close() on any file descriptor (fd) that is currently in use
through any other fs operation may lead to undefined behavior.
See the POSIX close(2) documentation for more detail.

fs.copyFile(src, dest[, mode], callback)#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v14.0.0
Changed flags argument to mode and imposed stricter type validation.
v8.5.0
Added in: v8.5.0




src <string> | <Buffer> | <URL> source filename to copy
dest <string> | <Buffer> | <URL> destination filename of the copy operation
mode <integer> modifiers for copy operation. Default: 0.
callback <Function>

err <Error>



Asynchronously copies src to dest. By default, dest is overwritten if it
already exists. No arguments other than a possible exception are given to the
callback function. Node.js makes no guarantees about the atomicity of the copy
operation. If an error occurs after the destination file has been opened for
writing, Node.js will attempt to remove the destination.
mode is an optional integer that specifies the behavior
of the copy operation. It is possible to create a mask consisting of the bitwise
OR of two or more values (e.g.
fs.constants.COPYFILE_EXCL | fs.constants.COPYFILE_FICLONE).

fs.constants.COPYFILE_EXCL: The copy operation will fail if dest already
exists.
fs.constants.COPYFILE_FICLONE: The copy operation will attempt to create a
copy-on-write reflink. If the platform does not support copy-on-write, then a
fallback copy mechanism is used.
fs.constants.COPYFILE_FICLONE_FORCE: The copy operation will attempt to
create a copy-on-write reflink. If the platform does not support
copy-on-write, then the operation will fail.

import { copyFile, constants } from 'node:fs';

function callback(err) {
  if (err) throw err;
  console.log('source.txt was copied to destination.txt');
}

// destination.txt will be created or overwritten by default.
copyFile('source.txt', 'destination.txt', callback);

// By using COPYFILE_EXCL, the operation will fail if destination.txt exists.
copyFile('source.txt', 'destination.txt', constants.COPYFILE_EXCL, callback); copy

fs.cp(src, dest[, options], callback)#

History

VersionChanges
v22.3.0
This API is no longer experimental.
v20.1.0, v18.17.0
Accept an additional mode option to specify the copy behavior as the mode argument of fs.copyFile().
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v17.6.0, v16.15.0
Accepts an additional verbatimSymlinks option to specify whether to perform path resolution for symlinks.
v16.7.0
Added in: v16.7.0




src <string> | <URL> source path to copy.
dest <string> | <URL> destination path to copy to.
options <Object>

dereference <boolean> dereference symlinks. Default: false.
errorOnExist <boolean> when force is false, and the destination
exists, throw an error. Default: false.
filter <Function> Function to filter copied files/directories. Return
true to copy the item, false to ignore it. When ignoring a directory,
all of its contents will be skipped as well. Can also return a Promise
that resolves to true or false Default: undefined.

src <string> source path to copy.
dest <string> destination path to copy to.
Returns: <boolean> | <Promise> A value that is coercible to boolean or
a Promise that fulfils with such value.


force <boolean> overwrite existing file or directory. The copy
operation will ignore errors if you set this to false and the destination
exists. Use the errorOnExist option to change this behavior.
Default: true.
mode <integer> modifiers for copy operation. Default: 0.
See mode flag of fs.copyFile().
preserveTimestamps <boolean> When true timestamps from src will
be preserved. Default: false.
recursive <boolean> copy directories recursively Default: false
verbatimSymlinks <boolean> When true, path resolution for symlinks will
be skipped. Default: false


callback <Function>

err <Error>



Asynchronously copies the entire directory structure from src to dest,
including subdirectories and files.
When copying a directory to another directory, globs are not supported and
behavior is similar to cp dir1/ dir2/.

fs.createReadStream(path[, options])#

History

VersionChanges
v16.10.0
The fs option does not need open method if an fd was provided.
v16.10.0
The fs option does not need close method if autoClose is false.
v15.5.0
Add support for AbortSignal.
v15.4.0
The fd option accepts FileHandle arguments.
v14.0.0
Change emitClose default to true.
v13.6.0, v12.17.0
The fs options allow overriding the used fs implementation.
v12.10.0
Enable emitClose option.
v11.0.0
Impose new restrictions on start and end, throwing more appropriate errors in cases when we cannot reasonably handle the input values.
v7.6.0
The path parameter can be a WHATWG URL object using file: protocol.
v7.0.0
The passed options object will never be modified.
v2.3.0
The passed options object can be a string now.
v0.1.31
Added in: v0.1.31




path <string> | <Buffer> | <URL>
options <string> | <Object>

flags <string> See support of file system flags. Default:
'r'.
encoding <string> Default: null
fd <integer> | <FileHandle> Default: null
mode <integer> Default: 0o666
autoClose <boolean> Default: true
emitClose <boolean> Default: true
start <integer>
end <integer> Default: Infinity
highWaterMark <integer> Default: 64 * 1024
fs <Object> | <null> Default: null
signal <AbortSignal> | <null> Default: null


Returns: <fs.ReadStream>

options can include start and end values to read a range of bytes from
the file instead of the entire file. Both start and end are inclusive and
start counting at 0, allowed values are in the
[0, Number.MAX_SAFE_INTEGER] range. If fd is specified and start is
omitted or undefined, fs.createReadStream() reads sequentially from the
current file position. The encoding can be any one of those accepted by
<Buffer>.
If fd is specified, ReadStream will ignore the path argument and will use
the specified file descriptor. This means that no 'open' event will be
emitted. fd should be blocking; non-blocking fds should be passed to
<net.Socket>.
If fd points to a character device that only supports blocking reads
(such as keyboard or sound card), read operations do not finish until data is
available. This can prevent the process from exiting and the stream from
closing naturally.
By default, the stream will emit a 'close' event after it has been
destroyed.  Set the emitClose option to false to change this behavior.
By providing the fs option, it is possible to override the corresponding fs
implementations for open, read, and close. When providing the fs option,
an override for read is required. If no fd is provided, an override for
open is also required. If autoClose is true, an override for close is
also required.
import { createReadStream } from 'node:fs';

// Create a stream from some character device.
const stream = createReadStream('/dev/input/event0');
setTimeout(() => {
  stream.close(); // This may not close the stream.
  // Artificially marking end-of-stream, as if the underlying resource had
  // indicated end-of-file by itself, allows the stream to close.
  // This does not cancel pending read operations, and if there is such an
  // operation, the process may still not be able to exit successfully
  // until it finishes.
  stream.push(null);
  stream.read(0);
}, 100); copy
If autoClose is false, then the file descriptor won't be closed, even if
there's an error. It is the application's responsibility to close it and make
sure there's no file descriptor leak. If autoClose is set to true (default
behavior), on 'error' or 'end' the file descriptor will be closed
automatically.
mode sets the file mode (permission and sticky bits), but only if the
file was created.
An example to read the last 10 bytes of a file which is 100 bytes long:
import { createReadStream } from 'node:fs';

createReadStream('sample.txt', { start: 90, end: 99 }); copy
If options is a string, then it specifies the encoding.

fs.createWriteStream(path[, options])#

History

VersionChanges
v21.0.0, v20.10.0
The flush option is now supported.
v16.10.0
The fs option does not need open method if an fd was provided.
v16.10.0
The fs option does not need close method if autoClose is false.
v15.5.0
Add support for AbortSignal.
v15.4.0
The fd option accepts FileHandle arguments.
v14.0.0
Change emitClose default to true.
v13.6.0, v12.17.0
The fs options allow overriding the used fs implementation.
v12.10.0
Enable emitClose option.
v7.6.0
The path parameter can be a WHATWG URL object using file: protocol.
v7.0.0
The passed options object will never be modified.
v5.5.0
The autoClose option is supported now.
v2.3.0
The passed options object can be a string now.
v0.1.31
Added in: v0.1.31




path <string> | <Buffer> | <URL>
options <string> | <Object>

flags <string> See support of file system flags. Default:
'w'.
encoding <string> Default: 'utf8'
fd <integer> | <FileHandle> Default: null
mode <integer> Default: 0o666
autoClose <boolean> Default: true
emitClose <boolean> Default: true
start <integer>
fs <Object> | <null> Default: null
signal <AbortSignal> | <null> Default: null
highWaterMark <number> Default: 16384
flush <boolean> If true, the underlying file descriptor is flushed
prior to closing it. Default: false.


Returns: <fs.WriteStream>

options may also include a start option to allow writing data at some
position past the beginning of the file, allowed values are in the
[0, Number.MAX_SAFE_INTEGER] range. Modifying a file rather than
replacing it may require the flags option to be set to r+ rather than the
default w. The encoding can be any one of those accepted by <Buffer>.
If autoClose is set to true (default behavior) on 'error' or 'finish'
the file descriptor will be closed automatically. If autoClose is false,
then the file descriptor won't be closed, even if there's an error.
It is the application's responsibility to close it and make sure there's no
file descriptor leak.
By default, the stream will emit a 'close' event after it has been
destroyed.  Set the emitClose option to false to change this behavior.
By providing the fs option it is possible to override the corresponding fs
implementations for open, write, writev, and close. Overriding write()
without writev() can reduce performance as some optimizations (_writev())
will be disabled. When providing the fs option, overrides for at least one of
write and writev are required. If no fd option is supplied, an override
for open is also required. If autoClose is true, an override for close
is also required.
Like <fs.ReadStream>, if fd is specified, <fs.WriteStream> will ignore the
path argument and will use the specified file descriptor. This means that no
'open' event will be emitted. fd should be blocking; non-blocking fds
should be passed to <net.Socket>.
If options is a string, then it specifies the encoding.

fs.exists(path, callback)#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v7.6.0
The path parameter can be a WHATWG URL object using file: protocol.
v1.0.0
Deprecated since: v1.0.0
v0.0.2
Added in: v0.0.2



Stability: 0 - Deprecated: Use fs.stat() or fs.access() instead.

path <string> | <Buffer> | <URL>
callback <Function>

exists <boolean>



Test whether or not the element at the given path exists by checking with the file system.
Then call the callback argument with either true or false:
import { exists } from 'node:fs';

exists('/etc/passwd', (e) => {
  console.log(e ? 'it exists' : 'no passwd!');
}); copy
The parameters for this callback are not consistent with other Node.js
callbacks. Normally, the first parameter to a Node.js callback is an err
parameter, optionally followed by other parameters. The fs.exists() callback
has only one boolean parameter. This is one reason fs.access() is recommended
instead of fs.exists().
If path is a symbolic link, it is followed. Thus, if path exists but points
to a non-existent element, the callback will receive the value false.
Using fs.exists() to check for the existence of a file before calling
fs.open(), fs.readFile(), or fs.writeFile() is not recommended. Doing
so introduces a race condition, since other processes may change the file's
state between the two calls. Instead, user code should open/read/write the
file directly and handle the error raised if the file does not exist.
write (NOT RECOMMENDED)
import { exists, open, close } from 'node:fs';

exists('myfile', (e) => {
  if (e) {
    console.error('myfile already exists');
  } else {
    open('myfile', 'wx', (err, fd) => {
      if (err) throw err;

      try {
        writeMyData(fd);
      } finally {
        close(fd, (err) => {
          if (err) throw err;
        });
      }
    });
  }
}); copy
write (RECOMMENDED)
import { open, close } from 'node:fs';
open('myfile', 'wx', (err, fd) => {
  if (err) {
    if (err.code === 'EEXIST') {
      console.error('myfile already exists');
      return;
    }

    throw err;
  }

  try {
    writeMyData(fd);
  } finally {
    close(fd, (err) => {
      if (err) throw err;
    });
  }
}); copy
read (NOT RECOMMENDED)
import { open, close, exists } from 'node:fs';

exists('myfile', (e) => {
  if (e) {
    open('myfile', 'r', (err, fd) => {
      if (err) throw err;

      try {
        readMyData(fd);
      } finally {
        close(fd, (err) => {
          if (err) throw err;
        });
      }
    });
  } else {
    console.error('myfile does not exist');
  }
}); copy
read (RECOMMENDED)
import { open, close } from 'node:fs';

open('myfile', 'r', (err, fd) => {
  if (err) {
    if (err.code === 'ENOENT') {
      console.error('myfile does not exist');
      return;
    }

    throw err;
  }

  try {
    readMyData(fd);
  } finally {
    close(fd, (err) => {
      if (err) throw err;
    });
  }
}); copy
The "not recommended" examples above check for existence and then use the
file; the "recommended" examples are better because they use the file directly
and handle the error, if any.
In general, check for the existence of a file only if the file won't be
used directly, for example when its existence is a signal from another
process.

fs.fchmod(fd, mode, callback)#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v10.0.0
The callback parameter is no longer optional. Not passing it will throw a TypeError at runtime.
v7.0.0
The callback parameter is no longer optional. Not passing it will emit a deprecation warning with id DEP0013.
v0.4.7
Added in: v0.4.7




fd <integer>
mode <string> | <integer>
callback <Function>

err <Error>



Sets the permissions on the file. No arguments other than a possible exception
are given to the completion callback.
See the POSIX fchmod(2) documentation for more detail.

fs.fchown(fd, uid, gid, callback)#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v10.0.0
The callback parameter is no longer optional. Not passing it will throw a TypeError at runtime.
v7.0.0
The callback parameter is no longer optional. Not passing it will emit a deprecation warning with id DEP0013.
v0.4.7
Added in: v0.4.7




fd <integer>
uid <integer>
gid <integer>
callback <Function>

err <Error>



Sets the owner of the file. No arguments other than a possible exception are
given to the completion callback.
See the POSIX fchown(2) documentation for more detail.

fs.fdatasync(fd, callback)#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v10.0.0
The callback parameter is no longer optional. Not passing it will throw a TypeError at runtime.
v7.0.0
The callback parameter is no longer optional. Not passing it will emit a deprecation warning with id DEP0013.
v0.1.96
Added in: v0.1.96




fd <integer>
callback <Function>

err <Error>



Forces all currently queued I/O operations associated with the file to the
operating system's synchronized I/O completion state. Refer to the POSIX
fdatasync(2) documentation for details. No arguments other than a possible
exception are given to the completion callback.

fs.fstat(fd[, options], callback)#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v10.5.0
Accepts an additional options object to specify whether the numeric values returned should be bigint.
v10.0.0
The callback parameter is no longer optional. Not passing it will throw a TypeError at runtime.
v7.0.0
The callback parameter is no longer optional. Not passing it will emit a deprecation warning with id DEP0013.
v0.1.95
Added in: v0.1.95




fd <integer>
options <Object>

bigint <boolean> Whether the numeric values in the returned
<fs.Stats> object should be bigint. Default: false.


callback <Function>

err <Error>
stats <fs.Stats>



Invokes the callback with the <fs.Stats> for the file descriptor.
See the POSIX fstat(2) documentation for more detail.

fs.fsync(fd, callback)#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v10.0.0
The callback parameter is no longer optional. Not passing it will throw a TypeError at runtime.
v7.0.0
The callback parameter is no longer optional. Not passing it will emit a deprecation warning with id DEP0013.
v0.1.96
Added in: v0.1.96




fd <integer>
callback <Function>

err <Error>



Request that all data for the open file descriptor is flushed to the storage
device. The specific implementation is operating system and device specific.
Refer to the POSIX fsync(2) documentation for more detail. No arguments other
than a possible exception are given to the completion callback.

fs.ftruncate(fd[, len], callback)#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v10.0.0
The callback parameter is no longer optional. Not passing it will throw a TypeError at runtime.
v7.0.0
The callback parameter is no longer optional. Not passing it will emit a deprecation warning with id DEP0013.
v0.8.6
Added in: v0.8.6




fd <integer>
len <integer> Default: 0
callback <Function>

err <Error>



Truncates the file descriptor. No arguments other than a possible exception are
given to the completion callback.
See the POSIX ftruncate(2) documentation for more detail.
If the file referred to by the file descriptor was larger than len bytes, only
the first len bytes will be retained in the file.
For example, the following program retains only the first four bytes of the
file:
import { open, close, ftruncate } from 'node:fs';

function closeFd(fd) {
  close(fd, (err) => {
    if (err) throw err;
  });
}

open('temp.txt', 'r+', (err, fd) => {
  if (err) throw err;

  try {
    ftruncate(fd, 4, (err) => {
      closeFd(fd);
      if (err) throw err;
    });
  } catch (err) {
    closeFd(fd);
    if (err) throw err;
  }
}); copy
If the file previously was shorter than len bytes, it is extended, and the
extended part is filled with null bytes ('\0'):
If len is negative then 0 will be used.

fs.futimes(fd, atime, mtime, callback)#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v10.0.0
The callback parameter is no longer optional. Not passing it will throw a TypeError at runtime.
v7.0.0
The callback parameter is no longer optional. Not passing it will emit a deprecation warning with id DEP0013.
v4.1.0
Numeric strings, NaN, and Infinity are now allowed time specifiers.
v0.4.2
Added in: v0.4.2




fd <integer>
atime <number> | <string> | <Date>
mtime <number> | <string> | <Date>
callback <Function>

err <Error>



Change the file system timestamps of the object referenced by the supplied file
descriptor. See fs.utimes().

fs.glob(pattern[, options], callback)#

History

VersionChanges
v24.0.0
Marking the API stable.
v23.7.0, v22.14.0
Add support for exclude option to accept glob patterns.
v22.2.0
Add support for withFileTypes as an option.
v22.0.0
Added in: v22.0.0





pattern <string> | <string[]>


options <Object>

cwd <string> current working directory. Default: process.cwd()
exclude <Function> | <string[]> Function to filter out files/directories or a
list of glob patterns to be excluded. If a function is provided, return
true to exclude the item, false to include it. Default: undefined.
withFileTypes <boolean> true if the glob should return paths as Dirents,
false otherwise. Default: false.



callback <Function>

err <Error>



Retrieves the files matching the specified pattern.



import { glob } from 'node:fs';

glob('**/*.js', (err, matches) => {
  if (err) throw err;
  console.log(matches);
});const { glob } = require('node:fs');

glob('**/*.js', (err, matches) => {
  if (err) throw err;
  console.log(matches);
});copy

fs.lchmod(path, mode, callback)#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v16.0.0
The error returned may be an AggregateError if more than one error is returned.
v10.0.0
The callback parameter is no longer optional. Not passing it will throw a TypeError at runtime.
v7.0.0
The callback parameter is no longer optional. Not passing it will emit a deprecation warning with id DEP0013.
v0.4.7
Deprecated since: v0.4.7



Stability: 0 - Deprecated

path <string> | <Buffer> | <URL>
mode <integer>
callback <Function>

err <Error> | <AggregateError>



Changes the permissions on a symbolic link. No arguments other than a possible
exception are given to the completion callback.
This method is only implemented on macOS.
See the POSIX lchmod(2) documentation for more detail.

fs.lchown(path, uid, gid, callback)#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v10.6.0
This API is no longer deprecated.
v10.0.0
The callback parameter is no longer optional. Not passing it will throw a TypeError at runtime.
v7.0.0
The callback parameter is no longer optional. Not passing it will emit a deprecation warning with id DEP0013.
v0.4.7
Documentation-only deprecation.




path <string> | <Buffer> | <URL>
uid <integer>
gid <integer>
callback <Function>

err <Error>



Set the owner of the symbolic link. No arguments other than a possible
exception are given to the completion callback.
See the POSIX lchown(2) documentation for more detail.

fs.lutimes(path, atime, mtime, callback)#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v14.5.0, v12.19.0
Added in: v14.5.0, v12.19.0




path <string> | <Buffer> | <URL>
atime <number> | <string> | <Date>
mtime <number> | <string> | <Date>
callback <Function>

err <Error>



Changes the access and modification times of a file in the same way as
fs.utimes(), with the difference that if the path refers to a symbolic
link, then the link is not dereferenced: instead, the timestamps of the
symbolic link itself are changed.
No arguments other than a possible exception are given to the completion
callback.

fs.link(existingPath, newPath, callback)#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v10.0.0
The callback parameter is no longer optional. Not passing it will throw a TypeError at runtime.
v7.6.0
The existingPath and newPath parameters can be WHATWG URL objects using file: protocol. Support is currently still experimental.
v7.0.0
The callback parameter is no longer optional. Not passing it will emit a deprecation warning with id DEP0013.
v0.1.31
Added in: v0.1.31




existingPath <string> | <Buffer> | <URL>
newPath <string> | <Buffer> | <URL>
callback <Function>

err <Error>



Creates a new link from the existingPath to the newPath. See the POSIX
link(2) documentation for more detail. No arguments other than a possible
exception are given to the completion callback.

fs.lstat(path[, options], callback)#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v10.5.0
Accepts an additional options object to specify whether the numeric values returned should be bigint.
v10.0.0
The callback parameter is no longer optional. Not passing it will throw a TypeError at runtime.
v7.6.0
The path parameter can be a WHATWG URL object using file: protocol.
v7.0.0
The callback parameter is no longer optional. Not passing it will emit a deprecation warning with id DEP0013.
v0.1.30
Added in: v0.1.30




path <string> | <Buffer> | <URL>
options <Object>

bigint <boolean> Whether the numeric values in the returned
<fs.Stats> object should be bigint. Default: false.


callback <Function>

err <Error>
stats <fs.Stats>



Retrieves the <fs.Stats> for the symbolic link referred to by the path.
The callback gets two arguments (err, stats) where stats is a <fs.Stats>
object. lstat() is identical to stat(), except that if path is a symbolic
link, then the link itself is stat-ed, not the file that it refers to.
See the POSIX lstat(2) documentation for more details.

fs.mkdir(path[, options], callback)#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v13.11.0, v12.17.0
In recursive mode, the callback now receives the first created path as an argument.
v10.12.0
The second argument can now be an options object with recursive and mode properties.
v10.0.0
The callback parameter is no longer optional. Not passing it will throw a TypeError at runtime.
v7.6.0
The path parameter can be a WHATWG URL object using file: protocol.
v7.0.0
The callback parameter is no longer optional. Not passing it will emit a deprecation warning with id DEP0013.
v0.1.8
Added in: v0.1.8




path <string> | <Buffer> | <URL>
options <Object> | <integer>

recursive <boolean> Default: false
mode <string> | <integer> Not supported on Windows. Default: 0o777.


callback <Function>

err <Error>
path <string> | <undefined> Present only if a directory is created with
recursive set to true.



Asynchronously creates a directory.
The callback is given a possible exception and, if recursive is true, the
first directory path created, (err[, path]).
path can still be undefined when recursive is true, if no directory was
created (for instance, if it was previously created).
The optional options argument can be an integer specifying mode (permission
and sticky bits), or an object with a mode property and a recursive
property indicating whether parent directories should be created. Calling
fs.mkdir() when path is a directory that exists results in an error only
when recursive is false. If recursive is false and the directory exists,
an EEXIST error occurs.
import { mkdir } from 'node:fs';

// Create ./tmp/a/apple, regardless of whether ./tmp and ./tmp/a exist.
mkdir('./tmp/a/apple', { recursive: true }, (err) => {
  if (err) throw err;
}); copy
On Windows, using fs.mkdir() on the root directory even with recursion will
result in an error:
import { mkdir } from 'node:fs';

mkdir('/', { recursive: true }, (err) => {
  // => [Error: EPERM: operation not permitted, mkdir 'C:\']
}); copy
See the POSIX mkdir(2) documentation for more details.

fs.mkdtemp(prefix[, options], callback)#

History

VersionChanges
v20.6.0, v18.19.0
The prefix parameter now accepts buffers and URL.
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v16.5.0, v14.18.0
The prefix parameter now accepts an empty string.
v10.0.0
The callback parameter is no longer optional. Not passing it will throw a TypeError at runtime.
v7.0.0
The callback parameter is no longer optional. Not passing it will emit a deprecation warning with id DEP0013.
v6.2.1
The callback parameter is optional now.
v5.10.0
Added in: v5.10.0




prefix <string> | <Buffer> | <URL>
options <string> | <Object>

encoding <string> Default: 'utf8'


callback <Function>

err <Error>
directory <string>



Creates a unique temporary directory.
Generates six random characters to be appended behind a required
prefix to create a unique temporary directory. Due to platform
inconsistencies, avoid trailing X characters in prefix. Some platforms,
notably the BSDs, can return more than six random characters, and replace
trailing X characters in prefix with random characters.
The created directory path is passed as a string to the callback's second
parameter.
The optional options argument can be a string specifying an encoding, or an
object with an encoding property specifying the character encoding to use.
import { mkdtemp } from 'node:fs';
import { join } from 'node:path';
import { tmpdir } from 'node:os';

mkdtemp(join(tmpdir(), 'foo-'), (err, directory) => {
  if (err) throw err;
  console.log(directory);
  // Prints: /tmp/foo-itXde2 or C:\Users\...\AppData\Local\Temp\foo-itXde2
}); copy
The fs.mkdtemp() method will append the six randomly selected characters
directly to the prefix string. For instance, given a directory /tmp, if the
intention is to create a temporary directory within /tmp, the prefix
must end with a trailing platform-specific path separator
(require('node:path').sep).
import { tmpdir } from 'node:os';
import { mkdtemp } from 'node:fs';

// The parent directory for the new temporary directory
const tmpDir = tmpdir();

// This method is *INCORRECT*:
mkdtemp(tmpDir, (err, directory) => {
  if (err) throw err;
  console.log(directory);
  // Will print something similar to `/tmpabc123`.
  // A new temporary directory is created at the file system root
  // rather than *within* the /tmp directory.
});

// This method is *CORRECT*:
import { sep } from 'node:path';
mkdtemp(`${tmpDir}${sep}`, (err, directory) => {
  if (err) throw err;
  console.log(directory);
  // Will print something similar to `/tmp/abc123`.
  // A new temporary directory is created within
  // the /tmp directory.
}); copy

fs.open(path[, flags[, mode]], callback)#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v11.1.0
The flags argument is now optional and defaults to 'r'.
v9.9.0
The as and as+ flags are supported now.
v7.6.0
The path parameter can be a WHATWG URL object using file: protocol.
v0.0.2
Added in: v0.0.2




path <string> | <Buffer> | <URL>
flags <string> | <number> See support of file system flags.
Default: 'r'.
mode <string> | <integer> Default: 0o666 (readable and writable)
callback <Function>

err <Error>
fd <integer>



Asynchronous file open. See the POSIX open(2) documentation for more details.
mode sets the file mode (permission and sticky bits), but only if the file was
created. On Windows, only the write permission can be manipulated; see
fs.chmod().
The callback gets two arguments (err, fd).
Some characters (< > : " / \ | ? *) are reserved under Windows as documented
by Naming Files, Paths, and Namespaces. Under NTFS, if the filename contains
a colon, Node.js will open a file system stream, as described by
this MSDN page.
Functions based on fs.open() exhibit this behavior as well:
fs.writeFile(), fs.readFile(), etc.

fs.openAsBlob(path[, options])#

History

VersionChanges
v24.0.0
Marking the API stable.
v19.8.0
Added in: v19.8.0




path <string> | <Buffer> | <URL>
options <Object>

type <string> An optional mime type for the blob.


Returns: <Promise> Fulfills with a <Blob> upon success.

Returns a <Blob> whose data is backed by the given file.
The file must not be modified after the <Blob> is created. Any modifications
will cause reading the <Blob> data to fail with a DOMException error.
Synchronous stat operations on the file when the Blob is created, and before
each read in order to detect whether the file data has been modified on disk.

import { openAsBlob } from 'node:fs';

const blob = await openAsBlob('the.file.txt');
const ab = await blob.arrayBuffer();
blob.stream();const { openAsBlob } = require('node:fs');

(async () => {
  const blob = await openAsBlob('the.file.txt');
  const ab = await blob.arrayBuffer();
  blob.stream();
})();copy

fs.opendir(path[, options], callback)#

History

VersionChanges
v20.1.0, v18.17.0
Added recursive option.
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v13.1.0, v12.16.0
The bufferSize option was introduced.
v12.12.0
Added in: v12.12.0




path <string> | <Buffer> | <URL>
options <Object>

encoding <string> | <null> Default: 'utf8'
bufferSize <number> Number of directory entries that are buffered
internally when reading from the directory. Higher values lead to better
performance but higher memory usage. Default: 32
recursive <boolean> Default: false


callback <Function>

err <Error>
dir <fs.Dir>



Asynchronously open a directory. See the POSIX opendir(3) documentation for
more details.
Creates an <fs.Dir>, which contains all further functions for reading from
and cleaning up the directory.
The encoding option sets the encoding for the path while opening the
directory and subsequent read operations.

fs.read(fd, buffer, offset, length, position, callback)#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v10.10.0
The buffer parameter can now be any TypedArray, or a DataView.
v7.4.0
The buffer parameter can now be a Uint8Array.
v6.0.0
The length parameter can now be 0.
v0.0.2
Added in: v0.0.2




fd <integer>
buffer <Buffer> | <TypedArray> | <DataView> The buffer that the data will be
written to.
offset <integer> The position in buffer to write the data to.
length <integer> The number of bytes to read.
position <integer> | <bigint> | <null> Specifies where to begin reading from in the
file. If position is null or -1 , data will be read from the current
file position, and the file position will be updated. If position is
a non-negative integer, the file position will be unchanged.
callback <Function>

err <Error>
bytesRead <integer>
buffer <Buffer>



Read data from the file specified by fd.
The callback is given the three arguments, (err, bytesRead, buffer).
If the file is not modified concurrently, the end-of-file is reached when the
number of bytes read is zero.
If this method is invoked as its util.promisify()ed version, it returns
a promise for an Object with bytesRead and buffer properties.
The fs.read() method reads data from the file specified
by the file descriptor (fd).
The length argument indicates the maximum number
of bytes that Node.js
will attempt to read from the kernel.
However, the actual number of bytes read (bytesRead) can be lower
than the specified length for various reasons.
For example:

If the file is shorter than the specified length, bytesRead
will be set to the actual number of bytes read.
If the file encounters EOF (End of File) before the buffer could
be filled, Node.js will read all available bytes until EOF is encountered,
and the bytesRead parameter in the callback will indicate
the actual number of bytes read, which may be less than the specified length.
If the file is on a slow network filesystem
or encounters any other issue during reading,
bytesRead can be lower than the specified length.

Therefore, when using fs.read(), it's important to
check the bytesRead value to
determine how many bytes were actually read from the file.
Depending on your application
logic, you may need to handle cases where bytesRead
is lower than the specified length,
such as by wrapping the read call in a loop if you require
a minimum amount of bytes.
This behavior is similar to the POSIX preadv2 function.

fs.read(fd[, options], callback)#

History

VersionChanges
v13.11.0, v12.17.0
Options object can be passed in to make buffer, offset, length, and position optional.
v13.11.0, v12.17.0
Added in: v13.11.0, v12.17.0




fd <integer>
options <Object>

buffer <Buffer> | <TypedArray> | <DataView> Default: Buffer.alloc(16384)
offset <integer> Default: 0
length <integer> Default: buffer.byteLength - offset
position <integer> | <bigint> | <null> Default: null


callback <Function>

err <Error>
bytesRead <integer>
buffer <Buffer>



Similar to the fs.read() function, this version takes an optional
options object. If no options object is specified, it will default with the
above values.

fs.read(fd, buffer[, options], callback)#

Added in: v18.2.0, v16.17.0


fd <integer>
buffer <Buffer> | <TypedArray> | <DataView> The buffer that the data will be
written to.
options <Object>

offset <integer> Default: 0
length <integer> Default: buffer.byteLength - offset
position <integer> | <bigint> Default: null


callback <Function>

err <Error>
bytesRead <integer>
buffer <Buffer>



Similar to the fs.read() function, this version takes an optional
options object. If no options object is specified, it will default with the
above values.

fs.readdir(path[, options], callback)#

History

VersionChanges
v20.1.0, v18.17.0
Added recursive option.
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v10.10.0
New option withFileTypes was added.
v10.0.0
The callback parameter is no longer optional. Not passing it will throw a TypeError at runtime.
v7.6.0
The path parameter can be a WHATWG URL object using file: protocol.
v7.0.0
The callback parameter is no longer optional. Not passing it will emit a deprecation warning with id DEP0013.
v6.0.0
The options parameter was added.
v0.1.8
Added in: v0.1.8




path <string> | <Buffer> | <URL>
options <string> | <Object>

encoding <string> Default: 'utf8'
withFileTypes <boolean> Default: false
recursive <boolean> If true, reads the contents of a directory
recursively. In recursive mode, it will list all files, sub files and
directories. Default: false.


callback <Function>

err <Error>
files <string[]> | <Buffer[]> | <fs.Dirent[]>



Reads the contents of a directory. The callback gets two arguments (err, files)
where files is an array of the names of the files in the directory excluding
'.' and '..'.
See the POSIX readdir(3) documentation for more details.
The optional options argument can be a string specifying an encoding, or an
object with an encoding property specifying the character encoding to use for
the filenames passed to the callback. If the encoding is set to 'buffer',
the filenames returned will be passed as <Buffer> objects.
If options.withFileTypes is set to true, the files array will contain
<fs.Dirent> objects.

fs.readFile(path[, options], callback)#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v16.0.0
The error returned may be an AggregateError if more than one error is returned.
v15.2.0, v14.17.0
The options argument may include an AbortSignal to abort an ongoing readFile request.
v10.0.0
The callback parameter is no longer optional. Not passing it will throw a TypeError at runtime.
v7.6.0
The path parameter can be a WHATWG URL object using file: protocol.
v7.0.0
The callback parameter is no longer optional. Not passing it will emit a deprecation warning with id DEP0013.
v5.1.0
The callback will always be called with null as the error parameter in case of success.
v5.0.0
The path parameter can be a file descriptor now.
v0.1.29
Added in: v0.1.29




path <string> | <Buffer> | <URL> | <integer> filename or file descriptor
options <Object> | <string>

encoding <string> | <null> Default: null
flag <string> See support of file system flags. Default: 'r'.
signal <AbortSignal> allows aborting an in-progress readFile


callback <Function>

err <Error> | <AggregateError>
data <string> | <Buffer>



Asynchronously reads the entire contents of a file.
import { readFile } from 'node:fs';

readFile('/etc/passwd', (err, data) => {
  if (err) throw err;
  console.log(data);
}); copy
The callback is passed two arguments (err, data), where data is the
contents of the file.
If no encoding is specified, then the raw buffer is returned.
If options is a string, then it specifies the encoding:
import { readFile } from 'node:fs';

readFile('/etc/passwd', 'utf8', callback); copy
When the path is a directory, the behavior of fs.readFile() and
fs.readFileSync() is platform-specific. On macOS, Linux, and Windows, an
error will be returned. On FreeBSD, a representation of the directory's contents
will be returned.
import { readFile } from 'node:fs';

// macOS, Linux, and Windows
readFile('<directory>', (err, data) => {
  // => [Error: EISDIR: illegal operation on a directory, read <directory>]
});

//  FreeBSD
readFile('<directory>', (err, data) => {
  // => null, <data>
}); copy
It is possible to abort an ongoing request using an AbortSignal. If a
request is aborted the callback is called with an AbortError:
import { readFile } from 'node:fs';

const controller = new AbortController();
const signal = controller.signal;
readFile(fileInfo[0].name, { signal }, (err, buf) => {
  // ...
});
// When you want to abort the request
controller.abort(); copy
The fs.readFile() function buffers the entire file. To minimize memory costs,
when possible prefer streaming via fs.createReadStream().
Aborting an ongoing request does not abort individual operating
system requests but rather the internal buffering fs.readFile performs.

File descriptors#

Any specified file descriptor has to support reading.
If a file descriptor is specified as the path, it will not be closed
automatically.
The reading will begin at the current position. For example, if the file
already had 'Hello World' and six bytes are read with the file descriptor,
the call to fs.readFile() with the same file descriptor, would give
'World', rather than 'Hello World'.


Performance Considerations#
The fs.readFile() method asynchronously reads the contents of a file into
memory one chunk at a time, allowing the event loop to turn between each chunk.
This allows the read operation to have less impact on other activity that may
be using the underlying libuv thread pool but means that it will take longer
to read a complete file into memory.
The additional read overhead can vary broadly on different systems and depends
on the type of file being read. If the file type is not a regular file (a pipe
for instance) and Node.js is unable to determine an actual file size, each read
operation will load on 64 KiB of data. For regular files, each read will process
512 KiB of data.
For applications that require as-fast-as-possible reading of file contents, it
is better to use fs.read() directly and for application code to manage
reading the full contents of the file itself.
The Node.js GitHub issue #25741 provides more information and a detailed
analysis on the performance of fs.readFile() for multiple file sizes in
different Node.js versions.

fs.readlink(path[, options], callback)#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v10.0.0
The callback parameter is no longer optional. Not passing it will throw a TypeError at runtime.
v7.6.0
The path parameter can be a WHATWG URL object using file: protocol.
v7.0.0
The callback parameter is no longer optional. Not passing it will emit a deprecation warning with id DEP0013.
v0.1.31
Added in: v0.1.31




path <string> | <Buffer> | <URL>
options <string> | <Object>

encoding <string> Default: 'utf8'


callback <Function>

err <Error>
linkString <string> | <Buffer>



Reads the contents of the symbolic link referred to by path. The callback gets
two arguments (err, linkString).
See the POSIX readlink(2) documentation for more details.
The optional options argument can be a string specifying an encoding, or an
object with an encoding property specifying the character encoding to use for
the link path passed to the callback. If the encoding is set to 'buffer',
the link path returned will be passed as a <Buffer> object.

fs.readv(fd, buffers[, position], callback)#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v13.13.0, v12.17.0
Added in: v13.13.0, v12.17.0




fd <integer>
buffers <ArrayBufferView[]>
position <integer> | <null> Default: null
callback <Function>

err <Error>
bytesRead <integer>
buffers <ArrayBufferView[]>



Read from a file specified by fd and write to an array of ArrayBufferViews
using readv().
position is the offset from the beginning of the file from where data
should be read. If typeof position !== 'number', the data will be read
from the current position.
The callback will be given three arguments: err, bytesRead, and
buffers. bytesRead is how many bytes were read from the file.
If this method is invoked as its util.promisify()ed version, it returns
a promise for an Object with bytesRead and buffers properties.

fs.realpath(path[, options], callback)#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v10.0.0
The callback parameter is no longer optional. Not passing it will throw a TypeError at runtime.
v8.0.0
Pipe/Socket resolve support was added.
v7.6.0
The path parameter can be a WHATWG URL object using file: protocol.
v7.0.0
The callback parameter is no longer optional. Not passing it will emit a deprecation warning with id DEP0013.
v6.4.0
Calling realpath now works again for various edge cases on Windows.
v6.0.0
The cache parameter was removed.
v0.1.31
Added in: v0.1.31




path <string> | <Buffer> | <URL>
options <string> | <Object>

encoding <string> Default: 'utf8'


callback <Function>

err <Error>
resolvedPath <string> | <Buffer>



Asynchronously computes the canonical pathname by resolving ., .., and
symbolic links.
A canonical pathname is not necessarily unique. Hard links and bind mounts can
expose a file system entity through many pathnames.
This function behaves like realpath(3), with some exceptions:


No case conversion is performed on case-insensitive file systems.


The maximum number of symbolic links is platform-independent and generally
(much) higher than what the native realpath(3) implementation supports.


The callback gets two arguments (err, resolvedPath). May use process.cwd
to resolve relative paths.
Only paths that can be converted to UTF8 strings are supported.
The optional options argument can be a string specifying an encoding, or an
object with an encoding property specifying the character encoding to use for
the path passed to the callback. If the encoding is set to 'buffer',
the path returned will be passed as a <Buffer> object.
If path resolves to a socket or a pipe, the function will return a system
dependent name for that object.
A path that does not exist results in an ENOENT error.
error.path is the absolute file path.

fs.realpath.native(path[, options], callback)#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v9.2.0
Added in: v9.2.0




path <string> | <Buffer> | <URL>
options <string> | <Object>

encoding <string> Default: 'utf8'


callback <Function>

err <Error>
resolvedPath <string> | <Buffer>



Asynchronous realpath(3).
The callback gets two arguments (err, resolvedPath).
Only paths that can be converted to UTF8 strings are supported.
The optional options argument can be a string specifying an encoding, or an
object with an encoding property specifying the character encoding to use for
the path passed to the callback. If the encoding is set to 'buffer',
the path returned will be passed as a <Buffer> object.
On Linux, when Node.js is linked against musl libc, the procfs file system must
be mounted on /proc in order for this function to work. Glibc does not have
this restriction.

fs.rename(oldPath, newPath, callback)#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v10.0.0
The callback parameter is no longer optional. Not passing it will throw a TypeError at runtime.
v7.6.0
The oldPath and newPath parameters can be WHATWG URL objects using file: protocol. Support is currently still experimental.
v7.0.0
The callback parameter is no longer optional. Not passing it will emit a deprecation warning with id DEP0013.
v0.0.2
Added in: v0.0.2




oldPath <string> | <Buffer> | <URL>
newPath <string> | <Buffer> | <URL>
callback <Function>

err <Error>



Asynchronously rename file at oldPath to the pathname provided
as newPath. In the case that newPath already exists, it will
be overwritten. If there is a directory at newPath, an error will
be raised instead. No arguments other than a possible exception are
given to the completion callback.
See also: rename(2).
import { rename } from 'node:fs';

rename('oldFile.txt', 'newFile.txt', (err) => {
  if (err) throw err;
  console.log('Rename complete!');
}); copy

fs.rmdir(path[, options], callback)#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v16.0.0
Using fs.rmdir(path, { recursive: true }) on a path that is a file is no longer permitted and results in an ENOENT error on Windows and an ENOTDIR error on POSIX.
v16.0.0
Using fs.rmdir(path, { recursive: true }) on a path that does not exist is no longer permitted and results in a ENOENT error.
v16.0.0
The recursive option is deprecated, using it triggers a deprecation warning.
v14.14.0
The recursive option is deprecated, use fs.rm instead.
v13.3.0, v12.16.0
The maxBusyTries option is renamed to maxRetries, and its default is 0. The emfileWait option has been removed, and EMFILE errors use the same retry logic as other errors. The retryDelay option is now supported. ENFILE errors are now retried.
v12.10.0
The recursive, maxBusyTries, and emfileWait options are now supported.
v10.0.0
The callback parameter is no longer optional. Not passing it will throw a TypeError at runtime.
v7.6.0
The path parameters can be a WHATWG URL object using file: protocol.
v7.0.0
The callback parameter is no longer optional. Not passing it will emit a deprecation warning with id DEP0013.
v0.0.2
Added in: v0.0.2




path <string> | <Buffer> | <URL>
options <Object>

maxRetries <integer> If an EBUSY, EMFILE, ENFILE, ENOTEMPTY, or
EPERM error is encountered, Node.js retries the operation with a linear
backoff wait of retryDelay milliseconds longer on each try. This option
represents the number of retries. This option is ignored if the recursive
option is not true. Default: 0.
recursive <boolean> If true, perform a recursive directory removal. In
recursive mode, operations are retried on failure. Default: false.
Deprecated.
retryDelay <integer> The amount of time in milliseconds to wait between
retries. This option is ignored if the recursive option is not true.
Default: 100.


callback <Function>

err <Error>



Asynchronous rmdir(2). No arguments other than a possible exception are given
to the completion callback.
Using fs.rmdir() on a file (not a directory) results in an ENOENT error on
Windows and an ENOTDIR error on POSIX.
To get a behavior similar to the rm -rf Unix command, use fs.rm()
with options { recursive: true, force: true }.

fs.rm(path[, options], callback)#

History

VersionChanges
v17.3.0, v16.14.0
The path parameter can be a WHATWG URL object using file: protocol.
v14.14.0
Added in: v14.14.0




path <string> | <Buffer> | <URL>
options <Object>

force <boolean> When true, exceptions will be ignored if path does
not exist. Default: false.
maxRetries <integer> If an EBUSY, EMFILE, ENFILE, ENOTEMPTY, or
EPERM error is encountered, Node.js will retry the operation with a linear
backoff wait of retryDelay milliseconds longer on each try. This option
represents the number of retries. This option is ignored if the recursive
option is not true. Default: 0.
recursive <boolean> If true, perform a recursive removal. In
recursive mode operations are retried on failure. Default: false.
retryDelay <integer> The amount of time in milliseconds to wait between
retries. This option is ignored if the recursive option is not true.
Default: 100.


callback <Function>

err <Error>



Asynchronously removes files and directories (modeled on the standard POSIX rm
utility). No arguments other than a possible exception are given to the
completion callback.

fs.stat(path[, options], callback)#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v10.5.0
Accepts an additional options object to specify whether the numeric values returned should be bigint.
v10.0.0
The callback parameter is no longer optional. Not passing it will throw a TypeError at runtime.
v7.6.0
The path parameter can be a WHATWG URL object using file: protocol.
v7.0.0
The callback parameter is no longer optional. Not passing it will emit a deprecation warning with id DEP0013.
v0.0.2
Added in: v0.0.2




path <string> | <Buffer> | <URL>
options <Object>

bigint <boolean> Whether the numeric values in the returned
<fs.Stats> object should be bigint. Default: false.


callback <Function>

err <Error>
stats <fs.Stats>



Asynchronous stat(2). The callback gets two arguments (err, stats) where
stats is an <fs.Stats> object.
In case of an error, the err.code will be one of Common System Errors.
fs.stat() follows symbolic links. Use fs.lstat() to look at the
links themselves.
Using fs.stat() to check for the existence of a file before calling
fs.open(), fs.readFile(), or fs.writeFile() is not recommended.
Instead, user code should open/read/write the file directly and handle the
error raised if the file is not available.
To check if a file exists without manipulating it afterwards, fs.access()
is recommended.
For example, given the following directory structure:
- txtDir
-- file.txt
- app.js copy
The next program will check for the stats of the given paths:
import { stat } from 'node:fs';

const pathsToCheck = ['./txtDir', './txtDir/file.txt'];

for (let i = 0; i < pathsToCheck.length; i++) {
  stat(pathsToCheck[i], (err, stats) => {
    console.log(stats.isDirectory());
    console.log(stats);
  });
} copy
The resulting output will resemble:
true
Stats {
  dev: 16777220,
  mode: 16877,
  nlink: 3,
  uid: 501,
  gid: 20,
  rdev: 0,
  blksize: 4096,
  ino: 14214262,
  size: 96,
  blocks: 0,
  atimeMs: 1561174653071.963,
  mtimeMs: 1561174614583.3518,
  ctimeMs: 1561174626623.5366,
  birthtimeMs: 1561174126937.2893,
  atime: 2019-06-22T03:37:33.072Z,
  mtime: 2019-06-22T03:36:54.583Z,
  ctime: 2019-06-22T03:37:06.624Z,
  birthtime: 2019-06-22T03:28:46.937Z
}
false
Stats {
  dev: 16777220,
  mode: 33188,
  nlink: 1,
  uid: 501,
  gid: 20,
  rdev: 0,
  blksize: 4096,
  ino: 14214074,
  size: 8,
  blocks: 8,
  atimeMs: 1561174616618.8555,
  mtimeMs: 1561174614584,
  ctimeMs: 1561174614583.8145,
  birthtimeMs: 1561174007710.7478,
  atime: 2019-06-22T03:36:56.619Z,
  mtime: 2019-06-22T03:36:54.584Z,
  ctime: 2019-06-22T03:36:54.584Z,
  birthtime: 2019-06-22T03:26:47.711Z
} copy

fs.statfs(path[, options], callback)#

Added in: v19.6.0, v18.15.0


path <string> | <Buffer> | <URL>
options <Object>

bigint <boolean> Whether the numeric values in the returned
<fs.StatFs> object should be bigint. Default: false.


callback <Function>

err <Error>
stats <fs.StatFs>



Asynchronous statfs(2). Returns information about the mounted file system which
contains path. The callback gets two arguments (err, stats) where stats
is an <fs.StatFs> object.
In case of an error, the err.code will be one of Common System Errors.

fs.symlink(target, path[, type], callback)#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v12.0.0
If the type argument is left undefined, Node will autodetect target type and automatically select dir or file.
v7.6.0
The target and path parameters can be WHATWG URL objects using file: protocol. Support is currently still experimental.
v0.1.31
Added in: v0.1.31




target <string> | <Buffer> | <URL>
path <string> | <Buffer> | <URL>
type <string> | <null> Default: null
callback <Function>

err <Error>



Creates the link called path pointing to target. No arguments other than a
possible exception are given to the completion callback.
See the POSIX symlink(2) documentation for more details.
The type argument is only available on Windows and ignored on other platforms.
It can be set to 'dir', 'file', or 'junction'. If the type argument is
null, Node.js will autodetect target type and use 'file' or 'dir'.
If the target does not exist, 'file' will be used. Windows junction points
require the destination path to be absolute. When using 'junction', the
target argument will automatically be normalized to absolute path. Junction
points on NTFS volumes can only point to directories.
Relative targets are relative to the link's parent directory.
import { symlink } from 'node:fs';

symlink('./mew', './mewtwo', callback); copy
The above example creates a symbolic link mewtwo which points to mew in the
same directory:
$ tree .
.
├── mew
└── mewtwo -> ./mew copy

fs.truncate(path[, len], callback)#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v16.0.0
The error returned may be an AggregateError if more than one error is returned.
v10.0.0
The callback parameter is no longer optional. Not passing it will throw a TypeError at runtime.
v7.0.0
The callback parameter is no longer optional. Not passing it will emit a deprecation warning with id DEP0013.
v0.8.6
Added in: v0.8.6




path <string> | <Buffer> | <URL>
len <integer> Default: 0
callback <Function>

err <Error> | <AggregateError>



Truncates the file. No arguments other than a possible exception are
given to the completion callback. A file descriptor can also be passed as the
first argument. In this case, fs.ftruncate() is called.

import { truncate } from 'node:fs';
// Assuming that 'path/file.txt' is a regular file.
truncate('path/file.txt', (err) => {
  if (err) throw err;
  console.log('path/file.txt was truncated');
});const { truncate } = require('node:fs');
// Assuming that 'path/file.txt' is a regular file.
truncate('path/file.txt', (err) => {
  if (err) throw err;
  console.log('path/file.txt was truncated');
});copy
Passing a file descriptor is deprecated and may result in an error being thrown
in the future.
See the POSIX truncate(2) documentation for more details.

fs.unlink(path, callback)#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v10.0.0
The callback parameter is no longer optional. Not passing it will throw a TypeError at runtime.
v7.6.0
The path parameter can be a WHATWG URL object using file: protocol.
v7.0.0
The callback parameter is no longer optional. Not passing it will emit a deprecation warning with id DEP0013.
v0.0.2
Added in: v0.0.2




path <string> | <Buffer> | <URL>
callback <Function>

err <Error>



Asynchronously removes a file or symbolic link. No arguments other than a
possible exception are given to the completion callback.
import { unlink } from 'node:fs';
// Assuming that 'path/file.txt' is a regular file.
unlink('path/file.txt', (err) => {
  if (err) throw err;
  console.log('path/file.txt was deleted');
}); copy
fs.unlink() will not work on a directory, empty or otherwise. To remove a
directory, use fs.rmdir().
See the POSIX unlink(2) documentation for more details.

fs.unwatchFile(filename[, listener])#

Added in: v0.1.31


filename <string> | <Buffer> | <URL>
listener <Function> Optional, a listener previously attached using
fs.watchFile()

Stop watching for changes on filename. If listener is specified, only that
particular listener is removed. Otherwise, all listeners are removed,
effectively stopping watching of filename.
Calling fs.unwatchFile() with a filename that is not being watched is a
no-op, not an error.
Using fs.watch() is more efficient than fs.watchFile() and
fs.unwatchFile(). fs.watch() should be used instead of fs.watchFile()
and fs.unwatchFile() when possible.

fs.utimes(path, atime, mtime, callback)#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v10.0.0
The callback parameter is no longer optional. Not passing it will throw a TypeError at runtime.
v8.0.0
NaN, Infinity, and -Infinity are no longer valid time specifiers.
v7.6.0
The path parameter can be a WHATWG URL object using file: protocol.
v7.0.0
The callback parameter is no longer optional. Not passing it will emit a deprecation warning with id DEP0013.
v4.1.0
Numeric strings, NaN, and Infinity are now allowed time specifiers.
v0.4.2
Added in: v0.4.2




path <string> | <Buffer> | <URL>
atime <number> | <string> | <Date>
mtime <number> | <string> | <Date>
callback <Function>

err <Error>



Change the file system timestamps of the object referenced by path.
The atime and mtime arguments follow these rules:

Values can be either numbers representing Unix epoch time in seconds,
Dates, or a numeric string like '123456789.0'.
If the value can not be converted to a number, or is NaN, Infinity, or
-Infinity, an Error will be thrown.


fs.watch(filename[, options][, listener])#

History

VersionChanges
v19.1.0
Added recursive support for Linux, AIX and IBMi.
v15.9.0, v14.17.0
Added support for closing the watcher with an AbortSignal.
v7.6.0
The filename parameter can be a WHATWG URL object using file: protocol.
v7.0.0
The passed options object will never be modified.
v0.5.10
Added in: v0.5.10




filename <string> | <Buffer> | <URL>
options <string> | <Object>

persistent <boolean> Indicates whether the process should continue to run
as long as files are being watched. Default: true.
recursive <boolean> Indicates whether all subdirectories should be
watched, or only the current directory. This applies when a directory is
specified, and only on supported platforms (See caveats). Default:
false.
encoding <string> Specifies the character encoding to be used for the
filename passed to the listener. Default: 'utf8'.
signal <AbortSignal> allows closing the watcher with an AbortSignal.


listener <Function> | <undefined> Default: undefined

eventType <string>
filename <string> | <Buffer> | <null>


Returns: <fs.FSWatcher>

Watch for changes on filename, where filename is either a file or a
directory.
The second argument is optional. If options is provided as a string, it
specifies the encoding. Otherwise options should be passed as an object.
The listener callback gets two arguments (eventType, filename). eventType
is either 'rename' or 'change', and filename is the name of the file
which triggered the event.
On most platforms, 'rename' is emitted whenever a filename appears or
disappears in the directory.
The listener callback is attached to the 'change' event fired by
<fs.FSWatcher>, but it is not the same thing as the 'change' value of
eventType.
If a signal is passed, aborting the corresponding AbortController will close
the returned <fs.FSWatcher>.

Caveats#

The fs.watch API is not 100% consistent across platforms, and is
unavailable in some situations.
On Windows, no events will be emitted if the watched directory is moved or
renamed. An EPERM error is reported when the watched directory is deleted.
The fs.watch API does not provide any protection with respect
to malicious actions on the file system. For example, on Windows it is
implemented by monitoring changes in a directory versus specific files. This
allows substitution of a file and fs reporting changes on the new file
with the same filename.

Availability#

This feature depends on the underlying operating system providing a way
to be notified of file system changes.

On Linux systems, this uses inotify(7).
On BSD systems, this uses kqueue(2).
On macOS, this uses kqueue(2) for files and FSEvents for
directories.
On SunOS systems (including Solaris and SmartOS), this uses event ports.
On Windows systems, this feature depends on ReadDirectoryChangesW.
On AIX systems, this feature depends on AHAFS, which must be enabled.
On IBM i systems, this feature is not supported.

If the underlying functionality is not available for some reason, then
fs.watch() will not be able to function and may throw an exception.
For example, watching files or directories can be unreliable, and in some
cases impossible, on network file systems (NFS, SMB, etc) or host file systems
when using virtualization software such as Vagrant or Docker.
It is still possible to use fs.watchFile(), which uses stat polling, but
this method is slower and less reliable.

Inodes#

On Linux and macOS systems, fs.watch() resolves the path to an inode and
watches the inode. If the watched path is deleted and recreated, it is assigned
a new inode. The watch will emit an event for the delete but will continue
watching the original inode. Events for the new inode will not be emitted.
This is expected behavior.
AIX files retain the same inode for the lifetime of a file. Saving and closing a
watched file on AIX will result in two notifications (one for adding new
content, and one for truncation).

Filename argument#

Providing filename argument in the callback is only supported on Linux,
macOS, Windows, and AIX. Even on supported platforms, filename is not always
guaranteed to be provided. Therefore, don't assume that filename argument is
always provided in the callback, and have some fallback logic if it is null.
import { watch } from 'node:fs';
watch('somedir', (eventType, filename) => {
  console.log(`event type is: ${eventType}`);
  if (filename) {
    console.log(`filename provided: ${filename}`);
  } else {
    console.log('filename not provided');
  }
}); copy

fs.watchFile(filename[, options], listener)#

History

VersionChanges
v10.5.0
The bigint option is now supported.
v7.6.0
The filename parameter can be a WHATWG URL object using file: protocol.
v0.1.31
Added in: v0.1.31




filename <string> | <Buffer> | <URL>
options <Object>

bigint <boolean> Default: false
persistent <boolean> Default: true
interval <integer> Default: 5007


listener <Function>

current <fs.Stats>
previous <fs.Stats>


Returns: <fs.StatWatcher>

Watch for changes on filename. The callback listener will be called each
time the file is accessed.
The options argument may be omitted. If provided, it should be an object. The
options object may contain a boolean named persistent that indicates
whether the process should continue to run as long as files are being watched.
The options object may specify an interval property indicating how often the
target should be polled in milliseconds.
The listener gets two arguments the current stat object and the previous
stat object:
import { watchFile } from 'node:fs';

watchFile('message.text', (curr, prev) => {
  console.log(`the current mtime is: ${curr.mtime}`);
  console.log(`the previous mtime was: ${prev.mtime}`);
}); copy
These stat objects are instances of fs.Stat. If the bigint option is true,
the numeric values in these objects are specified as BigInts.
To be notified when the file was modified, not just accessed, it is necessary
to compare curr.mtimeMs and prev.mtimeMs.
When an fs.watchFile operation results in an ENOENT error, it
will invoke the listener once, with all the fields zeroed (or, for dates, the
Unix Epoch). If the file is created later on, the listener will be called
again, with the latest stat objects. This is a change in functionality since
v0.10.
Using fs.watch() is more efficient than fs.watchFile and
fs.unwatchFile. fs.watch should be used instead of fs.watchFile and
fs.unwatchFile when possible.
When a file being watched by fs.watchFile() disappears and reappears,
then the contents of previous in the second callback event (the file's
reappearance) will be the same as the contents of previous in the first
callback event (its disappearance).
This happens when:

the file is deleted, followed by a restore
the file is renamed and then renamed a second time back to its original name


fs.write(fd, buffer, offset[, length[, position]], callback)#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v14.0.0
The buffer parameter won't coerce unsupported input to strings anymore.
v10.10.0
The buffer parameter can now be any TypedArray or a DataView.
v10.0.0
The callback parameter is no longer optional. Not passing it will throw a TypeError at runtime.
v7.4.0
The buffer parameter can now be a Uint8Array.
v7.2.0
The offset and length parameters are optional now.
v7.0.0
The callback parameter is no longer optional. Not passing it will emit a deprecation warning with id DEP0013.
v0.0.2
Added in: v0.0.2




fd <integer>
buffer <Buffer> | <TypedArray> | <DataView>
offset <integer> Default: 0
length <integer> Default: buffer.byteLength - offset
position <integer> | <null> Default: null
callback <Function>

err <Error>
bytesWritten <integer>
buffer <Buffer> | <TypedArray> | <DataView>



Write buffer to the file specified by fd.
offset determines the part of the buffer to be written, and length is
an integer specifying the number of bytes to write.
position refers to the offset from the beginning of the file where this data
should be written. If typeof position !== 'number', the data will be written
at the current position. See pwrite(2).
The callback will be given three arguments (err, bytesWritten, buffer) where
bytesWritten specifies how many bytes were written from buffer.
If this method is invoked as its util.promisify()ed version, it returns
a promise for an Object with bytesWritten and buffer properties.
It is unsafe to use fs.write() multiple times on the same file without waiting
for the callback. For this scenario, fs.createWriteStream() is
recommended.
On Linux, positional writes don't work when the file is opened in append mode.
The kernel ignores the position argument and always appends the data to
the end of the file.

fs.write(fd, buffer[, options], callback)#

Added in: v18.3.0, v16.17.0


fd <integer>
buffer <Buffer> | <TypedArray> | <DataView>
options <Object>

offset <integer> Default: 0
length <integer> Default: buffer.byteLength - offset
position <integer> | <null> Default: null


callback <Function>

err <Error>
bytesWritten <integer>
buffer <Buffer> | <TypedArray> | <DataView>



Write buffer to the file specified by fd.
Similar to the above fs.write function, this version takes an
optional options object. If no options object is specified, it will
default with the above values.

fs.write(fd, string[, position[, encoding]], callback)#

History

VersionChanges
v19.0.0
Passing to the string parameter an object with an own toString function is no longer supported.
v17.8.0
Passing to the string parameter an object with an own toString function is deprecated.
v14.12.0
The string parameter will stringify an object with an explicit toString function.
v14.0.0
The string parameter won't coerce unsupported input to strings anymore.
v10.0.0
The callback parameter is no longer optional. Not passing it will throw a TypeError at runtime.
v7.2.0
The position parameter is optional now.
v7.0.0
The callback parameter is no longer optional. Not passing it will emit a deprecation warning with id DEP0013.
v0.11.5
Added in: v0.11.5




fd <integer>
string <string>
position <integer> | <null> Default: null
encoding <string> Default: 'utf8'
callback <Function>

err <Error>
written <integer>
string <string>



Write string to the file specified by fd. If string is not a string,
an exception is thrown.
position refers to the offset from the beginning of the file where this data
should be written. If typeof position !== 'number' the data will be written at
the current position. See pwrite(2).
encoding is the expected string encoding.
The callback will receive the arguments (err, written, string) where written
specifies how many bytes the passed string required to be written. Bytes
written is not necessarily the same as string characters written. See
Buffer.byteLength.
It is unsafe to use fs.write() multiple times on the same file without waiting
for the callback. For this scenario, fs.createWriteStream() is
recommended.
On Linux, positional writes don't work when the file is opened in append mode.
The kernel ignores the position argument and always appends the data to
the end of the file.
On Windows, if the file descriptor is connected to the console (e.g. fd == 1
or stdout) a string containing non-ASCII characters will not be rendered
properly by default, regardless of the encoding used.
It is possible to configure the console to render UTF-8 properly by changing the
active codepage with the chcp 65001 command. See the chcp docs for more
details.

fs.writeFile(file, data[, options], callback)#

History

VersionChanges
v21.0.0, v20.10.0
The flush option is now supported.
v19.0.0
Passing to the string parameter an object with an own toString function is no longer supported.
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v17.8.0
Passing to the string parameter an object with an own toString function is deprecated.
v16.0.0
The error returned may be an AggregateError if more than one error is returned.
v15.2.0, v14.17.0
The options argument may include an AbortSignal to abort an ongoing writeFile request.
v14.12.0
The data parameter will stringify an object with an explicit toString function.
v14.0.0
The data parameter won't coerce unsupported input to strings anymore.
v10.10.0
The data parameter can now be any TypedArray or a DataView.
v10.0.0
The callback parameter is no longer optional. Not passing it will throw a TypeError at runtime.
v7.4.0
The data parameter can now be a Uint8Array.
v7.0.0
The callback parameter is no longer optional. Not passing it will emit a deprecation warning with id DEP0013.
v5.0.0
The file parameter can be a file descriptor now.
v0.1.29
Added in: v0.1.29




file <string> | <Buffer> | <URL> | <integer> filename or file descriptor
data <string> | <Buffer> | <TypedArray> | <DataView>
options <Object> | <string>

encoding <string> | <null> Default: 'utf8'
mode <integer> Default: 0o666
flag <string> See support of file system flags. Default: 'w'.
flush <boolean> If all data is successfully written to the file, and
flush is true, fs.fsync() is used to flush the data.
Default: false.
signal <AbortSignal> allows aborting an in-progress writeFile


callback <Function>

err <Error> | <AggregateError>



When file is a filename, asynchronously writes data to the file, replacing the
file if it already exists. data can be a string or a buffer.
When file is a file descriptor, the behavior is similar to calling
fs.write() directly (which is recommended). See the notes below on using
a file descriptor.
The encoding option is ignored if data is a buffer.
The mode option only affects the newly created file. See fs.open()
for more details.
import { writeFile } from 'node:fs';
import { Buffer } from 'node:buffer';

const data = new Uint8Array(Buffer.from('Hello Node.js'));
writeFile('message.txt', data, (err) => {
  if (err) throw err;
  console.log('The file has been saved!');
}); copy
If options is a string, then it specifies the encoding:
import { writeFile } from 'node:fs';

writeFile('message.txt', 'Hello Node.js', 'utf8', callback); copy
It is unsafe to use fs.writeFile() multiple times on the same file without
waiting for the callback. For this scenario, fs.createWriteStream() is
recommended.
Similarly to fs.readFile - fs.writeFile is a convenience method that
performs multiple write calls internally to write the buffer passed to it.
For performance sensitive code consider using fs.createWriteStream().
It is possible to use an <AbortSignal> to cancel an fs.writeFile().
Cancelation is "best effort", and some amount of data is likely still
to be written.
import { writeFile } from 'node:fs';
import { Buffer } from 'node:buffer';

const controller = new AbortController();
const { signal } = controller;
const data = new Uint8Array(Buffer.from('Hello Node.js'));
writeFile('message.txt', data, { signal }, (err) => {
  // When a request is aborted - the callback is called with an AbortError
});
// When the request should be aborted
controller.abort(); copy
Aborting an ongoing request does not abort individual operating
system requests but rather the internal buffering fs.writeFile performs.

Using fs.writeFile() with file descriptors#
When file is a file descriptor, the behavior is almost identical to directly
calling fs.write() like:
import { write } from 'node:fs';
import { Buffer } from 'node:buffer';

write(fd, Buffer.from(data, options.encoding), callback); copy
The difference from directly calling fs.write() is that under some unusual
conditions, fs.write() might write only part of the buffer and need to be
retried to write the remaining data, whereas fs.writeFile() retries until
the data is entirely written (or an error occurs).
The implications of this are a common source of confusion. In
the file descriptor case, the file is not replaced! The data is not necessarily
written to the beginning of the file, and the file's original data may remain
before and/or after the newly written data.
For example, if fs.writeFile() is called twice in a row, first to write the
string 'Hello', then to write the string ', World', the file would contain
'Hello, World', and might contain some of the file's original data (depending
on the size of the original file, and the position of the file descriptor). If
a file name had been used instead of a descriptor, the file would be guaranteed
to contain only ', World'.

fs.writev(fd, buffers[, position], callback)#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v12.9.0
Added in: v12.9.0




fd <integer>
buffers <ArrayBufferView[]>
position <integer> | <null> Default: null
callback <Function>

err <Error>
bytesWritten <integer>
buffers <ArrayBufferView[]>



Write an array of ArrayBufferViews to the file specified by fd using
writev().
position is the offset from the beginning of the file where this data
should be written. If typeof position !== 'number', the data will be written
at the current position.
The callback will be given three arguments: err, bytesWritten, and
buffers. bytesWritten is how many bytes were written from buffers.
If this method is util.promisify()ed, it returns a promise for an
Object with bytesWritten and buffers properties.
It is unsafe to use fs.writev() multiple times on the same file without
waiting for the callback. For this scenario, use fs.createWriteStream().
On Linux, positional writes don't work when the file is opened in append mode.
The kernel ignores the position argument and always appends the data to
the end of the file.

Synchronous API#
The synchronous APIs perform all operations synchronously, blocking the
event loop until the operation completes or fails.

fs.accessSync(path[, mode])#

History

VersionChanges
v7.6.0
The path parameter can be a WHATWG URL object using file: protocol.
v0.11.15
Added in: v0.11.15




path <string> | <Buffer> | <URL>
mode <integer> Default: fs.constants.F_OK

Synchronously tests a user's permissions for the file or directory specified
by path. The mode argument is an optional integer that specifies the
accessibility checks to be performed. mode should be either the value
fs.constants.F_OK or a mask consisting of the bitwise OR of any of
fs.constants.R_OK, fs.constants.W_OK, and fs.constants.X_OK (e.g.
fs.constants.W_OK | fs.constants.R_OK). Check File access constants for
possible values of mode.
If any of the accessibility checks fail, an Error will be thrown. Otherwise,
the method will return undefined.
import { accessSync, constants } from 'node:fs';

try {
  accessSync('etc/passwd', constants.R_OK | constants.W_OK);
  console.log('can read/write');
} catch (err) {
  console.error('no access!');
} copy

fs.appendFileSync(path, data[, options])#

History

VersionChanges
v21.1.0, v20.10.0
The flush option is now supported.
v7.0.0
The passed options object will never be modified.
v5.0.0
The file parameter can be a file descriptor now.
v0.6.7
Added in: v0.6.7




path <string> | <Buffer> | <URL> | <number> filename or file descriptor
data <string> | <Buffer>
options <Object> | <string>

encoding <string> | <null> Default: 'utf8'
mode <integer> Default: 0o666
flag <string> See support of file system flags. Default: 'a'.
flush <boolean> If true, the underlying file descriptor is flushed
prior to closing it. Default: false.



Synchronously append data to a file, creating the file if it does not yet
exist. data can be a string or a <Buffer>.
The mode option only affects the newly created file. See fs.open()
for more details.
import { appendFileSync } from 'node:fs';

try {
  appendFileSync('message.txt', 'data to append');
  console.log('The "data to append" was appended to file!');
} catch (err) {
  /* Handle the error */
} copy
If options is a string, then it specifies the encoding:
import { appendFileSync } from 'node:fs';

appendFileSync('message.txt', 'data to append', 'utf8'); copy
The path may be specified as a numeric file descriptor that has been opened
for appending (using fs.open() or fs.openSync()). The file descriptor will
not be closed automatically.
import { openSync, closeSync, appendFileSync } from 'node:fs';

let fd;

try {
  fd = openSync('message.txt', 'a');
  appendFileSync(fd, 'data to append', 'utf8');
} catch (err) {
  /* Handle the error */
} finally {
  if (fd !== undefined)
    closeSync(fd);
} copy

fs.chmodSync(path, mode)#

History

VersionChanges
v7.6.0
The path parameter can be a WHATWG URL object using file: protocol.
v0.6.7
Added in: v0.6.7




path <string> | <Buffer> | <URL>
mode <string> | <integer>

For detailed information, see the documentation of the asynchronous version of
this API: fs.chmod().
See the POSIX chmod(2) documentation for more detail.

fs.chownSync(path, uid, gid)#

History

VersionChanges
v7.6.0
The path parameter can be a WHATWG URL object using file: protocol.
v0.1.97
Added in: v0.1.97




path <string> | <Buffer> | <URL>
uid <integer>
gid <integer>

Synchronously changes owner and group of a file. Returns undefined.
This is the synchronous version of fs.chown().
See the POSIX chown(2) documentation for more detail.

fs.closeSync(fd)#

Added in: v0.1.21


fd <integer>

Closes the file descriptor. Returns undefined.
Calling fs.closeSync() on any file descriptor (fd) that is currently in use
through any other fs operation may lead to undefined behavior.
See the POSIX close(2) documentation for more detail.

fs.copyFileSync(src, dest[, mode])#

History

VersionChanges
v14.0.0
Changed flags argument to mode and imposed stricter type validation.
v8.5.0
Added in: v8.5.0




src <string> | <Buffer> | <URL> source filename to copy
dest <string> | <Buffer> | <URL> destination filename of the copy operation
mode <integer> modifiers for copy operation. Default: 0.

Synchronously copies src to dest. By default, dest is overwritten if it
already exists. Returns undefined. Node.js makes no guarantees about the
atomicity of the copy operation. If an error occurs after the destination file
has been opened for writing, Node.js will attempt to remove the destination.
mode is an optional integer that specifies the behavior
of the copy operation. It is possible to create a mask consisting of the bitwise
OR of two or more values (e.g.
fs.constants.COPYFILE_EXCL | fs.constants.COPYFILE_FICLONE).

fs.constants.COPYFILE_EXCL: The copy operation will fail if dest already
exists.
fs.constants.COPYFILE_FICLONE: The copy operation will attempt to create a
copy-on-write reflink. If the platform does not support copy-on-write, then a
fallback copy mechanism is used.
fs.constants.COPYFILE_FICLONE_FORCE: The copy operation will attempt to
create a copy-on-write reflink. If the platform does not support
copy-on-write, then the operation will fail.

import { copyFileSync, constants } from 'node:fs';

// destination.txt will be created or overwritten by default.
copyFileSync('source.txt', 'destination.txt');
console.log('source.txt was copied to destination.txt');

// By using COPYFILE_EXCL, the operation will fail if destination.txt exists.
copyFileSync('source.txt', 'destination.txt', constants.COPYFILE_EXCL); copy

fs.cpSync(src, dest[, options])#

History

VersionChanges
v22.3.0
This API is no longer experimental.
v20.1.0, v18.17.0
Accept an additional mode option to specify the copy behavior as the mode argument of fs.copyFile().
v17.6.0, v16.15.0
Accepts an additional verbatimSymlinks option to specify whether to perform path resolution for symlinks.
v16.7.0
Added in: v16.7.0




src <string> | <URL> source path to copy.
dest <string> | <URL> destination path to copy to.
options <Object>

dereference <boolean> dereference symlinks. Default: false.
errorOnExist <boolean> when force is false, and the destination
exists, throw an error. Default: false.
filter <Function> Function to filter copied files/directories. Return
true to copy the item, false to ignore it. When ignoring a directory,
all of its contents will be skipped as well. Default: undefined

src <string> source path to copy.
dest <string> destination path to copy to.
Returns: <boolean> Any non-Promise value that is coercible
to boolean.


force <boolean> overwrite existing file or directory. The copy
operation will ignore errors if you set this to false and the destination
exists. Use the errorOnExist option to change this behavior.
Default: true.
mode <integer> modifiers for copy operation. Default: 0.
See mode flag of fs.copyFileSync().
preserveTimestamps <boolean> When true timestamps from src will
be preserved. Default: false.
recursive <boolean> copy directories recursively Default: false
verbatimSymlinks <boolean> When true, path resolution for symlinks will
be skipped. Default: false



Synchronously copies the entire directory structure from src to dest,
including subdirectories and files.
When copying a directory to another directory, globs are not supported and
behavior is similar to cp dir1/ dir2/.

fs.existsSync(path)#

History

VersionChanges
v7.6.0
The path parameter can be a WHATWG URL object using file: protocol.
v0.1.21
Added in: v0.1.21




path <string> | <Buffer> | <URL>
Returns: <boolean>

Returns true if the path exists, false otherwise.
For detailed information, see the documentation of the asynchronous version of
this API: fs.exists().
fs.exists() is deprecated, but fs.existsSync() is not. The callback
parameter to fs.exists() accepts parameters that are inconsistent with other
Node.js callbacks. fs.existsSync() does not use a callback.
import { existsSync } from 'node:fs';

if (existsSync('/etc/passwd'))
  console.log('The path exists.'); copy

fs.fchmodSync(fd, mode)#

Added in: v0.4.7


fd <integer>
mode <string> | <integer>

Sets the permissions on the file. Returns undefined.
See the POSIX fchmod(2) documentation for more detail.

fs.fchownSync(fd, uid, gid)#

Added in: v0.4.7


fd <integer>
uid <integer> The file's new owner's user id.
gid <integer> The file's new group's group id.

Sets the owner of the file. Returns undefined.
See the POSIX fchown(2) documentation for more detail.

fs.fdatasyncSync(fd)#

Added in: v0.1.96


fd <integer>

Forces all currently queued I/O operations associated with the file to the
operating system's synchronized I/O completion state. Refer to the POSIX
fdatasync(2) documentation for details. Returns undefined.

fs.fstatSync(fd[, options])#

History

VersionChanges
v10.5.0
Accepts an additional options object to specify whether the numeric values returned should be bigint.
v0.1.95
Added in: v0.1.95




fd <integer>
options <Object>

bigint <boolean> Whether the numeric values in the returned
<fs.Stats> object should be bigint. Default: false.


Returns: <fs.Stats>

Retrieves the <fs.Stats> for the file descriptor.
See the POSIX fstat(2) documentation for more detail.

fs.fsyncSync(fd)#

Added in: v0.1.96


fd <integer>

Request that all data for the open file descriptor is flushed to the storage
device. The specific implementation is operating system and device specific.
Refer to the POSIX fsync(2) documentation for more detail. Returns undefined.

fs.ftruncateSync(fd[, len])#

Added in: v0.8.6


fd <integer>
len <integer> Default: 0

Truncates the file descriptor. Returns undefined.
For detailed information, see the documentation of the asynchronous version of
this API: fs.ftruncate().

fs.futimesSync(fd, atime, mtime)#

History

VersionChanges
v4.1.0
Numeric strings, NaN, and Infinity are now allowed time specifiers.
v0.4.2
Added in: v0.4.2




fd <integer>
atime <number> | <string> | <Date>
mtime <number> | <string> | <Date>

Synchronous version of fs.futimes(). Returns undefined.

fs.globSync(pattern[, options])#

History

VersionChanges
v24.0.0
Marking the API stable.
v23.7.0, v22.14.0
Add support for exclude option to accept glob patterns.
v22.2.0
Add support for withFileTypes as an option.
v22.0.0
Added in: v22.0.0




pattern <string> | <string[]>
options <Object>

cwd <string> current working directory. Default: process.cwd()
exclude <Function> | <string[]> Function to filter out files/directories or a
list of glob patterns to be excluded. If a function is provided, return
true to exclude the item, false to include it. Default: undefined.
withFileTypes <boolean> true if the glob should return paths as Dirents,
false otherwise. Default: false.


Returns: <string[]> paths of files that match the pattern.


import { globSync } from 'node:fs';

console.log(globSync('**/*.js'));const { globSync } = require('node:fs');

console.log(globSync('**/*.js'));copy

fs.lchmodSync(path, mode)#

Deprecated since: v0.4.7

Stability: 0 - Deprecated

path <string> | <Buffer> | <URL>
mode <integer>

Changes the permissions on a symbolic link. Returns undefined.
This method is only implemented on macOS.
See the POSIX lchmod(2) documentation for more detail.

fs.lchownSync(path, uid, gid)#

History

VersionChanges
v10.6.0
This API is no longer deprecated.
v0.4.7
Documentation-only deprecation.




path <string> | <Buffer> | <URL>
uid <integer> The file's new owner's user id.
gid <integer> The file's new group's group id.

Set the owner for the path. Returns undefined.
See the POSIX lchown(2) documentation for more details.

fs.lutimesSync(path, atime, mtime)#

Added in: v14.5.0, v12.19.0


path <string> | <Buffer> | <URL>
atime <number> | <string> | <Date>
mtime <number> | <string> | <Date>

Change the file system timestamps of the symbolic link referenced by path.
Returns undefined, or throws an exception when parameters are incorrect or
the operation fails. This is the synchronous version of fs.lutimes().

fs.linkSync(existingPath, newPath)#

History

VersionChanges
v7.6.0
The existingPath and newPath parameters can be WHATWG URL objects using file: protocol. Support is currently still experimental.
v0.1.31
Added in: v0.1.31




existingPath <string> | <Buffer> | <URL>
newPath <string> | <Buffer> | <URL>

Creates a new link from the existingPath to the newPath. See the POSIX
link(2) documentation for more detail. Returns undefined.

fs.lstatSync(path[, options])#

History

VersionChanges
v15.3.0, v14.17.0
Accepts a throwIfNoEntry option to specify whether an exception should be thrown if the entry does not exist.
v10.5.0
Accepts an additional options object to specify whether the numeric values returned should be bigint.
v7.6.0
The path parameter can be a WHATWG URL object using file: protocol.
v0.1.30
Added in: v0.1.30




path <string> | <Buffer> | <URL>
options <Object>

bigint <boolean> Whether the numeric values in the returned
<fs.Stats> object should be bigint. Default: false.
throwIfNoEntry <boolean> Whether an exception will be thrown
if no file system entry exists, rather than returning undefined.
Default: true.


Returns: <fs.Stats>

Retrieves the <fs.Stats> for the symbolic link referred to by path.
See the POSIX lstat(2) documentation for more details.

fs.mkdirSync(path[, options])#

History

VersionChanges
v13.11.0, v12.17.0
In recursive mode, the first created path is returned now.
v10.12.0
The second argument can now be an options object with recursive and mode properties.
v7.6.0
The path parameter can be a WHATWG URL object using file: protocol.
v0.1.21
Added in: v0.1.21




path <string> | <Buffer> | <URL>
options <Object> | <integer>

recursive <boolean> Default: false
mode <string> | <integer> Not supported on Windows. Default: 0o777.


Returns: <string> | <undefined>

Synchronously creates a directory. Returns undefined, or if recursive is
true, the first directory path created.
This is the synchronous version of fs.mkdir().
See the POSIX mkdir(2) documentation for more details.

fs.mkdtempSync(prefix[, options])#

History

VersionChanges
v20.6.0, v18.19.0
The prefix parameter now accepts buffers and URL.
v16.5.0, v14.18.0
The prefix parameter now accepts an empty string.
v5.10.0
Added in: v5.10.0




prefix <string> | <Buffer> | <URL>
options <string> | <Object>

encoding <string> Default: 'utf8'


Returns: <string>

Returns the created directory path.
For detailed information, see the documentation of the asynchronous version of
this API: fs.mkdtemp().
The optional options argument can be a string specifying an encoding, or an
object with an encoding property specifying the character encoding to use.

fs.opendirSync(path[, options])#

History

VersionChanges
v20.1.0, v18.17.0
Added recursive option.
v13.1.0, v12.16.0
The bufferSize option was introduced.
v12.12.0
Added in: v12.12.0




path <string> | <Buffer> | <URL>
options <Object>

encoding <string> | <null> Default: 'utf8'
bufferSize <number> Number of directory entries that are buffered
internally when reading from the directory. Higher values lead to better
performance but higher memory usage. Default: 32
recursive <boolean> Default: false


Returns: <fs.Dir>

Synchronously open a directory. See opendir(3).
Creates an <fs.Dir>, which contains all further functions for reading from
and cleaning up the directory.
The encoding option sets the encoding for the path while opening the
directory and subsequent read operations.

fs.openSync(path[, flags[, mode]])#

History

VersionChanges
v11.1.0
The flags argument is now optional and defaults to 'r'.
v9.9.0
The as and as+ flags are supported now.
v7.6.0
The path parameter can be a WHATWG URL object using file: protocol.
v0.1.21
Added in: v0.1.21




path <string> | <Buffer> | <URL>
flags <string> | <number> Default: 'r'.
See support of file system flags.
mode <string> | <integer> Default: 0o666
Returns: <number>

Returns an integer representing the file descriptor.
For detailed information, see the documentation of the asynchronous version of
this API: fs.open().

fs.readdirSync(path[, options])#

History

VersionChanges
v20.1.0, v18.17.0
Added recursive option.
v10.10.0
New option withFileTypes was added.
v7.6.0
The path parameter can be a WHATWG URL object using file: protocol.
v0.1.21
Added in: v0.1.21




path <string> | <Buffer> | <URL>
options <string> | <Object>

encoding <string> Default: 'utf8'
withFileTypes <boolean> Default: false
recursive <boolean> If true, reads the contents of a directory
recursively. In recursive mode, it will list all files, sub files, and
directories. Default: false.


Returns: <string[]> | <Buffer[]> | <fs.Dirent[]>

Reads the contents of the directory.
See the POSIX readdir(3) documentation for more details.
The optional options argument can be a string specifying an encoding, or an
object with an encoding property specifying the character encoding to use for
the filenames returned. If the encoding is set to 'buffer',
the filenames returned will be passed as <Buffer> objects.
If options.withFileTypes is set to true, the result will contain
<fs.Dirent> objects.

fs.readFileSync(path[, options])#

History

VersionChanges
v7.6.0
The path parameter can be a WHATWG URL object using file: protocol.
v5.0.0
The path parameter can be a file descriptor now.
v0.1.8
Added in: v0.1.8




path <string> | <Buffer> | <URL> | <integer> filename or file descriptor
options <Object> | <string>

encoding <string> | <null> Default: null
flag <string> See support of file system flags. Default: 'r'.


Returns: <string> | <Buffer>

Returns the contents of the path.
For detailed information, see the documentation of the asynchronous version of
this API: fs.readFile().
If the encoding option is specified then this function returns a
string. Otherwise it returns a buffer.
Similar to fs.readFile(), when the path is a directory, the behavior of
fs.readFileSync() is platform-specific.
import { readFileSync } from 'node:fs';

// macOS, Linux, and Windows
readFileSync('<directory>');
// => [Error: EISDIR: illegal operation on a directory, read <directory>]

//  FreeBSD
readFileSync('<directory>'); // => <data> copy

fs.readlinkSync(path[, options])#

History

VersionChanges
v7.6.0
The path parameter can be a WHATWG URL object using file: protocol.
v0.1.31
Added in: v0.1.31




path <string> | <Buffer> | <URL>
options <string> | <Object>

encoding <string> Default: 'utf8'


Returns: <string> | <Buffer>

Returns the symbolic link's string value.
See the POSIX readlink(2) documentation for more details.
The optional options argument can be a string specifying an encoding, or an
object with an encoding property specifying the character encoding to use for
the link path returned. If the encoding is set to 'buffer',
the link path returned will be passed as a <Buffer> object.

fs.readSync(fd, buffer, offset, length[, position])#

History

VersionChanges
v10.10.0
The buffer parameter can now be any TypedArray or a DataView.
v6.0.0
The length parameter can now be 0.
v0.1.21
Added in: v0.1.21




fd <integer>
buffer <Buffer> | <TypedArray> | <DataView>
offset <integer>
length <integer>
position <integer> | <bigint> | <null> Default: null
Returns: <number>

Returns the number of bytesRead.
For detailed information, see the documentation of the asynchronous version of
this API: fs.read().

fs.readSync(fd, buffer[, options])#

History

VersionChanges
v13.13.0, v12.17.0
Options object can be passed in to make offset, length, and position optional.
v13.13.0, v12.17.0
Added in: v13.13.0, v12.17.0




fd <integer>
buffer <Buffer> | <TypedArray> | <DataView>
options <Object>

offset <integer> Default: 0
length <integer> Default: buffer.byteLength - offset
position <integer> | <bigint> | <null> Default: null


Returns: <number>

Returns the number of bytesRead.
Similar to the above fs.readSync function, this version takes an optional options object.
If no options object is specified, it will default with the above values.
For detailed information, see the documentation of the asynchronous version of
this API: fs.read().

fs.readvSync(fd, buffers[, position])#

Added in: v13.13.0, v12.17.0


fd <integer>
buffers <ArrayBufferView[]>
position <integer> | <null> Default: null
Returns: <number> The number of bytes read.

For detailed information, see the documentation of the asynchronous version of
this API: fs.readv().

fs.realpathSync(path[, options])#

History

VersionChanges
v8.0.0
Pipe/Socket resolve support was added.
v7.6.0
The path parameter can be a WHATWG URL object using file: protocol.
v6.4.0
Calling realpathSync now works again for various edge cases on Windows.
v6.0.0
The cache parameter was removed.
v0.1.31
Added in: v0.1.31




path <string> | <Buffer> | <URL>
options <string> | <Object>

encoding <string> Default: 'utf8'


Returns: <string> | <Buffer>

Returns the resolved pathname.
For detailed information, see the documentation of the asynchronous version of
this API: fs.realpath().

fs.realpathSync.native(path[, options])#

Added in: v9.2.0


path <string> | <Buffer> | <URL>
options <string> | <Object>

encoding <string> Default: 'utf8'


Returns: <string> | <Buffer>

Synchronous realpath(3).
Only paths that can be converted to UTF8 strings are supported.
The optional options argument can be a string specifying an encoding, or an
object with an encoding property specifying the character encoding to use for
the path returned. If the encoding is set to 'buffer',
the path returned will be passed as a <Buffer> object.
On Linux, when Node.js is linked against musl libc, the procfs file system must
be mounted on /proc in order for this function to work. Glibc does not have
this restriction.

fs.renameSync(oldPath, newPath)#

History

VersionChanges
v7.6.0
The oldPath and newPath parameters can be WHATWG URL objects using file: protocol. Support is currently still experimental.
v0.1.21
Added in: v0.1.21




oldPath <string> | <Buffer> | <URL>
newPath <string> | <Buffer> | <URL>

Renames the file from oldPath to newPath. Returns undefined.
See the POSIX rename(2) documentation for more details.

fs.rmdirSync(path[, options])#

History

VersionChanges
v16.0.0
Using fs.rmdirSync(path, { recursive: true }) on a path that is a file is no longer permitted and results in an ENOENT error on Windows and an ENOTDIR error on POSIX.
v16.0.0
Using fs.rmdirSync(path, { recursive: true }) on a path that does not exist is no longer permitted and results in a ENOENT error.
v16.0.0
The recursive option is deprecated, using it triggers a deprecation warning.
v14.14.0
The recursive option is deprecated, use fs.rmSync instead.
v13.3.0, v12.16.0
The maxBusyTries option is renamed to maxRetries, and its default is 0. The emfileWait option has been removed, and EMFILE errors use the same retry logic as other errors. The retryDelay option is now supported. ENFILE errors are now retried.
v12.10.0
The recursive, maxBusyTries, and emfileWait options are now supported.
v7.6.0
The path parameters can be a WHATWG URL object using file: protocol.
v0.1.21
Added in: v0.1.21




path <string> | <Buffer> | <URL>
options <Object>

maxRetries <integer> If an EBUSY, EMFILE, ENFILE, ENOTEMPTY, or
EPERM error is encountered, Node.js retries the operation with a linear
backoff wait of retryDelay milliseconds longer on each try. This option
represents the number of retries. This option is ignored if the recursive
option is not true. Default: 0.
recursive <boolean> If true, perform a recursive directory removal. In
recursive mode, operations are retried on failure. Default: false.
Deprecated.
retryDelay <integer> The amount of time in milliseconds to wait between
retries. This option is ignored if the recursive option is not true.
Default: 100.



Synchronous rmdir(2). Returns undefined.
Using fs.rmdirSync() on a file (not a directory) results in an ENOENT error
on Windows and an ENOTDIR error on POSIX.
To get a behavior similar to the rm -rf Unix command, use fs.rmSync()
with options { recursive: true, force: true }.

fs.rmSync(path[, options])#

History

VersionChanges
v17.3.0, v16.14.0
The path parameter can be a WHATWG URL object using file: protocol.
v14.14.0
Added in: v14.14.0




path <string> | <Buffer> | <URL>
options <Object>

force <boolean> When true, exceptions will be ignored if path does
not exist. Default: false.
maxRetries <integer> If an EBUSY, EMFILE, ENFILE, ENOTEMPTY, or
EPERM error is encountered, Node.js will retry the operation with a linear
backoff wait of retryDelay milliseconds longer on each try. This option
represents the number of retries. This option is ignored if the recursive
option is not true. Default: 0.
recursive <boolean> If true, perform a recursive directory removal. In
recursive mode operations are retried on failure. Default: false.
retryDelay <integer> The amount of time in milliseconds to wait between
retries. This option is ignored if the recursive option is not true.
Default: 100.



Synchronously removes files and directories (modeled on the standard POSIX rm
utility). Returns undefined.

fs.statSync(path[, options])#

History

VersionChanges
v15.3.0, v14.17.0
Accepts a throwIfNoEntry option to specify whether an exception should be thrown if the entry does not exist.
v10.5.0
Accepts an additional options object to specify whether the numeric values returned should be bigint.
v7.6.0
The path parameter can be a WHATWG URL object using file: protocol.
v0.1.21
Added in: v0.1.21




path <string> | <Buffer> | <URL>
options <Object>

bigint <boolean> Whether the numeric values in the returned
<fs.Stats> object should be bigint. Default: false.
throwIfNoEntry <boolean> Whether an exception will be thrown
if no file system entry exists, rather than returning undefined.
Default: true.


Returns: <fs.Stats>

Retrieves the <fs.Stats> for the path.

fs.statfsSync(path[, options])#

Added in: v19.6.0, v18.15.0


path <string> | <Buffer> | <URL>
options <Object>

bigint <boolean> Whether the numeric values in the returned
<fs.StatFs> object should be bigint. Default: false.


Returns: <fs.StatFs>

Synchronous statfs(2). Returns information about the mounted file system which
contains path.
In case of an error, the err.code will be one of Common System Errors.

fs.symlinkSync(target, path[, type])#

History

VersionChanges
v12.0.0
If the type argument is left undefined, Node will autodetect target type and automatically select dir or file.
v7.6.0
The target and path parameters can be WHATWG URL objects using file: protocol. Support is currently still experimental.
v0.1.31
Added in: v0.1.31




target <string> | <Buffer> | <URL>
path <string> | <Buffer> | <URL>
type <string> | <null> Default: null

Returns undefined.
For detailed information, see the documentation of the asynchronous version of
this API: fs.symlink().

fs.truncateSync(path[, len])#

Added in: v0.8.6


path <string> | <Buffer> | <URL>
len <integer> Default: 0

Truncates the file. Returns undefined. A file descriptor can also be
passed as the first argument. In this case, fs.ftruncateSync() is called.
Passing a file descriptor is deprecated and may result in an error being thrown
in the future.

fs.unlinkSync(path)#

History

VersionChanges
v7.6.0
The path parameter can be a WHATWG URL object using file: protocol.
v0.1.21
Added in: v0.1.21




path <string> | <Buffer> | <URL>

Synchronous unlink(2). Returns undefined.

fs.utimesSync(path, atime, mtime)#

History

VersionChanges
v8.0.0
NaN, Infinity, and -Infinity are no longer valid time specifiers.
v7.6.0
The path parameter can be a WHATWG URL object using file: protocol.
v4.1.0
Numeric strings, NaN, and Infinity are now allowed time specifiers.
v0.4.2
Added in: v0.4.2




path <string> | <Buffer> | <URL>
atime <number> | <string> | <Date>
mtime <number> | <string> | <Date>

Returns undefined.
For detailed information, see the documentation of the asynchronous version of
this API: fs.utimes().

fs.writeFileSync(file, data[, options])#

History

VersionChanges
v21.0.0, v20.10.0
The flush option is now supported.
v19.0.0
Passing to the data parameter an object with an own toString function is no longer supported.
v17.8.0
Passing to the data parameter an object with an own toString function is deprecated.
v14.12.0
The data parameter will stringify an object with an explicit toString function.
v14.0.0
The data parameter won't coerce unsupported input to strings anymore.
v10.10.0
The data parameter can now be any TypedArray or a DataView.
v7.4.0
The data parameter can now be a Uint8Array.
v5.0.0
The file parameter can be a file descriptor now.
v0.1.29
Added in: v0.1.29




file <string> | <Buffer> | <URL> | <integer> filename or file descriptor
data <string> | <Buffer> | <TypedArray> | <DataView>
options <Object> | <string>

encoding <string> | <null> Default: 'utf8'
mode <integer> Default: 0o666
flag <string> See support of file system flags. Default: 'w'.
flush <boolean> If all data is successfully written to the file, and
flush is true, fs.fsyncSync() is used to flush the data.



Returns undefined.
The mode option only affects the newly created file. See fs.open()
for more details.
For detailed information, see the documentation of the asynchronous version of
this API: fs.writeFile().

fs.writeSync(fd, buffer, offset[, length[, position]])#

History

VersionChanges
v14.0.0
The buffer parameter won't coerce unsupported input to strings anymore.
v10.10.0
The buffer parameter can now be any TypedArray or a DataView.
v7.4.0
The buffer parameter can now be a Uint8Array.
v7.2.0
The offset and length parameters are optional now.
v0.1.21
Added in: v0.1.21




fd <integer>
buffer <Buffer> | <TypedArray> | <DataView>
offset <integer> Default: 0
length <integer> Default: buffer.byteLength - offset
position <integer> | <null> Default: null
Returns: <number> The number of bytes written.

For detailed information, see the documentation of the asynchronous version of
this API: fs.write(fd, buffer...).

fs.writeSync(fd, buffer[, options])#

Added in: v18.3.0, v16.17.0


fd <integer>
buffer <Buffer> | <TypedArray> | <DataView>
options <Object>

offset <integer> Default: 0
length <integer> Default: buffer.byteLength - offset
position <integer> | <null> Default: null


Returns: <number> The number of bytes written.

For detailed information, see the documentation of the asynchronous version of
this API: fs.write(fd, buffer...).

fs.writeSync(fd, string[, position[, encoding]])#

History

VersionChanges
v14.0.0
The string parameter won't coerce unsupported input to strings anymore.
v7.2.0
The position parameter is optional now.
v0.11.5
Added in: v0.11.5




fd <integer>
string <string>
position <integer> | <null> Default: null
encoding <string> Default: 'utf8'
Returns: <number> The number of bytes written.

For detailed information, see the documentation of the asynchronous version of
this API: fs.write(fd, string...).

fs.writevSync(fd, buffers[, position])#

Added in: v12.9.0


fd <integer>
buffers <ArrayBufferView[]>
position <integer> | <null> Default: null
Returns: <number> The number of bytes written.

For detailed information, see the documentation of the asynchronous version of
this API: fs.writev().

Common Objects#
The common objects are shared by all of the file system API variants
(promise, callback, and synchronous).

Class: fs.Dir#

Added in: v12.12.0

A class representing a directory stream.
Created by fs.opendir(), fs.opendirSync(), or
fsPromises.opendir().
import { opendir } from 'node:fs/promises';

try {
  const dir = await opendir('./');
  for await (const dirent of dir)
    console.log(dirent.name);
} catch (err) {
  console.error(err);
} copy
When using the async iterator, the <fs.Dir> object will be automatically
closed after the iterator exits.

dir.close()#

Added in: v12.12.0


Returns: <Promise>

Asynchronously close the directory's underlying resource handle.
Subsequent reads will result in errors.
A promise is returned that will be fulfilled after the resource has been
closed.

dir.close(callback)#

History

VersionChanges
v18.0.0
Passing an invalid callback to the callback argument now throws ERR_INVALID_ARG_TYPE instead of ERR_INVALID_CALLBACK.
v12.12.0
Added in: v12.12.0




callback <Function>

err <Error>



Asynchronously close the directory's underlying resource handle.
Subsequent reads will result in errors.
The callback will be called after the resource handle has been closed.

dir.closeSync()#

Added in: v12.12.0

Synchronously close the directory's underlying resource handle.
Subsequent reads will result in errors.

dir.path#

Added in: v12.12.0


<string>

The read-only path of this directory as was provided to fs.opendir(),
fs.opendirSync(), or fsPromises.opendir().

dir.read()#

Added in: v12.12.0


Returns: <Promise> Fulfills with a <fs.Dirent> | <null>

Asynchronously read the next directory entry via readdir(3) as an
<fs.Dirent>.
A promise is returned that will be fulfilled with an <fs.Dirent>, or null
if there are no more directory entries to read.
Directory entries returned by this function are in no particular order as
provided by the operating system's underlying directory mechanisms.
Entries added or removed while iterating over the directory might not be
included in the iteration results.

dir.read(callback)#

Added in: v12.12.0


callback <Function>

err <Error>
dirent <fs.Dirent> | <null>



Asynchronously read the next directory entry via readdir(3) as an
<fs.Dirent>.
After the read is completed, the callback will be called with an
<fs.Dirent>, or null if there are no more directory entries to read.
Directory entries returned by this function are in no particular order as
provided by the operating system's underlying directory mechanisms.
Entries added or removed while iterating over the directory might not be
included in the iteration results.

dir.readSync()#

Added in: v12.12.0


Returns: <fs.Dirent> | <null>

Synchronously read the next directory entry as an <fs.Dirent>. See the
POSIX readdir(3) documentation for more detail.
If there are no more directory entries to read, null will be returned.
Directory entries returned by this function are in no particular order as
provided by the operating system's underlying directory mechanisms.
Entries added or removed while iterating over the directory might not be
included in the iteration results.

dir[Symbol.asyncIterator]()#

Added in: v12.12.0


Returns: <AsyncIterator> An AsyncIterator of <fs.Dirent>

Asynchronously iterates over the directory until all entries have
been read. Refer to the POSIX readdir(3) documentation for more detail.
Entries returned by the async iterator are always an <fs.Dirent>.
The null case from dir.read() is handled internally.
See <fs.Dir> for an example.
Directory entries returned by this iterator are in no particular order as
provided by the operating system's underlying directory mechanisms.
Entries added or removed while iterating over the directory might not be
included in the iteration results.

Class: fs.Dirent#

Added in: v10.10.0

A representation of a directory entry, which can be a file or a subdirectory
within the directory, as returned by reading from an <fs.Dir>. The
directory entry is a combination of the file name and file type pairs.
Additionally, when fs.readdir() or fs.readdirSync() is called with
the withFileTypes option set to true, the resulting array is filled with
<fs.Dirent> objects, rather than strings or <Buffer>s.

dirent.isBlockDevice()#

Added in: v10.10.0


Returns: <boolean>

Returns true if the <fs.Dirent> object describes a block device.

dirent.isCharacterDevice()#

Added in: v10.10.0


Returns: <boolean>

Returns true if the <fs.Dirent> object describes a character device.

dirent.isDirectory()#

Added in: v10.10.0


Returns: <boolean>

Returns true if the <fs.Dirent> object describes a file system
directory.

dirent.isFIFO()#

Added in: v10.10.0


Returns: <boolean>

Returns true if the <fs.Dirent> object describes a first-in-first-out
(FIFO) pipe.

dirent.isFile()#

Added in: v10.10.0


Returns: <boolean>

Returns true if the <fs.Dirent> object describes a regular file.

dirent.isSocket()#

Added in: v10.10.0


Returns: <boolean>

Returns true if the <fs.Dirent> object describes a socket.

dirent.isSymbolicLink()#

Added in: v10.10.0


Returns: <boolean>

Returns true if the <fs.Dirent> object describes a symbolic link.

dirent.name#

Added in: v10.10.0


<string> | <Buffer>

The file name that this <fs.Dirent> object refers to. The type of this
value is determined by the options.encoding passed to fs.readdir() or
fs.readdirSync().

dirent.parentPath#

History

VersionChanges
v24.0.0
Marking the API stable.
v21.4.0, v20.12.0, v18.20.0
Added in: v21.4.0, v20.12.0, v18.20.0




<string>

The path to the parent directory of the file this <fs.Dirent> object refers to.

Class: fs.FSWatcher#

Added in: v0.5.8


Extends <EventEmitter>

A successful call to fs.watch() method will return a new <fs.FSWatcher>
object.
All <fs.FSWatcher> objects emit a 'change' event whenever a specific watched
file is modified.

Event: 'change'#

Added in: v0.5.8


eventType <string> The type of change event that has occurred
filename <string> | <Buffer> The filename that changed (if relevant/available)

Emitted when something changes in a watched directory or file.
See more details in fs.watch().
The filename argument may not be provided depending on operating system
support. If filename is provided, it will be provided as a <Buffer> if
fs.watch() is called with its encoding option set to 'buffer', otherwise
filename will be a UTF-8 string.
import { watch } from 'node:fs';
// Example when handled through fs.watch() listener
watch('./tmp', { encoding: 'buffer' }, (eventType, filename) => {
  if (filename) {
    console.log(filename);
    // Prints: <Buffer ...>
  }
}); copy

Event: 'close'#

Added in: v10.0.0

Emitted when the watcher stops watching for changes. The closed
<fs.FSWatcher> object is no longer usable in the event handler.

Event: 'error'#

Added in: v0.5.8


error <Error>

Emitted when an error occurs while watching the file. The errored
<fs.FSWatcher> object is no longer usable in the event handler.

watcher.close()#

Added in: v0.5.8

Stop watching for changes on the given <fs.FSWatcher>. Once stopped, the
<fs.FSWatcher> object is no longer usable.

watcher.ref()#

Added in: v14.3.0, v12.20.0


Returns: <fs.FSWatcher>

When called, requests that the Node.js event loop not exit so long as the
<fs.FSWatcher> is active. Calling watcher.ref() multiple times will have
no effect.
By default, all <fs.FSWatcher> objects are "ref'ed", making it normally
unnecessary to call watcher.ref() unless watcher.unref() had been
called previously.

watcher.unref()#

Added in: v14.3.0, v12.20.0


Returns: <fs.FSWatcher>

When called, the active <fs.FSWatcher> object will not require the Node.js
event loop to remain active. If there is no other activity keeping the
event loop running, the process may exit before the <fs.FSWatcher> object's
callback is invoked. Calling watcher.unref() multiple times will have
no effect.

Class: fs.StatWatcher#

Added in: v14.3.0, v12.20.0


Extends <EventEmitter>

A successful call to fs.watchFile() method will return a new <fs.StatWatcher>
object.

watcher.ref()#

Added in: v14.3.0, v12.20.0


Returns: <fs.StatWatcher>

When called, requests that the Node.js event loop not exit so long as the
<fs.StatWatcher> is active. Calling watcher.ref() multiple times will have
no effect.
By default, all <fs.StatWatcher> objects are "ref'ed", making it normally
unnecessary to call watcher.ref() unless watcher.unref() had been
called previously.

watcher.unref()#

Added in: v14.3.0, v12.20.0


Returns: <fs.StatWatcher>

When called, the active <fs.StatWatcher> object will not require the Node.js
event loop to remain active. If there is no other activity keeping the
event loop running, the process may exit before the <fs.StatWatcher> object's
callback is invoked. Calling watcher.unref() multiple times will have
no effect.

Class: fs.ReadStream#

Added in: v0.1.93


Extends: <stream.Readable>

Instances of <fs.ReadStream> are created and returned using the
fs.createReadStream() function.

Event: 'close'#

Added in: v0.1.93

Emitted when the <fs.ReadStream>'s underlying file descriptor has been closed.

Event: 'open'#

Added in: v0.1.93


fd <integer> Integer file descriptor used by the <fs.ReadStream>.

Emitted when the <fs.ReadStream>'s file descriptor has been opened.

Event: 'ready'#

Added in: v9.11.0

Emitted when the <fs.ReadStream> is ready to be used.
Fires immediately after 'open'.

readStream.bytesRead#

Added in: v6.4.0


<number>

The number of bytes that have been read so far.

readStream.path#

Added in: v0.1.93


<string> | <Buffer>

The path to the file the stream is reading from as specified in the first
argument to fs.createReadStream(). If path is passed as a string, then
readStream.path will be a string. If path is passed as a <Buffer>, then
readStream.path will be a <Buffer>. If fd is specified, then
readStream.path will be undefined.

readStream.pending#

Added in: v11.2.0, v10.16.0


<boolean>

This property is true if the underlying file has not been opened yet,
i.e. before the 'ready' event is emitted.

Class: fs.Stats#

History

VersionChanges
v22.0.0, v20.13.0
Public constructor is deprecated.
v8.1.0
Added times as numbers.
v0.1.21
Added in: v0.1.21



A <fs.Stats> object provides information about a file.
Objects returned from fs.stat(), fs.lstat(), fs.fstat(), and
their synchronous counterparts are of this type.
If bigint in the options passed to those methods is true, the numeric values
will be bigint instead of number, and the object will contain additional
nanosecond-precision properties suffixed with Ns.
Stat objects are not to be created directly using the new keyword.
Stats {
  dev: 2114,
  ino: 48064969,
  mode: 33188,
  nlink: 1,
  uid: 85,
  gid: 100,
  rdev: 0,
  size: 527,
  blksize: 4096,
  blocks: 8,
  atimeMs: 1318289051000.1,
  mtimeMs: 1318289051000.1,
  ctimeMs: 1318289051000.1,
  birthtimeMs: 1318289051000.1,
  atime: Mon, 10 Oct 2011 23:24:11 GMT,
  mtime: Mon, 10 Oct 2011 23:24:11 GMT,
  ctime: Mon, 10 Oct 2011 23:24:11 GMT,
  birthtime: Mon, 10 Oct 2011 23:24:11 GMT } copy
bigint version:
BigIntStats {
  dev: 2114n,
  ino: 48064969n,
  mode: 33188n,
  nlink: 1n,
  uid: 85n,
  gid: 100n,
  rdev: 0n,
  size: 527n,
  blksize: 4096n,
  blocks: 8n,
  atimeMs: 1318289051000n,
  mtimeMs: 1318289051000n,
  ctimeMs: 1318289051000n,
  birthtimeMs: 1318289051000n,
  atimeNs: 1318289051000000000n,
  mtimeNs: 1318289051000000000n,
  ctimeNs: 1318289051000000000n,
  birthtimeNs: 1318289051000000000n,
  atime: Mon, 10 Oct 2011 23:24:11 GMT,
  mtime: Mon, 10 Oct 2011 23:24:11 GMT,
  ctime: Mon, 10 Oct 2011 23:24:11 GMT,
  birthtime: Mon, 10 Oct 2011 23:24:11 GMT } copy

stats.isBlockDevice()#

Added in: v0.1.10


Returns: <boolean>

Returns true if the <fs.Stats> object describes a block device.

stats.isCharacterDevice()#

Added in: v0.1.10


Returns: <boolean>

Returns true if the <fs.Stats> object describes a character device.

stats.isDirectory()#

Added in: v0.1.10


Returns: <boolean>

Returns true if the <fs.Stats> object describes a file system directory.
If the <fs.Stats> object was obtained from calling fs.lstat() on a
symbolic link which resolves to a directory, this method will return false.
This is because fs.lstat() returns information
about a symbolic link itself and not the path it resolves to.

stats.isFIFO()#

Added in: v0.1.10


Returns: <boolean>

Returns true if the <fs.Stats> object describes a first-in-first-out (FIFO)
pipe.

stats.isFile()#

Added in: v0.1.10


Returns: <boolean>

Returns true if the <fs.Stats> object describes a regular file.

stats.isSocket()#

Added in: v0.1.10


Returns: <boolean>

Returns true if the <fs.Stats> object describes a socket.

stats.isSymbolicLink()#

Added in: v0.1.10


Returns: <boolean>

Returns true if the <fs.Stats> object describes a symbolic link.
This method is only valid when using fs.lstat().

stats.dev#

<number> | <bigint>

The numeric identifier of the device containing the file.

stats.ino#

<number> | <bigint>

The file system specific "Inode" number for the file.

stats.mode#

<number> | <bigint>

A bit-field describing the file type and mode.

stats.nlink#

<number> | <bigint>

The number of hard-links that exist for the file.

stats.uid#

<number> | <bigint>

The numeric user identifier of the user that owns the file (POSIX).

stats.gid#

<number> | <bigint>

The numeric group identifier of the group that owns the file (POSIX).

stats.rdev#

<number> | <bigint>

A numeric device identifier if the file represents a device.

stats.size#

<number> | <bigint>

The size of the file in bytes.
If the underlying file system does not support getting the size of the file,
this will be 0.

stats.blksize#

<number> | <bigint>

The file system block size for i/o operations.

stats.blocks#

<number> | <bigint>

The number of blocks allocated for this file.

stats.atimeMs#

Added in: v8.1.0


<number> | <bigint>

The timestamp indicating the last time this file was accessed expressed in
milliseconds since the POSIX Epoch.

stats.mtimeMs#

Added in: v8.1.0


<number> | <bigint>

The timestamp indicating the last time this file was modified expressed in
milliseconds since the POSIX Epoch.

stats.ctimeMs#

Added in: v8.1.0


<number> | <bigint>

The timestamp indicating the last time the file status was changed expressed
in milliseconds since the POSIX Epoch.

stats.birthtimeMs#

Added in: v8.1.0


<number> | <bigint>

The timestamp indicating the creation time of this file expressed in
milliseconds since the POSIX Epoch.

stats.atimeNs#

Added in: v12.10.0


<bigint>

Only present when bigint: true is passed into the method that generates
the object.
The timestamp indicating the last time this file was accessed expressed in
nanoseconds since the POSIX Epoch.

stats.mtimeNs#

Added in: v12.10.0


<bigint>

Only present when bigint: true is passed into the method that generates
the object.
The timestamp indicating the last time this file was modified expressed in
nanoseconds since the POSIX Epoch.

stats.ctimeNs#

Added in: v12.10.0


<bigint>

Only present when bigint: true is passed into the method that generates
the object.
The timestamp indicating the last time the file status was changed expressed
in nanoseconds since the POSIX Epoch.

stats.birthtimeNs#

Added in: v12.10.0


<bigint>

Only present when bigint: true is passed into the method that generates
the object.
The timestamp indicating the creation time of this file expressed in
nanoseconds since the POSIX Epoch.

stats.atime#

Added in: v0.11.13


<Date>

The timestamp indicating the last time this file was accessed.

stats.mtime#

Added in: v0.11.13


<Date>

The timestamp indicating the last time this file was modified.

stats.ctime#

Added in: v0.11.13


<Date>

The timestamp indicating the last time the file status was changed.

stats.birthtime#

Added in: v0.11.13


<Date>

The timestamp indicating the creation time of this file.

Stat time values#
The atimeMs, mtimeMs, ctimeMs, birthtimeMs properties are
numeric values that hold the corresponding times in milliseconds. Their
precision is platform specific. When bigint: true is passed into the
method that generates the object, the properties will be bigints,
otherwise they will be numbers.
The atimeNs, mtimeNs, ctimeNs, birthtimeNs properties are
bigints that hold the corresponding times in nanoseconds. They are
only present when bigint: true is passed into the method that generates
the object. Their precision is platform specific.
atime, mtime, ctime, and birthtime are
Date object alternate representations of the various times. The
Date and number values are not connected. Assigning a new number value, or
mutating the Date value, will not be reflected in the corresponding alternate
representation.
The times in the stat object have the following semantics:

atime "Access Time": Time when file data last accessed. Changed
by the mknod(2), utimes(2), and read(2) system calls.
mtime "Modified Time": Time when file data last modified.
Changed by the mknod(2), utimes(2), and write(2) system calls.
ctime "Change Time": Time when file status was last changed
(inode data modification). Changed by the chmod(2), chown(2),
link(2), mknod(2), rename(2), unlink(2), utimes(2),
read(2), and write(2) system calls.
birthtime "Birth Time": Time of file creation. Set once when the
file is created. On file systems where birthtime is not available,
this field may instead hold either the ctime or
1970-01-01T00:00Z (ie, Unix epoch timestamp 0). This value may be greater
than atime or mtime in this case. On Darwin and other FreeBSD variants,
also set if the atime is explicitly set to an earlier value than the current
birthtime using the utimes(2) system call.

Prior to Node.js 0.12, the ctime held the birthtime on Windows systems. As
of 0.12, ctime is not "creation time", and on Unix systems, it never was.

Class: fs.StatFs#

Added in: v19.6.0, v18.15.0

Provides information about a mounted file system.
Objects returned from fs.statfs() and its synchronous counterpart are of
this type. If bigint in the options passed to those methods is true, the
numeric values will be bigint instead of number.
StatFs {
  type: 1397114950,
  bsize: 4096,
  blocks: 121938943,
  bfree: 61058895,
  bavail: 61058895,
  files: 999,
  ffree: 1000000
} copy
bigint version:
StatFs {
  type: 1397114950n,
  bsize: 4096n,
  blocks: 121938943n,
  bfree: 61058895n,
  bavail: 61058895n,
  files: 999n,
  ffree: 1000000n
} copy

statfs.bavail#

Added in: v19.6.0, v18.15.0


<number> | <bigint>

Free blocks available to unprivileged users.

statfs.bfree#

Added in: v19.6.0, v18.15.0


<number> | <bigint>

Free blocks in file system.

statfs.blocks#

Added in: v19.6.0, v18.15.0


<number> | <bigint>

Total data blocks in file system.

statfs.bsize#

Added in: v19.6.0, v18.15.0


<number> | <bigint>

Optimal transfer block size.

statfs.ffree#

Added in: v19.6.0, v18.15.0


<number> | <bigint>

Free file nodes in file system.

statfs.files#

Added in: v19.6.0, v18.15.0


<number> | <bigint>

Total file nodes in file system.

statfs.type#

Added in: v19.6.0, v18.15.0


<number> | <bigint>

Type of file system.

Class: fs.WriteStream#

Added in: v0.1.93


Extends <stream.Writable>

Instances of <fs.WriteStream> are created and returned using the
fs.createWriteStream() function.

Event: 'close'#

Added in: v0.1.93

Emitted when the <fs.WriteStream>'s underlying file descriptor has been closed.

Event: 'open'#

Added in: v0.1.93


fd <integer> Integer file descriptor used by the <fs.WriteStream>.

Emitted when the <fs.WriteStream>'s file is opened.

Event: 'ready'#

Added in: v9.11.0

Emitted when the <fs.WriteStream> is ready to be used.
Fires immediately after 'open'.

writeStream.bytesWritten#

Added in: v0.4.7

The number of bytes written so far. Does not include data that is still queued
for writing.

writeStream.close([callback])#

Added in: v0.9.4


callback <Function>

err <Error>



Closes writeStream. Optionally accepts a
callback that will be executed once the writeStream
is closed.

writeStream.path#

Added in: v0.1.93

The path to the file the stream is writing to as specified in the first
argument to fs.createWriteStream(). If path is passed as a string, then
writeStream.path will be a string. If path is passed as a <Buffer>, then
writeStream.path will be a <Buffer>.

writeStream.pending#

Added in: v11.2.0


<boolean>

This property is true if the underlying file has not been opened yet,
i.e. before the 'ready' event is emitted.

fs.constants#

<Object>

Returns an object containing commonly used constants for file system
operations.

FS constants#
The following constants are exported by fs.constants and fsPromises.constants.
Not every constant will be available on every operating system;
this is especially important for Windows, where many of the POSIX specific
definitions are not available.
For portable applications it is recommended to check for their presence
before use.
To use more than one constant, use the bitwise OR | operator.
Example:
import { open, constants } from 'node:fs';

const {
  O_RDWR,
  O_CREAT,
  O_EXCL,
} = constants;

open('/path/to/my/file', O_RDWR | O_CREAT | O_EXCL, (err, fd) => {
  // ...
}); copy

File access constants#
The following constants are meant for use as the mode parameter passed to
fsPromises.access(), fs.access(), and fs.accessSync().

  
    Constant
    Description
  
  
    F_OK
    Flag indicating that the file is visible to the calling process.
     This is useful for determining if a file exists, but says nothing
     about rwx permissions. Default if no mode is specified.
  
  
    R_OK
    Flag indicating that the file can be read by the calling process.
  
  
    W_OK
    Flag indicating that the file can be written by the calling
    process.
  
  
    X_OK
    Flag indicating that the file can be executed by the calling
    process. This has no effect on Windows
    (will behave like fs.constants.F_OK).
  

The definitions are also available on Windows.

File copy constants#
The following constants are meant for use with fs.copyFile().

  
    Constant
    Description
  
  
    COPYFILE_EXCL
    If present, the copy operation will fail with an error if the
    destination path already exists.
  
  
    COPYFILE_FICLONE
    If present, the copy operation will attempt to create a
    copy-on-write reflink. If the underlying platform does not support
    copy-on-write, then a fallback copy mechanism is used.
  
  
    COPYFILE_FICLONE_FORCE
    If present, the copy operation will attempt to create a
    copy-on-write reflink. If the underlying platform does not support
    copy-on-write, then the operation will fail with an error.
  

The definitions are also available on Windows.

File open constants#
The following constants are meant for use with fs.open().

  
    Constant
    Description
  
  
    O_RDONLY
    Flag indicating to open a file for read-only access.
  
  
    O_WRONLY
    Flag indicating to open a file for write-only access.
  
  
    O_RDWR
    Flag indicating to open a file for read-write access.
  
  
    O_CREAT
    Flag indicating to create the file if it does not already exist.
  
  
    O_EXCL
    Flag indicating that opening a file should fail if the
    O_CREAT flag is set and the file already exists.
  
  
    O_NOCTTY
    Flag indicating that if path identifies a terminal device, opening the
    path shall not cause that terminal to become the controlling terminal for
    the process (if the process does not already have one).
  
  
    O_TRUNC
    Flag indicating that if the file exists and is a regular file, and the
    file is opened successfully for write access, its length shall be truncated
    to zero.
  
  
    O_APPEND
    Flag indicating that data will be appended to the end of the file.
  
  
    O_DIRECTORY
    Flag indicating that the open should fail if the path is not a
    directory.
  
  
  O_NOATIME
    Flag indicating reading accesses to the file system will no longer
    result in an update to the atime information associated with
    the file. This flag is available on Linux operating systems only.
  
  
    O_NOFOLLOW
    Flag indicating that the open should fail if the path is a symbolic
    link.
  
  
    O_SYNC
    Flag indicating that the file is opened for synchronized I/O with write
    operations waiting for file integrity.
  
  
    O_DSYNC
    Flag indicating that the file is opened for synchronized I/O with write
    operations waiting for data integrity.
  
  
    O_SYMLINK
    Flag indicating to open the symbolic link itself rather than the
    resource it is pointing to.
  
  
    O_DIRECT
    When set, an attempt will be made to minimize caching effects of file
    I/O.
  
  
    O_NONBLOCK
    Flag indicating to open the file in nonblocking mode when possible.
  
  
    UV_FS_O_FILEMAP
    When set, a memory file mapping is used to access the file. This flag
    is available on Windows operating systems only. On other operating systems,
    this flag is ignored.
  

On Windows, only O_APPEND, O_CREAT, O_EXCL, O_RDONLY, O_RDWR,
O_TRUNC, O_WRONLY, and UV_FS_O_FILEMAP are available.

File type constants#
The following constants are meant for use with the <fs.Stats> object's
mode property for determining a file's type.

  
    Constant
    Description
  
  
    S_IFMT
    Bit mask used to extract the file type code.
  
  
    S_IFREG
    File type constant for a regular file.
  
  
    S_IFDIR
    File type constant for a directory.
  
  
    S_IFCHR
    File type constant for a character-oriented device file.
  
  
    S_IFBLK
    File type constant for a block-oriented device file.
  
  
    S_IFIFO
    File type constant for a FIFO/pipe.
  
  
    S_IFLNK
    File type constant for a symbolic link.
  
  
    S_IFSOCK
    File type constant for a socket.
  

On Windows, only S_IFCHR, S_IFDIR, S_IFLNK, S_IFMT, and S_IFREG,
are available.

File mode constants#
The following constants are meant for use with the <fs.Stats> object's
mode property for determining the access permissions for a file.

  
    Constant
    Description
  
  
    S_IRWXU
    File mode indicating readable, writable, and executable by owner.
  
  
    S_IRUSR
    File mode indicating readable by owner.
  
  
    S_IWUSR
    File mode indicating writable by owner.
  
  
    S_IXUSR
    File mode indicating executable by owner.
  
  
    S_IRWXG
    File mode indicating readable, writable, and executable by group.
  
  
    S_IRGRP
    File mode indicating readable by group.
  
  
    S_IWGRP
    File mode indicating writable by group.
  
  
    S_IXGRP
    File mode indicating executable by group.
  
  
    S_IRWXO
    File mode indicating readable, writable, and executable by others.
  
  
    S_IROTH
    File mode indicating readable by others.
  
  
    S_IWOTH
    File mode indicating writable by others.
  
  
    S_IXOTH
    File mode indicating executable by others.
  

On Windows, only S_IRUSR and S_IWUSR are available.

Notes#

Ordering of callback and promise-based operations#
Because they are executed asynchronously by the underlying thread pool,
there is no guaranteed ordering when using either the callback or
promise-based methods.
For example, the following is prone to error because the fs.stat()
operation might complete before the fs.rename() operation:
const fs = require('node:fs');

fs.rename('/tmp/hello', '/tmp/world', (err) => {
  if (err) throw err;
  console.log('renamed complete');
});
fs.stat('/tmp/world', (err, stats) => {
  if (err) throw err;
  console.log(`stats: ${JSON.stringify(stats)}`);
}); copy
It is important to correctly order the operations by awaiting the results
of one before invoking the other:

import { rename, stat } from 'node:fs/promises';

const oldPath = '/tmp/hello';
const newPath = '/tmp/world';

try {
  await rename(oldPath, newPath);
  const stats = await stat(newPath);
  console.log(`stats: ${JSON.stringify(stats)}`);
} catch (error) {
  console.error('there was an error:', error.message);
}const { rename, stat } = require('node:fs/promises');

(async function(oldPath, newPath) {
  try {
    await rename(oldPath, newPath);
    const stats = await stat(newPath);
    console.log(`stats: ${JSON.stringify(stats)}`);
  } catch (error) {
    console.error('there was an error:', error.message);
  }
})('/tmp/hello', '/tmp/world');copy
Or, when using the callback APIs, move the fs.stat() call into the callback
of the fs.rename() operation:

import { rename, stat } from 'node:fs';

rename('/tmp/hello', '/tmp/world', (err) => {
  if (err) throw err;
  stat('/tmp/world', (err, stats) => {
    if (err) throw err;
    console.log(`stats: ${JSON.stringify(stats)}`);
  });
});const { rename, stat } = require('node:fs/promises');

rename('/tmp/hello', '/tmp/world', (err) => {
  if (err) throw err;
  stat('/tmp/world', (err, stats) => {
    if (err) throw err;
    console.log(`stats: ${JSON.stringify(stats)}`);
  });
});copy

File paths#
Most fs operations accept file paths that may be specified in the form of
a string, a <Buffer>, or a <URL> object using the file: protocol.

String paths#
String paths are interpreted as UTF-8 character sequences identifying
the absolute or relative filename. Relative paths will be resolved relative
to the current working directory as determined by calling process.cwd().
Example using an absolute path on POSIX:
import { open } from 'node:fs/promises';

let fd;
try {
  fd = await open('/open/some/file.txt', 'r');
  // Do something with the file
} finally {
  await fd?.close();
} copy
Example using a relative path on POSIX (relative to process.cwd()):
import { open } from 'node:fs/promises';

let fd;
try {
  fd = await open('file.txt', 'r');
  // Do something with the file
} finally {
  await fd?.close();
} copy

File URL paths#

Added in: v7.6.0

For most node:fs module functions, the path or filename argument may be
passed as a <URL> object using the file: protocol.
import { readFileSync } from 'node:fs';

readFileSync(new URL('file:///tmp/hello')); copy
file: URLs are always absolute paths.

Platform-specific considerations#
On Windows, file: <URL>s with a host name convert to UNC paths, while file:
<URL>s with drive letters convert to local absolute paths. file: <URL>s
with no host name and no drive letter will result in an error:
import { readFileSync } from 'node:fs';
// On Windows :

// - WHATWG file URLs with hostname convert to UNC path
// file://hostname/p/a/t/h/file => \\hostname\p\a\t\h\file
readFileSync(new URL('file://hostname/p/a/t/h/file'));

// - WHATWG file URLs with drive letters convert to absolute path
// file:///C:/tmp/hello => C:\tmp\hello
readFileSync(new URL('file:///C:/tmp/hello'));

// - WHATWG file URLs without hostname must have a drive letters
readFileSync(new URL('file:///notdriveletter/p/a/t/h/file'));
readFileSync(new URL('file:///c/p/a/t/h/file'));
// TypeError [ERR_INVALID_FILE_URL_PATH]: File URL path must be absolute copy
file: <URL>s with drive letters must use : as a separator just after
the drive letter. Using another separator will result in an error.
On all other platforms, file: <URL>s with a host name are unsupported and
will result in an error:
import { readFileSync } from 'node:fs';
// On other platforms:

// - WHATWG file URLs with hostname are unsupported
// file://hostname/p/a/t/h/file => throw!
readFileSync(new URL('file://hostname/p/a/t/h/file'));
// TypeError [ERR_INVALID_FILE_URL_PATH]: must be absolute

// - WHATWG file URLs convert to absolute path
// file:///tmp/hello => /tmp/hello
readFileSync(new URL('file:///tmp/hello')); copy
A file: <URL> having encoded slash characters will result in an error on all
platforms:
import { readFileSync } from 'node:fs';

// On Windows
readFileSync(new URL('file:///C:/p/a/t/h/%2F'));
readFileSync(new URL('file:///C:/p/a/t/h/%2f'));
/* TypeError [ERR_INVALID_FILE_URL_PATH]: File URL path must not include encoded
\ or / characters */

// On POSIX
readFileSync(new URL('file:///p/a/t/h/%2F'));
readFileSync(new URL('file:///p/a/t/h/%2f'));
/* TypeError [ERR_INVALID_FILE_URL_PATH]: File URL path must not include encoded
/ characters */ copy
On Windows, file: <URL>s having encoded backslash will result in an error:
import { readFileSync } from 'node:fs';

// On Windows
readFileSync(new URL('file:///C:/path/%5C'));
readFileSync(new URL('file:///C:/path/%5c'));
/* TypeError [ERR_INVALID_FILE_URL_PATH]: File URL path must not include encoded
\ or / characters */ copy

Buffer paths#
Paths specified using a <Buffer> are useful primarily on certain POSIX
operating systems that treat file paths as opaque byte sequences. On such
systems, it is possible for a single file path to contain sub-sequences that
use multiple character encodings. As with string paths, <Buffer> paths may
be relative or absolute:
Example using an absolute path on POSIX:
import { open } from 'node:fs/promises';
import { Buffer } from 'node:buffer';

let fd;
try {
  fd = await open(Buffer.from('/open/some/file.txt'), 'r');
  // Do something with the file
} finally {
  await fd?.close();
} copy

Per-drive working directories on Windows#
On Windows, Node.js follows the concept of per-drive working directory. This
behavior can be observed when using a drive path without a backslash. For
example fs.readdirSync('C:\\') can potentially return a different result than
fs.readdirSync('C:'). For more information, see
this MSDN page.

File descriptors#
On POSIX systems, for every process, the kernel maintains a table of currently
open files and resources. Each open file is assigned a simple numeric
identifier called a file descriptor. At the system-level, all file system
operations use these file descriptors to identify and track each specific
file. Windows systems use a different but conceptually similar mechanism for
tracking resources. To simplify things for users, Node.js abstracts away the
differences between operating systems and assigns all open files a numeric file
descriptor.
The callback-based fs.open(), and synchronous fs.openSync() methods open a
file and allocate a new file descriptor. Once allocated, the file descriptor may
be used to read data from, write data to, or request information about the file.
Operating systems limit the number of file descriptors that may be open
at any given time so it is critical to close the descriptor when operations
are completed. Failure to do so will result in a memory leak that will
eventually cause an application to crash.
import { open, close, fstat } from 'node:fs';

function closeFd(fd) {
  close(fd, (err) => {
    if (err) throw err;
  });
}

open('/open/some/file.txt', 'r', (err, fd) => {
  if (err) throw err;
  try {
    fstat(fd, (err, stat) => {
      if (err) {
        closeFd(fd);
        throw err;
      }

      // use stat

      closeFd(fd);
    });
  } catch (err) {
    closeFd(fd);
    throw err;
  }
}); copy
The promise-based APIs use a <FileHandle> object in place of the numeric
file descriptor. These objects are better managed by the system to ensure
that resources are not leaked. However, it is still required that they are
closed when operations are completed:
import { open } from 'node:fs/promises';

let file;
try {
  file = await open('/open/some/file.txt', 'r');
  const stat = await file.stat();
  // use stat
} finally {
  await file.close();
} copy

Threadpool usage#
All callback and promise-based file system APIs (with the exception of
fs.FSWatcher()) use libuv's threadpool. This can have surprising and negative
performance implications for some applications. See the
UV_THREADPOOL_SIZE documentation for more information.

File system flags#
The following flags are available wherever the flag option takes a
string.


'a': Open file for appending.
The file is created if it does not exist.


'ax': Like 'a' but fails if the path exists.


'a+': Open file for reading and appending.
The file is created if it does not exist.


'ax+': Like 'a+' but fails if the path exists.


'as': Open file for appending in synchronous mode.
The file is created if it does not exist.


'as+': Open file for reading and appending in synchronous mode.
The file is created if it does not exist.


'r': Open file for reading.
An exception occurs if the file does not exist.


'rs': Open file for reading in synchronous mode.
An exception occurs if the file does not exist.


'r+': Open file for reading and writing.
An exception occurs if the file does not exist.


'rs+': Open file for reading and writing in synchronous mode. Instructs
the operating system to bypass the local file system cache.
This is primarily useful for opening files on NFS mounts as it allows
skipping the potentially stale local cache. It has a very real impact on
I/O performance so using this flag is not recommended unless it is needed.
This doesn't turn fs.open() or fsPromises.open() into a synchronous
blocking call. If synchronous operation is desired, something like
fs.openSync() should be used.


'w': Open file for writing.
The file is created (if it does not exist) or truncated (if it exists).


'wx': Like 'w' but fails if the path exists.


'w+': Open file for reading and writing.
The file is created (if it does not exist) or truncated (if it exists).


'wx+': Like 'w+' but fails if the path exists.


flag can also be a number as documented by open(2); commonly used constants
are available from fs.constants. On Windows, flags are translated to
their equivalent ones where applicable, e.g. O_WRONLY to FILE_GENERIC_WRITE,
or O_EXCL|O_CREAT to CREATE_NEW, as accepted by CreateFileW.
The exclusive flag 'x' (O_EXCL flag in open(2)) causes the operation to
return an error if the path already exists. On POSIX, if the path is a symbolic
link, using O_EXCL returns an error even if the link is to a path that does
not exist. The exclusive flag might not work with network file systems.
On Linux, positional writes don't work when the file is opened in append mode.
The kernel ignores the position argument and always appends the data to
the end of the file.
Modifying a file rather than replacing it may require the flag option to be
set to 'r+' rather than the default 'w'.
The behavior of some flags are platform-specific. As such, opening a directory
on macOS and Linux with the 'a+' flag, as in the example below, will return an
error. In contrast, on Windows and FreeBSD, a file descriptor or a FileHandle
will be returned.
// macOS and Linux
fs.open('<directory>', 'a+', (err, fd) => {
  // => [Error: EISDIR: illegal operation on a directory, open <directory>]
});

// Windows and FreeBSD
fs.open('<directory>', 'a+', (err, fd) => {
  // => null, <fd>
}); copy
On Windows, opening an existing hidden file using the 'w' flag (either
through fs.open(), fs.writeFile(), or fsPromises.open()) will fail with
EPERM. Existing hidden files can be opened for writing with the 'r+' flag.
A call to fs.ftruncate() or filehandle.truncate() can be used to reset
the file contents.\n\n\n\nNode.js
        
      
      
About this documentation
Usage and example



Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Modules: TypeScript
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
Readline
REPL
Report
Single executable applications
SQLite
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker

    

    
      
        
          Node.js v24.0.1 documentation
          
            
            
          
        
        
          
            Node.js v24.0.1
            
    
      
        
        Table of contents
      

      
Global objects

Class: AbortController

abortController.abort([reason])
abortController.signal
Class: AbortSignal

Static method: AbortSignal.abort([reason])
Static method: AbortSignal.timeout(delay)
Static method: AbortSignal.any(signals)
Event: 'abort'
abortSignal.aborted
abortSignal.onabort
abortSignal.reason
abortSignal.throwIfAborted()




Class: Blob
Class: Buffer
Class: ByteLengthQueuingStrategy
__dirname
__filename
atob(data)
BroadcastChannel
btoa(data)
clearImmediate(immediateObject)
clearInterval(intervalObject)
clearTimeout(timeoutObject)
CloseEvent
Class: CompressionStream
console
Class: CountQueuingStrategy
Crypto
crypto
CryptoKey
CustomEvent
Class: DecompressionStream
Event
EventSource
EventTarget
exports
fetch
Custom dispatcher
Related classes
Class: File
Class FormData
global
Class Headers
localStorage
MessageChannel
MessageEvent
MessagePort
module
Navigator
navigator

navigator.hardwareConcurrency
navigator.language
navigator.languages
navigator.platform
navigator.userAgent


PerformanceEntry
PerformanceMark
PerformanceMeasure
PerformanceObserver
PerformanceObserverEntryList
PerformanceResourceTiming
performance
process
queueMicrotask(callback)
Class: ReadableByteStreamController
Class: ReadableStream
Class: ReadableStreamBYOBReader
Class: ReadableStreamBYOBRequest
Class: ReadableStreamDefaultController
Class: ReadableStreamDefaultReader
require()
Response
Request
sessionStorage
setImmediate(callback[, ...args])
setInterval(callback, delay[, ...args])
setTimeout(callback, delay[, ...args])
Class: Storage
structuredClone(value[, options])
SubtleCrypto
DOMException
TextDecoder
Class: TextDecoderStream
TextEncoder
Class: TextEncoderStream
Class: TransformStream
Class: TransformStreamDefaultController
URL
URLPattern
URLSearchParams
WebAssembly
WebSocket
Class: WritableStream
Class: WritableStreamDefaultController
Class: WritableStreamDefaultWriter



    
  
            
    
      
        
        Index
      

      
About this documentation
Usage and example

      
        Index
      
    
  


Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Modules: TypeScript
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
Readline
REPL
Report
Single executable applications
SQLite
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker

    
  
            
    
      
        
        Other versions
      
      24.x
23.x
22.x LTS
21.x
20.x LTS
19.x
18.x
17.x
16.x
15.x
14.x
13.x
12.x
11.x
10.x
9.x
8.x
7.x
6.x
5.x
4.x
0.12.x
0.10.x
    
  
            
              
                
                Options
              
        
              
                
                  
                    View on single page
                  
                  
                    View as JSON
                  
                  Edit on GitHub    
                
              
            
          
        
        
      

      Table of contents
Global objects

Class: AbortController

abortController.abort([reason])
abortController.signal
Class: AbortSignal

Static method: AbortSignal.abort([reason])
Static method: AbortSignal.timeout(delay)
Static method: AbortSignal.any(signals)
Event: 'abort'
abortSignal.aborted
abortSignal.onabort
abortSignal.reason
abortSignal.throwIfAborted()




Class: Blob
Class: Buffer
Class: ByteLengthQueuingStrategy
__dirname
__filename
atob(data)
BroadcastChannel
btoa(data)
clearImmediate(immediateObject)
clearInterval(intervalObject)
clearTimeout(timeoutObject)
CloseEvent
Class: CompressionStream
console
Class: CountQueuingStrategy
Crypto
crypto
CryptoKey
CustomEvent
Class: DecompressionStream
Event
EventSource
EventTarget
exports
fetch
Custom dispatcher
Related classes
Class: File
Class FormData
global
Class Headers
localStorage
MessageChannel
MessageEvent
MessagePort
module
Navigator
navigator

navigator.hardwareConcurrency
navigator.language
navigator.languages
navigator.platform
navigator.userAgent


PerformanceEntry
PerformanceMark
PerformanceMeasure
PerformanceObserver
PerformanceObserverEntryList
PerformanceResourceTiming
performance
process
queueMicrotask(callback)
Class: ReadableByteStreamController
Class: ReadableStream
Class: ReadableStreamBYOBReader
Class: ReadableStreamBYOBRequest
Class: ReadableStreamDefaultController
Class: ReadableStreamDefaultReader
require()
Response
Request
sessionStorage
setImmediate(callback[, ...args])
setInterval(callback, delay[, ...args])
setTimeout(callback, delay[, ...args])
Class: Storage
structuredClone(value[, options])
SubtleCrypto
DOMException
TextDecoder
Class: TextDecoderStream
TextEncoder
Class: TextEncoderStream
Class: TransformStream
Class: TransformStreamDefaultController
URL
URLPattern
URLSearchParams
WebAssembly
WebSocket
Class: WritableStream
Class: WritableStreamDefaultController
Class: WritableStreamDefaultWriter




      
        Global objects#


These objects are available in all modules.
The following variables may appear to be global but are not. They exist only in
the scope of CommonJS modules:

__dirname
__filename
exports
module
require()

The objects listed here are specific to Node.js. There are built-in objects
that are part of the JavaScript language itself, which are also globally
accessible.
Class: AbortController#

History

VersionChanges
v15.4.0
No longer experimental.
v15.0.0, v14.17.0
Added in: v15.0.0, v14.17.0



Stability: 2 - Stable

A utility class used to signal cancelation in selected Promise-based APIs.
The API is based on the Web API AbortController.
const ac = new AbortController();

ac.signal.addEventListener('abort', () => console.log('Aborted!'),
                           { once: true });

ac.abort();

console.log(ac.signal.aborted);  // Prints true copy

abortController.abort([reason])#

History

VersionChanges
v17.2.0, v16.14.0
Added the new optional reason argument.
v15.0.0, v14.17.0
Added in: v15.0.0, v14.17.0




reason <any> An optional reason, retrievable on the AbortSignal's
reason property.

Triggers the abort signal, causing the abortController.signal to emit
the 'abort' event.

abortController.signal#

Added in: v15.0.0, v14.17.0


Type: <AbortSignal>


Class: AbortSignal#

Added in: v15.0.0, v14.17.0


Extends: <EventTarget>

The AbortSignal is used to notify observers when the
abortController.abort() method is called.

Static method: AbortSignal.abort([reason])#

History

VersionChanges
v17.2.0, v16.14.0
Added the new optional reason argument.
v15.12.0, v14.17.0
Added in: v15.12.0, v14.17.0




reason: <any>
Returns: <AbortSignal>

Returns a new already aborted AbortSignal.

Static method: AbortSignal.timeout(delay)#

Added in: v17.3.0, v16.14.0


delay <number> The number of milliseconds to wait before triggering
the AbortSignal.

Returns a new AbortSignal which will be aborted in delay milliseconds.

Static method: AbortSignal.any(signals)#

Added in: v20.3.0, v18.17.0


signals <AbortSignal[]> The AbortSignals of which to compose a new AbortSignal.

Returns a new AbortSignal which will be aborted if any of the provided
signals are aborted. Its abortSignal.reason will be set to whichever
one of the signals caused it to be aborted.

Event: 'abort'#

Added in: v15.0.0, v14.17.0

The 'abort' event is emitted when the abortController.abort() method
is called. The callback is invoked with a single object argument with a
single type property set to 'abort':
const ac = new AbortController();

// Use either the onabort property...
ac.signal.onabort = () => console.log('aborted!');

// Or the EventTarget API...
ac.signal.addEventListener('abort', (event) => {
  console.log(event.type);  // Prints 'abort'
}, { once: true });

ac.abort(); copy
The AbortController with which the AbortSignal is associated will only
ever trigger the 'abort' event once. We recommended that code check
that the abortSignal.aborted attribute is false before adding an 'abort'
event listener.
Any event listeners attached to the AbortSignal should use the
{ once: true } option (or, if using the EventEmitter APIs to attach a
listener, use the once() method) to ensure that the event listener is
removed as soon as the 'abort' event is handled. Failure to do so may
result in memory leaks.

abortSignal.aborted#

Added in: v15.0.0, v14.17.0


Type: <boolean> True after the AbortController has been aborted.


abortSignal.onabort#

Added in: v15.0.0, v14.17.0


Type: <Function>

An optional callback function that may be set by user code to be notified
when the abortController.abort() function has been called.

abortSignal.reason#

Added in: v17.2.0, v16.14.0


Type: <any>

An optional reason specified when the AbortSignal was triggered.
const ac = new AbortController();
ac.abort(new Error('boom!'));
console.log(ac.signal.reason);  // Error: boom! copy

abortSignal.throwIfAborted()#

Added in: v17.3.0, v16.17.0

If abortSignal.aborted is true, throws abortSignal.reason.

Class: Blob#

Added in: v18.0.0

Stability: 2 - Stable

See <Blob>.
Class: Buffer#

Added in: v0.1.103

Stability: 2 - Stable


<Function>

Used to handle binary data. See the buffer section.
Class: ByteLengthQueuingStrategy#

History

VersionChanges
v23.11.0, v22.15.0
Marking the API stable.
v18.0.0
Added in: v18.0.0



A browser-compatible implementation of ByteLengthQueuingStrategy.
__dirname#
This variable may appear to be global but is not. See __dirname.
__filename#
This variable may appear to be global but is not. See __filename.
atob(data)#

Added in: v16.0.0

Stability: 3 - Legacy. Use Buffer.from(data, 'base64') instead.
Global alias for buffer.atob().
BroadcastChannel#

Added in: v18.0.0

Stability: 2 - Stable
See <BroadcastChannel>.
btoa(data)#

Added in: v16.0.0

Stability: 3 - Legacy. Use buf.toString('base64') instead.
Global alias for buffer.btoa().
clearImmediate(immediateObject)#

Added in: v0.9.1

Stability: 2 - Stable

clearImmediate is described in the timers section.
clearInterval(intervalObject)#

Added in: v0.0.1

Stability: 2 - Stable

clearInterval is described in the timers section.
clearTimeout(timeoutObject)#

Added in: v0.0.1

Stability: 2 - Stable

clearTimeout is described in the timers section.
CloseEvent#

Added in: v23.0.0

Stability: 2 - Stable

The CloseEvent class. See CloseEvent for more details.
A browser-compatible implementation of CloseEvent. Disable this API
with the --no-experimental-websocket CLI flag.
Class: CompressionStream#

History

VersionChanges
v23.11.0, v22.15.0
Marking the API stable.
v18.0.0
Added in: v18.0.0



A browser-compatible implementation of CompressionStream.
console#

Added in: v0.1.100

Stability: 2 - Stable


<Object>

Used to print to stdout and stderr. See the console section.
Class: CountQueuingStrategy#

History

VersionChanges
v23.11.0, v22.15.0
Marking the API stable.
v18.0.0
Added in: v18.0.0



A browser-compatible implementation of CountQueuingStrategy.
Crypto#

History

VersionChanges
v23.0.0
No longer experimental.
v19.0.0
No longer behind --experimental-global-webcrypto CLI flag.
v17.6.0, v16.15.0
Added in: v17.6.0, v16.15.0



Stability: 2 - Stable
A browser-compatible implementation of <Crypto>. This global is available
only if the Node.js binary was compiled with including support for the
node:crypto module.
crypto#

History

VersionChanges
v23.0.0
No longer experimental.
v19.0.0
No longer behind --experimental-global-webcrypto CLI flag.
v17.6.0, v16.15.0
Added in: v17.6.0, v16.15.0



Stability: 2 - Stable
A browser-compatible implementation of the Web Crypto API.
CryptoKey#

History

VersionChanges
v23.0.0
No longer experimental.
v19.0.0
No longer behind --experimental-global-webcrypto CLI flag.
v17.6.0, v16.15.0
Added in: v17.6.0, v16.15.0



Stability: 2 - Stable
A browser-compatible implementation of <CryptoKey>. This global is available
only if the Node.js binary was compiled with including support for the
node:crypto module.
CustomEvent#

History

VersionChanges
v23.0.0
No longer experimental.
v22.1.0, v20.13.0
CustomEvent is now stable.
v19.0.0
No longer behind --experimental-global-customevent CLI flag.
v18.7.0, v16.17.0
Added in: v18.7.0, v16.17.0



Stability: 2 - Stable

A browser-compatible implementation of the CustomEvent Web API.
Class: DecompressionStream#

History

VersionChanges
v23.11.0, v22.15.0
Marking the API stable.
v18.0.0
Added in: v18.0.0



A browser-compatible implementation of DecompressionStream.
Event#

History

VersionChanges
v15.4.0
No longer experimental.
v15.0.0
Added in: v15.0.0



Stability: 2 - Stable

A browser-compatible implementation of the Event class. See
EventTarget and Event API for more details.
EventSource#

Added in: v22.3.0, v20.18.0

Stability: 1 - Experimental. Enable this API with the --experimental-eventsource
CLI flag.
A browser-compatible implementation of the EventSource class.
EventTarget#

History

VersionChanges
v15.4.0
No longer experimental.
v15.0.0
Added in: v15.0.0



Stability: 2 - Stable

A browser-compatible implementation of the EventTarget class. See
EventTarget and Event API for more details.
exports#
This variable may appear to be global but is not. See exports.
fetch#

History

VersionChanges
v21.0.0
No longer experimental.
v18.0.0
No longer behind --experimental-fetch CLI flag.
v17.5.0, v16.15.0
Added in: v17.5.0, v16.15.0



Stability: 2 - Stable
A browser-compatible implementation of the fetch() function.
const res = await fetch('https://nodejs.org/api/documentation.json');
if (res.ok) {
  const data = await res.json();
  console.log(data);
} copy
The implementation is based upon undici, an HTTP/1.1 client
written from scratch for Node.js. You can figure out which version of undici is bundled
in your Node.js process reading the process.versions.undici property.
Custom dispatcher#
You can use a custom dispatcher to dispatch requests passing it in fetch's options object.
The dispatcher must be compatible with undici's
Dispatcher class.
fetch(url, { dispatcher: new MyAgent() }); copy
It is possible to change the global dispatcher in Node.js installing undici and using
the setGlobalDispatcher() method. Calling this method will affect both undici and
Node.js.
import { setGlobalDispatcher } from 'undici';
setGlobalDispatcher(new MyAgent()); copy
Related classes#
The following globals are available to use with fetch:

FormData
Headers
Request
Response.

Class: File#

Added in: v20.0.0

Stability: 2 - Stable

See <File>.
Class FormData#

History

VersionChanges
v21.0.0
No longer experimental.
v18.0.0
No longer behind --experimental-fetch CLI flag.
v17.6.0, v16.15.0
Added in: v17.6.0, v16.15.0



Stability: 2 - Stable
A browser-compatible implementation of <FormData>.
global#

Added in: v0.1.27


Stability: 3 - Legacy. Use globalThis instead.

<Object> The global namespace object.

In browsers, the top-level scope has traditionally been the global scope. This
means that var something will define a new global variable, except within
ECMAScript modules. In Node.js, this is different. The top-level scope is not
the global scope; var something inside a Node.js module will be local to that
module, regardless of whether it is a CommonJS module or an
ECMAScript module.
Class Headers#

History

VersionChanges
v21.0.0
No longer experimental.
v18.0.0
No longer behind --experimental-fetch CLI flag.
v17.5.0, v16.15.0
Added in: v17.5.0, v16.15.0



Stability: 2 - Stable
A browser-compatible implementation of <Headers>.
localStorage#

Added in: v22.4.0

Stability: 1.0 - Early development.
A browser-compatible implementation of localStorage. Data is stored
unencrypted in the file specified by the --localstorage-file CLI flag.
The maximum amount of data that can be stored is 10 MB.
Any modification of this data outside of the Web Storage API is not supported.
Enable this API with the --experimental-webstorage CLI flag.
localStorage data is not stored per user or per request when used in the context
of a server, it is shared across all users and requests.
MessageChannel#

Added in: v15.0.0

Stability: 2 - Stable

The MessageChannel class. See MessageChannel for more details.
MessageEvent#

Added in: v15.0.0

Stability: 2 - Stable

The MessageEvent class. See MessageEvent for more details.
MessagePort#

Added in: v15.0.0

Stability: 2 - Stable

The MessagePort class. See MessagePort for more details.
module#
This variable may appear to be global but is not. See module.
Navigator#

Added in: v21.0.0

Stability: 1.1 - Active development. Disable this API with the
--no-experimental-global-navigator CLI flag.
A partial implementation of the Navigator API.
navigator#

Added in: v21.0.0

Stability: 1.1 - Active development. Disable this API with the
--no-experimental-global-navigator CLI flag.
A partial implementation of window.navigator.

navigator.hardwareConcurrency#

Added in: v21.0.0


<number>

The navigator.hardwareConcurrency read-only property returns the number of
logical processors available to the current Node.js instance.
console.log(`This process is running on ${navigator.hardwareConcurrency} logical processors`); copy

navigator.language#

Added in: v21.2.0


<string>

The navigator.language read-only property returns a string representing the
preferred language of the Node.js instance. The language will be determined by
the ICU library used by Node.js at runtime based on the
default language of the operating system.
The value is representing the language version as defined in RFC 5646.
The fallback value on builds without ICU is 'en-US'.
console.log(`The preferred language of the Node.js instance has the tag '${navigator.language}'`); copy

navigator.languages#

Added in: v21.2.0


{Array}

The navigator.languages read-only property returns an array of strings
representing the preferred languages of the Node.js instance.
By default navigator.languages contains only the value of
navigator.language, which will be determined by the ICU library used by
Node.js at runtime based on the default language of the operating system.
The fallback value on builds without ICU is ['en-US'].
console.log(`The preferred languages are '${navigator.languages}'`); copy

navigator.platform#

Added in: v21.2.0


<string>

The navigator.platform read-only property returns a string identifying the
platform on which the Node.js instance is running.
console.log(`This process is running on ${navigator.platform}`); copy

navigator.userAgent#

Added in: v21.1.0


<string>

The navigator.userAgent read-only property returns user agent
consisting of the runtime name and major version number.
console.log(`The user-agent is ${navigator.userAgent}`); // Prints "Node.js/21" copy

PerformanceEntry#

Added in: v19.0.0

Stability: 2 - Stable

The PerformanceEntry class. See PerformanceEntry for more details.
PerformanceMark#

Added in: v19.0.0

Stability: 2 - Stable

The PerformanceMark class. See PerformanceMark for more details.
PerformanceMeasure#

Added in: v19.0.0

Stability: 2 - Stable

The PerformanceMeasure class. See PerformanceMeasure for more details.
PerformanceObserver#

Added in: v19.0.0

Stability: 2 - Stable

The PerformanceObserver class. See PerformanceObserver for more details.
PerformanceObserverEntryList#

Added in: v19.0.0

Stability: 2 - Stable

The PerformanceObserverEntryList class. See
PerformanceObserverEntryList for more details.
PerformanceResourceTiming#

Added in: v19.0.0

Stability: 2 - Stable

The PerformanceResourceTiming class. See PerformanceResourceTiming for
more details.
performance#

Added in: v16.0.0

Stability: 2 - Stable
The perf_hooks.performance object.
process#

Added in: v0.1.7

Stability: 2 - Stable


<Object>

The process object. See the process object section.
queueMicrotask(callback)#

Added in: v11.0.0

Stability: 2 - Stable


callback <Function> Function to be queued.

The queueMicrotask() method queues a microtask to invoke callback. If
callback throws an exception, the process object 'uncaughtException'
event will be emitted.
The microtask queue is managed by V8 and may be used in a similar manner to
the process.nextTick() queue, which is managed by Node.js. The
process.nextTick() queue is always processed before the microtask queue
within each turn of the Node.js event loop.
// Here, `queueMicrotask()` is used to ensure the 'load' event is always
// emitted asynchronously, and therefore consistently. Using
// `process.nextTick()` here would result in the 'load' event always emitting
// before any other promise jobs.

DataHandler.prototype.load = async function load(key) {
  const hit = this._cache.get(key);
  if (hit !== undefined) {
    queueMicrotask(() => {
      this.emit('load', hit);
    });
    return;
  }

  const data = await fetchData(key);
  this._cache.set(key, data);
  this.emit('load', data);
}; copy
Class: ReadableByteStreamController#

History

VersionChanges
v23.11.0, v22.15.0
Marking the API stable.
v18.0.0
Added in: v18.0.0



A browser-compatible implementation of ReadableByteStreamController.
Class: ReadableStream#

History

VersionChanges
v23.11.0, v22.15.0
Marking the API stable.
v18.0.0
Added in: v18.0.0



A browser-compatible implementation of ReadableStream.
Class: ReadableStreamBYOBReader#

History

VersionChanges
v23.11.0, v22.15.0
Marking the API stable.
v18.0.0
Added in: v18.0.0



A browser-compatible implementation of ReadableStreamBYOBReader.
Class: ReadableStreamBYOBRequest#

History

VersionChanges
v23.11.0, v22.15.0
Marking the API stable.
v18.0.0
Added in: v18.0.0



A browser-compatible implementation of ReadableStreamBYOBRequest.
Class: ReadableStreamDefaultController#

History

VersionChanges
v23.11.0, v22.15.0
Marking the API stable.
v18.0.0
Added in: v18.0.0



A browser-compatible implementation of ReadableStreamDefaultController.
Class: ReadableStreamDefaultReader#

History

VersionChanges
v23.11.0, v22.15.0
Marking the API stable.
v18.0.0
Added in: v18.0.0



A browser-compatible implementation of ReadableStreamDefaultReader.
require()#
This variable may appear to be global but is not. See require().
Response#

History

VersionChanges
v21.0.0
No longer experimental.
v18.0.0
No longer behind --experimental-fetch CLI flag.
v17.5.0, v16.15.0
Added in: v17.5.0, v16.15.0



Stability: 2 - Stable
A browser-compatible implementation of <Response>.
Request#

History

VersionChanges
v21.0.0
No longer experimental.
v18.0.0
No longer behind --experimental-fetch CLI flag.
v17.5.0, v16.15.0
Added in: v17.5.0, v16.15.0



Stability: 2 - Stable
A browser-compatible implementation of <Request>.
sessionStorage#

Added in: v22.4.0

Stability: 1.0 - Early development.
A browser-compatible implementation of sessionStorage. Data is stored in
memory, with a storage quota of 10 MB. sessionStorage data persists only within
the currently running process, and is not shared between workers.
setImmediate(callback[, ...args])#

Added in: v0.9.1

Stability: 2 - Stable

setImmediate is described in the timers section.
setInterval(callback, delay[, ...args])#

Added in: v0.0.1

Stability: 2 - Stable

setInterval is described in the timers section.
setTimeout(callback, delay[, ...args])#

Added in: v0.0.1

Stability: 2 - Stable

setTimeout is described in the timers section.
Class: Storage#

Added in: v22.4.0

Stability: 1.0 - Early development.
A browser-compatible implementation of Storage. Enable this API with the
--experimental-webstorage CLI flag.
structuredClone(value[, options])#

Added in: v17.0.0

Stability: 2 - Stable

The WHATWG structuredClone method.
SubtleCrypto#

History

VersionChanges
v19.0.0
No longer behind --experimental-global-webcrypto CLI flag.
v17.6.0, v16.15.0
Added in: v17.6.0, v16.15.0



Stability: 2 - Stable
A browser-compatible implementation of <SubtleCrypto>. This global is available
only if the Node.js binary was compiled with including support for the
node:crypto module.
DOMException#

Added in: v17.0.0

Stability: 2 - Stable

The WHATWG DOMException class. See DOMException for more details.
TextDecoder#

Added in: v11.0.0

Stability: 2 - Stable

The WHATWG TextDecoder class. See the TextDecoder section.
Class: TextDecoderStream#

History

VersionChanges
v23.11.0, v22.15.0
Marking the API stable.
v18.0.0
Added in: v18.0.0



A browser-compatible implementation of TextDecoderStream.
TextEncoder#

Added in: v11.0.0

Stability: 2 - Stable

The WHATWG TextEncoder class. See the TextEncoder section.
Class: TextEncoderStream#

History

VersionChanges
v23.11.0, v22.15.0
Marking the API stable.
v18.0.0
Added in: v18.0.0



A browser-compatible implementation of TextEncoderStream.
Class: TransformStream#

History

VersionChanges
v23.11.0, v22.15.0
Marking the API stable.
v18.0.0
Added in: v18.0.0



A browser-compatible implementation of TransformStream.
Class: TransformStreamDefaultController#

History

VersionChanges
v23.11.0, v22.15.0
Marking the API stable.
v18.0.0
Added in: v18.0.0



A browser-compatible implementation of TransformStreamDefaultController.
URL#

Added in: v10.0.0

Stability: 2 - Stable

The WHATWG URL class. See the URL section.
URLPattern#

Added in: v24.0.0

Stability: 1 - Experimental

The WHATWG URLPattern class. See the URLPattern section.
URLSearchParams#

Added in: v10.0.0

Stability: 2 - Stable

The WHATWG URLSearchParams class. See the URLSearchParams section.
WebAssembly#

Added in: v8.0.0

Stability: 2 - Stable


<Object>

The object that acts as the namespace for all W3C
WebAssembly related functionality. See the
Mozilla Developer Network for usage and compatibility.
WebSocket#

History

VersionChanges
v22.4.0
No longer experimental.
v22.0.0
No longer behind --experimental-websocket CLI flag.
v21.0.0, v20.10.0
Added in: v21.0.0, v20.10.0



Stability: 2 - Stable
A browser-compatible implementation of WebSocket. Disable this API
with the --no-experimental-websocket CLI flag.
Class: WritableStream#

History

VersionChanges
v23.11.0, v22.15.0
Marking the API stable.
v18.0.0
Added in: v18.0.0



A browser-compatible implementation of WritableStream.
Class: WritableStreamDefaultController#

History

VersionChanges
v23.11.0, v22.15.0
Marking the API stable.
v18.0.0
Added in: v18.0.0



A browser-compatible implementation of WritableStreamDefaultController.
Class: WritableStreamDefaultWriter#

History

VersionChanges
v23.11.0, v22.15.0
Marking the API stable.
v18.0.0
Added in: v18.0.0



A browser-compatible implementation of WritableStreamDefaultWriter.\n\n\n\nWednesday, May 14, 2025 Security ReleasesThe Node.js ProjectWednesday, May 14, 2025 Security ReleasesSummary
The Node.js project will release new versions of the 24.x, 23.x, 22.x, 20.x
releases lines on or shortly after, Wednesday, May 14, 2025 in order to address:

1 high severity issues.
1 medium severity issues.
1 low severity issues.

Impact

The 24.x release line of Node.js is vulnerable to 1 high severity issues.
The 23.x release line of Node.js is vulnerable to 1 high severity issues.
The 22.x release line of Node.js is vulnerable to 1 low severity issues, 1 high severity issues.
The 20.x release line of Node.js is vulnerable to 1 low severity issues, 1 high severity issues, 1 medium severity issues.

It's important to note that End-of-Life versions are always affected when a security release occurs.
To ensure your system's security, please use an up-to-date version as outlined in our
Release Schedule.
Release timing
Releases will be available on, or shortly after, Wednesday, May 14, 2025.
Contact and future updates
The current Node.js security policy can be found at https://nodejs.org/en/security/.
Please follow the process outlined in https://github.com/nodejs/node/blob/master/SECURITY.md if you wish to report a vulnerability in Node.js.
Subscribe to the low-volume announcement-only nodejs-sec mailing list at https://groups.google.com/forum/#!forum/nodejs-sec to stay up to date on security vulnerabilities and security-related releases of Node.js and the projects maintained in the nodejs GitHub organization.NextNode.js Test CI Security Incident\n\n\n\nWednesday, May 14, 2025 Security ReleasesThe Node.js ProjectWednesday, May 14, 2025 Security ReleasesSummary
The Node.js project will release new versions of the 24.x, 23.x, 22.x, 20.x
releases lines on or shortly after, Wednesday, May 14, 2025 in order to address:

1 high severity issues.
1 medium severity issues.
1 low severity issues.

Impact

The 24.x release line of Node.js is vulnerable to 1 high severity issues.
The 23.x release line of Node.js is vulnerable to 1 high severity issues.
The 22.x release line of Node.js is vulnerable to 1 low severity issues, 1 high severity issues.
The 20.x release line of Node.js is vulnerable to 1 low severity issues, 1 high severity issues, 1 medium severity issues.

It's important to note that End-of-Life versions are always affected when a security release occurs.
To ensure your system's security, please use an up-to-date version as outlined in our
Release Schedule.
Release timing
Releases will be available on, or shortly after, Wednesday, May 14, 2025.
Contact and future updates
The current Node.js security policy can be found at https://nodejs.org/en/security/.
Please follow the process outlined in https://github.com/nodejs/node/blob/master/SECURITY.md if you wish to report a vulnerability in Node.js.
Subscribe to the low-volume announcement-only nodejs-sec mailing list at https://groups.google.com/forum/#!forum/nodejs-sec to stay up to date on security vulnerabilities and security-related releases of Node.js and the projects maintained in the nodejs GitHub organization.NextNode.js Test CI Security Incident\n\n\n\nWednesday, May 14, 2025 Security ReleasesThe Node.js ProjectWednesday, May 14, 2025 Security ReleasesSummary
The Node.js project will release new versions of the 24.x, 23.x, 22.x, 20.x
releases lines on or shortly after, Wednesday, May 14, 2025 in order to address:

1 high severity issues.
1 medium severity issues.
1 low severity issues.

Impact

The 24.x release line of Node.js is vulnerable to 1 high severity issues.
The 23.x release line of Node.js is vulnerable to 1 high severity issues.
The 22.x release line of Node.js is vulnerable to 1 low severity issues, 1 high severity issues.
The 20.x release line of Node.js is vulnerable to 1 low severity issues, 1 high severity issues, 1 medium severity issues.

It's important to note that End-of-Life versions are always affected when a security release occurs.
To ensure your system's security, please use an up-to-date version as outlined in our
Release Schedule.
Release timing
Releases will be available on, or shortly after, Wednesday, May 14, 2025.
Contact and future updates
The current Node.js security policy can be found at https://nodejs.org/en/security/.
Please follow the process outlined in https://github.com/nodejs/node/blob/master/SECURITY.md if you wish to report a vulnerability in Node.js.
Subscribe to the low-volume announcement-only nodejs-sec mailing list at https://groups.google.com/forum/#!forum/nodejs-sec to stay up to date on security vulnerabilities and security-related releases of Node.js and the projects maintained in the nodejs GitHub organization.NextNode.js Test CI Security Incident\n\n\n\nWednesday, May 14, 2025 Security ReleasesThe Node.js ProjectWednesday, May 14, 2025 Security ReleasesSummary
The Node.js project will release new versions of the 24.x, 23.x, 22.x, 20.x
releases lines on or shortly after, Wednesday, May 14, 2025 in order to address:

1 high severity issues.
1 medium severity issues.
1 low severity issues.

Impact

The 24.x release line of Node.js is vulnerable to 1 high severity issues.
The 23.x release line of Node.js is vulnerable to 1 high severity issues.
The 22.x release line of Node.js is vulnerable to 1 low severity issues, 1 high severity issues.
The 20.x release line of Node.js is vulnerable to 1 low severity issues, 1 high severity issues, 1 medium severity issues.

It's important to note that End-of-Life versions are always affected when a security release occurs.
To ensure your system's security, please use an up-to-date version as outlined in our
Release Schedule.
Release timing
Releases will be available on, or shortly after, Wednesday, May 14, 2025.
Contact and future updates
The current Node.js security policy can be found at https://nodejs.org/en/security/.
Please follow the process outlined in https://github.com/nodejs/node/blob/master/SECURITY.md if you wish to report a vulnerability in Node.js.
Subscribe to the low-volume announcement-only nodejs-sec mailing list at https://groups.google.com/forum/#!forum/nodejs-sec to stay up to date on security vulnerabilities and security-related releases of Node.js and the projects maintained in the nodejs GitHub organization.NextNode.js Test CI Security Incident\n\n\n\nSecurity
Reporting a bug in Node.js
Report security bugs in Node.js via HackerOne.
Normally, your report will be acknowledged within 5 days, and you'll receive
a more detailed response to your report within 10 days indicating the
next steps in handling your submission. These timelines may extend when
our triage volunteers are away on holiday, particularly at the end of the
year.
After the initial reply to your report, the security team will endeavor to keep
you informed of the progress being made towards a fix and full announcement,
and may ask for additional information or guidance surrounding the reported
issue.
Node.js bug bounty program
The Node.js project engages in an official bug bounty program for security
researchers and responsible public disclosures.  The program is managed through
the HackerOne platform. See https://hackerone.com/nodejs for further details.
Reporting a bug in a third-party module
Security bugs in third-party modules should be reported to their respective
maintainers.
Disclosure policy
Here is the security disclosure policy for Node.js


The security report is received and is assigned a primary handler. This
person will coordinate the fix and release process. The problem is validated
against all supported Node.js versions. Once confirmed, a list of all affected
versions is determined. Code is audited to find any potential similar
problems. Fixes are prepared for all supported releases.
These fixes are not committed to the public repository but rather held locally
pending the announcement.


A suggested embargo date for this vulnerability is chosen and a CVE (Common
Vulnerabilities and Exposures (CVE®)) is requested for the vulnerability.


On the embargo date, a copy of the announcement is sent to the Node.js
security mailing list. The changes are pushed to the public repository and new
builds are deployed to nodejs.org. Within 6 hours of the mailing list being
notified, a copy of the advisory will be published on the Node.js blog.


Typically, the embargo date will be set 72 hours from the time the CVE is
issued. However, this may vary depending on the severity of the bug or
difficulty in applying a fix.


This process can take some time, especially when we need to coordinate with
maintainers of other projects. We will try to handle the bug as quickly as
possible; however, we must follow the release process above to ensure that we
handle disclosure consistently.


Code of Conduct and Vulnerability Reporting Guidelines
When reporting security vulnerabilities, reporters must adhere to the following guidelines:


Code of Conduct Compliance: All security reports must comply with our
Code of Conduct. Reports that violate our code of conduct
will not be considered and may result in being banned from future participation.


No Harmful Actions: Security research and vulnerability reporting must not:

Cause damage to running systems or production environments.
Disrupt Node.js development or infrastructure.
Affect other users' applications or systems.
Include actual exploits that could harm users.
Involve social engineering or phishing attempts.



Responsible Testing: When testing potential vulnerabilities:

Use isolated, controlled environments.
Do not test on production systems without prior authorization. Contact
the Node.js Technical Steering Committee (tsc@iojs.org) for permission or open
a HackerOne report.
Do not attempt to access or modify other users' data.
Immediately stop testing if unauthorized access is gained accidentally.



Report Quality

Provide clear, detailed steps to reproduce the vulnerability.
Include only the minimum proof of concept required to demonstrate the issue.
Remove any malicious payloads or components that could cause harm.



Failure to follow these guidelines may result in:

Rejection of the vulnerability report.
Forfeiture of any potential bug bounty.
Temporary or permanent ban from the bug bounty program.
Legal action in cases of malicious intent.

The Node.js threat model
In the Node.js threat model, there are trusted elements such as the
underlying operating system. Vulnerabilities that require the compromise
of these trusted elements are outside the scope of the Node.js threat
model.
For a vulnerability to be eligible for a bug bounty, it must be a
vulnerability in the context of the Node.js threat model. In other
words, it cannot assume that a trusted element (such as the operating
system) has been compromised.
Being able to cause the following through control of the elements that Node.js
does not trust is considered a vulnerability:

Disclosure or loss of integrity or confidentiality of data protected through
the correct use of Node.js APIs.
The unavailability of the runtime, including the unbounded degradation of its
performance.

If Node.js loads configuration files or runs code by default (without a
specific request from the user), and this is not documented, it is considered a
vulnerability.
Vulnerabilities related to this case may be fixed by a documentation update.
Node.js does NOT trust:

Data received from the remote end of inbound network connections
that are accepted through the use of Node.js APIs and
which is transformed/validated by Node.js before being passed
to the application. This includes:

HTTP APIs (all flavors) server APIs.


The data received from the remote end of outbound network connections
that are created through the use of Node.js APIs and
which is transformed/validated by Node.js before being passed
to the application EXCEPT with respect to payload length. Node.js trusts
that applications make connections/requests which will avoid payload
sizes that will result in a Denial of Service.

HTTP APIs (all flavors) client APIs.
DNS APIs.


Consumers of data protected through the use of Node.js APIs (for example,
people who have access to data encrypted through the Node.js crypto APIs).
The file content or other I/O that is opened for reading or writing by the
use of Node.js APIs (ex: stdin, stdout, stderr).

In other words, if the data passing through Node.js to/from the application
can trigger actions other than those documented for the APIs, there is likely
a security vulnerability. Examples of unwanted actions are polluting globals,
causing an unrecoverable crash, or any other unexpected side effects that can
lead to a loss of confidentiality, integrity, or availability.
For example, if trusted input (like secure application code) is correct,
then untrusted input must not lead to arbitrary JavaScript code execution.
Node.js trusts everything else. Examples include:

The developers and infrastructure that runs it.
The operating system that Node.js is running under and its configuration,
along with anything under control of the operating system.
The code it is asked to run, including JavaScript, WASM and native code, even
if said code is dynamically loaded, e.g., all dependencies installed from the
npm registry.
The code run inherits all the privileges of the execution user.
Inputs provided to it by the code it is asked to run, as it is the
responsibility of the application to perform the required input validations,
e.g. the input to JSON.parse().
Any connection used for inspector (debugger protocol) regardless of being
opened by command line options or Node.js APIs, and regardless of the remote
end being on the local machine or remote.
The file system when requiring a module.
See https://nodejs.org/api/modules.html#all-together.
The node:wasi module does not currently provide the comprehensive file
system security properties provided by some WASI runtimes.

Any unexpected behavior from the data manipulation from Node.js Internal
functions may be considered a vulnerability if they are exploitable via
untrusted resources.
In addition to addressing vulnerabilities based on the above, the project works
to avoid APIs and internal implementations that make it "easy" for application
code to use the APIs incorrectly in a way that results in vulnerabilities within
the application code itself. While we don’t consider those vulnerabilities in
Node.js itself and will not necessarily issue a CVE, we do want them to be
reported privately to Node.js first.
We often choose to work to improve our APIs based on those reports and issue
fixes either in regular or security releases depending on how much of a risk to
the community they pose.
Examples of vulnerabilities
Improper Certificate Validation (CWE-295)

Node.js provides APIs to validate handling of Subject Alternative Names (SANs)
in certificates used to connect to a TLS/SSL endpoint. If certificates can be
crafted which result in incorrect validation by the Node.js APIs that is
considered a vulnerability.

Inconsistent Interpretation of HTTP Requests (CWE-444)

Node.js provides APIs to accept http connections. Those APIs parse the
headers received for a connection and pass them on to the application.
Bugs in parsing those headers which can result in request smuggling are
considered vulnerabilities.

Missing Cryptographic Step (CWE-325)

Node.js provides APIs to encrypt data. Bugs that would allow an attacker
to get the original data without requiring the decryption key are
considered vulnerabilities.

External Control of System or Configuration Setting (CWE-15)

If Node.js automatically loads a configuration file which is not documented
and modification of that configuration can affect the confidentiality of
data protected using the Node.js APIs this is considered a vulnerability.

Examples of non-vulnerabilities
Malicious Third-Party Modules (CWE-1357)

Code is trusted by Node.js. Therefore any scenario that requires a malicious
third-party module cannot result in a vulnerability in Node.js.

Prototype Pollution Attacks (CWE-1321)

Node.js trusts the inputs provided to it by application code.
It is up to the application to sanitize appropriately. Therefore any scenario
that requires control over user input is not considered a vulnerability.

Uncontrolled Search Path Element (CWE-427)

Node.js trusts the file system in the environment accessible to it.
Therefore, it is not a vulnerability if it accesses/loads files from any path
that is accessible to it.

External Control of System or Configuration Setting (CWE-15)

If Node.js automatically loads a configuration file which is documented
no scenario that requires modification of that configuration file is
considered a vulnerability.

Uncontrolled Resource Consumption (CWE-400) on outbound connections

If Node.js is asked to connect to a remote site and return an
artifact, it is not considered a vulnerability if the size of
that artifact is large enough to impact performance or
cause the runtime to run out of resources.

Vulnerabilities affecting software downloaded by Corepack

Corepack defaults to downloading the latest version of the software requested
by the user, or a specific version requested by the user. For this reason,
Node.js releases won't be affected by such vulnerabilities. Users are
responsible for keeping the software they use through Corepack up-to-date.

Assessing experimental features reports
Experimental features are eligible to reports as any other stable feature of
Node.js. They will also be susceptible to receiving the same severity score
as any other stable feature.
Receiving security updates
Security notifications will be distributed via the following methods.

https://groups.google.com/group/nodejs-sec
https://nodejs.org/en/blog/vulnerability

Comments on this policy
If you have suggestions on how this process could be improved, please visit
the nodejs/security-wg
repository.\n\nnodejs
    
    /
    
      node
    

    Public
  


        

        
            
    
        
          
        

      

  
                Notifications
    You must be signed in to change notification settings

  

  
              Fork
    31.5k

  

  
        
            
          Star
          111k

  



        
      

        



          

  
      
  
    
              
        Code
          


    

      
  
    
              
        Issues
          1.7k


    

      
  
    
              
        Pull requests
          549


    

      
  
    
              
        Actions
          


    

      
  
    
              
        Projects
          2


    

      
  
    
              
        Security
          

    

      
  
    
              
        Insights
          


    


          
  
      
Additional navigation options



  
    
                
  
    
        
    
    
    
        
          
        
      
        
          Code
      

  

        
    
    
    
        
          
        
      
        
          Issues
      

  

        
    
    
    
        
          
        
      
        
          Pull requests
      

  

        
    
    
    
        
          
        
      
        
          Actions
      

  

        
    
    
    
        
          
        
      
        
          Projects
      

  

        
    
    
    
        
          
        
      
        
          Security
      

  

        
    
    
    
        
          
        
      
        
          Insights
      

  

    




      
  



  

  




    
    



    
      
Security: nodejs/node



    
  
          
Security Navigation


  
  
    
        
          

    
    
    
        
          
        
      
        
              Overview

      

  


          
        
          


  
      
  
    Reporting
  

    
        

    
    
    
        
          
        
      
        
                Policy

      

  


        

    
    
    
        
          
        
      
        
                    Advisories
          
    

  


      

  


    



  



          
    
  
  
    
      
        SECURITY.md
      
    
    
      Security
Reporting a bug in Node.js
Report security bugs in Node.js via HackerOne.
Normally, your report will be acknowledged within 5 days, and you'll receive
a more detailed response to your report within 10 days indicating the
next steps in handling your submission. These timelines may extend when
our triage volunteers are away on holiday, particularly at the end of the
year.
After the initial reply to your report, the security team will endeavor to keep
you informed of the progress being made towards a fix and full announcement,
and may ask for additional information or guidance surrounding the reported
issue.
Node.js bug bounty program
The Node.js project engages in an official bug bounty program for security
researchers and responsible public disclosures.  The program is managed through
the HackerOne platform. See https://hackerone.com/nodejs for further details.
Reporting a bug in a third-party module
Security bugs in third-party modules should be reported to their respective
maintainers.
Disclosure policy
Here is the security disclosure policy for Node.js


The security report is received and is assigned a primary handler. This
person will coordinate the fix and release process. The problem is validated
against all supported Node.js versions. Once confirmed, a list of all affected
versions is determined. Code is audited to find any potential similar
problems. Fixes are prepared for all supported releases.
These fixes are not committed to the public repository but rather held locally
pending the announcement.


A suggested embargo date for this vulnerability is chosen and a CVE (Common
Vulnerabilities and Exposures (CVE®)) is requested for the vulnerability.


On the embargo date, a copy of the announcement is sent to the Node.js
security mailing list. The changes are pushed to the public repository and new
builds are deployed to nodejs.org. Within 6 hours of the mailing list being
notified, a copy of the advisory will be published on the Node.js blog.


Typically, the embargo date will be set 72 hours from the time the CVE is
issued. However, this may vary depending on the severity of the bug or
difficulty in applying a fix.


This process can take some time, especially when we need to coordinate with
maintainers of other projects. We will try to handle the bug as quickly as
possible; however, we must follow the release process above to ensure that we
handle disclosure consistently.


Code of Conduct and Vulnerability Reporting Guidelines
When reporting security vulnerabilities, reporters must adhere to the following guidelines:


Code of Conduct Compliance: All security reports must comply with our
Code of Conduct. Reports that violate our code of conduct
will not be considered and may result in being banned from future participation.


No Harmful Actions: Security research and vulnerability reporting must not:

Cause damage to running systems or production environments.
Disrupt Node.js development or infrastructure.
Affect other users' applications or systems.
Include actual exploits that could harm users.
Involve social engineering or phishing attempts.



Responsible Testing: When testing potential vulnerabilities:

Use isolated, controlled environments.
Do not test on production systems without prior authorization. Contact
the Node.js Technical Steering Committee (tsc@iojs.org) for permission or open
a HackerOne report.
Do not attempt to access or modify other users' data.
Immediately stop testing if unauthorized access is gained accidentally.



Report Quality

Provide clear, detailed steps to reproduce the vulnerability.
Include only the minimum proof of concept required to demonstrate the issue.
Remove any malicious payloads or components that could cause harm.



Failure to follow these guidelines may result in:

Rejection of the vulnerability report.
Forfeiture of any potential bug bounty.
Temporary or permanent ban from the bug bounty program.
Legal action in cases of malicious intent.

The Node.js threat model
In the Node.js threat model, there are trusted elements such as the
underlying operating system. Vulnerabilities that require the compromise
of these trusted elements are outside the scope of the Node.js threat
model.
For a vulnerability to be eligible for a bug bounty, it must be a
vulnerability in the context of the Node.js threat model. In other
words, it cannot assume that a trusted element (such as the operating
system) has been compromised.
Being able to cause the following through control of the elements that Node.js
does not trust is considered a vulnerability:

Disclosure or loss of integrity or confidentiality of data protected through
the correct use of Node.js APIs.
The unavailability of the runtime, including the unbounded degradation of its
performance.

If Node.js loads configuration files or runs code by default (without a
specific request from the user), and this is not documented, it is considered a
vulnerability.
Vulnerabilities related to this case may be fixed by a documentation update.
Node.js does NOT trust:

Data received from the remote end of inbound network connections
that are accepted through the use of Node.js APIs and
which is transformed/validated by Node.js before being passed
to the application. This includes:

HTTP APIs (all flavors) server APIs.


The data received from the remote end of outbound network connections
that are created through the use of Node.js APIs and
which is transformed/validated by Node.js before being passed
to the application EXCEPT with respect to payload length. Node.js trusts
that applications make connections/requests which will avoid payload
sizes that will result in a Denial of Service.

HTTP APIs (all flavors) client APIs.
DNS APIs.


Consumers of data protected through the use of Node.js APIs (for example,
people who have access to data encrypted through the Node.js crypto APIs).
The file content or other I/O that is opened for reading or writing by the
use of Node.js APIs (ex: stdin, stdout, stderr).

In other words, if the data passing through Node.js to/from the application
can trigger actions other than those documented for the APIs, there is likely
a security vulnerability. Examples of unwanted actions are polluting globals,
causing an unrecoverable crash, or any other unexpected side effects that can
lead to a loss of confidentiality, integrity, or availability.
For example, if trusted input (like secure application code) is correct,
then untrusted input must not lead to arbitrary JavaScript code execution.
Node.js trusts everything else. Examples include:

The developers and infrastructure that runs it.
The operating system that Node.js is running under and its configuration,
along with anything under control of the operating system.
The code it is asked to run, including JavaScript, WASM and native code, even
if said code is dynamically loaded, e.g., all dependencies installed from the
npm registry.
The code run inherits all the privileges of the execution user.
Inputs provided to it by the code it is asked to run, as it is the
responsibility of the application to perform the required input validations,
e.g. the input to JSON.parse().
Any connection used for inspector (debugger protocol) regardless of being
opened by command line options or Node.js APIs, and regardless of the remote
end being on the local machine or remote.
The file system when requiring a module.
See https://nodejs.org/api/modules.html#all-together.
The node:wasi module does not currently provide the comprehensive file
system security properties provided by some WASI runtimes.

Any unexpected behavior from the data manipulation from Node.js Internal
functions may be considered a vulnerability if they are exploitable via
untrusted resources.
In addition to addressing vulnerabilities based on the above, the project works
to avoid APIs and internal implementations that make it "easy" for application
code to use the APIs incorrectly in a way that results in vulnerabilities within
the application code itself. While we don’t consider those vulnerabilities in
Node.js itself and will not necessarily issue a CVE, we do want them to be
reported privately to Node.js first.
We often choose to work to improve our APIs based on those reports and issue
fixes either in regular or security releases depending on how much of a risk to
the community they pose.
Examples of vulnerabilities
Improper Certificate Validation (CWE-295)

Node.js provides APIs to validate handling of Subject Alternative Names (SANs)
in certificates used to connect to a TLS/SSL endpoint. If certificates can be
crafted which result in incorrect validation by the Node.js APIs that is
considered a vulnerability.

Inconsistent Interpretation of HTTP Requests (CWE-444)

Node.js provides APIs to accept http connections. Those APIs parse the
headers received for a connection and pass them on to the application.
Bugs in parsing those headers which can result in request smuggling are
considered vulnerabilities.

Missing Cryptographic Step (CWE-325)

Node.js provides APIs to encrypt data. Bugs that would allow an attacker
to get the original data without requiring the decryption key are
considered vulnerabilities.

External Control of System or Configuration Setting (CWE-15)

If Node.js automatically loads a configuration file which is not documented
and modification of that configuration can affect the confidentiality of
data protected using the Node.js APIs this is considered a vulnerability.

Examples of non-vulnerabilities
Malicious Third-Party Modules (CWE-1357)

Code is trusted by Node.js. Therefore any scenario that requires a malicious
third-party module cannot result in a vulnerability in Node.js.

Prototype Pollution Attacks (CWE-1321)

Node.js trusts the inputs provided to it by application code.
It is up to the application to sanitize appropriately. Therefore any scenario
that requires control over user input is not considered a vulnerability.

Uncontrolled Search Path Element (CWE-427)

Node.js trusts the file system in the environment accessible to it.
Therefore, it is not a vulnerability if it accesses/loads files from any path
that is accessible to it.

External Control of System or Configuration Setting (CWE-15)

If Node.js automatically loads a configuration file which is documented
no scenario that requires modification of that configuration file is
considered a vulnerability.

Uncontrolled Resource Consumption (CWE-400) on outbound connections

If Node.js is asked to connect to a remote site and return an
artifact, it is not considered a vulnerability if the size of
that artifact is large enough to impact performance or
cause the runtime to run out of resources.

Vulnerabilities affecting software downloaded by Corepack

Corepack defaults to downloading the latest version of the software requested
by the user, or a specific version requested by the user. For this reason,
Node.js releases won't be affected by such vulnerabilities. Users are
responsible for keeping the software they use through Corepack up-to-date.

Assessing experimental features reports
Experimental features are eligible to reports as any other stable feature of
Node.js. They will also be susceptible to receiving the same severity score
as any other stable feature.
Receiving security updates
Security notifications will be distributed via the following methods.

https://groups.google.com/group/nodejs-sec
https://nodejs.org/en/blog/vulnerability

Comments on this policy
If you have suggestions on how this process could be improved, please visit
the nodejs/security-wg
repository.\n\n\n\nNode.js Test CI Security IncidentNode.js Technical Steering CommitteeNode.js Test CI Security Incident(Update 23-April-2025) Node.js Test CI Security Incident – Full Disclosure
Summary
On March 21, 2025, we received a security report via HackerOne (link restricted at time of writing), detailing a successful compromise of several Node.js test CI hosts.
According to the HackerOne report, the exploit proceeded as follows:

Submit a valid pull request to nodejs/node.
Wait for a maintainer to add the request-ci label (this label is added to every pull request with non-documentation changes).
After approval, update the pull request using an outdated Git commit timestamp.
When Jenkins pipelines trigger, they fetch and execute code from the forked pull request.
Attain code execution on Node.js Jenkins agents.

Upon review, we identified that the request-ci label step simplifies but is not required to carry out the attack. A similar attack could be used against the commit-queue label, thus potentially allowing an attacker to land an unauthorized code change.
The core issue stems from a Time-of-Check-Time-of-Use (TOCTOU) vulnerability between initiating a CI build and the moment the Jenkins job checks out the code. Previously, CI jobs used Git references (refs/pull/<pr_id>/head), which attackers can alter after triggering the CI. Importantly, the collaborator initiating the CI build did nothing wrong—the pull request appeared safe when CI was triggered.


Remediation
In response to this security incident, the Node.js security team took measures to mitigate risks and secure the infrastructure.

Immediately upon confirmation of the vulnerability, access to initiate new Jenkins CI runs was restricted to prevent further compromise while the team validated the report.
All compromised hosts (24 machines) were swiftly identified, removed from Jenkins, and rebuilt to eliminate any potential residual risk left over from the initial ingress.
Security improvements were implemented in Jenkins jobs to validate commit SHAs, ensuring jobs only executed trusted and verified code.
request-ci and commit-queue labels now act relying on validated commit SHAs instead of comparing dates.
Comprehensive audits were carried out across 140 Jenkins jobs, prioritizing frequently used ones, to detect and remediate vulnerabilities.
Identified vulnerable GitHub workflows were temporarily disabled, promptly patched, and re-enabled with enhanced security measures.

These targeted actions significantly strengthened the security posture of our CI infrastructure, preventing the recurrence of similar potential
intrusions and ensuring safe operations moving forward.
The change we implemented now requires every pull request to be approved before running the Jenkins CI - or for collaborators to specify the individual SHA.
Timeline

Friday, 21 March 2025: Report received on Hackerone. Initial triage confirmed the report as a genuine issue. The ability to start new Jenkins CI runs was restricted to prevent any further machine compromises.
Monday, 24 March 2025: All compromised machines (totalling 24) were identified and removed from Jenkins (pending a complete rebuild). Initial attempts to evaluate all 140 jobs defined in our Jenkins instance for vulnerability. Work started on updating the most often used vulnerable jobs to take an expected commit SHA and only proceed if the SHA of the code checked out on the machine matches.
Tuesday, 25 March 2025: Some affected hosts rebuilt. The updated jobs failed on macOS and were investigated and updated again.
Wednesday, 26 March 2025: More jobs updated and affected hosts rebuilt. Some GitHub workflows also identified as being vulnerable to similar attacks and disabled.
Thursday, 27 March 2025: Validation logic in the updated jobs tweaked again to allow daily testing on non-pull request branches. Decision taken to disable all remaining jobs that had not been evaluated for the vulnerability or identified as needing the fix applied. More machines rebuilt.
Friday, 28 March 2025: GitHub workflows were patched and commit-queue was re-enabled.
Tuesday, 1 April 2025: Ability to start jobs on Jenkins and via request-ci was reenabled. Some lesser used jobs were still disabled.
Wednesday, 2 April 2025: More machines rebuilt.
Thursday, 3 April 2025: Benchmarking and libuv CI jobs updated.

Security vs. Developer Experience
Over 300 volunteers maintain the Node.js project. Our processes aim to streamline CI initiation and verification of contributions across approximately 100 Jenkins runners spanning multiple operating systems and CPU architectures.
The existing CI system design anticipates potential compromises, recognizing the need to balance security with developer convenience.
Volunteer Organization
As a volunteer-driven organization, we rely on people dedicating their time to work on unglamorous tasks, such as hardening CI, handling security reports, and assembling releases. Even good-faith research against our live systems could significantly disrupt our operations. As always, we welcome all sorts of contributions, including penetration testing. We ask researchers to give us a heads up on what they are attempting to do on live systems and to keep an auditable record of their actions through our HackerOne program or by contacting the Node.js Technical Steering Committee directly ([email protected]). More on that in our SECURITY.md file.

Node.js Test CI Security Incident – Notice
On March 21st, the Node.js project received a security report regarding our development infrastructure via our bug bounty program. We immediately restricted access while implementing corrective actions.
The reported issue did not impact the Node.js runtime and there is no risk to users of Node.js. No action by Node.js users is required.
The development infrastructure is expected to be available to the community by April 15 or sooner.
A full report of this incident will be available forthcoming. We appreciate the time investment from our amazing volunteers who assisted in this response.
Contact and future updates
The current Node.js security policy can be found at https://nodejs.org/security/. Please follow the process outlined in https://github.com/nodejs/node/security/policy if you wish to report a vulnerability in Node.js.
Subscribe to the low-volume announcement-only nodejs-sec mailing list at https://groups.google.com/forum/#!forum/nodejs-sec to stay up to date on security vulnerabilities and security-related releases of Node.js and the projects maintained in the nodejs GitHub organization.PrevWednesday, May 14, 2025 Security ReleasesNextUpdates on CVE for End-of-Life Versions\n\n\n\nIntroduction to Node.js
Node.js is an open-source and cross-platform JavaScript runtime environment. It is a popular tool for almost any kind of project!
Node.js runs the V8 JavaScript engine, the core of Google Chrome, outside of the browser. This allows Node.js to be very performant.
A Node.js app runs in a single process, without creating a new thread for every request. Node.js provides a set of asynchronous I/O primitives in its standard library that prevent JavaScript code from blocking and generally, libraries in Node.js are written using non-blocking paradigms, making blocking behavior the exception rather than the norm.
When Node.js performs an I/O operation, like reading from the network, accessing a database or the filesystem, instead of blocking the thread and wasting CPU cycles waiting, Node.js will resume the operations when the response comes back.
This allows Node.js to handle thousands of concurrent connections with a single server without introducing the burden of managing thread concurrency, which could be a significant source of bugs.
Node.js has a unique advantage because millions of frontend developers that write JavaScript for the browser are now able to write the server-side code in addition to the client-side code without the need to learn a completely different language.
In Node.js the new ECMAScript standards can be used without problems, as you don't have to wait for all your users to update their browsers - you are in charge of deciding which ECMAScript version to use by changing the Node.js version, and you can also enable specific experimental features by running Node.js with flags.
An Example Node.js Application
The most common example Hello World of Node.js is a web server:
CJSMJSconst { createServer } = require('node:http');

const hostname = '127.0.0.1';
const port = 3000;

const server = createServer((req, res) => {
  res.statusCode = 200;
  res.setHeader('Content-Type', 'text/plain');
  res.end('Hello World');
});

server.listen(port, hostname, () => {
  console.log(`Server running at http://${hostname}:${port}/`);
});
JavaScriptCopy to clipboardTo run this snippet, save it as a server.js file and run node server.js in your terminal.
If you use mjs version of the code, you should save it as a server.mjs file and run node server.mjs in your terminal.
This code first includes the Node.js http module.
Node.js has a fantastic standard library, including first-class support for networking.
The createServer() method of http creates a new HTTP server and returns it.
The server is set to listen on the specified port and host name. When the server is ready, the callback function is called, in this case informing us that the server is running.
Whenever a new request is received, the request event is called, providing two objects: a request (an http.IncomingMessage object) and a response (an http.ServerResponse object).
Those 2 objects are essential to handle the HTTP call.
The first provides the request details. In this simple example, this is not used, but you could access the request headers and request data.
The second is used to return data to the caller.
In this case with:
res.statusCode = 200;
JavaScriptCopy to clipboard
we set the statusCode property to 200, to indicate a successful response.
We set the Content-Type header:
res.setHeader('Content-Type', 'text/plain');
JavaScriptCopy to clipboard
and we close the response, adding the content as an argument to end():
res.end('Hello World\n');
JavaScriptCopy to clipboard
If you haven't already done so, download Node.js.NextHow much JavaScript do you need to know to use Node.js?\n\n\n\nHow much JavaScript do you need to know to use Node.js?
As a beginner, it's hard to get to a point where you are confident enough in your programming abilities. While learning to code, you might also be confused at where does JavaScript end, and where Node.js begins, and vice versa.
What is recommended to learn before diving deep with Node.js?

Lexical Structure
Expressions
Data Types
Classes
Variables
Functions
this operator
Arrow Functions
Loops
Scopes
Arrays
Template Literals
Strict Mode
ECMAScript 2015 (ES6) and beyond
Asynchronous JavaScript

With those concepts in mind, you are well on your road to become a proficient JavaScript developer, in both the browser and in Node.js.
Asynchronous Programming
The following concepts are also key to understand asynchronous programming, which is one of the fundamental parts of Node.js:

Asynchronous programming and callbacks
Timers
Promises
Async and Await
Closures
The Event Loop
PrevIntroduction to Node.jsNextDifferences between Node.js and the Browser\n\n\n\nDifferences between Node.js and the Browser
Both the browser and Node.js use JavaScript as their programming language. Building apps that run in the browser is completely different from building a Node.js application. Despite the fact that it's always JavaScript, there are some key differences that make the experience radically different.
From the perspective of a frontend developer who extensively uses JavaScript, Node.js apps bring with them a huge advantage: the comfort of programming everything - the frontend and the backend - in a single language.
You have a huge opportunity because we know how hard it is to fully, deeply learn a programming language, and by using the same language to perform all your work on the web - both on the client and on the server, you're in a unique position of advantage.

What changes is the ecosystem.

In the browser, most of the time what you are doing is interacting with the DOM, or other Web Platform APIs like Cookies. Those do not exist in Node.js, of course. You don't have the document, window and all the other objects that are provided by the browser.
And in the browser, we don't have all the nice APIs that Node.js provides through its modules, like the filesystem access functionality.
Another big difference is that in Node.js you control the environment. Unless you are building an open source application that anyone can deploy anywhere, you know which version of Node.js you will run the application on. Compared to the browser environment, where you don't get the luxury to choose what browser your visitors will use, this is very convenient.
This means that you can write all the modern ES2015+ JavaScript that your Node.js version supports. Since JavaScript moves so fast, but browsers can be a bit slow to upgrade, sometimes on the web you are stuck with using older JavaScript / ECMAScript releases. You can use Babel to transform your code to be ES5-compatible before shipping it to the browser, but in Node.js, you won't need that.
Another difference is that Node.js supports both the CommonJS and ES module systems (since Node.js v12), while in the browser, we are starting to see the ES Modules standard being implemented.
In practice, this means that you can use both require() and import in Node.js, while you are limited to import in the browser.PrevHow much JavaScript do you need to know to use Node.js?NextThe V8 JavaScript Engine\n\n\n\nThe V8 JavaScript Engine
V8 is the name of the JavaScript engine that powers Google Chrome. It's the thing that takes our JavaScript and executes it while browsing with Chrome.
V8 is the JavaScript engine i.e. it parses and executes JavaScript code. The DOM, and the other Web Platform APIs (they all makeup runtime environment) are provided by the browser.
The cool thing is that the JavaScript engine is independent of the browser in which it's hosted. This key feature enabled the rise of Node.js. V8 was chosen to be the engine that powered Node.js back in 2009, and as the popularity of Node.js exploded, V8 became the engine that now powers an incredible amount of server-side code written in JavaScript.
The Node.js ecosystem is huge and thanks to V8 which also powers desktop apps, with projects like Electron.
Other JS engines
Other browsers have their own JavaScript engine:

Firefox has SpiderMonkey
Safari has JavaScriptCore (also called Nitro)
Edge was originally based on Chakra but has more recently been rebuilt using Chromium and the V8 engine.

and many others exist as well.
All those engines implement the ECMA ES-262 standard, also called ECMAScript, the standard used by JavaScript.
The quest for performance
V8 is written in C++, and it's continuously improved. It is portable and runs on Mac, Windows, Linux and several other systems.
In this V8 introduction, we will ignore the implementation details of V8: they can be found on more authoritative sites (e.g. the V8 official site), and they change over time, often radically.
V8 is always evolving, just like the other JavaScript engines around, to speed up the Web and the Node.js ecosystem.
On the web, there is a race for performance that's been going on for years, and we (as users and developers) benefit a lot from this competition because we get faster and more optimized machines year after year.
Compilation
JavaScript is generally considered an interpreted language, but modern JavaScript engines no longer just interpret JavaScript, they compile it.
This has been happening since 2009, when the SpiderMonkey JavaScript compiler was added to Firefox 3.5, and everyone followed this idea.
JavaScript is internally compiled by V8 with just-in-time (JIT) compilation to speed up the execution.
This might seem counter-intuitive, but since the introduction of Google Maps in 2004, JavaScript has evolved from a language that was generally executing a few dozens of lines of code to complete applications with thousands to hundreds of thousands of lines running in the browser.
Our applications can now run for hours inside a browser, rather than being just a few form validation rules or simple scripts.
In this new world, compiling JavaScript makes perfect sense because while it might take a little bit more to have the JavaScript ready, once done it's going to be much more performant than purely interpreted code.PrevDifferences between Node.js and the BrowserNextAn introduction to the npm package manager\n\n\n\nAn introduction to the npm package manager
Introduction to npm
npm is the standard package manager for Node.js.
In September 2022 over 2.1 million packages were reported being listed in the npm registry, making it the biggest single language code repository on Earth, and you can be sure there is a package for (almost!) everything.
It started as a way to download and manage dependencies of Node.js packages, but it has since become a tool used also in frontend JavaScript.

Yarn and pnpm are alternatives to npm cli. You can check them out as well.

Packages
npm installs, updates and manages downloads of dependencies of your project. Dependencies are pre-built pieces of code, such as libraries and packages, that your Node.js application needs to work.
Installing all dependencies
If a project has a package.json file, by running
npm install
ShellCopy to clipboard
it will install everything the project needs, in the node_modules folder, creating it if it's not existing already.
Installing a single package
You can also install a specific package by running
npm install <package-name>
ShellCopy to clipboard
Furthermore, since npm 5, this command adds <package-name> to the package.json file dependencies. Before version 5, you needed to add the flag --save.
Often you'll see more flags added to this command:

--save-dev installs and adds the entry to the package.json file devDependencies
--no-save installs but does not add the entry to the package.json file dependencies
--save-optional installs and adds the entry to the package.json file optionalDependencies
--no-optional will prevent optional dependencies from being installed

Shorthands of the flags can also be used:

-S: --save
-D: --save-dev
-O: --save-optional

The difference between devDependencies and dependencies is that the former contains development tools, like a testing library, while the latter is bundled with the app in production.
As for the optionalDependencies the difference is that build failure of the dependency will not cause installation to fail. But it is your program's responsibility to handle the lack of the dependency. Read more about optional dependencies.
Updating packages
Updating is also made easy, by running
npm update
ShellCopy to clipboard
npm will check all packages for a newer version that satisfies your versioning constraints.
You can specify a single package to update as well:
npm update <package-name>
ShellCopy to clipboard
Versioning
In addition to plain downloads, npm also manages versioning, so you can specify any specific version of a package, or require a version higher or lower than what you need.
Many times you'll find that a library is only compatible with a major release of another library.
Or a bug in the latest release of a lib, still unfixed, is causing an issue.
Specifying an explicit version of a library also helps to keep everyone on the same exact version of a package, so that the whole team runs the same version until the package.json file is updated.
In all those cases, versioning helps a lot, and npm follows the semantic versioning (semver) standard.
You can install a specific version of a package, by running
npm install <package-name>@<version>
ShellCopy to clipboard
Running Tasks
The package.json file supports a format for specifying command line tasks that can be run by using
npm run <task-name>
ShellCopy to clipboard
For example:
{
  "scripts": {
    "start-dev": "node lib/server-development",
    "start": "node lib/server-production"
  }
}
JSONCopy to clipboard
It's very common to use this feature to run Webpack:
{
  "scripts": {
    "watch": "webpack --watch --progress --colors --config webpack.conf.js",
    "dev": "webpack --progress --colors --config webpack.conf.js",
    "prod": "NODE_ENV=production webpack -p --config webpack.conf.js"
  }
}
JSONCopy to clipboard
So instead of typing those long commands, which are easy to forget or mistype, you can run
$ npm run watch
$ npm run dev
$ npm run prod
Shell SessionCopy to clipboardPrevThe V8 JavaScript EngineNextECMAScript 2015 (ES6) and beyond\n\n\n\nECMAScript 2015 (ES6) and beyond
Node.js is built against modern versions of V8. By keeping up-to-date with the latest releases of this engine, we ensure new features from the JavaScript ECMA-262 specification are brought to Node.js developers in a timely manner, as well as continued performance and stability improvements.
All ECMAScript 2015 (ES6) features are split into three groups for shipping, staged, and in progress features:

All shipping features, which V8 considers stable, are turned on by default on Node.js and do NOT require any kind of runtime flag.
Staged features, which are almost-completed features that are not considered stable by the V8 team, require a runtime flag: --harmony.
In progress features can be activated individually by their respective harmony flag, although this is highly discouraged unless for testing purposes. Note: these flags are exposed by V8 and will potentially change without any deprecation notice.

Which features ship with which Node.js version by default?
The website node.green provides an excellent overview over supported ECMAScript features in various versions of Node.js, based on kangax's compat-table.
Which features are in progress?
New features are constantly being added to the V8 engine. Generally speaking, expect them to land on a future Node.js release, although timing is unknown.
You may list all the in progress features available on each Node.js release by grepping through the --v8-options argument. Please note that these are incomplete and possibly broken features of V8, so use them at your own risk:
node --v8-options | grep "in progress"
ShellCopy to clipboard
I have my infrastructure set up to leverage the --harmony flag. Should I remove it?
The current behavior of the --harmony flag on Node.js is to enable staged features only. After all, it is now a synonym of --es_staging. As mentioned above, these are completed features that have not been considered stable yet. If you want to play safe, especially on production environments, consider removing this runtime flag until it ships by default on V8 and, consequently, on Node.js. If you keep this enabled, you should be prepared for further Node.js upgrades to break your code if V8 changes their semantics to more closely follow the standard.
How do I find which version of V8 ships with a particular version of Node.js?
Node.js provides a simple way to list all dependencies and respective versions that ship with a specific binary through the process global object. In case of the V8 engine, type the following in your terminal to retrieve its version:
node -p process.versions.v8
ShellCopy to clipboardPrevAn introduction to the npm package managerNextNode.js, the difference between development and production\n\n\n\nNode.js, the difference between development and production
There is no difference between development and production in Node.js, i.e., there are no specific settings you need to apply to make Node.js work in a production configuration.
However, a few libraries in the npm registry recognize using the NODE_ENV variable and default it to a development setting.
Always run your Node.js with the NODE_ENV=production set.
A popular way of configuring your application is by using the twelve factor methodology.
Why is NODE_ENV considered an antipattern?
An environment is a digital platform or a system where engineers can build, test, deploy, and manage software products. Conventionally, there are four stages or types of environments where our application is run:

Development
Testing
Staging
Production

The fundamental problem of NODE_ENV stems from developers combining optimizations and software behavior with the environment their software is running on. The result is code like the following:
if (process.env.NODE_ENV === 'development') {
  // ...
}

if (process.env.NODE_ENV === 'production') {
  // ...
}

if (['production', 'staging'].includes(process.env.NODE_ENV)) {
  // ...
}
JavaScriptCopy to clipboard
While this might look harmless, it makes the production and staging environments different, thus making reliable testing impossible. For example a test and thus a functionality of your product could pass when NODE_ENV is set to development but fail when setting NODE_ENV to production.
Therefore, setting NODE_ENV to anything but production is considered an antipattern.PrevECMAScript 2015 (ES6) and beyondNextNode.js with WebAssembly\n\n\n\nNode.js with WebAssembly
WebAssembly is a high-performance assembly-like language that can be compiled from various languages, including C/C++, Rust, and AssemblyScript. Currently, it is supported by Chrome, Firefox, Safari, Edge, and Node.js!
The WebAssembly specification details two file formats, a binary format called a WebAssembly Module with a .wasm extension and corresponding text representation called WebAssembly Text format with a .wat extension.
Key Concepts

Module - A compiled WebAssembly binary, i.e. a .wasm file.
Memory - A resizable ArrayBuffer.
Table - A resizable typed array of references not stored in Memory.
Instance - An instantiation of a Module with its Memory, Table, and variables.

In order to use WebAssembly, you need a .wasm binary file and a set of APIs to communicate with WebAssembly. Node.js provides the necessary APIs via the global WebAssembly object.
console.log(WebAssembly);
/*
Object [WebAssembly] {
  compile: [Function: compile],
  validate: [Function: validate],
  instantiate: [Function: instantiate]
}
*/
JavaScriptCopy to clipboard
Generating WebAssembly Modules
There are multiple methods available to generate WebAssembly binary files including:

Writing WebAssembly (.wat) by hand and converting to binary format using tools such as wabt
Using emscripten with a C/C++ application
Using wasm-pack with a Rust application
Using AssemblyScript if you prefer a TypeScript-like experience


Some of these tools generate not only the binary file, but the JavaScript "glue" code and corresponding HTML files to run in the browser.

How to use it
Once you have a WebAssembly module, you can use the Node.js WebAssembly object to instantiate it.
JSMJS// Assume add.wasm file exists that contains a single function adding 2 provided arguments
const fs = require('node:fs');

// Use the readFileSync function to read the contents of the "add.wasm" file
const wasmBuffer = fs.readFileSync('/path/to/add.wasm');

// Use the WebAssembly.instantiate method to instantiate the WebAssembly module
WebAssembly.instantiate(wasmBuffer).then(wasmModule => {
  // Exported function lives under instance.exports object
  const { add } = wasmModule.instance.exports;
  const sum = add(5, 6);
  console.log(sum); // Outputs: 11
});
JavaScriptCopy to clipboardInteracting with the OS
WebAssembly modules cannot directly access OS functionality on its own. A third-party tool Wasmtime can be used to access this functionality. Wasmtime utilizes the WASI API to access the OS functionality.
Resources

General WebAssembly Information
MDN Docs
Write WebAssembly by hand
PrevNode.js, the difference between development and productionNextDebugging Node.js\n\n\n\nDebugging Node.js
This guide will help you get started debugging your Node.js apps and scripts.
Enable Inspector
When started with the --inspect switch, a Node.js process listens for a
debugging client. By default, it will listen at host and port 127.0.0.1:9229.
Each process is also assigned a unique UUID.
Inspector clients must know and specify host address, port, and UUID to connect.
A full URL will look something like
ws://127.0.0.1:9229/0f2c936f-b1cd-4ac9-aab3-f63b0f33d55e.
Node.js will also start listening for debugging messages if it receives a
SIGUSR1 signal. (SIGUSR1 is not available on Windows.) In Node.js 7 and
earlier, this activates the legacy Debugger API. In Node.js 8 and later, it will
activate the Inspector API.
Security Implications
Since the debugger has full access to the Node.js execution environment, a
malicious actor able to connect to this port may be able to execute arbitrary
code on behalf of the Node.js process. It is important to understand the security
implications of exposing the debugger port on public and private networks.
Exposing the debug port publicly is unsafe
If the debugger is bound to a public IP address, or to 0.0.0.0, any clients that
can reach your IP address will be able to connect to the debugger without any
restriction and will be able to run arbitrary code.
By default node --inspect binds to 127.0.0.1. You explicitly need to provide a
public IP address or 0.0.0.0, etc., if you intend to allow external connections
to the debugger. Doing so may expose you to a potentially significant security
threat. We suggest you ensure appropriate firewalls and access controls in place
to prevent a security exposure.
See the section on 'Enabling remote debugging scenarios' on some advice on how
to safely allow remote debugger clients to connect.
Local applications have full access to the inspector
Even if you bind the inspector port to 127.0.0.1 (the default), any applications
running locally on your machine will have unrestricted access. This is by design
to allow local debuggers to be able to attach conveniently.
Browsers, WebSockets and same-origin policy
Websites open in a web-browser can make WebSocket and HTTP requests under the
browser security model. An initial HTTP connection is necessary to obtain a
unique debugger session id. The same-origin-policy prevents websites from being
able to make this HTTP connection. For additional security against
DNS rebinding attacks, Node.js
verifies that the 'Host' headers for the connection either
specify an IP address or localhost precisely.
These security policies disallow connecting to a remote debug server by
specifying the hostname. You can work-around this restriction by specifying
either the IP address or by using ssh tunnels as described below.
Inspector Clients
A minimal CLI debugger is available with node inspect myscript.js.
Several commercial and open source tools can also connect to the Node.js Inspector.
Chrome DevTools 55+, Microsoft Edge

Option 1: Open chrome://inspect in a Chromium-based
browser or edge://inspect in Edge. Click the Configure button and ensure your target host and port
are listed.
Option 2: Copy the devtoolsFrontendUrl from the output of /json/list
(see above) or the --inspect hint text and paste into Chrome.

See https://github.com/ChromeDevTools/devtools-frontend, https://www.microsoftedgeinsider.com for more information.
Visual Studio Code 1.10+

In the Debug panel, click the settings icon to open .vscode/launch.json.
Select "Node.js" for initial setup.

See https://github.com/microsoft/vscode for more information.
Visual Studio 2017+

Choose "Debug > Start Debugging" from the menu or hit F5.
Detailed instructions.

JetBrains WebStorm and other JetBrains IDEs

Create a new Node.js debug configuration and hit Debug. --inspect will be used
by default for Node.js 7+. To disable uncheck js.debugger.node.use.inspect in
the IDE Registry. To learn more about running and debugging Node.js in WebStorm and other JetBrains IDEs,
check out WebStorm online help.

chrome-remote-interface

Library to ease connections to Inspector Protocol endpoints.

See https://github.com/cyrus-and/chrome-remote-interface for more information.
Gitpod

Start a Node.js debug configuration from the Debug view or hit F5. Detailed instructions

See https://www.gitpod.io for more information.
Eclipse IDE with Eclipse Wild Web Developer extension

From a .js file, choose "Debug As... > Node program", or
Create a Debug Configuration to attach debugger to running Node.js application (already started with --inspect).

See https://eclipse.org/eclipseide for more information.
Command-line options
The following table lists the impact of various runtime flags on debugging:
FlagMeaning--inspectEnable inspector agent; Listen on default address and port (127.0.0.1:9229)--inspect=[host:port]Enable inspector agent; Bind to address or hostname host (default: 127.0.0.1); Listen on port port (default: 9229)--inspect-brkEnable inspector agent; Listen on default address and port (127.0.0.1:9229); Break before user code starts--inspect-brk=[host:port]Enable inspector agent; Bind to address or hostname host (default: 127.0.0.1); Listen on port port (default: 9229); Break before user code starts--inspect-waitEnable inspector agent; Listen on default address and port (127.0.0.1:9229); Wait for debugger to be attached.--inspect-wait=[host:port]Enable inspector agent; Bind to address or hostname host (default: 127.0.0.1); Listen on port port (default: 9229); Wait for debugger to be attached.node inspect script.jsSpawn child process to run user's script under --inspect flag; and use main process to run CLI debugger.node inspect --port=xxxx script.jsSpawn child process to run user's script under --inspect flag; and use main process to run CLI debugger. Listen on port port (default: 9229)
Enabling remote debugging scenarios
We recommend that you never have the debugger listen on a public IP address. If
you need to allow remote debugging connections we recommend the use of ssh
tunnels instead. We provide the following example for illustrative purposes only.
Please understand the security risk of allowing remote access to a privileged
service before proceeding.
Let's say you are running Node.js on a remote machine, remote.example.com, that
you want to be able to debug. On that machine, you should start the node process
with the inspector listening only to localhost (the default).
node --inspect server.js
ShellCopy to clipboard
Now, on your local machine from where you want to initiate a debug client
connection, you can setup an ssh tunnel:
ssh -L 9221:localhost:9229 [email protected]
ShellCopy to clipboard
This starts a ssh tunnel session where a connection to port 9221 on your local
machine will be forwarded to port 9229 on remote.example.com. You can now attach
a debugger such as Chrome DevTools or Visual Studio Code to localhost:9221,
which should be able to debug as if the Node.js application was running locally.
Legacy Debugger
The legacy debugger has been deprecated as of Node.js 7.7.0. Please use
--inspect and Inspector instead.
When started with the --debug or --debug-brk switches in version 7 and
earlier, Node.js listens for debugging commands defined by the discontinued
V8 Debugging Protocol on a TCP port, by default 5858. Any debugger client
which speaks this protocol can connect to and debug the running process; a
couple popular ones are listed below.
The V8 Debugging Protocol is no longer maintained or documented.
Built-in Debugger
Start node debug script_name.js to start your script under the builtin
command-line debugger. Your script starts in another Node.js process started with
the --debug-brk option, and the initial Node.js process runs the _debugger.js
script and connects to your target. See docs for more information.
node-inspector
Debug your Node.js app with Chrome DevTools by using an intermediary process
which translates the Inspector Protocol used in Chromium to the V8 Debugger
protocol used in Node.js. See https://github.com/node-inspector/node-inspector for more information.PrevNode.js with WebAssemblyNextProfiling Node.js Applications\n\n\n\nProfiling Node.js Applications
Profiling a Node.js application involves measuring its performance by analyzing
the CPU, memory, and other runtime metrics while the application is running.
This helps in identifying bottlenecks, high CPU usage, memory leaks, or slow
function calls that may impact the application's efficiency, responsiveness
and scalability.
There are many third party tools available for profiling Node.js applications
but, in many cases, the easiest option is to use the Node.js built-in profiler.
The built-in profiler uses the profiler inside V8 which samples the stack at
regular intervals during program execution. It records the results of these
samples, along with important optimization events such as jit compiles, as a
series of ticks:
code-creation,LazyCompile,0,0x2d5000a337a0,396,"bp native array.js:1153:16",0x289f644df68,~
code-creation,LazyCompile,0,0x2d5000a33940,716,"hasOwnProperty native v8natives.js:198:30",0x289f64438d0,~
code-creation,LazyCompile,0,0x2d5000a33c20,284,"ToName native runtime.js:549:16",0x289f643bb28,~
code-creation,Stub,2,0x2d5000a33d40,182,"DoubleToIStub"
code-creation,Stub,2,0x2d5000a33e00,507,"NumberToStringStub"

In the past, you needed the V8 source code to be able to interpret the ticks.
Luckily, tools have been introduced since Node.js 4.4.0 that facilitate the
consumption of this information without separately building V8 from source.
Let's see how the built-in profiler can help provide insight into application
performance.
To illustrate the use of the tick profiler, we will work with a simple Express
application. Our application will have two handlers, one for adding new users to
our system:
app.get('/newUser', (req, res) => {
  let username = req.query.username || '';
  const password = req.query.password || '';

  username = username.replace(/[!@#$%^&*]/g, '');

  if (!username || !password || users[username]) {
    return res.sendStatus(400);
  }

  const salt = crypto.randomBytes(128).toString('base64');
  const hash = crypto.pbkdf2Sync(password, salt, 10000, 512, 'sha512');

  users[username] = { salt, hash };

  res.sendStatus(200);
});
JavaScriptCopy to clipboard
and another for validating user authentication attempts:
app.get('/auth', (req, res) => {
  let username = req.query.username || '';
  const password = req.query.password || '';

  username = username.replace(/[!@#$%^&*]/g, '');

  if (!username || !password || !users[username]) {
    return res.sendStatus(400);
  }

  const { salt, hash } = users[username];
  const encryptHash = crypto.pbkdf2Sync(password, salt, 10000, 512, 'sha512');

  if (crypto.timingSafeEqual(hash, encryptHash)) {
    res.sendStatus(200);
  } else {
    res.sendStatus(401);
  }
});
JavaScriptCopy to clipboard
Please note that these are NOT recommended handlers for authenticating users in
your Node.js applications and are used purely for illustration purposes. You
should not be trying to design your own cryptographic authentication mechanisms
in general. It is much better to use existing, proven authentication solutions.
Now assume that we've deployed our application and users are complaining about
high latency on requests. We can easily run the app with the built-in profiler:
NODE_ENV=production node --prof app.js

and put some load on the server using ab (ApacheBench):
curl -X GET "http://localhost:8080/newUser?username=matt&password=password"
ab -k -c 20 -n 250 "http://localhost:8080/auth?username=matt&password=password"

and get an ab output of:
Concurrency Level:      20
Time taken for tests:   46.932 seconds
Complete requests:      250
Failed requests:        0
Keep-Alive requests:    250
Total transferred:      50250 bytes
HTML transferred:       500 bytes
Requests per second:    5.33 [#/sec] (mean)
Time per request:       3754.556 [ms] (mean)
Time per request:       187.728 [ms] (mean, across all concurrent requests)
Transfer rate:          1.05 [Kbytes/sec] received

...

Percentage of the requests served within a certain time (ms)
  50%   3755
  66%   3804
  75%   3818
  80%   3825
  90%   3845
  95%   3858
  98%   3874
  99%   3875
 100%   4225 (longest request)

From this output, we see that we're only managing to serve about 5 requests per
second and that the average request takes just under 4 seconds round trip. In a
real-world example, we could be doing lots of work in many functions on behalf
of a user request but even in our simple example, time could be lost compiling
regular expressions, generating random salts, generating unique hashes from user
passwords, or inside the Express framework itself.
Since we ran our application using the --prof option, a tick file was generated
in the same directory as your local run of the application. It should have the
form isolate-0xnnnnnnnnnnnn-v8.log (where n is a digit).
In order to make sense of this file, we need to use the tick processor bundled
with the Node.js binary. To run the processor, use the --prof-process flag:
node --prof-process isolate-0xnnnnnnnnnnnn-v8.log > processed.txt

Opening processed.txt in your favorite text editor will give you a few different
types of information. The file is broken up into sections which are again broken
up by language. First, we look at the summary section and see:
 [Summary]:
   ticks  total  nonlib   name
     79    0.2%    0.2%  JavaScript
  36703   97.2%   99.2%  C++
      7    0.0%    0.0%  GC
    767    2.0%          Shared libraries
    215    0.6%          Unaccounted

This tells us that 97% of all samples gathered occurred in C++ code and that
when viewing other sections of the processed output we should pay most attention
to work being done in C++ (as opposed to JavaScript). With this in mind, we next
find the [C++] section which contains information about which C++ functions are
taking the most CPU time and see:
 [C++]:
   ticks  total  nonlib   name
  19557   51.8%   52.9%  node::crypto::PBKDF2(v8::FunctionCallbackInfo<v8::Value> const&)
   4510   11.9%   12.2%  _sha1_block_data_order
   3165    8.4%    8.6%  _malloc_zone_malloc

We see that the top 3 entries account for 72.1% of CPU time taken by the
program. From this output, we immediately see that at least 51.8% of CPU time is
taken up by a function called PBKDF2 which corresponds to our hash generation
from a user's password. However, it may not be immediately obvious how the lower
two entries factor into our application (or if it is we will pretend otherwise
for the sake of example). To better understand the relationship between these
functions, we will next look at the [Bottom up (heavy) profile] section which
provides information about the primary callers of each function. Examining this
section, we find:
   ticks parent  name
  19557   51.8%  node::crypto::PBKDF2(v8::FunctionCallbackInfo<v8::Value> const&)
  19557  100.0%    v8::internal::Builtins::~Builtins()
  19557  100.0%      LazyCompile: ~pbkdf2 crypto.js:557:16

   4510   11.9%  _sha1_block_data_order
   4510  100.0%    LazyCompile: *pbkdf2 crypto.js:557:16
   4510  100.0%      LazyCompile: *exports.pbkdf2Sync crypto.js:552:30

   3165    8.4%  _malloc_zone_malloc
   3161   99.9%    LazyCompile: *pbkdf2 crypto.js:557:16
   3161  100.0%      LazyCompile: *exports.pbkdf2Sync crypto.js:552:30

Parsing this section takes a little more work than the raw tick counts above.
Within each of the "call stacks" above, the percentage in the parent column
tells you the percentage of samples for which the function in the row above was
called by the function in the current row. For example, in the middle "call
stack" above for _sha1_block_data_order, we see that _sha1_block_data_order occurred
in 11.9% of samples, which we knew from the raw counts above. However, here, we
can also tell that it was always called by the pbkdf2 function inside the
Node.js crypto module. We see that similarly, _malloc_zone_malloc was called
almost exclusively by the same pbkdf2 function. Thus, using the information in
this view, we can tell that our hash computation from the user's password
accounts not only for the 51.8% from above but also for all CPU time in the top
3 most sampled functions since the calls to _sha1_block_data_order and
_malloc_zone_malloc were made on behalf of the pbkdf2 function.
At this point, it is very clear that the password-based hash generation should
be the target of our optimization. Thankfully, you've fully internalized the
benefits of asynchronous programming and you realize that the work to
generate a hash from the user's password is being done in a synchronous way and
thus tying down the event loop. This prevents us from working on other incoming
requests while computing a hash.
To remedy this issue, you make a small modification to the above handlers to use
the asynchronous version of the pbkdf2 function:
app.get('/auth', (req, res) => {
  let username = req.query.username || '';
  const password = req.query.password || '';

  username = username.replace(/[!@#$%^&*]/g, '');

  if (!username || !password || !users[username]) {
    return res.sendStatus(400);
  }

  crypto.pbkdf2(
    password,
    users[username].salt,
    10000,
    512,
    'sha512',
    (err, hash) => {
      if (users[username].hash.toString() === hash.toString()) {
        res.sendStatus(200);
      } else {
        res.sendStatus(401);
      }
    }
  );
});
JavaScriptCopy to clipboard
A new run of the ab benchmark above with the asynchronous version of your app
yields:
Concurrency Level:      20
Time taken for tests:   12.846 seconds
Complete requests:      250
Failed requests:        0
Keep-Alive requests:    250
Total transferred:      50250 bytes
HTML transferred:       500 bytes
Requests per second:    19.46 [#/sec] (mean)
Time per request:       1027.689 [ms] (mean)
Time per request:       51.384 [ms] (mean, across all concurrent requests)
Transfer rate:          3.82 [Kbytes/sec] received

...

Percentage of the requests served within a certain time (ms)
  50%   1018
  66%   1035
  75%   1041
  80%   1043
  90%   1049
  95%   1063
  98%   1070
  99%   1071
 100%   1079 (longest request)

Yay! Your app is now serving about 20 requests per second, roughly 4 times more
than it was with the synchronous hash generation. Additionally, the average
latency is down from the 4 seconds before to just over 1 second.
Hopefully, through the performance investigation of this (admittedly contrived)
example, you've seen how the V8 tick processor can help you gain a better
understanding of the performance of your Node.js applications.
You may also find how to create a flame graph helpful.PrevDebugging Node.jsNextFetching data with Node.js\n\n\n\nUsing the Fetch API with Undici in Node.js
Introduction
Undici is an HTTP client library that powers the fetch API in Node.js. It was written from scratch and does not rely on the built-in HTTP client in Node.js. It includes a number of features that make it a good choice for high-performance applications.
For information on Undici's specification compliance, see the Undici documentation.
Basic GET Usage
async function main() {
  // Like the browser fetch API, the default method is GET
  const response = await fetch('https://jsonplaceholder.typicode.com/posts');
  const data = await response.json();
  console.log(data);
  // returns something like:
  //   {
  //   userId: 1,
  //   id: 1,
  //   title: 'sunt aut facere repellat provident occaecati excepturi optio reprehenderit',
  //   body: 'quia et suscipit\n' +
  //     'suscipit recusandae consequuntur expedita et cum\n' +
  //     'reprehenderit molestiae ut ut quas totam\n' +
  //     'nostrum rerum est autem sunt rem eveniet architecto'
  // }
}

main().catch(console.error);
JavaScriptCopy to clipboard
Basic POST Usage
// Data sent from the client to the server
const body = {
  title: 'foo',
  body: 'bar',
  userId: 1,
};

async function main() {
  const response = await fetch('https://jsonplaceholder.typicode.com/posts', {
    method: 'POST',
    headers: {
      'User-Agent': 'undici-stream-example',
      'Content-Type': 'application/json',
    },
    body: JSON.stringify(body),
  });
  const data = await response.json();
  console.log(data);
  // returns something like:
  // { title: 'foo', body: 'bar', userId: 1, id: 101 }
}

main().catch(console.error);
JavaScriptCopy to clipboard
Customizing the Fetch API with Undici
Undici allows you to customize the Fetch API by providing options to the fetch function. For example, you can set custom headers, set the request method, and set the request body. Here is an example of how you can customize the Fetch API with Undici:
The fetch function takes two arguments: the URL to fetch and an options object. The options object is the Request object that you can use to customize the request. The function returns a Promises that resolves to a Response object.
In the following example, we are sending a POST request to the Ollama API with a JSON payload. Ollama is a cli tool that allows you to run LLM's (Large Language Models) on your local machine. You can download it here
ollama run mistral
ShellCopy to clipboard
This will download the mistral model and run it on your local machine.
With a pool, you can reuse connections to the same server, which can improve performance. Here is an example of how you can use a pool with Undici:
import { Pool } from 'undici';

const ollamaPool = new Pool('http://localhost:11434', {
  connections: 10,
});

/**
 * Stream the completion of a prompt using the Ollama API.
 * @param {string} prompt - The prompt to complete.
 * @link https://github.com/ollama/ollama/blob/main/docs/api.md
 **/
async function streamOllamaCompletion(prompt) {
  const { statusCode, body } = await ollamaPool.request({
    path: '/api/generate',
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
    },
    body: JSON.stringify({ prompt, model: 'mistral' }),
  });

  // You can read about HTTP status codes here: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status
  // 200 means the request was successful.
  if (statusCode !== 200) {
    throw new Error(`Ollama request failed with status ${statusCode}`);
  }

  let partial = '';

  const decoder = new TextDecoder();
  for await (const chunk of body) {
    partial += decoder.decode(chunk, { stream: true });
    console.log(partial);
  }

  console.log('Streaming complete.');
}

try {
  await streamOllamaCompletion('What is recursion?');
} catch (error) {
  console.error('Error calling Ollama:', error);
} finally {
  console.log('Closing Ollama pool.');
  ollamaPool.close();
}
JavaScriptCopy to clipboard
Streaming Responses with Undici
Streams is a feature in Node.js that allows you to read and write chunks of data.
import { stream } from 'undici';
import { Writable } from 'stream';

async function fetchGitHubRepos() {
  const url = 'https://api.github.com/users/nodejs/repos';

  const { statusCode } = await stream(
    url,
    {
      method: 'GET',
      headers: {
        'User-Agent': 'undici-stream-example',
        Accept: 'application/json',
      },
    },
    () => {
      let buffer = '';

      return new Writable({
        write(chunk, encoding, callback) {
          buffer += chunk.toString();

          try {
            const json = JSON.parse(buffer);
            console.log(
              'Repository Names:',
              json.map(repo => repo.name)
            );
            buffer = '';
          } catch (error) {
            console.error('Error parsing JSON:', error);
          }

          callback();
        },
        final(callback) {
          console.log('Stream processing completed.');
          callback();
        },
      });
    }
  );

  console.log(`Response status: ${statusCode}`);
}

fetchGitHubRepos().catch(console.error);
JavaScriptCopy to clipboardPrevProfiling Node.js ApplicationsNextWebSocket client with Node.js\n\n\n\nNative WebSocket Client in Node.js
Introduction
Since Node.js v21, the WebSocket API has been enhanced using the Undici library, introducing a built-in WebSocket client. This simplifies real-time communication for Node.js applications. In Node.js v22.4.0 release, the WebSocket API was marked as stable, indicating it's ready for production use.
What is a WebSocket
WebSocket is a standardized communication protocol that enables simultaneous two-way communication over a single TCP connection. It has full-duplex or bi-directional capabilities that distinguishes it from HTTP. WebSocket achieves HTTP compatibility by using the HTTP Upgrade header to transition protocols. It allows servers to push content to clients without initial requests and maintains open connections for continuous message exchange, making it ideal for real-time data transfer with lower overhead than alternatives like HTTP polling. WebSocket communications typically occur over TCP ports 443 (secured) or 80 (unsecured), helping bypass firewall restrictions on non-web connections. The protocol defines its own URI schemes (ws:// and wss://) for unencrypted and encrypted connections respectively and supported by all major browsers.
Native WebSocket Client
Node.js can now act as a WebSocket client without relying on external libraries like ws or socket.io for client connections. This allows Node.js applications to initiate and manage outgoing WebSocket connections directly, streamlining tasks such as connecting to real-time data feeds or interacting with other WebSocket servers. Users can now create a websocket client connection with the standard new WebSocket() constructor.
Building on the above, let's add more practical examples to demonstrate the new WebSocket client functionality that demonstrates basic use-cases.
Basic Connection and Message Handling
// Creates a new WebSocket connection to the specified URL.
const socket = new WebSocket('ws://localhost:8080');

// Executes when the connection is successfully established.
socket.addEventListener('open', event => {
  console.log('WebSocket connection established!');
  // Sends a message to the WebSocket server.
  socket.send('Hello Server!');
});

// Listen for messages and executes when a message is received from the server.
socket.addEventListener('message', event => {
  console.log('Message from server: ', event.data);
});

// Executes when the connection is closed, providing the close code and reason.
socket.addEventListener('close', event => {
  console.log('WebSocket connection closed:', event.code, event.reason);
});

// Executes if an error occurs during the WebSocket communication.
socket.addEventListener('error', error => {
  console.error('WebSocket error:', error);
});
JavaScriptCopy to clipboard
Sending and Receiving JSON Data
const socket = new WebSocket('ws://localhost:8080');

socket.addEventListener('open', () => {
  const data = { type: 'message', content: 'Hello from Node.js!' };
  socket.send(JSON.stringify(data));
});

socket.addEventListener('message', event => {
  try {
    const receivedData = JSON.parse(event.data);
    console.log('Received JSON:', receivedData);
  } catch (error) {
    console.error('Error parsing JSON:', error);
    console.log('Received data was:', event.data);
  }
});
JavaScriptCopy to clipboard
The json code above demonstrates sending and receiving JSON data, which is common in WebSocket applications. It uses JSON.stringify() to convert JavaScript objects to JSON strings before sending. And converts the received string back to a JavaScript object with JSON.parse(). Finally, it includes error handling for JSON parsing.
This offers reduced dependency management and improved compatibility. Developers can avoid installing and maintaining additional WebSocket client libraries. The built-in implementation aligns with modern web standards, ensuring better interoperability. The enhancement focuses on the client-side of WebSocket communication, enabling Node.js to act as a WebSocket client.
Important to Understand
Node.js v22 does not provide a built-in native WebSocket server implementation. To create a WebSocket server that accepts incoming connections from web browsers or other clients, one still need to use libraries like ws or socket.io. This means that while Node.js can now easily connect to WebSocket servers, it still requires external tools to become a WebSocket server.
In Summary
Node.js v22 empowers applications to seamlessly interact with WebSocket servers as clients, but the creation of WebSocket servers within Node.js remains dependent on established libraries. This distinction is crucial for developers to understand when implementing real-time communication in their Node.js projects.PrevFetching data with Node.jsNextSecurity Best Practices\n\n\n\n