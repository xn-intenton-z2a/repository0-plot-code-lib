Content negotiationIn HTTP, content negotiation is the mechanism that is used for serving different representations of a resource to the same URI to help the user agent specify which representation is best suited for the user (for example, which document language, which image format, or which content encoding).

Note:
You'll find some disadvantages of HTTP content negotiation in a wiki page from WHATWG. HTML provides alternatives to content negotiation via, for example, the <source> element.
Principles of content negotiationA specific document is called a resource. When a client wants to obtain a resource, the client requests it via a URL. The server uses this URL to choose one of the variants available–each variant is called a representation–and returns a specific representation to the client. The overall resource, as well as each of the representations, has a specific URL. Content negotiation determines how a specific representation is chosen when the resource is called. There are several ways of negotiating between the client and the server.

The best-suited representation is identified through one of two mechanisms:

Specific HTTP headers by the client (server-driven negotiation or proactive negotiation), which is the standard way of negotiating a specific kind of resource.
The 300 (Multiple Choices) or 406 (Not Acceptable), 415 (Unsupported Media Type) HTTP response codes by the server (agent-driven negotiation or reactive negotiation), that are used as fallback mechanisms.

Over the years, other content negotiation proposals, like transparent content negotiation and the Alternates header, have been proposed. They failed to get traction and were abandoned.Server-driven content negotiationIn server-driven content negotiation, or proactive content negotiation, the browser (or any other kind of user agent) sends several HTTP headers along with the URL. These headers describe the user's preferred choice. The server uses them as hints and an internal algorithm chooses the best content to serve to the client. If it can't provide a suitable resource, it might respond with 406 (Not Acceptable) or 415 (Unsupported Media Type) and set headers for the types of media that it does support (e.g., using the Accept-Post or Accept-Patch for POST and PATCH requests, respectively). The algorithm is server-specific and not defined in the standard. See the Apache negotiation algorithm.

The HTTP/1.1 standard defines list of the standard headers that start server-driven negotiation (such as Accept, Accept-Encoding, and Accept-Language). Though User-Agent isn't in this list, it's sometimes also used to send a specific representation of the requested resource. However, this isn't always considered a good practice. The server uses the Vary header to indicate which headers it actually used for content negotiation (or more precisely, the associated request headers), so that caches can work optimally.
In addition to these, there's an experimental proposal to add more headers to the list of available headers, called client hints. Client hints advertise what kind of device the user agent runs on (for example, a desktop computer or a mobile device).
Even if server-driven content negotiation is the most common way to agree on a specific representation of a resource, it has several drawbacks:

The server doesn't have total knowledge of the browser. Even with the Client Hints extension, it doesn't have a complete knowledge of the capabilities of the browser. Unlike reactive content negotiation where the client makes the choice, the server choice is always somewhat arbitrary.
The information from the client is quite verbose (HTTP/2 header compression mitigates this problem) and a privacy risk (HTTP fingerprinting).
As several representations of a given resource are sent, shared caches are less efficient and server implementations are more complex.
The Accept headerThe Accept header lists the MIME types of media resources that the agent is willing to process. This is a comma-separated list of MIME types, each combined with a quality factor, a parameter that indicates the relative degree of preference between the different MIME types.
The Accept header is defined by the browser, or any other user agent, and can vary according to the context. For example, fetching an HTML page or an image, a video, or a script. It's different when fetching a document entered in the address bar or an element linked via an <img>, <video>, or <audio> element. Browsers are free to use the value of the header that they think is the most adequate; an exhaustive list of default values for common browsers is available.The Accept-CH header
Note:
This is part of an experimental technology called Client Hints. Initial support comes in Chrome 46 or later. The Device-Memory value is in Chrome 61 or later.

The experimental Accept-CH lists configuration data that the server can use to select an appropriate response. Valid values are:



Value
Meaning




Device-Memory
Indicates the approximate amount of device RAM. This value is an approximation given by rounding to the nearest power of 2 and dividing that number by 1024. For example, 512 megabytes will be reported as 0.5.


Viewport-Width
Indicates the layout viewport width in CSS pixels.


Width
Indicates the resource width in physical pixels (in other words the intrinsic size of an image).


The Accept-Encoding headerThe Accept-Encoding header defines the acceptable content encoding (supported compressions). The value is a q-factor list (e.g., br, gzip;q=0.8) that indicates the priority of the encoding values. The default value identity is at the lowest priority (unless otherwise noted).
Compressing HTTP messages is one of the most important ways to improve the performance of a website. It shrinks the size of the data transmitted and makes better use of the available bandwidth. Browsers always send this header and the server should be configured to use compression.The Accept-Language headerThe Accept-Language header is used to indicate the language preference of the user. It's a list of values with quality factors (e.g., de, en;q=0.7). A default value is often set according to the language of the graphical interface of the user agent, but most browsers allow different language preferences to be set.
Due to the configuration-based entropy increase, a modified value can be used to fingerprint the user. It's not recommended to change it and a website can't trust this value to reflect the actual intention of the user. It's best for site designers to avoid using language detection via this header as it can lead to a poor user experience.

They should always provide a way to override the server-chosen language, e.g., by providing a language menu on the site. Most user agents provide a default value for the Accept-Language header that's adapted to the user interface language. End users often don't modify it because they either don't know how or aren't able to do so based on their computing environment.
Once a user has overridden the server-chosen language, a site should no longer use language detection and should stick with the explicitly chosen language. In other words, only entry pages for a site should use this header to select the proper language.
The User-Agent header
Note:
Though there are legitimate uses of this header for selecting content, it's considered bad practice to rely on it to define what features are supported by the user agent.

The User-Agent header identifies the browser sending the request. This string may contain a space-separated list of product tokens and comments.
A product token is a name followed by a / and a version number, like Firefox/4.0.1. The user agent can include as many of these as it wants. A comment is an optional string delimited by parentheses. The information provided in a comment isn't standardized, though several browsers add several tokens to it separated by ;.The Vary response headerIn contrast to the previous Accept-* headers, which are sent by the client, the Vary HTTP header is sent by the web server in its response. It indicates the list of headers the server uses during the server-driven content negotiation phase. The Vary header is needed to inform the cache of the decision criteria so that it can reproduce it. This allows the cache to be functional while ensuring that the right content is served to the user.
The special value * means that the server-driven content negotiation also uses information not conveyed in a header to choose the appropriate content.
The Vary header was added in version 1.1 of HTTP and allows caches to work appropriately. To work with server-driven content negotiation, a cache needs to know which criteria the server used to select the transmitted content. That way, the cache can replay the algorithm and will be able to serve acceptable content directly, without more requests to the server. Obviously, the wildcard * prevents caching from occurring, as the cache can't know what element is behind it. For more information, see HTTP caching > Varying responses.Agent-driven negotiationServer-driven negotiation has a few drawbacks: it doesn't scale well. One header per feature is used in the negotiation. If you want to use screen size, resolution, or other dimensions, you need to create a new HTTP header. The headers must then be sent with every request. This isn't an issue if there are only a few headers, but as the number of headers increases, the message size could eventually affect performance. The more precisely headers are sent, the more entropy is sent, allowing for more HTTP fingerprinting and corresponding privacy concerns.
HTTP allows another negotiation type: agent-driven negotiation or reactive negotiation. In this case, the server sends back a page that contains links to the available alternative resources when faced with an ambiguous request. The user is presented the resources and chooses the one to use.

Unfortunately, the HTTP standard doesn't specify the format of the page for choosing between the available resources, which prevents the process from being automated. Besides falling back to the server-driven negotiation, this method is almost always used with scripting, especially with JavaScript redirection: after having checked for the negotiation criteria, the script performs the redirection. A second problem is that one more request is needed to fetch the real resource, slowing the availability of the resource to the user.See also
Caching\n\nContent negotiationIn HTTP, content negotiation is the mechanism that is used for serving different representations of a resource to the same URI to help the user agent specify which representation is best suited for the user (for example, which document language, which image format, or which content encoding).

Note:
You'll find some disadvantages of HTTP content negotiation in a wiki page from WHATWG. HTML provides alternatives to content negotiation via, for example, the <source> element.
Principles of content negotiationA specific document is called a resource. When a client wants to obtain a resource, the client requests it via a URL. The server uses this URL to choose one of the variants available–each variant is called a representation–and returns a specific representation to the client. The overall resource, as well as each of the representations, has a specific URL. Content negotiation determines how a specific representation is chosen when the resource is called. There are several ways of negotiating between the client and the server.

The best-suited representation is identified through one of two mechanisms:

Specific HTTP headers by the client (server-driven negotiation or proactive negotiation), which is the standard way of negotiating a specific kind of resource.
The 300 (Multiple Choices) or 406 (Not Acceptable), 415 (Unsupported Media Type) HTTP response codes by the server (agent-driven negotiation or reactive negotiation), that are used as fallback mechanisms.

Over the years, other content negotiation proposals, like transparent content negotiation and the Alternates header, have been proposed. They failed to get traction and were abandoned.Server-driven content negotiationIn server-driven content negotiation, or proactive content negotiation, the browser (or any other kind of user agent) sends several HTTP headers along with the URL. These headers describe the user's preferred choice. The server uses them as hints and an internal algorithm chooses the best content to serve to the client. If it can't provide a suitable resource, it might respond with 406 (Not Acceptable) or 415 (Unsupported Media Type) and set headers for the types of media that it does support (e.g., using the Accept-Post or Accept-Patch for POST and PATCH requests, respectively). The algorithm is server-specific and not defined in the standard. See the Apache negotiation algorithm.

The HTTP/1.1 standard defines list of the standard headers that start server-driven negotiation (such as Accept, Accept-Encoding, and Accept-Language). Though User-Agent isn't in this list, it's sometimes also used to send a specific representation of the requested resource. However, this isn't always considered a good practice. The server uses the Vary header to indicate which headers it actually used for content negotiation (or more precisely, the associated request headers), so that caches can work optimally.
In addition to these, there's an experimental proposal to add more headers to the list of available headers, called client hints. Client hints advertise what kind of device the user agent runs on (for example, a desktop computer or a mobile device).
Even if server-driven content negotiation is the most common way to agree on a specific representation of a resource, it has several drawbacks:

The server doesn't have total knowledge of the browser. Even with the Client Hints extension, it doesn't have a complete knowledge of the capabilities of the browser. Unlike reactive content negotiation where the client makes the choice, the server choice is always somewhat arbitrary.
The information from the client is quite verbose (HTTP/2 header compression mitigates this problem) and a privacy risk (HTTP fingerprinting).
As several representations of a given resource are sent, shared caches are less efficient and server implementations are more complex.
The Accept headerThe Accept header lists the MIME types of media resources that the agent is willing to process. This is a comma-separated list of MIME types, each combined with a quality factor, a parameter that indicates the relative degree of preference between the different MIME types.
The Accept header is defined by the browser, or any other user agent, and can vary according to the context. For example, fetching an HTML page or an image, a video, or a script. It's different when fetching a document entered in the address bar or an element linked via an <img>, <video>, or <audio> element. Browsers are free to use the value of the header that they think is the most adequate; an exhaustive list of default values for common browsers is available.The Accept-CH header
Note:
This is part of an experimental technology called Client Hints. Initial support comes in Chrome 46 or later. The Device-Memory value is in Chrome 61 or later.

The experimental Accept-CH lists configuration data that the server can use to select an appropriate response. Valid values are:



Value
Meaning




Device-Memory
Indicates the approximate amount of device RAM. This value is an approximation given by rounding to the nearest power of 2 and dividing that number by 1024. For example, 512 megabytes will be reported as 0.5.


Viewport-Width
Indicates the layout viewport width in CSS pixels.


Width
Indicates the resource width in physical pixels (in other words the intrinsic size of an image).


The Accept-Encoding headerThe Accept-Encoding header defines the acceptable content encoding (supported compressions). The value is a q-factor list (e.g., br, gzip;q=0.8) that indicates the priority of the encoding values. The default value identity is at the lowest priority (unless otherwise noted).
Compressing HTTP messages is one of the most important ways to improve the performance of a website. It shrinks the size of the data transmitted and makes better use of the available bandwidth. Browsers always send this header and the server should be configured to use compression.The Accept-Language headerThe Accept-Language header is used to indicate the language preference of the user. It's a list of values with quality factors (e.g., de, en;q=0.7). A default value is often set according to the language of the graphical interface of the user agent, but most browsers allow different language preferences to be set.
Due to the configuration-based entropy increase, a modified value can be used to fingerprint the user. It's not recommended to change it and a website can't trust this value to reflect the actual intention of the user. It's best for site designers to avoid using language detection via this header as it can lead to a poor user experience.

They should always provide a way to override the server-chosen language, e.g., by providing a language menu on the site. Most user agents provide a default value for the Accept-Language header that's adapted to the user interface language. End users often don't modify it because they either don't know how or aren't able to do so based on their computing environment.
Once a user has overridden the server-chosen language, a site should no longer use language detection and should stick with the explicitly chosen language. In other words, only entry pages for a site should use this header to select the proper language.
The User-Agent header
Note:
Though there are legitimate uses of this header for selecting content, it's considered bad practice to rely on it to define what features are supported by the user agent.

The User-Agent header identifies the browser sending the request. This string may contain a space-separated list of product tokens and comments.
A product token is a name followed by a / and a version number, like Firefox/4.0.1. The user agent can include as many of these as it wants. A comment is an optional string delimited by parentheses. The information provided in a comment isn't standardized, though several browsers add several tokens to it separated by ;.The Vary response headerIn contrast to the previous Accept-* headers, which are sent by the client, the Vary HTTP header is sent by the web server in its response. It indicates the list of headers the server uses during the server-driven content negotiation phase. The Vary header is needed to inform the cache of the decision criteria so that it can reproduce it. This allows the cache to be functional while ensuring that the right content is served to the user.
The special value * means that the server-driven content negotiation also uses information not conveyed in a header to choose the appropriate content.
The Vary header was added in version 1.1 of HTTP and allows caches to work appropriately. To work with server-driven content negotiation, a cache needs to know which criteria the server used to select the transmitted content. That way, the cache can replay the algorithm and will be able to serve acceptable content directly, without more requests to the server. Obviously, the wildcard * prevents caching from occurring, as the cache can't know what element is behind it. For more information, see HTTP caching > Varying responses.Agent-driven negotiationServer-driven negotiation has a few drawbacks: it doesn't scale well. One header per feature is used in the negotiation. If you want to use screen size, resolution, or other dimensions, you need to create a new HTTP header. The headers must then be sent with every request. This isn't an issue if there are only a few headers, but as the number of headers increases, the message size could eventually affect performance. The more precisely headers are sent, the more entropy is sent, allowing for more HTTP fingerprinting and corresponding privacy concerns.
HTTP allows another negotiation type: agent-driven negotiation or reactive negotiation. In this case, the server sends back a page that contains links to the available alternative resources when faced with an ambiguous request. The user is presented the resources and chooses the one to use.

Unfortunately, the HTTP standard doesn't specify the format of the page for choosing between the available resources, which prevents the process from being automated. Besides falling back to the server-driven negotiation, this method is almost always used with scripting, especially with JavaScript redirection: after having checked for the negotiation criteria, the script performs the redirection. A second problem is that one more request is needed to fetch the real resource, slowing the availability of the resource to the user.See also
Caching
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Apr 10, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nContent negotiationIn HTTP, content negotiation is the mechanism that is used for serving different representations of a resource to the same URI to help the user agent specify which representation is best suited for the user (for example, which document language, which image format, or which content encoding).

Note:
You'll find some disadvantages of HTTP content negotiation in a wiki page from WHATWG. HTML provides alternatives to content negotiation via, for example, the <source> element.
Principles of content negotiationA specific document is called a resource. When a client wants to obtain a resource, the client requests it via a URL. The server uses this URL to choose one of the variants available–each variant is called a representation–and returns a specific representation to the client. The overall resource, as well as each of the representations, has a specific URL. Content negotiation determines how a specific representation is chosen when the resource is called. There are several ways of negotiating between the client and the server.

The best-suited representation is identified through one of two mechanisms:

Specific HTTP headers by the client (server-driven negotiation or proactive negotiation), which is the standard way of negotiating a specific kind of resource.
The 300 (Multiple Choices) or 406 (Not Acceptable), 415 (Unsupported Media Type) HTTP response codes by the server (agent-driven negotiation or reactive negotiation), that are used as fallback mechanisms.

Over the years, other content negotiation proposals, like transparent content negotiation and the Alternates header, have been proposed. They failed to get traction and were abandoned.Server-driven content negotiationIn server-driven content negotiation, or proactive content negotiation, the browser (or any other kind of user agent) sends several HTTP headers along with the URL. These headers describe the user's preferred choice. The server uses them as hints and an internal algorithm chooses the best content to serve to the client. If it can't provide a suitable resource, it might respond with 406 (Not Acceptable) or 415 (Unsupported Media Type) and set headers for the types of media that it does support (e.g., using the Accept-Post or Accept-Patch for POST and PATCH requests, respectively). The algorithm is server-specific and not defined in the standard. See the Apache negotiation algorithm.

The HTTP/1.1 standard defines list of the standard headers that start server-driven negotiation (such as Accept, Accept-Encoding, and Accept-Language). Though User-Agent isn't in this list, it's sometimes also used to send a specific representation of the requested resource. However, this isn't always considered a good practice. The server uses the Vary header to indicate which headers it actually used for content negotiation (or more precisely, the associated request headers), so that caches can work optimally.
In addition to these, there's an experimental proposal to add more headers to the list of available headers, called client hints. Client hints advertise what kind of device the user agent runs on (for example, a desktop computer or a mobile device).
Even if server-driven content negotiation is the most common way to agree on a specific representation of a resource, it has several drawbacks:

The server doesn't have total knowledge of the browser. Even with the Client Hints extension, it doesn't have a complete knowledge of the capabilities of the browser. Unlike reactive content negotiation where the client makes the choice, the server choice is always somewhat arbitrary.
The information from the client is quite verbose (HTTP/2 header compression mitigates this problem) and a privacy risk (HTTP fingerprinting).
As several representations of a given resource are sent, shared caches are less efficient and server implementations are more complex.
The Accept headerThe Accept header lists the MIME types of media resources that the agent is willing to process. This is a comma-separated list of MIME types, each combined with a quality factor, a parameter that indicates the relative degree of preference between the different MIME types.
The Accept header is defined by the browser, or any other user agent, and can vary according to the context. For example, fetching an HTML page or an image, a video, or a script. It's different when fetching a document entered in the address bar or an element linked via an <img>, <video>, or <audio> element. Browsers are free to use the value of the header that they think is the most adequate; an exhaustive list of default values for common browsers is available.The Accept-CH header
Note:
This is part of an experimental technology called Client Hints. Initial support comes in Chrome 46 or later. The Device-Memory value is in Chrome 61 or later.

The experimental Accept-CH lists configuration data that the server can use to select an appropriate response. Valid values are:



Value
Meaning




Device-Memory
Indicates the approximate amount of device RAM. This value is an approximation given by rounding to the nearest power of 2 and dividing that number by 1024. For example, 512 megabytes will be reported as 0.5.


Viewport-Width
Indicates the layout viewport width in CSS pixels.


Width
Indicates the resource width in physical pixels (in other words the intrinsic size of an image).


The Accept-Encoding headerThe Accept-Encoding header defines the acceptable content encoding (supported compressions). The value is a q-factor list (e.g., br, gzip;q=0.8) that indicates the priority of the encoding values. The default value identity is at the lowest priority (unless otherwise noted).
Compressing HTTP messages is one of the most important ways to improve the performance of a website. It shrinks the size of the data transmitted and makes better use of the available bandwidth. Browsers always send this header and the server should be configured to use compression.The Accept-Language headerThe Accept-Language header is used to indicate the language preference of the user. It's a list of values with quality factors (e.g., de, en;q=0.7). A default value is often set according to the language of the graphical interface of the user agent, but most browsers allow different language preferences to be set.
Due to the configuration-based entropy increase, a modified value can be used to fingerprint the user. It's not recommended to change it and a website can't trust this value to reflect the actual intention of the user. It's best for site designers to avoid using language detection via this header as it can lead to a poor user experience.

They should always provide a way to override the server-chosen language, e.g., by providing a language menu on the site. Most user agents provide a default value for the Accept-Language header that's adapted to the user interface language. End users often don't modify it because they either don't know how or aren't able to do so based on their computing environment.
Once a user has overridden the server-chosen language, a site should no longer use language detection and should stick with the explicitly chosen language. In other words, only entry pages for a site should use this header to select the proper language.
The User-Agent header
Note:
Though there are legitimate uses of this header for selecting content, it's considered bad practice to rely on it to define what features are supported by the user agent.

The User-Agent header identifies the browser sending the request. This string may contain a space-separated list of product tokens and comments.
A product token is a name followed by a / and a version number, like Firefox/4.0.1. The user agent can include as many of these as it wants. A comment is an optional string delimited by parentheses. The information provided in a comment isn't standardized, though several browsers add several tokens to it separated by ;.The Vary response headerIn contrast to the previous Accept-* headers, which are sent by the client, the Vary HTTP header is sent by the web server in its response. It indicates the list of headers the server uses during the server-driven content negotiation phase. The Vary header is needed to inform the cache of the decision criteria so that it can reproduce it. This allows the cache to be functional while ensuring that the right content is served to the user.
The special value * means that the server-driven content negotiation also uses information not conveyed in a header to choose the appropriate content.
The Vary header was added in version 1.1 of HTTP and allows caches to work appropriately. To work with server-driven content negotiation, a cache needs to know which criteria the server used to select the transmitted content. That way, the cache can replay the algorithm and will be able to serve acceptable content directly, without more requests to the server. Obviously, the wildcard * prevents caching from occurring, as the cache can't know what element is behind it. For more information, see HTTP caching > Varying responses.Agent-driven negotiationServer-driven negotiation has a few drawbacks: it doesn't scale well. One header per feature is used in the negotiation. If you want to use screen size, resolution, or other dimensions, you need to create a new HTTP header. The headers must then be sent with every request. This isn't an issue if there are only a few headers, but as the number of headers increases, the message size could eventually affect performance. The more precisely headers are sent, the more entropy is sent, allowing for more HTTP fingerprinting and corresponding privacy concerns.
HTTP allows another negotiation type: agent-driven negotiation or reactive negotiation. In this case, the server sends back a page that contains links to the available alternative resources when faced with an ambiguous request. The user is presented the resources and chooses the one to use.

Unfortunately, the HTTP standard doesn't specify the format of the page for choosing between the available resources, which prevents the process from being automated. Besides falling back to the server-driven negotiation, this method is almost always used with scripting, especially with JavaScript redirection: after having checked for the negotiation criteria, the script performs the redirection. A second problem is that one more request is needed to fetch the real resource, slowing the availability of the resource to the user.See also
Caching
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Apr 10, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nContent negotiationIn HTTP, content negotiation is the mechanism that is used for serving different representations of a resource to the same URI to help the user agent specify which representation is best suited for the user (for example, which document language, which image format, or which content encoding).

Note:
You'll find some disadvantages of HTTP content negotiation in a wiki page from WHATWG. HTML provides alternatives to content negotiation via, for example, the <source> element.
Principles of content negotiationA specific document is called a resource. When a client wants to obtain a resource, the client requests it via a URL. The server uses this URL to choose one of the variants available–each variant is called a representation–and returns a specific representation to the client. The overall resource, as well as each of the representations, has a specific URL. Content negotiation determines how a specific representation is chosen when the resource is called. There are several ways of negotiating between the client and the server.

The best-suited representation is identified through one of two mechanisms:

Specific HTTP headers by the client (server-driven negotiation or proactive negotiation), which is the standard way of negotiating a specific kind of resource.
The 300 (Multiple Choices) or 406 (Not Acceptable), 415 (Unsupported Media Type) HTTP response codes by the server (agent-driven negotiation or reactive negotiation), that are used as fallback mechanisms.

Over the years, other content negotiation proposals, like transparent content negotiation and the Alternates header, have been proposed. They failed to get traction and were abandoned.Server-driven content negotiationIn server-driven content negotiation, or proactive content negotiation, the browser (or any other kind of user agent) sends several HTTP headers along with the URL. These headers describe the user's preferred choice. The server uses them as hints and an internal algorithm chooses the best content to serve to the client. If it can't provide a suitable resource, it might respond with 406 (Not Acceptable) or 415 (Unsupported Media Type) and set headers for the types of media that it does support (e.g., using the Accept-Post or Accept-Patch for POST and PATCH requests, respectively). The algorithm is server-specific and not defined in the standard. See the Apache negotiation algorithm.

The HTTP/1.1 standard defines list of the standard headers that start server-driven negotiation (such as Accept, Accept-Encoding, and Accept-Language). Though User-Agent isn't in this list, it's sometimes also used to send a specific representation of the requested resource. However, this isn't always considered a good practice. The server uses the Vary header to indicate which headers it actually used for content negotiation (or more precisely, the associated request headers), so that caches can work optimally.
In addition to these, there's an experimental proposal to add more headers to the list of available headers, called client hints. Client hints advertise what kind of device the user agent runs on (for example, a desktop computer or a mobile device).
Even if server-driven content negotiation is the most common way to agree on a specific representation of a resource, it has several drawbacks:

The server doesn't have total knowledge of the browser. Even with the Client Hints extension, it doesn't have a complete knowledge of the capabilities of the browser. Unlike reactive content negotiation where the client makes the choice, the server choice is always somewhat arbitrary.
The information from the client is quite verbose (HTTP/2 header compression mitigates this problem) and a privacy risk (HTTP fingerprinting).
As several representations of a given resource are sent, shared caches are less efficient and server implementations are more complex.
The Accept headerThe Accept header lists the MIME types of media resources that the agent is willing to process. This is a comma-separated list of MIME types, each combined with a quality factor, a parameter that indicates the relative degree of preference between the different MIME types.
The Accept header is defined by the browser, or any other user agent, and can vary according to the context. For example, fetching an HTML page or an image, a video, or a script. It's different when fetching a document entered in the address bar or an element linked via an <img>, <video>, or <audio> element. Browsers are free to use the value of the header that they think is the most adequate; an exhaustive list of default values for common browsers is available.The Accept-CH header
Note:
This is part of an experimental technology called Client Hints. Initial support comes in Chrome 46 or later. The Device-Memory value is in Chrome 61 or later.

The experimental Accept-CH lists configuration data that the server can use to select an appropriate response. Valid values are:



Value
Meaning




Device-Memory
Indicates the approximate amount of device RAM. This value is an approximation given by rounding to the nearest power of 2 and dividing that number by 1024. For example, 512 megabytes will be reported as 0.5.


Viewport-Width
Indicates the layout viewport width in CSS pixels.


Width
Indicates the resource width in physical pixels (in other words the intrinsic size of an image).


The Accept-Encoding headerThe Accept-Encoding header defines the acceptable content encoding (supported compressions). The value is a q-factor list (e.g., br, gzip;q=0.8) that indicates the priority of the encoding values. The default value identity is at the lowest priority (unless otherwise noted).
Compressing HTTP messages is one of the most important ways to improve the performance of a website. It shrinks the size of the data transmitted and makes better use of the available bandwidth. Browsers always send this header and the server should be configured to use compression.The Accept-Language headerThe Accept-Language header is used to indicate the language preference of the user. It's a list of values with quality factors (e.g., de, en;q=0.7). A default value is often set according to the language of the graphical interface of the user agent, but most browsers allow different language preferences to be set.
Due to the configuration-based entropy increase, a modified value can be used to fingerprint the user. It's not recommended to change it and a website can't trust this value to reflect the actual intention of the user. It's best for site designers to avoid using language detection via this header as it can lead to a poor user experience.

They should always provide a way to override the server-chosen language, e.g., by providing a language menu on the site. Most user agents provide a default value for the Accept-Language header that's adapted to the user interface language. End users often don't modify it because they either don't know how or aren't able to do so based on their computing environment.
Once a user has overridden the server-chosen language, a site should no longer use language detection and should stick with the explicitly chosen language. In other words, only entry pages for a site should use this header to select the proper language.
The User-Agent header
Note:
Though there are legitimate uses of this header for selecting content, it's considered bad practice to rely on it to define what features are supported by the user agent.

The User-Agent header identifies the browser sending the request. This string may contain a space-separated list of product tokens and comments.
A product token is a name followed by a / and a version number, like Firefox/4.0.1. The user agent can include as many of these as it wants. A comment is an optional string delimited by parentheses. The information provided in a comment isn't standardized, though several browsers add several tokens to it separated by ;.The Vary response headerIn contrast to the previous Accept-* headers, which are sent by the client, the Vary HTTP header is sent by the web server in its response. It indicates the list of headers the server uses during the server-driven content negotiation phase. The Vary header is needed to inform the cache of the decision criteria so that it can reproduce it. This allows the cache to be functional while ensuring that the right content is served to the user.
The special value * means that the server-driven content negotiation also uses information not conveyed in a header to choose the appropriate content.
The Vary header was added in version 1.1 of HTTP and allows caches to work appropriately. To work with server-driven content negotiation, a cache needs to know which criteria the server used to select the transmitted content. That way, the cache can replay the algorithm and will be able to serve acceptable content directly, without more requests to the server. Obviously, the wildcard * prevents caching from occurring, as the cache can't know what element is behind it. For more information, see HTTP caching > Varying responses.Agent-driven negotiationServer-driven negotiation has a few drawbacks: it doesn't scale well. One header per feature is used in the negotiation. If you want to use screen size, resolution, or other dimensions, you need to create a new HTTP header. The headers must then be sent with every request. This isn't an issue if there are only a few headers, but as the number of headers increases, the message size could eventually affect performance. The more precisely headers are sent, the more entropy is sent, allowing for more HTTP fingerprinting and corresponding privacy concerns.
HTTP allows another negotiation type: agent-driven negotiation or reactive negotiation. In this case, the server sends back a page that contains links to the available alternative resources when faced with an ambiguous request. The user is presented the resources and chooses the one to use.

Unfortunately, the HTTP standard doesn't specify the format of the page for choosing between the available resources, which prevents the process from being automated. Besides falling back to the server-driven negotiation, this method is almost always used with scripting, especially with JavaScript redirection: after having checked for the negotiation criteria, the script performs the redirection. A second problem is that one more request is needed to fetch the real resource, slowing the availability of the resource to the user.See also
Caching\n\nContent negotiationIn HTTP, content negotiation is the mechanism that is used for serving different representations of a resource to the same URI to help the user agent specify which representation is best suited for the user (for example, which document language, which image format, or which content encoding).

Note:
You'll find some disadvantages of HTTP content negotiation in a wiki page from WHATWG. HTML provides alternatives to content negotiation via, for example, the <source> element.
Principles of content negotiationA specific document is called a resource. When a client wants to obtain a resource, the client requests it via a URL. The server uses this URL to choose one of the variants available–each variant is called a representation–and returns a specific representation to the client. The overall resource, as well as each of the representations, has a specific URL. Content negotiation determines how a specific representation is chosen when the resource is called. There are several ways of negotiating between the client and the server.

The best-suited representation is identified through one of two mechanisms:

Specific HTTP headers by the client (server-driven negotiation or proactive negotiation), which is the standard way of negotiating a specific kind of resource.
The 300 (Multiple Choices) or 406 (Not Acceptable), 415 (Unsupported Media Type) HTTP response codes by the server (agent-driven negotiation or reactive negotiation), that are used as fallback mechanisms.

Over the years, other content negotiation proposals, like transparent content negotiation and the Alternates header, have been proposed. They failed to get traction and were abandoned.Server-driven content negotiationIn server-driven content negotiation, or proactive content negotiation, the browser (or any other kind of user agent) sends several HTTP headers along with the URL. These headers describe the user's preferred choice. The server uses them as hints and an internal algorithm chooses the best content to serve to the client. If it can't provide a suitable resource, it might respond with 406 (Not Acceptable) or 415 (Unsupported Media Type) and set headers for the types of media that it does support (e.g., using the Accept-Post or Accept-Patch for POST and PATCH requests, respectively). The algorithm is server-specific and not defined in the standard. See the Apache negotiation algorithm.

The HTTP/1.1 standard defines list of the standard headers that start server-driven negotiation (such as Accept, Accept-Encoding, and Accept-Language). Though User-Agent isn't in this list, it's sometimes also used to send a specific representation of the requested resource. However, this isn't always considered a good practice. The server uses the Vary header to indicate which headers it actually used for content negotiation (or more precisely, the associated request headers), so that caches can work optimally.
In addition to these, there's an experimental proposal to add more headers to the list of available headers, called client hints. Client hints advertise what kind of device the user agent runs on (for example, a desktop computer or a mobile device).
Even if server-driven content negotiation is the most common way to agree on a specific representation of a resource, it has several drawbacks:

The server doesn't have total knowledge of the browser. Even with the Client Hints extension, it doesn't have a complete knowledge of the capabilities of the browser. Unlike reactive content negotiation where the client makes the choice, the server choice is always somewhat arbitrary.
The information from the client is quite verbose (HTTP/2 header compression mitigates this problem) and a privacy risk (HTTP fingerprinting).
As several representations of a given resource are sent, shared caches are less efficient and server implementations are more complex.
The Accept headerThe Accept header lists the MIME types of media resources that the agent is willing to process. This is a comma-separated list of MIME types, each combined with a quality factor, a parameter that indicates the relative degree of preference between the different MIME types.
The Accept header is defined by the browser, or any other user agent, and can vary according to the context. For example, fetching an HTML page or an image, a video, or a script. It's different when fetching a document entered in the address bar or an element linked via an <img>, <video>, or <audio> element. Browsers are free to use the value of the header that they think is the most adequate; an exhaustive list of default values for common browsers is available.The Accept-CH header
Note:
This is part of an experimental technology called Client Hints. Initial support comes in Chrome 46 or later. The Device-Memory value is in Chrome 61 or later.

The experimental Accept-CH lists configuration data that the server can use to select an appropriate response. Valid values are:



Value
Meaning




Device-Memory
Indicates the approximate amount of device RAM. This value is an approximation given by rounding to the nearest power of 2 and dividing that number by 1024. For example, 512 megabytes will be reported as 0.5.


Viewport-Width
Indicates the layout viewport width in CSS pixels.


Width
Indicates the resource width in physical pixels (in other words the intrinsic size of an image).


The Accept-Encoding headerThe Accept-Encoding header defines the acceptable content encoding (supported compressions). The value is a q-factor list (e.g., br, gzip;q=0.8) that indicates the priority of the encoding values. The default value identity is at the lowest priority (unless otherwise noted).
Compressing HTTP messages is one of the most important ways to improve the performance of a website. It shrinks the size of the data transmitted and makes better use of the available bandwidth. Browsers always send this header and the server should be configured to use compression.The Accept-Language headerThe Accept-Language header is used to indicate the language preference of the user. It's a list of values with quality factors (e.g., de, en;q=0.7). A default value is often set according to the language of the graphical interface of the user agent, but most browsers allow different language preferences to be set.
Due to the configuration-based entropy increase, a modified value can be used to fingerprint the user. It's not recommended to change it and a website can't trust this value to reflect the actual intention of the user. It's best for site designers to avoid using language detection via this header as it can lead to a poor user experience.

They should always provide a way to override the server-chosen language, e.g., by providing a language menu on the site. Most user agents provide a default value for the Accept-Language header that's adapted to the user interface language. End users often don't modify it because they either don't know how or aren't able to do so based on their computing environment.
Once a user has overridden the server-chosen language, a site should no longer use language detection and should stick with the explicitly chosen language. In other words, only entry pages for a site should use this header to select the proper language.
The User-Agent header
Note:
Though there are legitimate uses of this header for selecting content, it's considered bad practice to rely on it to define what features are supported by the user agent.

The User-Agent header identifies the browser sending the request. This string may contain a space-separated list of product tokens and comments.
A product token is a name followed by a / and a version number, like Firefox/4.0.1. The user agent can include as many of these as it wants. A comment is an optional string delimited by parentheses. The information provided in a comment isn't standardized, though several browsers add several tokens to it separated by ;.The Vary response headerIn contrast to the previous Accept-* headers, which are sent by the client, the Vary HTTP header is sent by the web server in its response. It indicates the list of headers the server uses during the server-driven content negotiation phase. The Vary header is needed to inform the cache of the decision criteria so that it can reproduce it. This allows the cache to be functional while ensuring that the right content is served to the user.
The special value * means that the server-driven content negotiation also uses information not conveyed in a header to choose the appropriate content.
The Vary header was added in version 1.1 of HTTP and allows caches to work appropriately. To work with server-driven content negotiation, a cache needs to know which criteria the server used to select the transmitted content. That way, the cache can replay the algorithm and will be able to serve acceptable content directly, without more requests to the server. Obviously, the wildcard * prevents caching from occurring, as the cache can't know what element is behind it. For more information, see HTTP caching > Varying responses.Agent-driven negotiationServer-driven negotiation has a few drawbacks: it doesn't scale well. One header per feature is used in the negotiation. If you want to use screen size, resolution, or other dimensions, you need to create a new HTTP header. The headers must then be sent with every request. This isn't an issue if there are only a few headers, but as the number of headers increases, the message size could eventually affect performance. The more precisely headers are sent, the more entropy is sent, allowing for more HTTP fingerprinting and corresponding privacy concerns.
HTTP allows another negotiation type: agent-driven negotiation or reactive negotiation. In this case, the server sends back a page that contains links to the available alternative resources when faced with an ambiguous request. The user is presented the resources and chooses the one to use.

Unfortunately, the HTTP standard doesn't specify the format of the page for choosing between the available resources, which prevents the process from being automated. Besides falling back to the server-driven negotiation, this method is almost always used with scripting, especially with JavaScript redirection: after having checked for the negotiation criteria, the script performs the redirection. A second problem is that one more request is needed to fetch the real resource, slowing the availability of the resource to the user.See also
Caching
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Apr 10, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nContent negotiationIn HTTP, content negotiation is the mechanism that is used for serving different representations of a resource to the same URI to help the user agent specify which representation is best suited for the user (for example, which document language, which image format, or which content encoding).

Note:
You'll find some disadvantages of HTTP content negotiation in a wiki page from WHATWG. HTML provides alternatives to content negotiation via, for example, the <source> element.
Principles of content negotiationA specific document is called a resource. When a client wants to obtain a resource, the client requests it via a URL. The server uses this URL to choose one of the variants available–each variant is called a representation–and returns a specific representation to the client. The overall resource, as well as each of the representations, has a specific URL. Content negotiation determines how a specific representation is chosen when the resource is called. There are several ways of negotiating between the client and the server.

The best-suited representation is identified through one of two mechanisms:

Specific HTTP headers by the client (server-driven negotiation or proactive negotiation), which is the standard way of negotiating a specific kind of resource.
The 300 (Multiple Choices) or 406 (Not Acceptable), 415 (Unsupported Media Type) HTTP response codes by the server (agent-driven negotiation or reactive negotiation), that are used as fallback mechanisms.

Over the years, other content negotiation proposals, like transparent content negotiation and the Alternates header, have been proposed. They failed to get traction and were abandoned.Server-driven content negotiationIn server-driven content negotiation, or proactive content negotiation, the browser (or any other kind of user agent) sends several HTTP headers along with the URL. These headers describe the user's preferred choice. The server uses them as hints and an internal algorithm chooses the best content to serve to the client. If it can't provide a suitable resource, it might respond with 406 (Not Acceptable) or 415 (Unsupported Media Type) and set headers for the types of media that it does support (e.g., using the Accept-Post or Accept-Patch for POST and PATCH requests, respectively). The algorithm is server-specific and not defined in the standard. See the Apache negotiation algorithm.

The HTTP/1.1 standard defines list of the standard headers that start server-driven negotiation (such as Accept, Accept-Encoding, and Accept-Language). Though User-Agent isn't in this list, it's sometimes also used to send a specific representation of the requested resource. However, this isn't always considered a good practice. The server uses the Vary header to indicate which headers it actually used for content negotiation (or more precisely, the associated request headers), so that caches can work optimally.
In addition to these, there's an experimental proposal to add more headers to the list of available headers, called client hints. Client hints advertise what kind of device the user agent runs on (for example, a desktop computer or a mobile device).
Even if server-driven content negotiation is the most common way to agree on a specific representation of a resource, it has several drawbacks:

The server doesn't have total knowledge of the browser. Even with the Client Hints extension, it doesn't have a complete knowledge of the capabilities of the browser. Unlike reactive content negotiation where the client makes the choice, the server choice is always somewhat arbitrary.
The information from the client is quite verbose (HTTP/2 header compression mitigates this problem) and a privacy risk (HTTP fingerprinting).
As several representations of a given resource are sent, shared caches are less efficient and server implementations are more complex.
The Accept headerThe Accept header lists the MIME types of media resources that the agent is willing to process. This is a comma-separated list of MIME types, each combined with a quality factor, a parameter that indicates the relative degree of preference between the different MIME types.
The Accept header is defined by the browser, or any other user agent, and can vary according to the context. For example, fetching an HTML page or an image, a video, or a script. It's different when fetching a document entered in the address bar or an element linked via an <img>, <video>, or <audio> element. Browsers are free to use the value of the header that they think is the most adequate; an exhaustive list of default values for common browsers is available.The Accept-CH header
Note:
This is part of an experimental technology called Client Hints. Initial support comes in Chrome 46 or later. The Device-Memory value is in Chrome 61 or later.

The experimental Accept-CH lists configuration data that the server can use to select an appropriate response. Valid values are:



Value
Meaning




Device-Memory
Indicates the approximate amount of device RAM. This value is an approximation given by rounding to the nearest power of 2 and dividing that number by 1024. For example, 512 megabytes will be reported as 0.5.


Viewport-Width
Indicates the layout viewport width in CSS pixels.


Width
Indicates the resource width in physical pixels (in other words the intrinsic size of an image).


The Accept-Encoding headerThe Accept-Encoding header defines the acceptable content encoding (supported compressions). The value is a q-factor list (e.g., br, gzip;q=0.8) that indicates the priority of the encoding values. The default value identity is at the lowest priority (unless otherwise noted).
Compressing HTTP messages is one of the most important ways to improve the performance of a website. It shrinks the size of the data transmitted and makes better use of the available bandwidth. Browsers always send this header and the server should be configured to use compression.The Accept-Language headerThe Accept-Language header is used to indicate the language preference of the user. It's a list of values with quality factors (e.g., de, en;q=0.7). A default value is often set according to the language of the graphical interface of the user agent, but most browsers allow different language preferences to be set.
Due to the configuration-based entropy increase, a modified value can be used to fingerprint the user. It's not recommended to change it and a website can't trust this value to reflect the actual intention of the user. It's best for site designers to avoid using language detection via this header as it can lead to a poor user experience.

They should always provide a way to override the server-chosen language, e.g., by providing a language menu on the site. Most user agents provide a default value for the Accept-Language header that's adapted to the user interface language. End users often don't modify it because they either don't know how or aren't able to do so based on their computing environment.
Once a user has overridden the server-chosen language, a site should no longer use language detection and should stick with the explicitly chosen language. In other words, only entry pages for a site should use this header to select the proper language.
The User-Agent header
Note:
Though there are legitimate uses of this header for selecting content, it's considered bad practice to rely on it to define what features are supported by the user agent.

The User-Agent header identifies the browser sending the request. This string may contain a space-separated list of product tokens and comments.
A product token is a name followed by a / and a version number, like Firefox/4.0.1. The user agent can include as many of these as it wants. A comment is an optional string delimited by parentheses. The information provided in a comment isn't standardized, though several browsers add several tokens to it separated by ;.The Vary response headerIn contrast to the previous Accept-* headers, which are sent by the client, the Vary HTTP header is sent by the web server in its response. It indicates the list of headers the server uses during the server-driven content negotiation phase. The Vary header is needed to inform the cache of the decision criteria so that it can reproduce it. This allows the cache to be functional while ensuring that the right content is served to the user.
The special value * means that the server-driven content negotiation also uses information not conveyed in a header to choose the appropriate content.
The Vary header was added in version 1.1 of HTTP and allows caches to work appropriately. To work with server-driven content negotiation, a cache needs to know which criteria the server used to select the transmitted content. That way, the cache can replay the algorithm and will be able to serve acceptable content directly, without more requests to the server. Obviously, the wildcard * prevents caching from occurring, as the cache can't know what element is behind it. For more information, see HTTP caching > Varying responses.Agent-driven negotiationServer-driven negotiation has a few drawbacks: it doesn't scale well. One header per feature is used in the negotiation. If you want to use screen size, resolution, or other dimensions, you need to create a new HTTP header. The headers must then be sent with every request. This isn't an issue if there are only a few headers, but as the number of headers increases, the message size could eventually affect performance. The more precisely headers are sent, the more entropy is sent, allowing for more HTTP fingerprinting and corresponding privacy concerns.
HTTP allows another negotiation type: agent-driven negotiation or reactive negotiation. In this case, the server sends back a page that contains links to the available alternative resources when faced with an ambiguous request. The user is presented the resources and chooses the one to use.

Unfortunately, the HTTP standard doesn't specify the format of the page for choosing between the available resources, which prevents the process from being automated. Besides falling back to the server-driven negotiation, this method is almost always used with scripting, especially with JavaScript redirection: after having checked for the negotiation criteria, the script performs the redirection. A second problem is that one more request is needed to fetch the real resource, slowing the availability of the resource to the user.See also
Caching
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Apr 10, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nContent negotiationIn HTTP, content negotiation is the mechanism that is used for serving different representations of a resource to the same URI to help the user agent specify which representation is best suited for the user (for example, which document language, which image format, or which content encoding).

Note:
You'll find some disadvantages of HTTP content negotiation in a wiki page from WHATWG. HTML provides alternatives to content negotiation via, for example, the <source> element.
Principles of content negotiationA specific document is called a resource. When a client wants to obtain a resource, the client requests it via a URL. The server uses this URL to choose one of the variants available–each variant is called a representation–and returns a specific representation to the client. The overall resource, as well as each of the representations, has a specific URL. Content negotiation determines how a specific representation is chosen when the resource is called. There are several ways of negotiating between the client and the server.

The best-suited representation is identified through one of two mechanisms:

Specific HTTP headers by the client (server-driven negotiation or proactive negotiation), which is the standard way of negotiating a specific kind of resource.
The 300 (Multiple Choices) or 406 (Not Acceptable), 415 (Unsupported Media Type) HTTP response codes by the server (agent-driven negotiation or reactive negotiation), that are used as fallback mechanisms.

Over the years, other content negotiation proposals, like transparent content negotiation and the Alternates header, have been proposed. They failed to get traction and were abandoned.Server-driven content negotiationIn server-driven content negotiation, or proactive content negotiation, the browser (or any other kind of user agent) sends several HTTP headers along with the URL. These headers describe the user's preferred choice. The server uses them as hints and an internal algorithm chooses the best content to serve to the client. If it can't provide a suitable resource, it might respond with 406 (Not Acceptable) or 415 (Unsupported Media Type) and set headers for the types of media that it does support (e.g., using the Accept-Post or Accept-Patch for POST and PATCH requests, respectively). The algorithm is server-specific and not defined in the standard. See the Apache negotiation algorithm.

The HTTP/1.1 standard defines list of the standard headers that start server-driven negotiation (such as Accept, Accept-Encoding, and Accept-Language). Though User-Agent isn't in this list, it's sometimes also used to send a specific representation of the requested resource. However, this isn't always considered a good practice. The server uses the Vary header to indicate which headers it actually used for content negotiation (or more precisely, the associated request headers), so that caches can work optimally.
In addition to these, there's an experimental proposal to add more headers to the list of available headers, called client hints. Client hints advertise what kind of device the user agent runs on (for example, a desktop computer or a mobile device).
Even if server-driven content negotiation is the most common way to agree on a specific representation of a resource, it has several drawbacks:

The server doesn't have total knowledge of the browser. Even with the Client Hints extension, it doesn't have a complete knowledge of the capabilities of the browser. Unlike reactive content negotiation where the client makes the choice, the server choice is always somewhat arbitrary.
The information from the client is quite verbose (HTTP/2 header compression mitigates this problem) and a privacy risk (HTTP fingerprinting).
As several representations of a given resource are sent, shared caches are less efficient and server implementations are more complex.
The Accept headerThe Accept header lists the MIME types of media resources that the agent is willing to process. This is a comma-separated list of MIME types, each combined with a quality factor, a parameter that indicates the relative degree of preference between the different MIME types.
The Accept header is defined by the browser, or any other user agent, and can vary according to the context. For example, fetching an HTML page or an image, a video, or a script. It's different when fetching a document entered in the address bar or an element linked via an <img>, <video>, or <audio> element. Browsers are free to use the value of the header that they think is the most adequate; an exhaustive list of default values for common browsers is available.The Accept-CH header
Note:
This is part of an experimental technology called Client Hints. Initial support comes in Chrome 46 or later. The Device-Memory value is in Chrome 61 or later.

The experimental Accept-CH lists configuration data that the server can use to select an appropriate response. Valid values are:



Value
Meaning




Device-Memory
Indicates the approximate amount of device RAM. This value is an approximation given by rounding to the nearest power of 2 and dividing that number by 1024. For example, 512 megabytes will be reported as 0.5.


Viewport-Width
Indicates the layout viewport width in CSS pixels.


Width
Indicates the resource width in physical pixels (in other words the intrinsic size of an image).


The Accept-Encoding headerThe Accept-Encoding header defines the acceptable content encoding (supported compressions). The value is a q-factor list (e.g., br, gzip;q=0.8) that indicates the priority of the encoding values. The default value identity is at the lowest priority (unless otherwise noted).
Compressing HTTP messages is one of the most important ways to improve the performance of a website. It shrinks the size of the data transmitted and makes better use of the available bandwidth. Browsers always send this header and the server should be configured to use compression.The Accept-Language headerThe Accept-Language header is used to indicate the language preference of the user. It's a list of values with quality factors (e.g., de, en;q=0.7). A default value is often set according to the language of the graphical interface of the user agent, but most browsers allow different language preferences to be set.
Due to the configuration-based entropy increase, a modified value can be used to fingerprint the user. It's not recommended to change it and a website can't trust this value to reflect the actual intention of the user. It's best for site designers to avoid using language detection via this header as it can lead to a poor user experience.

They should always provide a way to override the server-chosen language, e.g., by providing a language menu on the site. Most user agents provide a default value for the Accept-Language header that's adapted to the user interface language. End users often don't modify it because they either don't know how or aren't able to do so based on their computing environment.
Once a user has overridden the server-chosen language, a site should no longer use language detection and should stick with the explicitly chosen language. In other words, only entry pages for a site should use this header to select the proper language.
The User-Agent header
Note:
Though there are legitimate uses of this header for selecting content, it's considered bad practice to rely on it to define what features are supported by the user agent.

The User-Agent header identifies the browser sending the request. This string may contain a space-separated list of product tokens and comments.
A product token is a name followed by a / and a version number, like Firefox/4.0.1. The user agent can include as many of these as it wants. A comment is an optional string delimited by parentheses. The information provided in a comment isn't standardized, though several browsers add several tokens to it separated by ;.The Vary response headerIn contrast to the previous Accept-* headers, which are sent by the client, the Vary HTTP header is sent by the web server in its response. It indicates the list of headers the server uses during the server-driven content negotiation phase. The Vary header is needed to inform the cache of the decision criteria so that it can reproduce it. This allows the cache to be functional while ensuring that the right content is served to the user.
The special value * means that the server-driven content negotiation also uses information not conveyed in a header to choose the appropriate content.
The Vary header was added in version 1.1 of HTTP and allows caches to work appropriately. To work with server-driven content negotiation, a cache needs to know which criteria the server used to select the transmitted content. That way, the cache can replay the algorithm and will be able to serve acceptable content directly, without more requests to the server. Obviously, the wildcard * prevents caching from occurring, as the cache can't know what element is behind it. For more information, see HTTP caching > Varying responses.Agent-driven negotiationServer-driven negotiation has a few drawbacks: it doesn't scale well. One header per feature is used in the negotiation. If you want to use screen size, resolution, or other dimensions, you need to create a new HTTP header. The headers must then be sent with every request. This isn't an issue if there are only a few headers, but as the number of headers increases, the message size could eventually affect performance. The more precisely headers are sent, the more entropy is sent, allowing for more HTTP fingerprinting and corresponding privacy concerns.
HTTP allows another negotiation type: agent-driven negotiation or reactive negotiation. In this case, the server sends back a page that contains links to the available alternative resources when faced with an ambiguous request. The user is presented the resources and chooses the one to use.

Unfortunately, the HTTP standard doesn't specify the format of the page for choosing between the available resources, which prevents the process from being automated. Besides falling back to the server-driven negotiation, this method is almost always used with scripting, especially with JavaScript redirection: after having checked for the negotiation criteria, the script performs the redirection. A second problem is that one more request is needed to fetch the real resource, slowing the availability of the resource to the user.See also
Caching\n\nContent negotiationIn HTTP, content negotiation is the mechanism that is used for serving different representations of a resource to the same URI to help the user agent specify which representation is best suited for the user (for example, which document language, which image format, or which content encoding).

Note:
You'll find some disadvantages of HTTP content negotiation in a wiki page from WHATWG. HTML provides alternatives to content negotiation via, for example, the <source> element.
Principles of content negotiationA specific document is called a resource. When a client wants to obtain a resource, the client requests it via a URL. The server uses this URL to choose one of the variants available–each variant is called a representation–and returns a specific representation to the client. The overall resource, as well as each of the representations, has a specific URL. Content negotiation determines how a specific representation is chosen when the resource is called. There are several ways of negotiating between the client and the server.

The best-suited representation is identified through one of two mechanisms:

Specific HTTP headers by the client (server-driven negotiation or proactive negotiation), which is the standard way of negotiating a specific kind of resource.
The 300 (Multiple Choices) or 406 (Not Acceptable), 415 (Unsupported Media Type) HTTP response codes by the server (agent-driven negotiation or reactive negotiation), that are used as fallback mechanisms.

Over the years, other content negotiation proposals, like transparent content negotiation and the Alternates header, have been proposed. They failed to get traction and were abandoned.Server-driven content negotiationIn server-driven content negotiation, or proactive content negotiation, the browser (or any other kind of user agent) sends several HTTP headers along with the URL. These headers describe the user's preferred choice. The server uses them as hints and an internal algorithm chooses the best content to serve to the client. If it can't provide a suitable resource, it might respond with 406 (Not Acceptable) or 415 (Unsupported Media Type) and set headers for the types of media that it does support (e.g., using the Accept-Post or Accept-Patch for POST and PATCH requests, respectively). The algorithm is server-specific and not defined in the standard. See the Apache negotiation algorithm.

The HTTP/1.1 standard defines list of the standard headers that start server-driven negotiation (such as Accept, Accept-Encoding, and Accept-Language). Though User-Agent isn't in this list, it's sometimes also used to send a specific representation of the requested resource. However, this isn't always considered a good practice. The server uses the Vary header to indicate which headers it actually used for content negotiation (or more precisely, the associated request headers), so that caches can work optimally.
In addition to these, there's an experimental proposal to add more headers to the list of available headers, called client hints. Client hints advertise what kind of device the user agent runs on (for example, a desktop computer or a mobile device).
Even if server-driven content negotiation is the most common way to agree on a specific representation of a resource, it has several drawbacks:

The server doesn't have total knowledge of the browser. Even with the Client Hints extension, it doesn't have a complete knowledge of the capabilities of the browser. Unlike reactive content negotiation where the client makes the choice, the server choice is always somewhat arbitrary.
The information from the client is quite verbose (HTTP/2 header compression mitigates this problem) and a privacy risk (HTTP fingerprinting).
As several representations of a given resource are sent, shared caches are less efficient and server implementations are more complex.
The Accept headerThe Accept header lists the MIME types of media resources that the agent is willing to process. This is a comma-separated list of MIME types, each combined with a quality factor, a parameter that indicates the relative degree of preference between the different MIME types.
The Accept header is defined by the browser, or any other user agent, and can vary according to the context. For example, fetching an HTML page or an image, a video, or a script. It's different when fetching a document entered in the address bar or an element linked via an <img>, <video>, or <audio> element. Browsers are free to use the value of the header that they think is the most adequate; an exhaustive list of default values for common browsers is available.The Accept-CH header
Note:
This is part of an experimental technology called Client Hints. Initial support comes in Chrome 46 or later. The Device-Memory value is in Chrome 61 or later.

The experimental Accept-CH lists configuration data that the server can use to select an appropriate response. Valid values are:



Value
Meaning




Device-Memory
Indicates the approximate amount of device RAM. This value is an approximation given by rounding to the nearest power of 2 and dividing that number by 1024. For example, 512 megabytes will be reported as 0.5.


Viewport-Width
Indicates the layout viewport width in CSS pixels.


Width
Indicates the resource width in physical pixels (in other words the intrinsic size of an image).


The Accept-Encoding headerThe Accept-Encoding header defines the acceptable content encoding (supported compressions). The value is a q-factor list (e.g., br, gzip;q=0.8) that indicates the priority of the encoding values. The default value identity is at the lowest priority (unless otherwise noted).
Compressing HTTP messages is one of the most important ways to improve the performance of a website. It shrinks the size of the data transmitted and makes better use of the available bandwidth. Browsers always send this header and the server should be configured to use compression.The Accept-Language headerThe Accept-Language header is used to indicate the language preference of the user. It's a list of values with quality factors (e.g., de, en;q=0.7). A default value is often set according to the language of the graphical interface of the user agent, but most browsers allow different language preferences to be set.
Due to the configuration-based entropy increase, a modified value can be used to fingerprint the user. It's not recommended to change it and a website can't trust this value to reflect the actual intention of the user. It's best for site designers to avoid using language detection via this header as it can lead to a poor user experience.

They should always provide a way to override the server-chosen language, e.g., by providing a language menu on the site. Most user agents provide a default value for the Accept-Language header that's adapted to the user interface language. End users often don't modify it because they either don't know how or aren't able to do so based on their computing environment.
Once a user has overridden the server-chosen language, a site should no longer use language detection and should stick with the explicitly chosen language. In other words, only entry pages for a site should use this header to select the proper language.
The User-Agent header
Note:
Though there are legitimate uses of this header for selecting content, it's considered bad practice to rely on it to define what features are supported by the user agent.

The User-Agent header identifies the browser sending the request. This string may contain a space-separated list of product tokens and comments.
A product token is a name followed by a / and a version number, like Firefox/4.0.1. The user agent can include as many of these as it wants. A comment is an optional string delimited by parentheses. The information provided in a comment isn't standardized, though several browsers add several tokens to it separated by ;.The Vary response headerIn contrast to the previous Accept-* headers, which are sent by the client, the Vary HTTP header is sent by the web server in its response. It indicates the list of headers the server uses during the server-driven content negotiation phase. The Vary header is needed to inform the cache of the decision criteria so that it can reproduce it. This allows the cache to be functional while ensuring that the right content is served to the user.
The special value * means that the server-driven content negotiation also uses information not conveyed in a header to choose the appropriate content.
The Vary header was added in version 1.1 of HTTP and allows caches to work appropriately. To work with server-driven content negotiation, a cache needs to know which criteria the server used to select the transmitted content. That way, the cache can replay the algorithm and will be able to serve acceptable content directly, without more requests to the server. Obviously, the wildcard * prevents caching from occurring, as the cache can't know what element is behind it. For more information, see HTTP caching > Varying responses.Agent-driven negotiationServer-driven negotiation has a few drawbacks: it doesn't scale well. One header per feature is used in the negotiation. If you want to use screen size, resolution, or other dimensions, you need to create a new HTTP header. The headers must then be sent with every request. This isn't an issue if there are only a few headers, but as the number of headers increases, the message size could eventually affect performance. The more precisely headers are sent, the more entropy is sent, allowing for more HTTP fingerprinting and corresponding privacy concerns.
HTTP allows another negotiation type: agent-driven negotiation or reactive negotiation. In this case, the server sends back a page that contains links to the available alternative resources when faced with an ambiguous request. The user is presented the resources and chooses the one to use.

Unfortunately, the HTTP standard doesn't specify the format of the page for choosing between the available resources, which prevents the process from being automated. Besides falling back to the server-driven negotiation, this method is almost always used with scripting, especially with JavaScript redirection: after having checked for the negotiation criteria, the script performs the redirection. A second problem is that one more request is needed to fetch the real resource, slowing the availability of the resource to the user.See also
Caching
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Apr 10, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nContent negotiationIn HTTP, content negotiation is the mechanism that is used for serving different representations of a resource to the same URI to help the user agent specify which representation is best suited for the user (for example, which document language, which image format, or which content encoding).

Note:
You'll find some disadvantages of HTTP content negotiation in a wiki page from WHATWG. HTML provides alternatives to content negotiation via, for example, the <source> element.
Principles of content negotiationA specific document is called a resource. When a client wants to obtain a resource, the client requests it via a URL. The server uses this URL to choose one of the variants available–each variant is called a representation–and returns a specific representation to the client. The overall resource, as well as each of the representations, has a specific URL. Content negotiation determines how a specific representation is chosen when the resource is called. There are several ways of negotiating between the client and the server.

The best-suited representation is identified through one of two mechanisms:

Specific HTTP headers by the client (server-driven negotiation or proactive negotiation), which is the standard way of negotiating a specific kind of resource.
The 300 (Multiple Choices) or 406 (Not Acceptable), 415 (Unsupported Media Type) HTTP response codes by the server (agent-driven negotiation or reactive negotiation), that are used as fallback mechanisms.

Over the years, other content negotiation proposals, like transparent content negotiation and the Alternates header, have been proposed. They failed to get traction and were abandoned.Server-driven content negotiationIn server-driven content negotiation, or proactive content negotiation, the browser (or any other kind of user agent) sends several HTTP headers along with the URL. These headers describe the user's preferred choice. The server uses them as hints and an internal algorithm chooses the best content to serve to the client. If it can't provide a suitable resource, it might respond with 406 (Not Acceptable) or 415 (Unsupported Media Type) and set headers for the types of media that it does support (e.g., using the Accept-Post or Accept-Patch for POST and PATCH requests, respectively). The algorithm is server-specific and not defined in the standard. See the Apache negotiation algorithm.

The HTTP/1.1 standard defines list of the standard headers that start server-driven negotiation (such as Accept, Accept-Encoding, and Accept-Language). Though User-Agent isn't in this list, it's sometimes also used to send a specific representation of the requested resource. However, this isn't always considered a good practice. The server uses the Vary header to indicate which headers it actually used for content negotiation (or more precisely, the associated request headers), so that caches can work optimally.
In addition to these, there's an experimental proposal to add more headers to the list of available headers, called client hints. Client hints advertise what kind of device the user agent runs on (for example, a desktop computer or a mobile device).
Even if server-driven content negotiation is the most common way to agree on a specific representation of a resource, it has several drawbacks:

The server doesn't have total knowledge of the browser. Even with the Client Hints extension, it doesn't have a complete knowledge of the capabilities of the browser. Unlike reactive content negotiation where the client makes the choice, the server choice is always somewhat arbitrary.
The information from the client is quite verbose (HTTP/2 header compression mitigates this problem) and a privacy risk (HTTP fingerprinting).
As several representations of a given resource are sent, shared caches are less efficient and server implementations are more complex.
The Accept headerThe Accept header lists the MIME types of media resources that the agent is willing to process. This is a comma-separated list of MIME types, each combined with a quality factor, a parameter that indicates the relative degree of preference between the different MIME types.
The Accept header is defined by the browser, or any other user agent, and can vary according to the context. For example, fetching an HTML page or an image, a video, or a script. It's different when fetching a document entered in the address bar or an element linked via an <img>, <video>, or <audio> element. Browsers are free to use the value of the header that they think is the most adequate; an exhaustive list of default values for common browsers is available.The Accept-CH header
Note:
This is part of an experimental technology called Client Hints. Initial support comes in Chrome 46 or later. The Device-Memory value is in Chrome 61 or later.

The experimental Accept-CH lists configuration data that the server can use to select an appropriate response. Valid values are:



Value
Meaning




Device-Memory
Indicates the approximate amount of device RAM. This value is an approximation given by rounding to the nearest power of 2 and dividing that number by 1024. For example, 512 megabytes will be reported as 0.5.


Viewport-Width
Indicates the layout viewport width in CSS pixels.


Width
Indicates the resource width in physical pixels (in other words the intrinsic size of an image).


The Accept-Encoding headerThe Accept-Encoding header defines the acceptable content encoding (supported compressions). The value is a q-factor list (e.g., br, gzip;q=0.8) that indicates the priority of the encoding values. The default value identity is at the lowest priority (unless otherwise noted).
Compressing HTTP messages is one of the most important ways to improve the performance of a website. It shrinks the size of the data transmitted and makes better use of the available bandwidth. Browsers always send this header and the server should be configured to use compression.The Accept-Language headerThe Accept-Language header is used to indicate the language preference of the user. It's a list of values with quality factors (e.g., de, en;q=0.7). A default value is often set according to the language of the graphical interface of the user agent, but most browsers allow different language preferences to be set.
Due to the configuration-based entropy increase, a modified value can be used to fingerprint the user. It's not recommended to change it and a website can't trust this value to reflect the actual intention of the user. It's best for site designers to avoid using language detection via this header as it can lead to a poor user experience.

They should always provide a way to override the server-chosen language, e.g., by providing a language menu on the site. Most user agents provide a default value for the Accept-Language header that's adapted to the user interface language. End users often don't modify it because they either don't know how or aren't able to do so based on their computing environment.
Once a user has overridden the server-chosen language, a site should no longer use language detection and should stick with the explicitly chosen language. In other words, only entry pages for a site should use this header to select the proper language.
The User-Agent header
Note:
Though there are legitimate uses of this header for selecting content, it's considered bad practice to rely on it to define what features are supported by the user agent.

The User-Agent header identifies the browser sending the request. This string may contain a space-separated list of product tokens and comments.
A product token is a name followed by a / and a version number, like Firefox/4.0.1. The user agent can include as many of these as it wants. A comment is an optional string delimited by parentheses. The information provided in a comment isn't standardized, though several browsers add several tokens to it separated by ;.The Vary response headerIn contrast to the previous Accept-* headers, which are sent by the client, the Vary HTTP header is sent by the web server in its response. It indicates the list of headers the server uses during the server-driven content negotiation phase. The Vary header is needed to inform the cache of the decision criteria so that it can reproduce it. This allows the cache to be functional while ensuring that the right content is served to the user.
The special value * means that the server-driven content negotiation also uses information not conveyed in a header to choose the appropriate content.
The Vary header was added in version 1.1 of HTTP and allows caches to work appropriately. To work with server-driven content negotiation, a cache needs to know which criteria the server used to select the transmitted content. That way, the cache can replay the algorithm and will be able to serve acceptable content directly, without more requests to the server. Obviously, the wildcard * prevents caching from occurring, as the cache can't know what element is behind it. For more information, see HTTP caching > Varying responses.Agent-driven negotiationServer-driven negotiation has a few drawbacks: it doesn't scale well. One header per feature is used in the negotiation. If you want to use screen size, resolution, or other dimensions, you need to create a new HTTP header. The headers must then be sent with every request. This isn't an issue if there are only a few headers, but as the number of headers increases, the message size could eventually affect performance. The more precisely headers are sent, the more entropy is sent, allowing for more HTTP fingerprinting and corresponding privacy concerns.
HTTP allows another negotiation type: agent-driven negotiation or reactive negotiation. In this case, the server sends back a page that contains links to the available alternative resources when faced with an ambiguous request. The user is presented the resources and chooses the one to use.

Unfortunately, the HTTP standard doesn't specify the format of the page for choosing between the available resources, which prevents the process from being automated. Besides falling back to the server-driven negotiation, this method is almost always used with scripting, especially with JavaScript redirection: after having checked for the negotiation criteria, the script performs the redirection. A second problem is that one more request is needed to fetch the real resource, slowing the availability of the resource to the user.See also
Caching
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Apr 10, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nContent negotiationIn HTTP, content negotiation is the mechanism that is used for serving different representations of a resource to the same URI to help the user agent specify which representation is best suited for the user (for example, which document language, which image format, or which content encoding).

Note:
You'll find some disadvantages of HTTP content negotiation in a wiki page from WHATWG. HTML provides alternatives to content negotiation via, for example, the <source> element.
Principles of content negotiationA specific document is called a resource. When a client wants to obtain a resource, the client requests it via a URL. The server uses this URL to choose one of the variants available–each variant is called a representation–and returns a specific representation to the client. The overall resource, as well as each of the representations, has a specific URL. Content negotiation determines how a specific representation is chosen when the resource is called. There are several ways of negotiating between the client and the server.

The best-suited representation is identified through one of two mechanisms:

Specific HTTP headers by the client (server-driven negotiation or proactive negotiation), which is the standard way of negotiating a specific kind of resource.
The 300 (Multiple Choices) or 406 (Not Acceptable), 415 (Unsupported Media Type) HTTP response codes by the server (agent-driven negotiation or reactive negotiation), that are used as fallback mechanisms.

Over the years, other content negotiation proposals, like transparent content negotiation and the Alternates header, have been proposed. They failed to get traction and were abandoned.Server-driven content negotiationIn server-driven content negotiation, or proactive content negotiation, the browser (or any other kind of user agent) sends several HTTP headers along with the URL. These headers describe the user's preferred choice. The server uses them as hints and an internal algorithm chooses the best content to serve to the client. If it can't provide a suitable resource, it might respond with 406 (Not Acceptable) or 415 (Unsupported Media Type) and set headers for the types of media that it does support (e.g., using the Accept-Post or Accept-Patch for POST and PATCH requests, respectively). The algorithm is server-specific and not defined in the standard. See the Apache negotiation algorithm.

The HTTP/1.1 standard defines list of the standard headers that start server-driven negotiation (such as Accept, Accept-Encoding, and Accept-Language). Though User-Agent isn't in this list, it's sometimes also used to send a specific representation of the requested resource. However, this isn't always considered a good practice. The server uses the Vary header to indicate which headers it actually used for content negotiation (or more precisely, the associated request headers), so that caches can work optimally.
In addition to these, there's an experimental proposal to add more headers to the list of available headers, called client hints. Client hints advertise what kind of device the user agent runs on (for example, a desktop computer or a mobile device).
Even if server-driven content negotiation is the most common way to agree on a specific representation of a resource, it has several drawbacks:

The server doesn't have total knowledge of the browser. Even with the Client Hints extension, it doesn't have a complete knowledge of the capabilities of the browser. Unlike reactive content negotiation where the client makes the choice, the server choice is always somewhat arbitrary.
The information from the client is quite verbose (HTTP/2 header compression mitigates this problem) and a privacy risk (HTTP fingerprinting).
As several representations of a given resource are sent, shared caches are less efficient and server implementations are more complex.
The Accept headerThe Accept header lists the MIME types of media resources that the agent is willing to process. This is a comma-separated list of MIME types, each combined with a quality factor, a parameter that indicates the relative degree of preference between the different MIME types.
The Accept header is defined by the browser, or any other user agent, and can vary according to the context. For example, fetching an HTML page or an image, a video, or a script. It's different when fetching a document entered in the address bar or an element linked via an <img>, <video>, or <audio> element. Browsers are free to use the value of the header that they think is the most adequate; an exhaustive list of default values for common browsers is available.The Accept-CH header
Note:
This is part of an experimental technology called Client Hints. Initial support comes in Chrome 46 or later. The Device-Memory value is in Chrome 61 or later.

The experimental Accept-CH lists configuration data that the server can use to select an appropriate response. Valid values are:



Value
Meaning




Device-Memory
Indicates the approximate amount of device RAM. This value is an approximation given by rounding to the nearest power of 2 and dividing that number by 1024. For example, 512 megabytes will be reported as 0.5.


Viewport-Width
Indicates the layout viewport width in CSS pixels.


Width
Indicates the resource width in physical pixels (in other words the intrinsic size of an image).


The Accept-Encoding headerThe Accept-Encoding header defines the acceptable content encoding (supported compressions). The value is a q-factor list (e.g., br, gzip;q=0.8) that indicates the priority of the encoding values. The default value identity is at the lowest priority (unless otherwise noted).
Compressing HTTP messages is one of the most important ways to improve the performance of a website. It shrinks the size of the data transmitted and makes better use of the available bandwidth. Browsers always send this header and the server should be configured to use compression.The Accept-Language headerThe Accept-Language header is used to indicate the language preference of the user. It's a list of values with quality factors (e.g., de, en;q=0.7). A default value is often set according to the language of the graphical interface of the user agent, but most browsers allow different language preferences to be set.
Due to the configuration-based entropy increase, a modified value can be used to fingerprint the user. It's not recommended to change it and a website can't trust this value to reflect the actual intention of the user. It's best for site designers to avoid using language detection via this header as it can lead to a poor user experience.

They should always provide a way to override the server-chosen language, e.g., by providing a language menu on the site. Most user agents provide a default value for the Accept-Language header that's adapted to the user interface language. End users often don't modify it because they either don't know how or aren't able to do so based on their computing environment.
Once a user has overridden the server-chosen language, a site should no longer use language detection and should stick with the explicitly chosen language. In other words, only entry pages for a site should use this header to select the proper language.
The User-Agent header
Note:
Though there are legitimate uses of this header for selecting content, it's considered bad practice to rely on it to define what features are supported by the user agent.

The User-Agent header identifies the browser sending the request. This string may contain a space-separated list of product tokens and comments.
A product token is a name followed by a / and a version number, like Firefox/4.0.1. The user agent can include as many of these as it wants. A comment is an optional string delimited by parentheses. The information provided in a comment isn't standardized, though several browsers add several tokens to it separated by ;.The Vary response headerIn contrast to the previous Accept-* headers, which are sent by the client, the Vary HTTP header is sent by the web server in its response. It indicates the list of headers the server uses during the server-driven content negotiation phase. The Vary header is needed to inform the cache of the decision criteria so that it can reproduce it. This allows the cache to be functional while ensuring that the right content is served to the user.
The special value * means that the server-driven content negotiation also uses information not conveyed in a header to choose the appropriate content.
The Vary header was added in version 1.1 of HTTP and allows caches to work appropriately. To work with server-driven content negotiation, a cache needs to know which criteria the server used to select the transmitted content. That way, the cache can replay the algorithm and will be able to serve acceptable content directly, without more requests to the server. Obviously, the wildcard * prevents caching from occurring, as the cache can't know what element is behind it. For more information, see HTTP caching > Varying responses.Agent-driven negotiationServer-driven negotiation has a few drawbacks: it doesn't scale well. One header per feature is used in the negotiation. If you want to use screen size, resolution, or other dimensions, you need to create a new HTTP header. The headers must then be sent with every request. This isn't an issue if there are only a few headers, but as the number of headers increases, the message size could eventually affect performance. The more precisely headers are sent, the more entropy is sent, allowing for more HTTP fingerprinting and corresponding privacy concerns.
HTTP allows another negotiation type: agent-driven negotiation or reactive negotiation. In this case, the server sends back a page that contains links to the available alternative resources when faced with an ambiguous request. The user is presented the resources and chooses the one to use.

Unfortunately, the HTTP standard doesn't specify the format of the page for choosing between the available resources, which prevents the process from being automated. Besides falling back to the server-driven negotiation, this method is almost always used with scripting, especially with JavaScript redirection: after having checked for the negotiation criteria, the script performs the redirection. A second problem is that one more request is needed to fetch the real resource, slowing the availability of the resource to the user.See also
Caching\n\nContent negotiationIn HTTP, content negotiation is the mechanism that is used for serving different representations of a resource to the same URI to help the user agent specify which representation is best suited for the user (for example, which document language, which image format, or which content encoding).

Note:
You'll find some disadvantages of HTTP content negotiation in a wiki page from WHATWG. HTML provides alternatives to content negotiation via, for example, the <source> element.
Principles of content negotiationA specific document is called a resource. When a client wants to obtain a resource, the client requests it via a URL. The server uses this URL to choose one of the variants available–each variant is called a representation–and returns a specific representation to the client. The overall resource, as well as each of the representations, has a specific URL. Content negotiation determines how a specific representation is chosen when the resource is called. There are several ways of negotiating between the client and the server.

The best-suited representation is identified through one of two mechanisms:

Specific HTTP headers by the client (server-driven negotiation or proactive negotiation), which is the standard way of negotiating a specific kind of resource.
The 300 (Multiple Choices) or 406 (Not Acceptable), 415 (Unsupported Media Type) HTTP response codes by the server (agent-driven negotiation or reactive negotiation), that are used as fallback mechanisms.

Over the years, other content negotiation proposals, like transparent content negotiation and the Alternates header, have been proposed. They failed to get traction and were abandoned.Server-driven content negotiationIn server-driven content negotiation, or proactive content negotiation, the browser (or any other kind of user agent) sends several HTTP headers along with the URL. These headers describe the user's preferred choice. The server uses them as hints and an internal algorithm chooses the best content to serve to the client. If it can't provide a suitable resource, it might respond with 406 (Not Acceptable) or 415 (Unsupported Media Type) and set headers for the types of media that it does support (e.g., using the Accept-Post or Accept-Patch for POST and PATCH requests, respectively). The algorithm is server-specific and not defined in the standard. See the Apache negotiation algorithm.

The HTTP/1.1 standard defines list of the standard headers that start server-driven negotiation (such as Accept, Accept-Encoding, and Accept-Language). Though User-Agent isn't in this list, it's sometimes also used to send a specific representation of the requested resource. However, this isn't always considered a good practice. The server uses the Vary header to indicate which headers it actually used for content negotiation (or more precisely, the associated request headers), so that caches can work optimally.
In addition to these, there's an experimental proposal to add more headers to the list of available headers, called client hints. Client hints advertise what kind of device the user agent runs on (for example, a desktop computer or a mobile device).
Even if server-driven content negotiation is the most common way to agree on a specific representation of a resource, it has several drawbacks:

The server doesn't have total knowledge of the browser. Even with the Client Hints extension, it doesn't have a complete knowledge of the capabilities of the browser. Unlike reactive content negotiation where the client makes the choice, the server choice is always somewhat arbitrary.
The information from the client is quite verbose (HTTP/2 header compression mitigates this problem) and a privacy risk (HTTP fingerprinting).
As several representations of a given resource are sent, shared caches are less efficient and server implementations are more complex.
The Accept headerThe Accept header lists the MIME types of media resources that the agent is willing to process. This is a comma-separated list of MIME types, each combined with a quality factor, a parameter that indicates the relative degree of preference between the different MIME types.
The Accept header is defined by the browser, or any other user agent, and can vary according to the context. For example, fetching an HTML page or an image, a video, or a script. It's different when fetching a document entered in the address bar or an element linked via an <img>, <video>, or <audio> element. Browsers are free to use the value of the header that they think is the most adequate; an exhaustive list of default values for common browsers is available.The Accept-CH header
Note:
This is part of an experimental technology called Client Hints. Initial support comes in Chrome 46 or later. The Device-Memory value is in Chrome 61 or later.

The experimental Accept-CH lists configuration data that the server can use to select an appropriate response. Valid values are:



Value
Meaning




Device-Memory
Indicates the approximate amount of device RAM. This value is an approximation given by rounding to the nearest power of 2 and dividing that number by 1024. For example, 512 megabytes will be reported as 0.5.


Viewport-Width
Indicates the layout viewport width in CSS pixels.


Width
Indicates the resource width in physical pixels (in other words the intrinsic size of an image).


The Accept-Encoding headerThe Accept-Encoding header defines the acceptable content encoding (supported compressions). The value is a q-factor list (e.g., br, gzip;q=0.8) that indicates the priority of the encoding values. The default value identity is at the lowest priority (unless otherwise noted).
Compressing HTTP messages is one of the most important ways to improve the performance of a website. It shrinks the size of the data transmitted and makes better use of the available bandwidth. Browsers always send this header and the server should be configured to use compression.The Accept-Language headerThe Accept-Language header is used to indicate the language preference of the user. It's a list of values with quality factors (e.g., de, en;q=0.7). A default value is often set according to the language of the graphical interface of the user agent, but most browsers allow different language preferences to be set.
Due to the configuration-based entropy increase, a modified value can be used to fingerprint the user. It's not recommended to change it and a website can't trust this value to reflect the actual intention of the user. It's best for site designers to avoid using language detection via this header as it can lead to a poor user experience.

They should always provide a way to override the server-chosen language, e.g., by providing a language menu on the site. Most user agents provide a default value for the Accept-Language header that's adapted to the user interface language. End users often don't modify it because they either don't know how or aren't able to do so based on their computing environment.
Once a user has overridden the server-chosen language, a site should no longer use language detection and should stick with the explicitly chosen language. In other words, only entry pages for a site should use this header to select the proper language.
The User-Agent header
Note:
Though there are legitimate uses of this header for selecting content, it's considered bad practice to rely on it to define what features are supported by the user agent.

The User-Agent header identifies the browser sending the request. This string may contain a space-separated list of product tokens and comments.
A product token is a name followed by a / and a version number, like Firefox/4.0.1. The user agent can include as many of these as it wants. A comment is an optional string delimited by parentheses. The information provided in a comment isn't standardized, though several browsers add several tokens to it separated by ;.The Vary response headerIn contrast to the previous Accept-* headers, which are sent by the client, the Vary HTTP header is sent by the web server in its response. It indicates the list of headers the server uses during the server-driven content negotiation phase. The Vary header is needed to inform the cache of the decision criteria so that it can reproduce it. This allows the cache to be functional while ensuring that the right content is served to the user.
The special value * means that the server-driven content negotiation also uses information not conveyed in a header to choose the appropriate content.
The Vary header was added in version 1.1 of HTTP and allows caches to work appropriately. To work with server-driven content negotiation, a cache needs to know which criteria the server used to select the transmitted content. That way, the cache can replay the algorithm and will be able to serve acceptable content directly, without more requests to the server. Obviously, the wildcard * prevents caching from occurring, as the cache can't know what element is behind it. For more information, see HTTP caching > Varying responses.Agent-driven negotiationServer-driven negotiation has a few drawbacks: it doesn't scale well. One header per feature is used in the negotiation. If you want to use screen size, resolution, or other dimensions, you need to create a new HTTP header. The headers must then be sent with every request. This isn't an issue if there are only a few headers, but as the number of headers increases, the message size could eventually affect performance. The more precisely headers are sent, the more entropy is sent, allowing for more HTTP fingerprinting and corresponding privacy concerns.
HTTP allows another negotiation type: agent-driven negotiation or reactive negotiation. In this case, the server sends back a page that contains links to the available alternative resources when faced with an ambiguous request. The user is presented the resources and chooses the one to use.

Unfortunately, the HTTP standard doesn't specify the format of the page for choosing between the available resources, which prevents the process from being automated. Besides falling back to the server-driven negotiation, this method is almost always used with scripting, especially with JavaScript redirection: after having checked for the negotiation criteria, the script performs the redirection. A second problem is that one more request is needed to fetch the real resource, slowing the availability of the resource to the user.See also
Caching
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Apr 10, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nContent negotiationIn HTTP, content negotiation is the mechanism that is used for serving different representations of a resource to the same URI to help the user agent specify which representation is best suited for the user (for example, which document language, which image format, or which content encoding).

Note:
You'll find some disadvantages of HTTP content negotiation in a wiki page from WHATWG. HTML provides alternatives to content negotiation via, for example, the <source> element.
Principles of content negotiationA specific document is called a resource. When a client wants to obtain a resource, the client requests it via a URL. The server uses this URL to choose one of the variants available–each variant is called a representation–and returns a specific representation to the client. The overall resource, as well as each of the representations, has a specific URL. Content negotiation determines how a specific representation is chosen when the resource is called. There are several ways of negotiating between the client and the server.

The best-suited representation is identified through one of two mechanisms:

Specific HTTP headers by the client (server-driven negotiation or proactive negotiation), which is the standard way of negotiating a specific kind of resource.
The 300 (Multiple Choices) or 406 (Not Acceptable), 415 (Unsupported Media Type) HTTP response codes by the server (agent-driven negotiation or reactive negotiation), that are used as fallback mechanisms.

Over the years, other content negotiation proposals, like transparent content negotiation and the Alternates header, have been proposed. They failed to get traction and were abandoned.Server-driven content negotiationIn server-driven content negotiation, or proactive content negotiation, the browser (or any other kind of user agent) sends several HTTP headers along with the URL. These headers describe the user's preferred choice. The server uses them as hints and an internal algorithm chooses the best content to serve to the client. If it can't provide a suitable resource, it might respond with 406 (Not Acceptable) or 415 (Unsupported Media Type) and set headers for the types of media that it does support (e.g., using the Accept-Post or Accept-Patch for POST and PATCH requests, respectively). The algorithm is server-specific and not defined in the standard. See the Apache negotiation algorithm.

The HTTP/1.1 standard defines list of the standard headers that start server-driven negotiation (such as Accept, Accept-Encoding, and Accept-Language). Though User-Agent isn't in this list, it's sometimes also used to send a specific representation of the requested resource. However, this isn't always considered a good practice. The server uses the Vary header to indicate which headers it actually used for content negotiation (or more precisely, the associated request headers), so that caches can work optimally.
In addition to these, there's an experimental proposal to add more headers to the list of available headers, called client hints. Client hints advertise what kind of device the user agent runs on (for example, a desktop computer or a mobile device).
Even if server-driven content negotiation is the most common way to agree on a specific representation of a resource, it has several drawbacks:

The server doesn't have total knowledge of the browser. Even with the Client Hints extension, it doesn't have a complete knowledge of the capabilities of the browser. Unlike reactive content negotiation where the client makes the choice, the server choice is always somewhat arbitrary.
The information from the client is quite verbose (HTTP/2 header compression mitigates this problem) and a privacy risk (HTTP fingerprinting).
As several representations of a given resource are sent, shared caches are less efficient and server implementations are more complex.
The Accept headerThe Accept header lists the MIME types of media resources that the agent is willing to process. This is a comma-separated list of MIME types, each combined with a quality factor, a parameter that indicates the relative degree of preference between the different MIME types.
The Accept header is defined by the browser, or any other user agent, and can vary according to the context. For example, fetching an HTML page or an image, a video, or a script. It's different when fetching a document entered in the address bar or an element linked via an <img>, <video>, or <audio> element. Browsers are free to use the value of the header that they think is the most adequate; an exhaustive list of default values for common browsers is available.The Accept-CH header
Note:
This is part of an experimental technology called Client Hints. Initial support comes in Chrome 46 or later. The Device-Memory value is in Chrome 61 or later.

The experimental Accept-CH lists configuration data that the server can use to select an appropriate response. Valid values are:



Value
Meaning




Device-Memory
Indicates the approximate amount of device RAM. This value is an approximation given by rounding to the nearest power of 2 and dividing that number by 1024. For example, 512 megabytes will be reported as 0.5.


Viewport-Width
Indicates the layout viewport width in CSS pixels.


Width
Indicates the resource width in physical pixels (in other words the intrinsic size of an image).


The Accept-Encoding headerThe Accept-Encoding header defines the acceptable content encoding (supported compressions). The value is a q-factor list (e.g., br, gzip;q=0.8) that indicates the priority of the encoding values. The default value identity is at the lowest priority (unless otherwise noted).
Compressing HTTP messages is one of the most important ways to improve the performance of a website. It shrinks the size of the data transmitted and makes better use of the available bandwidth. Browsers always send this header and the server should be configured to use compression.The Accept-Language headerThe Accept-Language header is used to indicate the language preference of the user. It's a list of values with quality factors (e.g., de, en;q=0.7). A default value is often set according to the language of the graphical interface of the user agent, but most browsers allow different language preferences to be set.
Due to the configuration-based entropy increase, a modified value can be used to fingerprint the user. It's not recommended to change it and a website can't trust this value to reflect the actual intention of the user. It's best for site designers to avoid using language detection via this header as it can lead to a poor user experience.

They should always provide a way to override the server-chosen language, e.g., by providing a language menu on the site. Most user agents provide a default value for the Accept-Language header that's adapted to the user interface language. End users often don't modify it because they either don't know how or aren't able to do so based on their computing environment.
Once a user has overridden the server-chosen language, a site should no longer use language detection and should stick with the explicitly chosen language. In other words, only entry pages for a site should use this header to select the proper language.
The User-Agent header
Note:
Though there are legitimate uses of this header for selecting content, it's considered bad practice to rely on it to define what features are supported by the user agent.

The User-Agent header identifies the browser sending the request. This string may contain a space-separated list of product tokens and comments.
A product token is a name followed by a / and a version number, like Firefox/4.0.1. The user agent can include as many of these as it wants. A comment is an optional string delimited by parentheses. The information provided in a comment isn't standardized, though several browsers add several tokens to it separated by ;.The Vary response headerIn contrast to the previous Accept-* headers, which are sent by the client, the Vary HTTP header is sent by the web server in its response. It indicates the list of headers the server uses during the server-driven content negotiation phase. The Vary header is needed to inform the cache of the decision criteria so that it can reproduce it. This allows the cache to be functional while ensuring that the right content is served to the user.
The special value * means that the server-driven content negotiation also uses information not conveyed in a header to choose the appropriate content.
The Vary header was added in version 1.1 of HTTP and allows caches to work appropriately. To work with server-driven content negotiation, a cache needs to know which criteria the server used to select the transmitted content. That way, the cache can replay the algorithm and will be able to serve acceptable content directly, without more requests to the server. Obviously, the wildcard * prevents caching from occurring, as the cache can't know what element is behind it. For more information, see HTTP caching > Varying responses.Agent-driven negotiationServer-driven negotiation has a few drawbacks: it doesn't scale well. One header per feature is used in the negotiation. If you want to use screen size, resolution, or other dimensions, you need to create a new HTTP header. The headers must then be sent with every request. This isn't an issue if there are only a few headers, but as the number of headers increases, the message size could eventually affect performance. The more precisely headers are sent, the more entropy is sent, allowing for more HTTP fingerprinting and corresponding privacy concerns.
HTTP allows another negotiation type: agent-driven negotiation or reactive negotiation. In this case, the server sends back a page that contains links to the available alternative resources when faced with an ambiguous request. The user is presented the resources and chooses the one to use.

Unfortunately, the HTTP standard doesn't specify the format of the page for choosing between the available resources, which prevents the process from being automated. Besides falling back to the server-driven negotiation, this method is almost always used with scripting, especially with JavaScript redirection: after having checked for the negotiation criteria, the script performs the redirection. A second problem is that one more request is needed to fetch the real resource, slowing the availability of the resource to the user.See also
Caching
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Apr 10, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nResources for Developers, by DevelopersDocumenting web technologies, including CSS, HTML, and JavaScript, since 2005.Search MDNClear search inputSearchFeatured articlesBlogJavaScript Temporal is comingA new way to handle dates and times is being added to JavaScript. Let's take a look at Temporal, what problems it solves, the current state, and what you'll find in the new documentation about it on MDN.
CSSCSS anchor positioningThe CSS anchor positioning module defines features that allow you to tether elements together. Certain elements are defined as anchor elements; anchor-positioned elements can then have their size and position set based on the size and location of the anchor elements to which they are bound.
Web APIsUsing the View Transition APIThis article explains the theory behind how the View Transition API works, how to create view transitions and customize the transition animations, and how to manipulate active view transitions. This covers view transitions for both DOM state updates in a single-page app (SPA), and navigating between documents in a multi-page app (MPA).
JavaScriptTemporalThe Temporal object enables date and time management in various scenarios, including built-in time zone and calendar representation, wall-clock time conversions, arithmetics, formatting, and more. It is designed as a full replacement for the Date object.
Latest newsMDN 2024 content projectsdeveloper.mozilla.org4 months agoA new learning experience on MDNdeveloper.mozilla.org4 months agoIntroducing the new MDN Community pagedeveloper.mozilla.org6 months agoRecent contributions[zh-cn]: update the translation of Location `host` propertymdn/translated-contenta day ago[zh-cn]: update the translation of HTML `<abbr>` elementmdn/translated-contenta day ago[zh-cn] sync translated contentmdn/translated-contenta day ago[zh-cn] Fix the unrecognizable symbolsmdn/translated-content9 hours ago[ko] web standards 신규 번역mdn/translated-content8 hours agoauthor manifest key cross-browser clarificationsmdn/content7 hours agoBug-1657575 webRequest.handlerBehaviorChanged implementation release notemdn/content7 hours agoClarify the type description in pseudo-classmdn/content6 hours agoSmall fixes on "Grid layout using line-based placement" pagemdn/content6 hours agoElementInternals.aria* examplesmdn/content2 hours agoContributor SpotlightYash Raj BhartiMDN resonates with my passion to build a consistent and open web, where developers can learn and grow.Get involved →\n\nResources for Developers, by DevelopersDocumenting web technologies, including CSS, HTML, and JavaScript, since 2005.Search MDNClear search inputSearchFeatured articlesBlogJavaScript Temporal is comingA new way to handle dates and times is being added to JavaScript. Let's take a look at Temporal, what problems it solves, the current state, and what you'll find in the new documentation about it on MDN.
CSSCSS anchor positioningThe CSS anchor positioning module defines features that allow you to tether elements together. Certain elements are defined as anchor elements; anchor-positioned elements can then have their size and position set based on the size and location of the anchor elements to which they are bound.
Web APIsUsing the View Transition APIThis article explains the theory behind how the View Transition API works, how to create view transitions and customize the transition animations, and how to manipulate active view transitions. This covers view transitions for both DOM state updates in a single-page app (SPA), and navigating between documents in a multi-page app (MPA).
JavaScriptTemporalThe Temporal object enables date and time management in various scenarios, including built-in time zone and calendar representation, wall-clock time conversions, arithmetics, formatting, and more. It is designed as a full replacement for the Date object.
Latest newsMDN 2024 content projectsdeveloper.mozilla.org4 months agoA new learning experience on MDNdeveloper.mozilla.org4 months agoIntroducing the new MDN Community pagedeveloper.mozilla.org6 months agoRecent contributions[zh-cn]: update the translation of Location `host` propertymdn/translated-contenta day ago[zh-cn]: update the translation of HTML `<abbr>` elementmdn/translated-contenta day ago[zh-cn] sync translated contentmdn/translated-contenta day ago[zh-cn] Fix the unrecognizable symbolsmdn/translated-content9 hours ago[ko] web standards 신규 번역mdn/translated-content8 hours agoauthor manifest key cross-browser clarificationsmdn/content7 hours agoBug-1657575 webRequest.handlerBehaviorChanged implementation release notemdn/content7 hours agoClarify the type description in pseudo-classmdn/content6 hours agoSmall fixes on "Grid layout using line-based placement" pagemdn/content6 hours agoElementInternals.aria* examplesmdn/content2 hours agoContributor SpotlightYash Raj BhartiMDN resonates with my passion to build a consistent and open web, where developers can learn and grow.Get involved →\n\n\n\nWeb technology for developersThe open Web presents incredible opportunities for developers. To take full advantage of these technologies, you need to know how to use them. Below you'll find links to our Web technology documentation.Documentation for Web developers
Web developer guides

The Web Developer Guides provide practical, how-to content to help you use Web technologies for your goals or needs.

Tutorials for Web developers

Tutorials to take you step-by-step through learning HTML, CSS, JavaScript, and Web APIs.

Accessibility

Enabling as many people as possible to use websites, even when those people's abilities are limited in some way.

Performance

Making content as available and interactive as possible, as soon as possible.

Privacy

Protecting users' personal data.

Security

Protecting users from data leaks and data theft, side-channel attacks, and attacks such as cross-site scripting, content injection, and click-jacking.

Glossary

Definitions of Web-related terms.

Web technology references
Web APIs

JavaScript programming APIs you can use to build apps on the Web.

HTML

HTML provides the fundamental building blocks for structuring Web documents and apps.

CSS

Cascading Style Sheets are used to describe the appearance of Web documents and apps.

JavaScript

JavaScript is the Web's native programming language.

WebAssembly

WebAssembly allows programs written in C, C++, Rust, Swift, C#, Go, and more to run on the Web.

Events

Events are what you build Web apps to react to; for example, when a Web page finishes loading, or a user selects something, presses a key, resizes a window, submits a form, or pauses a video.

HTTP

HTTP is the fundamental Internet protocol for fetching documents, stylesheets, scripts, images, videos, fonts, and other resources over the Web — and for sending data back to Web servers.

Media

Formats, codecs, protocols, APIs, and techniques for embedding and streaming video, audio, and image content in Web documents and apps.

SVG

Scalable Vector Graphics lets you create images that scale smoothly to any size.

MathML

MathML lets you display complex mathematical notation on the Web.

URI

Uniform Resource Identifiers are used by various technologies, including the browser itself via the address bar, to identify resources in various ways.

WebDriver

WebDriver is a browser-automation mechanism for remotely controlling a browser by emulating the actions of a real person using the browser. It's widely used for cross-browser testing of Web apps.

Web Extensions

Web Extensions are a way for you to give users enhanced capabilities in their browsers — for doing things such as blocking ads and other content, customizing the appearance of pages, and more.

Web App Manifests

Web App Manifests let you enable users to install Web apps to their device home screens, with aspects such as portrait/landscape screen orientation and display mode (e.g., full screen) pre-set.

Progressive Web Apps (PWAs)

Progressive Web Apps provide a user experience similar to native mobile apps.

OpenSearch

OpenSearch allows a website to describe a search engine for itself, so that a browser or other client application can use that search engine.

XML

The Extensible Markup Language is a strict serialization of the Document Object Model.

XSLT

Extensible Stylesheet Language Transformations is an XML-based language used, in conjunction with specialized processing software, for the transformation of XML documents.

XPath

XPath uses a non-XML syntax to provide a flexible way of addressing (pointing to) different parts of an XML document. It can also be used to test addressed nodes within a document to determine whether they match a pattern or not.

EXSLT

EXSLT a set of extensions to XSLT.

Developer tools documentation
Firefox Developer Tools

Documentation for the set of web-developer tools built into Firefox.

Chrome DevTools

Documentation for the set of web-developer tools built into Chrome.

Safari Web Inspector

Documentation for the set of web-developer tools built into Safari.

Edge DevTools

Documentation for the set of web-developer tools built into Edge.\n\nWeb technology for developersThe open Web presents incredible opportunities for developers. To take full advantage of these technologies, you need to know how to use them. Below you'll find links to our Web technology documentation.Documentation for Web developers
Web developer guides

The Web Developer Guides provide practical, how-to content to help you use Web technologies for your goals or needs.

Tutorials for Web developers

Tutorials to take you step-by-step through learning HTML, CSS, JavaScript, and Web APIs.

Accessibility

Enabling as many people as possible to use websites, even when those people's abilities are limited in some way.

Performance

Making content as available and interactive as possible, as soon as possible.

Privacy

Protecting users' personal data.

Security

Protecting users from data leaks and data theft, side-channel attacks, and attacks such as cross-site scripting, content injection, and click-jacking.

Glossary

Definitions of Web-related terms.

Web technology references
Web APIs

JavaScript programming APIs you can use to build apps on the Web.

HTML

HTML provides the fundamental building blocks for structuring Web documents and apps.

CSS

Cascading Style Sheets are used to describe the appearance of Web documents and apps.

JavaScript

JavaScript is the Web's native programming language.

WebAssembly

WebAssembly allows programs written in C, C++, Rust, Swift, C#, Go, and more to run on the Web.

Events

Events are what you build Web apps to react to; for example, when a Web page finishes loading, or a user selects something, presses a key, resizes a window, submits a form, or pauses a video.

HTTP

HTTP is the fundamental Internet protocol for fetching documents, stylesheets, scripts, images, videos, fonts, and other resources over the Web — and for sending data back to Web servers.

Media

Formats, codecs, protocols, APIs, and techniques for embedding and streaming video, audio, and image content in Web documents and apps.

SVG

Scalable Vector Graphics lets you create images that scale smoothly to any size.

MathML

MathML lets you display complex mathematical notation on the Web.

URI

Uniform Resource Identifiers are used by various technologies, including the browser itself via the address bar, to identify resources in various ways.

WebDriver

WebDriver is a browser-automation mechanism for remotely controlling a browser by emulating the actions of a real person using the browser. It's widely used for cross-browser testing of Web apps.

Web Extensions

Web Extensions are a way for you to give users enhanced capabilities in their browsers — for doing things such as blocking ads and other content, customizing the appearance of pages, and more.

Web App Manifests

Web App Manifests let you enable users to install Web apps to their device home screens, with aspects such as portrait/landscape screen orientation and display mode (e.g., full screen) pre-set.

Progressive Web Apps (PWAs)

Progressive Web Apps provide a user experience similar to native mobile apps.

OpenSearch

OpenSearch allows a website to describe a search engine for itself, so that a browser or other client application can use that search engine.

XML

The Extensible Markup Language is a strict serialization of the Document Object Model.

XSLT

Extensible Stylesheet Language Transformations is an XML-based language used, in conjunction with specialized processing software, for the transformation of XML documents.

XPath

XPath uses a non-XML syntax to provide a flexible way of addressing (pointing to) different parts of an XML document. It can also be used to test addressed nodes within a document to determine whether they match a pattern or not.

EXSLT

EXSLT a set of extensions to XSLT.

Developer tools documentation
Firefox Developer Tools

Documentation for the set of web-developer tools built into Firefox.

Chrome DevTools

Documentation for the set of web-developer tools built into Chrome.

Safari Web Inspector

Documentation for the set of web-developer tools built into Safari.

Edge DevTools

Documentation for the set of web-developer tools built into Edge.

Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Feb 21, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nWeb technology for developersThe open Web presents incredible opportunities for developers. To take full advantage of these technologies, you need to know how to use them. Below you'll find links to our Web technology documentation.Documentation for Web developers
Web developer guides

The Web Developer Guides provide practical, how-to content to help you use Web technologies for your goals or needs.

Tutorials for Web developers

Tutorials to take you step-by-step through learning HTML, CSS, JavaScript, and Web APIs.

Accessibility

Enabling as many people as possible to use websites, even when those people's abilities are limited in some way.

Performance

Making content as available and interactive as possible, as soon as possible.

Privacy

Protecting users' personal data.

Security

Protecting users from data leaks and data theft, side-channel attacks, and attacks such as cross-site scripting, content injection, and click-jacking.

Glossary

Definitions of Web-related terms.

Web technology references
Web APIs

JavaScript programming APIs you can use to build apps on the Web.

HTML

HTML provides the fundamental building blocks for structuring Web documents and apps.

CSS

Cascading Style Sheets are used to describe the appearance of Web documents and apps.

JavaScript

JavaScript is the Web's native programming language.

WebAssembly

WebAssembly allows programs written in C, C++, Rust, Swift, C#, Go, and more to run on the Web.

Events

Events are what you build Web apps to react to; for example, when a Web page finishes loading, or a user selects something, presses a key, resizes a window, submits a form, or pauses a video.

HTTP

HTTP is the fundamental Internet protocol for fetching documents, stylesheets, scripts, images, videos, fonts, and other resources over the Web — and for sending data back to Web servers.

Media

Formats, codecs, protocols, APIs, and techniques for embedding and streaming video, audio, and image content in Web documents and apps.

SVG

Scalable Vector Graphics lets you create images that scale smoothly to any size.

MathML

MathML lets you display complex mathematical notation on the Web.

URI

Uniform Resource Identifiers are used by various technologies, including the browser itself via the address bar, to identify resources in various ways.

WebDriver

WebDriver is a browser-automation mechanism for remotely controlling a browser by emulating the actions of a real person using the browser. It's widely used for cross-browser testing of Web apps.

Web Extensions

Web Extensions are a way for you to give users enhanced capabilities in their browsers — for doing things such as blocking ads and other content, customizing the appearance of pages, and more.

Web App Manifests

Web App Manifests let you enable users to install Web apps to their device home screens, with aspects such as portrait/landscape screen orientation and display mode (e.g., full screen) pre-set.

Progressive Web Apps (PWAs)

Progressive Web Apps provide a user experience similar to native mobile apps.

OpenSearch

OpenSearch allows a website to describe a search engine for itself, so that a browser or other client application can use that search engine.

XML

The Extensible Markup Language is a strict serialization of the Document Object Model.

XSLT

Extensible Stylesheet Language Transformations is an XML-based language used, in conjunction with specialized processing software, for the transformation of XML documents.

XPath

XPath uses a non-XML syntax to provide a flexible way of addressing (pointing to) different parts of an XML document. It can also be used to test addressed nodes within a document to determine whether they match a pattern or not.

EXSLT

EXSLT a set of extensions to XSLT.

Developer tools documentation
Firefox Developer Tools

Documentation for the set of web-developer tools built into Firefox.

Chrome DevTools

Documentation for the set of web-developer tools built into Chrome.

Safari Web Inspector

Documentation for the set of web-developer tools built into Safari.

Edge DevTools

Documentation for the set of web-developer tools built into Edge.

Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Feb 21, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nHTML: HyperText Markup LanguageHTML (HyperText Markup Language) is the most basic building block of the Web. It defines the meaning and structure of web content. Other technologies besides HTML are generally used to describe a web page's appearance/presentation (CSS) or functionality/behavior (JavaScript).
"Hypertext" refers to links that connect web pages to one another, either within a single website or between websites. Links are a fundamental aspect of the Web. By uploading content to the Internet and linking it to pages created by other people, you become an active participant in the World Wide Web.
HTML uses "markup" to annotate text, images, and other content for display in a Web browser. HTML markup includes special "elements" such as <head>, <title>, <body>, <header>, <footer>, <article>, <section>, <p>, <div>, <span>, <img>, <aside>, <audio>, <canvas>, <datalist>, <details>, <embed>, <nav>, <search>, <output>, <progress>, <video>, <ul>, <ol>, <li> and many others.
An HTML element is set off from other text in a document by "tags", which consist of the element name surrounded by < and >. The name of an element inside a tag is case-insensitive. That is, it can be written in uppercase, lowercase, or a mixture. For example, the <title> tag can be written as <Title>, <TITLE>, or in any other way. However, the convention and recommended practice is to write tags in lowercase.
The articles below can help you learn more about HTML.Beginner's tutorials
Your first website: Creating the content

This article provides a brief tour of what HTML is and how to use it, aimed at people who are completely new to web development.

Structuring content with HTML

Our Learn web development section's HTML module teaches all the HTML fundamentals from the ground up.

Guides
HTML forms

Forms are a very important part of the Web — these provide much of the functionality you need for interacting with websites, e.g., registering and logging in, sending feedback, buying products, and more. This module gets you started with creating the client-side/front-end parts of forms.

CORS enabled image

The crossorigin attribute, in combination with an appropriate CORS header, allows images defined by the <img> element to be loaded from foreign origins and used in a <canvas> element as if they were being loaded from the current origin.

CORS settings attributes

Some HTML elements that provide support for CORS, such as <img> or <video>, have a crossorigin attribute (crossOrigin property), which lets you configure the CORS requests for the element's fetched data.

Preloading content with rel="preload"

The preload value of the <link> element's rel attribute allows you to write declarative fetch requests in your HTML <head>, specifying resources that your pages will need very soon after loading, which you therefore want to start preloading early in the lifecycle of a page load, before the browser's main rendering machinery kicks in. This ensures that they are made available earlier and are less likely to block the page's first render, leading to performance improvements. This article provides a basic guide to how preload works.

Responsive images

In this article, we'll learn about the concept of responsive images — images that work well on devices with widely differing screen sizes, resolutions, and other such features — and look at what tools HTML provides to help implement them. This helps to improve performance across different devices.

Reference
HTML reference

HTML consists of elements, each of which may be modified by some number of attributes. HTML documents are connected to each other with links.

HTML element reference

Browse a list of all HTML elements.

HTML attribute reference

Elements in HTML have attributes. These are additional values that configure the elements or adjust their behavior in various ways.

Global attributes

Global attributes may be specified on all HTML elements, even those not specified in the standard. This means that any non-standard elements must still permit these attributes, even though those elements make the document HTML5-noncompliant.

Inline-level elements and block-level elements

HTML elements are usually "inline-level" or "block-level" elements. An inline-level element occupies only the space bounded by the tags that define it. A block-level element occupies the entire space of its parent element (container), thereby creating a "block box".

HTML comments

HTML comments are used to add explanatory notes to the markup or to prevent the browser from interpreting specific parts of the document.

Guide to media types and formats on the web

The <audio> and <video> elements allow you to play audio and video media natively within your content without the need for external software support.

HTML content categories

HTML is comprised of several kinds of content, each of which is allowed to be used in certain contexts and is disallowed in others. Similarly, each context has a set of other content categories it can contain and elements that can or can't be used in them. This is a guide to these categories.

Quirks mode and standards mode

Historical information on quirks mode and standards mode.

Related topics
Applying color to HTML elements using CSS

This article covers most of the ways you use CSS to add color to HTML content, listing what parts of HTML documents can be colored and what CSS properties to use when doing so.\n\nHTML: HyperText Markup LanguageHTML (HyperText Markup Language) is the most basic building block of the Web. It defines the meaning and structure of web content. Other technologies besides HTML are generally used to describe a web page's appearance/presentation (CSS) or functionality/behavior (JavaScript).
"Hypertext" refers to links that connect web pages to one another, either within a single website or between websites. Links are a fundamental aspect of the Web. By uploading content to the Internet and linking it to pages created by other people, you become an active participant in the World Wide Web.
HTML uses "markup" to annotate text, images, and other content for display in a Web browser. HTML markup includes special "elements" such as <head>, <title>, <body>, <header>, <footer>, <article>, <section>, <p>, <div>, <span>, <img>, <aside>, <audio>, <canvas>, <datalist>, <details>, <embed>, <nav>, <search>, <output>, <progress>, <video>, <ul>, <ol>, <li> and many others.
An HTML element is set off from other text in a document by "tags", which consist of the element name surrounded by < and >. The name of an element inside a tag is case-insensitive. That is, it can be written in uppercase, lowercase, or a mixture. For example, the <title> tag can be written as <Title>, <TITLE>, or in any other way. However, the convention and recommended practice is to write tags in lowercase.
The articles below can help you learn more about HTML.Beginner's tutorials
Your first website: Creating the content

This article provides a brief tour of what HTML is and how to use it, aimed at people who are completely new to web development.

Structuring content with HTML

Our Learn web development section's HTML module teaches all the HTML fundamentals from the ground up.

Guides
HTML forms

Forms are a very important part of the Web — these provide much of the functionality you need for interacting with websites, e.g., registering and logging in, sending feedback, buying products, and more. This module gets you started with creating the client-side/front-end parts of forms.

CORS enabled image

The crossorigin attribute, in combination with an appropriate CORS header, allows images defined by the <img> element to be loaded from foreign origins and used in a <canvas> element as if they were being loaded from the current origin.

CORS settings attributes

Some HTML elements that provide support for CORS, such as <img> or <video>, have a crossorigin attribute (crossOrigin property), which lets you configure the CORS requests for the element's fetched data.

Preloading content with rel="preload"

The preload value of the <link> element's rel attribute allows you to write declarative fetch requests in your HTML <head>, specifying resources that your pages will need very soon after loading, which you therefore want to start preloading early in the lifecycle of a page load, before the browser's main rendering machinery kicks in. This ensures that they are made available earlier and are less likely to block the page's first render, leading to performance improvements. This article provides a basic guide to how preload works.

Responsive images

In this article, we'll learn about the concept of responsive images — images that work well on devices with widely differing screen sizes, resolutions, and other such features — and look at what tools HTML provides to help implement them. This helps to improve performance across different devices.

Reference
HTML reference

HTML consists of elements, each of which may be modified by some number of attributes. HTML documents are connected to each other with links.

HTML element reference

Browse a list of all HTML elements.

HTML attribute reference

Elements in HTML have attributes. These are additional values that configure the elements or adjust their behavior in various ways.

Global attributes

Global attributes may be specified on all HTML elements, even those not specified in the standard. This means that any non-standard elements must still permit these attributes, even though those elements make the document HTML5-noncompliant.

Inline-level elements and block-level elements

HTML elements are usually "inline-level" or "block-level" elements. An inline-level element occupies only the space bounded by the tags that define it. A block-level element occupies the entire space of its parent element (container), thereby creating a "block box".

HTML comments

HTML comments are used to add explanatory notes to the markup or to prevent the browser from interpreting specific parts of the document.

Guide to media types and formats on the web

The <audio> and <video> elements allow you to play audio and video media natively within your content without the need for external software support.

HTML content categories

HTML is comprised of several kinds of content, each of which is allowed to be used in certain contexts and is disallowed in others. Similarly, each context has a set of other content categories it can contain and elements that can or can't be used in them. This is a guide to these categories.

Quirks mode and standards mode

Historical information on quirks mode and standards mode.

Related topics
Applying color to HTML elements using CSS

This article covers most of the ways you use CSS to add color to HTML content, listing what parts of HTML documents can be colored and what CSS properties to use when doing so.

Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Apr 10, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nHTML: HyperText Markup LanguageHTML (HyperText Markup Language) is the most basic building block of the Web. It defines the meaning and structure of web content. Other technologies besides HTML are generally used to describe a web page's appearance/presentation (CSS) or functionality/behavior (JavaScript).
"Hypertext" refers to links that connect web pages to one another, either within a single website or between websites. Links are a fundamental aspect of the Web. By uploading content to the Internet and linking it to pages created by other people, you become an active participant in the World Wide Web.
HTML uses "markup" to annotate text, images, and other content for display in a Web browser. HTML markup includes special "elements" such as <head>, <title>, <body>, <header>, <footer>, <article>, <section>, <p>, <div>, <span>, <img>, <aside>, <audio>, <canvas>, <datalist>, <details>, <embed>, <nav>, <search>, <output>, <progress>, <video>, <ul>, <ol>, <li> and many others.
An HTML element is set off from other text in a document by "tags", which consist of the element name surrounded by < and >. The name of an element inside a tag is case-insensitive. That is, it can be written in uppercase, lowercase, or a mixture. For example, the <title> tag can be written as <Title>, <TITLE>, or in any other way. However, the convention and recommended practice is to write tags in lowercase.
The articles below can help you learn more about HTML.Beginner's tutorials
Your first website: Creating the content

This article provides a brief tour of what HTML is and how to use it, aimed at people who are completely new to web development.

Structuring content with HTML

Our Learn web development section's HTML module teaches all the HTML fundamentals from the ground up.

Guides
HTML forms

Forms are a very important part of the Web — these provide much of the functionality you need for interacting with websites, e.g., registering and logging in, sending feedback, buying products, and more. This module gets you started with creating the client-side/front-end parts of forms.

CORS enabled image

The crossorigin attribute, in combination with an appropriate CORS header, allows images defined by the <img> element to be loaded from foreign origins and used in a <canvas> element as if they were being loaded from the current origin.

CORS settings attributes

Some HTML elements that provide support for CORS, such as <img> or <video>, have a crossorigin attribute (crossOrigin property), which lets you configure the CORS requests for the element's fetched data.

Preloading content with rel="preload"

The preload value of the <link> element's rel attribute allows you to write declarative fetch requests in your HTML <head>, specifying resources that your pages will need very soon after loading, which you therefore want to start preloading early in the lifecycle of a page load, before the browser's main rendering machinery kicks in. This ensures that they are made available earlier and are less likely to block the page's first render, leading to performance improvements. This article provides a basic guide to how preload works.

Responsive images

In this article, we'll learn about the concept of responsive images — images that work well on devices with widely differing screen sizes, resolutions, and other such features — and look at what tools HTML provides to help implement them. This helps to improve performance across different devices.

Reference
HTML reference

HTML consists of elements, each of which may be modified by some number of attributes. HTML documents are connected to each other with links.

HTML element reference

Browse a list of all HTML elements.

HTML attribute reference

Elements in HTML have attributes. These are additional values that configure the elements or adjust their behavior in various ways.

Global attributes

Global attributes may be specified on all HTML elements, even those not specified in the standard. This means that any non-standard elements must still permit these attributes, even though those elements make the document HTML5-noncompliant.

Inline-level elements and block-level elements

HTML elements are usually "inline-level" or "block-level" elements. An inline-level element occupies only the space bounded by the tags that define it. A block-level element occupies the entire space of its parent element (container), thereby creating a "block box".

HTML comments

HTML comments are used to add explanatory notes to the markup or to prevent the browser from interpreting specific parts of the document.

Guide to media types and formats on the web

The <audio> and <video> elements allow you to play audio and video media natively within your content without the need for external software support.

HTML content categories

HTML is comprised of several kinds of content, each of which is allowed to be used in certain contexts and is disallowed in others. Similarly, each context has a set of other content categories it can contain and elements that can or can't be used in them. This is a guide to these categories.

Quirks mode and standards mode

Historical information on quirks mode and standards mode.

Related topics
Applying color to HTML elements using CSS

This article covers most of the ways you use CSS to add color to HTML content, listing what parts of HTML documents can be colored and what CSS properties to use when doing so.

Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Apr 10, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nCSS: Cascading Style SheetsCascading Style Sheets (CSS) is a stylesheet language used to describe the presentation of a document written in HTML or XML (including XML dialects such as SVG, MathML or XHTML). CSS describes how elements should be rendered on screen, on paper, in speech, or on other media.
CSS is among the core languages of the open web and is standardized across Web browsers according to W3C specifications. Previously, the development of various parts of CSS specification was done synchronously, which allowed the versioning of the latest recommendations. You might have heard about CSS1, CSS2.1, or even CSS3. There will never be a CSS3 or a CSS4; rather, everything is now just "CSS" with individual CSS modules having version numbers.
After CSS 2.1, the scope of the specification increased significantly and the progress on different CSS modules started to differ so much, that it became more effective to develop and release recommendations separately per module. Instead of versioning the CSS specification, W3C now periodically takes a snapshot of the latest stable state of the CSS specification and individual modules progress. CSS modules now have version numbers, or levels, such as CSS Color Module Level 5.Beginner's tutorials
Your first website: Styling the content

This article provides a brief tour of what CSS is and how to use it, aimed at people who are completely new to web development.

CSS styling basics

Our Learn web development section's CSS basics module teaches CSS fundamentals from the ground up.

CSS text styling

Here we look at fundamentals including setting font, boldness, italics, line and letter spacing, drop shadows, and other text features. We round off the module by looking at applying custom fonts to your page, and styling lists and links.

CSS layout

Now it's time to look at how to correctly lay out your boxes in relation to one another, and the browser viewport. This module looks at floats, positioning, other modern layout tools, and building responsive designs that will adapt to different devices, screen sizes, and resolutions.

ReferenceThe CSS reference is an exhaustive reference for seasoned Web developers, describing every property and concept of CSS, including:

The syntax and forms of the language
Specificity, inheritance, and the cascade
CSS selectors, including pseudo-elements, nesting, scoping and shadow parts
CSS at-rules, including media and container queries
CSS values and units module, including numeric data types, textual data types and functional notations
Box model and margin collapse
The containing block
Stacking and block-formatting contexts
Initial, computed, used, and actual values
CSS shorthand properties
CSS flexible box, multi-column and grid layout
Animation, transitions, and transforms
CookbookThe CSS layout cookbook aims to bring together recipes for common layout patterns, things you might need to implement in your sites. In addition to providing code you can use as a starting point in your projects, these recipes highlight the different ways layout specifications can be used and the choices you can make as a developer.Tools for CSS development
You can use the W3C CSS Validation Service to check if your CSS is valid. This is an invaluable debugging tool.
Firefox Developer Tools lets you view and edit a page's live CSS via the Inspector and Style Editor tools.
The Web Developer extension for Firefox lets you track and edit live CSS on watched sites.
Meta bugs
Firefox: Firefox bug 1323667
See also
Web languages to which CSS is often applied: HTML, SVG, MathML, XHTML, and XML.
Stack Overflow questions about CSS\n\nCSS: Cascading Style SheetsCascading Style Sheets (CSS) is a stylesheet language used to describe the presentation of a document written in HTML or XML (including XML dialects such as SVG, MathML or XHTML). CSS describes how elements should be rendered on screen, on paper, in speech, or on other media.
CSS is among the core languages of the open web and is standardized across Web browsers according to W3C specifications. Previously, the development of various parts of CSS specification was done synchronously, which allowed the versioning of the latest recommendations. You might have heard about CSS1, CSS2.1, or even CSS3. There will never be a CSS3 or a CSS4; rather, everything is now just "CSS" with individual CSS modules having version numbers.
After CSS 2.1, the scope of the specification increased significantly and the progress on different CSS modules started to differ so much, that it became more effective to develop and release recommendations separately per module. Instead of versioning the CSS specification, W3C now periodically takes a snapshot of the latest stable state of the CSS specification and individual modules progress. CSS modules now have version numbers, or levels, such as CSS Color Module Level 5.Beginner's tutorials
Your first website: Styling the content

This article provides a brief tour of what CSS is and how to use it, aimed at people who are completely new to web development.

CSS styling basics

Our Learn web development section's CSS basics module teaches CSS fundamentals from the ground up.

CSS text styling

Here we look at fundamentals including setting font, boldness, italics, line and letter spacing, drop shadows, and other text features. We round off the module by looking at applying custom fonts to your page, and styling lists and links.

CSS layout

Now it's time to look at how to correctly lay out your boxes in relation to one another, and the browser viewport. This module looks at floats, positioning, other modern layout tools, and building responsive designs that will adapt to different devices, screen sizes, and resolutions.

ReferenceThe CSS reference is an exhaustive reference for seasoned Web developers, describing every property and concept of CSS, including:

The syntax and forms of the language
Specificity, inheritance, and the cascade
CSS selectors, including pseudo-elements, nesting, scoping and shadow parts
CSS at-rules, including media and container queries
CSS values and units module, including numeric data types, textual data types and functional notations
Box model and margin collapse
The containing block
Stacking and block-formatting contexts
Initial, computed, used, and actual values
CSS shorthand properties
CSS flexible box, multi-column and grid layout
Animation, transitions, and transforms
CookbookThe CSS layout cookbook aims to bring together recipes for common layout patterns, things you might need to implement in your sites. In addition to providing code you can use as a starting point in your projects, these recipes highlight the different ways layout specifications can be used and the choices you can make as a developer.Tools for CSS development
You can use the W3C CSS Validation Service to check if your CSS is valid. This is an invaluable debugging tool.
Firefox Developer Tools lets you view and edit a page's live CSS via the Inspector and Style Editor tools.
The Web Developer extension for Firefox lets you track and edit live CSS on watched sites.
Meta bugs
Firefox: Firefox bug 1323667
See also
Web languages to which CSS is often applied: HTML, SVG, MathML, XHTML, and XML.
Stack Overflow questions about CSS
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 22, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nCSS: Cascading Style SheetsCascading Style Sheets (CSS) is a stylesheet language used to describe the presentation of a document written in HTML or XML (including XML dialects such as SVG, MathML or XHTML). CSS describes how elements should be rendered on screen, on paper, in speech, or on other media.
CSS is among the core languages of the open web and is standardized across Web browsers according to W3C specifications. Previously, the development of various parts of CSS specification was done synchronously, which allowed the versioning of the latest recommendations. You might have heard about CSS1, CSS2.1, or even CSS3. There will never be a CSS3 or a CSS4; rather, everything is now just "CSS" with individual CSS modules having version numbers.
After CSS 2.1, the scope of the specification increased significantly and the progress on different CSS modules started to differ so much, that it became more effective to develop and release recommendations separately per module. Instead of versioning the CSS specification, W3C now periodically takes a snapshot of the latest stable state of the CSS specification and individual modules progress. CSS modules now have version numbers, or levels, such as CSS Color Module Level 5.Beginner's tutorials
Your first website: Styling the content

This article provides a brief tour of what CSS is and how to use it, aimed at people who are completely new to web development.

CSS styling basics

Our Learn web development section's CSS basics module teaches CSS fundamentals from the ground up.

CSS text styling

Here we look at fundamentals including setting font, boldness, italics, line and letter spacing, drop shadows, and other text features. We round off the module by looking at applying custom fonts to your page, and styling lists and links.

CSS layout

Now it's time to look at how to correctly lay out your boxes in relation to one another, and the browser viewport. This module looks at floats, positioning, other modern layout tools, and building responsive designs that will adapt to different devices, screen sizes, and resolutions.

ReferenceThe CSS reference is an exhaustive reference for seasoned Web developers, describing every property and concept of CSS, including:

The syntax and forms of the language
Specificity, inheritance, and the cascade
CSS selectors, including pseudo-elements, nesting, scoping and shadow parts
CSS at-rules, including media and container queries
CSS values and units module, including numeric data types, textual data types and functional notations
Box model and margin collapse
The containing block
Stacking and block-formatting contexts
Initial, computed, used, and actual values
CSS shorthand properties
CSS flexible box, multi-column and grid layout
Animation, transitions, and transforms
CookbookThe CSS layout cookbook aims to bring together recipes for common layout patterns, things you might need to implement in your sites. In addition to providing code you can use as a starting point in your projects, these recipes highlight the different ways layout specifications can be used and the choices you can make as a developer.Tools for CSS development
You can use the W3C CSS Validation Service to check if your CSS is valid. This is an invaluable debugging tool.
Firefox Developer Tools lets you view and edit a page's live CSS via the Inspector and Style Editor tools.
The Web Developer extension for Firefox lets you track and edit live CSS on watched sites.
Meta bugs
Firefox: Firefox bug 1323667
See also
Web languages to which CSS is often applied: HTML, SVG, MathML, XHTML, and XML.
Stack Overflow questions about CSS
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 22, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nJavaScriptJavaScript (JS) is a lightweight interpreted (or just-in-time compiled) programming language with first-class functions. While it is most well-known as the scripting language for Web pages, many non-browser environments also use it, such as Node.js, Apache CouchDB and Adobe Acrobat. JavaScript is a prototype-based, multi-paradigm, single-threaded, dynamic language, supporting object-oriented, imperative, and declarative (e.g., functional programming) styles.
JavaScript's dynamic capabilities include runtime object construction, variable parameter lists, function variables, dynamic script creation (via eval), object introspection (via for...in and Object utilities), and source-code recovery (JavaScript functions store their source text and can be retrieved through toString()).
This section is dedicated to the JavaScript language itself, and not the parts that are specific to Web pages or other host environments. For information about APIs that are specific to Web pages, please see Web APIs and DOM.
The standards for JavaScript are the ECMAScript Language Specification (ECMA-262) and the ECMAScript Internationalization API specification (ECMA-402). As soon as one browser implements a feature, we try to document it. This means that cases where some proposals for new ECMAScript features have already been implemented in browsers, documentation and examples in MDN articles may use some of those new features. Most of the time, this happens between the stages 3 and 4, and is usually before the spec is officially published.
Do not confuse JavaScript with the Java programming language — JavaScript is not "Interpreted Java". Both "Java" and "JavaScript" are trademarks or registered trademarks of Oracle in the U.S. and other countries. However, the two programming languages have very different syntax, semantics, and use.
JavaScript documentation of core language features (pure ECMAScript, for the most part) includes the following:

The JavaScript guide
The JavaScript reference

For more information about JavaScript specifications and related technologies, see JavaScript technologies overview.Beginner's tutorialsLearn how to program in JavaScript from the ground up with our beginner's tutorials.

Your first website: Adding interactivity

This article provides a brief tour of what JavaScript is and how to use it, aimed at people who are completely new to web development.

Dynamic scripting with JavaScript

Our Learn web development section's JavaScript module teaches all the JavaScript fundamentals from the ground up.

JavaScript frameworks and libraries

JavaScript frameworks are an essential part of modern front-end web development, providing developers with tried and tested tools for building scalable, interactive web applications. Many modern companies use frameworks as a standard part of their tooling, so many front-end development jobs now require framework experience. In this set of articles, we aim to give you a comfortable starting point to help you begin learning frameworks.

JavaScript guidesFundamental language guides
JavaScript Guide

A much more detailed guide to the JavaScript language, aimed at those with previous programming experience either in JavaScript or another language.

Intermediate
Advanced JavaScript objects

The object-oriented nature of JavaScript is important to understand if you want to go further with your knowledge of the language and write more efficient code, therefore we've provided this module to help you.

Asynchronous JavaScript

In this module, we take a look at asynchronous JavaScript, why it is important, and how it can be used to effectively handle potential blocking operations, such as fetching resources from a server.

Client-side web APIs

Explores what APIs are, and how to use some of the most common APIs you'll come across often in your development work.

JavaScript language overview

An overview of the basic syntax and semantics of JavaScript for those coming from other programming languages to get up to speed.

JavaScript data structures

Overview of available data structures in JavaScript.

Equality comparisons and sameness

JavaScript provides three different value comparison operations: strict equality using ===, loose equality using ==, and the Object.is() method.

Enumerability and ownership of properties

How different methods that visit a group of object properties one-by-one handle the enumerability and ownership of properties.

Closures

A closure is the combination of a function and the lexical environment within which that function was declared.

Advanced
Inheritance and the prototype chain

Explanation of the widely misunderstood and underestimated prototype-based inheritance.

Memory Management

Memory life cycle and garbage collection in JavaScript.

ReferenceBrowse the complete JavaScript reference documentation.

Standard objects

Get to know standard built-in objects: Array, Boolean, Error, Function, JSON, Math, Number, Object, RegExp, String, Map, Set, WeakMap, WeakSet, and others.

Expressions and operators

Learn more about the behavior of JavaScript's operators instanceof, typeof, new, this, the operator precedence, and more.

Statements and declarations

Learn how do-while, for-in, for-of, try-catch, let, var, const, if-else, switch, and more JavaScript statements and keywords work.

Functions

Learn how to work with JavaScript's functions to develop your applications.

Classes

JavaScript classes are the most appropriate way to do object-oriented programming.\n\nJavaScriptJavaScript (JS) is a lightweight interpreted (or just-in-time compiled) programming language with first-class functions. While it is most well-known as the scripting language for Web pages, many non-browser environments also use it, such as Node.js, Apache CouchDB and Adobe Acrobat. JavaScript is a prototype-based, multi-paradigm, single-threaded, dynamic language, supporting object-oriented, imperative, and declarative (e.g., functional programming) styles.
JavaScript's dynamic capabilities include runtime object construction, variable parameter lists, function variables, dynamic script creation (via eval), object introspection (via for...in and Object utilities), and source-code recovery (JavaScript functions store their source text and can be retrieved through toString()).
This section is dedicated to the JavaScript language itself, and not the parts that are specific to Web pages or other host environments. For information about APIs that are specific to Web pages, please see Web APIs and DOM.
The standards for JavaScript are the ECMAScript Language Specification (ECMA-262) and the ECMAScript Internationalization API specification (ECMA-402). As soon as one browser implements a feature, we try to document it. This means that cases where some proposals for new ECMAScript features have already been implemented in browsers, documentation and examples in MDN articles may use some of those new features. Most of the time, this happens between the stages 3 and 4, and is usually before the spec is officially published.
Do not confuse JavaScript with the Java programming language — JavaScript is not "Interpreted Java". Both "Java" and "JavaScript" are trademarks or registered trademarks of Oracle in the U.S. and other countries. However, the two programming languages have very different syntax, semantics, and use.
JavaScript documentation of core language features (pure ECMAScript, for the most part) includes the following:

The JavaScript guide
The JavaScript reference

For more information about JavaScript specifications and related technologies, see JavaScript technologies overview.Beginner's tutorialsLearn how to program in JavaScript from the ground up with our beginner's tutorials.

Your first website: Adding interactivity

This article provides a brief tour of what JavaScript is and how to use it, aimed at people who are completely new to web development.

Dynamic scripting with JavaScript

Our Learn web development section's JavaScript module teaches all the JavaScript fundamentals from the ground up.

JavaScript frameworks and libraries

JavaScript frameworks are an essential part of modern front-end web development, providing developers with tried and tested tools for building scalable, interactive web applications. Many modern companies use frameworks as a standard part of their tooling, so many front-end development jobs now require framework experience. In this set of articles, we aim to give you a comfortable starting point to help you begin learning frameworks.

JavaScript guidesFundamental language guides
JavaScript Guide

A much more detailed guide to the JavaScript language, aimed at those with previous programming experience either in JavaScript or another language.

Intermediate
Advanced JavaScript objects

The object-oriented nature of JavaScript is important to understand if you want to go further with your knowledge of the language and write more efficient code, therefore we've provided this module to help you.

Asynchronous JavaScript

In this module, we take a look at asynchronous JavaScript, why it is important, and how it can be used to effectively handle potential blocking operations, such as fetching resources from a server.

Client-side web APIs

Explores what APIs are, and how to use some of the most common APIs you'll come across often in your development work.

JavaScript language overview

An overview of the basic syntax and semantics of JavaScript for those coming from other programming languages to get up to speed.

JavaScript data structures

Overview of available data structures in JavaScript.

Equality comparisons and sameness

JavaScript provides three different value comparison operations: strict equality using ===, loose equality using ==, and the Object.is() method.

Enumerability and ownership of properties

How different methods that visit a group of object properties one-by-one handle the enumerability and ownership of properties.

Closures

A closure is the combination of a function and the lexical environment within which that function was declared.

Advanced
Inheritance and the prototype chain

Explanation of the widely misunderstood and underestimated prototype-based inheritance.

Memory Management

Memory life cycle and garbage collection in JavaScript.

ReferenceBrowse the complete JavaScript reference documentation.

Standard objects

Get to know standard built-in objects: Array, Boolean, Error, Function, JSON, Math, Number, Object, RegExp, String, Map, Set, WeakMap, WeakSet, and others.

Expressions and operators

Learn more about the behavior of JavaScript's operators instanceof, typeof, new, this, the operator precedence, and more.

Statements and declarations

Learn how do-while, for-in, for-of, try-catch, let, var, const, if-else, switch, and more JavaScript statements and keywords work.

Functions

Learn how to work with JavaScript's functions to develop your applications.

Classes

JavaScript classes are the most appropriate way to do object-oriented programming.

Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Apr 3, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nJavaScriptJavaScript (JS) is a lightweight interpreted (or just-in-time compiled) programming language with first-class functions. While it is most well-known as the scripting language for Web pages, many non-browser environments also use it, such as Node.js, Apache CouchDB and Adobe Acrobat. JavaScript is a prototype-based, multi-paradigm, single-threaded, dynamic language, supporting object-oriented, imperative, and declarative (e.g., functional programming) styles.
JavaScript's dynamic capabilities include runtime object construction, variable parameter lists, function variables, dynamic script creation (via eval), object introspection (via for...in and Object utilities), and source-code recovery (JavaScript functions store their source text and can be retrieved through toString()).
This section is dedicated to the JavaScript language itself, and not the parts that are specific to Web pages or other host environments. For information about APIs that are specific to Web pages, please see Web APIs and DOM.
The standards for JavaScript are the ECMAScript Language Specification (ECMA-262) and the ECMAScript Internationalization API specification (ECMA-402). As soon as one browser implements a feature, we try to document it. This means that cases where some proposals for new ECMAScript features have already been implemented in browsers, documentation and examples in MDN articles may use some of those new features. Most of the time, this happens between the stages 3 and 4, and is usually before the spec is officially published.
Do not confuse JavaScript with the Java programming language — JavaScript is not "Interpreted Java". Both "Java" and "JavaScript" are trademarks or registered trademarks of Oracle in the U.S. and other countries. However, the two programming languages have very different syntax, semantics, and use.
JavaScript documentation of core language features (pure ECMAScript, for the most part) includes the following:

The JavaScript guide
The JavaScript reference

For more information about JavaScript specifications and related technologies, see JavaScript technologies overview.Beginner's tutorialsLearn how to program in JavaScript from the ground up with our beginner's tutorials.

Your first website: Adding interactivity

This article provides a brief tour of what JavaScript is and how to use it, aimed at people who are completely new to web development.

Dynamic scripting with JavaScript

Our Learn web development section's JavaScript module teaches all the JavaScript fundamentals from the ground up.

JavaScript frameworks and libraries

JavaScript frameworks are an essential part of modern front-end web development, providing developers with tried and tested tools for building scalable, interactive web applications. Many modern companies use frameworks as a standard part of their tooling, so many front-end development jobs now require framework experience. In this set of articles, we aim to give you a comfortable starting point to help you begin learning frameworks.

JavaScript guidesFundamental language guides
JavaScript Guide

A much more detailed guide to the JavaScript language, aimed at those with previous programming experience either in JavaScript or another language.

Intermediate
Advanced JavaScript objects

The object-oriented nature of JavaScript is important to understand if you want to go further with your knowledge of the language and write more efficient code, therefore we've provided this module to help you.

Asynchronous JavaScript

In this module, we take a look at asynchronous JavaScript, why it is important, and how it can be used to effectively handle potential blocking operations, such as fetching resources from a server.

Client-side web APIs

Explores what APIs are, and how to use some of the most common APIs you'll come across often in your development work.

JavaScript language overview

An overview of the basic syntax and semantics of JavaScript for those coming from other programming languages to get up to speed.

JavaScript data structures

Overview of available data structures in JavaScript.

Equality comparisons and sameness

JavaScript provides three different value comparison operations: strict equality using ===, loose equality using ==, and the Object.is() method.

Enumerability and ownership of properties

How different methods that visit a group of object properties one-by-one handle the enumerability and ownership of properties.

Closures

A closure is the combination of a function and the lexical environment within which that function was declared.

Advanced
Inheritance and the prototype chain

Explanation of the widely misunderstood and underestimated prototype-based inheritance.

Memory Management

Memory life cycle and garbage collection in JavaScript.

ReferenceBrowse the complete JavaScript reference documentation.

Standard objects

Get to know standard built-in objects: Array, Boolean, Error, Function, JSON, Math, Number, Object, RegExp, String, Map, Set, WeakMap, WeakSet, and others.

Expressions and operators

Learn more about the behavior of JavaScript's operators instanceof, typeof, new, this, the operator precedence, and more.

Statements and declarations

Learn how do-while, for-in, for-of, try-catch, let, var, const, if-else, switch, and more JavaScript statements and keywords work.

Functions

Learn how to work with JavaScript's functions to develop your applications.

Classes

JavaScript classes are the most appropriate way to do object-oriented programming.

Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Apr 3, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nHTTPHypertext Transfer Protocol (HTTP) is an application-layer protocol for transmitting hypermedia documents, such as HTML.
It was designed for communication between web browsers and web servers, but it can also be used for other purposes, such as machine-to-machine communication, programmatic access to APIs, and more.
HTTP follows a classical client-server model, with a client opening a connection to make a request, then waiting until it receives a response from the server.
HTTP is a stateless protocol, meaning that the server does not keep any session data between two requests, although the later addition of cookies adds state to some client-server interactions.Reference documentationThe HTTP reference documentation contains detailed information about headers, request methods, status responses, and lists relevant specifications and standards documents.

HTTP headers

Message headers are used to send metadata about a resource or a HTTP message, and to describe the behavior of the client or the server.

HTTP request methods

Request methods indicate the purpose of the request and what is expected if the request is successful.
The most common methods are GET and POST for retrieving and sending data to servers, respectively, but there are other methods which serve different purposes.

HTTP response status codes

Response status codes indicate the outcome of a specific HTTP request.
Responses are grouped in five classes: informational, successful, redirections, client errors, and server errors.

HTTP resources and specifications

This page lists relevant resources about HTTP since it was first specified in the early 1990s.


The following subsections are also notable:

CSP directives

The Content-Security-Policy (CSP) response header allows website administrators to specify which resources the user agent is allowed to load for a given page.
This section lists directives that can be used in a CSP header, with individual documentation pages that describe how the directives work and how to use them.

Permissions-Policy directives

The Permissions-Policy response header provides a mechanism to allow or deny the use of browser features in a document or within any <iframe> element in the document.
This section lists directives that can be used in a Permissions-Policy header, with individual documentation pages that describe how the directives work and how to use them.

HTTP guidesHTTP is an extensible protocol that relies on concepts like resources and Uniform Resource Identifiers (URIs), a basic message structure, and client-server communication model.
On top of these concepts, numerous extensions have been developed over the years that add functionality and updated semantics, including additional HTTP methods and headers.
The guides below are listed in order from general overviews to specialized, use-case-driven topics.
Beginners are encouraged to start with the foundational guides before exploring more focused articles.

Overview of HTTP

The basic features of HTTP, what it can do, its intended use in web architecture, and its position in the protocol stack.

Evolution of HTTP

HTTP was created in the early 1990s and has been extended several times.
This article goes through its history and describes HTTP/0.9, HTTP/1.0, HTTP/1.1, through HTTP/2 and HTTP/3, as well as novelties introduced over the years.

A typical HTTP session

Describes the flow of an HTTP session, from establishing a connection, sending a request, to receiving a response.

HTTP messages

HTTP messages transmitted as requests and responses have a defined structure.
This article describes this general structure, its purpose, and the different types of messages.

MIME types

Since HTTP/1.0, different types of content can be transmitted.
This article explains how this is accomplished using the Content-Type header and the MIME standard.
A shortlist of common types used by web developers can be found in Common MIME types.

Compression in HTTP

Browsers and servers compress their messages before sending them over the network to reduce the amount of data that needs to be transmitted, improving transfer speed and bandwidth utilization.

HTTP caching

Caching is a highly important mechanism for delivering fast experiences on the Web and for efficient use of resources.
This article describes different methods of caching and how to use HTTP headers to control them.

HTTP authentication

Authentication is a way to verify the identity of a client when making requests to a server.
It ensures that only authorized users or systems can access certain resources.

Using HTTP cookies

Although HTTP is a stateless protocol, a server can send a Set-Cookie header with the response.
The client then returns the cookie's value with every subsequent request to the server in the form of a Cookie request header.
This adds the ability to store and exchange a small amount of data which effectively adds state to some client-server interactions.

Redirections in HTTP

URL redirection, also known as URL forwarding, is a technique to give more than one URL address to a page, a form, a whole website, or a web application.
HTTP has a special kind of response, called a HTTP redirect, for this operation.

HTTP conditional requests

In conditional requests, the outcome of a request depends on the value of a validator in the request.
This method is used heavily in caching and use cases such as resuming a download, preventing lost updates when modifying a document on the server, and more.

HTTP range requests

A range request asks the server to send a specific part (or parts) of a resource back to a client instead of the full resource.
Range requests are useful for cases when a client knows they need only part of a large file, or for cases where an application allows the user to pause and resume a download.

Content negotiation

HTTP defines a set of message headers, starting with Accept as a way for a browser to announce the format, language, or encoding it prefers.
This article explains how this advertisement happens, how the server is expected to react, and how it chooses the most adequate response to a request.

Connection management in HTTP/1.x

HTTP/1.1 was the first version of HTTP to support persistent connections and pipelining.
This article explains both concepts, including the pros and cons of each.

Protocol upgrade mechanism

HTTP/1.1 provides a mechanism to upgrade an already-established connection to a different protocol using the Upgrade header.
A client can upgrade a connection from HTTP/1.1 to HTTP/2, or an HTTP(S) connection to a WebSocket (ws / wss).

Proxy servers and tunneling

A proxy can be on the user's local computer, or anywhere between the user's computer and a destination server on the Internet.
This page outlines some basics about proxies and introduces a few configuration options.

HTTP Client hints

Client Hints are a set of response headers that a server can use to proactively request information from a client about the device, network, user, and user-agent-specific preferences.
The server can then determine which resources to send, based on the information that the client chooses to provide.

Network Error Logging 
Experimental


Network Error Logging is a mechanism that can be configured via the NEL HTTP response header.
This experimental header allows websites and applications to opt-in to receive reports about failed (or even successful) network fetches from supporting browsers.

Browser detection using the user agent

It's very rarely a good idea to use user agent sniffing to detect a browser, but there are edge cases that require it.
This document will guide you in doing this as correctly as possible when this is necessary, with an emphasis on considerations to make before embarking on this route.

Security and privacy
Permissions Policy

Permissions Policy provides mechanisms for web developers to explicitly declare what functionality can and cannot be used on a website.
You define a set of "policies" that restrict what APIs the site's code can access or modify the browser's default behavior for certain features.

Cross-Origin Resource Sharing (CORS)

Cross-site HTTP requests are requests for resources from a different domain than that of the resource making the request.
Web pages today very commonly load cross-site resources, for example, a page 'Domain A' (http://domaina.example/) requests an image on 'Domain B' (http://domainb.foo/image.jpg) via the img element.
CORS allows web developers to control how their site reacts to cross-site requests.

Content Security Policy (CSP)

CSP allows website administrators to use the Content-Security-Policy response header to control which resources the client is allowed to load for a given page.
The CSP guide describes the overall Content Security Policy mechanism which helps detect and mitigate certain types of attacks, including Cross-Site Scripting (XSS) and data injection attacks.

Cross-Origin Resource Policy (CORP)

CORP lets websites and applications opt in to protection against specific requests from other origins (such as those issued with elements like <script> and <img>), to mitigate speculative side-channel attacks.

Mozilla web security guidelines

A collection of tips to help operational teams with creating secure web applications.

Related resources
URIs

Uniform Resource Identifiers (URIs) are used to describe and locate resources on the web and are an essential component in HTTP requests.

Configuring servers for Ogg media

This guide covers a few server configuration changes that may be necessary for your web server to correctly serve Ogg media files.
This information may also be useful if you encounter other media types your server isn't already configured to recognize.

Tools & resourcesHelpful tools and resources for understanding and debugging HTTP.

Firefox Developer Tools

Network monitor

HTTP Observatory

A project designed to help developers, system administrators, and security professionals configure their sites safely and securely.

RedBot

Tools to check your cache-related headers.

nghttp2

An HTTP/2 client, server and proxy implementation written in C with load test and benchmarking tools and an HPACK encoder and decoder.

curl

A command-line tool for transferring data specified with URL syntax.
Supports HTTP, HTTPS, WS, WSS, among many other protocols.

How Browsers Work (2011)

A very comprehensive article on browser internals and request flow through HTTP protocol.\n\nHTTPHypertext Transfer Protocol (HTTP) is an application-layer protocol for transmitting hypermedia documents, such as HTML.
It was designed for communication between web browsers and web servers, but it can also be used for other purposes, such as machine-to-machine communication, programmatic access to APIs, and more.
HTTP follows a classical client-server model, with a client opening a connection to make a request, then waiting until it receives a response from the server.
HTTP is a stateless protocol, meaning that the server does not keep any session data between two requests, although the later addition of cookies adds state to some client-server interactions.Reference documentationThe HTTP reference documentation contains detailed information about headers, request methods, status responses, and lists relevant specifications and standards documents.

HTTP headers

Message headers are used to send metadata about a resource or a HTTP message, and to describe the behavior of the client or the server.

HTTP request methods

Request methods indicate the purpose of the request and what is expected if the request is successful.
The most common methods are GET and POST for retrieving and sending data to servers, respectively, but there are other methods which serve different purposes.

HTTP response status codes

Response status codes indicate the outcome of a specific HTTP request.
Responses are grouped in five classes: informational, successful, redirections, client errors, and server errors.

HTTP resources and specifications

This page lists relevant resources about HTTP since it was first specified in the early 1990s.


The following subsections are also notable:

CSP directives

The Content-Security-Policy (CSP) response header allows website administrators to specify which resources the user agent is allowed to load for a given page.
This section lists directives that can be used in a CSP header, with individual documentation pages that describe how the directives work and how to use them.

Permissions-Policy directives

The Permissions-Policy response header provides a mechanism to allow or deny the use of browser features in a document or within any <iframe> element in the document.
This section lists directives that can be used in a Permissions-Policy header, with individual documentation pages that describe how the directives work and how to use them.

HTTP guidesHTTP is an extensible protocol that relies on concepts like resources and Uniform Resource Identifiers (URIs), a basic message structure, and client-server communication model.
On top of these concepts, numerous extensions have been developed over the years that add functionality and updated semantics, including additional HTTP methods and headers.
The guides below are listed in order from general overviews to specialized, use-case-driven topics.
Beginners are encouraged to start with the foundational guides before exploring more focused articles.

Overview of HTTP

The basic features of HTTP, what it can do, its intended use in web architecture, and its position in the protocol stack.

Evolution of HTTP

HTTP was created in the early 1990s and has been extended several times.
This article goes through its history and describes HTTP/0.9, HTTP/1.0, HTTP/1.1, through HTTP/2 and HTTP/3, as well as novelties introduced over the years.

A typical HTTP session

Describes the flow of an HTTP session, from establishing a connection, sending a request, to receiving a response.

HTTP messages

HTTP messages transmitted as requests and responses have a defined structure.
This article describes this general structure, its purpose, and the different types of messages.

MIME types

Since HTTP/1.0, different types of content can be transmitted.
This article explains how this is accomplished using the Content-Type header and the MIME standard.
A shortlist of common types used by web developers can be found in Common MIME types.

Compression in HTTP

Browsers and servers compress their messages before sending them over the network to reduce the amount of data that needs to be transmitted, improving transfer speed and bandwidth utilization.

HTTP caching

Caching is a highly important mechanism for delivering fast experiences on the Web and for efficient use of resources.
This article describes different methods of caching and how to use HTTP headers to control them.

HTTP authentication

Authentication is a way to verify the identity of a client when making requests to a server.
It ensures that only authorized users or systems can access certain resources.

Using HTTP cookies

Although HTTP is a stateless protocol, a server can send a Set-Cookie header with the response.
The client then returns the cookie's value with every subsequent request to the server in the form of a Cookie request header.
This adds the ability to store and exchange a small amount of data which effectively adds state to some client-server interactions.

Redirections in HTTP

URL redirection, also known as URL forwarding, is a technique to give more than one URL address to a page, a form, a whole website, or a web application.
HTTP has a special kind of response, called a HTTP redirect, for this operation.

HTTP conditional requests

In conditional requests, the outcome of a request depends on the value of a validator in the request.
This method is used heavily in caching and use cases such as resuming a download, preventing lost updates when modifying a document on the server, and more.

HTTP range requests

A range request asks the server to send a specific part (or parts) of a resource back to a client instead of the full resource.
Range requests are useful for cases when a client knows they need only part of a large file, or for cases where an application allows the user to pause and resume a download.

Content negotiation

HTTP defines a set of message headers, starting with Accept as a way for a browser to announce the format, language, or encoding it prefers.
This article explains how this advertisement happens, how the server is expected to react, and how it chooses the most adequate response to a request.

Connection management in HTTP/1.x

HTTP/1.1 was the first version of HTTP to support persistent connections and pipelining.
This article explains both concepts, including the pros and cons of each.

Protocol upgrade mechanism

HTTP/1.1 provides a mechanism to upgrade an already-established connection to a different protocol using the Upgrade header.
A client can upgrade a connection from HTTP/1.1 to HTTP/2, or an HTTP(S) connection to a WebSocket (ws / wss).

Proxy servers and tunneling

A proxy can be on the user's local computer, or anywhere between the user's computer and a destination server on the Internet.
This page outlines some basics about proxies and introduces a few configuration options.

HTTP Client hints

Client Hints are a set of response headers that a server can use to proactively request information from a client about the device, network, user, and user-agent-specific preferences.
The server can then determine which resources to send, based on the information that the client chooses to provide.

Network Error Logging 
Experimental


Network Error Logging is a mechanism that can be configured via the NEL HTTP response header.
This experimental header allows websites and applications to opt-in to receive reports about failed (or even successful) network fetches from supporting browsers.

Browser detection using the user agent

It's very rarely a good idea to use user agent sniffing to detect a browser, but there are edge cases that require it.
This document will guide you in doing this as correctly as possible when this is necessary, with an emphasis on considerations to make before embarking on this route.

Security and privacy
Permissions Policy

Permissions Policy provides mechanisms for web developers to explicitly declare what functionality can and cannot be used on a website.
You define a set of "policies" that restrict what APIs the site's code can access or modify the browser's default behavior for certain features.

Cross-Origin Resource Sharing (CORS)

Cross-site HTTP requests are requests for resources from a different domain than that of the resource making the request.
Web pages today very commonly load cross-site resources, for example, a page 'Domain A' (http://domaina.example/) requests an image on 'Domain B' (http://domainb.foo/image.jpg) via the img element.
CORS allows web developers to control how their site reacts to cross-site requests.

Content Security Policy (CSP)

CSP allows website administrators to use the Content-Security-Policy response header to control which resources the client is allowed to load for a given page.
The CSP guide describes the overall Content Security Policy mechanism which helps detect and mitigate certain types of attacks, including Cross-Site Scripting (XSS) and data injection attacks.

Cross-Origin Resource Policy (CORP)

CORP lets websites and applications opt in to protection against specific requests from other origins (such as those issued with elements like <script> and <img>), to mitigate speculative side-channel attacks.

Mozilla web security guidelines

A collection of tips to help operational teams with creating secure web applications.

Related resources
URIs

Uniform Resource Identifiers (URIs) are used to describe and locate resources on the web and are an essential component in HTTP requests.

Configuring servers for Ogg media

This guide covers a few server configuration changes that may be necessary for your web server to correctly serve Ogg media files.
This information may also be useful if you encounter other media types your server isn't already configured to recognize.

Tools & resourcesHelpful tools and resources for understanding and debugging HTTP.

Firefox Developer Tools

Network monitor

HTTP Observatory

A project designed to help developers, system administrators, and security professionals configure their sites safely and securely.

RedBot

Tools to check your cache-related headers.

nghttp2

An HTTP/2 client, server and proxy implementation written in C with load test and benchmarking tools and an HPACK encoder and decoder.

curl

A command-line tool for transferring data specified with URL syntax.
Supports HTTP, HTTPS, WS, WSS, among many other protocols.

How Browsers Work (2011)

A very comprehensive article on browser internals and request flow through HTTP protocol.

Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 14, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nHTTPHypertext Transfer Protocol (HTTP) is an application-layer protocol for transmitting hypermedia documents, such as HTML.
It was designed for communication between web browsers and web servers, but it can also be used for other purposes, such as machine-to-machine communication, programmatic access to APIs, and more.
HTTP follows a classical client-server model, with a client opening a connection to make a request, then waiting until it receives a response from the server.
HTTP is a stateless protocol, meaning that the server does not keep any session data between two requests, although the later addition of cookies adds state to some client-server interactions.Reference documentationThe HTTP reference documentation contains detailed information about headers, request methods, status responses, and lists relevant specifications and standards documents.

HTTP headers

Message headers are used to send metadata about a resource or a HTTP message, and to describe the behavior of the client or the server.

HTTP request methods

Request methods indicate the purpose of the request and what is expected if the request is successful.
The most common methods are GET and POST for retrieving and sending data to servers, respectively, but there are other methods which serve different purposes.

HTTP response status codes

Response status codes indicate the outcome of a specific HTTP request.
Responses are grouped in five classes: informational, successful, redirections, client errors, and server errors.

HTTP resources and specifications

This page lists relevant resources about HTTP since it was first specified in the early 1990s.


The following subsections are also notable:

CSP directives

The Content-Security-Policy (CSP) response header allows website administrators to specify which resources the user agent is allowed to load for a given page.
This section lists directives that can be used in a CSP header, with individual documentation pages that describe how the directives work and how to use them.

Permissions-Policy directives

The Permissions-Policy response header provides a mechanism to allow or deny the use of browser features in a document or within any <iframe> element in the document.
This section lists directives that can be used in a Permissions-Policy header, with individual documentation pages that describe how the directives work and how to use them.

HTTP guidesHTTP is an extensible protocol that relies on concepts like resources and Uniform Resource Identifiers (URIs), a basic message structure, and client-server communication model.
On top of these concepts, numerous extensions have been developed over the years that add functionality and updated semantics, including additional HTTP methods and headers.
The guides below are listed in order from general overviews to specialized, use-case-driven topics.
Beginners are encouraged to start with the foundational guides before exploring more focused articles.

Overview of HTTP

The basic features of HTTP, what it can do, its intended use in web architecture, and its position in the protocol stack.

Evolution of HTTP

HTTP was created in the early 1990s and has been extended several times.
This article goes through its history and describes HTTP/0.9, HTTP/1.0, HTTP/1.1, through HTTP/2 and HTTP/3, as well as novelties introduced over the years.

A typical HTTP session

Describes the flow of an HTTP session, from establishing a connection, sending a request, to receiving a response.

HTTP messages

HTTP messages transmitted as requests and responses have a defined structure.
This article describes this general structure, its purpose, and the different types of messages.

MIME types

Since HTTP/1.0, different types of content can be transmitted.
This article explains how this is accomplished using the Content-Type header and the MIME standard.
A shortlist of common types used by web developers can be found in Common MIME types.

Compression in HTTP

Browsers and servers compress their messages before sending them over the network to reduce the amount of data that needs to be transmitted, improving transfer speed and bandwidth utilization.

HTTP caching

Caching is a highly important mechanism for delivering fast experiences on the Web and for efficient use of resources.
This article describes different methods of caching and how to use HTTP headers to control them.

HTTP authentication

Authentication is a way to verify the identity of a client when making requests to a server.
It ensures that only authorized users or systems can access certain resources.

Using HTTP cookies

Although HTTP is a stateless protocol, a server can send a Set-Cookie header with the response.
The client then returns the cookie's value with every subsequent request to the server in the form of a Cookie request header.
This adds the ability to store and exchange a small amount of data which effectively adds state to some client-server interactions.

Redirections in HTTP

URL redirection, also known as URL forwarding, is a technique to give more than one URL address to a page, a form, a whole website, or a web application.
HTTP has a special kind of response, called a HTTP redirect, for this operation.

HTTP conditional requests

In conditional requests, the outcome of a request depends on the value of a validator in the request.
This method is used heavily in caching and use cases such as resuming a download, preventing lost updates when modifying a document on the server, and more.

HTTP range requests

A range request asks the server to send a specific part (or parts) of a resource back to a client instead of the full resource.
Range requests are useful for cases when a client knows they need only part of a large file, or for cases where an application allows the user to pause and resume a download.

Content negotiation

HTTP defines a set of message headers, starting with Accept as a way for a browser to announce the format, language, or encoding it prefers.
This article explains how this advertisement happens, how the server is expected to react, and how it chooses the most adequate response to a request.

Connection management in HTTP/1.x

HTTP/1.1 was the first version of HTTP to support persistent connections and pipelining.
This article explains both concepts, including the pros and cons of each.

Protocol upgrade mechanism

HTTP/1.1 provides a mechanism to upgrade an already-established connection to a different protocol using the Upgrade header.
A client can upgrade a connection from HTTP/1.1 to HTTP/2, or an HTTP(S) connection to a WebSocket (ws / wss).

Proxy servers and tunneling

A proxy can be on the user's local computer, or anywhere between the user's computer and a destination server on the Internet.
This page outlines some basics about proxies and introduces a few configuration options.

HTTP Client hints

Client Hints are a set of response headers that a server can use to proactively request information from a client about the device, network, user, and user-agent-specific preferences.
The server can then determine which resources to send, based on the information that the client chooses to provide.

Network Error Logging 
Experimental


Network Error Logging is a mechanism that can be configured via the NEL HTTP response header.
This experimental header allows websites and applications to opt-in to receive reports about failed (or even successful) network fetches from supporting browsers.

Browser detection using the user agent

It's very rarely a good idea to use user agent sniffing to detect a browser, but there are edge cases that require it.
This document will guide you in doing this as correctly as possible when this is necessary, with an emphasis on considerations to make before embarking on this route.

Security and privacy
Permissions Policy

Permissions Policy provides mechanisms for web developers to explicitly declare what functionality can and cannot be used on a website.
You define a set of "policies" that restrict what APIs the site's code can access or modify the browser's default behavior for certain features.

Cross-Origin Resource Sharing (CORS)

Cross-site HTTP requests are requests for resources from a different domain than that of the resource making the request.
Web pages today very commonly load cross-site resources, for example, a page 'Domain A' (http://domaina.example/) requests an image on 'Domain B' (http://domainb.foo/image.jpg) via the img element.
CORS allows web developers to control how their site reacts to cross-site requests.

Content Security Policy (CSP)

CSP allows website administrators to use the Content-Security-Policy response header to control which resources the client is allowed to load for a given page.
The CSP guide describes the overall Content Security Policy mechanism which helps detect and mitigate certain types of attacks, including Cross-Site Scripting (XSS) and data injection attacks.

Cross-Origin Resource Policy (CORP)

CORP lets websites and applications opt in to protection against specific requests from other origins (such as those issued with elements like <script> and <img>), to mitigate speculative side-channel attacks.

Mozilla web security guidelines

A collection of tips to help operational teams with creating secure web applications.

Related resources
URIs

Uniform Resource Identifiers (URIs) are used to describe and locate resources on the web and are an essential component in HTTP requests.

Configuring servers for Ogg media

This guide covers a few server configuration changes that may be necessary for your web server to correctly serve Ogg media files.
This information may also be useful if you encounter other media types your server isn't already configured to recognize.

Tools & resourcesHelpful tools and resources for understanding and debugging HTTP.

Firefox Developer Tools

Network monitor

HTTP Observatory

A project designed to help developers, system administrators, and security professionals configure their sites safely and securely.

RedBot

Tools to check your cache-related headers.

nghttp2

An HTTP/2 client, server and proxy implementation written in C with load test and benchmarking tools and an HPACK encoder and decoder.

curl

A command-line tool for transferring data specified with URL syntax.
Supports HTTP, HTTPS, WS, WSS, among many other protocols.

How Browsers Work (2011)

A very comprehensive article on browser internals and request flow through HTTP protocol.

Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 14, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nWeb APIsWhen writing code for the Web, there are a large number of Web APIs available. Below is a list of all the APIs and interfaces (object types) that you may be able to use while developing your Web app or site.
Web APIs are typically used with JavaScript, although this doesn't always have to be the case.SpecificationsThis is a list of all the APIs that are available.
AAttribution Reporting API
Experimental
Audio Output Devices API
Experimental
BBackground Fetch API
Experimental
Background Synchronization APIBackground Tasks APIBadging APIBarcode Detection API
Experimental
Battery Status APIBeacon APIWeb Bluetooth API
Experimental
Broadcast Channel APICCSS Custom Highlight APICSS Font Loading APICSS Painting API
Experimental
CSS Properties and Values APICSS Typed Object Model APICSS Object Model (CSSOM)Canvas APIChannel Messaging APIClipboard APICompression Streams APICompute Pressure API
Experimental
Console APIContact Picker API
Experimental
Content Index API
Experimental
Cookie Store APICredential Management APIDDocument Object Model (DOM)Device Memory APIDevice orientation eventsDevice Posture API
Experimental
Document Picture-in-Picture API
Experimental
EEditContext API
Experimental
Encoding APIEncrypted Media Extensions APIEyeDropper API
Experimental
FFederated Credential Management (FedCM) API
Experimental
Fenced Frame API
Experimental
Fetch APIFile APIFile System APIFile and Directory Entries APIForce Touch events
Non-standard
Fullscreen APIGGamepad APIGeolocation APIGeometry interfacesHThe HTML DOM APIHTML Drag and Drop APIHistory APIHoudini APIsIIdle Detection API
Experimental
MediaStream Image Capture APIIndexedDB APIInk API
Experimental
InputDeviceCapabilities API
Experimental
Insertable Streams for MediaStreamTrack APIIntersection Observer APIInvoker Commands APIJJS Self-Profiling API
Experimental
KKeyboard API
Experimental
LLaunch Handler API
Experimental
Local Font Access API
Experimental
MMedia Capabilities APIMedia Capture and Streams API (Media Stream)Media Session APIMedia Source API
Experimental
MediaStream Recording APINNavigation API
Experimental
Network Information APIPPage Visibility APIPayment Handler API
Experimental
Payment Request APIPerformance APIsWeb Periodic Background Synchronization API
Experimental
Permissions APIPicture-in-Picture APIPointer eventsPointer Lock APIPopover APIPresentation API
Experimental
Prioritized Task Scheduling APIPush APIRRemote Playback APIReporting APIResize Observer APISSVG APIScreen Capture APIScreen Orientation APIScreen Wake Lock APISelection APISensor APIsServer-sent eventsService Worker APIShared Storage API
Experimental
Speculation Rules API
Experimental
Storage APIStorage Access APIStreams APITTopics API
Experimental

Non-standard
Touch eventsTrusted Types APIUUI EventsURL APIURL Fragment Text DirectivesURL Pattern API
Experimental
User-Agent Client Hints API
Experimental
VVibration APIView Transition APIVirtualKeyboard API
Experimental
Visual Viewport APIWWeb Animations APIWeb Audio APIWeb Authentication APIWeb ComponentsWeb Crypto APIWeb Locks APIWeb MIDI APIWeb NFC API
Experimental
Notifications APIWeb Serial API
Experimental
Web Share APIWeb Speech APIWeb Storage APIWeb Workers APIWebCodecs APIWebGL: 2D and 3D graphics for the webWebGPU API
Experimental
WebHID API
Experimental
WebOTP APIWebRTC APIThe WebSocket API (WebSockets)WebTransport APIWebUSB API
Experimental
WebVR API
Non-standard

Deprecated
WebVTT APIWebXR Device API
Experimental
Window Controls Overlay API
Experimental
Window Management API
Experimental
XXMLHttpRequest APIffetchLater() API
Experimental
InterfacesThis is a list of all the interfaces (that is, types of objects) that are available.
AAbortControllerAbortSignalAbsoluteOrientationSensorAbstractRangeAccelerometer
Experimental
AesCbcParamsAesCtrParamsAesGcmParamsAesKeyGenParamsAmbientLightSensor
Experimental
AnalyserNodeANGLE_instanced_arraysAnimationAnimationEffectAnimationEventAnimationPlaybackEventAnimationTimelineAttrAudioBufferAudioBufferSourceNodeAudioContextAudioDataAudioDecoderAudioDestinationNodeAudioEncoderAudioListenerAudioNodeAudioParamAudioParamDescriptorAudioParamMapAudioProcessingEvent
Deprecated
AudioScheduledSourceNodeAudioSinkInfo
Experimental
AudioTrackAudioTrackListAudioWorkletAudioWorkletGlobalScopeAudioWorkletNodeAudioWorkletProcessorAuthenticatorAssertionResponseAuthenticatorAttestationResponseAuthenticatorResponseBBackgroundFetchEvent
Experimental
BackgroundFetchManager
Experimental
BackgroundFetchRecord
Experimental
BackgroundFetchRegistration
Experimental
BackgroundFetchUpdateUIEvent
Experimental
BarcodeDetector
Experimental
BarPropBaseAudioContextBatteryManagerBeforeInstallPromptEvent
Experimental

Non-standard
BeforeUnloadEventBiquadFilterNodeBlobBlobEventBluetooth
Experimental
BluetoothCharacteristicProperties
Experimental
BluetoothDevice
Experimental
BluetoothRemoteGATTCharacteristic
Experimental
BluetoothRemoteGATTDescriptor
Experimental
BluetoothRemoteGATTServer
Experimental
BluetoothRemoteGATTService
Experimental
BluetoothUUIDBroadcastChannelBrowserCaptureMediaStreamTrack
Experimental
ByteLengthQueuingStrategyCCacheCacheStorageCanMakePaymentEvent
Experimental
CanvasCaptureMediaStreamTrackCanvasGradientCanvasPatternCanvasRenderingContext2DCaptureController
Experimental
CaretPositionCDATASectionChannelMergerNodeChannelSplitterNodeChapterInformation
Experimental
CharacterBoundsUpdateEvent
Experimental
CharacterDataClientClientsClipboardClipboardEventClipboardItemCloseEventCloseWatcher
Experimental
CommandEventCommentCompositionEventCompressionStreamcconsoleCConstantSourceNodeContactAddress
Experimental
ContactsManager
Experimental
ContentIndex
Experimental
ContentIndexEvent
Experimental
ContentVisibilityAutoStateChangeEventConvolverNodeCookieChangeEventCookieStoreCookieStoreManagerCountQueuingStrategyCredentialCredentialsContainerCropTarget
Experimental
CryptoCryptoKeyCryptoKeyPairCSPViolationReportBodyCSSCSSAnimationCSSConditionRuleCSSContainerRuleCSSCounterStyleRuleCSSFontFaceRuleCSSFontFeatureValuesRuleCSSFontPaletteValuesRuleCSSGroupingRuleCSSImageValueCSSImportRuleCSSKeyframeRuleCSSKeyframesRuleCSSKeywordValueCSSLayerBlockRuleCSSLayerStatementRuleCSSMathInvertCSSMathMaxCSSMathMinCSSMathNegateCSSMathProductCSSMathSumCSSMathValueCSSMatrixComponentCSSMediaRuleCSSNamespaceRuleCSSNestedDeclarationsCSSNumericArrayCSSNumericValueCSSPageDescriptors
Experimental
CSSPageRuleCSSPerspectiveCSSPositionTryDescriptors
Experimental
CSSPositionTryRule
Experimental
CSSPositionValue
Non-standard

Deprecated
CSSPrimitiveValue
Deprecated
CSSPropertyRuleCSSPseudoElement
Experimental
CSSRotateCSSRuleCSSRuleListCSSScaleCSSScopeRuleCSSSkewCSSSkewXCSSSkewYCSSStartingStyleRuleCSSStyleDeclarationCSSStyleRuleCSSStyleSheetCSSStyleValueCSSSupportsRuleCSSTransformComponentCSSTransformValueCSSTransitionCSSTranslateCSSUnitValueCSSUnparsedValueCSSValue
Deprecated
CSSValueList
Deprecated
CSSVariableReferenceValueCustomElementRegistryCustomEventCustomStateSetDDataTransferDataTransferItemDataTransferItemListDecompressionStreamDedicatedWorkerGlobalScopeDeferredRequestInit
Experimental
DelayNodeDelegatedInkTrailPresenter
Experimental
DeprecationReportBody
Experimental
DeviceMotionEventDeviceMotionEventAccelerationDeviceMotionEventRotationRateDeviceOrientationEventDevicePosture
Experimental
DirectoryEntrySync
Non-standard

Deprecated
DirectoryReaderSync
Non-standard

Deprecated
DocumentDocumentFragmentDocumentPictureInPicture
Experimental
DocumentPictureInPictureEvent
Experimental
DocumentTimelineDocumentTypeDOMError
Deprecated
DOMExceptionDOMHighResTimeStampDOMImplementationDOMMatrixDOMMatrixReadOnlyDOMParserDOMPointDOMPointReadOnlyDOMQuadDOMRectDOMRectListDOMRectReadOnlyDOMStringListDOMStringMapDOMTokenListDragEventDynamicsCompressorNodeEEcdhKeyDeriveParamsEcdsaParamsEcKeyGenParamsEcKeyImportParamsEditContext
Experimental
ElementElementInternalsEncodedAudioChunkEncodedVideoChunkErrorEventEventEventCountsEventSourceEventTargetExtendableCookieChangeEventExtendableEventExtendableMessageEventEyeDropper
Experimental
FFeaturePolicy
Experimental
FederatedCredential
Experimental
FederatedCredentialInitFence
Experimental
FencedFrameConfig
Experimental
FetchEventFetchLaterResult
Experimental
FileFileEntrySync
Non-standard

Deprecated
FileListFileReaderFileReaderSyncFileSystemFileSystemChangeRecordFileSystemDirectoryEntryFileSystemDirectoryHandleFileSystemDirectoryReaderFileSystemEntryFileSystemFileEntryFileSystemFileHandleFileSystemHandleFileSystemObserver
Experimental

Non-standard
FileSystemSync
Non-standard

Deprecated
FileSystemSyncAccessHandleFileSystemWritableFileStreamFocusEventFontData
Experimental
FontFaceFontFaceSetFontFaceSetLoadEventFormDataFormDataEventFragmentDirectiveGGainNodeGamepadGamepadButtonGamepadEventGamepadHapticActuatorGamepadPose
Experimental
GeolocationGeolocationCoordinatesGeolocationPositionGeolocationPositionErrorGestureEvent
Non-standard
GPU
Experimental
GPUAdapter
Experimental
GPUAdapterInfo
Experimental
GPUBindGroup
Experimental
GPUBindGroupLayout
Experimental
GPUBuffer
Experimental
GPUCanvasContext
Experimental
GPUCommandBuffer
Experimental
GPUCommandEncoder
Experimental
GPUCompilationInfo
Experimental
GPUCompilationMessage
Experimental
GPUComputePassEncoder
Experimental
GPUComputePipeline
Experimental
GPUDevice
Experimental
GPUDeviceLostInfo
Experimental
GPUError
Experimental
GPUExternalTexture
Experimental
GPUInternalError
Experimental
GPUOutOfMemoryError
Experimental
GPUPipelineError
Experimental
GPUPipelineLayout
Experimental
GPUQuerySet
Experimental
GPUQueue
Experimental
GPURenderBundle
Experimental
GPURenderBundleEncoder
Experimental
GPURenderPassEncoder
Experimental
GPURenderPipeline
Experimental
GPUSampler
Experimental
GPUShaderModule
Experimental
GPUSupportedFeatures
Experimental
GPUSupportedLimits
Experimental
GPUTexture
Experimental
GPUTextureView
Experimental
GPUUncapturedErrorEvent
Experimental
GPUValidationError
Experimental
GravitySensorGyroscopeHHashChangeEventHeadersHID
Experimental
HIDConnectionEvent
Experimental
HIDDevice
Experimental
HIDInputReportEvent
Experimental
HighlightHighlightRegistryHistoryHkdfParamsHmacImportParamsHmacKeyGenParamsHMDVRDevice
Non-standard

Deprecated
HTMLAllCollectionHTMLAnchorElementHTMLAreaElementHTMLAudioElementHTMLBaseElementHTMLBodyElementHTMLBRElementHTMLButtonElementHTMLCanvasElementHTMLCollectionHTMLDataElementHTMLDataListElementHTMLDetailsElementHTMLDialogElementHTMLDivElementHTMLDListElementHTMLDocumentHTMLElementHTMLEmbedElementHTMLFencedFrameElement
Experimental
HTMLFieldSetElementHTMLFontElement
Deprecated
HTMLFormControlsCollectionHTMLFormElementHTMLFrameSetElement
Deprecated
HTMLHeadElementHTMLHeadingElementHTMLHRElementHTMLHtmlElementHTMLIFrameElementHTMLImageElementHTMLInputElementHTMLLabelElementHTMLLegendElementHTMLLIElementHTMLLinkElementHTMLMapElementHTMLMarqueeElement
Deprecated
HTMLMediaElementHTMLMenuElementHTMLMetaElementHTMLMeterElementHTMLModElementHTMLObjectElementHTMLOListElementHTMLOptGroupElementHTMLOptionElementHTMLOptionsCollectionHTMLOutputElementHTMLParagraphElementHTMLParamElement
Deprecated
HTMLPictureElementHTMLPreElementHTMLProgressElementHTMLQuoteElementHTMLScriptElementHTMLSelectedContentElementHTMLSelectElementHTMLSlotElementHTMLSourceElementHTMLSpanElementHTMLStyleElementHTMLTableCaptionElementHTMLTableCellElementHTMLTableColElementHTMLTableElementHTMLTableRowElementHTMLTableSectionElementHTMLTemplateElementHTMLTextAreaElementHTMLTimeElementHTMLTitleElementHTMLTrackElementHTMLUListElementHTMLUnknownElementHTMLVideoElementIIDBCursorIDBCursorWithValueIDBDatabaseIDBFactoryIDBIndexIDBKeyRangeIDBObjectStoreIDBOpenDBRequestIDBRequestIDBTransactionIDBVersionChangeEventIdentityCredential
Experimental
IdentityCredentialRequestOptionsIdentityProvider
Experimental
IdleDeadlineIdleDetector
Experimental
IIRFilterNodeImageBitmapImageBitmapRenderingContextImageCaptureImageDataImageDecoderImageTrackImageTrackListInk
Experimental
InputDeviceCapabilities
Experimental
InputDeviceInfoInputEventInstallEventIntersectionObserverIntersectionObserverEntryInterventionReportBody
Experimental
KKeyboard
Experimental
KeyboardEventKeyboardLayoutMap
Experimental
KeyframeEffectLLargestContentfulPaintLaunchParams
Experimental
LaunchQueue
Experimental
LayoutShift
Experimental
LayoutShiftAttribution
Experimental
LinearAccelerationSensorLocationLockLockManagerMMagnetometer
Experimental
MathMLElementMediaCapabilitiesMediaDeviceInfoMediaDevicesMediaElementAudioSourceNodeMediaEncryptedEventMediaErrorMediaKeyMessageEventMediaKeysMediaKeySessionMediaKeyStatusMapMediaKeySystemAccessMediaListMediaMetadataMediaQueryListMediaQueryListEventMediaRecorderMediaRecorderErrorEvent
Non-standard

Deprecated
MediaSessionMediaSourceMediaSourceHandleMediaStreamMediaStreamAudioDestinationNodeMediaStreamAudioSourceNodeMediaStreamEvent
Non-standard

Deprecated
MediaStreamTrackMediaStreamTrackAudioSourceNodeMediaStreamTrackEventMediaStreamTrackGenerator
Experimental

Non-standard
MediaStreamTrackProcessor
Experimental
MediaTrackConstraintsMediaTrackSettingsMediaTrackSupportedConstraintsMerchantValidationEvent
Deprecated
MessageChannelMessageEventMessagePortMetadata
Experimental

Non-standard
MIDIAccessMIDIConnectionEventMIDIInputMIDIInputMapMIDIMessageEventMIDIOutputMIDIOutputMapMIDIPortMimeType
Deprecated
MimeTypeArray
Deprecated
MouseEventMouseScrollEvent
Non-standard

Deprecated
MutationEvent
Non-standard

Deprecated
MutationObserverMutationRecordNNamedNodeMapNavigateEvent
Experimental
Navigation
Experimental
NavigationActivation
Experimental
NavigationCurrentEntryChangeEvent
Experimental
NavigationDestination
Experimental
NavigationHistoryEntry
Experimental
NavigationPreloadManagerNavigationTransition
Experimental
NavigatorNavigatorLoginNavigatorUAData
Experimental
NDEFMessage
Experimental
NDEFReader
Experimental
NDEFReadingEvent
Experimental
NDEFRecord
Experimental
NetworkInformationNodeNodeIteratorNodeListNotificationNotificationEventNotRestoredReasonDetails
Experimental
NotRestoredReasons
Experimental
OOES_draw_buffers_indexedOfflineAudioCompletionEventOfflineAudioContextOffscreenCanvasOffscreenCanvasRenderingContext2DOrientationSensorOscillatorNodeOTPCredential
Experimental
OverconstrainedErrorPPageRevealEventPageSwapEventPageTransitionEventPaintRenderingContext2DPaintSizePaintWorkletGlobalScope
Experimental
PannerNodePasswordCredential
Experimental
PasswordCredentialInitPath2DPaymentAddress
Non-standard

Deprecated
PaymentManager
Experimental
PaymentMethodChangeEventPaymentRequestPaymentRequestEvent
Experimental
PaymentRequestUpdateEventPaymentResponsePbkdf2ParamsPerformancePerformanceElementTiming
Experimental
PerformanceEntryPerformanceEventTimingPerformanceLongAnimationFrameTiming
Experimental
PerformanceLongTaskTiming
Experimental
PerformanceMarkPerformanceMeasurePerformanceNavigation
Deprecated
PerformanceNavigationTimingPerformanceObserverPerformanceObserverEntryListPerformancePaintTimingPerformanceResourceTimingPerformanceScriptTiming
Experimental
PerformanceServerTimingPerformanceTiming
Deprecated
PeriodicSyncEvent
Experimental
PeriodicSyncManager
Experimental
PeriodicWavePermissionsPermissionStatusPictureInPictureEventPictureInPictureWindowPlugin
Deprecated
PluginArray
Deprecated
Point
Non-standard

Deprecated
PointerEventPopStateEventPositionSensorVRDevice
Non-standard

Deprecated
Presentation
Experimental
PresentationAvailability
Experimental
PresentationConnection
Experimental
PresentationConnectionAvailableEvent
Experimental
PresentationConnectionCloseEvent
Experimental
PresentationConnectionList
Experimental
PresentationReceiver
Experimental
PresentationRequest
Experimental
PressureObserver
Experimental
PressureRecord
Experimental
ProcessingInstructionProfiler
Experimental
ProgressEventPromiseRejectionEventPublicKeyCredentialPublicKeyCredentialCreationOptionsPublicKeyCredentialRequestOptionsPushEventPushManagerPushMessageDataPushSubscriptionPushSubscriptionOptionsRRadioNodeListRangeReadableByteStreamControllerReadableStreamReadableStreamBYOBReaderReadableStreamBYOBRequestReadableStreamDefaultControllerReadableStreamDefaultReaderRelativeOrientationSensorRemotePlaybackReportReportBodyReportingObserverRequestRequestInitResizeObserverResizeObserverEntryResizeObserverSizeResponseRestrictionTarget
Experimental
RsaHashedImportParamsRsaHashedKeyGenParamsRsaOaepParamsRsaPssParamsRTCAudioSourceStatsRTCCertificateRTCCertificateStatsRTCCodecStatsRTCDataChannelRTCDataChannelEventRTCDataChannelStatsRTCDtlsTransportRTCDTMFSenderRTCDTMFToneChangeEventRTCEncodedAudioFrameRTCEncodedVideoFrameRTCErrorRTCErrorEventRTCIceCandidateRTCIceCandidatePairRTCIceCandidatePairStatsRTCIceCandidateStatsRTCIceParametersRTCIceTransportRTCIdentityAssertion
Experimental
RTCInboundRtpStreamStatsRTCOutboundRtpStreamStatsRTCPeerConnectionRTCPeerConnectionIceErrorEventRTCPeerConnectionIceEventRTCPeerConnectionStatsRTCRemoteInboundRtpStreamStatsRTCRemoteOutboundRtpStreamStatsRTCRtpReceiverRTCRtpScriptTransformRTCRtpScriptTransformerRTCRtpSenderRTCRtpTransceiverRTCSctpTransportRTCSessionDescriptionRTCStatsReportRTCTrackEventRTCTransformEventRTCTransportStatsRTCVideoSourceStatsSSchedulerScheduling
Experimental
ScreenScreenDetailed
Experimental
ScreenDetails
Experimental
ScreenOrientationScriptProcessorNode
Deprecated
ScrollTimeline
Experimental
SecurePaymentConfirmationRequestSecurityPolicyViolationEventSelectionSensorSensorErrorEventSerial
Experimental
SerialPort
Experimental
ServiceWorkerServiceWorkerContainerServiceWorkerGlobalScopeServiceWorkerRegistrationShadowRootSharedStorage
Experimental
SharedStorageOperation
Experimental
SharedStorageRunOperation
Experimental
SharedStorageSelectURLOperation
Experimental
SharedStorageWorklet
Experimental
SharedStorageWorkletGlobalScope
Experimental
SharedWorkerSharedWorkerGlobalScopeSnapEvent
Experimental
SourceBufferSourceBufferListSpeechGrammar
Non-standard

Deprecated
SpeechGrammarList
Experimental
SpeechRecognitionSpeechRecognitionAlternativeSpeechRecognitionErrorEventSpeechRecognitionEventSpeechRecognitionResultSpeechRecognitionResultListSpeechSynthesisSpeechSynthesisErrorEventSpeechSynthesisEventSpeechSynthesisUtteranceSpeechSynthesisVoiceStaticRangeStereoPannerNodeStorageStorageAccessHandleStorageEventStorageManagerStylePropertyMapStylePropertyMapReadOnlyStyleSheetStyleSheetListSubmitEventSubtleCryptoSVGAElementSVGAngleSVGAnimateColorElement
Deprecated
SVGAnimatedAngleSVGAnimatedBooleanSVGAnimatedEnumerationSVGAnimatedIntegerSVGAnimatedLengthSVGAnimatedLengthListSVGAnimatedNumberSVGAnimatedNumberListSVGAnimatedPreserveAspectRatioSVGAnimatedRectSVGAnimatedStringSVGAnimatedTransformListSVGAnimateElementSVGAnimateMotionElementSVGAnimateTransformElementSVGAnimationElementSVGCircleElementSVGClipPathElementSVGComponentTransferFunctionElementSVGDefsElementSVGDescElementSVGDiscardElement
Experimental
SVGElementSVGEllipseElementSVGFEBlendElementSVGFEColorMatrixElementSVGFEComponentTransferElementSVGFECompositeElementSVGFEConvolveMatrixElementSVGFEDiffuseLightingElementSVGFEDisplacementMapElementSVGFEDistantLightElementSVGFEDropShadowElementSVGFEFloodElementSVGFEFuncAElementSVGFEFuncBElementSVGFEFuncGElementSVGFEFuncRElementSVGFEGaussianBlurElementSVGFEImageElementSVGFEMergeElementSVGFEMergeNodeElementSVGFEMorphologyElementSVGFEOffsetElementSVGFEPointLightElementSVGFESpecularLightingElementSVGFESpotLightElementSVGFETileElementSVGFETurbulenceElementSVGFilterElementSVGForeignObjectElementSVGGElementSVGGeometryElementSVGGradientElementSVGGraphicsElementSVGImageElementSVGLengthSVGLengthListSVGLinearGradientElementSVGLineElementSVGMarkerElementSVGMaskElementSVGMetadataElementSVGMPathElementSVGNumberSVGNumberListSVGPathElementSVGPatternElementSVGPoint
Deprecated
SVGPointListSVGPolygonElementSVGPolylineElementSVGPreserveAspectRatioSVGRadialGradientElementSVGRectSVGRectElementSVGRenderingIntent
Deprecated
SVGScriptElementSVGSetElementSVGStopElementSVGStringListSVGStyleElementSVGSVGElementSVGSwitchElementSVGSymbolElementSVGTextContentElementSVGTextElementSVGTextPathElementSVGTextPositioningElementSVGTitleElementSVGTransformSVGTransformListSVGTSpanElementSVGUnitTypesSVGUseElementSVGViewElementSyncEventSyncManagerTTaskAttributionTiming
Experimental
TaskControllerTaskPriorityChangeEventTaskSignalTextTextDecoderTextDecoderStreamTextEncoderTextEncoderStreamTextEvent
Deprecated
TextFormat
Experimental
TextFormatUpdateEvent
Experimental
TextMetricsTextTrackTextTrackCueTextTrackCueListTextTrackListTextUpdateEvent
Experimental
TimeEventTimeRangesToggleEventTouchTouchEventTouchListTrackEventTransformStreamTransformStreamDefaultControllerTransitionEventTreeWalkerTrustedHTMLTrustedScriptTrustedScriptURLTrustedTypePolicyTrustedTypePolicyFactoryUUIEventURLURLPattern
Experimental
URLSearchParamsUSB
Experimental
USBAlternateInterface
Experimental
USBConfiguration
Experimental
USBConnectionEvent
Experimental
USBDevice
Experimental
USBEndpoint
Experimental
USBInterface
Experimental
USBInTransferResult
Experimental
USBIsochronousInTransferPacket
Experimental
USBIsochronousInTransferResult
Experimental
USBIsochronousOutTransferPacket
Experimental
USBIsochronousOutTransferResult
Experimental
USBOutTransferResult
Experimental
UserActivationVValidityStateVideoColorSpaceVideoDecoderVideoEncoderVideoFrameVideoPlaybackQualityVideoTrackVideoTrackGenerator
Experimental
VideoTrackListViewTimeline
Experimental
ViewTransitionVirtualKeyboard
Experimental
VisibilityStateEntry
Experimental
VisualViewportVRDisplay
Non-standard

Deprecated
VRDisplayCapabilities
Non-standard

Deprecated
VRDisplayEvent
Non-standard

Deprecated
VREyeParameters
Non-standard

Deprecated
VRFieldOfView
Non-standard

Deprecated
VRFrameData
Non-standard

Deprecated
VRLayerInit
Deprecated
VRPose
Non-standard

Deprecated
VRStageParameters
Non-standard

Deprecated
VTTCueVTTRegionWWakeLockWakeLockSentinelWaveShaperNodeWebGL2RenderingContextWebGLActiveInfoWebGLBufferWebGLContextEventWebGLFramebufferWebGLObject
Experimental
WebGLProgramWebGLQueryWebGLRenderbufferWebGLRenderingContextWebGLSamplerWebGLShaderWebGLShaderPrecisionFormatWebGLSyncWebGLTextureWebGLTransformFeedbackWebGLUniformLocationWebGLVertexArrayObjectWebSocketWebSocketStream
Experimental
WebTransportWebTransportBidirectionalStreamWebTransportDatagramDuplexStreamWebTransportErrorWebTransportReceiveStream
Experimental
WebTransportSendStream
Experimental
WGSLLanguageFeatures
Experimental
WheelEventWindowWindowClientWindowControlsOverlay
Experimental
WindowControlsOverlayGeometryChangeEvent
Experimental
WindowSharedStorage
Experimental
WorkerWorkerGlobalScopeWorkerLocationWorkerNavigatorWorkletWorkletGlobalScopeWorkletSharedStorage
Experimental
WritableStreamWritableStreamDefaultControllerWritableStreamDefaultWriterXXMLDocumentXMLHttpRequestXMLHttpRequestEventTargetXMLHttpRequestUploadXMLSerializerXPathEvaluatorXPathExpressionXPathResultXRAnchor
Experimental
XRAnchorSet
Experimental
XRBoundedReferenceSpace
Experimental
XRCompositionLayer
Experimental
XRCPUDepthInformation
Experimental
XRCubeLayer
Experimental
XRCylinderLayer
Experimental
XRDepthInformation
Experimental
XREquirectLayer
Experimental
XRFrame
Experimental
XRHandXRHitTestResult
Experimental
XRHitTestSource
Experimental
XRInputSourceXRInputSourceArray
Experimental
XRInputSourceEventXRInputSourcesChangeEventXRJointPoseXRJointSpaceXRLayer
Experimental
XRLayerEvent
Experimental
XRLightEstimate
Experimental
XRLightProbe
Experimental
XRMediaBinding
Experimental
XRPoseXRProjectionLayer
Experimental
XRQuadLayer
Experimental
XRRay
Experimental
XRReferenceSpaceXRReferenceSpaceEventXRRenderState
Experimental
XRRigidTransformXRSession
Experimental
XRSessionEventXRSpaceXRSubImage
Experimental
XRSystem
Experimental
XRTransientInputHitTestResult
Experimental
XRTransientInputHitTestSource
Experimental
XRView
Experimental
XRViewerPoseXRViewportXRWebGLBinding
Experimental
XRWebGLDepthInformation
Experimental
XRWebGLLayer
Experimental
XRWebGLSubImage
Experimental
XSLTProcessorSee also
Web API event reference\n\nWeb APIsWhen writing code for the Web, there are a large number of Web APIs available. Below is a list of all the APIs and interfaces (object types) that you may be able to use while developing your Web app or site.
Web APIs are typically used with JavaScript, although this doesn't always have to be the case.SpecificationsThis is a list of all the APIs that are available.
AAttribution Reporting API
Experimental
Audio Output Devices API
Experimental
BBackground Fetch API
Experimental
Background Synchronization APIBackground Tasks APIBadging APIBarcode Detection API
Experimental
Battery Status APIBeacon APIWeb Bluetooth API
Experimental
Broadcast Channel APICCSS Custom Highlight APICSS Font Loading APICSS Painting API
Experimental
CSS Properties and Values APICSS Typed Object Model APICSS Object Model (CSSOM)Canvas APIChannel Messaging APIClipboard APICompression Streams APICompute Pressure API
Experimental
Console APIContact Picker API
Experimental
Content Index API
Experimental
Cookie Store APICredential Management APIDDocument Object Model (DOM)Device Memory APIDevice orientation eventsDevice Posture API
Experimental
Document Picture-in-Picture API
Experimental
EEditContext API
Experimental
Encoding APIEncrypted Media Extensions APIEyeDropper API
Experimental
FFederated Credential Management (FedCM) API
Experimental
Fenced Frame API
Experimental
Fetch APIFile APIFile System APIFile and Directory Entries APIForce Touch events
Non-standard
Fullscreen APIGGamepad APIGeolocation APIGeometry interfacesHThe HTML DOM APIHTML Drag and Drop APIHistory APIHoudini APIsIIdle Detection API
Experimental
MediaStream Image Capture APIIndexedDB APIInk API
Experimental
InputDeviceCapabilities API
Experimental
Insertable Streams for MediaStreamTrack APIIntersection Observer APIInvoker Commands APIJJS Self-Profiling API
Experimental
KKeyboard API
Experimental
LLaunch Handler API
Experimental
Local Font Access API
Experimental
MMedia Capabilities APIMedia Capture and Streams API (Media Stream)Media Session APIMedia Source API
Experimental
MediaStream Recording APINNavigation API
Experimental
Network Information APIPPage Visibility APIPayment Handler API
Experimental
Payment Request APIPerformance APIsWeb Periodic Background Synchronization API
Experimental
Permissions APIPicture-in-Picture APIPointer eventsPointer Lock APIPopover APIPresentation API
Experimental
Prioritized Task Scheduling APIPush APIRRemote Playback APIReporting APIResize Observer APISSVG APIScreen Capture APIScreen Orientation APIScreen Wake Lock APISelection APISensor APIsServer-sent eventsService Worker APIShared Storage API
Experimental
Speculation Rules API
Experimental
Storage APIStorage Access APIStreams APITTopics API
Experimental

Non-standard
Touch eventsTrusted Types APIUUI EventsURL APIURL Fragment Text DirectivesURL Pattern API
Experimental
User-Agent Client Hints API
Experimental
VVibration APIView Transition APIVirtualKeyboard API
Experimental
Visual Viewport APIWWeb Animations APIWeb Audio APIWeb Authentication APIWeb ComponentsWeb Crypto APIWeb Locks APIWeb MIDI APIWeb NFC API
Experimental
Notifications APIWeb Serial API
Experimental
Web Share APIWeb Speech APIWeb Storage APIWeb Workers APIWebCodecs APIWebGL: 2D and 3D graphics for the webWebGPU API
Experimental
WebHID API
Experimental
WebOTP APIWebRTC APIThe WebSocket API (WebSockets)WebTransport APIWebUSB API
Experimental
WebVR API
Non-standard

Deprecated
WebVTT APIWebXR Device API
Experimental
Window Controls Overlay API
Experimental
Window Management API
Experimental
XXMLHttpRequest APIffetchLater() API
Experimental
InterfacesThis is a list of all the interfaces (that is, types of objects) that are available.
AAbortControllerAbortSignalAbsoluteOrientationSensorAbstractRangeAccelerometer
Experimental
AesCbcParamsAesCtrParamsAesGcmParamsAesKeyGenParamsAmbientLightSensor
Experimental
AnalyserNodeANGLE_instanced_arraysAnimationAnimationEffectAnimationEventAnimationPlaybackEventAnimationTimelineAttrAudioBufferAudioBufferSourceNodeAudioContextAudioDataAudioDecoderAudioDestinationNodeAudioEncoderAudioListenerAudioNodeAudioParamAudioParamDescriptorAudioParamMapAudioProcessingEvent
Deprecated
AudioScheduledSourceNodeAudioSinkInfo
Experimental
AudioTrackAudioTrackListAudioWorkletAudioWorkletGlobalScopeAudioWorkletNodeAudioWorkletProcessorAuthenticatorAssertionResponseAuthenticatorAttestationResponseAuthenticatorResponseBBackgroundFetchEvent
Experimental
BackgroundFetchManager
Experimental
BackgroundFetchRecord
Experimental
BackgroundFetchRegistration
Experimental
BackgroundFetchUpdateUIEvent
Experimental
BarcodeDetector
Experimental
BarPropBaseAudioContextBatteryManagerBeforeInstallPromptEvent
Experimental

Non-standard
BeforeUnloadEventBiquadFilterNodeBlobBlobEventBluetooth
Experimental
BluetoothCharacteristicProperties
Experimental
BluetoothDevice
Experimental
BluetoothRemoteGATTCharacteristic
Experimental
BluetoothRemoteGATTDescriptor
Experimental
BluetoothRemoteGATTServer
Experimental
BluetoothRemoteGATTService
Experimental
BluetoothUUIDBroadcastChannelBrowserCaptureMediaStreamTrack
Experimental
ByteLengthQueuingStrategyCCacheCacheStorageCanMakePaymentEvent
Experimental
CanvasCaptureMediaStreamTrackCanvasGradientCanvasPatternCanvasRenderingContext2DCaptureController
Experimental
CaretPositionCDATASectionChannelMergerNodeChannelSplitterNodeChapterInformation
Experimental
CharacterBoundsUpdateEvent
Experimental
CharacterDataClientClientsClipboardClipboardEventClipboardItemCloseEventCloseWatcher
Experimental
CommandEventCommentCompositionEventCompressionStreamcconsoleCConstantSourceNodeContactAddress
Experimental
ContactsManager
Experimental
ContentIndex
Experimental
ContentIndexEvent
Experimental
ContentVisibilityAutoStateChangeEventConvolverNodeCookieChangeEventCookieStoreCookieStoreManagerCountQueuingStrategyCredentialCredentialsContainerCropTarget
Experimental
CryptoCryptoKeyCryptoKeyPairCSPViolationReportBodyCSSCSSAnimationCSSConditionRuleCSSContainerRuleCSSCounterStyleRuleCSSFontFaceRuleCSSFontFeatureValuesRuleCSSFontPaletteValuesRuleCSSGroupingRuleCSSImageValueCSSImportRuleCSSKeyframeRuleCSSKeyframesRuleCSSKeywordValueCSSLayerBlockRuleCSSLayerStatementRuleCSSMathInvertCSSMathMaxCSSMathMinCSSMathNegateCSSMathProductCSSMathSumCSSMathValueCSSMatrixComponentCSSMediaRuleCSSNamespaceRuleCSSNestedDeclarationsCSSNumericArrayCSSNumericValueCSSPageDescriptors
Experimental
CSSPageRuleCSSPerspectiveCSSPositionTryDescriptors
Experimental
CSSPositionTryRule
Experimental
CSSPositionValue
Non-standard

Deprecated
CSSPrimitiveValue
Deprecated
CSSPropertyRuleCSSPseudoElement
Experimental
CSSRotateCSSRuleCSSRuleListCSSScaleCSSScopeRuleCSSSkewCSSSkewXCSSSkewYCSSStartingStyleRuleCSSStyleDeclarationCSSStyleRuleCSSStyleSheetCSSStyleValueCSSSupportsRuleCSSTransformComponentCSSTransformValueCSSTransitionCSSTranslateCSSUnitValueCSSUnparsedValueCSSValue
Deprecated
CSSValueList
Deprecated
CSSVariableReferenceValueCustomElementRegistryCustomEventCustomStateSetDDataTransferDataTransferItemDataTransferItemListDecompressionStreamDedicatedWorkerGlobalScopeDeferredRequestInit
Experimental
DelayNodeDelegatedInkTrailPresenter
Experimental
DeprecationReportBody
Experimental
DeviceMotionEventDeviceMotionEventAccelerationDeviceMotionEventRotationRateDeviceOrientationEventDevicePosture
Experimental
DirectoryEntrySync
Non-standard

Deprecated
DirectoryReaderSync
Non-standard

Deprecated
DocumentDocumentFragmentDocumentPictureInPicture
Experimental
DocumentPictureInPictureEvent
Experimental
DocumentTimelineDocumentTypeDOMError
Deprecated
DOMExceptionDOMHighResTimeStampDOMImplementationDOMMatrixDOMMatrixReadOnlyDOMParserDOMPointDOMPointReadOnlyDOMQuadDOMRectDOMRectListDOMRectReadOnlyDOMStringListDOMStringMapDOMTokenListDragEventDynamicsCompressorNodeEEcdhKeyDeriveParamsEcdsaParamsEcKeyGenParamsEcKeyImportParamsEditContext
Experimental
ElementElementInternalsEncodedAudioChunkEncodedVideoChunkErrorEventEventEventCountsEventSourceEventTargetExtendableCookieChangeEventExtendableEventExtendableMessageEventEyeDropper
Experimental
FFeaturePolicy
Experimental
FederatedCredential
Experimental
FederatedCredentialInitFence
Experimental
FencedFrameConfig
Experimental
FetchEventFetchLaterResult
Experimental
FileFileEntrySync
Non-standard

Deprecated
FileListFileReaderFileReaderSyncFileSystemFileSystemChangeRecordFileSystemDirectoryEntryFileSystemDirectoryHandleFileSystemDirectoryReaderFileSystemEntryFileSystemFileEntryFileSystemFileHandleFileSystemHandleFileSystemObserver
Experimental

Non-standard
FileSystemSync
Non-standard

Deprecated
FileSystemSyncAccessHandleFileSystemWritableFileStreamFocusEventFontData
Experimental
FontFaceFontFaceSetFontFaceSetLoadEventFormDataFormDataEventFragmentDirectiveGGainNodeGamepadGamepadButtonGamepadEventGamepadHapticActuatorGamepadPose
Experimental
GeolocationGeolocationCoordinatesGeolocationPositionGeolocationPositionErrorGestureEvent
Non-standard
GPU
Experimental
GPUAdapter
Experimental
GPUAdapterInfo
Experimental
GPUBindGroup
Experimental
GPUBindGroupLayout
Experimental
GPUBuffer
Experimental
GPUCanvasContext
Experimental
GPUCommandBuffer
Experimental
GPUCommandEncoder
Experimental
GPUCompilationInfo
Experimental
GPUCompilationMessage
Experimental
GPUComputePassEncoder
Experimental
GPUComputePipeline
Experimental
GPUDevice
Experimental
GPUDeviceLostInfo
Experimental
GPUError
Experimental
GPUExternalTexture
Experimental
GPUInternalError
Experimental
GPUOutOfMemoryError
Experimental
GPUPipelineError
Experimental
GPUPipelineLayout
Experimental
GPUQuerySet
Experimental
GPUQueue
Experimental
GPURenderBundle
Experimental
GPURenderBundleEncoder
Experimental
GPURenderPassEncoder
Experimental
GPURenderPipeline
Experimental
GPUSampler
Experimental
GPUShaderModule
Experimental
GPUSupportedFeatures
Experimental
GPUSupportedLimits
Experimental
GPUTexture
Experimental
GPUTextureView
Experimental
GPUUncapturedErrorEvent
Experimental
GPUValidationError
Experimental
GravitySensorGyroscopeHHashChangeEventHeadersHID
Experimental
HIDConnectionEvent
Experimental
HIDDevice
Experimental
HIDInputReportEvent
Experimental
HighlightHighlightRegistryHistoryHkdfParamsHmacImportParamsHmacKeyGenParamsHMDVRDevice
Non-standard

Deprecated
HTMLAllCollectionHTMLAnchorElementHTMLAreaElementHTMLAudioElementHTMLBaseElementHTMLBodyElementHTMLBRElementHTMLButtonElementHTMLCanvasElementHTMLCollectionHTMLDataElementHTMLDataListElementHTMLDetailsElementHTMLDialogElementHTMLDivElementHTMLDListElementHTMLDocumentHTMLElementHTMLEmbedElementHTMLFencedFrameElement
Experimental
HTMLFieldSetElementHTMLFontElement
Deprecated
HTMLFormControlsCollectionHTMLFormElementHTMLFrameSetElement
Deprecated
HTMLHeadElementHTMLHeadingElementHTMLHRElementHTMLHtmlElementHTMLIFrameElementHTMLImageElementHTMLInputElementHTMLLabelElementHTMLLegendElementHTMLLIElementHTMLLinkElementHTMLMapElementHTMLMarqueeElement
Deprecated
HTMLMediaElementHTMLMenuElementHTMLMetaElementHTMLMeterElementHTMLModElementHTMLObjectElementHTMLOListElementHTMLOptGroupElementHTMLOptionElementHTMLOptionsCollectionHTMLOutputElementHTMLParagraphElementHTMLParamElement
Deprecated
HTMLPictureElementHTMLPreElementHTMLProgressElementHTMLQuoteElementHTMLScriptElementHTMLSelectedContentElementHTMLSelectElementHTMLSlotElementHTMLSourceElementHTMLSpanElementHTMLStyleElementHTMLTableCaptionElementHTMLTableCellElementHTMLTableColElementHTMLTableElementHTMLTableRowElementHTMLTableSectionElementHTMLTemplateElementHTMLTextAreaElementHTMLTimeElementHTMLTitleElementHTMLTrackElementHTMLUListElementHTMLUnknownElementHTMLVideoElementIIDBCursorIDBCursorWithValueIDBDatabaseIDBFactoryIDBIndexIDBKeyRangeIDBObjectStoreIDBOpenDBRequestIDBRequestIDBTransactionIDBVersionChangeEventIdentityCredential
Experimental
IdentityCredentialRequestOptionsIdentityProvider
Experimental
IdleDeadlineIdleDetector
Experimental
IIRFilterNodeImageBitmapImageBitmapRenderingContextImageCaptureImageDataImageDecoderImageTrackImageTrackListInk
Experimental
InputDeviceCapabilities
Experimental
InputDeviceInfoInputEventInstallEventIntersectionObserverIntersectionObserverEntryInterventionReportBody
Experimental
KKeyboard
Experimental
KeyboardEventKeyboardLayoutMap
Experimental
KeyframeEffectLLargestContentfulPaintLaunchParams
Experimental
LaunchQueue
Experimental
LayoutShift
Experimental
LayoutShiftAttribution
Experimental
LinearAccelerationSensorLocationLockLockManagerMMagnetometer
Experimental
MathMLElementMediaCapabilitiesMediaDeviceInfoMediaDevicesMediaElementAudioSourceNodeMediaEncryptedEventMediaErrorMediaKeyMessageEventMediaKeysMediaKeySessionMediaKeyStatusMapMediaKeySystemAccessMediaListMediaMetadataMediaQueryListMediaQueryListEventMediaRecorderMediaRecorderErrorEvent
Non-standard

Deprecated
MediaSessionMediaSourceMediaSourceHandleMediaStreamMediaStreamAudioDestinationNodeMediaStreamAudioSourceNodeMediaStreamEvent
Non-standard

Deprecated
MediaStreamTrackMediaStreamTrackAudioSourceNodeMediaStreamTrackEventMediaStreamTrackGenerator
Experimental

Non-standard
MediaStreamTrackProcessor
Experimental
MediaTrackConstraintsMediaTrackSettingsMediaTrackSupportedConstraintsMerchantValidationEvent
Deprecated
MessageChannelMessageEventMessagePortMetadata
Experimental

Non-standard
MIDIAccessMIDIConnectionEventMIDIInputMIDIInputMapMIDIMessageEventMIDIOutputMIDIOutputMapMIDIPortMimeType
Deprecated
MimeTypeArray
Deprecated
MouseEventMouseScrollEvent
Non-standard

Deprecated
MutationEvent
Non-standard

Deprecated
MutationObserverMutationRecordNNamedNodeMapNavigateEvent
Experimental
Navigation
Experimental
NavigationActivation
Experimental
NavigationCurrentEntryChangeEvent
Experimental
NavigationDestination
Experimental
NavigationHistoryEntry
Experimental
NavigationPreloadManagerNavigationTransition
Experimental
NavigatorNavigatorLoginNavigatorUAData
Experimental
NDEFMessage
Experimental
NDEFReader
Experimental
NDEFReadingEvent
Experimental
NDEFRecord
Experimental
NetworkInformationNodeNodeIteratorNodeListNotificationNotificationEventNotRestoredReasonDetails
Experimental
NotRestoredReasons
Experimental
OOES_draw_buffers_indexedOfflineAudioCompletionEventOfflineAudioContextOffscreenCanvasOffscreenCanvasRenderingContext2DOrientationSensorOscillatorNodeOTPCredential
Experimental
OverconstrainedErrorPPageRevealEventPageSwapEventPageTransitionEventPaintRenderingContext2DPaintSizePaintWorkletGlobalScope
Experimental
PannerNodePasswordCredential
Experimental
PasswordCredentialInitPath2DPaymentAddress
Non-standard

Deprecated
PaymentManager
Experimental
PaymentMethodChangeEventPaymentRequestPaymentRequestEvent
Experimental
PaymentRequestUpdateEventPaymentResponsePbkdf2ParamsPerformancePerformanceElementTiming
Experimental
PerformanceEntryPerformanceEventTimingPerformanceLongAnimationFrameTiming
Experimental
PerformanceLongTaskTiming
Experimental
PerformanceMarkPerformanceMeasurePerformanceNavigation
Deprecated
PerformanceNavigationTimingPerformanceObserverPerformanceObserverEntryListPerformancePaintTimingPerformanceResourceTimingPerformanceScriptTiming
Experimental
PerformanceServerTimingPerformanceTiming
Deprecated
PeriodicSyncEvent
Experimental
PeriodicSyncManager
Experimental
PeriodicWavePermissionsPermissionStatusPictureInPictureEventPictureInPictureWindowPlugin
Deprecated
PluginArray
Deprecated
Point
Non-standard

Deprecated
PointerEventPopStateEventPositionSensorVRDevice
Non-standard

Deprecated
Presentation
Experimental
PresentationAvailability
Experimental
PresentationConnection
Experimental
PresentationConnectionAvailableEvent
Experimental
PresentationConnectionCloseEvent
Experimental
PresentationConnectionList
Experimental
PresentationReceiver
Experimental
PresentationRequest
Experimental
PressureObserver
Experimental
PressureRecord
Experimental
ProcessingInstructionProfiler
Experimental
ProgressEventPromiseRejectionEventPublicKeyCredentialPublicKeyCredentialCreationOptionsPublicKeyCredentialRequestOptionsPushEventPushManagerPushMessageDataPushSubscriptionPushSubscriptionOptionsRRadioNodeListRangeReadableByteStreamControllerReadableStreamReadableStreamBYOBReaderReadableStreamBYOBRequestReadableStreamDefaultControllerReadableStreamDefaultReaderRelativeOrientationSensorRemotePlaybackReportReportBodyReportingObserverRequestRequestInitResizeObserverResizeObserverEntryResizeObserverSizeResponseRestrictionTarget
Experimental
RsaHashedImportParamsRsaHashedKeyGenParamsRsaOaepParamsRsaPssParamsRTCAudioSourceStatsRTCCertificateRTCCertificateStatsRTCCodecStatsRTCDataChannelRTCDataChannelEventRTCDataChannelStatsRTCDtlsTransportRTCDTMFSenderRTCDTMFToneChangeEventRTCEncodedAudioFrameRTCEncodedVideoFrameRTCErrorRTCErrorEventRTCIceCandidateRTCIceCandidatePairRTCIceCandidatePairStatsRTCIceCandidateStatsRTCIceParametersRTCIceTransportRTCIdentityAssertion
Experimental
RTCInboundRtpStreamStatsRTCOutboundRtpStreamStatsRTCPeerConnectionRTCPeerConnectionIceErrorEventRTCPeerConnectionIceEventRTCPeerConnectionStatsRTCRemoteInboundRtpStreamStatsRTCRemoteOutboundRtpStreamStatsRTCRtpReceiverRTCRtpScriptTransformRTCRtpScriptTransformerRTCRtpSenderRTCRtpTransceiverRTCSctpTransportRTCSessionDescriptionRTCStatsReportRTCTrackEventRTCTransformEventRTCTransportStatsRTCVideoSourceStatsSSchedulerScheduling
Experimental
ScreenScreenDetailed
Experimental
ScreenDetails
Experimental
ScreenOrientationScriptProcessorNode
Deprecated
ScrollTimeline
Experimental
SecurePaymentConfirmationRequestSecurityPolicyViolationEventSelectionSensorSensorErrorEventSerial
Experimental
SerialPort
Experimental
ServiceWorkerServiceWorkerContainerServiceWorkerGlobalScopeServiceWorkerRegistrationShadowRootSharedStorage
Experimental
SharedStorageOperation
Experimental
SharedStorageRunOperation
Experimental
SharedStorageSelectURLOperation
Experimental
SharedStorageWorklet
Experimental
SharedStorageWorkletGlobalScope
Experimental
SharedWorkerSharedWorkerGlobalScopeSnapEvent
Experimental
SourceBufferSourceBufferListSpeechGrammar
Non-standard

Deprecated
SpeechGrammarList
Experimental
SpeechRecognitionSpeechRecognitionAlternativeSpeechRecognitionErrorEventSpeechRecognitionEventSpeechRecognitionResultSpeechRecognitionResultListSpeechSynthesisSpeechSynthesisErrorEventSpeechSynthesisEventSpeechSynthesisUtteranceSpeechSynthesisVoiceStaticRangeStereoPannerNodeStorageStorageAccessHandleStorageEventStorageManagerStylePropertyMapStylePropertyMapReadOnlyStyleSheetStyleSheetListSubmitEventSubtleCryptoSVGAElementSVGAngleSVGAnimateColorElement
Deprecated
SVGAnimatedAngleSVGAnimatedBooleanSVGAnimatedEnumerationSVGAnimatedIntegerSVGAnimatedLengthSVGAnimatedLengthListSVGAnimatedNumberSVGAnimatedNumberListSVGAnimatedPreserveAspectRatioSVGAnimatedRectSVGAnimatedStringSVGAnimatedTransformListSVGAnimateElementSVGAnimateMotionElementSVGAnimateTransformElementSVGAnimationElementSVGCircleElementSVGClipPathElementSVGComponentTransferFunctionElementSVGDefsElementSVGDescElementSVGDiscardElement
Experimental
SVGElementSVGEllipseElementSVGFEBlendElementSVGFEColorMatrixElementSVGFEComponentTransferElementSVGFECompositeElementSVGFEConvolveMatrixElementSVGFEDiffuseLightingElementSVGFEDisplacementMapElementSVGFEDistantLightElementSVGFEDropShadowElementSVGFEFloodElementSVGFEFuncAElementSVGFEFuncBElementSVGFEFuncGElementSVGFEFuncRElementSVGFEGaussianBlurElementSVGFEImageElementSVGFEMergeElementSVGFEMergeNodeElementSVGFEMorphologyElementSVGFEOffsetElementSVGFEPointLightElementSVGFESpecularLightingElementSVGFESpotLightElementSVGFETileElementSVGFETurbulenceElementSVGFilterElementSVGForeignObjectElementSVGGElementSVGGeometryElementSVGGradientElementSVGGraphicsElementSVGImageElementSVGLengthSVGLengthListSVGLinearGradientElementSVGLineElementSVGMarkerElementSVGMaskElementSVGMetadataElementSVGMPathElementSVGNumberSVGNumberListSVGPathElementSVGPatternElementSVGPoint
Deprecated
SVGPointListSVGPolygonElementSVGPolylineElementSVGPreserveAspectRatioSVGRadialGradientElementSVGRectSVGRectElementSVGRenderingIntent
Deprecated
SVGScriptElementSVGSetElementSVGStopElementSVGStringListSVGStyleElementSVGSVGElementSVGSwitchElementSVGSymbolElementSVGTextContentElementSVGTextElementSVGTextPathElementSVGTextPositioningElementSVGTitleElementSVGTransformSVGTransformListSVGTSpanElementSVGUnitTypesSVGUseElementSVGViewElementSyncEventSyncManagerTTaskAttributionTiming
Experimental
TaskControllerTaskPriorityChangeEventTaskSignalTextTextDecoderTextDecoderStreamTextEncoderTextEncoderStreamTextEvent
Deprecated
TextFormat
Experimental
TextFormatUpdateEvent
Experimental
TextMetricsTextTrackTextTrackCueTextTrackCueListTextTrackListTextUpdateEvent
Experimental
TimeEventTimeRangesToggleEventTouchTouchEventTouchListTrackEventTransformStreamTransformStreamDefaultControllerTransitionEventTreeWalkerTrustedHTMLTrustedScriptTrustedScriptURLTrustedTypePolicyTrustedTypePolicyFactoryUUIEventURLURLPattern
Experimental
URLSearchParamsUSB
Experimental
USBAlternateInterface
Experimental
USBConfiguration
Experimental
USBConnectionEvent
Experimental
USBDevice
Experimental
USBEndpoint
Experimental
USBInterface
Experimental
USBInTransferResult
Experimental
USBIsochronousInTransferPacket
Experimental
USBIsochronousInTransferResult
Experimental
USBIsochronousOutTransferPacket
Experimental
USBIsochronousOutTransferResult
Experimental
USBOutTransferResult
Experimental
UserActivationVValidityStateVideoColorSpaceVideoDecoderVideoEncoderVideoFrameVideoPlaybackQualityVideoTrackVideoTrackGenerator
Experimental
VideoTrackListViewTimeline
Experimental
ViewTransitionVirtualKeyboard
Experimental
VisibilityStateEntry
Experimental
VisualViewportVRDisplay
Non-standard

Deprecated
VRDisplayCapabilities
Non-standard

Deprecated
VRDisplayEvent
Non-standard

Deprecated
VREyeParameters
Non-standard

Deprecated
VRFieldOfView
Non-standard

Deprecated
VRFrameData
Non-standard

Deprecated
VRLayerInit
Deprecated
VRPose
Non-standard

Deprecated
VRStageParameters
Non-standard

Deprecated
VTTCueVTTRegionWWakeLockWakeLockSentinelWaveShaperNodeWebGL2RenderingContextWebGLActiveInfoWebGLBufferWebGLContextEventWebGLFramebufferWebGLObject
Experimental
WebGLProgramWebGLQueryWebGLRenderbufferWebGLRenderingContextWebGLSamplerWebGLShaderWebGLShaderPrecisionFormatWebGLSyncWebGLTextureWebGLTransformFeedbackWebGLUniformLocationWebGLVertexArrayObjectWebSocketWebSocketStream
Experimental
WebTransportWebTransportBidirectionalStreamWebTransportDatagramDuplexStreamWebTransportErrorWebTransportReceiveStream
Experimental
WebTransportSendStream
Experimental
WGSLLanguageFeatures
Experimental
WheelEventWindowWindowClientWindowControlsOverlay
Experimental
WindowControlsOverlayGeometryChangeEvent
Experimental
WindowSharedStorage
Experimental
WorkerWorkerGlobalScopeWorkerLocationWorkerNavigatorWorkletWorkletGlobalScopeWorkletSharedStorage
Experimental
WritableStreamWritableStreamDefaultControllerWritableStreamDefaultWriterXXMLDocumentXMLHttpRequestXMLHttpRequestEventTargetXMLHttpRequestUploadXMLSerializerXPathEvaluatorXPathExpressionXPathResultXRAnchor
Experimental
XRAnchorSet
Experimental
XRBoundedReferenceSpace
Experimental
XRCompositionLayer
Experimental
XRCPUDepthInformation
Experimental
XRCubeLayer
Experimental
XRCylinderLayer
Experimental
XRDepthInformation
Experimental
XREquirectLayer
Experimental
XRFrame
Experimental
XRHandXRHitTestResult
Experimental
XRHitTestSource
Experimental
XRInputSourceXRInputSourceArray
Experimental
XRInputSourceEventXRInputSourcesChangeEventXRJointPoseXRJointSpaceXRLayer
Experimental
XRLayerEvent
Experimental
XRLightEstimate
Experimental
XRLightProbe
Experimental
XRMediaBinding
Experimental
XRPoseXRProjectionLayer
Experimental
XRQuadLayer
Experimental
XRRay
Experimental
XRReferenceSpaceXRReferenceSpaceEventXRRenderState
Experimental
XRRigidTransformXRSession
Experimental
XRSessionEventXRSpaceXRSubImage
Experimental
XRSystem
Experimental
XRTransientInputHitTestResult
Experimental
XRTransientInputHitTestSource
Experimental
XRView
Experimental
XRViewerPoseXRViewportXRWebGLBinding
Experimental
XRWebGLDepthInformation
Experimental
XRWebGLLayer
Experimental
XRWebGLSubImage
Experimental
XSLTProcessorSee also
Web API event reference
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Feb 20, 2023 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nWeb APIsWhen writing code for the Web, there are a large number of Web APIs available. Below is a list of all the APIs and interfaces (object types) that you may be able to use while developing your Web app or site.
Web APIs are typically used with JavaScript, although this doesn't always have to be the case.SpecificationsThis is a list of all the APIs that are available.
AAttribution Reporting API
Experimental
Audio Output Devices API
Experimental
BBackground Fetch API
Experimental
Background Synchronization APIBackground Tasks APIBadging APIBarcode Detection API
Experimental
Battery Status APIBeacon APIWeb Bluetooth API
Experimental
Broadcast Channel APICCSS Custom Highlight APICSS Font Loading APICSS Painting API
Experimental
CSS Properties and Values APICSS Typed Object Model APICSS Object Model (CSSOM)Canvas APIChannel Messaging APIClipboard APICompression Streams APICompute Pressure API
Experimental
Console APIContact Picker API
Experimental
Content Index API
Experimental
Cookie Store APICredential Management APIDDocument Object Model (DOM)Device Memory APIDevice orientation eventsDevice Posture API
Experimental
Document Picture-in-Picture API
Experimental
EEditContext API
Experimental
Encoding APIEncrypted Media Extensions APIEyeDropper API
Experimental
FFederated Credential Management (FedCM) API
Experimental
Fenced Frame API
Experimental
Fetch APIFile APIFile System APIFile and Directory Entries APIForce Touch events
Non-standard
Fullscreen APIGGamepad APIGeolocation APIGeometry interfacesHThe HTML DOM APIHTML Drag and Drop APIHistory APIHoudini APIsIIdle Detection API
Experimental
MediaStream Image Capture APIIndexedDB APIInk API
Experimental
InputDeviceCapabilities API
Experimental
Insertable Streams for MediaStreamTrack APIIntersection Observer APIInvoker Commands APIJJS Self-Profiling API
Experimental
KKeyboard API
Experimental
LLaunch Handler API
Experimental
Local Font Access API
Experimental
MMedia Capabilities APIMedia Capture and Streams API (Media Stream)Media Session APIMedia Source API
Experimental
MediaStream Recording APINNavigation API
Experimental
Network Information APIPPage Visibility APIPayment Handler API
Experimental
Payment Request APIPerformance APIsWeb Periodic Background Synchronization API
Experimental
Permissions APIPicture-in-Picture APIPointer eventsPointer Lock APIPopover APIPresentation API
Experimental
Prioritized Task Scheduling APIPush APIRRemote Playback APIReporting APIResize Observer APISSVG APIScreen Capture APIScreen Orientation APIScreen Wake Lock APISelection APISensor APIsServer-sent eventsService Worker APIShared Storage API
Experimental
Speculation Rules API
Experimental
Storage APIStorage Access APIStreams APITTopics API
Experimental

Non-standard
Touch eventsTrusted Types APIUUI EventsURL APIURL Fragment Text DirectivesURL Pattern API
Experimental
User-Agent Client Hints API
Experimental
VVibration APIView Transition APIVirtualKeyboard API
Experimental
Visual Viewport APIWWeb Animations APIWeb Audio APIWeb Authentication APIWeb ComponentsWeb Crypto APIWeb Locks APIWeb MIDI APIWeb NFC API
Experimental
Notifications APIWeb Serial API
Experimental
Web Share APIWeb Speech APIWeb Storage APIWeb Workers APIWebCodecs APIWebGL: 2D and 3D graphics for the webWebGPU API
Experimental
WebHID API
Experimental
WebOTP APIWebRTC APIThe WebSocket API (WebSockets)WebTransport APIWebUSB API
Experimental
WebVR API
Non-standard

Deprecated
WebVTT APIWebXR Device API
Experimental
Window Controls Overlay API
Experimental
Window Management API
Experimental
XXMLHttpRequest APIffetchLater() API
Experimental
InterfacesThis is a list of all the interfaces (that is, types of objects) that are available.
AAbortControllerAbortSignalAbsoluteOrientationSensorAbstractRangeAccelerometer
Experimental
AesCbcParamsAesCtrParamsAesGcmParamsAesKeyGenParamsAmbientLightSensor
Experimental
AnalyserNodeANGLE_instanced_arraysAnimationAnimationEffectAnimationEventAnimationPlaybackEventAnimationTimelineAttrAudioBufferAudioBufferSourceNodeAudioContextAudioDataAudioDecoderAudioDestinationNodeAudioEncoderAudioListenerAudioNodeAudioParamAudioParamDescriptorAudioParamMapAudioProcessingEvent
Deprecated
AudioScheduledSourceNodeAudioSinkInfo
Experimental
AudioTrackAudioTrackListAudioWorkletAudioWorkletGlobalScopeAudioWorkletNodeAudioWorkletProcessorAuthenticatorAssertionResponseAuthenticatorAttestationResponseAuthenticatorResponseBBackgroundFetchEvent
Experimental
BackgroundFetchManager
Experimental
BackgroundFetchRecord
Experimental
BackgroundFetchRegistration
Experimental
BackgroundFetchUpdateUIEvent
Experimental
BarcodeDetector
Experimental
BarPropBaseAudioContextBatteryManagerBeforeInstallPromptEvent
Experimental

Non-standard
BeforeUnloadEventBiquadFilterNodeBlobBlobEventBluetooth
Experimental
BluetoothCharacteristicProperties
Experimental
BluetoothDevice
Experimental
BluetoothRemoteGATTCharacteristic
Experimental
BluetoothRemoteGATTDescriptor
Experimental
BluetoothRemoteGATTServer
Experimental
BluetoothRemoteGATTService
Experimental
BluetoothUUIDBroadcastChannelBrowserCaptureMediaStreamTrack
Experimental
ByteLengthQueuingStrategyCCacheCacheStorageCanMakePaymentEvent
Experimental
CanvasCaptureMediaStreamTrackCanvasGradientCanvasPatternCanvasRenderingContext2DCaptureController
Experimental
CaretPositionCDATASectionChannelMergerNodeChannelSplitterNodeChapterInformation
Experimental
CharacterBoundsUpdateEvent
Experimental
CharacterDataClientClientsClipboardClipboardEventClipboardItemCloseEventCloseWatcher
Experimental
CommandEventCommentCompositionEventCompressionStreamcconsoleCConstantSourceNodeContactAddress
Experimental
ContactsManager
Experimental
ContentIndex
Experimental
ContentIndexEvent
Experimental
ContentVisibilityAutoStateChangeEventConvolverNodeCookieChangeEventCookieStoreCookieStoreManagerCountQueuingStrategyCredentialCredentialsContainerCropTarget
Experimental
CryptoCryptoKeyCryptoKeyPairCSPViolationReportBodyCSSCSSAnimationCSSConditionRuleCSSContainerRuleCSSCounterStyleRuleCSSFontFaceRuleCSSFontFeatureValuesRuleCSSFontPaletteValuesRuleCSSGroupingRuleCSSImageValueCSSImportRuleCSSKeyframeRuleCSSKeyframesRuleCSSKeywordValueCSSLayerBlockRuleCSSLayerStatementRuleCSSMathInvertCSSMathMaxCSSMathMinCSSMathNegateCSSMathProductCSSMathSumCSSMathValueCSSMatrixComponentCSSMediaRuleCSSNamespaceRuleCSSNestedDeclarationsCSSNumericArrayCSSNumericValueCSSPageDescriptors
Experimental
CSSPageRuleCSSPerspectiveCSSPositionTryDescriptors
Experimental
CSSPositionTryRule
Experimental
CSSPositionValue
Non-standard

Deprecated
CSSPrimitiveValue
Deprecated
CSSPropertyRuleCSSPseudoElement
Experimental
CSSRotateCSSRuleCSSRuleListCSSScaleCSSScopeRuleCSSSkewCSSSkewXCSSSkewYCSSStartingStyleRuleCSSStyleDeclarationCSSStyleRuleCSSStyleSheetCSSStyleValueCSSSupportsRuleCSSTransformComponentCSSTransformValueCSSTransitionCSSTranslateCSSUnitValueCSSUnparsedValueCSSValue
Deprecated
CSSValueList
Deprecated
CSSVariableReferenceValueCustomElementRegistryCustomEventCustomStateSetDDataTransferDataTransferItemDataTransferItemListDecompressionStreamDedicatedWorkerGlobalScopeDeferredRequestInit
Experimental
DelayNodeDelegatedInkTrailPresenter
Experimental
DeprecationReportBody
Experimental
DeviceMotionEventDeviceMotionEventAccelerationDeviceMotionEventRotationRateDeviceOrientationEventDevicePosture
Experimental
DirectoryEntrySync
Non-standard

Deprecated
DirectoryReaderSync
Non-standard

Deprecated
DocumentDocumentFragmentDocumentPictureInPicture
Experimental
DocumentPictureInPictureEvent
Experimental
DocumentTimelineDocumentTypeDOMError
Deprecated
DOMExceptionDOMHighResTimeStampDOMImplementationDOMMatrixDOMMatrixReadOnlyDOMParserDOMPointDOMPointReadOnlyDOMQuadDOMRectDOMRectListDOMRectReadOnlyDOMStringListDOMStringMapDOMTokenListDragEventDynamicsCompressorNodeEEcdhKeyDeriveParamsEcdsaParamsEcKeyGenParamsEcKeyImportParamsEditContext
Experimental
ElementElementInternalsEncodedAudioChunkEncodedVideoChunkErrorEventEventEventCountsEventSourceEventTargetExtendableCookieChangeEventExtendableEventExtendableMessageEventEyeDropper
Experimental
FFeaturePolicy
Experimental
FederatedCredential
Experimental
FederatedCredentialInitFence
Experimental
FencedFrameConfig
Experimental
FetchEventFetchLaterResult
Experimental
FileFileEntrySync
Non-standard

Deprecated
FileListFileReaderFileReaderSyncFileSystemFileSystemChangeRecordFileSystemDirectoryEntryFileSystemDirectoryHandleFileSystemDirectoryReaderFileSystemEntryFileSystemFileEntryFileSystemFileHandleFileSystemHandleFileSystemObserver
Experimental

Non-standard
FileSystemSync
Non-standard

Deprecated
FileSystemSyncAccessHandleFileSystemWritableFileStreamFocusEventFontData
Experimental
FontFaceFontFaceSetFontFaceSetLoadEventFormDataFormDataEventFragmentDirectiveGGainNodeGamepadGamepadButtonGamepadEventGamepadHapticActuatorGamepadPose
Experimental
GeolocationGeolocationCoordinatesGeolocationPositionGeolocationPositionErrorGestureEvent
Non-standard
GPU
Experimental
GPUAdapter
Experimental
GPUAdapterInfo
Experimental
GPUBindGroup
Experimental
GPUBindGroupLayout
Experimental
GPUBuffer
Experimental
GPUCanvasContext
Experimental
GPUCommandBuffer
Experimental
GPUCommandEncoder
Experimental
GPUCompilationInfo
Experimental
GPUCompilationMessage
Experimental
GPUComputePassEncoder
Experimental
GPUComputePipeline
Experimental
GPUDevice
Experimental
GPUDeviceLostInfo
Experimental
GPUError
Experimental
GPUExternalTexture
Experimental
GPUInternalError
Experimental
GPUOutOfMemoryError
Experimental
GPUPipelineError
Experimental
GPUPipelineLayout
Experimental
GPUQuerySet
Experimental
GPUQueue
Experimental
GPURenderBundle
Experimental
GPURenderBundleEncoder
Experimental
GPURenderPassEncoder
Experimental
GPURenderPipeline
Experimental
GPUSampler
Experimental
GPUShaderModule
Experimental
GPUSupportedFeatures
Experimental
GPUSupportedLimits
Experimental
GPUTexture
Experimental
GPUTextureView
Experimental
GPUUncapturedErrorEvent
Experimental
GPUValidationError
Experimental
GravitySensorGyroscopeHHashChangeEventHeadersHID
Experimental
HIDConnectionEvent
Experimental
HIDDevice
Experimental
HIDInputReportEvent
Experimental
HighlightHighlightRegistryHistoryHkdfParamsHmacImportParamsHmacKeyGenParamsHMDVRDevice
Non-standard

Deprecated
HTMLAllCollectionHTMLAnchorElementHTMLAreaElementHTMLAudioElementHTMLBaseElementHTMLBodyElementHTMLBRElementHTMLButtonElementHTMLCanvasElementHTMLCollectionHTMLDataElementHTMLDataListElementHTMLDetailsElementHTMLDialogElementHTMLDivElementHTMLDListElementHTMLDocumentHTMLElementHTMLEmbedElementHTMLFencedFrameElement
Experimental
HTMLFieldSetElementHTMLFontElement
Deprecated
HTMLFormControlsCollectionHTMLFormElementHTMLFrameSetElement
Deprecated
HTMLHeadElementHTMLHeadingElementHTMLHRElementHTMLHtmlElementHTMLIFrameElementHTMLImageElementHTMLInputElementHTMLLabelElementHTMLLegendElementHTMLLIElementHTMLLinkElementHTMLMapElementHTMLMarqueeElement
Deprecated
HTMLMediaElementHTMLMenuElementHTMLMetaElementHTMLMeterElementHTMLModElementHTMLObjectElementHTMLOListElementHTMLOptGroupElementHTMLOptionElementHTMLOptionsCollectionHTMLOutputElementHTMLParagraphElementHTMLParamElement
Deprecated
HTMLPictureElementHTMLPreElementHTMLProgressElementHTMLQuoteElementHTMLScriptElementHTMLSelectedContentElementHTMLSelectElementHTMLSlotElementHTMLSourceElementHTMLSpanElementHTMLStyleElementHTMLTableCaptionElementHTMLTableCellElementHTMLTableColElementHTMLTableElementHTMLTableRowElementHTMLTableSectionElementHTMLTemplateElementHTMLTextAreaElementHTMLTimeElementHTMLTitleElementHTMLTrackElementHTMLUListElementHTMLUnknownElementHTMLVideoElementIIDBCursorIDBCursorWithValueIDBDatabaseIDBFactoryIDBIndexIDBKeyRangeIDBObjectStoreIDBOpenDBRequestIDBRequestIDBTransactionIDBVersionChangeEventIdentityCredential
Experimental
IdentityCredentialRequestOptionsIdentityProvider
Experimental
IdleDeadlineIdleDetector
Experimental
IIRFilterNodeImageBitmapImageBitmapRenderingContextImageCaptureImageDataImageDecoderImageTrackImageTrackListInk
Experimental
InputDeviceCapabilities
Experimental
InputDeviceInfoInputEventInstallEventIntersectionObserverIntersectionObserverEntryInterventionReportBody
Experimental
KKeyboard
Experimental
KeyboardEventKeyboardLayoutMap
Experimental
KeyframeEffectLLargestContentfulPaintLaunchParams
Experimental
LaunchQueue
Experimental
LayoutShift
Experimental
LayoutShiftAttribution
Experimental
LinearAccelerationSensorLocationLockLockManagerMMagnetometer
Experimental
MathMLElementMediaCapabilitiesMediaDeviceInfoMediaDevicesMediaElementAudioSourceNodeMediaEncryptedEventMediaErrorMediaKeyMessageEventMediaKeysMediaKeySessionMediaKeyStatusMapMediaKeySystemAccessMediaListMediaMetadataMediaQueryListMediaQueryListEventMediaRecorderMediaRecorderErrorEvent
Non-standard

Deprecated
MediaSessionMediaSourceMediaSourceHandleMediaStreamMediaStreamAudioDestinationNodeMediaStreamAudioSourceNodeMediaStreamEvent
Non-standard

Deprecated
MediaStreamTrackMediaStreamTrackAudioSourceNodeMediaStreamTrackEventMediaStreamTrackGenerator
Experimental

Non-standard
MediaStreamTrackProcessor
Experimental
MediaTrackConstraintsMediaTrackSettingsMediaTrackSupportedConstraintsMerchantValidationEvent
Deprecated
MessageChannelMessageEventMessagePortMetadata
Experimental

Non-standard
MIDIAccessMIDIConnectionEventMIDIInputMIDIInputMapMIDIMessageEventMIDIOutputMIDIOutputMapMIDIPortMimeType
Deprecated
MimeTypeArray
Deprecated
MouseEventMouseScrollEvent
Non-standard

Deprecated
MutationEvent
Non-standard

Deprecated
MutationObserverMutationRecordNNamedNodeMapNavigateEvent
Experimental
Navigation
Experimental
NavigationActivation
Experimental
NavigationCurrentEntryChangeEvent
Experimental
NavigationDestination
Experimental
NavigationHistoryEntry
Experimental
NavigationPreloadManagerNavigationTransition
Experimental
NavigatorNavigatorLoginNavigatorUAData
Experimental
NDEFMessage
Experimental
NDEFReader
Experimental
NDEFReadingEvent
Experimental
NDEFRecord
Experimental
NetworkInformationNodeNodeIteratorNodeListNotificationNotificationEventNotRestoredReasonDetails
Experimental
NotRestoredReasons
Experimental
OOES_draw_buffers_indexedOfflineAudioCompletionEventOfflineAudioContextOffscreenCanvasOffscreenCanvasRenderingContext2DOrientationSensorOscillatorNodeOTPCredential
Experimental
OverconstrainedErrorPPageRevealEventPageSwapEventPageTransitionEventPaintRenderingContext2DPaintSizePaintWorkletGlobalScope
Experimental
PannerNodePasswordCredential
Experimental
PasswordCredentialInitPath2DPaymentAddress
Non-standard

Deprecated
PaymentManager
Experimental
PaymentMethodChangeEventPaymentRequestPaymentRequestEvent
Experimental
PaymentRequestUpdateEventPaymentResponsePbkdf2ParamsPerformancePerformanceElementTiming
Experimental
PerformanceEntryPerformanceEventTimingPerformanceLongAnimationFrameTiming
Experimental
PerformanceLongTaskTiming
Experimental
PerformanceMarkPerformanceMeasurePerformanceNavigation
Deprecated
PerformanceNavigationTimingPerformanceObserverPerformanceObserverEntryListPerformancePaintTimingPerformanceResourceTimingPerformanceScriptTiming
Experimental
PerformanceServerTimingPerformanceTiming
Deprecated
PeriodicSyncEvent
Experimental
PeriodicSyncManager
Experimental
PeriodicWavePermissionsPermissionStatusPictureInPictureEventPictureInPictureWindowPlugin
Deprecated
PluginArray
Deprecated
Point
Non-standard

Deprecated
PointerEventPopStateEventPositionSensorVRDevice
Non-standard

Deprecated
Presentation
Experimental
PresentationAvailability
Experimental
PresentationConnection
Experimental
PresentationConnectionAvailableEvent
Experimental
PresentationConnectionCloseEvent
Experimental
PresentationConnectionList
Experimental
PresentationReceiver
Experimental
PresentationRequest
Experimental
PressureObserver
Experimental
PressureRecord
Experimental
ProcessingInstructionProfiler
Experimental
ProgressEventPromiseRejectionEventPublicKeyCredentialPublicKeyCredentialCreationOptionsPublicKeyCredentialRequestOptionsPushEventPushManagerPushMessageDataPushSubscriptionPushSubscriptionOptionsRRadioNodeListRangeReadableByteStreamControllerReadableStreamReadableStreamBYOBReaderReadableStreamBYOBRequestReadableStreamDefaultControllerReadableStreamDefaultReaderRelativeOrientationSensorRemotePlaybackReportReportBodyReportingObserverRequestRequestInitResizeObserverResizeObserverEntryResizeObserverSizeResponseRestrictionTarget
Experimental
RsaHashedImportParamsRsaHashedKeyGenParamsRsaOaepParamsRsaPssParamsRTCAudioSourceStatsRTCCertificateRTCCertificateStatsRTCCodecStatsRTCDataChannelRTCDataChannelEventRTCDataChannelStatsRTCDtlsTransportRTCDTMFSenderRTCDTMFToneChangeEventRTCEncodedAudioFrameRTCEncodedVideoFrameRTCErrorRTCErrorEventRTCIceCandidateRTCIceCandidatePairRTCIceCandidatePairStatsRTCIceCandidateStatsRTCIceParametersRTCIceTransportRTCIdentityAssertion
Experimental
RTCInboundRtpStreamStatsRTCOutboundRtpStreamStatsRTCPeerConnectionRTCPeerConnectionIceErrorEventRTCPeerConnectionIceEventRTCPeerConnectionStatsRTCRemoteInboundRtpStreamStatsRTCRemoteOutboundRtpStreamStatsRTCRtpReceiverRTCRtpScriptTransformRTCRtpScriptTransformerRTCRtpSenderRTCRtpTransceiverRTCSctpTransportRTCSessionDescriptionRTCStatsReportRTCTrackEventRTCTransformEventRTCTransportStatsRTCVideoSourceStatsSSchedulerScheduling
Experimental
ScreenScreenDetailed
Experimental
ScreenDetails
Experimental
ScreenOrientationScriptProcessorNode
Deprecated
ScrollTimeline
Experimental
SecurePaymentConfirmationRequestSecurityPolicyViolationEventSelectionSensorSensorErrorEventSerial
Experimental
SerialPort
Experimental
ServiceWorkerServiceWorkerContainerServiceWorkerGlobalScopeServiceWorkerRegistrationShadowRootSharedStorage
Experimental
SharedStorageOperation
Experimental
SharedStorageRunOperation
Experimental
SharedStorageSelectURLOperation
Experimental
SharedStorageWorklet
Experimental
SharedStorageWorkletGlobalScope
Experimental
SharedWorkerSharedWorkerGlobalScopeSnapEvent
Experimental
SourceBufferSourceBufferListSpeechGrammar
Non-standard

Deprecated
SpeechGrammarList
Experimental
SpeechRecognitionSpeechRecognitionAlternativeSpeechRecognitionErrorEventSpeechRecognitionEventSpeechRecognitionResultSpeechRecognitionResultListSpeechSynthesisSpeechSynthesisErrorEventSpeechSynthesisEventSpeechSynthesisUtteranceSpeechSynthesisVoiceStaticRangeStereoPannerNodeStorageStorageAccessHandleStorageEventStorageManagerStylePropertyMapStylePropertyMapReadOnlyStyleSheetStyleSheetListSubmitEventSubtleCryptoSVGAElementSVGAngleSVGAnimateColorElement
Deprecated
SVGAnimatedAngleSVGAnimatedBooleanSVGAnimatedEnumerationSVGAnimatedIntegerSVGAnimatedLengthSVGAnimatedLengthListSVGAnimatedNumberSVGAnimatedNumberListSVGAnimatedPreserveAspectRatioSVGAnimatedRectSVGAnimatedStringSVGAnimatedTransformListSVGAnimateElementSVGAnimateMotionElementSVGAnimateTransformElementSVGAnimationElementSVGCircleElementSVGClipPathElementSVGComponentTransferFunctionElementSVGDefsElementSVGDescElementSVGDiscardElement
Experimental
SVGElementSVGEllipseElementSVGFEBlendElementSVGFEColorMatrixElementSVGFEComponentTransferElementSVGFECompositeElementSVGFEConvolveMatrixElementSVGFEDiffuseLightingElementSVGFEDisplacementMapElementSVGFEDistantLightElementSVGFEDropShadowElementSVGFEFloodElementSVGFEFuncAElementSVGFEFuncBElementSVGFEFuncGElementSVGFEFuncRElementSVGFEGaussianBlurElementSVGFEImageElementSVGFEMergeElementSVGFEMergeNodeElementSVGFEMorphologyElementSVGFEOffsetElementSVGFEPointLightElementSVGFESpecularLightingElementSVGFESpotLightElementSVGFETileElementSVGFETurbulenceElementSVGFilterElementSVGForeignObjectElementSVGGElementSVGGeometryElementSVGGradientElementSVGGraphicsElementSVGImageElementSVGLengthSVGLengthListSVGLinearGradientElementSVGLineElementSVGMarkerElementSVGMaskElementSVGMetadataElementSVGMPathElementSVGNumberSVGNumberListSVGPathElementSVGPatternElementSVGPoint
Deprecated
SVGPointListSVGPolygonElementSVGPolylineElementSVGPreserveAspectRatioSVGRadialGradientElementSVGRectSVGRectElementSVGRenderingIntent
Deprecated
SVGScriptElementSVGSetElementSVGStopElementSVGStringListSVGStyleElementSVGSVGElementSVGSwitchElementSVGSymbolElementSVGTextContentElementSVGTextElementSVGTextPathElementSVGTextPositioningElementSVGTitleElementSVGTransformSVGTransformListSVGTSpanElementSVGUnitTypesSVGUseElementSVGViewElementSyncEventSyncManagerTTaskAttributionTiming
Experimental
TaskControllerTaskPriorityChangeEventTaskSignalTextTextDecoderTextDecoderStreamTextEncoderTextEncoderStreamTextEvent
Deprecated
TextFormat
Experimental
TextFormatUpdateEvent
Experimental
TextMetricsTextTrackTextTrackCueTextTrackCueListTextTrackListTextUpdateEvent
Experimental
TimeEventTimeRangesToggleEventTouchTouchEventTouchListTrackEventTransformStreamTransformStreamDefaultControllerTransitionEventTreeWalkerTrustedHTMLTrustedScriptTrustedScriptURLTrustedTypePolicyTrustedTypePolicyFactoryUUIEventURLURLPattern
Experimental
URLSearchParamsUSB
Experimental
USBAlternateInterface
Experimental
USBConfiguration
Experimental
USBConnectionEvent
Experimental
USBDevice
Experimental
USBEndpoint
Experimental
USBInterface
Experimental
USBInTransferResult
Experimental
USBIsochronousInTransferPacket
Experimental
USBIsochronousInTransferResult
Experimental
USBIsochronousOutTransferPacket
Experimental
USBIsochronousOutTransferResult
Experimental
USBOutTransferResult
Experimental
UserActivationVValidityStateVideoColorSpaceVideoDecoderVideoEncoderVideoFrameVideoPlaybackQualityVideoTrackVideoTrackGenerator
Experimental
VideoTrackListViewTimeline
Experimental
ViewTransitionVirtualKeyboard
Experimental
VisibilityStateEntry
Experimental
VisualViewportVRDisplay
Non-standard

Deprecated
VRDisplayCapabilities
Non-standard

Deprecated
VRDisplayEvent
Non-standard

Deprecated
VREyeParameters
Non-standard

Deprecated
VRFieldOfView
Non-standard

Deprecated
VRFrameData
Non-standard

Deprecated
VRLayerInit
Deprecated
VRPose
Non-standard

Deprecated
VRStageParameters
Non-standard

Deprecated
VTTCueVTTRegionWWakeLockWakeLockSentinelWaveShaperNodeWebGL2RenderingContextWebGLActiveInfoWebGLBufferWebGLContextEventWebGLFramebufferWebGLObject
Experimental
WebGLProgramWebGLQueryWebGLRenderbufferWebGLRenderingContextWebGLSamplerWebGLShaderWebGLShaderPrecisionFormatWebGLSyncWebGLTextureWebGLTransformFeedbackWebGLUniformLocationWebGLVertexArrayObjectWebSocketWebSocketStream
Experimental
WebTransportWebTransportBidirectionalStreamWebTransportDatagramDuplexStreamWebTransportErrorWebTransportReceiveStream
Experimental
WebTransportSendStream
Experimental
WGSLLanguageFeatures
Experimental
WheelEventWindowWindowClientWindowControlsOverlay
Experimental
WindowControlsOverlayGeometryChangeEvent
Experimental
WindowSharedStorage
Experimental
WorkerWorkerGlobalScopeWorkerLocationWorkerNavigatorWorkletWorkletGlobalScopeWorkletSharedStorage
Experimental
WritableStreamWritableStreamDefaultControllerWritableStreamDefaultWriterXXMLDocumentXMLHttpRequestXMLHttpRequestEventTargetXMLHttpRequestUploadXMLSerializerXPathEvaluatorXPathExpressionXPathResultXRAnchor
Experimental
XRAnchorSet
Experimental
XRBoundedReferenceSpace
Experimental
XRCompositionLayer
Experimental
XRCPUDepthInformation
Experimental
XRCubeLayer
Experimental
XRCylinderLayer
Experimental
XRDepthInformation
Experimental
XREquirectLayer
Experimental
XRFrame
Experimental
XRHandXRHitTestResult
Experimental
XRHitTestSource
Experimental
XRInputSourceXRInputSourceArray
Experimental
XRInputSourceEventXRInputSourcesChangeEventXRJointPoseXRJointSpaceXRLayer
Experimental
XRLayerEvent
Experimental
XRLightEstimate
Experimental
XRLightProbe
Experimental
XRMediaBinding
Experimental
XRPoseXRProjectionLayer
Experimental
XRQuadLayer
Experimental
XRRay
Experimental
XRReferenceSpaceXRReferenceSpaceEventXRRenderState
Experimental
XRRigidTransformXRSession
Experimental
XRSessionEventXRSpaceXRSubImage
Experimental
XRSystem
Experimental
XRTransientInputHitTestResult
Experimental
XRTransientInputHitTestSource
Experimental
XRView
Experimental
XRViewerPoseXRViewportXRWebGLBinding
Experimental
XRWebGLDepthInformation
Experimental
XRWebGLLayer
Experimental
XRWebGLSubImage
Experimental
XSLTProcessorSee also
Web API event reference
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Feb 20, 2023 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nBrowser extensionsExtensions, or add-ons, can modify and enhance the capability of a browser. Extensions for Firefox are built using the WebExtensions API cross-browser technology.
The technology for extensions in Firefox is, to a large extent, compatible with the extension API supported by Chromium-based browsers (such as Google Chrome, Microsoft Edge, Opera, Vivaldi). In most cases, extensions written for Chromium-based browsers run in Firefox with just a few changes.Key resources
Guides

Whether you're just beginning or looking for more advanced advice, learn about how extensions work and use the WebExtensions API from our extensive range of tutorials and guides.

References

Get comprehensive details about the methods, properties, types, and events of the WebExtensions APIs and full details about the manifest keys.

Firefox workflow

Discover how to build and publish extensions for Firefox: get the lowdown on developer tools, publication and distribution, and porting on Extension Workshop.



Note:
If you have ideas or questions or need help, you can reach us on the community forum or in the Add-ons Room on Matrix.
Get startedDiscover what extensions can do before building your first extension. Learn about the anatomy of an extension and get an overview of the extension development and publication workflow, Firefox style. Explore a little deeper with a comprehensive selection of example extensions that you can run right in Firefox.ConceptsGet detailed information on the concept that underpin extensions from an overview of the JavaScript API, through content scripts, match patterns, working with files, internationalization, and content security policy, to more advanced subjects such as native messaging, using the devtools APIs, and native manifests.User interfaceDiscover all the user interface components you can use in your extensions, with coding examples and tips.How toFrom patterns you'll regularly use such as work with the Tabs API and adding a button to the toolbar to more advanced topics such as intercepting HTTP requests and working with contextual identities, you'll find a range of tutorials to get you started.Firefox workflowWhen you are ready to create your extension for Firefox or port your Chrome extension, head over to Extension Workshop. It has details on:

The Firefox workflow, such as temporarily installing extensions during development, debugging, request the right permissions, and more.
The web-ext developer tool.
Porting a Google Chrome extension, differences between desktop and Android, and more.
Publishing and distribution overview, promoting your extension, the extension lifecycle best practices, and more.
ReferenceJavaScript APIsGet comprehensive details about the methods, properties, types, and events for all the JavaScript APIs. There is also detailed information about the compatibility of each API with the major browsers. Most reference pages also include coding examples and links to the extension examples that use the API.Manifest keysGet full details about the manifest keys, including all their properties and settings.\n\nBrowser extensionsExtensions, or add-ons, can modify and enhance the capability of a browser. Extensions for Firefox are built using the WebExtensions API cross-browser technology.
The technology for extensions in Firefox is, to a large extent, compatible with the extension API supported by Chromium-based browsers (such as Google Chrome, Microsoft Edge, Opera, Vivaldi). In most cases, extensions written for Chromium-based browsers run in Firefox with just a few changes.Key resources
Guides

Whether you're just beginning or looking for more advanced advice, learn about how extensions work and use the WebExtensions API from our extensive range of tutorials and guides.

References

Get comprehensive details about the methods, properties, types, and events of the WebExtensions APIs and full details about the manifest keys.

Firefox workflow

Discover how to build and publish extensions for Firefox: get the lowdown on developer tools, publication and distribution, and porting on Extension Workshop.



Note:
If you have ideas or questions or need help, you can reach us on the community forum or in the Add-ons Room on Matrix.
Get startedDiscover what extensions can do before building your first extension. Learn about the anatomy of an extension and get an overview of the extension development and publication workflow, Firefox style. Explore a little deeper with a comprehensive selection of example extensions that you can run right in Firefox.ConceptsGet detailed information on the concept that underpin extensions from an overview of the JavaScript API, through content scripts, match patterns, working with files, internationalization, and content security policy, to more advanced subjects such as native messaging, using the devtools APIs, and native manifests.User interfaceDiscover all the user interface components you can use in your extensions, with coding examples and tips.How toFrom patterns you'll regularly use such as work with the Tabs API and adding a button to the toolbar to more advanced topics such as intercepting HTTP requests and working with contextual identities, you'll find a range of tutorials to get you started.Firefox workflowWhen you are ready to create your extension for Firefox or port your Chrome extension, head over to Extension Workshop. It has details on:

The Firefox workflow, such as temporarily installing extensions during development, debugging, request the right permissions, and more.
The web-ext developer tool.
Porting a Google Chrome extension, differences between desktop and Android, and more.
Publishing and distribution overview, promoting your extension, the extension lifecycle best practices, and more.
ReferenceJavaScript APIsGet comprehensive details about the methods, properties, types, and events for all the JavaScript APIs. There is also detailed information about the compatibility of each API with the major browsers. Most reference pages also include coding examples and links to the extension examples that use the API.Manifest keysGet full details about the manifest keys, including all their properties and settings.Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 22, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nBrowser extensionsExtensions, or add-ons, can modify and enhance the capability of a browser. Extensions for Firefox are built using the WebExtensions API cross-browser technology.
The technology for extensions in Firefox is, to a large extent, compatible with the extension API supported by Chromium-based browsers (such as Google Chrome, Microsoft Edge, Opera, Vivaldi). In most cases, extensions written for Chromium-based browsers run in Firefox with just a few changes.Key resources
Guides

Whether you're just beginning or looking for more advanced advice, learn about how extensions work and use the WebExtensions API from our extensive range of tutorials and guides.

References

Get comprehensive details about the methods, properties, types, and events of the WebExtensions APIs and full details about the manifest keys.

Firefox workflow

Discover how to build and publish extensions for Firefox: get the lowdown on developer tools, publication and distribution, and porting on Extension Workshop.



Note:
If you have ideas or questions or need help, you can reach us on the community forum or in the Add-ons Room on Matrix.
Get startedDiscover what extensions can do before building your first extension. Learn about the anatomy of an extension and get an overview of the extension development and publication workflow, Firefox style. Explore a little deeper with a comprehensive selection of example extensions that you can run right in Firefox.ConceptsGet detailed information on the concept that underpin extensions from an overview of the JavaScript API, through content scripts, match patterns, working with files, internationalization, and content security policy, to more advanced subjects such as native messaging, using the devtools APIs, and native manifests.User interfaceDiscover all the user interface components you can use in your extensions, with coding examples and tips.How toFrom patterns you'll regularly use such as work with the Tabs API and adding a button to the toolbar to more advanced topics such as intercepting HTTP requests and working with contextual identities, you'll find a range of tutorials to get you started.Firefox workflowWhen you are ready to create your extension for Firefox or port your Chrome extension, head over to Extension Workshop. It has details on:

The Firefox workflow, such as temporarily installing extensions during development, debugging, request the right permissions, and more.
The web-ext developer tool.
Porting a Google Chrome extension, differences between desktop and Android, and more.
Publishing and distribution overview, promoting your extension, the extension lifecycle best practices, and more.
ReferenceJavaScript APIsGet comprehensive details about the methods, properties, types, and events for all the JavaScript APIs. There is also detailed information about the compatibility of each API with the major browsers. Most reference pages also include coding examples and links to the extension examples that use the API.Manifest keysGet full details about the manifest keys, including all their properties and settings.Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 22, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nAccessibilityAccessibility (often abbreviated to A11y — as in, "a", then 11 characters, and then "y") in web development means enabling as many people as possible to use websites, even when those people's abilities are limited in some way.
For many people, technology makes things easier. For people with disabilities, technology makes things possible. Accessibility means developing content to be as accessible as possible, no matter an individual's physical and cognitive abilities and how they access the web.

The Web is fundamentally designed to work for all people, whatever their hardware, software, language, location, or ability.
When the Web meets this goal, it is accessible to people with a diverse range of hearing, movement, sight, and cognitive ability. 
– (W3C - Accessibility)
Accessibility guides
Accessibility information for web authors

This document lists guidelines and regulations, how-to's, and tools for checking and repairing accessibility problems with websites.

Personalization to help browse safely

This article discusses making web content accessible for those with vestibular disorders, and those who support them, by taking advantage of personalization and accessibility settings built into the operating systems.

Accessible web applications and widgets

Most JavaScript libraries offer a library of client-side widgets that mimic the behavior of familiar desktop interfaces.
While this results in a widget that looks like its desktop counterpart, there usually isn't enough semantic information in the markup to be usable by an assistive technology.
This document describes techniques to improve accessibility of such widgets.

Keyboard-navigable JavaScript widgets

Until now, web developers who wanted to make their styled <div> and <span> based widgets accessible have lacked proper techniques.
Keyboard accessibility is part of the minimum accessibility requirements, which a developer should be aware of.
This document describes techniques to make JavaScript widgets accessible with the keyboard.

Mobile accessibility checklist

This document provides a concise checklist of accessibility requirements for mobile app developers.

Understanding the Web Content Accessibility Guidelines (WCAG)

A set of articles that provide quick explanations to help you understand the steps that need to be taken to conform to the recommendations outlined in the Web Content Accessibility Guidelines (WCAG).

Cognitive accessibility

Cognitive accessibility covers accessibility considerations for people with cognition and learning disabilities.
This document introduces cognitive accessibility and improving accessibility of the web for people with cognitive and learning differences.

Accessibility and spatial patterns

This document describes visual patterns that can induce physical symptoms in people who have photosensitive epilepsy, vestibular disorders, or other perceptual issues.

Web Accessibility: Understanding Colors and Luminance

While understanding color, luminance, and saturation is important for design and readability for all sighted users, they are essential for those with reduced vision and color-deficient vision and those with specific neurological, cognitive, and other impairments.

Web accessibility for seizures and physical reactions

Some types of visual web content can induce seizures in people with certain brain disorders.
This article helps you understand the types of content that can be problematic and find tools and strategies to help you avoid them.

ARIA

This is a collection of articles to learn how to use Accessible Rich Internet Applications (ARIA) to make your HTML documents more accessible.

Tutorials for beginnersThe MDN Accessibility Learning Area contains modern, up-to-date tutorials covering the following accessibility essentials:

What is accessibility?

This article starts off the module with a good look at what accessibility actually is — this includes what groups of people we need to consider and why, what tools different people use to interact with the Web, and how we can make accessibility part of our web development workflow.

HTML: A good basis for accessibility

A great deal of web content can be made accessible just by making sure that the correct HTML elements are used for the correct purpose at all times. This article looks in detail at how HTML can be used to ensure maximum accessibility.

CSS and JavaScript accessibility best practices

CSS and JavaScript, when used properly, also have the potential to allow for accessible web experiences. They can significantly harm accessibility if misused. This article outlines some CSS and JavaScript best practices that should be considered to ensure that even complex content is as accessible as possible.

WAI-ARIA basics

Following on from the previous article, sometimes making complex UI controls that involve unsemantic HTML and dynamic JavaScript-updated content can be difficult. WAI-ARIA is a technology that can help with such problems by adding in further semantics that browsers and assistive technologies can recognize and let users know what is going on. Here we'll show how to use it at a basic level to improve accessibility.

Accessible multimedia

Another category of content that can create accessibility problems is multimedia — video, audio, and image content need to be given proper textual alternatives so that they can be understood by assistive technologies and their users. This article shows how.

Mobile accessibility

With web access on mobile devices being so popular and popular platforms such as iOS and Android having fully-fledged accessibility tools, it is important to consider the accessibility of your web content on these platforms. This article looks at mobile-specific accessibility considerations.

References
ARIA reference

Reference documentation for Accessible Rich Internet Applications (ARIA) attributes and roles.

See also
Developer guides
WAI Interest Group\n\nAccessibilityAccessibility (often abbreviated to A11y — as in, "a", then 11 characters, and then "y") in web development means enabling as many people as possible to use websites, even when those people's abilities are limited in some way.
For many people, technology makes things easier. For people with disabilities, technology makes things possible. Accessibility means developing content to be as accessible as possible, no matter an individual's physical and cognitive abilities and how they access the web.

The Web is fundamentally designed to work for all people, whatever their hardware, software, language, location, or ability.
When the Web meets this goal, it is accessible to people with a diverse range of hearing, movement, sight, and cognitive ability. 
– (W3C - Accessibility)
Accessibility guides
Accessibility information for web authors

This document lists guidelines and regulations, how-to's, and tools for checking and repairing accessibility problems with websites.

Personalization to help browse safely

This article discusses making web content accessible for those with vestibular disorders, and those who support them, by taking advantage of personalization and accessibility settings built into the operating systems.

Accessible web applications and widgets

Most JavaScript libraries offer a library of client-side widgets that mimic the behavior of familiar desktop interfaces.
While this results in a widget that looks like its desktop counterpart, there usually isn't enough semantic information in the markup to be usable by an assistive technology.
This document describes techniques to improve accessibility of such widgets.

Keyboard-navigable JavaScript widgets

Until now, web developers who wanted to make their styled <div> and <span> based widgets accessible have lacked proper techniques.
Keyboard accessibility is part of the minimum accessibility requirements, which a developer should be aware of.
This document describes techniques to make JavaScript widgets accessible with the keyboard.

Mobile accessibility checklist

This document provides a concise checklist of accessibility requirements for mobile app developers.

Understanding the Web Content Accessibility Guidelines (WCAG)

A set of articles that provide quick explanations to help you understand the steps that need to be taken to conform to the recommendations outlined in the Web Content Accessibility Guidelines (WCAG).

Cognitive accessibility

Cognitive accessibility covers accessibility considerations for people with cognition and learning disabilities.
This document introduces cognitive accessibility and improving accessibility of the web for people with cognitive and learning differences.

Accessibility and spatial patterns

This document describes visual patterns that can induce physical symptoms in people who have photosensitive epilepsy, vestibular disorders, or other perceptual issues.

Web Accessibility: Understanding Colors and Luminance

While understanding color, luminance, and saturation is important for design and readability for all sighted users, they are essential for those with reduced vision and color-deficient vision and those with specific neurological, cognitive, and other impairments.

Web accessibility for seizures and physical reactions

Some types of visual web content can induce seizures in people with certain brain disorders.
This article helps you understand the types of content that can be problematic and find tools and strategies to help you avoid them.

ARIA

This is a collection of articles to learn how to use Accessible Rich Internet Applications (ARIA) to make your HTML documents more accessible.

Tutorials for beginnersThe MDN Accessibility Learning Area contains modern, up-to-date tutorials covering the following accessibility essentials:

What is accessibility?

This article starts off the module with a good look at what accessibility actually is — this includes what groups of people we need to consider and why, what tools different people use to interact with the Web, and how we can make accessibility part of our web development workflow.

HTML: A good basis for accessibility

A great deal of web content can be made accessible just by making sure that the correct HTML elements are used for the correct purpose at all times. This article looks in detail at how HTML can be used to ensure maximum accessibility.

CSS and JavaScript accessibility best practices

CSS and JavaScript, when used properly, also have the potential to allow for accessible web experiences. They can significantly harm accessibility if misused. This article outlines some CSS and JavaScript best practices that should be considered to ensure that even complex content is as accessible as possible.

WAI-ARIA basics

Following on from the previous article, sometimes making complex UI controls that involve unsemantic HTML and dynamic JavaScript-updated content can be difficult. WAI-ARIA is a technology that can help with such problems by adding in further semantics that browsers and assistive technologies can recognize and let users know what is going on. Here we'll show how to use it at a basic level to improve accessibility.

Accessible multimedia

Another category of content that can create accessibility problems is multimedia — video, audio, and image content need to be given proper textual alternatives so that they can be understood by assistive technologies and their users. This article shows how.

Mobile accessibility

With web access on mobile devices being so popular and popular platforms such as iOS and Android having fully-fledged accessibility tools, it is important to consider the accessibility of your web content on these platforms. This article looks at mobile-specific accessibility considerations.

References
ARIA reference

Reference documentation for Accessible Rich Internet Applications (ARIA) attributes and roles.

See also
Developer guides
WAI Interest Group
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 6, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nAccessibilityAccessibility (often abbreviated to A11y — as in, "a", then 11 characters, and then "y") in web development means enabling as many people as possible to use websites, even when those people's abilities are limited in some way.
For many people, technology makes things easier. For people with disabilities, technology makes things possible. Accessibility means developing content to be as accessible as possible, no matter an individual's physical and cognitive abilities and how they access the web.

The Web is fundamentally designed to work for all people, whatever their hardware, software, language, location, or ability.
When the Web meets this goal, it is accessible to people with a diverse range of hearing, movement, sight, and cognitive ability. 
– (W3C - Accessibility)
Accessibility guides
Accessibility information for web authors

This document lists guidelines and regulations, how-to's, and tools for checking and repairing accessibility problems with websites.

Personalization to help browse safely

This article discusses making web content accessible for those with vestibular disorders, and those who support them, by taking advantage of personalization and accessibility settings built into the operating systems.

Accessible web applications and widgets

Most JavaScript libraries offer a library of client-side widgets that mimic the behavior of familiar desktop interfaces.
While this results in a widget that looks like its desktop counterpart, there usually isn't enough semantic information in the markup to be usable by an assistive technology.
This document describes techniques to improve accessibility of such widgets.

Keyboard-navigable JavaScript widgets

Until now, web developers who wanted to make their styled <div> and <span> based widgets accessible have lacked proper techniques.
Keyboard accessibility is part of the minimum accessibility requirements, which a developer should be aware of.
This document describes techniques to make JavaScript widgets accessible with the keyboard.

Mobile accessibility checklist

This document provides a concise checklist of accessibility requirements for mobile app developers.

Understanding the Web Content Accessibility Guidelines (WCAG)

A set of articles that provide quick explanations to help you understand the steps that need to be taken to conform to the recommendations outlined in the Web Content Accessibility Guidelines (WCAG).

Cognitive accessibility

Cognitive accessibility covers accessibility considerations for people with cognition and learning disabilities.
This document introduces cognitive accessibility and improving accessibility of the web for people with cognitive and learning differences.

Accessibility and spatial patterns

This document describes visual patterns that can induce physical symptoms in people who have photosensitive epilepsy, vestibular disorders, or other perceptual issues.

Web Accessibility: Understanding Colors and Luminance

While understanding color, luminance, and saturation is important for design and readability for all sighted users, they are essential for those with reduced vision and color-deficient vision and those with specific neurological, cognitive, and other impairments.

Web accessibility for seizures and physical reactions

Some types of visual web content can induce seizures in people with certain brain disorders.
This article helps you understand the types of content that can be problematic and find tools and strategies to help you avoid them.

ARIA

This is a collection of articles to learn how to use Accessible Rich Internet Applications (ARIA) to make your HTML documents more accessible.

Tutorials for beginnersThe MDN Accessibility Learning Area contains modern, up-to-date tutorials covering the following accessibility essentials:

What is accessibility?

This article starts off the module with a good look at what accessibility actually is — this includes what groups of people we need to consider and why, what tools different people use to interact with the Web, and how we can make accessibility part of our web development workflow.

HTML: A good basis for accessibility

A great deal of web content can be made accessible just by making sure that the correct HTML elements are used for the correct purpose at all times. This article looks in detail at how HTML can be used to ensure maximum accessibility.

CSS and JavaScript accessibility best practices

CSS and JavaScript, when used properly, also have the potential to allow for accessible web experiences. They can significantly harm accessibility if misused. This article outlines some CSS and JavaScript best practices that should be considered to ensure that even complex content is as accessible as possible.

WAI-ARIA basics

Following on from the previous article, sometimes making complex UI controls that involve unsemantic HTML and dynamic JavaScript-updated content can be difficult. WAI-ARIA is a technology that can help with such problems by adding in further semantics that browsers and assistive technologies can recognize and let users know what is going on. Here we'll show how to use it at a basic level to improve accessibility.

Accessible multimedia

Another category of content that can create accessibility problems is multimedia — video, audio, and image content need to be given proper textual alternatives so that they can be understood by assistive technologies and their users. This article shows how.

Mobile accessibility

With web access on mobile devices being so popular and popular platforms such as iOS and Android having fully-fledged accessibility tools, it is important to consider the accessibility of your web content on these platforms. This article looks at mobile-specific accessibility considerations.

References
ARIA reference

Reference documentation for Accessible Rich Internet Applications (ARIA) attributes and roles.

See also
Developer guides
WAI Interest Group
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 6, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nLearn web developmentThe essential skillset for new front-end developersWelcome to MDN Learning Web Development (also known as Learn). This resource provides a structured set of tutorials teaching the essential skills and practices for being a successful front-end developer, along with challenges and further recommended resources.About Learn web development

Teaches the essential skills and knowledge every front-end developer needs for career success and industry relevance, as defined in the MDN Curriculum.


Created by the MDN community and refined with insights from students, educators, and developers from the broader web community.


Designed to take you from "beginner" to "comfortable" (not "beginner" to "expert"), giving you enough knowledge to use more advanced resources (such as the rest of MDN).



Note:
Last updated: December 2024 (see changelog).
Don't know where to get started?
Never coded before?

Our Getting started modules provide setup tutorials and essential concepts and background information for complete beginners. You should start here if you are a complete beginner (i.e., you've not installed a code editor or written any code yet).

Want to master the essentials?

Our Core modules provide a structured set of tutorials teaching the essential skills and practices for being a successful front-end developer.

Beyond the basics?

Our Extension modules cover useful additional skills to learn as you start to expand your knowledge and develop specialisms. Go onto these after you finish our Core.

Working at a school?

Use our modules to guide your teaching, check out our Educators page for more ideas, or enroll your students in Scrimba's Frontend Developer Career PathMDN learning partner.

Getting our code examplesThe code examples you'll encounter in the Learning Area are all available on GitHub:

The easiest way to get them is to download a ZIP of the latest main code branch.
If you are familiar with Git and GitHub, you could also choose to clone the repository.
Contact usIf you want to get in touch with us about anything, use the communication channels. We'd love to hear from you about anything you think is wrong or missing on the site, requests for new learning topics, requests for help with items you don't understand, or any other questions or concerns.
If you're interested in helping develop/improve the content, take a look at how you can help and get in touch! We are more than happy to talk to you, whether you are a learner, teacher, experienced web developer, or someone else interested in helping to improve the learning experience.See also
The Frontend Developer Career Path MDN learning partner

Scrimba's Frontend Developer Career Path teaches all you need to know to be a competent front-end web developer, with fun interactive lessons and challenges, knowledgeable teachers, and a supportive community. Go from zero to landing your first front-end job! Many of the course components are available as standalone free versions.

Codecademy

A great interactive site for learning programming languages from scratch.

freeCodeCamp.org

Interactive site with tutorials and projects to learn web development.

Learn JavaScript

An excellent resource for aspiring web developers — Learn JavaScript in an interactive environment, with short lessons and interactive tests, guided by automated assessment. The first 40 lessons are free, and the complete course is available for a small one-time payment.\n\nLearn web developmentThe essential skillset for new front-end developersWelcome to MDN Learning Web Development (also known as Learn). This resource provides a structured set of tutorials teaching the essential skills and practices for being a successful front-end developer, along with challenges and further recommended resources.About Learn web development

Teaches the essential skills and knowledge every front-end developer needs for career success and industry relevance, as defined in the MDN Curriculum.


Created by the MDN community and refined with insights from students, educators, and developers from the broader web community.


Designed to take you from "beginner" to "comfortable" (not "beginner" to "expert"), giving you enough knowledge to use more advanced resources (such as the rest of MDN).



Note:
Last updated: December 2024 (see changelog).
Don't know where to get started?
Never coded before?

Our Getting started modules provide setup tutorials and essential concepts and background information for complete beginners. You should start here if you are a complete beginner (i.e., you've not installed a code editor or written any code yet).

Want to master the essentials?

Our Core modules provide a structured set of tutorials teaching the essential skills and practices for being a successful front-end developer.

Beyond the basics?

Our Extension modules cover useful additional skills to learn as you start to expand your knowledge and develop specialisms. Go onto these after you finish our Core.

Working at a school?

Use our modules to guide your teaching, check out our Educators page for more ideas, or enroll your students in Scrimba's Frontend Developer Career PathMDN learning partner.

Getting our code examplesThe code examples you'll encounter in the Learning Area are all available on GitHub:

The easiest way to get them is to download a ZIP of the latest main code branch.
If you are familiar with Git and GitHub, you could also choose to clone the repository.
Contact usIf you want to get in touch with us about anything, use the communication channels. We'd love to hear from you about anything you think is wrong or missing on the site, requests for new learning topics, requests for help with items you don't understand, or any other questions or concerns.
If you're interested in helping develop/improve the content, take a look at how you can help and get in touch! We are more than happy to talk to you, whether you are a learner, teacher, experienced web developer, or someone else interested in helping to improve the learning experience.See also
The Frontend Developer Career Path MDN learning partner

Scrimba's Frontend Developer Career Path teaches all you need to know to be a competent front-end web developer, with fun interactive lessons and challenges, knowledgeable teachers, and a supportive community. Go from zero to landing your first front-end job! Many of the course components are available as standalone free versions.

Codecademy

A great interactive site for learning programming languages from scratch.

freeCodeCamp.org

Interactive site with tutorials and projects to learn web development.

Learn JavaScript

An excellent resource for aspiring web developers — Learn JavaScript in an interactive environment, with short lessons and interactive tests, guided by automated assessment. The first 40 lessons are free, and the complete course is available for a small one-time payment.

Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Apr 18, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nLearn web developmentThe essential skillset for new front-end developersWelcome to MDN Learning Web Development (also known as Learn). This resource provides a structured set of tutorials teaching the essential skills and practices for being a successful front-end developer, along with challenges and further recommended resources.About Learn web development

Teaches the essential skills and knowledge every front-end developer needs for career success and industry relevance, as defined in the MDN Curriculum.


Created by the MDN community and refined with insights from students, educators, and developers from the broader web community.


Designed to take you from "beginner" to "comfortable" (not "beginner" to "expert"), giving you enough knowledge to use more advanced resources (such as the rest of MDN).



Note:
Last updated: December 2024 (see changelog).
Don't know where to get started?
Never coded before?

Our Getting started modules provide setup tutorials and essential concepts and background information for complete beginners. You should start here if you are a complete beginner (i.e., you've not installed a code editor or written any code yet).

Want to master the essentials?

Our Core modules provide a structured set of tutorials teaching the essential skills and practices for being a successful front-end developer.

Beyond the basics?

Our Extension modules cover useful additional skills to learn as you start to expand your knowledge and develop specialisms. Go onto these after you finish our Core.

Working at a school?

Use our modules to guide your teaching, check out our Educators page for more ideas, or enroll your students in Scrimba's Frontend Developer Career PathMDN learning partner.

Getting our code examplesThe code examples you'll encounter in the Learning Area are all available on GitHub:

The easiest way to get them is to download a ZIP of the latest main code branch.
If you are familiar with Git and GitHub, you could also choose to clone the repository.
Contact usIf you want to get in touch with us about anything, use the communication channels. We'd love to hear from you about anything you think is wrong or missing on the site, requests for new learning topics, requests for help with items you don't understand, or any other questions or concerns.
If you're interested in helping develop/improve the content, take a look at how you can help and get in touch! We are more than happy to talk to you, whether you are a learner, teacher, experienced web developer, or someone else interested in helping to improve the learning experience.See also
The Frontend Developer Career Path MDN learning partner

Scrimba's Frontend Developer Career Path teaches all you need to know to be a competent front-end web developer, with fun interactive lessons and challenges, knowledgeable teachers, and a supportive community. Go from zero to landing your first front-end job! Many of the course components are available as standalone free versions.

Codecademy

A great interactive site for learning programming languages from scratch.

freeCodeCamp.org

Interactive site with tutorials and projects to learn web development.

Learn JavaScript

An excellent resource for aspiring web developers — Learn JavaScript in an interactive environment, with short lessons and interactive tests, guided by automated assessment. The first 40 lessons are free, and the complete course is available for a small one-time payment.

Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Apr 18, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nStructuring content with HTML Overview: Core learning modules Next  
HTML is the technology that defines the content and structure of any website. Written properly, it should also define the semantics (meaning) of the content in a machine-readable way, which is vital for accessibility, search engine optimization, and making use of the built-in features browsers provide for content to work optimally. This module covers the basics of the language, before looking at key areas such as document structure, links, lists, images, forms, and more.PrerequisitesBefore starting this module, you don't need any previous HTML knowledge, but you should have at least basic familiarity with using computers and using the web passively (i.e., just looking at it and consuming content). You should have a basic work environment set up (as detailed in Installing basic software), and understand how to create and manage files (as detailed in Dealing with files). Both are parts of our Getting started with the web complete beginner's module.

Note:
If you are working on a computer/tablet/other device where you don't have the ability to create your own files, you could try out (most of) the code examples in an online coding program such as JSBin or Glitch.
Tutorials and challenges
Basic HTML syntax

Covers the absolute basics of HTML, to get you started — we define elements, attributes, and other important terms, and show where they fit in the language. We also show how a typical HTML page is structured and how an HTML element is structured, and explain other important basic language features. Along the way, we'll play with some HTML to get you interested!

What's in the head? Web page metadata

The head of an HTML document is the part that is not displayed in the web browser when the page is loaded. It contains metadata information such as the page <title>, links to CSS (if you want to style your HTML content with CSS), links to custom favicons, and metadata (data about the HTML, such as who wrote it, and important keywords that describe the document).

Headings and paragraphs

One of HTML's main jobs is to give text structure so that a browser can display an HTML document the way its developer intends. This article explains how HTML can be used to provide fundamental page structure by defining headings and paragraphs.

Emphasis and importance

The previous article looked at why semantics are important in HTML, and focused on headings and paragraphs. This article continues on the theme of semantics, looking at HTML elements that apply emphasis and importance to text (parallel to italics and bold text in print media).

Lists

Lists are everywhere in life—from your shopping list to the list of directions you subconsciously follow to get to your house every day, to the lists of instructions you are following in these tutorials! It may not surprise you that HTML has a convenient set of elements that allows us to define different types of list. On the web, we have three types of lists: unordered, ordered, and description lists. This lesson shows you how to use the different types.

Structuring documents

In addition to defining individual parts of your page (such as "a paragraph" or "an image"), HTML also boasts a number of block level elements used to define areas of your website (such as "the header", "the navigation menu", "the main content column"). This article looks into how to plan a basic website structure, and write the HTML to represent this structure.

Advanced text features

There are many other elements in HTML for defining text semantics, which we didn't get to in the Emphasis and importance article. The elements described in this article are less known, but still useful to know about (and this is still not a complete list by any means). Here you'll learn about marking up quotations, computer code and other related text, subscript and superscript, contact information, and more.

Creating links

Links (also known as hyperlinks) are really important — they are what makes the Web a web. This article shows the syntax required to make a link, and discusses link best practices.

Marking up a letter Challenge

We all learn to write a letter sooner or later; it is also a useful example to test our text formatting skills. In this challenge, you'll have a letter to mark up as a test for your HTML text formatting skills, as well as hyperlinks and proper use of the HTML <head> element.

Structuring a page of content Challenge

Structuring a page of content ready for laying it out using CSS is a very important skill to master, so in this challenge you'll be tested on your ability to think about how a page might end up looking, and choose appropriate structural semantics to build a layout on top of.

HTML images

In the beginning, the web was just text, and it was really quite boring. Fortunately, it wasn't too long before the ability to embed images (and other more interesting types of content) inside web pages was added. In this article we'll look at how to use the <img> element in depth, including the basics, annotating it with captions using <figure>, and detailing how it relates to CSS background images.

HTML video and audio

Now that we are comfortable with adding simple images to a webpage, the next step is to start adding video and audio players to your HTML documents! In this article we'll look at doing just that with the <video> and <audio> elements; we'll then finish off by looking at how to add captions/subtitles to your videos.

Mozilla splash page Challenge

In this challenge, we'll test your knowledge of some of the techniques discussed in the last couple of lessons, getting you to add some images and video to a funky splash page all about Mozilla!

HTML table basics

This article gets you started with HTML tables, covering the very basics such as rows, cells, headings, making cells span multiple columns and rows, and how to group together all the cells in a column for styling purposes.

HTML table accessibility

In this article we look at more HTML table accessibility features such as captions/summaries, grouping your rows into table head, body and footer sections, and scoping columns and rows.

Structuring a planet data table Challenge

In this challenge, we provide you with some data on the planets in our solar system. Your job is to structure it into an accessible HTML table.

Forms and buttons in HTML

HTML forms and buttons are powerful tools for interacting with users — most commonly they are used for collecting data from users or allowing them to control a user interface. In this article we provide an introduction to the basics of forms and buttons.

Debugging HTML

Writing HTML is fine, but what if something goes wrong, and you can't work out where the error in the code is? This article will introduce you to some tools that can help you find and fix errors in HTML.

Test your skills: HTML

This page lists HTML tests you can try so you can verify if you've understood the content in this module.

Additional tutorialsThese tutorials are not part of the learning pathway, but they are interesting nonetheless — you should consider these as stretch goals, to optionally study when you are done with the main Core articles.

Including vector graphics in HTML

Vector graphics are very useful in many circumstances — they have small file sizes and are highly scalable, so they don't pixelate when zoomed in or blown up to a large size. In this article we'll show you how to include one in your webpage.

From object to iframe — general embedding technologies

Developers commonly think of embedding media such as images, video and audio into web pages. In this article we take somewhat of a sideways step, looking at some elements that allow you to embed a wide variety of content types into your webpages: the <iframe>, <embed> and <object> elements. <iframe>s are for embedding other web pages, and the other two allow you to embed external resources such as PDF files.

See also
Learn HTML and CSS, Scrimba MDN learning partner

Scrimba's Learn HTML and CSS course teaches you HTML and CSS through building and deploying five awesome projects, with fun interactive lessons and challenges taught by knowledgeable teachers.

Learn HTML, Codecademy

Another useful resource for learning HTML basics.

The basics of semantic HTML, Scrimba MDN learning partner

This interactive lesson provides a useful description of HTML, with particular emphasis on why the semantic aspect of it is important.


 Overview: Core learning modules Next\n\nStructuring content with HTML Overview: Core learning modules Next  
HTML is the technology that defines the content and structure of any website. Written properly, it should also define the semantics (meaning) of the content in a machine-readable way, which is vital for accessibility, search engine optimization, and making use of the built-in features browsers provide for content to work optimally. This module covers the basics of the language, before looking at key areas such as document structure, links, lists, images, forms, and more.PrerequisitesBefore starting this module, you don't need any previous HTML knowledge, but you should have at least basic familiarity with using computers and using the web passively (i.e., just looking at it and consuming content). You should have a basic work environment set up (as detailed in Installing basic software), and understand how to create and manage files (as detailed in Dealing with files). Both are parts of our Getting started with the web complete beginner's module.

Note:
If you are working on a computer/tablet/other device where you don't have the ability to create your own files, you could try out (most of) the code examples in an online coding program such as JSBin or Glitch.
Tutorials and challenges
Basic HTML syntax

Covers the absolute basics of HTML, to get you started — we define elements, attributes, and other important terms, and show where they fit in the language. We also show how a typical HTML page is structured and how an HTML element is structured, and explain other important basic language features. Along the way, we'll play with some HTML to get you interested!

What's in the head? Web page metadata

The head of an HTML document is the part that is not displayed in the web browser when the page is loaded. It contains metadata information such as the page <title>, links to CSS (if you want to style your HTML content with CSS), links to custom favicons, and metadata (data about the HTML, such as who wrote it, and important keywords that describe the document).

Headings and paragraphs

One of HTML's main jobs is to give text structure so that a browser can display an HTML document the way its developer intends. This article explains how HTML can be used to provide fundamental page structure by defining headings and paragraphs.

Emphasis and importance

The previous article looked at why semantics are important in HTML, and focused on headings and paragraphs. This article continues on the theme of semantics, looking at HTML elements that apply emphasis and importance to text (parallel to italics and bold text in print media).

Lists

Lists are everywhere in life—from your shopping list to the list of directions you subconsciously follow to get to your house every day, to the lists of instructions you are following in these tutorials! It may not surprise you that HTML has a convenient set of elements that allows us to define different types of list. On the web, we have three types of lists: unordered, ordered, and description lists. This lesson shows you how to use the different types.

Structuring documents

In addition to defining individual parts of your page (such as "a paragraph" or "an image"), HTML also boasts a number of block level elements used to define areas of your website (such as "the header", "the navigation menu", "the main content column"). This article looks into how to plan a basic website structure, and write the HTML to represent this structure.

Advanced text features

There are many other elements in HTML for defining text semantics, which we didn't get to in the Emphasis and importance article. The elements described in this article are less known, but still useful to know about (and this is still not a complete list by any means). Here you'll learn about marking up quotations, computer code and other related text, subscript and superscript, contact information, and more.

Creating links

Links (also known as hyperlinks) are really important — they are what makes the Web a web. This article shows the syntax required to make a link, and discusses link best practices.

Marking up a letter Challenge

We all learn to write a letter sooner or later; it is also a useful example to test our text formatting skills. In this challenge, you'll have a letter to mark up as a test for your HTML text formatting skills, as well as hyperlinks and proper use of the HTML <head> element.

Structuring a page of content Challenge

Structuring a page of content ready for laying it out using CSS is a very important skill to master, so in this challenge you'll be tested on your ability to think about how a page might end up looking, and choose appropriate structural semantics to build a layout on top of.

HTML images

In the beginning, the web was just text, and it was really quite boring. Fortunately, it wasn't too long before the ability to embed images (and other more interesting types of content) inside web pages was added. In this article we'll look at how to use the <img> element in depth, including the basics, annotating it with captions using <figure>, and detailing how it relates to CSS background images.

HTML video and audio

Now that we are comfortable with adding simple images to a webpage, the next step is to start adding video and audio players to your HTML documents! In this article we'll look at doing just that with the <video> and <audio> elements; we'll then finish off by looking at how to add captions/subtitles to your videos.

Mozilla splash page Challenge

In this challenge, we'll test your knowledge of some of the techniques discussed in the last couple of lessons, getting you to add some images and video to a funky splash page all about Mozilla!

HTML table basics

This article gets you started with HTML tables, covering the very basics such as rows, cells, headings, making cells span multiple columns and rows, and how to group together all the cells in a column for styling purposes.

HTML table accessibility

In this article we look at more HTML table accessibility features such as captions/summaries, grouping your rows into table head, body and footer sections, and scoping columns and rows.

Structuring a planet data table Challenge

In this challenge, we provide you with some data on the planets in our solar system. Your job is to structure it into an accessible HTML table.

Forms and buttons in HTML

HTML forms and buttons are powerful tools for interacting with users — most commonly they are used for collecting data from users or allowing them to control a user interface. In this article we provide an introduction to the basics of forms and buttons.

Debugging HTML

Writing HTML is fine, but what if something goes wrong, and you can't work out where the error in the code is? This article will introduce you to some tools that can help you find and fix errors in HTML.

Test your skills: HTML

This page lists HTML tests you can try so you can verify if you've understood the content in this module.

Additional tutorialsThese tutorials are not part of the learning pathway, but they are interesting nonetheless — you should consider these as stretch goals, to optionally study when you are done with the main Core articles.

Including vector graphics in HTML

Vector graphics are very useful in many circumstances — they have small file sizes and are highly scalable, so they don't pixelate when zoomed in or blown up to a large size. In this article we'll show you how to include one in your webpage.

From object to iframe — general embedding technologies

Developers commonly think of embedding media such as images, video and audio into web pages. In this article we take somewhat of a sideways step, looking at some elements that allow you to embed a wide variety of content types into your webpages: the <iframe>, <embed> and <object> elements. <iframe>s are for embedding other web pages, and the other two allow you to embed external resources such as PDF files.

See also
Learn HTML and CSS, Scrimba MDN learning partner

Scrimba's Learn HTML and CSS course teaches you HTML and CSS through building and deploying five awesome projects, with fun interactive lessons and challenges taught by knowledgeable teachers.

Learn HTML, Codecademy

Another useful resource for learning HTML basics.

The basics of semantic HTML, Scrimba MDN learning partner

This interactive lesson provides a useful description of HTML, with particular emphasis on why the semantic aspect of it is important.


 Overview: Core learning modules Next  Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Apr 18, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nStructuring content with HTML Overview: Core learning modules Next  
HTML is the technology that defines the content and structure of any website. Written properly, it should also define the semantics (meaning) of the content in a machine-readable way, which is vital for accessibility, search engine optimization, and making use of the built-in features browsers provide for content to work optimally. This module covers the basics of the language, before looking at key areas such as document structure, links, lists, images, forms, and more.PrerequisitesBefore starting this module, you don't need any previous HTML knowledge, but you should have at least basic familiarity with using computers and using the web passively (i.e., just looking at it and consuming content). You should have a basic work environment set up (as detailed in Installing basic software), and understand how to create and manage files (as detailed in Dealing with files). Both are parts of our Getting started with the web complete beginner's module.

Note:
If you are working on a computer/tablet/other device where you don't have the ability to create your own files, you could try out (most of) the code examples in an online coding program such as JSBin or Glitch.
Tutorials and challenges
Basic HTML syntax

Covers the absolute basics of HTML, to get you started — we define elements, attributes, and other important terms, and show where they fit in the language. We also show how a typical HTML page is structured and how an HTML element is structured, and explain other important basic language features. Along the way, we'll play with some HTML to get you interested!

What's in the head? Web page metadata

The head of an HTML document is the part that is not displayed in the web browser when the page is loaded. It contains metadata information such as the page <title>, links to CSS (if you want to style your HTML content with CSS), links to custom favicons, and metadata (data about the HTML, such as who wrote it, and important keywords that describe the document).

Headings and paragraphs

One of HTML's main jobs is to give text structure so that a browser can display an HTML document the way its developer intends. This article explains how HTML can be used to provide fundamental page structure by defining headings and paragraphs.

Emphasis and importance

The previous article looked at why semantics are important in HTML, and focused on headings and paragraphs. This article continues on the theme of semantics, looking at HTML elements that apply emphasis and importance to text (parallel to italics and bold text in print media).

Lists

Lists are everywhere in life—from your shopping list to the list of directions you subconsciously follow to get to your house every day, to the lists of instructions you are following in these tutorials! It may not surprise you that HTML has a convenient set of elements that allows us to define different types of list. On the web, we have three types of lists: unordered, ordered, and description lists. This lesson shows you how to use the different types.

Structuring documents

In addition to defining individual parts of your page (such as "a paragraph" or "an image"), HTML also boasts a number of block level elements used to define areas of your website (such as "the header", "the navigation menu", "the main content column"). This article looks into how to plan a basic website structure, and write the HTML to represent this structure.

Advanced text features

There are many other elements in HTML for defining text semantics, which we didn't get to in the Emphasis and importance article. The elements described in this article are less known, but still useful to know about (and this is still not a complete list by any means). Here you'll learn about marking up quotations, computer code and other related text, subscript and superscript, contact information, and more.

Creating links

Links (also known as hyperlinks) are really important — they are what makes the Web a web. This article shows the syntax required to make a link, and discusses link best practices.

Marking up a letter Challenge

We all learn to write a letter sooner or later; it is also a useful example to test our text formatting skills. In this challenge, you'll have a letter to mark up as a test for your HTML text formatting skills, as well as hyperlinks and proper use of the HTML <head> element.

Structuring a page of content Challenge

Structuring a page of content ready for laying it out using CSS is a very important skill to master, so in this challenge you'll be tested on your ability to think about how a page might end up looking, and choose appropriate structural semantics to build a layout on top of.

HTML images

In the beginning, the web was just text, and it was really quite boring. Fortunately, it wasn't too long before the ability to embed images (and other more interesting types of content) inside web pages was added. In this article we'll look at how to use the <img> element in depth, including the basics, annotating it with captions using <figure>, and detailing how it relates to CSS background images.

HTML video and audio

Now that we are comfortable with adding simple images to a webpage, the next step is to start adding video and audio players to your HTML documents! In this article we'll look at doing just that with the <video> and <audio> elements; we'll then finish off by looking at how to add captions/subtitles to your videos.

Mozilla splash page Challenge

In this challenge, we'll test your knowledge of some of the techniques discussed in the last couple of lessons, getting you to add some images and video to a funky splash page all about Mozilla!

HTML table basics

This article gets you started with HTML tables, covering the very basics such as rows, cells, headings, making cells span multiple columns and rows, and how to group together all the cells in a column for styling purposes.

HTML table accessibility

In this article we look at more HTML table accessibility features such as captions/summaries, grouping your rows into table head, body and footer sections, and scoping columns and rows.

Structuring a planet data table Challenge

In this challenge, we provide you with some data on the planets in our solar system. Your job is to structure it into an accessible HTML table.

Forms and buttons in HTML

HTML forms and buttons are powerful tools for interacting with users — most commonly they are used for collecting data from users or allowing them to control a user interface. In this article we provide an introduction to the basics of forms and buttons.

Debugging HTML

Writing HTML is fine, but what if something goes wrong, and you can't work out where the error in the code is? This article will introduce you to some tools that can help you find and fix errors in HTML.

Test your skills: HTML

This page lists HTML tests you can try so you can verify if you've understood the content in this module.

Additional tutorialsThese tutorials are not part of the learning pathway, but they are interesting nonetheless — you should consider these as stretch goals, to optionally study when you are done with the main Core articles.

Including vector graphics in HTML

Vector graphics are very useful in many circumstances — they have small file sizes and are highly scalable, so they don't pixelate when zoomed in or blown up to a large size. In this article we'll show you how to include one in your webpage.

From object to iframe — general embedding technologies

Developers commonly think of embedding media such as images, video and audio into web pages. In this article we take somewhat of a sideways step, looking at some elements that allow you to embed a wide variety of content types into your webpages: the <iframe>, <embed> and <object> elements. <iframe>s are for embedding other web pages, and the other two allow you to embed external resources such as PDF files.

See also
Learn HTML and CSS, Scrimba MDN learning partner

Scrimba's Learn HTML and CSS course teaches you HTML and CSS through building and deploying five awesome projects, with fun interactive lessons and challenges taught by knowledgeable teachers.

Learn HTML, Codecademy

Another useful resource for learning HTML basics.

The basics of semantic HTML, Scrimba MDN learning partner

This interactive lesson provides a useful description of HTML, with particular emphasis on why the semantic aspect of it is important.


 Overview: Core learning modules Next  Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Apr 18, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nCSS styling basics Overview: Core learning modules Next  
CSS (Cascading Style Sheets) is used to style and layout web pages — for example, to alter the font, color, size, and spacing of your content, split it into multiple columns, or add animations and other decorative features. This module provides all the CSS fundamentals you'll need for now, including syntax, features, and techniques.PrerequisitesBefore starting this module, you should have a basic work environment set up (as detailed in Installing basic software), and understand how to create and manage files (as detailed in Dealing with files). You should also be familiar with HTML (work through our Structuring content with HTML module if not).

Note:
If you are working on a computer/tablet/other device where you don't have the ability to create your own files, you could try out (most of) the code examples in an online coding program such as JSBin or Glitch.
Tutorials and challenges
What is CSS?

CSS allows you to create great-looking web pages, but how does it work under the hood? This article explains what CSS, what the basic syntax looks like, and how your browser applies CSS to HTML to style it.

Getting started with CSS

In this article, we will take a simple HTML document and apply CSS to it, learning some practical details of the language along the way. We will also review the CSS syntax features you've not looked at yet.

Styling a biography page Challenge

In this challenge you will style a simple bio page, testing you on some of the skills you learned in the last couple of lessons including writing selectors and text styling.

Basic CSS selectors

In this article we'll recap some selector fundamentals, including the basic type, class, and ID selectors.

Attribute selectors

As you know from your study of HTML, elements can have attributes that give further detail about the element being marked up. In CSS you can use attribute selectors to target elements with certain attributes. This lesson will show you how to use these very useful selectors.

Pseudo-classes and pseudo-elements

The next set of selectors we will look at are referred to as pseudo-classes and pseudo-elements. There are a large number of these, and they often serve quite specific purposes. Once you know how to use them, you can look through the different types to see if there is something which works for the task you are trying to achieve.

Combinators

The final selectors we will look at are called combinators. Combinators are used to combine other selectors in a way that allows us to select elements based on their location in the DOM relative to other elements (for example, child or sibling).

The box model

Everything in CSS has a box around it, and understanding these boxes is key to being able to create more complex layouts with CSS, or to align items with other items. In this lesson, we will take a look at the CSS Box model. You'll get an understanding of how it works and the terminology that relates to it.

Handling conflicts

The aim of this lesson is to develop your understanding of some of the most fundamental concepts of CSS — the cascade, specificity, and inheritance — which control how CSS is applied to HTML and how conflicts between style declarations are resolved.

Values and units

CSS rules contain declarations, which in turn are composed of properties and values. Each property used in CSS has a value type that describes what kind of values it is allowed to have. In this lesson, we will take a look at some of the most frequently used value types, what they are, and how they work.

Sizing items in CSS

Understanding how big the different features in your design will be is important. In this lesson we will summarize the various ways elements get a size via CSS and define a few terms about sizing that will help you in the future.

Backgrounds and borders

In this lesson, we will take a look at some of the creative things you can do with CSS backgrounds and borders. From adding gradients, background images, and rounded corners, backgrounds and borders are the answer to a lot of styling questions in CSS.

Overflowing content

Overflow is what happens when there is too much content to fit inside an element box. In this lesson, you will learn how to manage overflow using CSS.

Images, media, and form elements

In this lesson we will take a look at how certain special elements are treated in CSS. Images, other media, and form elements behave a little differently from regular boxes in terms of your ability to style them with CSS. Understanding what is and isn't possible can save some frustration, and this lesson will highlight some of the main things that you need to know.

Styling tables

Styling an HTML table isn't the most glamorous job in the world, but sometimes we all have to do it. This article explains how to make HTML tables look good, with some specific table styling techniques highlighted.

Debugging CSS

This article will give you guidance on how to go about debugging a CSS problem, and show you how the DevTools included in all modern browsers can help you to find out what is going on.

Challenge: Fundamental CSS comprehension Challenge

This challenge provides a number of related exercises that must be completed in order to create the final design — a business card/gamer card/social media profile.

Challenge: Creating fancy letterheaded paper Challenge

If you want to make the right impression, writing a letter on nice letterheaded paper can be a really good start. In this challenge you will create an online template to achieve such a look.

Challenge: A cool-looking box Challenge

In this challenge, you'll get some more practice in creating cool-looking boxes by trying to create an eye-catching box.

Additional tutorialsThese tutorials are not part of the learning pathway, but they are interesting nonetheless — you should consider these as stretch goals, to optionally study when you are done with the main Core articles.

Advanced styling effects

This article will give you guidance on how to go about debugging a CSS problem, and show you how the DevTools included in all modern browsers can help you to find out what is going on.

Cascade layers

This lesson aims to introduce you to cascade layers, a more advanced feature that builds on the fundamental concepts of the CSS cascade and CSS specificity.

Handling different text directions

In recent years, CSS has evolved in order to better support different directionality of content, including right-to-left but also top-to-bottom content (such as Japanese) — these different directionalities are called writing modes. As you progress in your study and begin to work with layout, an understanding of writing modes will be very helpful to you, therefore we will introduce them in this article.

Organizing CSS

As you start to work on larger stylesheets and big projects you will discover that maintaining a huge CSS file can be challenging. In this article we will take a brief look at some best practices for writing your CSS to make it easily maintainable, and some of the solutions you will find in use by others to help improve maintainability.

See also
Learn HTML and CSS, Scrimba MDN learning partner

Scrimba's Learn HTML and CSS course teaches you HTML and CSS through building and deploying five awesome projects, with fun interactive lessons and challenges taught by knowledgeable teachers.

Write your first lines of CSS!, Scrimba MDN learning partner

This interactive lesson provides a useful introduction to CSS syntax.


 Overview: Core learning modules Next\n\nCSS styling basics Overview: Core learning modules Next  
CSS (Cascading Style Sheets) is used to style and layout web pages — for example, to alter the font, color, size, and spacing of your content, split it into multiple columns, or add animations and other decorative features. This module provides all the CSS fundamentals you'll need for now, including syntax, features, and techniques.PrerequisitesBefore starting this module, you should have a basic work environment set up (as detailed in Installing basic software), and understand how to create and manage files (as detailed in Dealing with files). You should also be familiar with HTML (work through our Structuring content with HTML module if not).

Note:
If you are working on a computer/tablet/other device where you don't have the ability to create your own files, you could try out (most of) the code examples in an online coding program such as JSBin or Glitch.
Tutorials and challenges
What is CSS?

CSS allows you to create great-looking web pages, but how does it work under the hood? This article explains what CSS, what the basic syntax looks like, and how your browser applies CSS to HTML to style it.

Getting started with CSS

In this article, we will take a simple HTML document and apply CSS to it, learning some practical details of the language along the way. We will also review the CSS syntax features you've not looked at yet.

Styling a biography page Challenge

In this challenge you will style a simple bio page, testing you on some of the skills you learned in the last couple of lessons including writing selectors and text styling.

Basic CSS selectors

In this article we'll recap some selector fundamentals, including the basic type, class, and ID selectors.

Attribute selectors

As you know from your study of HTML, elements can have attributes that give further detail about the element being marked up. In CSS you can use attribute selectors to target elements with certain attributes. This lesson will show you how to use these very useful selectors.

Pseudo-classes and pseudo-elements

The next set of selectors we will look at are referred to as pseudo-classes and pseudo-elements. There are a large number of these, and they often serve quite specific purposes. Once you know how to use them, you can look through the different types to see if there is something which works for the task you are trying to achieve.

Combinators

The final selectors we will look at are called combinators. Combinators are used to combine other selectors in a way that allows us to select elements based on their location in the DOM relative to other elements (for example, child or sibling).

The box model

Everything in CSS has a box around it, and understanding these boxes is key to being able to create more complex layouts with CSS, or to align items with other items. In this lesson, we will take a look at the CSS Box model. You'll get an understanding of how it works and the terminology that relates to it.

Handling conflicts

The aim of this lesson is to develop your understanding of some of the most fundamental concepts of CSS — the cascade, specificity, and inheritance — which control how CSS is applied to HTML and how conflicts between style declarations are resolved.

Values and units

CSS rules contain declarations, which in turn are composed of properties and values. Each property used in CSS has a value type that describes what kind of values it is allowed to have. In this lesson, we will take a look at some of the most frequently used value types, what they are, and how they work.

Sizing items in CSS

Understanding how big the different features in your design will be is important. In this lesson we will summarize the various ways elements get a size via CSS and define a few terms about sizing that will help you in the future.

Backgrounds and borders

In this lesson, we will take a look at some of the creative things you can do with CSS backgrounds and borders. From adding gradients, background images, and rounded corners, backgrounds and borders are the answer to a lot of styling questions in CSS.

Overflowing content

Overflow is what happens when there is too much content to fit inside an element box. In this lesson, you will learn how to manage overflow using CSS.

Images, media, and form elements

In this lesson we will take a look at how certain special elements are treated in CSS. Images, other media, and form elements behave a little differently from regular boxes in terms of your ability to style them with CSS. Understanding what is and isn't possible can save some frustration, and this lesson will highlight some of the main things that you need to know.

Styling tables

Styling an HTML table isn't the most glamorous job in the world, but sometimes we all have to do it. This article explains how to make HTML tables look good, with some specific table styling techniques highlighted.

Debugging CSS

This article will give you guidance on how to go about debugging a CSS problem, and show you how the DevTools included in all modern browsers can help you to find out what is going on.

Challenge: Fundamental CSS comprehension Challenge

This challenge provides a number of related exercises that must be completed in order to create the final design — a business card/gamer card/social media profile.

Challenge: Creating fancy letterheaded paper Challenge

If you want to make the right impression, writing a letter on nice letterheaded paper can be a really good start. In this challenge you will create an online template to achieve such a look.

Challenge: A cool-looking box Challenge

In this challenge, you'll get some more practice in creating cool-looking boxes by trying to create an eye-catching box.

Additional tutorialsThese tutorials are not part of the learning pathway, but they are interesting nonetheless — you should consider these as stretch goals, to optionally study when you are done with the main Core articles.

Advanced styling effects

This article will give you guidance on how to go about debugging a CSS problem, and show you how the DevTools included in all modern browsers can help you to find out what is going on.

Cascade layers

This lesson aims to introduce you to cascade layers, a more advanced feature that builds on the fundamental concepts of the CSS cascade and CSS specificity.

Handling different text directions

In recent years, CSS has evolved in order to better support different directionality of content, including right-to-left but also top-to-bottom content (such as Japanese) — these different directionalities are called writing modes. As you progress in your study and begin to work with layout, an understanding of writing modes will be very helpful to you, therefore we will introduce them in this article.

Organizing CSS

As you start to work on larger stylesheets and big projects you will discover that maintaining a huge CSS file can be challenging. In this article we will take a brief look at some best practices for writing your CSS to make it easily maintainable, and some of the solutions you will find in use by others to help improve maintainability.

See also
Learn HTML and CSS, Scrimba MDN learning partner

Scrimba's Learn HTML and CSS course teaches you HTML and CSS through building and deploying five awesome projects, with fun interactive lessons and challenges taught by knowledgeable teachers.

Write your first lines of CSS!, Scrimba MDN learning partner

This interactive lesson provides a useful introduction to CSS syntax.


 Overview: Core learning modules Next  Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Apr 15, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nCSS styling basics Overview: Core learning modules Next  
CSS (Cascading Style Sheets) is used to style and layout web pages — for example, to alter the font, color, size, and spacing of your content, split it into multiple columns, or add animations and other decorative features. This module provides all the CSS fundamentals you'll need for now, including syntax, features, and techniques.PrerequisitesBefore starting this module, you should have a basic work environment set up (as detailed in Installing basic software), and understand how to create and manage files (as detailed in Dealing with files). You should also be familiar with HTML (work through our Structuring content with HTML module if not).

Note:
If you are working on a computer/tablet/other device where you don't have the ability to create your own files, you could try out (most of) the code examples in an online coding program such as JSBin or Glitch.
Tutorials and challenges
What is CSS?

CSS allows you to create great-looking web pages, but how does it work under the hood? This article explains what CSS, what the basic syntax looks like, and how your browser applies CSS to HTML to style it.

Getting started with CSS

In this article, we will take a simple HTML document and apply CSS to it, learning some practical details of the language along the way. We will also review the CSS syntax features you've not looked at yet.

Styling a biography page Challenge

In this challenge you will style a simple bio page, testing you on some of the skills you learned in the last couple of lessons including writing selectors and text styling.

Basic CSS selectors

In this article we'll recap some selector fundamentals, including the basic type, class, and ID selectors.

Attribute selectors

As you know from your study of HTML, elements can have attributes that give further detail about the element being marked up. In CSS you can use attribute selectors to target elements with certain attributes. This lesson will show you how to use these very useful selectors.

Pseudo-classes and pseudo-elements

The next set of selectors we will look at are referred to as pseudo-classes and pseudo-elements. There are a large number of these, and they often serve quite specific purposes. Once you know how to use them, you can look through the different types to see if there is something which works for the task you are trying to achieve.

Combinators

The final selectors we will look at are called combinators. Combinators are used to combine other selectors in a way that allows us to select elements based on their location in the DOM relative to other elements (for example, child or sibling).

The box model

Everything in CSS has a box around it, and understanding these boxes is key to being able to create more complex layouts with CSS, or to align items with other items. In this lesson, we will take a look at the CSS Box model. You'll get an understanding of how it works and the terminology that relates to it.

Handling conflicts

The aim of this lesson is to develop your understanding of some of the most fundamental concepts of CSS — the cascade, specificity, and inheritance — which control how CSS is applied to HTML and how conflicts between style declarations are resolved.

Values and units

CSS rules contain declarations, which in turn are composed of properties and values. Each property used in CSS has a value type that describes what kind of values it is allowed to have. In this lesson, we will take a look at some of the most frequently used value types, what they are, and how they work.

Sizing items in CSS

Understanding how big the different features in your design will be is important. In this lesson we will summarize the various ways elements get a size via CSS and define a few terms about sizing that will help you in the future.

Backgrounds and borders

In this lesson, we will take a look at some of the creative things you can do with CSS backgrounds and borders. From adding gradients, background images, and rounded corners, backgrounds and borders are the answer to a lot of styling questions in CSS.

Overflowing content

Overflow is what happens when there is too much content to fit inside an element box. In this lesson, you will learn how to manage overflow using CSS.

Images, media, and form elements

In this lesson we will take a look at how certain special elements are treated in CSS. Images, other media, and form elements behave a little differently from regular boxes in terms of your ability to style them with CSS. Understanding what is and isn't possible can save some frustration, and this lesson will highlight some of the main things that you need to know.

Styling tables

Styling an HTML table isn't the most glamorous job in the world, but sometimes we all have to do it. This article explains how to make HTML tables look good, with some specific table styling techniques highlighted.

Debugging CSS

This article will give you guidance on how to go about debugging a CSS problem, and show you how the DevTools included in all modern browsers can help you to find out what is going on.

Challenge: Fundamental CSS comprehension Challenge

This challenge provides a number of related exercises that must be completed in order to create the final design — a business card/gamer card/social media profile.

Challenge: Creating fancy letterheaded paper Challenge

If you want to make the right impression, writing a letter on nice letterheaded paper can be a really good start. In this challenge you will create an online template to achieve such a look.

Challenge: A cool-looking box Challenge

In this challenge, you'll get some more practice in creating cool-looking boxes by trying to create an eye-catching box.

Additional tutorialsThese tutorials are not part of the learning pathway, but they are interesting nonetheless — you should consider these as stretch goals, to optionally study when you are done with the main Core articles.

Advanced styling effects

This article will give you guidance on how to go about debugging a CSS problem, and show you how the DevTools included in all modern browsers can help you to find out what is going on.

Cascade layers

This lesson aims to introduce you to cascade layers, a more advanced feature that builds on the fundamental concepts of the CSS cascade and CSS specificity.

Handling different text directions

In recent years, CSS has evolved in order to better support different directionality of content, including right-to-left but also top-to-bottom content (such as Japanese) — these different directionalities are called writing modes. As you progress in your study and begin to work with layout, an understanding of writing modes will be very helpful to you, therefore we will introduce them in this article.

Organizing CSS

As you start to work on larger stylesheets and big projects you will discover that maintaining a huge CSS file can be challenging. In this article we will take a brief look at some best practices for writing your CSS to make it easily maintainable, and some of the solutions you will find in use by others to help improve maintainability.

See also
Learn HTML and CSS, Scrimba MDN learning partner

Scrimba's Learn HTML and CSS course teaches you HTML and CSS through building and deploying five awesome projects, with fun interactive lessons and challenges taught by knowledgeable teachers.

Write your first lines of CSS!, Scrimba MDN learning partner

This interactive lesson provides a useful introduction to CSS syntax.


 Overview: Core learning modules Next  Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Apr 15, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nDynamic scripting with JavaScript Overview: Core learning modules Next  
JavaScript is a huge topic, with so many different features, styles, and techniques to learn, and so many APIs and tools built on top of it. This module focuses mostly on the essentials of the core language, plus some key surrounding topics — learning these topics will give you a solid basis to work from.PrerequisitesBefore starting this module, you don't need any previous JavaScript knowledge, but you should have worked through the previous modules in the course. You should at least know HTML and the basic fundamentals of CSS.

Note:
If you are working on a computer/tablet/other device where you don't have the ability to create your own files, you could try out (most of) the code examples in an online coding program such as JSBin or Glitch.
Tutorials and challenges
What is JavaScript?

Welcome to the MDN beginner's JavaScript course! In this first article we will look at JavaScript from a high level, answering questions such as "what is it?", and "what is it doing?", and making sure you are comfortable with JavaScript's purpose.

A first splash into JavaScript

Now you've learned something about the theory of JavaScript, and what you can do with it, we are going to give you a crash course on the basic features of JavaScript via a completely practical tutorial. Here you'll build up a simple "Guess the number" game, step by step.

What went wrong? Troubleshooting JavaScript

When you built up the "Guess the number" game in the previous article, you may have found that it didn't work. Never fear — this article aims to save you from tearing your hair out over such problems by providing you with some simple tips on how to find and fix errors in JavaScript programs.

Storing the information you need — Variables

After reading the last couple of articles you should now know what JavaScript is, what it can do for you, how you use it alongside other web technologies, and what its main features look like from a high level. In this article, we will get down to the real basics, looking at how to work with the most basic building blocks of JavaScript — Variables.

Basic math in JavaScript — numbers and operators

At this point in the course, we discuss maths in JavaScript — how we can combine operators and other features to successfully manipulate numbers to do our bidding.

Handling text — strings in JavaScript

Next, we'll turn our attention to strings — this is what pieces of text are called in programming. In this article, we'll look at all the common things that you really ought to know about strings when learning JavaScript, such as creating strings, escaping quotes in strings, and joining them together.

Useful string methods

Now we've looked at the very basics of strings, let's move up a gear and start thinking about what useful operations we can do on strings with built-in methods, such as finding the length of a text string, joining and splitting strings, substituting one character in a string for another, and more.

Arrays

In this lesson we'll look at arrays — a neat way of storing a list of data items under a single variable name. Here we look at why this is useful, then explore how to create an array, retrieve, add, and remove items stored in an array, and more besides.

Challenge: Silly story generator Challenge

In this challenge, you'll be tasked with taking some of the knowledge you've picked up in this module's articles and applying it to creating a fun app that generates random silly stories. Have fun!

Making decisions in your code — conditionals

In any programming language, the code needs to make decisions and carry out actions accordingly depending on different inputs. For example, in a game, if the player's number of lives is 0, then it's game over. In a weather app, if it is being looked at in the morning, show a sunrise graphic; show stars and a moon if it is nighttime. In this article, we'll explore how so-called conditional statements work in JavaScript.

Looping code

Programming languages are very useful for rapidly completing repetitive tasks, from multiple basic calculations to just about any other situation where you've got a lot of similar items of work to complete. Here we'll look at the loop structures available in JavaScript that handle such needs.

Functions — reusable blocks of code

Another essential concept in coding is functions, which allow you to store a piece of code that does a single task inside a defined block, and then call that code whenever you need it using a single short command — rather than having to type out the same code multiple times. In this article we'll explore fundamental concepts behind functions such as basic syntax, how to invoke and define them, scope, and parameters.

Build your own function

With most of the essential theory dealt with in the previous article, this article provides practical experience. Here you will get some practice building your own, custom function. Along the way, we'll also explain some useful details of dealing with functions.

Function return values

There's one last essential concept about functions for us to discuss — return values. Some functions don't return a significant value, but others do. It's important to understand what their values are, how to use them in your code, and how to make functions return useful values. We'll cover all of these below.

Introduction to events

In this article, we discuss some important concepts surrounding events, and look at the fundamentals of how they work in browsers.

Event bubbling

This article introduces the concepts of event bubbling, event capture, and event delegation, which are all about what happens when you add a listener to an element that contains another element, and an event then happens to the contained element.

Challenge: Image gallery Challenge

Now that we've looked at the fundamental building blocks of JavaScript, we'll test your knowledge of loops, functions, conditionals and events by getting you to build a fairly common item you'll see on a lot of websites — a JavaScript-powered image gallery.

Object basics

In this article, we'll look at fundamental JavaScript object syntax, and revisit some JavaScript features that we've already seen earlier in the course, reiterating the fact that many of the features you've already dealt with are objects.

DOM scripting introduction

When writing web pages and apps, one of the most common things you'll want to do is change the document structure in some way. This is usually done by manipulating the Document Object Model (DOM) via a set of built-in browser APIs for controlling HTML and styling information. In this article we'll introduce you to DOM scripting.

Making network requests with JavaScript

Another very common task in modern websites and applications is making network requests to retrieve individual data items from the server to update sections of a webpage without having to load an entire new page. This seemingly small detail has had a huge impact on the performance and behavior of sites, so in this article, we'll explain the concept and look at technologies that make it possible.

Working with JSON

JavaScript Object Notation (JSON) is a standard text-based format for representing structured data based on JavaScript object syntax. It is commonly used for transmitting data in web applications (e.g., sending some data from the server to the client, so it can be displayed on a web page, or vice versa). You'll come across it quite often, so in this article, we give you all you need to work with JSON using JavaScript, including parsing JSON so you can access data within it, and creating JSON.

JavaScript debugging and error handling

In this lesson, we will return to the subject of debugging JavaScript (which we first looked at in What went wrong?). Here we will delve deeper into techniques for tracking down errors, but also look at how to code defensively and handle errors in your code, avoiding problems in the first place.

Test your skills: JavaScript

This page lists JavaScript tests you can try so you can verify if you've understood the content in this module.

See also
Scrimba: Learn JavaScript MDN learning partner

Scrimba's Learn JavaScript course teaches you JavaScript through solving 140+ interactive coding challenges, building projects including a game, a browser extension, and even a mobile app. Scrimba features fun interactive lessons taught by knowledgeable teachers.

Learn JavaScript

An excellent resource for aspiring web developers — Learn JavaScript in an interactive environment, with short lessons and interactive tests, guided by automated assessment. The first 40 lessons are free, and the complete course is available for a small one-time payment.


 Overview: Core learning modules Next\n\nDynamic scripting with JavaScript Overview: Core learning modules Next  
JavaScript is a huge topic, with so many different features, styles, and techniques to learn, and so many APIs and tools built on top of it. This module focuses mostly on the essentials of the core language, plus some key surrounding topics — learning these topics will give you a solid basis to work from.PrerequisitesBefore starting this module, you don't need any previous JavaScript knowledge, but you should have worked through the previous modules in the course. You should at least know HTML and the basic fundamentals of CSS.

Note:
If you are working on a computer/tablet/other device where you don't have the ability to create your own files, you could try out (most of) the code examples in an online coding program such as JSBin or Glitch.
Tutorials and challenges
What is JavaScript?

Welcome to the MDN beginner's JavaScript course! In this first article we will look at JavaScript from a high level, answering questions such as "what is it?", and "what is it doing?", and making sure you are comfortable with JavaScript's purpose.

A first splash into JavaScript

Now you've learned something about the theory of JavaScript, and what you can do with it, we are going to give you a crash course on the basic features of JavaScript via a completely practical tutorial. Here you'll build up a simple "Guess the number" game, step by step.

What went wrong? Troubleshooting JavaScript

When you built up the "Guess the number" game in the previous article, you may have found that it didn't work. Never fear — this article aims to save you from tearing your hair out over such problems by providing you with some simple tips on how to find and fix errors in JavaScript programs.

Storing the information you need — Variables

After reading the last couple of articles you should now know what JavaScript is, what it can do for you, how you use it alongside other web technologies, and what its main features look like from a high level. In this article, we will get down to the real basics, looking at how to work with the most basic building blocks of JavaScript — Variables.

Basic math in JavaScript — numbers and operators

At this point in the course, we discuss maths in JavaScript — how we can combine operators and other features to successfully manipulate numbers to do our bidding.

Handling text — strings in JavaScript

Next, we'll turn our attention to strings — this is what pieces of text are called in programming. In this article, we'll look at all the common things that you really ought to know about strings when learning JavaScript, such as creating strings, escaping quotes in strings, and joining them together.

Useful string methods

Now we've looked at the very basics of strings, let's move up a gear and start thinking about what useful operations we can do on strings with built-in methods, such as finding the length of a text string, joining and splitting strings, substituting one character in a string for another, and more.

Arrays

In this lesson we'll look at arrays — a neat way of storing a list of data items under a single variable name. Here we look at why this is useful, then explore how to create an array, retrieve, add, and remove items stored in an array, and more besides.

Challenge: Silly story generator Challenge

In this challenge, you'll be tasked with taking some of the knowledge you've picked up in this module's articles and applying it to creating a fun app that generates random silly stories. Have fun!

Making decisions in your code — conditionals

In any programming language, the code needs to make decisions and carry out actions accordingly depending on different inputs. For example, in a game, if the player's number of lives is 0, then it's game over. In a weather app, if it is being looked at in the morning, show a sunrise graphic; show stars and a moon if it is nighttime. In this article, we'll explore how so-called conditional statements work in JavaScript.

Looping code

Programming languages are very useful for rapidly completing repetitive tasks, from multiple basic calculations to just about any other situation where you've got a lot of similar items of work to complete. Here we'll look at the loop structures available in JavaScript that handle such needs.

Functions — reusable blocks of code

Another essential concept in coding is functions, which allow you to store a piece of code that does a single task inside a defined block, and then call that code whenever you need it using a single short command — rather than having to type out the same code multiple times. In this article we'll explore fundamental concepts behind functions such as basic syntax, how to invoke and define them, scope, and parameters.

Build your own function

With most of the essential theory dealt with in the previous article, this article provides practical experience. Here you will get some practice building your own, custom function. Along the way, we'll also explain some useful details of dealing with functions.

Function return values

There's one last essential concept about functions for us to discuss — return values. Some functions don't return a significant value, but others do. It's important to understand what their values are, how to use them in your code, and how to make functions return useful values. We'll cover all of these below.

Introduction to events

In this article, we discuss some important concepts surrounding events, and look at the fundamentals of how they work in browsers.

Event bubbling

This article introduces the concepts of event bubbling, event capture, and event delegation, which are all about what happens when you add a listener to an element that contains another element, and an event then happens to the contained element.

Challenge: Image gallery Challenge

Now that we've looked at the fundamental building blocks of JavaScript, we'll test your knowledge of loops, functions, conditionals and events by getting you to build a fairly common item you'll see on a lot of websites — a JavaScript-powered image gallery.

Object basics

In this article, we'll look at fundamental JavaScript object syntax, and revisit some JavaScript features that we've already seen earlier in the course, reiterating the fact that many of the features you've already dealt with are objects.

DOM scripting introduction

When writing web pages and apps, one of the most common things you'll want to do is change the document structure in some way. This is usually done by manipulating the Document Object Model (DOM) via a set of built-in browser APIs for controlling HTML and styling information. In this article we'll introduce you to DOM scripting.

Making network requests with JavaScript

Another very common task in modern websites and applications is making network requests to retrieve individual data items from the server to update sections of a webpage without having to load an entire new page. This seemingly small detail has had a huge impact on the performance and behavior of sites, so in this article, we'll explain the concept and look at technologies that make it possible.

Working with JSON

JavaScript Object Notation (JSON) is a standard text-based format for representing structured data based on JavaScript object syntax. It is commonly used for transmitting data in web applications (e.g., sending some data from the server to the client, so it can be displayed on a web page, or vice versa). You'll come across it quite often, so in this article, we give you all you need to work with JSON using JavaScript, including parsing JSON so you can access data within it, and creating JSON.

JavaScript debugging and error handling

In this lesson, we will return to the subject of debugging JavaScript (which we first looked at in What went wrong?). Here we will delve deeper into techniques for tracking down errors, but also look at how to code defensively and handle errors in your code, avoiding problems in the first place.

Test your skills: JavaScript

This page lists JavaScript tests you can try so you can verify if you've understood the content in this module.

See also
Scrimba: Learn JavaScript MDN learning partner

Scrimba's Learn JavaScript course teaches you JavaScript through solving 140+ interactive coding challenges, building projects including a game, a browser extension, and even a mobile app. Scrimba features fun interactive lessons taught by knowledgeable teachers.

Learn JavaScript

An excellent resource for aspiring web developers — Learn JavaScript in an interactive environment, with short lessons and interactive tests, guided by automated assessment. The first 40 lessons are free, and the complete course is available for a small one-time payment.


 Overview: Core learning modules Next  Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Apr 15, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nDynamic scripting with JavaScript Overview: Core learning modules Next  
JavaScript is a huge topic, with so many different features, styles, and techniques to learn, and so many APIs and tools built on top of it. This module focuses mostly on the essentials of the core language, plus some key surrounding topics — learning these topics will give you a solid basis to work from.PrerequisitesBefore starting this module, you don't need any previous JavaScript knowledge, but you should have worked through the previous modules in the course. You should at least know HTML and the basic fundamentals of CSS.

Note:
If you are working on a computer/tablet/other device where you don't have the ability to create your own files, you could try out (most of) the code examples in an online coding program such as JSBin or Glitch.
Tutorials and challenges
What is JavaScript?

Welcome to the MDN beginner's JavaScript course! In this first article we will look at JavaScript from a high level, answering questions such as "what is it?", and "what is it doing?", and making sure you are comfortable with JavaScript's purpose.

A first splash into JavaScript

Now you've learned something about the theory of JavaScript, and what you can do with it, we are going to give you a crash course on the basic features of JavaScript via a completely practical tutorial. Here you'll build up a simple "Guess the number" game, step by step.

What went wrong? Troubleshooting JavaScript

When you built up the "Guess the number" game in the previous article, you may have found that it didn't work. Never fear — this article aims to save you from tearing your hair out over such problems by providing you with some simple tips on how to find and fix errors in JavaScript programs.

Storing the information you need — Variables

After reading the last couple of articles you should now know what JavaScript is, what it can do for you, how you use it alongside other web technologies, and what its main features look like from a high level. In this article, we will get down to the real basics, looking at how to work with the most basic building blocks of JavaScript — Variables.

Basic math in JavaScript — numbers and operators

At this point in the course, we discuss maths in JavaScript — how we can combine operators and other features to successfully manipulate numbers to do our bidding.

Handling text — strings in JavaScript

Next, we'll turn our attention to strings — this is what pieces of text are called in programming. In this article, we'll look at all the common things that you really ought to know about strings when learning JavaScript, such as creating strings, escaping quotes in strings, and joining them together.

Useful string methods

Now we've looked at the very basics of strings, let's move up a gear and start thinking about what useful operations we can do on strings with built-in methods, such as finding the length of a text string, joining and splitting strings, substituting one character in a string for another, and more.

Arrays

In this lesson we'll look at arrays — a neat way of storing a list of data items under a single variable name. Here we look at why this is useful, then explore how to create an array, retrieve, add, and remove items stored in an array, and more besides.

Challenge: Silly story generator Challenge

In this challenge, you'll be tasked with taking some of the knowledge you've picked up in this module's articles and applying it to creating a fun app that generates random silly stories. Have fun!

Making decisions in your code — conditionals

In any programming language, the code needs to make decisions and carry out actions accordingly depending on different inputs. For example, in a game, if the player's number of lives is 0, then it's game over. In a weather app, if it is being looked at in the morning, show a sunrise graphic; show stars and a moon if it is nighttime. In this article, we'll explore how so-called conditional statements work in JavaScript.

Looping code

Programming languages are very useful for rapidly completing repetitive tasks, from multiple basic calculations to just about any other situation where you've got a lot of similar items of work to complete. Here we'll look at the loop structures available in JavaScript that handle such needs.

Functions — reusable blocks of code

Another essential concept in coding is functions, which allow you to store a piece of code that does a single task inside a defined block, and then call that code whenever you need it using a single short command — rather than having to type out the same code multiple times. In this article we'll explore fundamental concepts behind functions such as basic syntax, how to invoke and define them, scope, and parameters.

Build your own function

With most of the essential theory dealt with in the previous article, this article provides practical experience. Here you will get some practice building your own, custom function. Along the way, we'll also explain some useful details of dealing with functions.

Function return values

There's one last essential concept about functions for us to discuss — return values. Some functions don't return a significant value, but others do. It's important to understand what their values are, how to use them in your code, and how to make functions return useful values. We'll cover all of these below.

Introduction to events

In this article, we discuss some important concepts surrounding events, and look at the fundamentals of how they work in browsers.

Event bubbling

This article introduces the concepts of event bubbling, event capture, and event delegation, which are all about what happens when you add a listener to an element that contains another element, and an event then happens to the contained element.

Challenge: Image gallery Challenge

Now that we've looked at the fundamental building blocks of JavaScript, we'll test your knowledge of loops, functions, conditionals and events by getting you to build a fairly common item you'll see on a lot of websites — a JavaScript-powered image gallery.

Object basics

In this article, we'll look at fundamental JavaScript object syntax, and revisit some JavaScript features that we've already seen earlier in the course, reiterating the fact that many of the features you've already dealt with are objects.

DOM scripting introduction

When writing web pages and apps, one of the most common things you'll want to do is change the document structure in some way. This is usually done by manipulating the Document Object Model (DOM) via a set of built-in browser APIs for controlling HTML and styling information. In this article we'll introduce you to DOM scripting.

Making network requests with JavaScript

Another very common task in modern websites and applications is making network requests to retrieve individual data items from the server to update sections of a webpage without having to load an entire new page. This seemingly small detail has had a huge impact on the performance and behavior of sites, so in this article, we'll explain the concept and look at technologies that make it possible.

Working with JSON

JavaScript Object Notation (JSON) is a standard text-based format for representing structured data based on JavaScript object syntax. It is commonly used for transmitting data in web applications (e.g., sending some data from the server to the client, so it can be displayed on a web page, or vice versa). You'll come across it quite often, so in this article, we give you all you need to work with JSON using JavaScript, including parsing JSON so you can access data within it, and creating JSON.

JavaScript debugging and error handling

In this lesson, we will return to the subject of debugging JavaScript (which we first looked at in What went wrong?). Here we will delve deeper into techniques for tracking down errors, but also look at how to code defensively and handle errors in your code, avoiding problems in the first place.

Test your skills: JavaScript

This page lists JavaScript tests you can try so you can verify if you've understood the content in this module.

See also
Scrimba: Learn JavaScript MDN learning partner

Scrimba's Learn JavaScript course teaches you JavaScript through solving 140+ interactive coding challenges, building projects including a game, a browser extension, and even a mobile app. Scrimba features fun interactive lessons taught by knowledgeable teachers.

Learn JavaScript

An excellent resource for aspiring web developers — Learn JavaScript in an interactive environment, with short lessons and interactive tests, guided by automated assessment. The first 40 lessons are free, and the complete course is available for a small one-time payment.


 Overview: Core learning modules Next  Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Apr 15, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nAccessibility on the web Overview: Core learning modules Next  
Access to web content such as public services, education, e-commerce sites, and entertainment is a human right. No one should be excluded based on disability, race, geography, or other human characteristics. This module discusses the best practices and techniques you should learn to make your websites as accessible as possible.PrerequisitesYou should be familiar with HTML, CSS, and JavaScript before starting this module.

Note:
If you are working on a computer/tablet/other devices where you don't have the ability to create your own files, you can try out most of the code examples in an online coding program such as JS Bin or Glitch.
Tutorials and challenges
What is accessibility?

This article starts off the module with a good look at what accessibility is — this includes what groups of people we need to consider and why, what tools different people use to interact with the web, and how we can make accessibility part of our web development workflow.

Accessibility tooling and assistive technology

Next we turn our attention to accessibility tooling, providing information on the kinds of tools you can use to help solve accessibility issues, and the assistive technologies used by people with disabilities as they browse the web. You'll be using these tools throughout subsequent articles.

HTML: A good basis for accessibility

A great deal of web content can be made accessible just by making sure the correct HTML elements are always used for the correct purpose. This article looks in detail at how HTML can be used to ensure maximum accessibility.

CSS and JavaScript accessibility best practices

CSS and JavaScript, when used properly, also have the potential to allow for accessible web experiences, but if misused they can significantly harm accessibility. This article outlines some CSS and JavaScript best practices that should be considered to ensure that even complex content is as accessible as possible.

WAI-ARIA basics

Following on from the previous article, sometimes making complex UI controls that involve unsemantic HTML and dynamic JavaScript-updated content can be difficult. WAI-ARIA is a technology that can help with such problems by adding in further semantics that browsers and assistive technologies can recognize and use to let users know what is going on. Here we'll show how to use it at a basic level to improve accessibility.

Accessible multimedia

Another category of content that can create accessibility problems is multimedia — video, audio, and image content need to be given proper textual alternatives, so they can be understood by assistive technologies and their users. This article shows how.

Mobile accessibility

With web access on mobile devices being so popular, and popular platforms such as iOS and Android having fully-fledged accessibility tools, it is important to consider the accessibility of your web content on these platforms. This article looks at mobile-specific accessibility considerations.

Accessibility troubleshooting Challenge

In this challenge, we present to you a simple site with several accessibility issues that you need to diagnose and fix.

See also
Start Building Accessible Web Applications Today

An excellent series of video tutorials by Marcy Sutton.

Deque University resources

Includes code examples, screen reader references, and other useful resources.

WebAIM resources

Includes guides, checklists, tools, and more.

Web Accessibility Evaluation Tools List

Includes a list of web accessibility evaluation tools.

Learn Accessible Web Design MDN learning partner

Scrimba's Learn Accessible Web Design course teaches you how to write accessible HTML by solving interactive coding challenges and fixing a real-world website.


 Overview: Core learning modules Next\n\nAccessibility on the web Overview: Core learning modules Next  
Access to web content such as public services, education, e-commerce sites, and entertainment is a human right. No one should be excluded based on disability, race, geography, or other human characteristics. This module discusses the best practices and techniques you should learn to make your websites as accessible as possible.PrerequisitesYou should be familiar with HTML, CSS, and JavaScript before starting this module.

Note:
If you are working on a computer/tablet/other devices where you don't have the ability to create your own files, you can try out most of the code examples in an online coding program such as JS Bin or Glitch.
Tutorials and challenges
What is accessibility?

This article starts off the module with a good look at what accessibility is — this includes what groups of people we need to consider and why, what tools different people use to interact with the web, and how we can make accessibility part of our web development workflow.

Accessibility tooling and assistive technology

Next we turn our attention to accessibility tooling, providing information on the kinds of tools you can use to help solve accessibility issues, and the assistive technologies used by people with disabilities as they browse the web. You'll be using these tools throughout subsequent articles.

HTML: A good basis for accessibility

A great deal of web content can be made accessible just by making sure the correct HTML elements are always used for the correct purpose. This article looks in detail at how HTML can be used to ensure maximum accessibility.

CSS and JavaScript accessibility best practices

CSS and JavaScript, when used properly, also have the potential to allow for accessible web experiences, but if misused they can significantly harm accessibility. This article outlines some CSS and JavaScript best practices that should be considered to ensure that even complex content is as accessible as possible.

WAI-ARIA basics

Following on from the previous article, sometimes making complex UI controls that involve unsemantic HTML and dynamic JavaScript-updated content can be difficult. WAI-ARIA is a technology that can help with such problems by adding in further semantics that browsers and assistive technologies can recognize and use to let users know what is going on. Here we'll show how to use it at a basic level to improve accessibility.

Accessible multimedia

Another category of content that can create accessibility problems is multimedia — video, audio, and image content need to be given proper textual alternatives, so they can be understood by assistive technologies and their users. This article shows how.

Mobile accessibility

With web access on mobile devices being so popular, and popular platforms such as iOS and Android having fully-fledged accessibility tools, it is important to consider the accessibility of your web content on these platforms. This article looks at mobile-specific accessibility considerations.

Accessibility troubleshooting Challenge

In this challenge, we present to you a simple site with several accessibility issues that you need to diagnose and fix.

See also
Start Building Accessible Web Applications Today

An excellent series of video tutorials by Marcy Sutton.

Deque University resources

Includes code examples, screen reader references, and other useful resources.

WebAIM resources

Includes guides, checklists, tools, and more.

Web Accessibility Evaluation Tools List

Includes a list of web accessibility evaluation tools.

Learn Accessible Web Design MDN learning partner

Scrimba's Learn Accessible Web Design course teaches you how to write accessible HTML by solving interactive coding challenges and fixing a real-world website.


 Overview: Core learning modules Next  Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Apr 15, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nAccessibility on the web Overview: Core learning modules Next  
Access to web content such as public services, education, e-commerce sites, and entertainment is a human right. No one should be excluded based on disability, race, geography, or other human characteristics. This module discusses the best practices and techniques you should learn to make your websites as accessible as possible.PrerequisitesYou should be familiar with HTML, CSS, and JavaScript before starting this module.

Note:
If you are working on a computer/tablet/other devices where you don't have the ability to create your own files, you can try out most of the code examples in an online coding program such as JS Bin or Glitch.
Tutorials and challenges
What is accessibility?

This article starts off the module with a good look at what accessibility is — this includes what groups of people we need to consider and why, what tools different people use to interact with the web, and how we can make accessibility part of our web development workflow.

Accessibility tooling and assistive technology

Next we turn our attention to accessibility tooling, providing information on the kinds of tools you can use to help solve accessibility issues, and the assistive technologies used by people with disabilities as they browse the web. You'll be using these tools throughout subsequent articles.

HTML: A good basis for accessibility

A great deal of web content can be made accessible just by making sure the correct HTML elements are always used for the correct purpose. This article looks in detail at how HTML can be used to ensure maximum accessibility.

CSS and JavaScript accessibility best practices

CSS and JavaScript, when used properly, also have the potential to allow for accessible web experiences, but if misused they can significantly harm accessibility. This article outlines some CSS and JavaScript best practices that should be considered to ensure that even complex content is as accessible as possible.

WAI-ARIA basics

Following on from the previous article, sometimes making complex UI controls that involve unsemantic HTML and dynamic JavaScript-updated content can be difficult. WAI-ARIA is a technology that can help with such problems by adding in further semantics that browsers and assistive technologies can recognize and use to let users know what is going on. Here we'll show how to use it at a basic level to improve accessibility.

Accessible multimedia

Another category of content that can create accessibility problems is multimedia — video, audio, and image content need to be given proper textual alternatives, so they can be understood by assistive technologies and their users. This article shows how.

Mobile accessibility

With web access on mobile devices being so popular, and popular platforms such as iOS and Android having fully-fledged accessibility tools, it is important to consider the accessibility of your web content on these platforms. This article looks at mobile-specific accessibility considerations.

Accessibility troubleshooting Challenge

In this challenge, we present to you a simple site with several accessibility issues that you need to diagnose and fix.

See also
Start Building Accessible Web Applications Today

An excellent series of video tutorials by Marcy Sutton.

Deque University resources

Includes code examples, screen reader references, and other useful resources.

WebAIM resources

Includes guides, checklists, tools, and more.

Web Accessibility Evaluation Tools List

Includes a list of web accessibility evaluation tools.

Learn Accessible Web Design MDN learning partner

Scrimba's Learn Accessible Web Design course teaches you how to write accessible HTML by solving interactive coding challenges and fixing a real-world website.


 Overview: Core learning modules Next  Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Apr 15, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nMore MDN. Your MDN.Support MDN and make it your own.Get startedWhat's includedGo ads freeEnjoy MDN ads-free with an MDN Plus subscription.Support MDN and enjoy a focused, ad-free experience alongside other features such as curated collections, custom web platform updates, offline access, and more. Subscribers to paid tiers of MDN Plus have the option to browse MDN without ads.Learn more →AI HelpGet real-time assistance and support.No need to scroll through page after page to find your answers. Introducing an AI assistant that can answer all your web development questions in real time. Powered by OpenAI GPT-4o and GPT-4o mini.Learn more →PlaygroundWrite,Test and Share your code.Your playground to learn and share your amazing work with the world. By simply logging in, you can now spread your creativity far and wide.Learn more →UpdatesCompatibility changes at a glance.Filter and sort updates that matter most to build your projectThe Web doesn't have a changelog, but MDN can help. You can personalize and filter compatibility changes based on browsers or the tech category you are interested in whether that is JavaScript, CSS, etc.Learn more →CollectionsBuild your perfect library. Or let us build it for you.No more haphazard hunting through the vast virtual library: unleash your inner curator and collect your favorite articles in one place for convenient consultation.Learn more →Loading available plans…* Do you need MDN Plus for your company? Let us know and we’ll get back to you when it becomes available.\n\nMore MDN. Your MDN.Support MDN and make it your own.Get startedWhat's includedGo ads freeEnjoy MDN ads-free with an MDN Plus subscription.Support MDN and enjoy a focused, ad-free experience alongside other features such as curated collections, custom web platform updates, offline access, and more. Subscribers to paid tiers of MDN Plus have the option to browse MDN without ads.Learn more →AI HelpGet real-time assistance and support.No need to scroll through page after page to find your answers. Introducing an AI assistant that can answer all your web development questions in real time. Powered by OpenAI GPT-4o and GPT-4o mini.Learn more →PlaygroundWrite,Test and Share your code.Your playground to learn and share your amazing work with the world. By simply logging in, you can now spread your creativity far and wide.Learn more →UpdatesCompatibility changes at a glance.Filter and sort updates that matter most to build your projectThe Web doesn't have a changelog, but MDN can help. You can personalize and filter compatibility changes based on browsers or the tech category you are interested in whether that is JavaScript, CSS, etc.Learn more →CollectionsBuild your perfect library. Or let us build it for you.No more haphazard hunting through the vast virtual library: unleash your inner curator and collect your favorite articles in one place for convenient consultation.Learn more →Loading available plans…* Do you need MDN Plus for your company? Let us know and we’ll get back to you when it becomes available.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverview

More MDN. Your MDN. Get started.
This page is an overview of the MDN Plus documentation and related resources.

MDN Plus is a premium subscription service launched by Mozilla. The service
allows users to customize their MDN Web Docs experience through premium features
such as Collections, filtering Updates and MDN Offline.
Learn more about MDN Plus on our website or in this
blogpost.\n\nOverview

More MDN. Your MDN. Get started.
This page is an overview of the MDN Plus documentation and related resources.

MDN Plus is a premium subscription service launched by Mozilla. The service
allows users to customize their MDN Web Docs experience through premium features
such as Collections, filtering Updates and MDN Offline.
Learn more about MDN Plus on our website or in this
blogpost.\n\nOverview

More MDN. Your MDN. Get started.
This page is an overview of the MDN Plus documentation and related resources.

MDN Plus is a premium subscription service launched by Mozilla. The service
allows users to customize their MDN Web Docs experience through premium features
such as Collections, filtering Updates and MDN Offline.
Learn more about MDN Plus on our website or in this
blogpost.\n\n\n\nFrequently asked questionsWhat is MDN Plus?MDN Plus is a premium subscription service launched in March 2022 by Mozilla.
The service allows users to customize their MDN Web Docs experience through
premium features such as Updates,
Collections and
MDN Offline.Why are we working on premium features on MDN?The extensive research we have done in 2020 and 2021 showed us that MDN users
would appreciate a customized experience on MDN. We’ve got information on what
you would find useful and what you would be interested in. All the premium
features we propose today reflect that feedback. MDN Plus is an initial step
towards making the experience on the site more interactive and helpful for our
users.How much does MDN Plus cost?A three-tiered pricing model has been put in place in order to try and
accommodate our users’ needs as much as possible:

MDN Core - A free plan, for those ones who want to try out a limited version
of the premium features.
MDN Plus 5 - A $5/month or $50/year plan that offers unlimited access to the
premium features included in MDN Plus.
MDN Supporter 10 - A $10/month or $100/year plan for users who want to
support MDN with a higher amount. On top of the MDN Plus premium features, MDN
supporters will be able to contribute and shape the product moving forward, by
having early access to premium features and a direct feedback channel with the
MDN team.

Subscribing for a yearly plan activates a 20% discount for all the paid options.Can I upgrade/downgrade my plan?Currently, you can only upgrade your plan. For getting a downgrade, please
cancel your current subscription first and then activate the new one.What is happening with the existing MDN Web Docs?Nothing. We will continue to develop & maintain our web documentation that will
remain free and accessible for everyone. There will be no change there. Even
more, we believe that MDN Web Docs will benefit from MDN Plus, as we plan to
reinvest part of the gains from MDN Plus and improve our documentation as well
as the overall user experience on the website.Are we violating any OS license obligation by adding a paid product to MDN?MDN content is made available under a CC BY-SA 2.5 license. That license doesn't
preclude Mozilla (or other users of MDN content) from having a paid product. MDN
Plus adds premium features like updates and collections on top of the free
content. Regular users can still access and reuse MDN content under the Creative
Commons license.Where will the money from MDN Plus go?Since its beginning in 2005, MDN Web Docs has been a project hosted and provided
by Mozilla. Mozilla covers the cost of infrastructure, development and
maintenance of the MDN platform, including a team of engineers and its own team
of dedicated writers.
Mozilla wants MDN Plus to help ensure that MDN's open source content continues
to be supported into the future. MDN Plus has been built only with Mozilla
resources, and any revenue generated by MDN Plus will stay within Mozilla. We
are looking into ways to reinvest some of these additional funds into open
source projects contributing to MDN but it is still in the early stages.Does the launch of MDN Plus impact the relationship with partners like OWD?The existence of a new subscription model will not detract from MDN's current
free Web Docs offering in any way. The current experience of accessing web
documentation will not change for users who do not wish to sign up for a premium
subscription. Open Web Docs (OWD) and Mozilla will continue to work closely
together on MDN for the best possible web platform documentation for everyone.
For more information about how our organizations work together, please check
this article.What regions is MDN Plus available in?The free version of MDN Plus is available worldwide. Anyone can create an MDN
Plus account and try out a limited version of the premium features. As for the
paid plans, they are currently available as follows: in the United States,
Canada (since March 24th, 2022), Austria, Belgium, Finland, France, the United
Kingdom, Germany, Ireland, Italy, Malaysia, the Netherlands, New Zealand, Puerto
Rico, Sweden, Singapore, Switzerland, Spain (since April 28th, 2022), Estonia,
Greece, Latvia, Lithuania, Portugal, Slovakia and Slovenia (since June 15th,
2022). We are working on expanding this list even further.I have an idea for MDN Plus, who should I contact?In case you have an idea you would like to share about MDN Plus, you can add
your suggestions to our mdn-community
repo.
If a subscriber, you can also leave us feedback by accessing the ‘Feedback’
option in the user menu.\n\nFrequently asked questionsWhat is MDN Plus?MDN Plus is a premium subscription service launched in March 2022 by Mozilla.
The service allows users to customize their MDN Web Docs experience through
premium features such as Updates,
Collections and
MDN Offline.Why are we working on premium features on MDN?The extensive research we have done in 2020 and 2021 showed us that MDN users
would appreciate a customized experience on MDN. We’ve got information on what
you would find useful and what you would be interested in. All the premium
features we propose today reflect that feedback. MDN Plus is an initial step
towards making the experience on the site more interactive and helpful for our
users.How much does MDN Plus cost?A three-tiered pricing model has been put in place in order to try and
accommodate our users’ needs as much as possible:

MDN Core - A free plan, for those ones who want to try out a limited version
of the premium features.
MDN Plus 5 - A $5/month or $50/year plan that offers unlimited access to the
premium features included in MDN Plus.
MDN Supporter 10 - A $10/month or $100/year plan for users who want to
support MDN with a higher amount. On top of the MDN Plus premium features, MDN
supporters will be able to contribute and shape the product moving forward, by
having early access to premium features and a direct feedback channel with the
MDN team.

Subscribing for a yearly plan activates a 20% discount for all the paid options.Can I upgrade/downgrade my plan?Currently, you can only upgrade your plan. For getting a downgrade, please
cancel your current subscription first and then activate the new one.What is happening with the existing MDN Web Docs?Nothing. We will continue to develop & maintain our web documentation that will
remain free and accessible for everyone. There will be no change there. Even
more, we believe that MDN Web Docs will benefit from MDN Plus, as we plan to
reinvest part of the gains from MDN Plus and improve our documentation as well
as the overall user experience on the website.Are we violating any OS license obligation by adding a paid product to MDN?MDN content is made available under a CC BY-SA 2.5 license. That license doesn't
preclude Mozilla (or other users of MDN content) from having a paid product. MDN
Plus adds premium features like updates and collections on top of the free
content. Regular users can still access and reuse MDN content under the Creative
Commons license.Where will the money from MDN Plus go?Since its beginning in 2005, MDN Web Docs has been a project hosted and provided
by Mozilla. Mozilla covers the cost of infrastructure, development and
maintenance of the MDN platform, including a team of engineers and its own team
of dedicated writers.
Mozilla wants MDN Plus to help ensure that MDN's open source content continues
to be supported into the future. MDN Plus has been built only with Mozilla
resources, and any revenue generated by MDN Plus will stay within Mozilla. We
are looking into ways to reinvest some of these additional funds into open
source projects contributing to MDN but it is still in the early stages.Does the launch of MDN Plus impact the relationship with partners like OWD?The existence of a new subscription model will not detract from MDN's current
free Web Docs offering in any way. The current experience of accessing web
documentation will not change for users who do not wish to sign up for a premium
subscription. Open Web Docs (OWD) and Mozilla will continue to work closely
together on MDN for the best possible web platform documentation for everyone.
For more information about how our organizations work together, please check
this article.What regions is MDN Plus available in?The free version of MDN Plus is available worldwide. Anyone can create an MDN
Plus account and try out a limited version of the premium features. As for the
paid plans, they are currently available as follows: in the United States,
Canada (since March 24th, 2022), Austria, Belgium, Finland, France, the United
Kingdom, Germany, Ireland, Italy, Malaysia, the Netherlands, New Zealand, Puerto
Rico, Sweden, Singapore, Switzerland, Spain (since April 28th, 2022), Estonia,
Greece, Latvia, Lithuania, Portugal, Slovakia and Slovenia (since June 15th,
2022). We are working on expanding this list even further.I have an idea for MDN Plus, who should I contact?In case you have an idea you would like to share about MDN Plus, you can add
your suggestions to our mdn-community
repo.
If a subscriber, you can also leave us feedback by accessing the ‘Feedback’
option in the user menu.\n\nFrequently asked questionsWhat is MDN Plus?MDN Plus is a premium subscription service launched in March 2022 by Mozilla.
The service allows users to customize their MDN Web Docs experience through
premium features such as Updates,
Collections and
MDN Offline.Why are we working on premium features on MDN?The extensive research we have done in 2020 and 2021 showed us that MDN users
would appreciate a customized experience on MDN. We’ve got information on what
you would find useful and what you would be interested in. All the premium
features we propose today reflect that feedback. MDN Plus is an initial step
towards making the experience on the site more interactive and helpful for our
users.How much does MDN Plus cost?A three-tiered pricing model has been put in place in order to try and
accommodate our users’ needs as much as possible:

MDN Core - A free plan, for those ones who want to try out a limited version
of the premium features.
MDN Plus 5 - A $5/month or $50/year plan that offers unlimited access to the
premium features included in MDN Plus.
MDN Supporter 10 - A $10/month or $100/year plan for users who want to
support MDN with a higher amount. On top of the MDN Plus premium features, MDN
supporters will be able to contribute and shape the product moving forward, by
having early access to premium features and a direct feedback channel with the
MDN team.

Subscribing for a yearly plan activates a 20% discount for all the paid options.Can I upgrade/downgrade my plan?Currently, you can only upgrade your plan. For getting a downgrade, please
cancel your current subscription first and then activate the new one.What is happening with the existing MDN Web Docs?Nothing. We will continue to develop & maintain our web documentation that will
remain free and accessible for everyone. There will be no change there. Even
more, we believe that MDN Web Docs will benefit from MDN Plus, as we plan to
reinvest part of the gains from MDN Plus and improve our documentation as well
as the overall user experience on the website.Are we violating any OS license obligation by adding a paid product to MDN?MDN content is made available under a CC BY-SA 2.5 license. That license doesn't
preclude Mozilla (or other users of MDN content) from having a paid product. MDN
Plus adds premium features like updates and collections on top of the free
content. Regular users can still access and reuse MDN content under the Creative
Commons license.Where will the money from MDN Plus go?Since its beginning in 2005, MDN Web Docs has been a project hosted and provided
by Mozilla. Mozilla covers the cost of infrastructure, development and
maintenance of the MDN platform, including a team of engineers and its own team
of dedicated writers.
Mozilla wants MDN Plus to help ensure that MDN's open source content continues
to be supported into the future. MDN Plus has been built only with Mozilla
resources, and any revenue generated by MDN Plus will stay within Mozilla. We
are looking into ways to reinvest some of these additional funds into open
source projects contributing to MDN but it is still in the early stages.Does the launch of MDN Plus impact the relationship with partners like OWD?The existence of a new subscription model will not detract from MDN's current
free Web Docs offering in any way. The current experience of accessing web
documentation will not change for users who do not wish to sign up for a premium
subscription. Open Web Docs (OWD) and Mozilla will continue to work closely
together on MDN for the best possible web platform documentation for everyone.
For more information about how our organizations work together, please check
this article.What regions is MDN Plus available in?The free version of MDN Plus is available worldwide. Anyone can create an MDN
Plus account and try out a limited version of the premium features. As for the
paid plans, they are currently available as follows: in the United States,
Canada (since March 24th, 2022), Austria, Belgium, Finland, France, the United
Kingdom, Germany, Ireland, Italy, Malaysia, the Netherlands, New Zealand, Puerto
Rico, Sweden, Singapore, Switzerland, Spain (since April 28th, 2022), Estonia,
Greece, Latvia, Lithuania, Portugal, Slovakia and Slovenia (since June 15th,
2022). We are working on expanding this list even further.I have an idea for MDN Plus, who should I contact?In case you have an idea you would like to share about MDN Plus, you can add
your suggestions to our mdn-community
repo.
If a subscriber, you can also leave us feedback by accessing the ‘Feedback’
option in the user menu.\n\n\n\nMDN CurriculumThe essential skillset for new front-end developersThe MDN Curriculum provides a structured guide to the essential skills and practices for being a successful front-end developer, along with recommended learning resources.
Last updated: February 2024About the curriculum
Beginner's level
Self-paced
Free

Defines the essential skills and knowledge every front-end developer needs for career success and industry relevance.
Created by Mozilla and refined with insights from students, educators, and developers from the broader web community.
Includes learning resource recommendations covering every curriculum topic, helping you become job-ready.
Learn moreLearn our curriculum with Scrimba's interactive Frontend Developer Career Path.ModulesGetting started1. Soft skillsDevelop a great attitude towards learning, researching, and collaborating to enhance your chances of success.Best Practices2. Environment setupFamiliarize yourself with your development environment and the tools you'll use to build websites.ToolingLet's beginCore1. Web standardsUnderstand how the web works at a high level, and the process for creating web technologies.Web Standards & Semantics2. Semantic HTMLLearn the fundamentals of HTML, the language used to define and structure web content.Web Standards & Semantics3. CSS fundamentalsDive into the fundamentals of CSS, the language you'll use to style and layout websites.Styling4. CSS text stylingFocus on using CSS to style text and apply custom web fonts.Styling5. CSS layoutLearn modern techniques for creating flexible layouts that work on a wide variety of devices.Styling6. JavaScript fundamentalsFocus on the core JavaScript language and fundamental surrounding topics.Scripting7. AccessibilityUnderstand the need for universal access to web content and how to write accessible code.Best Practices8. Design for developersAppreciate basic design theory, how to speak design language, and what makes websites look good.Best Practices9. Version controlUnderstand why version control is necessary, and use GitHub to store code and collaborate with others.ToolingLet's beginExtensions1. Transform & animate CSSAdd animations to your toolbox to enhance user experience and perceived performance.Web Standards & Semantics2. Custom JS objectsCreate custom JavaScript objects to gain a deeper understanding of object-oriented programming.Scripting3. Web APIsStudy common WebAPIs in depth to appreciate how WebAPIs work in general.Scripting4. PerformanceExplore how to create performant, fast-loading websites and enhance perceived performance.Best Practices5. Security and privacyLearn how to protect data from unauthorized access and how to treat user data responsibly.Best Practices6. TestingExplore the need for testing, and learn how to implement common test types.Best Practices7. JavaScript frameworksStudy the features of popular JavaScript frameworks, and use them to implement common use cases.Tooling8. CSS toolingLook at popular CSS tooling and understand what code problems they can solve.Tooling9. Other tooling typesUnderstand the purpose and usage of other tooling types commonly found in a web project.ToolingLet's beginLearn the curriculum with Scrimba and become job readyScrimba's Frontend Developer Career Path teaches the MDN Curriculum Core with fun interactive lessons and challenges, knowledgeable teachers, and a supportive community. Go from zero to landing your first front-end job!Find out moreHow can youboost your employability with the MDNCurriculum?Learn about research collaboration and other essential soft skills.Balance between modern tooling and long-term best practices.Get access to high-quality recommended resources.Get guidance from trusted voices.Don't know where toget started? 

Starting out with coding?
Begin with our "Getting started" and "Core" modules to grasp the essential skills for web development.
Core modules


Beyond the basics?
Dive deeper with our "Extensions" modules to develop specialized skills.
Extensions modules


Seeking employment?
Our "Soft skills" module, part of "Getting started", offers crucial insights to help you land your job.
Getting started modules


Working at a school?
Use our modules to guide your teaching, or enroll your students in Scrimba's Frontend Path.
Frontend Path\n\nMDN CurriculumThe essential skillset for new front-end developersThe MDN Curriculum provides a structured guide to the essential skills and practices for being a successful front-end developer, along with recommended learning resources.
Last updated: February 2024About the curriculum
Beginner's level
Self-paced
Free

Defines the essential skills and knowledge every front-end developer needs for career success and industry relevance.
Created by Mozilla and refined with insights from students, educators, and developers from the broader web community.
Includes learning resource recommendations covering every curriculum topic, helping you become job-ready.
Learn moreLearn our curriculum with Scrimba's interactive Frontend Developer Career Path.ModulesGetting started1. Soft skillsDevelop a great attitude towards learning, researching, and collaborating to enhance your chances of success.Best Practices2. Environment setupFamiliarize yourself with your development environment and the tools you'll use to build websites.ToolingLet's beginCore1. Web standardsUnderstand how the web works at a high level, and the process for creating web technologies.Web Standards & Semantics2. Semantic HTMLLearn the fundamentals of HTML, the language used to define and structure web content.Web Standards & Semantics3. CSS fundamentalsDive into the fundamentals of CSS, the language you'll use to style and layout websites.Styling4. CSS text stylingFocus on using CSS to style text and apply custom web fonts.Styling5. CSS layoutLearn modern techniques for creating flexible layouts that work on a wide variety of devices.Styling6. JavaScript fundamentalsFocus on the core JavaScript language and fundamental surrounding topics.Scripting7. AccessibilityUnderstand the need for universal access to web content and how to write accessible code.Best Practices8. Design for developersAppreciate basic design theory, how to speak design language, and what makes websites look good.Best Practices9. Version controlUnderstand why version control is necessary, and use GitHub to store code and collaborate with others.ToolingLet's beginExtensions1. Transform & animate CSSAdd animations to your toolbox to enhance user experience and perceived performance.Web Standards & Semantics2. Custom JS objectsCreate custom JavaScript objects to gain a deeper understanding of object-oriented programming.Scripting3. Web APIsStudy common WebAPIs in depth to appreciate how WebAPIs work in general.Scripting4. PerformanceExplore how to create performant, fast-loading websites and enhance perceived performance.Best Practices5. Security and privacyLearn how to protect data from unauthorized access and how to treat user data responsibly.Best Practices6. TestingExplore the need for testing, and learn how to implement common test types.Best Practices7. JavaScript frameworksStudy the features of popular JavaScript frameworks, and use them to implement common use cases.Tooling8. CSS toolingLook at popular CSS tooling and understand what code problems they can solve.Tooling9. Other tooling typesUnderstand the purpose and usage of other tooling types commonly found in a web project.ToolingLet's beginLearn the curriculum with Scrimba and become job readyScrimba's Frontend Developer Career Path teaches the MDN Curriculum Core with fun interactive lessons and challenges, knowledgeable teachers, and a supportive community. Go from zero to landing your first front-end job!Find out moreHow can youboost your employability with the MDNCurriculum?Learn about research collaboration and other essential soft skills.Balance between modern tooling and long-term best practices.Get access to high-quality recommended resources.Get guidance from trusted voices.Don't know where toget started? 

Starting out with coding?
Begin with our "Getting started" and "Core" modules to grasp the essential skills for web development.
Core modules


Beyond the basics?
Dive deeper with our "Extensions" modules to develop specialized skills.
Extensions modules


Seeking employment?
Our "Soft skills" module, part of "Getting started", offers crucial insights to help you land your job.
Getting started modules


Working at a school?
Use our modules to guide your teaching, or enroll your students in Scrimba's Frontend Path.
Frontend Path\n\nMDN CurriculumThe essential skillset for new front-end developersThe MDN Curriculum provides a structured guide to the essential skills and practices for being a successful front-end developer, along with recommended learning resources.
Last updated: February 2024About the curriculum
Beginner's level
Self-paced
Free

Defines the essential skills and knowledge every front-end developer needs for career success and industry relevance.
Created by Mozilla and refined with insights from students, educators, and developers from the broader web community.
Includes learning resource recommendations covering every curriculum topic, helping you become job-ready.
Learn moreLearn our curriculum with Scrimba's interactive Frontend Developer Career Path.ModulesGetting started1. Soft skillsDevelop a great attitude towards learning, researching, and collaborating to enhance your chances of success.Best Practices2. Environment setupFamiliarize yourself with your development environment and the tools you'll use to build websites.ToolingLet's beginCore1. Web standardsUnderstand how the web works at a high level, and the process for creating web technologies.Web Standards & Semantics2. Semantic HTMLLearn the fundamentals of HTML, the language used to define and structure web content.Web Standards & Semantics3. CSS fundamentalsDive into the fundamentals of CSS, the language you'll use to style and layout websites.Styling4. CSS text stylingFocus on using CSS to style text and apply custom web fonts.Styling5. CSS layoutLearn modern techniques for creating flexible layouts that work on a wide variety of devices.Styling6. JavaScript fundamentalsFocus on the core JavaScript language and fundamental surrounding topics.Scripting7. AccessibilityUnderstand the need for universal access to web content and how to write accessible code.Best Practices8. Design for developersAppreciate basic design theory, how to speak design language, and what makes websites look good.Best Practices9. Version controlUnderstand why version control is necessary, and use GitHub to store code and collaborate with others.ToolingLet's beginExtensions1. Transform & animate CSSAdd animations to your toolbox to enhance user experience and perceived performance.Web Standards & Semantics2. Custom JS objectsCreate custom JavaScript objects to gain a deeper understanding of object-oriented programming.Scripting3. Web APIsStudy common WebAPIs in depth to appreciate how WebAPIs work in general.Scripting4. PerformanceExplore how to create performant, fast-loading websites and enhance perceived performance.Best Practices5. Security and privacyLearn how to protect data from unauthorized access and how to treat user data responsibly.Best Practices6. TestingExplore the need for testing, and learn how to implement common test types.Best Practices7. JavaScript frameworksStudy the features of popular JavaScript frameworks, and use them to implement common use cases.Tooling8. CSS toolingLook at popular CSS tooling and understand what code problems they can solve.Tooling9. Other tooling typesUnderstand the purpose and usage of other tooling types commonly found in a web project.ToolingLet's beginLearn the curriculum with Scrimba and become job readyScrimba's Frontend Developer Career Path teaches the MDN Curriculum Core with fun interactive lessons and challenges, knowledgeable teachers, and a supportive community. Go from zero to landing your first front-end job!Find out moreHow can youboost your employability with the MDNCurriculum?Learn about research collaboration and other essential soft skills.Balance between modern tooling and long-term best practices.Get access to high-quality recommended resources.Get guidance from trusted voices.Don't know where toget started? 

Starting out with coding?
Begin with our "Getting started" and "Core" modules to grasp the essential skills for web development.
Core modules


Beyond the basics?
Dive deeper with our "Extensions" modules to develop specialized skills.
Extensions modules


Seeking employment?
Our "Soft skills" module, part of "Getting started", offers crucial insights to help you land your job.
Getting started modules


Working at a school?
Use our modules to guide your teaching, or enroll your students in Scrimba's Frontend Path.
Frontend Path\n\n\n\nDefault styles for h1 elements are changingSimon PietersApril 11, 20254 minute readBrowsers are starting to roll out changes in default UA styles for nested section headings. This post describes the incoming changes, how to identify if it's an issue on your websites, and hints for conformant and better-structured pages.
Read more →Implications of Global Privacy ControlLola OdelolaMarch 15, 20255 minute readGlobal Privacy Control (GPC) is on the way to becoming a formal privacy standard with the recent publication of its first working draft. Let's take a look at what the implications are for developers and users.Read more →JavaScript Temporal is comingBrian SmithJanuary 24, 20255 minute readA new way to handle dates and times is being added to JavaScript. Let's take a look at Temporal, what problems it solves, the current state, and what you'll find in the new documentation about it on MDN.
Read more →Fix your website's Largest Contentful Paint by optimizing image loadingDebugBearJanuary 13, 202510 minute readLearn techniques to improve the Largest Contentful Paint metric, a part of Core Web Vitals, for your website.
SponsoredRead more →MDN 2024 content projectsVadim MakeevJanuary 8, 20259 minute readLet's have a look at MDN Web Docs content projects in 2024, with highlights of our top picks and recommended reading, and at what's next on MDN for 2025.
Read more →A new learning experience on MDNRuth JohnDecember 20, 20244 minute readThere's a new Learn Web Development section on MDN that merges the MDN Curriculum with the Learn section. Here's the background to these changes, what's new, and what you can expect to see in the future.
Read more →Countdown to the holidays with daily coding challengesSonal SoodDecember 1, 20242 minute readJoin JavaScriptmas this December for daily coding challenges designed to boost your skills and bring festive fun. Solve challenges on Scrimba, learn something new, and take part for a chance to win exciting prizes!
Read more →Monitoring and optimizing website performanceDebugBearNovember 11, 202412 minute readLearn about reading network request waterfalls, identifying common network performance issues, and optimizing page rendering.
SponsoredRead more →How to land your first developer jobPer BorgenNovember 1, 202411 minute readHere are six effective strategies for landing your first developer job. These are especially relevant if you're self-taught or breaking into the tech industry without a traditional CS degree.
SponsoredRead more →Introducing the new MDN Community pagePranshu KhannaOctober 15, 20245 minute readWe are thrilled to announce the new MDN community page that will be a hub to recognize our contributors and a place for contributors to get involved.
Read more →Fixing your website's JavaScript performanceDebugBearOctober 9, 20249 minute readLearn about lesser-known web performance bottlenecks connected to excessive JavaScript usage, like long tasks, large bundle sizes, and hydration issues.
SponsoredRead more →Get back to school! Supercharge your learning with MDN and ScrimbaHermina CondeiSeptember 12, 20242 minute readFor many of us, the holidays are over, and the time has come to focus.  Now is an ideal time to dive into learning web development, and you're in luck — MDN and Scrimba are offering a 30% discount on select courses for the next month!
Read more →Efficient data handling with the Streams APIVultrSeptember 6, 20246 minute readThis post demonstrates how to use the Streams API in a web application to fetch and transform text on the fly.  By processing the data as it arrives, this approach enhances performance, responsiveness, and resource efficiency.
SponsoredRead more →Locale-sensitive text segmentation in JavaScript with Intl.SegmenterBrian SmithSeptember 3, 20245 minute readLearn how to use Intl.Segmenter for locale-sensitive text segmentation in JavaScript to simplify localization, count words or sentences in different languages, and more.Read more →Optimize your workflow with Git stashGitLabAugust 28, 20248 minute readLearn how to use Git stash to break down large commits. Discover a better approach for saving work when switching branches.SponsoredRead more →How to debug mobile apps across devicesLambdaTestAugust 7, 20248 minute readThis post explores what mobile app debugging is, commonly used techniques, and how you can debug mobile apps on multiple devices.SponsoredRead more →Exclusive accordions using the HTML details elementBrian SmithAugust 5, 20243 minute readThe 'name' attribute of the HTML details element is gaining more support across browsers. Learn how this feature allows creating exclusive accordions without scripting widgets from scratch.Read more →Exploring the Broadcast Channel API for cross-tab communicationVultrJuly 12, 20244 minute readThis article explains how to use the Broadcast Channel API to build synchronized and interconnected web applications.SponsoredRead more →MDN partners with Scrimba to enhance web development learningHermina CondeiJuly 9, 20246 minute readWe have chosen Scrimba as a course partner for the MDN Curriculum. This blog post explores what the partnership means practically, and how we will provide an even better web education experience together.Read more →Introducing the MDN HTTP ObservatoryHermina CondeiJuly 2, 20247 minute readFirst released in 2016, the HTTP Observatory became popular in the web community with a combination of helpful security audits and educational material. Fast forward to 2024, and we are delighted to announce that Observatory's new home is MDN. Read on to find out more about what this entails, and give the HTTP Observatory a warm welcome!Read more →Static Site Generation (SSG) with Next.jsVultrJune 28, 20247 minute readThis guide explains how to use Static Site Generation in Next.js to build scalable and secure web applications with fast loading times and a focus on performance.SponsoredRead more →New JavaScript Set methodsBrian SmithJune 24, 20245 minute readNew JavaScript Set methods are landing across browsers. Learn about sets, how you can use these methods to compare different sets, create new sets with specific properties, and more.Read more →Securing APIs: Express rate limit and slow downVultrMay 28, 20246 minute readThis guide introduces you to rate limits and slow down mechanisms. Learn how to apply slow down and rate limit mechanisms in Express applications.SponsoredRead more →Using the Page Visibility APIBrian SmithMay 10, 20246 minute readThis post takes a look at what page visibility is, how you can use the Page Visibility API in your applications, and describes pitfalls to avoid if you build features around this functionality.Read more →A year of publishing the MDN BlogThe MDN TeamMay 3, 20245 minute readWe've been writing about web development and the web platform on the MDN Blog since May 2023. Here's our highlights and top posts along with our favorites.Read more →Setting up service workers on VultrVultrApril 23, 20246 minute readThis guide introduces you to service workers and their lifecycle. Learn how to deploy a project using service workers with HTTPS on Vultr.SponsoredRead more →Interop 2023: MDN updatesBrian SmithMarch 27, 20246 minute readInterop 2023 has successfully concluded, and the Interop 2024 project is now officially underway. Learn what Interop is, discover the updates from Interop 2023 now on MDN, and find out what's coming to the web next.Read more →Testing JavaScript with Jest on VultrVultrMarch 22, 20247 minute readThis guide introduces you to the common types of tests and the testing conventions. Learn how to test JavaScript with Jest on Vultr.SponsoredRead more →Creating color palettes with the CSS color-mix() functionMichelle BarkerMarch 8, 20247 minute readWorking with colors on the web just got more interesting! In this article, we’ll explore how to use the CSS color-mix() function to create variations in color palettes.Read more →Modernizing conventional test automation with TestGridTestGridFebruary 29, 202412 minute readThis post reflects on the conventional test automation methods using Selenium and Appium. Learn how you can use TestGrid's unified testing platform to enhance the conventional methods and also leverage the modern codeless testing techniques.SponsoredRead more →Lift-off: The MDN Curriculum launchHermina CondeiFebruary 27, 20246 minute readThe long-awaited MDN Curriculum is now live on MDN, providing a structured guide to the essential front-end development skills and best practices for industry newcomers. Learn all the key details in this article.Read more →Creating effective technical documentationDipika BhattacharyaFebruary 13, 20247 minute readThis article provides an overview of the core components required for creating effective technical documentation. Learn the best practices to make your documentation clear, consistent, and well-structured.Read more →Leveraging Bun on Vultr: A superior Node.js alternativeVultrJanuary 17, 20245 minute readThis guide explains Bun functionalities as a runtime package manager and a bundler. It also explains the benefits of built-in Bun APIs and how to use Bun's Vultr marketplace application.SponsoredRead more →Border images in CSS: A key focus area for Interop 2023Dipika BhattacharyaDecember 19, 202310 minute readAligning with Interop 2023's emphasis on cross-browser consistency, this post walks you through various `border-image` properties that you can control to create captivating web designs. Learn how to use custom graphics for enhancing the look of your websites that appear consistent across different browsers.Read more →Build AI-powered applications using OpenLLM and Vultr Cloud GPUVultrDecember 12, 20237 minute readLearn how to build AI-powered apps using OpenLLM and Vultr Cloud GPU. This guide shows how to generate API responses using a Large Language Model. It also covers instructions for setting up an Nginx server and implementing SSL security.SponsoredRead more →Saying goodbye to third-party cookies in 2024Chris MillsDecember 8, 20238 minute readThe tail end of 2023 welcomes positive news for web privacy, as Chrome announces it is to join Firefox and Safari in deprecating third-party cookies in 2024. Find out more details about these changes, and what they mean for web developers.Read more →Baseline's evolution on MDNVadim MakeevDecember 5, 20234 minute readToday we're updating the Baseline widgets and introducing a new one, along with the updated definition of Baseline.Read more →Developer essentials: JavaScript console methodsBrian SmithNovember 30, 20236 minute readThe JavaScript console is an essential tool for web development. Learn new and fun ways to use the console to display data and debug your code.Read more →Getting started with CSS container queriesMichelle BarkerNovember 16, 20238 minute readCSS container queries are a powerful new tool for our CSS layout toolbox. In this post we'll dive into the practicalities of building a layout with container queries.Read more →Deploying Node.js applications with PM2 on VultrVultrNovember 8, 20237 minute readLearn how to deploy a Node.js application on Vultr using PM2 to create persistent services. This guide shows how to efficiently use resources via PM2 cluster mode. It also covers Nginx server setup and SSL security.SponsoredRead more →VS Code: Tips and tricks for beginnersDipika BhattacharyaNovember 7, 20238 minute readDiscover essential tips and tricks for using Visual Studio Code (VS Code), a powerful IDE. Learn how to leverage its integrated editing features and Git support, and explore a few extensions.Read more →Coming Soon: MDN Observatory 2.0The MDN TeamOctober 25, 20232 minute readObservatory 2.0 is launching soon as part of the Mozilla Developer Network as the MDN Observatory with new security scoring standards and other exciting updates.Read more →Optimizing DevSecOps workflows with GitLab's conditional CI/CD pipelinesGitLabOctober 23, 20238 minute readThis guide explores the various types of CI/CD pipelines and helps you understand their specific use cases. Learn how to leverage rules to create highly efficient DevSecOps workflows.SponsoredRead more →Introduction to web sustainabilityMichelle BarkerOctober 11, 20238 minute readWhat can web designers and developers do to build a more sustainable web? This post explores the environmental impacts of web technologies and looks at some of the ways we can build greener websites.Read more →Migrating from GitHub to GitLab seamlessly: A step-by-step guideGitLabOctober 5, 20239 minute readThinking about making the move from GitHub to GitLab? This guide demystifies the migration process, addressing common concerns for DevSecOps teams that are looking to seamlessly transition between the two platforms. This post provides a step-by-step guided tutorial on how to migrate your data from GitHub into GitLab.SponsoredRead more →Announcing the MDN front-end developer curriculumThe MDN TeamAugust 14, 20235 minute readMDN has created a curriculum for aspiring front-end developers to build a rewarding and successful career. Take a look at the curriculum, who it's for, and the research it's based on.Read more →Creating custom easing effects in CSS animations using the linear() functionMichelle BarkerAugust 1, 202310 minute readThe new CSS linear() timing function enables custom easing in animations. Explore how linear() works compared with other timing functions used for easing, with practical examples.Read more →Securing your CDN: Why and how should you use SRITerence EdenJuly 21, 20234 minute readRelying on external resources for your website is always fraught with risks. Learn how to protect your website and its visitors by using SRI to secure third-party content.Read more →Scroll progress animations in CSSMichelle BarkerJuly 14, 20237 minute readScroll-driven animations are coming to CSS! In this post, we'll look at a few types of animations and learn how to link them to the scroll progress of a container.Read more →Reflections on AI Explain: A postmortemThe MDN TeamJuly 11, 202310 minute readWe recently launched a feature called AI Explain, but we have rolled this back for now. In this post, we look into the story behind AI Explain: its development, launch, and the reasons that led us to press the pause button.Read more →Developer essentials: How to search code using grepBrian SmithJuly 3, 20239 minute readgrep is a powerful tool for searching code from the terminal. This post will show you how to use grep and why it's an essential developer tool.Read more →Introducing AI Help (Beta): Your Companion for Web DevelopmentHermina CondeiJune 27, 20233 minute readWe're introducing an AI assistant powered by MDN and OpenAI GPT 3.5 to answer all your web development questions in real time.Read more →Learn how to use hue in CSS colors with HSLBrian SmithJune 26, 20237 minute readHues are a bright way to define colors in CSS. Learn about hues, color wheels, how to use color functions, and how you can create vibrant color palettes for your website using hue.Read more →Introducing the MDN Playground: Bring your code to life!Florian DiemingerJune 22, 20236 minute readMDN is launching a code Playground. Users can prototype ideas and expand all live samples into an interactive experience.Read more →MDN doc updates: CSS selectors & media queries, WebGPU & WebTransport APIs, Progressive web appsDipika BhattacharyaJune 13, 20236 minute readDiscover CSS :lang(), experimental media queries, manipulating graphics with WebGPU, client-server communication with WebTransport, ECMAScript module support, and more.Read more →How to draw any regular shape with just one JavaScript functionRuth JohnMay 26, 20234 minute readLearn how to use JavaScript to draw any regular shape to a HTML canvas with a single function, and how to modify it to draw multiple shapes.Read more →New reference pages on MDN for JavaScript regular expressionsBrian SmithMay 23, 20235 minute readSee the latest updates to the MDN reference pages about JavaScript regular expressions, including new sections on sub-features and browser compatibility information.Read more →Celebrating Global Accessibility Awareness DaySchalk NeethlingMay 18, 20236 minute readIn celebration of Global Accessibility Awareness Day in 2023, we share some tools and guidelines to help you make the web more accessible.Read more →Using HTML landmark roles to improve accessibilitySchalk NeethlingMay 15, 202311 minute readLearn what HTML landmark roles are, how they improve accessibility, and how you can include them on your website effectively.Read more →Introducing Baseline: a unified view of stable web featuresHermina CondeiMay 10, 20233 minute readMDN leads the way in implementing WebDX community group's efforts, delivering a clear and simple baseline for the web platform to developers.Read more →How :not() chains multiple selectorsDipika BhattacharyaMay 5, 20234 minute readLearn how the CSS `:not()` pseudo-class behaves when multiple selectors are passed as argument.Read more →New functions, gradients, and hues in CSS colors (Level 4)Brian SmithMay 3, 20239 minute readLearn what's new in CSS Colors Module Level 4, including color spaces, color functions, fancy gradients, and support for wide-gamut displays.Read more →Welcome to the MDN blogRuth JohnMay 3, 20232 minute readThe MDN blog publishes web development news, tutorials, and insights as an extension of MDN Web Docs, helping you discover, learn, and create for the web.Read more →\n\nBlog it betterDefault styles for h1 elements are changingSimon PietersApril 11, 20254 minute readBrowsers are starting to roll out changes in default UA styles for nested section headings. This post describes the incoming changes, how to identify if it's an issue on your websites, and hints for conformant and better-structured pages.
Read more →Implications of Global Privacy ControlLola OdelolaMarch 15, 20255 minute readGlobal Privacy Control (GPC) is on the way to becoming a formal privacy standard with the recent publication of its first working draft. Let's take a look at what the implications are for developers and users.Read more →JavaScript Temporal is comingBrian SmithJanuary 24, 20255 minute readA new way to handle dates and times is being added to JavaScript. Let's take a look at Temporal, what problems it solves, the current state, and what you'll find in the new documentation about it on MDN.
Read more →Fix your website's Largest Contentful Paint by optimizing image loadingDebugBearJanuary 13, 202510 minute readLearn techniques to improve the Largest Contentful Paint metric, a part of Core Web Vitals, for your website.
SponsoredRead more →MDN 2024 content projectsVadim MakeevJanuary 8, 20259 minute readLet's have a look at MDN Web Docs content projects in 2024, with highlights of our top picks and recommended reading, and at what's next on MDN for 2025.
Read more →A new learning experience on MDNRuth JohnDecember 20, 20244 minute readThere's a new Learn Web Development section on MDN that merges the MDN Curriculum with the Learn section. Here's the background to these changes, what's new, and what you can expect to see in the future.
Read more →Countdown to the holidays with daily coding challengesSonal SoodDecember 1, 20242 minute readJoin JavaScriptmas this December for daily coding challenges designed to boost your skills and bring festive fun. Solve challenges on Scrimba, learn something new, and take part for a chance to win exciting prizes!
Read more →Monitoring and optimizing website performanceDebugBearNovember 11, 202412 minute readLearn about reading network request waterfalls, identifying common network performance issues, and optimizing page rendering.
SponsoredRead more →How to land your first developer jobPer BorgenNovember 1, 202411 minute readHere are six effective strategies for landing your first developer job. These are especially relevant if you're self-taught or breaking into the tech industry without a traditional CS degree.
SponsoredRead more →Introducing the new MDN Community pagePranshu KhannaOctober 15, 20245 minute readWe are thrilled to announce the new MDN community page that will be a hub to recognize our contributors and a place for contributors to get involved.
Read more →Fixing your website's JavaScript performanceDebugBearOctober 9, 20249 minute readLearn about lesser-known web performance bottlenecks connected to excessive JavaScript usage, like long tasks, large bundle sizes, and hydration issues.
SponsoredRead more →Get back to school! Supercharge your learning with MDN and ScrimbaHermina CondeiSeptember 12, 20242 minute readFor many of us, the holidays are over, and the time has come to focus.  Now is an ideal time to dive into learning web development, and you're in luck — MDN and Scrimba are offering a 30% discount on select courses for the next month!
Read more →Efficient data handling with the Streams APIVultrSeptember 6, 20246 minute readThis post demonstrates how to use the Streams API in a web application to fetch and transform text on the fly.  By processing the data as it arrives, this approach enhances performance, responsiveness, and resource efficiency.
SponsoredRead more →Locale-sensitive text segmentation in JavaScript with Intl.SegmenterBrian SmithSeptember 3, 20245 minute readLearn how to use Intl.Segmenter for locale-sensitive text segmentation in JavaScript to simplify localization, count words or sentences in different languages, and more.Read more →Optimize your workflow with Git stashGitLabAugust 28, 20248 minute readLearn how to use Git stash to break down large commits. Discover a better approach for saving work when switching branches.SponsoredRead more →How to debug mobile apps across devicesLambdaTestAugust 7, 20248 minute readThis post explores what mobile app debugging is, commonly used techniques, and how you can debug mobile apps on multiple devices.SponsoredRead more →Exclusive accordions using the HTML details elementBrian SmithAugust 5, 20243 minute readThe 'name' attribute of the HTML details element is gaining more support across browsers. Learn how this feature allows creating exclusive accordions without scripting widgets from scratch.Read more →Exploring the Broadcast Channel API for cross-tab communicationVultrJuly 12, 20244 minute readThis article explains how to use the Broadcast Channel API to build synchronized and interconnected web applications.SponsoredRead more →MDN partners with Scrimba to enhance web development learningHermina CondeiJuly 9, 20246 minute readWe have chosen Scrimba as a course partner for the MDN Curriculum. This blog post explores what the partnership means practically, and how we will provide an even better web education experience together.Read more →Introducing the MDN HTTP ObservatoryHermina CondeiJuly 2, 20247 minute readFirst released in 2016, the HTTP Observatory became popular in the web community with a combination of helpful security audits and educational material. Fast forward to 2024, and we are delighted to announce that Observatory's new home is MDN. Read on to find out more about what this entails, and give the HTTP Observatory a warm welcome!Read more →Static Site Generation (SSG) with Next.jsVultrJune 28, 20247 minute readThis guide explains how to use Static Site Generation in Next.js to build scalable and secure web applications with fast loading times and a focus on performance.SponsoredRead more →New JavaScript Set methodsBrian SmithJune 24, 20245 minute readNew JavaScript Set methods are landing across browsers. Learn about sets, how you can use these methods to compare different sets, create new sets with specific properties, and more.Read more →Securing APIs: Express rate limit and slow downVultrMay 28, 20246 minute readThis guide introduces you to rate limits and slow down mechanisms. Learn how to apply slow down and rate limit mechanisms in Express applications.SponsoredRead more →Using the Page Visibility APIBrian SmithMay 10, 20246 minute readThis post takes a look at what page visibility is, how you can use the Page Visibility API in your applications, and describes pitfalls to avoid if you build features around this functionality.Read more →A year of publishing the MDN BlogThe MDN TeamMay 3, 20245 minute readWe've been writing about web development and the web platform on the MDN Blog since May 2023. Here's our highlights and top posts along with our favorites.Read more →Setting up service workers on VultrVultrApril 23, 20246 minute readThis guide introduces you to service workers and their lifecycle. Learn how to deploy a project using service workers with HTTPS on Vultr.SponsoredRead more →Interop 2023: MDN updatesBrian SmithMarch 27, 20246 minute readInterop 2023 has successfully concluded, and the Interop 2024 project is now officially underway. Learn what Interop is, discover the updates from Interop 2023 now on MDN, and find out what's coming to the web next.Read more →Testing JavaScript with Jest on VultrVultrMarch 22, 20247 minute readThis guide introduces you to the common types of tests and the testing conventions. Learn how to test JavaScript with Jest on Vultr.SponsoredRead more →Creating color palettes with the CSS color-mix() functionMichelle BarkerMarch 8, 20247 minute readWorking with colors on the web just got more interesting! In this article, we’ll explore how to use the CSS color-mix() function to create variations in color palettes.Read more →Modernizing conventional test automation with TestGridTestGridFebruary 29, 202412 minute readThis post reflects on the conventional test automation methods using Selenium and Appium. Learn how you can use TestGrid's unified testing platform to enhance the conventional methods and also leverage the modern codeless testing techniques.SponsoredRead more →Lift-off: The MDN Curriculum launchHermina CondeiFebruary 27, 20246 minute readThe long-awaited MDN Curriculum is now live on MDN, providing a structured guide to the essential front-end development skills and best practices for industry newcomers. Learn all the key details in this article.Read more →Creating effective technical documentationDipika BhattacharyaFebruary 13, 20247 minute readThis article provides an overview of the core components required for creating effective technical documentation. Learn the best practices to make your documentation clear, consistent, and well-structured.Read more →Leveraging Bun on Vultr: A superior Node.js alternativeVultrJanuary 17, 20245 minute readThis guide explains Bun functionalities as a runtime package manager and a bundler. It also explains the benefits of built-in Bun APIs and how to use Bun's Vultr marketplace application.SponsoredRead more →Border images in CSS: A key focus area for Interop 2023Dipika BhattacharyaDecember 19, 202310 minute readAligning with Interop 2023's emphasis on cross-browser consistency, this post walks you through various `border-image` properties that you can control to create captivating web designs. Learn how to use custom graphics for enhancing the look of your websites that appear consistent across different browsers.Read more →Build AI-powered applications using OpenLLM and Vultr Cloud GPUVultrDecember 12, 20237 minute readLearn how to build AI-powered apps using OpenLLM and Vultr Cloud GPU. This guide shows how to generate API responses using a Large Language Model. It also covers instructions for setting up an Nginx server and implementing SSL security.SponsoredRead more →Saying goodbye to third-party cookies in 2024Chris MillsDecember 8, 20238 minute readThe tail end of 2023 welcomes positive news for web privacy, as Chrome announces it is to join Firefox and Safari in deprecating third-party cookies in 2024. Find out more details about these changes, and what they mean for web developers.Read more →Baseline's evolution on MDNVadim MakeevDecember 5, 20234 minute readToday we're updating the Baseline widgets and introducing a new one, along with the updated definition of Baseline.Read more →Developer essentials: JavaScript console methodsBrian SmithNovember 30, 20236 minute readThe JavaScript console is an essential tool for web development. Learn new and fun ways to use the console to display data and debug your code.Read more →Getting started with CSS container queriesMichelle BarkerNovember 16, 20238 minute readCSS container queries are a powerful new tool for our CSS layout toolbox. In this post we'll dive into the practicalities of building a layout with container queries.Read more →Deploying Node.js applications with PM2 on VultrVultrNovember 8, 20237 minute readLearn how to deploy a Node.js application on Vultr using PM2 to create persistent services. This guide shows how to efficiently use resources via PM2 cluster mode. It also covers Nginx server setup and SSL security.SponsoredRead more →VS Code: Tips and tricks for beginnersDipika BhattacharyaNovember 7, 20238 minute readDiscover essential tips and tricks for using Visual Studio Code (VS Code), a powerful IDE. Learn how to leverage its integrated editing features and Git support, and explore a few extensions.Read more →Coming Soon: MDN Observatory 2.0The MDN TeamOctober 25, 20232 minute readObservatory 2.0 is launching soon as part of the Mozilla Developer Network as the MDN Observatory with new security scoring standards and other exciting updates.Read more →Optimizing DevSecOps workflows with GitLab's conditional CI/CD pipelinesGitLabOctober 23, 20238 minute readThis guide explores the various types of CI/CD pipelines and helps you understand their specific use cases. Learn how to leverage rules to create highly efficient DevSecOps workflows.SponsoredRead more →Introduction to web sustainabilityMichelle BarkerOctober 11, 20238 minute readWhat can web designers and developers do to build a more sustainable web? This post explores the environmental impacts of web technologies and looks at some of the ways we can build greener websites.Read more →Migrating from GitHub to GitLab seamlessly: A step-by-step guideGitLabOctober 5, 20239 minute readThinking about making the move from GitHub to GitLab? This guide demystifies the migration process, addressing common concerns for DevSecOps teams that are looking to seamlessly transition between the two platforms. This post provides a step-by-step guided tutorial on how to migrate your data from GitHub into GitLab.SponsoredRead more →Announcing the MDN front-end developer curriculumThe MDN TeamAugust 14, 20235 minute readMDN has created a curriculum for aspiring front-end developers to build a rewarding and successful career. Take a look at the curriculum, who it's for, and the research it's based on.Read more →Creating custom easing effects in CSS animations using the linear() functionMichelle BarkerAugust 1, 202310 minute readThe new CSS linear() timing function enables custom easing in animations. Explore how linear() works compared with other timing functions used for easing, with practical examples.Read more →Securing your CDN: Why and how should you use SRITerence EdenJuly 21, 20234 minute readRelying on external resources for your website is always fraught with risks. Learn how to protect your website and its visitors by using SRI to secure third-party content.Read more →Scroll progress animations in CSSMichelle BarkerJuly 14, 20237 minute readScroll-driven animations are coming to CSS! In this post, we'll look at a few types of animations and learn how to link them to the scroll progress of a container.Read more →Reflections on AI Explain: A postmortemThe MDN TeamJuly 11, 202310 minute readWe recently launched a feature called AI Explain, but we have rolled this back for now. In this post, we look into the story behind AI Explain: its development, launch, and the reasons that led us to press the pause button.Read more →Developer essentials: How to search code using grepBrian SmithJuly 3, 20239 minute readgrep is a powerful tool for searching code from the terminal. This post will show you how to use grep and why it's an essential developer tool.Read more →Introducing AI Help (Beta): Your Companion for Web DevelopmentHermina CondeiJune 27, 20233 minute readWe're introducing an AI assistant powered by MDN and OpenAI GPT 3.5 to answer all your web development questions in real time.Read more →Learn how to use hue in CSS colors with HSLBrian SmithJune 26, 20237 minute readHues are a bright way to define colors in CSS. Learn about hues, color wheels, how to use color functions, and how you can create vibrant color palettes for your website using hue.Read more →Introducing the MDN Playground: Bring your code to life!Florian DiemingerJune 22, 20236 minute readMDN is launching a code Playground. Users can prototype ideas and expand all live samples into an interactive experience.Read more →MDN doc updates: CSS selectors & media queries, WebGPU & WebTransport APIs, Progressive web appsDipika BhattacharyaJune 13, 20236 minute readDiscover CSS :lang(), experimental media queries, manipulating graphics with WebGPU, client-server communication with WebTransport, ECMAScript module support, and more.Read more →How to draw any regular shape with just one JavaScript functionRuth JohnMay 26, 20234 minute readLearn how to use JavaScript to draw any regular shape to a HTML canvas with a single function, and how to modify it to draw multiple shapes.Read more →New reference pages on MDN for JavaScript regular expressionsBrian SmithMay 23, 20235 minute readSee the latest updates to the MDN reference pages about JavaScript regular expressions, including new sections on sub-features and browser compatibility information.Read more →Celebrating Global Accessibility Awareness DaySchalk NeethlingMay 18, 20236 minute readIn celebration of Global Accessibility Awareness Day in 2023, we share some tools and guidelines to help you make the web more accessible.Read more →Using HTML landmark roles to improve accessibilitySchalk NeethlingMay 15, 202311 minute readLearn what HTML landmark roles are, how they improve accessibility, and how you can include them on your website effectively.Read more →Introducing Baseline: a unified view of stable web featuresHermina CondeiMay 10, 20233 minute readMDN leads the way in implementing WebDX community group's efforts, delivering a clear and simple baseline for the web platform to developers.Read more →How :not() chains multiple selectorsDipika BhattacharyaMay 5, 20234 minute readLearn how the CSS `:not()` pseudo-class behaves when multiple selectors are passed as argument.Read more →New functions, gradients, and hues in CSS colors (Level 4)Brian SmithMay 3, 20239 minute readLearn what's new in CSS Colors Module Level 4, including color spaces, color functions, fancy gradients, and support for wide-gamut displays.Read more →Welcome to the MDN blogRuth JohnMay 3, 20232 minute readThe MDN blog publishes web development news, tutorials, and insights as an extension of MDN Web Docs, helping you discover, learn, and create for the web.Read more →\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHTTP guidesThis page lists guides for HTTP.
They're intended to help you understand what kinds of things are possible using the HTTP protocol.
A typical HTTP sessionIn client-server protocols, like HTTP, sessions consist of three phases:An overview of HTTPHTTP is a protocol for fetching resources such as HTML documents.
It is the foundation of any data exchange on the Web and it is a client-server protocol, which means requests are initiated by the recipient, usually the Web browser.
A complete document is typically constructed from resources such as text content, layout instructions, images, videos, scripts, and more.Browser detection using the user agent string (UA sniffing)Along with every request to a server, browsers include a User-Agent HTTP header with a value called a user agent (UA) string.
This string is intended to identify the browser, its version number, and its host operating system.Compression Dictionary TransportCompression Dictionary Transport is a way of using a shared compression dictionary to dramatically reduce the transport size of HTTP responses.Compression in HTTPCompression is an important way to increase the performance of a website. For some documents, size reduction of up to 70% lowers the bandwidth capacity needs. Over the years, algorithms also got more efficient, and new ones are supported by clients and servers.Connection management in HTTP/1.xConnection management is a key topic in HTTP: opening and maintaining connections largely impacts the performance of websites and Web applications. In HTTP/1.x, there are several models: short-lived connections, persistent connections, and HTTP pipelining.Content negotiationIn HTTP, content negotiation is the mechanism that is used for serving different representations of a resource to the same URI to help the user agent specify which representation is best suited for the user (for example, which document language, which image format, or which content encoding).Content Security Policy (CSP)Content Security Policy (CSP) is a feature that helps to prevent or minimize the risk of certain types of security threats. It consists of a series of instructions from a website to a browser, which instruct the browser to place restrictions on the things that the code comprising the site is allowed to do.Cross-Origin Resource Policy (CORP)Cross-Origin Resource Policy is a policy set by the Cross-Origin-Resource-Policy HTTP header that lets websites and applications opt in to protection against certain requests from other origins (such as those issued with elements like <script> and <img>), to mitigate speculative side-channel attacks, like Spectre, as well as Cross-Site Script Inclusion attacks.Cross-Origin Resource Sharing (CORS)Cross-Origin Resource Sharing (CORS) is an HTTP-header based mechanism that allows a server to indicate any origins (domain, scheme, or port) other than its own from which a browser should permit loading resources. CORS also relies on a mechanism by which browsers make a "preflight" request to the server hosting the cross-origin resource, in order to check that the server will permit the actual request. In that preflight, the browser sends headers that indicate the HTTP method and headers that will be used in the actual request.Evolution of HTTPHTTP (HyperText Transfer Protocol) is the underlying protocol of the World Wide Web. Developed by Tim Berners-Lee and his team between 1989-1991, HTTP has gone through many changes that have helped maintain its simplicity while shaping its flexibility. Keep reading to learn how HTTP evolved from a protocol designed to exchange files in a semitrusted laboratory environment into a modern internet maze that carries images and videos in high resolution and 3D.HTTP authenticationHTTP provides a general framework for access control and authentication.
This page is an introduction to the HTTP framework for authentication, and shows how to restrict access to your server using the HTTP "Basic" scheme.HTTP cachingThe HTTP cache stores a response associated with a request and reuses the stored response for subsequent requests.HTTP Client hintsClient hints are a set of HTTP request header fields that a server can proactively request from a client to get information about the device, network, user, and user-agent-specific preferences.
The server can determine which resources to send, based on the information that the client chooses to provide.HTTP conditional requestsHTTP has a concept of conditional requests, where the result, and even the success of a request, can be controlled by comparing the affected resources with a validator.
These requests are useful for validating cached content, ensuring that it is only fetched if it differs from the copy that is already available to the browser.
Conditional requests are also useful for ensuring the integrity of a document when resuming a download, or preventing lost updates when uploading or modifying a document on the server.HTTP messagesHTTP messages are the mechanism used to exchange data between a server and a client in the HTTP protocol.
There are two types of messages: requests sent by the client to trigger an action on the server, and responses, the answer that the server sends in response to a request.HTTP range requestsAn HTTP Range request asks the server to send parts of a resource back to a client.
Range requests are useful for various clients, including media players that support random access, data tools that require only part of a large file, and download managers that let users pause and resume a download.MIME types (IANA media types)A media type (also known as a Multipurpose Internet Mail Extensions or MIME type) indicates the nature and format of a document, file, or assortment of bytes.
MIME types are defined and standardized in IETF's 6838.Network Error LoggingNetwork Error Logging is a mechanism that can be configured via the NEL HTTP response header. This experimental header allows websites and applications to opt-in to receive reports about failed (and, if desired, successful) network fetches from supporting browsers.Permissions PolicyPermissions Policy provides mechanisms for web developers to explicitly declare what functionality can and cannot be used on a website. You define a set of "policies" that restrict what APIs the site's code can access or modify the browser's default behavior for certain features. This allows you to enforce best practices, even as the codebase evolves — as well as more safely compose third-party content.Protocol upgrade mechanismThe HTTP/1.1 protocol provides a special mechanism that can be used to upgrade an already established connection to a different protocol, using the Upgrade header field.Proxy servers and tunnelingWhen navigating through different networks of the Internet, proxy servers and HTTP tunnels are facilitating access to content on the World Wide Web. A proxy can be on the user's local computer, or anywhere between the user's computer and a destination server on the Internet. This page outlines some basics about proxies and introduces a few configuration options.Redirections in HTTPURL redirection, also known as URL forwarding, is a technique to give more than one URL address to a page, a form, a whole website, or a web application. HTTP has a special kind of response, called a HTTP redirect, for this operation.Using HTTP cookiesA cookie (also known as a web cookie or browser cookie) is a small piece of data a server sends to a user's web browser. The browser may store cookies, create new cookies, modify existing ones, and send them back to the same server with later requests. Cookies enable web applications to store limited amounts of data and remember state information; by default the HTTP protocol is stateless.\n\nHTTP guidesThis page lists guides for HTTP.
They're intended to help you understand what kinds of things are possible using the HTTP protocol.
A typical HTTP sessionIn client-server protocols, like HTTP, sessions consist of three phases:An overview of HTTPHTTP is a protocol for fetching resources such as HTML documents.
It is the foundation of any data exchange on the Web and it is a client-server protocol, which means requests are initiated by the recipient, usually the Web browser.
A complete document is typically constructed from resources such as text content, layout instructions, images, videos, scripts, and more.Browser detection using the user agent string (UA sniffing)Along with every request to a server, browsers include a User-Agent HTTP header with a value called a user agent (UA) string.
This string is intended to identify the browser, its version number, and its host operating system.Compression Dictionary TransportCompression Dictionary Transport is a way of using a shared compression dictionary to dramatically reduce the transport size of HTTP responses.Compression in HTTPCompression is an important way to increase the performance of a website. For some documents, size reduction of up to 70% lowers the bandwidth capacity needs. Over the years, algorithms also got more efficient, and new ones are supported by clients and servers.Connection management in HTTP/1.xConnection management is a key topic in HTTP: opening and maintaining connections largely impacts the performance of websites and Web applications. In HTTP/1.x, there are several models: short-lived connections, persistent connections, and HTTP pipelining.Content negotiationIn HTTP, content negotiation is the mechanism that is used for serving different representations of a resource to the same URI to help the user agent specify which representation is best suited for the user (for example, which document language, which image format, or which content encoding).Content Security Policy (CSP)Content Security Policy (CSP) is a feature that helps to prevent or minimize the risk of certain types of security threats. It consists of a series of instructions from a website to a browser, which instruct the browser to place restrictions on the things that the code comprising the site is allowed to do.Cross-Origin Resource Policy (CORP)Cross-Origin Resource Policy is a policy set by the Cross-Origin-Resource-Policy HTTP header that lets websites and applications opt in to protection against certain requests from other origins (such as those issued with elements like <script> and <img>), to mitigate speculative side-channel attacks, like Spectre, as well as Cross-Site Script Inclusion attacks.Cross-Origin Resource Sharing (CORS)Cross-Origin Resource Sharing (CORS) is an HTTP-header based mechanism that allows a server to indicate any origins (domain, scheme, or port) other than its own from which a browser should permit loading resources. CORS also relies on a mechanism by which browsers make a "preflight" request to the server hosting the cross-origin resource, in order to check that the server will permit the actual request. In that preflight, the browser sends headers that indicate the HTTP method and headers that will be used in the actual request.Evolution of HTTPHTTP (HyperText Transfer Protocol) is the underlying protocol of the World Wide Web. Developed by Tim Berners-Lee and his team between 1989-1991, HTTP has gone through many changes that have helped maintain its simplicity while shaping its flexibility. Keep reading to learn how HTTP evolved from a protocol designed to exchange files in a semitrusted laboratory environment into a modern internet maze that carries images and videos in high resolution and 3D.HTTP authenticationHTTP provides a general framework for access control and authentication.
This page is an introduction to the HTTP framework for authentication, and shows how to restrict access to your server using the HTTP "Basic" scheme.HTTP cachingThe HTTP cache stores a response associated with a request and reuses the stored response for subsequent requests.HTTP Client hintsClient hints are a set of HTTP request header fields that a server can proactively request from a client to get information about the device, network, user, and user-agent-specific preferences.
The server can determine which resources to send, based on the information that the client chooses to provide.HTTP conditional requestsHTTP has a concept of conditional requests, where the result, and even the success of a request, can be controlled by comparing the affected resources with a validator.
These requests are useful for validating cached content, ensuring that it is only fetched if it differs from the copy that is already available to the browser.
Conditional requests are also useful for ensuring the integrity of a document when resuming a download, or preventing lost updates when uploading or modifying a document on the server.HTTP messagesHTTP messages are the mechanism used to exchange data between a server and a client in the HTTP protocol.
There are two types of messages: requests sent by the client to trigger an action on the server, and responses, the answer that the server sends in response to a request.HTTP range requestsAn HTTP Range request asks the server to send parts of a resource back to a client.
Range requests are useful for various clients, including media players that support random access, data tools that require only part of a large file, and download managers that let users pause and resume a download.MIME types (IANA media types)A media type (also known as a Multipurpose Internet Mail Extensions or MIME type) indicates the nature and format of a document, file, or assortment of bytes.
MIME types are defined and standardized in IETF's 6838.Network Error LoggingNetwork Error Logging is a mechanism that can be configured via the NEL HTTP response header. This experimental header allows websites and applications to opt-in to receive reports about failed (and, if desired, successful) network fetches from supporting browsers.Permissions PolicyPermissions Policy provides mechanisms for web developers to explicitly declare what functionality can and cannot be used on a website. You define a set of "policies" that restrict what APIs the site's code can access or modify the browser's default behavior for certain features. This allows you to enforce best practices, even as the codebase evolves — as well as more safely compose third-party content.Protocol upgrade mechanismThe HTTP/1.1 protocol provides a special mechanism that can be used to upgrade an already established connection to a different protocol, using the Upgrade header field.Proxy servers and tunnelingWhen navigating through different networks of the Internet, proxy servers and HTTP tunnels are facilitating access to content on the World Wide Web. A proxy can be on the user's local computer, or anywhere between the user's computer and a destination server on the Internet. This page outlines some basics about proxies and introduces a few configuration options.Redirections in HTTPURL redirection, also known as URL forwarding, is a technique to give more than one URL address to a page, a form, a whole website, or a web application. HTTP has a special kind of response, called a HTTP redirect, for this operation.Using HTTP cookiesA cookie (also known as a web cookie or browser cookie) is a small piece of data a server sends to a user's web browser. The browser may store cookies, create new cookies, modify existing ones, and send them back to the same server with later requests. Cookies enable web applications to store limited amounts of data and remember state information; by default the HTTP protocol is stateless.Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nHTTP guidesThis page lists guides for HTTP.
They're intended to help you understand what kinds of things are possible using the HTTP protocol.
A typical HTTP sessionIn client-server protocols, like HTTP, sessions consist of three phases:An overview of HTTPHTTP is a protocol for fetching resources such as HTML documents.
It is the foundation of any data exchange on the Web and it is a client-server protocol, which means requests are initiated by the recipient, usually the Web browser.
A complete document is typically constructed from resources such as text content, layout instructions, images, videos, scripts, and more.Browser detection using the user agent string (UA sniffing)Along with every request to a server, browsers include a User-Agent HTTP header with a value called a user agent (UA) string.
This string is intended to identify the browser, its version number, and its host operating system.Compression Dictionary TransportCompression Dictionary Transport is a way of using a shared compression dictionary to dramatically reduce the transport size of HTTP responses.Compression in HTTPCompression is an important way to increase the performance of a website. For some documents, size reduction of up to 70% lowers the bandwidth capacity needs. Over the years, algorithms also got more efficient, and new ones are supported by clients and servers.Connection management in HTTP/1.xConnection management is a key topic in HTTP: opening and maintaining connections largely impacts the performance of websites and Web applications. In HTTP/1.x, there are several models: short-lived connections, persistent connections, and HTTP pipelining.Content negotiationIn HTTP, content negotiation is the mechanism that is used for serving different representations of a resource to the same URI to help the user agent specify which representation is best suited for the user (for example, which document language, which image format, or which content encoding).Content Security Policy (CSP)Content Security Policy (CSP) is a feature that helps to prevent or minimize the risk of certain types of security threats. It consists of a series of instructions from a website to a browser, which instruct the browser to place restrictions on the things that the code comprising the site is allowed to do.Cross-Origin Resource Policy (CORP)Cross-Origin Resource Policy is a policy set by the Cross-Origin-Resource-Policy HTTP header that lets websites and applications opt in to protection against certain requests from other origins (such as those issued with elements like <script> and <img>), to mitigate speculative side-channel attacks, like Spectre, as well as Cross-Site Script Inclusion attacks.Cross-Origin Resource Sharing (CORS)Cross-Origin Resource Sharing (CORS) is an HTTP-header based mechanism that allows a server to indicate any origins (domain, scheme, or port) other than its own from which a browser should permit loading resources. CORS also relies on a mechanism by which browsers make a "preflight" request to the server hosting the cross-origin resource, in order to check that the server will permit the actual request. In that preflight, the browser sends headers that indicate the HTTP method and headers that will be used in the actual request.Evolution of HTTPHTTP (HyperText Transfer Protocol) is the underlying protocol of the World Wide Web. Developed by Tim Berners-Lee and his team between 1989-1991, HTTP has gone through many changes that have helped maintain its simplicity while shaping its flexibility. Keep reading to learn how HTTP evolved from a protocol designed to exchange files in a semitrusted laboratory environment into a modern internet maze that carries images and videos in high resolution and 3D.HTTP authenticationHTTP provides a general framework for access control and authentication.
This page is an introduction to the HTTP framework for authentication, and shows how to restrict access to your server using the HTTP "Basic" scheme.HTTP cachingThe HTTP cache stores a response associated with a request and reuses the stored response for subsequent requests.HTTP Client hintsClient hints are a set of HTTP request header fields that a server can proactively request from a client to get information about the device, network, user, and user-agent-specific preferences.
The server can determine which resources to send, based on the information that the client chooses to provide.HTTP conditional requestsHTTP has a concept of conditional requests, where the result, and even the success of a request, can be controlled by comparing the affected resources with a validator.
These requests are useful for validating cached content, ensuring that it is only fetched if it differs from the copy that is already available to the browser.
Conditional requests are also useful for ensuring the integrity of a document when resuming a download, or preventing lost updates when uploading or modifying a document on the server.HTTP messagesHTTP messages are the mechanism used to exchange data between a server and a client in the HTTP protocol.
There are two types of messages: requests sent by the client to trigger an action on the server, and responses, the answer that the server sends in response to a request.HTTP range requestsAn HTTP Range request asks the server to send parts of a resource back to a client.
Range requests are useful for various clients, including media players that support random access, data tools that require only part of a large file, and download managers that let users pause and resume a download.MIME types (IANA media types)A media type (also known as a Multipurpose Internet Mail Extensions or MIME type) indicates the nature and format of a document, file, or assortment of bytes.
MIME types are defined and standardized in IETF's 6838.Network Error LoggingNetwork Error Logging is a mechanism that can be configured via the NEL HTTP response header. This experimental header allows websites and applications to opt-in to receive reports about failed (and, if desired, successful) network fetches from supporting browsers.Permissions PolicyPermissions Policy provides mechanisms for web developers to explicitly declare what functionality can and cannot be used on a website. You define a set of "policies" that restrict what APIs the site's code can access or modify the browser's default behavior for certain features. This allows you to enforce best practices, even as the codebase evolves — as well as more safely compose third-party content.Protocol upgrade mechanismThe HTTP/1.1 protocol provides a special mechanism that can be used to upgrade an already established connection to a different protocol, using the Upgrade header field.Proxy servers and tunnelingWhen navigating through different networks of the Internet, proxy servers and HTTP tunnels are facilitating access to content on the World Wide Web. A proxy can be on the user's local computer, or anywhere between the user's computer and a destination server on the Internet. This page outlines some basics about proxies and introduces a few configuration options.Redirections in HTTPURL redirection, also known as URL forwarding, is a technique to give more than one URL address to a page, a form, a whole website, or a web application. HTTP has a special kind of response, called a HTTP redirect, for this operation.Using HTTP cookiesA cookie (also known as a web cookie or browser cookie) is a small piece of data a server sends to a user's web browser. The browser may store cookies, create new cookies, modify existing ones, and send them back to the same server with later requests. Cookies enable web applications to store limited amounts of data and remember state information; by default the HTTP protocol is stateless.Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nContent negotiationIn HTTP, content negotiation is the mechanism that is used for serving different representations of a resource to the same URI to help the user agent specify which representation is best suited for the user (for example, which document language, which image format, or which content encoding).

Note:
You'll find some disadvantages of HTTP content negotiation in a wiki page from WHATWG. HTML provides alternatives to content negotiation via, for example, the <source> element.
Principles of content negotiationA specific document is called a resource. When a client wants to obtain a resource, the client requests it via a URL. The server uses this URL to choose one of the variants available–each variant is called a representation–and returns a specific representation to the client. The overall resource, as well as each of the representations, has a specific URL. Content negotiation determines how a specific representation is chosen when the resource is called. There are several ways of negotiating between the client and the server.

The best-suited representation is identified through one of two mechanisms:

Specific HTTP headers by the client (server-driven negotiation or proactive negotiation), which is the standard way of negotiating a specific kind of resource.
The 300 (Multiple Choices) or 406 (Not Acceptable), 415 (Unsupported Media Type) HTTP response codes by the server (agent-driven negotiation or reactive negotiation), that are used as fallback mechanisms.

Over the years, other content negotiation proposals, like transparent content negotiation and the Alternates header, have been proposed. They failed to get traction and were abandoned.Server-driven content negotiationIn server-driven content negotiation, or proactive content negotiation, the browser (or any other kind of user agent) sends several HTTP headers along with the URL. These headers describe the user's preferred choice. The server uses them as hints and an internal algorithm chooses the best content to serve to the client. If it can't provide a suitable resource, it might respond with 406 (Not Acceptable) or 415 (Unsupported Media Type) and set headers for the types of media that it does support (e.g., using the Accept-Post or Accept-Patch for POST and PATCH requests, respectively). The algorithm is server-specific and not defined in the standard. See the Apache negotiation algorithm.

The HTTP/1.1 standard defines list of the standard headers that start server-driven negotiation (such as Accept, Accept-Encoding, and Accept-Language). Though User-Agent isn't in this list, it's sometimes also used to send a specific representation of the requested resource. However, this isn't always considered a good practice. The server uses the Vary header to indicate which headers it actually used for content negotiation (or more precisely, the associated request headers), so that caches can work optimally.
In addition to these, there's an experimental proposal to add more headers to the list of available headers, called client hints. Client hints advertise what kind of device the user agent runs on (for example, a desktop computer or a mobile device).
Even if server-driven content negotiation is the most common way to agree on a specific representation of a resource, it has several drawbacks:

The server doesn't have total knowledge of the browser. Even with the Client Hints extension, it doesn't have a complete knowledge of the capabilities of the browser. Unlike reactive content negotiation where the client makes the choice, the server choice is always somewhat arbitrary.
The information from the client is quite verbose (HTTP/2 header compression mitigates this problem) and a privacy risk (HTTP fingerprinting).
As several representations of a given resource are sent, shared caches are less efficient and server implementations are more complex.
The Accept headerThe Accept header lists the MIME types of media resources that the agent is willing to process. This is a comma-separated list of MIME types, each combined with a quality factor, a parameter that indicates the relative degree of preference between the different MIME types.
The Accept header is defined by the browser, or any other user agent, and can vary according to the context. For example, fetching an HTML page or an image, a video, or a script. It's different when fetching a document entered in the address bar or an element linked via an <img>, <video>, or <audio> element. Browsers are free to use the value of the header that they think is the most adequate; an exhaustive list of default values for common browsers is available.The Accept-CH header
Note:
This is part of an experimental technology called Client Hints. Initial support comes in Chrome 46 or later. The Device-Memory value is in Chrome 61 or later.

The experimental Accept-CH lists configuration data that the server can use to select an appropriate response. Valid values are:



Value
Meaning




Device-Memory
Indicates the approximate amount of device RAM. This value is an approximation given by rounding to the nearest power of 2 and dividing that number by 1024. For example, 512 megabytes will be reported as 0.5.


Viewport-Width
Indicates the layout viewport width in CSS pixels.


Width
Indicates the resource width in physical pixels (in other words the intrinsic size of an image).


The Accept-Encoding headerThe Accept-Encoding header defines the acceptable content encoding (supported compressions). The value is a q-factor list (e.g., br, gzip;q=0.8) that indicates the priority of the encoding values. The default value identity is at the lowest priority (unless otherwise noted).
Compressing HTTP messages is one of the most important ways to improve the performance of a website. It shrinks the size of the data transmitted and makes better use of the available bandwidth. Browsers always send this header and the server should be configured to use compression.The Accept-Language headerThe Accept-Language header is used to indicate the language preference of the user. It's a list of values with quality factors (e.g., de, en;q=0.7). A default value is often set according to the language of the graphical interface of the user agent, but most browsers allow different language preferences to be set.
Due to the configuration-based entropy increase, a modified value can be used to fingerprint the user. It's not recommended to change it and a website can't trust this value to reflect the actual intention of the user. It's best for site designers to avoid using language detection via this header as it can lead to a poor user experience.

They should always provide a way to override the server-chosen language, e.g., by providing a language menu on the site. Most user agents provide a default value for the Accept-Language header that's adapted to the user interface language. End users often don't modify it because they either don't know how or aren't able to do so based on their computing environment.
Once a user has overridden the server-chosen language, a site should no longer use language detection and should stick with the explicitly chosen language. In other words, only entry pages for a site should use this header to select the proper language.
The User-Agent header
Note:
Though there are legitimate uses of this header for selecting content, it's considered bad practice to rely on it to define what features are supported by the user agent.

The User-Agent header identifies the browser sending the request. This string may contain a space-separated list of product tokens and comments.
A product token is a name followed by a / and a version number, like Firefox/4.0.1. The user agent can include as many of these as it wants. A comment is an optional string delimited by parentheses. The information provided in a comment isn't standardized, though several browsers add several tokens to it separated by ;.The Vary response headerIn contrast to the previous Accept-* headers, which are sent by the client, the Vary HTTP header is sent by the web server in its response. It indicates the list of headers the server uses during the server-driven content negotiation phase. The Vary header is needed to inform the cache of the decision criteria so that it can reproduce it. This allows the cache to be functional while ensuring that the right content is served to the user.
The special value * means that the server-driven content negotiation also uses information not conveyed in a header to choose the appropriate content.
The Vary header was added in version 1.1 of HTTP and allows caches to work appropriately. To work with server-driven content negotiation, a cache needs to know which criteria the server used to select the transmitted content. That way, the cache can replay the algorithm and will be able to serve acceptable content directly, without more requests to the server. Obviously, the wildcard * prevents caching from occurring, as the cache can't know what element is behind it. For more information, see HTTP caching > Varying responses.Agent-driven negotiationServer-driven negotiation has a few drawbacks: it doesn't scale well. One header per feature is used in the negotiation. If you want to use screen size, resolution, or other dimensions, you need to create a new HTTP header. The headers must then be sent with every request. This isn't an issue if there are only a few headers, but as the number of headers increases, the message size could eventually affect performance. The more precisely headers are sent, the more entropy is sent, allowing for more HTTP fingerprinting and corresponding privacy concerns.
HTTP allows another negotiation type: agent-driven negotiation or reactive negotiation. In this case, the server sends back a page that contains links to the available alternative resources when faced with an ambiguous request. The user is presented the resources and chooses the one to use.

Unfortunately, the HTTP standard doesn't specify the format of the page for choosing between the available resources, which prevents the process from being automated. Besides falling back to the server-driven negotiation, this method is almost always used with scripting, especially with JavaScript redirection: after having checked for the negotiation criteria, the script performs the redirection. A second problem is that one more request is needed to fetch the real resource, slowing the availability of the resource to the user.See also
Caching\n\nContent negotiationIn HTTP, content negotiation is the mechanism that is used for serving different representations of a resource to the same URI to help the user agent specify which representation is best suited for the user (for example, which document language, which image format, or which content encoding).

Note:
You'll find some disadvantages of HTTP content negotiation in a wiki page from WHATWG. HTML provides alternatives to content negotiation via, for example, the <source> element.
Principles of content negotiationA specific document is called a resource. When a client wants to obtain a resource, the client requests it via a URL. The server uses this URL to choose one of the variants available–each variant is called a representation–and returns a specific representation to the client. The overall resource, as well as each of the representations, has a specific URL. Content negotiation determines how a specific representation is chosen when the resource is called. There are several ways of negotiating between the client and the server.

The best-suited representation is identified through one of two mechanisms:

Specific HTTP headers by the client (server-driven negotiation or proactive negotiation), which is the standard way of negotiating a specific kind of resource.
The 300 (Multiple Choices) or 406 (Not Acceptable), 415 (Unsupported Media Type) HTTP response codes by the server (agent-driven negotiation or reactive negotiation), that are used as fallback mechanisms.

Over the years, other content negotiation proposals, like transparent content negotiation and the Alternates header, have been proposed. They failed to get traction and were abandoned.Server-driven content negotiationIn server-driven content negotiation, or proactive content negotiation, the browser (or any other kind of user agent) sends several HTTP headers along with the URL. These headers describe the user's preferred choice. The server uses them as hints and an internal algorithm chooses the best content to serve to the client. If it can't provide a suitable resource, it might respond with 406 (Not Acceptable) or 415 (Unsupported Media Type) and set headers for the types of media that it does support (e.g., using the Accept-Post or Accept-Patch for POST and PATCH requests, respectively). The algorithm is server-specific and not defined in the standard. See the Apache negotiation algorithm.

The HTTP/1.1 standard defines list of the standard headers that start server-driven negotiation (such as Accept, Accept-Encoding, and Accept-Language). Though User-Agent isn't in this list, it's sometimes also used to send a specific representation of the requested resource. However, this isn't always considered a good practice. The server uses the Vary header to indicate which headers it actually used for content negotiation (or more precisely, the associated request headers), so that caches can work optimally.
In addition to these, there's an experimental proposal to add more headers to the list of available headers, called client hints. Client hints advertise what kind of device the user agent runs on (for example, a desktop computer or a mobile device).
Even if server-driven content negotiation is the most common way to agree on a specific representation of a resource, it has several drawbacks:

The server doesn't have total knowledge of the browser. Even with the Client Hints extension, it doesn't have a complete knowledge of the capabilities of the browser. Unlike reactive content negotiation where the client makes the choice, the server choice is always somewhat arbitrary.
The information from the client is quite verbose (HTTP/2 header compression mitigates this problem) and a privacy risk (HTTP fingerprinting).
As several representations of a given resource are sent, shared caches are less efficient and server implementations are more complex.
The Accept headerThe Accept header lists the MIME types of media resources that the agent is willing to process. This is a comma-separated list of MIME types, each combined with a quality factor, a parameter that indicates the relative degree of preference between the different MIME types.
The Accept header is defined by the browser, or any other user agent, and can vary according to the context. For example, fetching an HTML page or an image, a video, or a script. It's different when fetching a document entered in the address bar or an element linked via an <img>, <video>, or <audio> element. Browsers are free to use the value of the header that they think is the most adequate; an exhaustive list of default values for common browsers is available.The Accept-CH header
Note:
This is part of an experimental technology called Client Hints. Initial support comes in Chrome 46 or later. The Device-Memory value is in Chrome 61 or later.

The experimental Accept-CH lists configuration data that the server can use to select an appropriate response. Valid values are:



Value
Meaning




Device-Memory
Indicates the approximate amount of device RAM. This value is an approximation given by rounding to the nearest power of 2 and dividing that number by 1024. For example, 512 megabytes will be reported as 0.5.


Viewport-Width
Indicates the layout viewport width in CSS pixels.


Width
Indicates the resource width in physical pixels (in other words the intrinsic size of an image).


The Accept-Encoding headerThe Accept-Encoding header defines the acceptable content encoding (supported compressions). The value is a q-factor list (e.g., br, gzip;q=0.8) that indicates the priority of the encoding values. The default value identity is at the lowest priority (unless otherwise noted).
Compressing HTTP messages is one of the most important ways to improve the performance of a website. It shrinks the size of the data transmitted and makes better use of the available bandwidth. Browsers always send this header and the server should be configured to use compression.The Accept-Language headerThe Accept-Language header is used to indicate the language preference of the user. It's a list of values with quality factors (e.g., de, en;q=0.7). A default value is often set according to the language of the graphical interface of the user agent, but most browsers allow different language preferences to be set.
Due to the configuration-based entropy increase, a modified value can be used to fingerprint the user. It's not recommended to change it and a website can't trust this value to reflect the actual intention of the user. It's best for site designers to avoid using language detection via this header as it can lead to a poor user experience.

They should always provide a way to override the server-chosen language, e.g., by providing a language menu on the site. Most user agents provide a default value for the Accept-Language header that's adapted to the user interface language. End users often don't modify it because they either don't know how or aren't able to do so based on their computing environment.
Once a user has overridden the server-chosen language, a site should no longer use language detection and should stick with the explicitly chosen language. In other words, only entry pages for a site should use this header to select the proper language.
The User-Agent header
Note:
Though there are legitimate uses of this header for selecting content, it's considered bad practice to rely on it to define what features are supported by the user agent.

The User-Agent header identifies the browser sending the request. This string may contain a space-separated list of product tokens and comments.
A product token is a name followed by a / and a version number, like Firefox/4.0.1. The user agent can include as many of these as it wants. A comment is an optional string delimited by parentheses. The information provided in a comment isn't standardized, though several browsers add several tokens to it separated by ;.The Vary response headerIn contrast to the previous Accept-* headers, which are sent by the client, the Vary HTTP header is sent by the web server in its response. It indicates the list of headers the server uses during the server-driven content negotiation phase. The Vary header is needed to inform the cache of the decision criteria so that it can reproduce it. This allows the cache to be functional while ensuring that the right content is served to the user.
The special value * means that the server-driven content negotiation also uses information not conveyed in a header to choose the appropriate content.
The Vary header was added in version 1.1 of HTTP and allows caches to work appropriately. To work with server-driven content negotiation, a cache needs to know which criteria the server used to select the transmitted content. That way, the cache can replay the algorithm and will be able to serve acceptable content directly, without more requests to the server. Obviously, the wildcard * prevents caching from occurring, as the cache can't know what element is behind it. For more information, see HTTP caching > Varying responses.Agent-driven negotiationServer-driven negotiation has a few drawbacks: it doesn't scale well. One header per feature is used in the negotiation. If you want to use screen size, resolution, or other dimensions, you need to create a new HTTP header. The headers must then be sent with every request. This isn't an issue if there are only a few headers, but as the number of headers increases, the message size could eventually affect performance. The more precisely headers are sent, the more entropy is sent, allowing for more HTTP fingerprinting and corresponding privacy concerns.
HTTP allows another negotiation type: agent-driven negotiation or reactive negotiation. In this case, the server sends back a page that contains links to the available alternative resources when faced with an ambiguous request. The user is presented the resources and chooses the one to use.

Unfortunately, the HTTP standard doesn't specify the format of the page for choosing between the available resources, which prevents the process from being automated. Besides falling back to the server-driven negotiation, this method is almost always used with scripting, especially with JavaScript redirection: after having checked for the negotiation criteria, the script performs the redirection. A second problem is that one more request is needed to fetch the real resource, slowing the availability of the resource to the user.See also
Caching
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Apr 10, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nContent negotiationIn HTTP, content negotiation is the mechanism that is used for serving different representations of a resource to the same URI to help the user agent specify which representation is best suited for the user (for example, which document language, which image format, or which content encoding).

Note:
You'll find some disadvantages of HTTP content negotiation in a wiki page from WHATWG. HTML provides alternatives to content negotiation via, for example, the <source> element.
Principles of content negotiationA specific document is called a resource. When a client wants to obtain a resource, the client requests it via a URL. The server uses this URL to choose one of the variants available–each variant is called a representation–and returns a specific representation to the client. The overall resource, as well as each of the representations, has a specific URL. Content negotiation determines how a specific representation is chosen when the resource is called. There are several ways of negotiating between the client and the server.

The best-suited representation is identified through one of two mechanisms:

Specific HTTP headers by the client (server-driven negotiation or proactive negotiation), which is the standard way of negotiating a specific kind of resource.
The 300 (Multiple Choices) or 406 (Not Acceptable), 415 (Unsupported Media Type) HTTP response codes by the server (agent-driven negotiation or reactive negotiation), that are used as fallback mechanisms.

Over the years, other content negotiation proposals, like transparent content negotiation and the Alternates header, have been proposed. They failed to get traction and were abandoned.Server-driven content negotiationIn server-driven content negotiation, or proactive content negotiation, the browser (or any other kind of user agent) sends several HTTP headers along with the URL. These headers describe the user's preferred choice. The server uses them as hints and an internal algorithm chooses the best content to serve to the client. If it can't provide a suitable resource, it might respond with 406 (Not Acceptable) or 415 (Unsupported Media Type) and set headers for the types of media that it does support (e.g., using the Accept-Post or Accept-Patch for POST and PATCH requests, respectively). The algorithm is server-specific and not defined in the standard. See the Apache negotiation algorithm.

The HTTP/1.1 standard defines list of the standard headers that start server-driven negotiation (such as Accept, Accept-Encoding, and Accept-Language). Though User-Agent isn't in this list, it's sometimes also used to send a specific representation of the requested resource. However, this isn't always considered a good practice. The server uses the Vary header to indicate which headers it actually used for content negotiation (or more precisely, the associated request headers), so that caches can work optimally.
In addition to these, there's an experimental proposal to add more headers to the list of available headers, called client hints. Client hints advertise what kind of device the user agent runs on (for example, a desktop computer or a mobile device).
Even if server-driven content negotiation is the most common way to agree on a specific representation of a resource, it has several drawbacks:

The server doesn't have total knowledge of the browser. Even with the Client Hints extension, it doesn't have a complete knowledge of the capabilities of the browser. Unlike reactive content negotiation where the client makes the choice, the server choice is always somewhat arbitrary.
The information from the client is quite verbose (HTTP/2 header compression mitigates this problem) and a privacy risk (HTTP fingerprinting).
As several representations of a given resource are sent, shared caches are less efficient and server implementations are more complex.
The Accept headerThe Accept header lists the MIME types of media resources that the agent is willing to process. This is a comma-separated list of MIME types, each combined with a quality factor, a parameter that indicates the relative degree of preference between the different MIME types.
The Accept header is defined by the browser, or any other user agent, and can vary according to the context. For example, fetching an HTML page or an image, a video, or a script. It's different when fetching a document entered in the address bar or an element linked via an <img>, <video>, or <audio> element. Browsers are free to use the value of the header that they think is the most adequate; an exhaustive list of default values for common browsers is available.The Accept-CH header
Note:
This is part of an experimental technology called Client Hints. Initial support comes in Chrome 46 or later. The Device-Memory value is in Chrome 61 or later.

The experimental Accept-CH lists configuration data that the server can use to select an appropriate response. Valid values are:



Value
Meaning




Device-Memory
Indicates the approximate amount of device RAM. This value is an approximation given by rounding to the nearest power of 2 and dividing that number by 1024. For example, 512 megabytes will be reported as 0.5.


Viewport-Width
Indicates the layout viewport width in CSS pixels.


Width
Indicates the resource width in physical pixels (in other words the intrinsic size of an image).


The Accept-Encoding headerThe Accept-Encoding header defines the acceptable content encoding (supported compressions). The value is a q-factor list (e.g., br, gzip;q=0.8) that indicates the priority of the encoding values. The default value identity is at the lowest priority (unless otherwise noted).
Compressing HTTP messages is one of the most important ways to improve the performance of a website. It shrinks the size of the data transmitted and makes better use of the available bandwidth. Browsers always send this header and the server should be configured to use compression.The Accept-Language headerThe Accept-Language header is used to indicate the language preference of the user. It's a list of values with quality factors (e.g., de, en;q=0.7). A default value is often set according to the language of the graphical interface of the user agent, but most browsers allow different language preferences to be set.
Due to the configuration-based entropy increase, a modified value can be used to fingerprint the user. It's not recommended to change it and a website can't trust this value to reflect the actual intention of the user. It's best for site designers to avoid using language detection via this header as it can lead to a poor user experience.

They should always provide a way to override the server-chosen language, e.g., by providing a language menu on the site. Most user agents provide a default value for the Accept-Language header that's adapted to the user interface language. End users often don't modify it because they either don't know how or aren't able to do so based on their computing environment.
Once a user has overridden the server-chosen language, a site should no longer use language detection and should stick with the explicitly chosen language. In other words, only entry pages for a site should use this header to select the proper language.
The User-Agent header
Note:
Though there are legitimate uses of this header for selecting content, it's considered bad practice to rely on it to define what features are supported by the user agent.

The User-Agent header identifies the browser sending the request. This string may contain a space-separated list of product tokens and comments.
A product token is a name followed by a / and a version number, like Firefox/4.0.1. The user agent can include as many of these as it wants. A comment is an optional string delimited by parentheses. The information provided in a comment isn't standardized, though several browsers add several tokens to it separated by ;.The Vary response headerIn contrast to the previous Accept-* headers, which are sent by the client, the Vary HTTP header is sent by the web server in its response. It indicates the list of headers the server uses during the server-driven content negotiation phase. The Vary header is needed to inform the cache of the decision criteria so that it can reproduce it. This allows the cache to be functional while ensuring that the right content is served to the user.
The special value * means that the server-driven content negotiation also uses information not conveyed in a header to choose the appropriate content.
The Vary header was added in version 1.1 of HTTP and allows caches to work appropriately. To work with server-driven content negotiation, a cache needs to know which criteria the server used to select the transmitted content. That way, the cache can replay the algorithm and will be able to serve acceptable content directly, without more requests to the server. Obviously, the wildcard * prevents caching from occurring, as the cache can't know what element is behind it. For more information, see HTTP caching > Varying responses.Agent-driven negotiationServer-driven negotiation has a few drawbacks: it doesn't scale well. One header per feature is used in the negotiation. If you want to use screen size, resolution, or other dimensions, you need to create a new HTTP header. The headers must then be sent with every request. This isn't an issue if there are only a few headers, but as the number of headers increases, the message size could eventually affect performance. The more precisely headers are sent, the more entropy is sent, allowing for more HTTP fingerprinting and corresponding privacy concerns.
HTTP allows another negotiation type: agent-driven negotiation or reactive negotiation. In this case, the server sends back a page that contains links to the available alternative resources when faced with an ambiguous request. The user is presented the resources and chooses the one to use.

Unfortunately, the HTTP standard doesn't specify the format of the page for choosing between the available resources, which prevents the process from being automated. Besides falling back to the server-driven negotiation, this method is almost always used with scripting, especially with JavaScript redirection: after having checked for the negotiation criteria, the script performs the redirection. A second problem is that one more request is needed to fetch the real resource, slowing the availability of the resource to the user.See also
Caching
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Apr 10, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nInhaltsaushandlungIm HTTP ist die Inhaltsaushandlung das Mechanismus, das verwendet wird, um verschiedene Darstellungen einer Ressource unter derselben URI bereitzustellen, um dem Benutzeragenten zu helfen, die Darstellung zu spezifizieren, die am besten für den Benutzer geeignet ist (zum Beispiel, welche Dokumentensprache, welches Bildformat oder welche Inhaltskodierung).

Hinweis:
Sie finden einige Nachteile der HTTP-Inhaltsaushandlung auf einer Wiki-Seite der WHATWG. HTML bietet Alternativen zur Inhaltsaushandlung zum Beispiel über das <source>-Element.
Prinzipien der InhaltsaushandlungEin spezifisches Dokument wird als Ressource bezeichnet. Wenn ein Client eine Ressource beziehen möchte, fordert der Client diese über eine URL an. Der Server verwendet diese URL, um eine der verfügbaren Varianten auszuwählen – jede Variante wird als Darstellung bezeichnet – und gibt dem Client eine spezifische Darstellung zurück. Die gesamte Ressource sowie jede der Darstellungen hat eine spezifische URL. Die Inhaltsaushandlung bestimmt, wie eine spezifische Darstellung ausgewählt wird, wenn die Ressource angefordert wird. Es gibt mehrere Möglichkeiten der Aushandlung zwischen dem Client und dem Server.

Die am besten geeignete Darstellung wird durch einen von zwei Mechanismen identifiziert:

Spezifische HTTP-Header vom Client (serverseitige Aushandlung oder proaktive Aushandlung), was die übliche Art der Aushandlung einer bestimmten Art von Ressource ist.
Die 300 (Multiple Choices) oder 406 (Not Acceptable), 415 (Unsupported Media Type) HTTP-Antwortcodes vom Server (agentengetriebene Aushandlung oder reaktive Aushandlung), die als Rückfallmechanismen verwendet werden.

Im Laufe der Jahre wurden andere Vorschläge zur Inhaltsaushandlung gemacht, wie die transparente Inhaltsaushandlung und der Alternates-Header. Diese konnten sich jedoch nicht durchsetzen und wurden aufgegeben.Serverseitige InhaltsaushandlungBei der serverseitigen Inhaltsaushandlung oder proaktiven Inhaltsaushandlung sendet der Browser (oder jeder andere Benutzeragent) mehrere HTTP-Header zusammen mit der URL. Diese Header beschreiben die bevorzugte Wahl des Benutzers. Der Server verwendet sie als Hinweise und ein interner Algorithmus wählt den besten Inhalt aus, um ihn dem Client bereitzustellen. Wenn er keine geeignete Ressource bereitstellen kann, könnte er mit 406 (Not Acceptable) oder 415 (Unsupported Media Type) antworten und Header für die unterstützten Medientypen setzen (z.B. unter Verwendung von Accept-Post oder Accept-Patch für POST- und PATCH-Anfragen respektive). Der Algorithmus ist spezifisch für den Server und nicht im Standard definiert. Siehe den Apache-Aushandlungsalgorithmus.

Der HTTP/1.1-Standard definiert eine Liste der Standardheader, die die serverseitige Aushandlung starten (wie z.B. Accept, Accept-Encoding und Accept-Language). Obwohl User-Agent nicht in dieser Liste enthalten ist, wird er manchmal auch verwendet, um eine spezifische Darstellung der angeforderten Ressource zu senden. Dies wird jedoch nicht immer als gute Praxis angesehen. Der Server verwendet den Vary-Header, um anzuzeigen, welche Header er tatsächlich für die Inhaltsaushandlung (oder präziser gesagt, die damit verbundenen Anforderungsheader) verwendet hat, damit Caches optimal funktionieren können.
Zusätzlich dazu gibt es einen experimentellen Vorschlag, mehr Header zur Liste der verfügbaren Header hinzuzufügen, genannt Client-Hinweise. Client-Hinweise geben an, auf welcher Art von Gerät der Benutzeragent ausgeführt wird (zum Beispiel auf einem Desktop-Computer oder einem mobilen Gerät).
Auch wenn serverseitige Inhaltsaushandlung die häufigste Methode zur Vereinbarung einer spezifischen Darstellung einer Ressource ist, hat sie mehrere Nachteile:

Der Server hat kein vollständiges Wissen über den Browser. Selbst mit der Client-Hinweise-Erweiterung hat er kein vollständiges Wissen über die Fähigkeiten des Browsers. Im Gegensatz zur reaktiven Inhaltsaushandlung, bei der der Client die Wahl trifft, bleibt die Serverentscheidung immer ein Stück weit willkürlich.
Die Informationen vom Client sind ziemlich umfangreich (HTTP/2-Header-Komprimierung mildert dieses Problem) und ein Datenschutzrisiko (HTTP-Fingerprinting).
Da mehrere Darstellungen einer gegebenen Ressource gesendet werden, sind gemeinsame Caches weniger effizient und Serverimplementierungen sind komplexer.
Der Accept-HeaderDer Accept-Header listet die MIME-Typen von Medienressourcen auf, die der Agent zu verarbeiten bereit ist. Dies ist eine durch Kommas getrennte Liste von MIME-Typen, die jeweils mit einem Qualitätsfaktor kombiniert sind, einem Parameter, der den relativen Grad der Präferenz zwischen den verschiedenen MIME-Typen angibt.
Der Accept-Header wird vom Browser oder einem anderen Benutzeragenten definiert und kann je nach Kontext variieren. Zum Beispiel, beim Abrufen einer HTML-Seite oder eines Bildes, eines Videos oder eines Skripts. Er ist unterschiedlich, wenn ein Dokument in der Adressleiste eingegeben oder ein Element über ein <img>, <video> oder <audio>-Element verlinkt wird. Browser sind frei, den Headerwert zu verwenden, den sie für am angemessensten halten; eine umfassende Liste der Standardwerte für gängige Browser ist verfügbar.Der Accept-CH-Header
Hinweis:
Dies ist Teil einer experimentellen Technologie namens Client-Hinweise. Erste Unterstützung kommt in Chrome 46 oder später. Der Device-Memory-Wert ist in Chrome 61 oder später verfügbar.

Der experimentelle Accept-CH-Header listet Konfigurationsdaten auf, die der Server verwenden kann, um eine geeignete Antwort auszuwählen. Gültige Werte sind:



Wert
Bedeutung




Device-Memory
Gibt die ungefähre Menge an Gerät-RAM an. Dieser Wert ist eine Annäherung, die durch Rundung auf die nächste Zweierpotenz gegeben ist und durch 1024 dividiert wird. Zum Beispiel wird 512 Megabyte als 0.5 gemeldet.


Viewport-Width
Gibt die Breite des Layout-Viewports in CSS-Pixeln an.


Width
Gibt die Ressourcenbreite in physischen Pixeln an (also die intrinsische Größe eines Bildes).


Der Accept-Encoding-HeaderDer Accept-Encoding-Header definiert die akzeptable Inhaltskodierung (unterstützte Kompressionen). Der Wert ist eine Q-Faktor-Liste (z.B. br, gzip;q=0.8), die die Priorität der Kodierungswerte angibt. Der Standardwert identity hat die niedrigste Priorität (es sei denn, anders angegeben).
Die Komprimierung von HTTP-Nachrichten ist eine der wichtigsten Methoden zur Verbesserung der Leistung einer Website. Sie reduziert die Größe der übertragenen Daten und nutzt die verfügbare Bandbreite besser aus. Browser senden diesen Header immer und der Server sollte so konfiguriert sein, dass er Kompression verwendet.Der Accept-Language-HeaderDer Accept-Language-Header wird verwendet, um die Sprachpräferenz des Benutzers anzuzeigen. Es handelt sich um eine Liste von Werten mit Qualitätsfaktoren (z.B. de, en;q=0.7). Ein Standardwert wird oft entsprechend der Sprache der grafischen Benutzeroberfläche des Benutzeragenten gesetzt, aber die meisten Browser ermöglichen es, unterschiedliche Sprachpräferenzen zu setzen.
Aufgrund der Konfigurationsbasierten Entropie -Zunahme kann ein modifizierter Wert verwendet werden, um den Benutzer zu fingerprinten. Es wird nicht empfohlen, ihn zu ändern, und eine Website kann diesem Wert nicht vertrauen, um die tatsächliche Absicht des Benutzers widerzuspiegeln. Es ist am besten, wenn Site-Designer die Spracherkennung über diesen Header vermeiden, da dies zu einem schlechten Benutzererlebnis führen kann.

Sie sollten immer eine Möglichkeit bieten, die vom Server gewählte Sprache zu überschreiben, z.B. durch ein Sprachmenü auf der Seite. Die meisten Benutzeragenten bieten einen Standardwert für den Accept-Language-Header, der an die Sprache der Benutzeroberfläche angepasst ist. Endbenutzer ändern ihn oft nicht, weil sie entweder nicht wissen, wie oder aufgrund ihrer Computerumgebung nicht dazu in der Lage sind.
Sobald ein Benutzer die vom Server gewählte Sprache überschrieben hat, sollte eine Site keine Spracheerkennung mehr verwenden und bei der explizit gewählten Sprache bleiben. Mit anderen Worten, nur Einstiegsseiten für eine Site sollten diesen Header verwenden, um die richtige Sprache auszuwählen.
Der User-Agent-Header
Hinweis:
Obwohl es legitime Anwendungen dieses Headers zur Inhaltsauswahl gibt, wird es als schlechte Praxis angesehen, sich darauf zu verlassen, um zu definieren, welche Funktionen vom Benutzeragent unterstützt werden.

Der User-Agent-Header identifiziert den Browser, der die Anfrage sendet. Dieser String kann eine durch Leerzeichen getrennte Liste von Produkttokens und Kommentaren enthalten.
Ein Produkttoken ist ein Name, gefolgt von einem / und einer Versionsnummer, wie Firefox/4.0.1. Der Benutzeragent kann so viele davon einfügen, wie er möchte. Ein Kommentar ist ein optionaler String, der in Klammern eingeschlossen ist. Die im Kommentar enthaltenen Informationen sind nicht standardisiert, obwohl mehrere Browser mehrere Tokens dazu trennen, die durch ; getrennt sind.Der Vary-AntwortheaderIm Gegensatz zu den vorherigen Accept-*-Headern, die vom Client gesendet werden, wird der Vary-HTTP-Header vom Webserver in seiner Antwort gesendet. Er gibt die Liste der Header an, die der Server während der serverseitigen Inhaltsaushandlungsphase verwendet hat. Der Vary-Header ist notwendig, um den Cache über die Entscheidungskriterien zu informieren, damit er diesen reproduzieren kann. Dies ermöglicht es dem Cache, funktional zu bleiben, während sichergestellt wird, dass der richtige Inhalt dem Benutzer bereitgestellt wird.
Der spezielle Wert * bedeutet, dass die serverseitige Inhaltsaushandlung auch Informationen verwendet, die nicht in einem Header übermittelt werden, um den geeigneten Inhalt auszuwählen.
Der Vary-Header wurde in Version 1.1 von HTTP hinzugefügt und ermöglicht Caches, ordnungsgemäß zu funktionieren. Um mit serverseitiger Inhaltsaushandlung zu arbeiten, muss ein Cache wissen, welche Kriterien der Server zur Auswahl des übertragenen Inhalts verwendet hat. Auf diese Weise kann der Cache den Algorithmus erneut abspielen und akzeptablen Inhalt direkt bereitstellen, ohne weitere Anfragen an den Server zu stellen. Offensichtlich verhindert der Platzhalter *, dass das Caching erfolgt, da der Cache nicht weiß, welches Element dahinter steckt. Weitere Informationen finden Sie unter HTTP Caching > Varying responses.Agentengetriebene AushandlungDie serverseitige Aushandlung hat einige Nachteile: Sie skaliert nicht gut. Ein Header pro Merkmal wird in der Aushandlung verwendet. Wenn Sie die Bildschirmgröße, Auflösung oder andere Dimensionen verwenden möchten, müssen Sie einen neuen HTTP-Header erstellen. Die Header müssen dann bei jedem Request mitgesendet werden. Dies ist kein Problem, wenn es nur wenige Header gibt, aber wenn die Anzahl der Header zunimmt, könnte die Nachrichtengröße möglicherweise die Leistung beeinträchtigen. Je genauer Header gesendet werden, desto mehr Entropie wird gesendet, was mehr HTTP-Fingerprinting und entsprechende Datenschutzbedenken ermöglicht.
HTTP erlaubt eine andere Aushandlungsart: agentengetriebene Aushandlung oder reaktive Aushandlung. In diesem Fall sendet der Server eine Seite zurück, die Links zu den verfügbaren alternativen Ressourcen enthält, wenn er mit einer mehrdeutigen Anfrage konfrontiert ist. Der Benutzer erhält die Ressourcen und wählt die zu verwendende aus.

Leider spezifiziert der HTTP-Standard nicht das Format der Seite zur Auswahl zwischen den verfügbaren Ressourcen, was den Prozess von Automatisierung abhält. Abgesehen vom Rückgriff auf die serverseitige Aushandlung wird diese Methode fast immer mit Scripting verwendet, insbesondere mit JavaScript-Weiterleitung: Nachdem die Aushandlungskriterien überprüft wurden, führt das Skript die Weiterleitung durch. Ein zweites Problem ist, dass eine weitere Anfrage erforderlich ist, um die eigentliche Ressource abzurufen, was die Verfügbarkeit der Ressource für den Benutzer verlangsamt.Siehe auch
Caching\n\nInhaltsaushandlungIm HTTP ist die Inhaltsaushandlung das Mechanismus, das verwendet wird, um verschiedene Darstellungen einer Ressource unter derselben URI bereitzustellen, um dem Benutzeragenten zu helfen, die Darstellung zu spezifizieren, die am besten für den Benutzer geeignet ist (zum Beispiel, welche Dokumentensprache, welches Bildformat oder welche Inhaltskodierung).

Hinweis:
Sie finden einige Nachteile der HTTP-Inhaltsaushandlung auf einer Wiki-Seite der WHATWG. HTML bietet Alternativen zur Inhaltsaushandlung zum Beispiel über das <source>-Element.
Prinzipien der InhaltsaushandlungEin spezifisches Dokument wird als Ressource bezeichnet. Wenn ein Client eine Ressource beziehen möchte, fordert der Client diese über eine URL an. Der Server verwendet diese URL, um eine der verfügbaren Varianten auszuwählen – jede Variante wird als Darstellung bezeichnet – und gibt dem Client eine spezifische Darstellung zurück. Die gesamte Ressource sowie jede der Darstellungen hat eine spezifische URL. Die Inhaltsaushandlung bestimmt, wie eine spezifische Darstellung ausgewählt wird, wenn die Ressource angefordert wird. Es gibt mehrere Möglichkeiten der Aushandlung zwischen dem Client und dem Server.

Die am besten geeignete Darstellung wird durch einen von zwei Mechanismen identifiziert:

Spezifische HTTP-Header vom Client (serverseitige Aushandlung oder proaktive Aushandlung), was die übliche Art der Aushandlung einer bestimmten Art von Ressource ist.
Die 300 (Multiple Choices) oder 406 (Not Acceptable), 415 (Unsupported Media Type) HTTP-Antwortcodes vom Server (agentengetriebene Aushandlung oder reaktive Aushandlung), die als Rückfallmechanismen verwendet werden.

Im Laufe der Jahre wurden andere Vorschläge zur Inhaltsaushandlung gemacht, wie die transparente Inhaltsaushandlung und der Alternates-Header. Diese konnten sich jedoch nicht durchsetzen und wurden aufgegeben.Serverseitige InhaltsaushandlungBei der serverseitigen Inhaltsaushandlung oder proaktiven Inhaltsaushandlung sendet der Browser (oder jeder andere Benutzeragent) mehrere HTTP-Header zusammen mit der URL. Diese Header beschreiben die bevorzugte Wahl des Benutzers. Der Server verwendet sie als Hinweise und ein interner Algorithmus wählt den besten Inhalt aus, um ihn dem Client bereitzustellen. Wenn er keine geeignete Ressource bereitstellen kann, könnte er mit 406 (Not Acceptable) oder 415 (Unsupported Media Type) antworten und Header für die unterstützten Medientypen setzen (z.B. unter Verwendung von Accept-Post oder Accept-Patch für POST- und PATCH-Anfragen respektive). Der Algorithmus ist spezifisch für den Server und nicht im Standard definiert. Siehe den Apache-Aushandlungsalgorithmus.

Der HTTP/1.1-Standard definiert eine Liste der Standardheader, die die serverseitige Aushandlung starten (wie z.B. Accept, Accept-Encoding und Accept-Language). Obwohl User-Agent nicht in dieser Liste enthalten ist, wird er manchmal auch verwendet, um eine spezifische Darstellung der angeforderten Ressource zu senden. Dies wird jedoch nicht immer als gute Praxis angesehen. Der Server verwendet den Vary-Header, um anzuzeigen, welche Header er tatsächlich für die Inhaltsaushandlung (oder präziser gesagt, die damit verbundenen Anforderungsheader) verwendet hat, damit Caches optimal funktionieren können.
Zusätzlich dazu gibt es einen experimentellen Vorschlag, mehr Header zur Liste der verfügbaren Header hinzuzufügen, genannt Client-Hinweise. Client-Hinweise geben an, auf welcher Art von Gerät der Benutzeragent ausgeführt wird (zum Beispiel auf einem Desktop-Computer oder einem mobilen Gerät).
Auch wenn serverseitige Inhaltsaushandlung die häufigste Methode zur Vereinbarung einer spezifischen Darstellung einer Ressource ist, hat sie mehrere Nachteile:

Der Server hat kein vollständiges Wissen über den Browser. Selbst mit der Client-Hinweise-Erweiterung hat er kein vollständiges Wissen über die Fähigkeiten des Browsers. Im Gegensatz zur reaktiven Inhaltsaushandlung, bei der der Client die Wahl trifft, bleibt die Serverentscheidung immer ein Stück weit willkürlich.
Die Informationen vom Client sind ziemlich umfangreich (HTTP/2-Header-Komprimierung mildert dieses Problem) und ein Datenschutzrisiko (HTTP-Fingerprinting).
Da mehrere Darstellungen einer gegebenen Ressource gesendet werden, sind gemeinsame Caches weniger effizient und Serverimplementierungen sind komplexer.
Der Accept-HeaderDer Accept-Header listet die MIME-Typen von Medienressourcen auf, die der Agent zu verarbeiten bereit ist. Dies ist eine durch Kommas getrennte Liste von MIME-Typen, die jeweils mit einem Qualitätsfaktor kombiniert sind, einem Parameter, der den relativen Grad der Präferenz zwischen den verschiedenen MIME-Typen angibt.
Der Accept-Header wird vom Browser oder einem anderen Benutzeragenten definiert und kann je nach Kontext variieren. Zum Beispiel, beim Abrufen einer HTML-Seite oder eines Bildes, eines Videos oder eines Skripts. Er ist unterschiedlich, wenn ein Dokument in der Adressleiste eingegeben oder ein Element über ein <img>, <video> oder <audio>-Element verlinkt wird. Browser sind frei, den Headerwert zu verwenden, den sie für am angemessensten halten; eine umfassende Liste der Standardwerte für gängige Browser ist verfügbar.Der Accept-CH-Header
Hinweis:
Dies ist Teil einer experimentellen Technologie namens Client-Hinweise. Erste Unterstützung kommt in Chrome 46 oder später. Der Device-Memory-Wert ist in Chrome 61 oder später verfügbar.

Der experimentelle Accept-CH-Header listet Konfigurationsdaten auf, die der Server verwenden kann, um eine geeignete Antwort auszuwählen. Gültige Werte sind:



Wert
Bedeutung




Device-Memory
Gibt die ungefähre Menge an Gerät-RAM an. Dieser Wert ist eine Annäherung, die durch Rundung auf die nächste Zweierpotenz gegeben ist und durch 1024 dividiert wird. Zum Beispiel wird 512 Megabyte als 0.5 gemeldet.


Viewport-Width
Gibt die Breite des Layout-Viewports in CSS-Pixeln an.


Width
Gibt die Ressourcenbreite in physischen Pixeln an (also die intrinsische Größe eines Bildes).


Der Accept-Encoding-HeaderDer Accept-Encoding-Header definiert die akzeptable Inhaltskodierung (unterstützte Kompressionen). Der Wert ist eine Q-Faktor-Liste (z.B. br, gzip;q=0.8), die die Priorität der Kodierungswerte angibt. Der Standardwert identity hat die niedrigste Priorität (es sei denn, anders angegeben).
Die Komprimierung von HTTP-Nachrichten ist eine der wichtigsten Methoden zur Verbesserung der Leistung einer Website. Sie reduziert die Größe der übertragenen Daten und nutzt die verfügbare Bandbreite besser aus. Browser senden diesen Header immer und der Server sollte so konfiguriert sein, dass er Kompression verwendet.Der Accept-Language-HeaderDer Accept-Language-Header wird verwendet, um die Sprachpräferenz des Benutzers anzuzeigen. Es handelt sich um eine Liste von Werten mit Qualitätsfaktoren (z.B. de, en;q=0.7). Ein Standardwert wird oft entsprechend der Sprache der grafischen Benutzeroberfläche des Benutzeragenten gesetzt, aber die meisten Browser ermöglichen es, unterschiedliche Sprachpräferenzen zu setzen.
Aufgrund der Konfigurationsbasierten Entropie -Zunahme kann ein modifizierter Wert verwendet werden, um den Benutzer zu fingerprinten. Es wird nicht empfohlen, ihn zu ändern, und eine Website kann diesem Wert nicht vertrauen, um die tatsächliche Absicht des Benutzers widerzuspiegeln. Es ist am besten, wenn Site-Designer die Spracherkennung über diesen Header vermeiden, da dies zu einem schlechten Benutzererlebnis führen kann.

Sie sollten immer eine Möglichkeit bieten, die vom Server gewählte Sprache zu überschreiben, z.B. durch ein Sprachmenü auf der Seite. Die meisten Benutzeragenten bieten einen Standardwert für den Accept-Language-Header, der an die Sprache der Benutzeroberfläche angepasst ist. Endbenutzer ändern ihn oft nicht, weil sie entweder nicht wissen, wie oder aufgrund ihrer Computerumgebung nicht dazu in der Lage sind.
Sobald ein Benutzer die vom Server gewählte Sprache überschrieben hat, sollte eine Site keine Spracheerkennung mehr verwenden und bei der explizit gewählten Sprache bleiben. Mit anderen Worten, nur Einstiegsseiten für eine Site sollten diesen Header verwenden, um die richtige Sprache auszuwählen.
Der User-Agent-Header
Hinweis:
Obwohl es legitime Anwendungen dieses Headers zur Inhaltsauswahl gibt, wird es als schlechte Praxis angesehen, sich darauf zu verlassen, um zu definieren, welche Funktionen vom Benutzeragent unterstützt werden.

Der User-Agent-Header identifiziert den Browser, der die Anfrage sendet. Dieser String kann eine durch Leerzeichen getrennte Liste von Produkttokens und Kommentaren enthalten.
Ein Produkttoken ist ein Name, gefolgt von einem / und einer Versionsnummer, wie Firefox/4.0.1. Der Benutzeragent kann so viele davon einfügen, wie er möchte. Ein Kommentar ist ein optionaler String, der in Klammern eingeschlossen ist. Die im Kommentar enthaltenen Informationen sind nicht standardisiert, obwohl mehrere Browser mehrere Tokens dazu trennen, die durch ; getrennt sind.Der Vary-AntwortheaderIm Gegensatz zu den vorherigen Accept-*-Headern, die vom Client gesendet werden, wird der Vary-HTTP-Header vom Webserver in seiner Antwort gesendet. Er gibt die Liste der Header an, die der Server während der serverseitigen Inhaltsaushandlungsphase verwendet hat. Der Vary-Header ist notwendig, um den Cache über die Entscheidungskriterien zu informieren, damit er diesen reproduzieren kann. Dies ermöglicht es dem Cache, funktional zu bleiben, während sichergestellt wird, dass der richtige Inhalt dem Benutzer bereitgestellt wird.
Der spezielle Wert * bedeutet, dass die serverseitige Inhaltsaushandlung auch Informationen verwendet, die nicht in einem Header übermittelt werden, um den geeigneten Inhalt auszuwählen.
Der Vary-Header wurde in Version 1.1 von HTTP hinzugefügt und ermöglicht Caches, ordnungsgemäß zu funktionieren. Um mit serverseitiger Inhaltsaushandlung zu arbeiten, muss ein Cache wissen, welche Kriterien der Server zur Auswahl des übertragenen Inhalts verwendet hat. Auf diese Weise kann der Cache den Algorithmus erneut abspielen und akzeptablen Inhalt direkt bereitstellen, ohne weitere Anfragen an den Server zu stellen. Offensichtlich verhindert der Platzhalter *, dass das Caching erfolgt, da der Cache nicht weiß, welches Element dahinter steckt. Weitere Informationen finden Sie unter HTTP Caching > Varying responses.Agentengetriebene AushandlungDie serverseitige Aushandlung hat einige Nachteile: Sie skaliert nicht gut. Ein Header pro Merkmal wird in der Aushandlung verwendet. Wenn Sie die Bildschirmgröße, Auflösung oder andere Dimensionen verwenden möchten, müssen Sie einen neuen HTTP-Header erstellen. Die Header müssen dann bei jedem Request mitgesendet werden. Dies ist kein Problem, wenn es nur wenige Header gibt, aber wenn die Anzahl der Header zunimmt, könnte die Nachrichtengröße möglicherweise die Leistung beeinträchtigen. Je genauer Header gesendet werden, desto mehr Entropie wird gesendet, was mehr HTTP-Fingerprinting und entsprechende Datenschutzbedenken ermöglicht.
HTTP erlaubt eine andere Aushandlungsart: agentengetriebene Aushandlung oder reaktive Aushandlung. In diesem Fall sendet der Server eine Seite zurück, die Links zu den verfügbaren alternativen Ressourcen enthält, wenn er mit einer mehrdeutigen Anfrage konfrontiert ist. Der Benutzer erhält die Ressourcen und wählt die zu verwendende aus.

Leider spezifiziert der HTTP-Standard nicht das Format der Seite zur Auswahl zwischen den verfügbaren Ressourcen, was den Prozess von Automatisierung abhält. Abgesehen vom Rückgriff auf die serverseitige Aushandlung wird diese Methode fast immer mit Scripting verwendet, insbesondere mit JavaScript-Weiterleitung: Nachdem die Aushandlungskriterien überprüft wurden, führt das Skript die Weiterleitung durch. Ein zweites Problem ist, dass eine weitere Anfrage erforderlich ist, um die eigentliche Ressource abzurufen, was die Verfügbarkeit der Ressource für den Benutzer verlangsamt.Siehe auch
Caching
MDN-Feedback-BoxWar diese Übersetzung hilfreich?JaNeinDiese Seite wurde automatisch aus dem Englischen übersetzt.Übersetzung auf GitHub anzeigen • Fehler mit dieser Übersetzung melden\n\nInhaltsaushandlungIm HTTP ist die Inhaltsaushandlung das Mechanismus, das verwendet wird, um verschiedene Darstellungen einer Ressource unter derselben URI bereitzustellen, um dem Benutzeragenten zu helfen, die Darstellung zu spezifizieren, die am besten für den Benutzer geeignet ist (zum Beispiel, welche Dokumentensprache, welches Bildformat oder welche Inhaltskodierung).

Hinweis:
Sie finden einige Nachteile der HTTP-Inhaltsaushandlung auf einer Wiki-Seite der WHATWG. HTML bietet Alternativen zur Inhaltsaushandlung zum Beispiel über das <source>-Element.
Prinzipien der InhaltsaushandlungEin spezifisches Dokument wird als Ressource bezeichnet. Wenn ein Client eine Ressource beziehen möchte, fordert der Client diese über eine URL an. Der Server verwendet diese URL, um eine der verfügbaren Varianten auszuwählen – jede Variante wird als Darstellung bezeichnet – und gibt dem Client eine spezifische Darstellung zurück. Die gesamte Ressource sowie jede der Darstellungen hat eine spezifische URL. Die Inhaltsaushandlung bestimmt, wie eine spezifische Darstellung ausgewählt wird, wenn die Ressource angefordert wird. Es gibt mehrere Möglichkeiten der Aushandlung zwischen dem Client und dem Server.

Die am besten geeignete Darstellung wird durch einen von zwei Mechanismen identifiziert:

Spezifische HTTP-Header vom Client (serverseitige Aushandlung oder proaktive Aushandlung), was die übliche Art der Aushandlung einer bestimmten Art von Ressource ist.
Die 300 (Multiple Choices) oder 406 (Not Acceptable), 415 (Unsupported Media Type) HTTP-Antwortcodes vom Server (agentengetriebene Aushandlung oder reaktive Aushandlung), die als Rückfallmechanismen verwendet werden.

Im Laufe der Jahre wurden andere Vorschläge zur Inhaltsaushandlung gemacht, wie die transparente Inhaltsaushandlung und der Alternates-Header. Diese konnten sich jedoch nicht durchsetzen und wurden aufgegeben.Serverseitige InhaltsaushandlungBei der serverseitigen Inhaltsaushandlung oder proaktiven Inhaltsaushandlung sendet der Browser (oder jeder andere Benutzeragent) mehrere HTTP-Header zusammen mit der URL. Diese Header beschreiben die bevorzugte Wahl des Benutzers. Der Server verwendet sie als Hinweise und ein interner Algorithmus wählt den besten Inhalt aus, um ihn dem Client bereitzustellen. Wenn er keine geeignete Ressource bereitstellen kann, könnte er mit 406 (Not Acceptable) oder 415 (Unsupported Media Type) antworten und Header für die unterstützten Medientypen setzen (z.B. unter Verwendung von Accept-Post oder Accept-Patch für POST- und PATCH-Anfragen respektive). Der Algorithmus ist spezifisch für den Server und nicht im Standard definiert. Siehe den Apache-Aushandlungsalgorithmus.

Der HTTP/1.1-Standard definiert eine Liste der Standardheader, die die serverseitige Aushandlung starten (wie z.B. Accept, Accept-Encoding und Accept-Language). Obwohl User-Agent nicht in dieser Liste enthalten ist, wird er manchmal auch verwendet, um eine spezifische Darstellung der angeforderten Ressource zu senden. Dies wird jedoch nicht immer als gute Praxis angesehen. Der Server verwendet den Vary-Header, um anzuzeigen, welche Header er tatsächlich für die Inhaltsaushandlung (oder präziser gesagt, die damit verbundenen Anforderungsheader) verwendet hat, damit Caches optimal funktionieren können.
Zusätzlich dazu gibt es einen experimentellen Vorschlag, mehr Header zur Liste der verfügbaren Header hinzuzufügen, genannt Client-Hinweise. Client-Hinweise geben an, auf welcher Art von Gerät der Benutzeragent ausgeführt wird (zum Beispiel auf einem Desktop-Computer oder einem mobilen Gerät).
Auch wenn serverseitige Inhaltsaushandlung die häufigste Methode zur Vereinbarung einer spezifischen Darstellung einer Ressource ist, hat sie mehrere Nachteile:

Der Server hat kein vollständiges Wissen über den Browser. Selbst mit der Client-Hinweise-Erweiterung hat er kein vollständiges Wissen über die Fähigkeiten des Browsers. Im Gegensatz zur reaktiven Inhaltsaushandlung, bei der der Client die Wahl trifft, bleibt die Serverentscheidung immer ein Stück weit willkürlich.
Die Informationen vom Client sind ziemlich umfangreich (HTTP/2-Header-Komprimierung mildert dieses Problem) und ein Datenschutzrisiko (HTTP-Fingerprinting).
Da mehrere Darstellungen einer gegebenen Ressource gesendet werden, sind gemeinsame Caches weniger effizient und Serverimplementierungen sind komplexer.
Der Accept-HeaderDer Accept-Header listet die MIME-Typen von Medienressourcen auf, die der Agent zu verarbeiten bereit ist. Dies ist eine durch Kommas getrennte Liste von MIME-Typen, die jeweils mit einem Qualitätsfaktor kombiniert sind, einem Parameter, der den relativen Grad der Präferenz zwischen den verschiedenen MIME-Typen angibt.
Der Accept-Header wird vom Browser oder einem anderen Benutzeragenten definiert und kann je nach Kontext variieren. Zum Beispiel, beim Abrufen einer HTML-Seite oder eines Bildes, eines Videos oder eines Skripts. Er ist unterschiedlich, wenn ein Dokument in der Adressleiste eingegeben oder ein Element über ein <img>, <video> oder <audio>-Element verlinkt wird. Browser sind frei, den Headerwert zu verwenden, den sie für am angemessensten halten; eine umfassende Liste der Standardwerte für gängige Browser ist verfügbar.Der Accept-CH-Header
Hinweis:
Dies ist Teil einer experimentellen Technologie namens Client-Hinweise. Erste Unterstützung kommt in Chrome 46 oder später. Der Device-Memory-Wert ist in Chrome 61 oder später verfügbar.

Der experimentelle Accept-CH-Header listet Konfigurationsdaten auf, die der Server verwenden kann, um eine geeignete Antwort auszuwählen. Gültige Werte sind:



Wert
Bedeutung




Device-Memory
Gibt die ungefähre Menge an Gerät-RAM an. Dieser Wert ist eine Annäherung, die durch Rundung auf die nächste Zweierpotenz gegeben ist und durch 1024 dividiert wird. Zum Beispiel wird 512 Megabyte als 0.5 gemeldet.


Viewport-Width
Gibt die Breite des Layout-Viewports in CSS-Pixeln an.


Width
Gibt die Ressourcenbreite in physischen Pixeln an (also die intrinsische Größe eines Bildes).


Der Accept-Encoding-HeaderDer Accept-Encoding-Header definiert die akzeptable Inhaltskodierung (unterstützte Kompressionen). Der Wert ist eine Q-Faktor-Liste (z.B. br, gzip;q=0.8), die die Priorität der Kodierungswerte angibt. Der Standardwert identity hat die niedrigste Priorität (es sei denn, anders angegeben).
Die Komprimierung von HTTP-Nachrichten ist eine der wichtigsten Methoden zur Verbesserung der Leistung einer Website. Sie reduziert die Größe der übertragenen Daten und nutzt die verfügbare Bandbreite besser aus. Browser senden diesen Header immer und der Server sollte so konfiguriert sein, dass er Kompression verwendet.Der Accept-Language-HeaderDer Accept-Language-Header wird verwendet, um die Sprachpräferenz des Benutzers anzuzeigen. Es handelt sich um eine Liste von Werten mit Qualitätsfaktoren (z.B. de, en;q=0.7). Ein Standardwert wird oft entsprechend der Sprache der grafischen Benutzeroberfläche des Benutzeragenten gesetzt, aber die meisten Browser ermöglichen es, unterschiedliche Sprachpräferenzen zu setzen.
Aufgrund der Konfigurationsbasierten Entropie -Zunahme kann ein modifizierter Wert verwendet werden, um den Benutzer zu fingerprinten. Es wird nicht empfohlen, ihn zu ändern, und eine Website kann diesem Wert nicht vertrauen, um die tatsächliche Absicht des Benutzers widerzuspiegeln. Es ist am besten, wenn Site-Designer die Spracherkennung über diesen Header vermeiden, da dies zu einem schlechten Benutzererlebnis führen kann.

Sie sollten immer eine Möglichkeit bieten, die vom Server gewählte Sprache zu überschreiben, z.B. durch ein Sprachmenü auf der Seite. Die meisten Benutzeragenten bieten einen Standardwert für den Accept-Language-Header, der an die Sprache der Benutzeroberfläche angepasst ist. Endbenutzer ändern ihn oft nicht, weil sie entweder nicht wissen, wie oder aufgrund ihrer Computerumgebung nicht dazu in der Lage sind.
Sobald ein Benutzer die vom Server gewählte Sprache überschrieben hat, sollte eine Site keine Spracheerkennung mehr verwenden und bei der explizit gewählten Sprache bleiben. Mit anderen Worten, nur Einstiegsseiten für eine Site sollten diesen Header verwenden, um die richtige Sprache auszuwählen.
Der User-Agent-Header
Hinweis:
Obwohl es legitime Anwendungen dieses Headers zur Inhaltsauswahl gibt, wird es als schlechte Praxis angesehen, sich darauf zu verlassen, um zu definieren, welche Funktionen vom Benutzeragent unterstützt werden.

Der User-Agent-Header identifiziert den Browser, der die Anfrage sendet. Dieser String kann eine durch Leerzeichen getrennte Liste von Produkttokens und Kommentaren enthalten.
Ein Produkttoken ist ein Name, gefolgt von einem / und einer Versionsnummer, wie Firefox/4.0.1. Der Benutzeragent kann so viele davon einfügen, wie er möchte. Ein Kommentar ist ein optionaler String, der in Klammern eingeschlossen ist. Die im Kommentar enthaltenen Informationen sind nicht standardisiert, obwohl mehrere Browser mehrere Tokens dazu trennen, die durch ; getrennt sind.Der Vary-AntwortheaderIm Gegensatz zu den vorherigen Accept-*-Headern, die vom Client gesendet werden, wird der Vary-HTTP-Header vom Webserver in seiner Antwort gesendet. Er gibt die Liste der Header an, die der Server während der serverseitigen Inhaltsaushandlungsphase verwendet hat. Der Vary-Header ist notwendig, um den Cache über die Entscheidungskriterien zu informieren, damit er diesen reproduzieren kann. Dies ermöglicht es dem Cache, funktional zu bleiben, während sichergestellt wird, dass der richtige Inhalt dem Benutzer bereitgestellt wird.
Der spezielle Wert * bedeutet, dass die serverseitige Inhaltsaushandlung auch Informationen verwendet, die nicht in einem Header übermittelt werden, um den geeigneten Inhalt auszuwählen.
Der Vary-Header wurde in Version 1.1 von HTTP hinzugefügt und ermöglicht Caches, ordnungsgemäß zu funktionieren. Um mit serverseitiger Inhaltsaushandlung zu arbeiten, muss ein Cache wissen, welche Kriterien der Server zur Auswahl des übertragenen Inhalts verwendet hat. Auf diese Weise kann der Cache den Algorithmus erneut abspielen und akzeptablen Inhalt direkt bereitstellen, ohne weitere Anfragen an den Server zu stellen. Offensichtlich verhindert der Platzhalter *, dass das Caching erfolgt, da der Cache nicht weiß, welches Element dahinter steckt. Weitere Informationen finden Sie unter HTTP Caching > Varying responses.Agentengetriebene AushandlungDie serverseitige Aushandlung hat einige Nachteile: Sie skaliert nicht gut. Ein Header pro Merkmal wird in der Aushandlung verwendet. Wenn Sie die Bildschirmgröße, Auflösung oder andere Dimensionen verwenden möchten, müssen Sie einen neuen HTTP-Header erstellen. Die Header müssen dann bei jedem Request mitgesendet werden. Dies ist kein Problem, wenn es nur wenige Header gibt, aber wenn die Anzahl der Header zunimmt, könnte die Nachrichtengröße möglicherweise die Leistung beeinträchtigen. Je genauer Header gesendet werden, desto mehr Entropie wird gesendet, was mehr HTTP-Fingerprinting und entsprechende Datenschutzbedenken ermöglicht.
HTTP erlaubt eine andere Aushandlungsart: agentengetriebene Aushandlung oder reaktive Aushandlung. In diesem Fall sendet der Server eine Seite zurück, die Links zu den verfügbaren alternativen Ressourcen enthält, wenn er mit einer mehrdeutigen Anfrage konfrontiert ist. Der Benutzer erhält die Ressourcen und wählt die zu verwendende aus.

Leider spezifiziert der HTTP-Standard nicht das Format der Seite zur Auswahl zwischen den verfügbaren Ressourcen, was den Prozess von Automatisierung abhält. Abgesehen vom Rückgriff auf die serverseitige Aushandlung wird diese Methode fast immer mit Scripting verwendet, insbesondere mit JavaScript-Weiterleitung: Nachdem die Aushandlungskriterien überprüft wurden, führt das Skript die Weiterleitung durch. Ein zweites Problem ist, dass eine weitere Anfrage erforderlich ist, um die eigentliche Ressource abzurufen, was die Verfügbarkeit der Ressource für den Benutzer verlangsamt.Siehe auch
Caching
MDN-Feedback-BoxWar diese Übersetzung hilfreich?JaNeinDiese Seite wurde automatisch aus dem Englischen übersetzt.Übersetzung auf GitHub anzeigen • Fehler mit dieser Übersetzung melden\n\n\n\nLa négociation de contenuEn HTTP, la négociation de contenu est le mécanisme utilisé pour servir différentes représentations d'une ressource à partir du même URI pour aider l'agent utilisateur à indiquer la représentation la plus adaptée à l'utilisatrice ou à l'utilisateur (par exemple, la langue du document, le format d'image ou l'encodage à utiliser pour le contenu).

Note : Le wiki du WHATWG explique certains inconvénients liés à la négociation de contenu HTTP. Sachez que HTML fournit des méthodes complémentaires pour la négociation de contenu, par exemple avec l'élément <source>.
Les principes de la négociation de contenuUn document donné est défini comme une ressource. Lorsqu'un client souhaite obtenir une ressource, il la demande via une URL. Le serveur utilise alors cette URL pour choisir l'une des variantes disponibles. Chaque variante est appelée une représentation. Le serveur renvoie alors une représentation donnée au client. La ressource, ainsi que chacune de ses représentations, dispose d'une URL spécifique. La négociation de contenu détermine quelle représentation donnée est utilisée lorsque la ressource est demandée. Il existe plusieurs méthodes de négociation entre le client et le serveur.

La représentation la plus adaptée est choisie selon l'un de ces deux mécanismes :

Des en-têtes HTTP spécifiques envoyés par le client (négociation menée par le serveur ou négociation proactive) : il s'agit de la méthode standard pour négocier un type de ressource donné.
Les codes de réponse HTTP 300 Multiple Choices, 406 Not Acceptable ou 415 Unsupported Media Type envoyés par le serveur (négociation menée par l'agent ou négociation réactive), sont utilisés comme mécanismes de recours.

Au fur et à mesure des années, d'autres propositions relatives à la négociation de contenu ont été faites, comme la négociation de contenu transparente et l'en-tête Alternates. Toutefois, elles n'ont pas suffisamment pris d'ampleur et ont finalement été abandonnées.Négociation de contenu menée par le serveurLors d'une négociation de contenu menée par le serveur (aussi appelée négociation de contenu proactive), le navigateur (ou tout autre agent utilisateur) envoie plusieurs en-têtes HTTP avec l'URL. Ces en-têtes décrivent les préférences de la personne. Le serveur utilise alors ces en-têtes comme indications et un algorithme interne détermine le meilleur contenu à servir au client. Si le serveur ne peut fournir une ressource adéquate, il peut répondre avec les erreurs 406 Not Acceptable ou 415 Unsupported Media Type et renvoyer des en-têtes indiquant les types de média qu'il prend en charge (par exemple avec Accept-Post ou Accept-Patch selon que la requête utilise respectivement le verbe POST ou PATCH). L'algorithme est propre au serveur et n'est pas défini par le standard. Comme exemple, vous pouvez consulter l'algorithme de négociation utilisé par le serveur HTTP httpd d'Apache.

Le standard HTTP/1.1 définit une liste des en-têtes standard qui initient la négociation menée par le serveur (comme Accept, Accept-Encoding, et Accept-Language). Bien que l'en-tête User-Agent ne soit pas dans cette liste, il est parfois utilisé en pratique pour déterminer la ressource à envoyer, bien que ce ne soit pas une bonne pratique. Le serveur utilise l'en-tête Vary pour indiquer les en-têtes effectivement utilisés pour la négociation de contenu (ou, plus précisément, les en-têtes correspondants à ceux de la requête), afin que les caches puissent fonctionner de façon optimale.
En complément de ces en-têtes, une proposition expérimentale décrit plusieurs en-têtes supplémentaires appelés indications client (client hints). Ces indications exposent le type d'appareil sur lequel est utilisé l'agent utilisateur (par exemple un ordinateur de bureau ou un appareil).
Même si la négociation menée par le serveur est la méthode la plus fréquemment employée pour s'accorder sur la représentation spécifique d'une ressource, elle souffre de plusieurs inconvénients :

Le serveur ne connaît pas tout du navigateur. Même avec les indications client, le serveur ne peut connaître toutes les capacités du navigateur. Contrairement à la négociation de contenu menée par le client, où c'est ce dernier qui fait le choix, le choix du serveur repose toujours sur une partie d'arbitraire.
Les informations envoyées par le client sont assez verbeuses (la compression des en-têtes HTTP/2 atténue ce problème) et peuvent être un risque quant à la vie privée (en permettant par exemple de construire des empreintes HTTP uniques).
Lorsque plusieurs représentations d'une même ressource sont envoyées par le serveur, l'efficacité des caches est réduite et les implémentations des serveurs deviennent plus complexes.
L'en-tête AcceptL'en-tête Accept liste les types MIME des ressources média que l'agent accepte de traiter. Il s'agit d'une liste de types MIME séparés par des virgules, chacun associé avec un facteur de qualité indiquant la préférence relative entre chaque type MIME.
L'en-tête Accept est défini par le navigateur (ou tout autre agent utilisateur) et peut varier selon le contexte, par exemple que la ressource soit une page HTML, une image, une vidéo ou un script. Cet en-tête sera différent selon qu'on récupère un document demandé via la barre d'adresse, ou une ressource désignée par un élément <img>, <video>, ou <audio>. Les navigateurs peuvent utiliser la valeur d'en-tête qu'ils estiment la plus adéquate. Une liste exhaustive des valeurs par défaut pour les navigateurs principaux est disponible.L'en-tête Accept-CH 
Expérimental

Note :
Cet en-tête fait partie de la technologie expérimentale des indications client (client hints). La prise en charge initiale est arrivée avec Chrome 46 et celle de la valeur Device-Memory avec Chrome 61.

L'en-tête expérimental Accept-CH expose les données de configuration que le serveur peut utiliser afin de déterminer une réponse appropriée. Les valeurs valides sont :



Valeur
Signification




Device-Memory
Indique la quantité approximative de mémoire vive de l'appareil. Cette valeur est une approximation à la puissance de deux la plus proche, divisée par 1024. Ainsi, 512 mégaoctets seront indiqués par la valeur 0.5.


Viewport-Width
Indique la largeur de la zone d'affichage (viewport) en pixels CSS.


Width
Indique la largeur de la ressource en pixels physiques (autrement dit, la taille intrinsèque d'une image).


L'en-tête Accept-CH-Lifetime 
Expérimental

Note :
Cet en-tête fait partie de la technologie expérimentale des indications client (client hints) et est uniquement disponible pour Chrome, à partir de Chrome 61.

L'en-tête Accept-CH-Lifetime est utilisé de concert avec la valeur Device-Memory de l'en-tête Accept-CH et indique la durée pendant laquelle l'appareil devrait partager sa quantité de mémoire vive. La valeur est exprimée en millisecondes et est optionnelle.L'en-tête Accept-EncodingL'en-tête Accept-Encoding définit les encodages de contenu acceptables (et les compressions associées). La valeur est une liste de valeurs pondérées (par exemple, br, gzip;q=0.8) qui indique la priorité de chaque encodage. La valeur par défaut, identity reçoit la priorité la plus basse (sauf mention contraire).
La compression des messages HTTP est l'une des méthodes majeures pour améliorer la performance d'un site web. Elle permet de réduire la taille des données transmises sur le réseau et de mieux utiliser la bande passant. Les navigateurs envoient toujours cet en-tête et le serveur devrait être configuré pour utiliser de la compression.L'en-tête Accept-LanguageL'en-tête Accept-Language sert à indiquer la langue à privilégier pour l'utilisatrice ou l'utilisateur. Il s'agit d'une liste de valeurs pondérées (par exemple de, en;q=0.7). Une valeur par défaut est généralement paramétrée à travers l'interface graphique de l'agent utilisateur, mais la plupart des navigateurs autorisent la sélection de plusieurs langues.
En raison de l'entropie croissante déduite de la configuration, une valeur modifiée peut être utilisée pour tracer la personne. Il n'est pas recommandé de la charger et un site web ne peut pas intégralement se baser sur cette valeur pour déduire l'intention effective de la personne. Il est préférable d'éviter la détection des langues via cet en-tête, car l'expérience utilisateur peut être dégradée.

Les sites devraient toujours fournir une méthode pour passer outre la langue sélectionnée par défaut par le serveur, par exemple en fournissant un menu de sélection des langues. La plupart des agents utilisateur fournissent une valeur par défaut pour l'en-tête Accept-Language qui est adaptée à la langue de l'interface utilisateur. Les utilisatrices et utilisateurs finaux ne modifient pas nécessairement ce réglage, soit parce qu'ils ne savent pas comment, soit parce que celui-ci est basé sur l'environnement sous-jacent (par exemple, la langue configurée sur l'ordinateur).
Une fois que la personne a choisi une autre langue que celle fournie par le serveur par défaut, un site ne devrait plus utiliser la détection de langue, mais conserver l'utilisation de la langue choisie. Autrement dit, seules les pages d'accueil d'un site devraient utiliser cet en-tête pour sélectionner la langue à utiliser.
L'en-tête User-Agent
Note :
Bien qu'il existe certains cas d'usage légitimes pour cet en-tête afin de sélectionner du contenu, il s'agit d'une mauvaise pratique quand il s'agit de déterminer les fonctionnalités prises en charge ou non par l'agent utilisateur.

L'en-tête User-Agent identifie le navigateur qui envoie la requête. Cette chaîne de caractères peut contenir une liste de jetons produits et de commentaires séparés par des espaces.
Un jeton produit est un nom suivi par une barre oblique (/) puis d'un numéro de version (par exemple Firefox/4.0.1). L'agent utilisateur peut inclure autant de jetons qu'il le souhaite. Un commentaire est une chaîne de caractères optionnelle délimitée par des parenthèses. Les informations qui sont fournies par le commentaire ne sont pas standardisées, bien que plusieurs navigateurs y ajoutent plusieurs jetons séparés par des points-virgules.L'en-tête de réponse VaryContrairement aux en-têtes Accept-* précédents qui sont envoyés par le client, l'en-tête HTTP Vary est envoyé par le serveur dans la réponse. Il indique la liste des en-têtes que le serveur utilise pendant la phase de négociation menée par le serveur. L'en-tête Vary est nécessaire pour informer le cache des critères de décision afin qu'il puisse les reproduire. Cela permet au cache d'être opérationnel tout en s'assurant que le bon contenu est servi au client.
La valeur spéciale * signifie que la négociation menée par le serveur utilise également des informations qui ne sont pas transmises par un en-tête afin de déterminer le contenu approprié.
L'en-tête Vary a été ajouté à la version 1.1 de HTTP et permet le fonctionnement approprié. Pour fonctionner lors de la négociation menée par le serveur, un cache a besoin de connaître les critères utilisés par le serveur pour sélectionner le contenu à transmettre. Ainsi, le cache peut rejouer l'algorithme et être capable de servir le contenu acceptable directement, sans envoyer d'autres requêtes au serveur. Bien entendu, le joker * empêche toute mise en cache, car le cache ne peut alors pas savoir l'élément responsable de la sélection. Pour plus d'informations, voir mise en cache HTTP > réponses variantes.Négociation menée par l'agentLa négociation menée par le serveur possède quelques inconvénients : elle s'étend assez mal. Un en-tête est utilisé par fonctionnalité lors de la négociation. Si on veut utiliser la taille d'écran, la résolution ou d'autres dimensions, il faudra créer un nouvel en-tête HTTP. Les en-têtes doivent ensuite être envoyés à chaque requête. Ce n'est pas un problème lorsqu'il y a peu d'en-têtes, mais si le nombre d'en-têtes devient trop élevé, la taille du message pourra avoir un impact sur les performances. En contrepartie, plus des en-têtes précis sont envoyés, plus d'entropie est envoyée, facilitant le pistage et l'identification via des empreintes HTTP.
HTTP permet un autre type de négociation : la négociation menée par l'agent, aussi appelée négociation réactive. Dans ce cas, le serveur envoie une page contenant les liens vers les différentes ressources alternatives lorsqu'il reçoit une requête ambigüe. Les ressources seront présentées à l'utilisatrice ou à l'utilisateur, qui choisira celle à utiliser.

Cependant, le standard HTTP ne définit pas le format de la page pour le choix entre les ressources disponibles, ce qui empêche d'automatiser le procédé. En plus d'utiliser la négociation menée par le serveur en cas de recours, cette méthode est toujours utilisée avec des scripts. Il faut aussi plus d'une requête pour obtenir la ressource finale, ralentissant ainsi l'arrivée de la ressource jusqu'au client.\n\nLa négociation de contenuEn HTTP, la négociation de contenu est le mécanisme utilisé pour servir différentes représentations d'une ressource à partir du même URI pour aider l'agent utilisateur à indiquer la représentation la plus adaptée à l'utilisatrice ou à l'utilisateur (par exemple, la langue du document, le format d'image ou l'encodage à utiliser pour le contenu).

Note : Le wiki du WHATWG explique certains inconvénients liés à la négociation de contenu HTTP. Sachez que HTML fournit des méthodes complémentaires pour la négociation de contenu, par exemple avec l'élément <source>.
Les principes de la négociation de contenuUn document donné est défini comme une ressource. Lorsqu'un client souhaite obtenir une ressource, il la demande via une URL. Le serveur utilise alors cette URL pour choisir l'une des variantes disponibles. Chaque variante est appelée une représentation. Le serveur renvoie alors une représentation donnée au client. La ressource, ainsi que chacune de ses représentations, dispose d'une URL spécifique. La négociation de contenu détermine quelle représentation donnée est utilisée lorsque la ressource est demandée. Il existe plusieurs méthodes de négociation entre le client et le serveur.

La représentation la plus adaptée est choisie selon l'un de ces deux mécanismes :

Des en-têtes HTTP spécifiques envoyés par le client (négociation menée par le serveur ou négociation proactive) : il s'agit de la méthode standard pour négocier un type de ressource donné.
Les codes de réponse HTTP 300 Multiple Choices, 406 Not Acceptable ou 415 Unsupported Media Type envoyés par le serveur (négociation menée par l'agent ou négociation réactive), sont utilisés comme mécanismes de recours.

Au fur et à mesure des années, d'autres propositions relatives à la négociation de contenu ont été faites, comme la négociation de contenu transparente et l'en-tête Alternates. Toutefois, elles n'ont pas suffisamment pris d'ampleur et ont finalement été abandonnées.Négociation de contenu menée par le serveurLors d'une négociation de contenu menée par le serveur (aussi appelée négociation de contenu proactive), le navigateur (ou tout autre agent utilisateur) envoie plusieurs en-têtes HTTP avec l'URL. Ces en-têtes décrivent les préférences de la personne. Le serveur utilise alors ces en-têtes comme indications et un algorithme interne détermine le meilleur contenu à servir au client. Si le serveur ne peut fournir une ressource adéquate, il peut répondre avec les erreurs 406 Not Acceptable ou 415 Unsupported Media Type et renvoyer des en-têtes indiquant les types de média qu'il prend en charge (par exemple avec Accept-Post ou Accept-Patch selon que la requête utilise respectivement le verbe POST ou PATCH). L'algorithme est propre au serveur et n'est pas défini par le standard. Comme exemple, vous pouvez consulter l'algorithme de négociation utilisé par le serveur HTTP httpd d'Apache.

Le standard HTTP/1.1 définit une liste des en-têtes standard qui initient la négociation menée par le serveur (comme Accept, Accept-Encoding, et Accept-Language). Bien que l'en-tête User-Agent ne soit pas dans cette liste, il est parfois utilisé en pratique pour déterminer la ressource à envoyer, bien que ce ne soit pas une bonne pratique. Le serveur utilise l'en-tête Vary pour indiquer les en-têtes effectivement utilisés pour la négociation de contenu (ou, plus précisément, les en-têtes correspondants à ceux de la requête), afin que les caches puissent fonctionner de façon optimale.
En complément de ces en-têtes, une proposition expérimentale décrit plusieurs en-têtes supplémentaires appelés indications client (client hints). Ces indications exposent le type d'appareil sur lequel est utilisé l'agent utilisateur (par exemple un ordinateur de bureau ou un appareil).
Même si la négociation menée par le serveur est la méthode la plus fréquemment employée pour s'accorder sur la représentation spécifique d'une ressource, elle souffre de plusieurs inconvénients :

Le serveur ne connaît pas tout du navigateur. Même avec les indications client, le serveur ne peut connaître toutes les capacités du navigateur. Contrairement à la négociation de contenu menée par le client, où c'est ce dernier qui fait le choix, le choix du serveur repose toujours sur une partie d'arbitraire.
Les informations envoyées par le client sont assez verbeuses (la compression des en-têtes HTTP/2 atténue ce problème) et peuvent être un risque quant à la vie privée (en permettant par exemple de construire des empreintes HTTP uniques).
Lorsque plusieurs représentations d'une même ressource sont envoyées par le serveur, l'efficacité des caches est réduite et les implémentations des serveurs deviennent plus complexes.
L'en-tête AcceptL'en-tête Accept liste les types MIME des ressources média que l'agent accepte de traiter. Il s'agit d'une liste de types MIME séparés par des virgules, chacun associé avec un facteur de qualité indiquant la préférence relative entre chaque type MIME.
L'en-tête Accept est défini par le navigateur (ou tout autre agent utilisateur) et peut varier selon le contexte, par exemple que la ressource soit une page HTML, une image, une vidéo ou un script. Cet en-tête sera différent selon qu'on récupère un document demandé via la barre d'adresse, ou une ressource désignée par un élément <img>, <video>, ou <audio>. Les navigateurs peuvent utiliser la valeur d'en-tête qu'ils estiment la plus adéquate. Une liste exhaustive des valeurs par défaut pour les navigateurs principaux est disponible.L'en-tête Accept-CH 
Expérimental

Note :
Cet en-tête fait partie de la technologie expérimentale des indications client (client hints). La prise en charge initiale est arrivée avec Chrome 46 et celle de la valeur Device-Memory avec Chrome 61.

L'en-tête expérimental Accept-CH expose les données de configuration que le serveur peut utiliser afin de déterminer une réponse appropriée. Les valeurs valides sont :



Valeur
Signification




Device-Memory
Indique la quantité approximative de mémoire vive de l'appareil. Cette valeur est une approximation à la puissance de deux la plus proche, divisée par 1024. Ainsi, 512 mégaoctets seront indiqués par la valeur 0.5.


Viewport-Width
Indique la largeur de la zone d'affichage (viewport) en pixels CSS.


Width
Indique la largeur de la ressource en pixels physiques (autrement dit, la taille intrinsèque d'une image).


L'en-tête Accept-CH-Lifetime 
Expérimental

Note :
Cet en-tête fait partie de la technologie expérimentale des indications client (client hints) et est uniquement disponible pour Chrome, à partir de Chrome 61.

L'en-tête Accept-CH-Lifetime est utilisé de concert avec la valeur Device-Memory de l'en-tête Accept-CH et indique la durée pendant laquelle l'appareil devrait partager sa quantité de mémoire vive. La valeur est exprimée en millisecondes et est optionnelle.L'en-tête Accept-EncodingL'en-tête Accept-Encoding définit les encodages de contenu acceptables (et les compressions associées). La valeur est une liste de valeurs pondérées (par exemple, br, gzip;q=0.8) qui indique la priorité de chaque encodage. La valeur par défaut, identity reçoit la priorité la plus basse (sauf mention contraire).
La compression des messages HTTP est l'une des méthodes majeures pour améliorer la performance d'un site web. Elle permet de réduire la taille des données transmises sur le réseau et de mieux utiliser la bande passant. Les navigateurs envoient toujours cet en-tête et le serveur devrait être configuré pour utiliser de la compression.L'en-tête Accept-LanguageL'en-tête Accept-Language sert à indiquer la langue à privilégier pour l'utilisatrice ou l'utilisateur. Il s'agit d'une liste de valeurs pondérées (par exemple de, en;q=0.7). Une valeur par défaut est généralement paramétrée à travers l'interface graphique de l'agent utilisateur, mais la plupart des navigateurs autorisent la sélection de plusieurs langues.
En raison de l'entropie croissante déduite de la configuration, une valeur modifiée peut être utilisée pour tracer la personne. Il n'est pas recommandé de la charger et un site web ne peut pas intégralement se baser sur cette valeur pour déduire l'intention effective de la personne. Il est préférable d'éviter la détection des langues via cet en-tête, car l'expérience utilisateur peut être dégradée.

Les sites devraient toujours fournir une méthode pour passer outre la langue sélectionnée par défaut par le serveur, par exemple en fournissant un menu de sélection des langues. La plupart des agents utilisateur fournissent une valeur par défaut pour l'en-tête Accept-Language qui est adaptée à la langue de l'interface utilisateur. Les utilisatrices et utilisateurs finaux ne modifient pas nécessairement ce réglage, soit parce qu'ils ne savent pas comment, soit parce que celui-ci est basé sur l'environnement sous-jacent (par exemple, la langue configurée sur l'ordinateur).
Une fois que la personne a choisi une autre langue que celle fournie par le serveur par défaut, un site ne devrait plus utiliser la détection de langue, mais conserver l'utilisation de la langue choisie. Autrement dit, seules les pages d'accueil d'un site devraient utiliser cet en-tête pour sélectionner la langue à utiliser.
L'en-tête User-Agent
Note :
Bien qu'il existe certains cas d'usage légitimes pour cet en-tête afin de sélectionner du contenu, il s'agit d'une mauvaise pratique quand il s'agit de déterminer les fonctionnalités prises en charge ou non par l'agent utilisateur.

L'en-tête User-Agent identifie le navigateur qui envoie la requête. Cette chaîne de caractères peut contenir une liste de jetons produits et de commentaires séparés par des espaces.
Un jeton produit est un nom suivi par une barre oblique (/) puis d'un numéro de version (par exemple Firefox/4.0.1). L'agent utilisateur peut inclure autant de jetons qu'il le souhaite. Un commentaire est une chaîne de caractères optionnelle délimitée par des parenthèses. Les informations qui sont fournies par le commentaire ne sont pas standardisées, bien que plusieurs navigateurs y ajoutent plusieurs jetons séparés par des points-virgules.L'en-tête de réponse VaryContrairement aux en-têtes Accept-* précédents qui sont envoyés par le client, l'en-tête HTTP Vary est envoyé par le serveur dans la réponse. Il indique la liste des en-têtes que le serveur utilise pendant la phase de négociation menée par le serveur. L'en-tête Vary est nécessaire pour informer le cache des critères de décision afin qu'il puisse les reproduire. Cela permet au cache d'être opérationnel tout en s'assurant que le bon contenu est servi au client.
La valeur spéciale * signifie que la négociation menée par le serveur utilise également des informations qui ne sont pas transmises par un en-tête afin de déterminer le contenu approprié.
L'en-tête Vary a été ajouté à la version 1.1 de HTTP et permet le fonctionnement approprié. Pour fonctionner lors de la négociation menée par le serveur, un cache a besoin de connaître les critères utilisés par le serveur pour sélectionner le contenu à transmettre. Ainsi, le cache peut rejouer l'algorithme et être capable de servir le contenu acceptable directement, sans envoyer d'autres requêtes au serveur. Bien entendu, le joker * empêche toute mise en cache, car le cache ne peut alors pas savoir l'élément responsable de la sélection. Pour plus d'informations, voir mise en cache HTTP > réponses variantes.Négociation menée par l'agentLa négociation menée par le serveur possède quelques inconvénients : elle s'étend assez mal. Un en-tête est utilisé par fonctionnalité lors de la négociation. Si on veut utiliser la taille d'écran, la résolution ou d'autres dimensions, il faudra créer un nouvel en-tête HTTP. Les en-têtes doivent ensuite être envoyés à chaque requête. Ce n'est pas un problème lorsqu'il y a peu d'en-têtes, mais si le nombre d'en-têtes devient trop élevé, la taille du message pourra avoir un impact sur les performances. En contrepartie, plus des en-têtes précis sont envoyés, plus d'entropie est envoyée, facilitant le pistage et l'identification via des empreintes HTTP.
HTTP permet un autre type de négociation : la négociation menée par l'agent, aussi appelée négociation réactive. Dans ce cas, le serveur envoie une page contenant les liens vers les différentes ressources alternatives lorsqu'il reçoit une requête ambigüe. Les ressources seront présentées à l'utilisatrice ou à l'utilisateur, qui choisira celle à utiliser.

Cependant, le standard HTTP ne définit pas le format de la page pour le choix entre les ressources disponibles, ce qui empêche d'automatiser le procédé. En plus d'utiliser la négociation menée par le serveur en cas de recours, cette méthode est toujours utilisée avec des scripts. Il faut aussi plus d'une requête pour obtenir la ressource finale, ralentissant ainsi l'arrivée de la ressource jusqu'au client.Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on 1 janv. 1970 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nLa négociation de contenuEn HTTP, la négociation de contenu est le mécanisme utilisé pour servir différentes représentations d'une ressource à partir du même URI pour aider l'agent utilisateur à indiquer la représentation la plus adaptée à l'utilisatrice ou à l'utilisateur (par exemple, la langue du document, le format d'image ou l'encodage à utiliser pour le contenu).

Note : Le wiki du WHATWG explique certains inconvénients liés à la négociation de contenu HTTP. Sachez que HTML fournit des méthodes complémentaires pour la négociation de contenu, par exemple avec l'élément <source>.
Les principes de la négociation de contenuUn document donné est défini comme une ressource. Lorsqu'un client souhaite obtenir une ressource, il la demande via une URL. Le serveur utilise alors cette URL pour choisir l'une des variantes disponibles. Chaque variante est appelée une représentation. Le serveur renvoie alors une représentation donnée au client. La ressource, ainsi que chacune de ses représentations, dispose d'une URL spécifique. La négociation de contenu détermine quelle représentation donnée est utilisée lorsque la ressource est demandée. Il existe plusieurs méthodes de négociation entre le client et le serveur.

La représentation la plus adaptée est choisie selon l'un de ces deux mécanismes :

Des en-têtes HTTP spécifiques envoyés par le client (négociation menée par le serveur ou négociation proactive) : il s'agit de la méthode standard pour négocier un type de ressource donné.
Les codes de réponse HTTP 300 Multiple Choices, 406 Not Acceptable ou 415 Unsupported Media Type envoyés par le serveur (négociation menée par l'agent ou négociation réactive), sont utilisés comme mécanismes de recours.

Au fur et à mesure des années, d'autres propositions relatives à la négociation de contenu ont été faites, comme la négociation de contenu transparente et l'en-tête Alternates. Toutefois, elles n'ont pas suffisamment pris d'ampleur et ont finalement été abandonnées.Négociation de contenu menée par le serveurLors d'une négociation de contenu menée par le serveur (aussi appelée négociation de contenu proactive), le navigateur (ou tout autre agent utilisateur) envoie plusieurs en-têtes HTTP avec l'URL. Ces en-têtes décrivent les préférences de la personne. Le serveur utilise alors ces en-têtes comme indications et un algorithme interne détermine le meilleur contenu à servir au client. Si le serveur ne peut fournir une ressource adéquate, il peut répondre avec les erreurs 406 Not Acceptable ou 415 Unsupported Media Type et renvoyer des en-têtes indiquant les types de média qu'il prend en charge (par exemple avec Accept-Post ou Accept-Patch selon que la requête utilise respectivement le verbe POST ou PATCH). L'algorithme est propre au serveur et n'est pas défini par le standard. Comme exemple, vous pouvez consulter l'algorithme de négociation utilisé par le serveur HTTP httpd d'Apache.

Le standard HTTP/1.1 définit une liste des en-têtes standard qui initient la négociation menée par le serveur (comme Accept, Accept-Encoding, et Accept-Language). Bien que l'en-tête User-Agent ne soit pas dans cette liste, il est parfois utilisé en pratique pour déterminer la ressource à envoyer, bien que ce ne soit pas une bonne pratique. Le serveur utilise l'en-tête Vary pour indiquer les en-têtes effectivement utilisés pour la négociation de contenu (ou, plus précisément, les en-têtes correspondants à ceux de la requête), afin que les caches puissent fonctionner de façon optimale.
En complément de ces en-têtes, une proposition expérimentale décrit plusieurs en-têtes supplémentaires appelés indications client (client hints). Ces indications exposent le type d'appareil sur lequel est utilisé l'agent utilisateur (par exemple un ordinateur de bureau ou un appareil).
Même si la négociation menée par le serveur est la méthode la plus fréquemment employée pour s'accorder sur la représentation spécifique d'une ressource, elle souffre de plusieurs inconvénients :

Le serveur ne connaît pas tout du navigateur. Même avec les indications client, le serveur ne peut connaître toutes les capacités du navigateur. Contrairement à la négociation de contenu menée par le client, où c'est ce dernier qui fait le choix, le choix du serveur repose toujours sur une partie d'arbitraire.
Les informations envoyées par le client sont assez verbeuses (la compression des en-têtes HTTP/2 atténue ce problème) et peuvent être un risque quant à la vie privée (en permettant par exemple de construire des empreintes HTTP uniques).
Lorsque plusieurs représentations d'une même ressource sont envoyées par le serveur, l'efficacité des caches est réduite et les implémentations des serveurs deviennent plus complexes.
L'en-tête AcceptL'en-tête Accept liste les types MIME des ressources média que l'agent accepte de traiter. Il s'agit d'une liste de types MIME séparés par des virgules, chacun associé avec un facteur de qualité indiquant la préférence relative entre chaque type MIME.
L'en-tête Accept est défini par le navigateur (ou tout autre agent utilisateur) et peut varier selon le contexte, par exemple que la ressource soit une page HTML, une image, une vidéo ou un script. Cet en-tête sera différent selon qu'on récupère un document demandé via la barre d'adresse, ou une ressource désignée par un élément <img>, <video>, ou <audio>. Les navigateurs peuvent utiliser la valeur d'en-tête qu'ils estiment la plus adéquate. Une liste exhaustive des valeurs par défaut pour les navigateurs principaux est disponible.L'en-tête Accept-CH 
Expérimental

Note :
Cet en-tête fait partie de la technologie expérimentale des indications client (client hints). La prise en charge initiale est arrivée avec Chrome 46 et celle de la valeur Device-Memory avec Chrome 61.

L'en-tête expérimental Accept-CH expose les données de configuration que le serveur peut utiliser afin de déterminer une réponse appropriée. Les valeurs valides sont :



Valeur
Signification




Device-Memory
Indique la quantité approximative de mémoire vive de l'appareil. Cette valeur est une approximation à la puissance de deux la plus proche, divisée par 1024. Ainsi, 512 mégaoctets seront indiqués par la valeur 0.5.


Viewport-Width
Indique la largeur de la zone d'affichage (viewport) en pixels CSS.


Width
Indique la largeur de la ressource en pixels physiques (autrement dit, la taille intrinsèque d'une image).


L'en-tête Accept-CH-Lifetime 
Expérimental

Note :
Cet en-tête fait partie de la technologie expérimentale des indications client (client hints) et est uniquement disponible pour Chrome, à partir de Chrome 61.

L'en-tête Accept-CH-Lifetime est utilisé de concert avec la valeur Device-Memory de l'en-tête Accept-CH et indique la durée pendant laquelle l'appareil devrait partager sa quantité de mémoire vive. La valeur est exprimée en millisecondes et est optionnelle.L'en-tête Accept-EncodingL'en-tête Accept-Encoding définit les encodages de contenu acceptables (et les compressions associées). La valeur est une liste de valeurs pondérées (par exemple, br, gzip;q=0.8) qui indique la priorité de chaque encodage. La valeur par défaut, identity reçoit la priorité la plus basse (sauf mention contraire).
La compression des messages HTTP est l'une des méthodes majeures pour améliorer la performance d'un site web. Elle permet de réduire la taille des données transmises sur le réseau et de mieux utiliser la bande passant. Les navigateurs envoient toujours cet en-tête et le serveur devrait être configuré pour utiliser de la compression.L'en-tête Accept-LanguageL'en-tête Accept-Language sert à indiquer la langue à privilégier pour l'utilisatrice ou l'utilisateur. Il s'agit d'une liste de valeurs pondérées (par exemple de, en;q=0.7). Une valeur par défaut est généralement paramétrée à travers l'interface graphique de l'agent utilisateur, mais la plupart des navigateurs autorisent la sélection de plusieurs langues.
En raison de l'entropie croissante déduite de la configuration, une valeur modifiée peut être utilisée pour tracer la personne. Il n'est pas recommandé de la charger et un site web ne peut pas intégralement se baser sur cette valeur pour déduire l'intention effective de la personne. Il est préférable d'éviter la détection des langues via cet en-tête, car l'expérience utilisateur peut être dégradée.

Les sites devraient toujours fournir une méthode pour passer outre la langue sélectionnée par défaut par le serveur, par exemple en fournissant un menu de sélection des langues. La plupart des agents utilisateur fournissent une valeur par défaut pour l'en-tête Accept-Language qui est adaptée à la langue de l'interface utilisateur. Les utilisatrices et utilisateurs finaux ne modifient pas nécessairement ce réglage, soit parce qu'ils ne savent pas comment, soit parce que celui-ci est basé sur l'environnement sous-jacent (par exemple, la langue configurée sur l'ordinateur).
Une fois que la personne a choisi une autre langue que celle fournie par le serveur par défaut, un site ne devrait plus utiliser la détection de langue, mais conserver l'utilisation de la langue choisie. Autrement dit, seules les pages d'accueil d'un site devraient utiliser cet en-tête pour sélectionner la langue à utiliser.
L'en-tête User-Agent
Note :
Bien qu'il existe certains cas d'usage légitimes pour cet en-tête afin de sélectionner du contenu, il s'agit d'une mauvaise pratique quand il s'agit de déterminer les fonctionnalités prises en charge ou non par l'agent utilisateur.

L'en-tête User-Agent identifie le navigateur qui envoie la requête. Cette chaîne de caractères peut contenir une liste de jetons produits et de commentaires séparés par des espaces.
Un jeton produit est un nom suivi par une barre oblique (/) puis d'un numéro de version (par exemple Firefox/4.0.1). L'agent utilisateur peut inclure autant de jetons qu'il le souhaite. Un commentaire est une chaîne de caractères optionnelle délimitée par des parenthèses. Les informations qui sont fournies par le commentaire ne sont pas standardisées, bien que plusieurs navigateurs y ajoutent plusieurs jetons séparés par des points-virgules.L'en-tête de réponse VaryContrairement aux en-têtes Accept-* précédents qui sont envoyés par le client, l'en-tête HTTP Vary est envoyé par le serveur dans la réponse. Il indique la liste des en-têtes que le serveur utilise pendant la phase de négociation menée par le serveur. L'en-tête Vary est nécessaire pour informer le cache des critères de décision afin qu'il puisse les reproduire. Cela permet au cache d'être opérationnel tout en s'assurant que le bon contenu est servi au client.
La valeur spéciale * signifie que la négociation menée par le serveur utilise également des informations qui ne sont pas transmises par un en-tête afin de déterminer le contenu approprié.
L'en-tête Vary a été ajouté à la version 1.1 de HTTP et permet le fonctionnement approprié. Pour fonctionner lors de la négociation menée par le serveur, un cache a besoin de connaître les critères utilisés par le serveur pour sélectionner le contenu à transmettre. Ainsi, le cache peut rejouer l'algorithme et être capable de servir le contenu acceptable directement, sans envoyer d'autres requêtes au serveur. Bien entendu, le joker * empêche toute mise en cache, car le cache ne peut alors pas savoir l'élément responsable de la sélection. Pour plus d'informations, voir mise en cache HTTP > réponses variantes.Négociation menée par l'agentLa négociation menée par le serveur possède quelques inconvénients : elle s'étend assez mal. Un en-tête est utilisé par fonctionnalité lors de la négociation. Si on veut utiliser la taille d'écran, la résolution ou d'autres dimensions, il faudra créer un nouvel en-tête HTTP. Les en-têtes doivent ensuite être envoyés à chaque requête. Ce n'est pas un problème lorsqu'il y a peu d'en-têtes, mais si le nombre d'en-têtes devient trop élevé, la taille du message pourra avoir un impact sur les performances. En contrepartie, plus des en-têtes précis sont envoyés, plus d'entropie est envoyée, facilitant le pistage et l'identification via des empreintes HTTP.
HTTP permet un autre type de négociation : la négociation menée par l'agent, aussi appelée négociation réactive. Dans ce cas, le serveur envoie une page contenant les liens vers les différentes ressources alternatives lorsqu'il reçoit une requête ambigüe. Les ressources seront présentées à l'utilisatrice ou à l'utilisateur, qui choisira celle à utiliser.

Cependant, le standard HTTP ne définit pas le format de la page pour le choix entre les ressources disponibles, ce qui empêche d'automatiser le procédé. En plus d'utiliser la négociation menée par le serveur en cas de recours, cette méthode est toujours utilisée avec des scripts. Il faut aussi plus d'une requête pour obtenir la ressource finale, ralentissant ainsi l'arrivée de la ressource jusqu'au client.Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on 1 janv. 1970 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nコンテンツネゴシエーションHTTP においてコンテンツネゴシエーション (content negotiation) は、同じ URI におけるさまざまな表現のリソースを提供するために使用する仕組みであり、ユーザーエージェントはどのリソースがユーザーにもっとも適しているか（例えば文書の言語はどれか、画像形式はどれか、コンテンツエンコーディングはどれか）を指定することができます。

メモ: WHATWG のウィキページには、 HTTP コンテンツネゴシエーションの短所がいくつか書かれています。 HTML では、コンテンツネゴシエーションの代替として、例えば <source> 要素を提供しています。
コンテンツネゴシエーションの原理特定の文書はリソース (resource) と呼ばれます。クライアントがリソースを取得したいときは、 URL でリクエストします。サーバーはこの URL を使用して、表現 (representation) と呼ばれる利用可能な変化形–特定の表現をクライアントに返します。それぞれの表現を含むリソース全体が一つの特定の URL を持ちます。コンテンツネゴシエーションは、リソースが呼び出されたときに特定の表現を選択する方法を定めます。クライアントサーバーの間でネゴシエーションする方法がいくつかあります。

最適な表現は、以下の 2 つの仕組みのいずれかによって識別されます。

クライアントによる特定の HTTP ヘッダー (サーバー駆動型ネゴシエーションまたはプロアクティブネゴシエーション)。これは、特定の種類のリソースでネゴシエーションを行う標準的な方法です。
サーバーによる 300 (Multiple Choices)、406 (Not Acceptable)、415 (Unsupported Media Type) のいずれかの HTTP レスポンスコード（エージェント駆動型ネゴシエーションまたはリアクティブネゴシエーション）。これはフォールバック機構として使用します。

数年来、透過的コンテンツネゴシエーション (transparent content negotiation) や Alternates ヘッダーといった他のコンテンツネゴシエーションが提案されてきました。これらは支持を得られず、破棄されました。サーバー駆動型コンテンツネゴシエーションサーバー駆動型コンテンツネゴシエーションまたはプロアクティブコンテンツネゴシエーションでは、ブラウザー（または他の種類のユーザー エージェント）はいくつかの HTTP ヘッダーを URL と一緒に送信します。これらのヘッダーには、ユーザーが希望する選択肢を記述します。サーバーはこれらをヒントとして使い、内部アルゴリズムがクライアントに提供する最適なコンテンツを選択します。適切なリソースを提供できない場合、 406 (Not Acceptable) または 415 (Unsupported Media Type) で応答し、対応しているメディアタイプのヘッダーを設定します（たとえば、POST と PATCH リクエストに対しては、それぞれ Accept-Post または Accept-Patch を使用します）。このアルゴリズムはサーバーに依存し、標準では定義されていません。 Apache ネゴシエーションアルゴリズム をご覧ください。

HTTP/1.1 標準では、サーバー駆動型ネゴシエーションを開始する標準ヘッダーの一覧（例えば Accept, Accept-Encoding, Accept-Language）を定義しています。厳密に言えば User-Agent はこの一覧に含まれていませんが、リクエストしたリソースの特定の表現を送信するために使用されることがあります。ただし、これはよい習慣ではないと考えられています。サーバーはどのヘッダーを実際にコンテンツネゴシエーションで使用したかを示すために Vary ヘッダー（あるいは、より的確な関係があるレスポンスヘッダー）を使用します。これにより、キャッシュが適切に機能します。
さらに、ネゴシエーションに使用できるヘッダーを追加する実験的な提案があり、クライアントヒントと呼ばれています。クライアントヒントは、ユーザーエージェントを実行している端末がどのようなものか（例えば、デスクトップコンピューターかモバイル端末か）を伝えます。
サーバー駆動型コンテンツネゴシエーションは、リソースの特定の表現を決定するためのもっとも一般的な方法ですが、いくつか欠点があります。

サーバーは、ブラウザーのことをすべて知っているわけではありません。クライアント拡張を加えても、ブラウザーの機能を完全には把握できません。クライアントが選択するリアクティブコンテンツネゴシエーションとは異なり、サーバーの選択は常に少し独断的です。
クライアントが提供する情報はかなり冗長であり（HTTP/2 のヘッダー圧縮は、この問題を緩和します）、またプライバシーのリスク（HTTP フィンガープリンティング）もあります。
指定されたリソースの複数の表現を送信すると、共有キャッシュの効率が下がります。また、サーバーの実装がより複雑になります。
Accept ヘッダーAccept ヘッダーは、エージェントが処理することを望むメディアリソースの MIME タイプを羅列します。これはカンマ区切りの MIME タイプのリストで、それぞれの MIME タイプは、別の MIME タイプとの相対的な優先度を示す引数である品質係数と結びつけられています。
Accept ヘッダーは、ブラウザーまたは他のユーザーエージェントによって定義され、そのコンテキストによって変わることがあります。例えば、取得するものが HTML ページ、画像、動画、スクリプトなどに変わります。アドレスバーで指定した文書を取得するときと <img>, <video>, <audio> 要素でリンクしたものを取得するときで異なります。ブラウザーはこのヘッダーで、最適と思われる値を自由に使用できます。一般的なブラウザーの既定値の包括的な一覧があります。Accept-CH ヘッダー 
Experimental

メモ:
これはクライアントヒント (Client Hints) と呼ばれる実験的な技術の一部であり、現在は Chrome 46 以降が実装しています。 Device-Memory の値は Chrome 61 以降が実装しています。

Accept-CH は実験的なもので、サーバーが適切なリソースを選択するために使用できる設定データを羅列します。有効な値は以下のとおりです。



値
意味




Device-Memory
端末に搭載されている RAM のおおよその量を示します。この値は、 2 の整数乗を 1024 で割った近似値です。たとえば、 512 メガバイトは 0.5 として報告されます。


Viewport-Width
レイアウトビューポートの幅を CSS ピクセルで示します。


Width
リソースの幅を物理ピクセルで示します（言い換えると、画像の本来の幅です）。


Accept-CH-Lifetime ヘッダー
メモ:
これはクライアントヒント (Client Hints) と呼ばれる実験的な技術の一部であり、 Chrome 61 以降でのみ利用できます。

Accept-CH-Lifetime ヘッダーは、 Accept-CH ヘッダーの Device-Memory 値と共に使用され、端末がメモリーの量をサーバーと共有することを許可すべき時間を示します。値はミリ秒単位で与えられ、使用は任意です。Accept-Encoding ヘッダーAccept-Encoding ヘッダーは、コンテンツの受け入れ可能なエンコーディング（対応する圧縮方式）を定義します。この値は、エンコーディングの優先度を示す Q 値のリスト (例: br, gzip;q=0.8) です。既定値 identity は（ほかに指定されていなければ）優先度が最低です。
HTTP メッセージの圧縮はウェブサイトのパフォーマンスを向上させるためにもっとも有力な手段のひとつであり、転送するデータのサイズを削減して利用可能な帯域を有効活用します。ブラウザーは常にこのヘッダーを送信し、またサーバーはこのヘッダーを受け入れるように設定して、圧縮を行うべきです。Accept-Language ヘッダーAccept-Language ヘッダーは、ユーザーの言語設定を示すために使用します。これは、品質係数を伴う値のリストです（例: "de, en;q=0.7"）。既定値はたいてい、ユーザーエージェントのグラフィカルインターフェイスの言語に従いますが、ほとんどのブラウザーでは異なる言語を設定できます。
設定に基づくエントロピーが高まるため、変更された値はユーザーのフィンガープリントとして使用される可能性があります。値を変更することは推奨されておらず、ウェブサイトは、この値がユーザーの本当の希望を反映していると信じてはいけません。このヘッダーで言語検出を行うと、使い勝手を損なう可能性があるため、サイトのデザイナーは使用することを避けてください。

サイトデザイナーは常に、サーバーが選択した言語を変える手段を、例えばサイト上に言語切り替えメニューを提供するなりして提供するべきです。多くのユーザーエージェントは Accept-Language ヘッダーに、ユーザーインターフェイス言語に合わせた既定値を提供します。エンドユーザーは大抵、この設定を変更しません。変更する方法を知らなかったり、コンピューティング環境の都合で変更できなかったりするからです。
サーバーが選択した言語をユーザーが変更したら、サイトは言語検出を使用せず、明示的に指定された言語に従うべきです。言い換えると、このヘッダーを使用して適切な言語を選択するのは、サイトの入口のページだけとするべきです。
User-Agent ヘッダー
メモ:
コンテンツの選択にこのヘッダーを使用することは、正当な使用方法ですが、ユーザーエージェントがどの機能に対応しているかを判断するためにこのヘッダーを頼ることは悪い習慣であると考えられています。

User-Agent ヘッダーは、リクエストを送信するブラウザーを識別します。この文字列には、空白区切りで製品トークンやコメントのリストが含まれることがあります。
製品トークンは Firefox/4.0.1 のように、名称、スラッシュ '/'、バージョン番号で構成されます。ユーザーエージェントは好きなだけこれを入れることができます。コメントは、括弧で囲まれた任意の文字列です。当然ながら、その文字列内で括弧を使用することはできません。コメントの内部形式は標準化されておらず、従って各ブラウザーがさまざまなトークンをセミコロン ';' 区切りで入れています。Vary レスポンスヘッダークライアントが送信する前出の Accept-* ヘッダーとは対照的に、 Vary HTTP ヘッダーはウェブサーバーがレスポンスで送信します。これは、サーバーがサーバー駆動型コンテンツネゴシエーションで使用したヘッダーのリストを示します。このヘッダーはネゴシエーションを再現できるように、判断基準のキャッシュを知らせるために必要であり、キャッシュが機能を果たすようにするとともに、ユーザーに誤ったコンテンツを提供することを防ぎます。
特別な値 '*' は、サーバー駆動型コンテンツネゴシエーションで適切なコンテンツを選ぶために、ヘッダーで与えられていない情報も使用することを表します。
Vary ヘッダーは HTTP バージョン 1.1 で追加され、キャッシュが適切に働くようにするためのものです。サーバー駆動型コンテンツネゴシエーションで動作させるためには、転送されたコンテンツを選択するためにサーバーが使用した基準をキャッシュが知らなければなりません。この方法で、キャッシュはコンテンツ選択のアルゴリズムを再生することを可能にして、サーバーへさらにリクエストを行うことなく適切なコンテンツを直接提供できるでしょう。当然ながらワイルドカード '*' は、背後にある要素をキャッシュで知ることができないため、キャッシュの生成を妨げます。詳しくは、 HTTP キャッシュ > 変化するレスポンスを参照してください。エージェント駆動型ネゴシエーションサーバー駆動型ネゴシエーションには、うまくスケーリングできないという欠点があります。ネゴシエーションでは、ひとつの機能に対してひとつのヘッダーを使用します。画面サイズ、解像度、または他の軸を使用したい場合は、新たな HTTP ヘッダーを作成する必要があります。このヘッダーを、すべてのリクエストで送信しなければなりません。ヘッダーが少ない場合は問題にはなりませんが、ヘッダーの数が増えると、最終的にはメッセージの大きさがパフォーマンスに影響を与える可能性があります。多くの詳細なヘッダーを送信するとエントロピーも多く送信されますので、 HTTP フィンガープリンティングの可能性やそれに伴うプライバシーの懸念が増大します。
HTTP では、もうひとつのネゴシエーション方法であるエージェント駆動型ネゴシエーションまたはリアクティブネゴシエーションが利用できます。この場合、サーバーはあいまいなリクエストに直面したときに、利用可能な代替リソースへのリンクを含むページを送り返します。ユーザーはそのリソースを提示され、使用するリソースを選択します。

残念ながら HTTP 標準では、使用可能なリソースを選択するためのページの様式を定めていないため、このプロセスを自動化することができません。この方法は、サーバー駆動型ネゴシエーションのフォールバックのほかにも、スクリプト、特に JavaScript のリダイレクトで常に使われています。ネゴシエーション基準を確認した後、スクリプトがリダイレクトを実行します。第二の問題点は、実際のリソースを取り出すために複数のリクエストが必要であるため、ユーザーがリソースを利用可能になるのが遅くなることです。\n\nコンテンツネゴシエーションHTTP においてコンテンツネゴシエーション (content negotiation) は、同じ URI におけるさまざまな表現のリソースを提供するために使用する仕組みであり、ユーザーエージェントはどのリソースがユーザーにもっとも適しているか（例えば文書の言語はどれか、画像形式はどれか、コンテンツエンコーディングはどれか）を指定することができます。

メモ: WHATWG のウィキページには、 HTTP コンテンツネゴシエーションの短所がいくつか書かれています。 HTML では、コンテンツネゴシエーションの代替として、例えば <source> 要素を提供しています。
コンテンツネゴシエーションの原理特定の文書はリソース (resource) と呼ばれます。クライアントがリソースを取得したいときは、 URL でリクエストします。サーバーはこの URL を使用して、表現 (representation) と呼ばれる利用可能な変化形–特定の表現をクライアントに返します。それぞれの表現を含むリソース全体が一つの特定の URL を持ちます。コンテンツネゴシエーションは、リソースが呼び出されたときに特定の表現を選択する方法を定めます。クライアントサーバーの間でネゴシエーションする方法がいくつかあります。

最適な表現は、以下の 2 つの仕組みのいずれかによって識別されます。

クライアントによる特定の HTTP ヘッダー (サーバー駆動型ネゴシエーションまたはプロアクティブネゴシエーション)。これは、特定の種類のリソースでネゴシエーションを行う標準的な方法です。
サーバーによる 300 (Multiple Choices)、406 (Not Acceptable)、415 (Unsupported Media Type) のいずれかの HTTP レスポンスコード（エージェント駆動型ネゴシエーションまたはリアクティブネゴシエーション）。これはフォールバック機構として使用します。

数年来、透過的コンテンツネゴシエーション (transparent content negotiation) や Alternates ヘッダーといった他のコンテンツネゴシエーションが提案されてきました。これらは支持を得られず、破棄されました。サーバー駆動型コンテンツネゴシエーションサーバー駆動型コンテンツネゴシエーションまたはプロアクティブコンテンツネゴシエーションでは、ブラウザー（または他の種類のユーザー エージェント）はいくつかの HTTP ヘッダーを URL と一緒に送信します。これらのヘッダーには、ユーザーが希望する選択肢を記述します。サーバーはこれらをヒントとして使い、内部アルゴリズムがクライアントに提供する最適なコンテンツを選択します。適切なリソースを提供できない場合、 406 (Not Acceptable) または 415 (Unsupported Media Type) で応答し、対応しているメディアタイプのヘッダーを設定します（たとえば、POST と PATCH リクエストに対しては、それぞれ Accept-Post または Accept-Patch を使用します）。このアルゴリズムはサーバーに依存し、標準では定義されていません。 Apache ネゴシエーションアルゴリズム をご覧ください。

HTTP/1.1 標準では、サーバー駆動型ネゴシエーションを開始する標準ヘッダーの一覧（例えば Accept, Accept-Encoding, Accept-Language）を定義しています。厳密に言えば User-Agent はこの一覧に含まれていませんが、リクエストしたリソースの特定の表現を送信するために使用されることがあります。ただし、これはよい習慣ではないと考えられています。サーバーはどのヘッダーを実際にコンテンツネゴシエーションで使用したかを示すために Vary ヘッダー（あるいは、より的確な関係があるレスポンスヘッダー）を使用します。これにより、キャッシュが適切に機能します。
さらに、ネゴシエーションに使用できるヘッダーを追加する実験的な提案があり、クライアントヒントと呼ばれています。クライアントヒントは、ユーザーエージェントを実行している端末がどのようなものか（例えば、デスクトップコンピューターかモバイル端末か）を伝えます。
サーバー駆動型コンテンツネゴシエーションは、リソースの特定の表現を決定するためのもっとも一般的な方法ですが、いくつか欠点があります。

サーバーは、ブラウザーのことをすべて知っているわけではありません。クライアント拡張を加えても、ブラウザーの機能を完全には把握できません。クライアントが選択するリアクティブコンテンツネゴシエーションとは異なり、サーバーの選択は常に少し独断的です。
クライアントが提供する情報はかなり冗長であり（HTTP/2 のヘッダー圧縮は、この問題を緩和します）、またプライバシーのリスク（HTTP フィンガープリンティング）もあります。
指定されたリソースの複数の表現を送信すると、共有キャッシュの効率が下がります。また、サーバーの実装がより複雑になります。
Accept ヘッダーAccept ヘッダーは、エージェントが処理することを望むメディアリソースの MIME タイプを羅列します。これはカンマ区切りの MIME タイプのリストで、それぞれの MIME タイプは、別の MIME タイプとの相対的な優先度を示す引数である品質係数と結びつけられています。
Accept ヘッダーは、ブラウザーまたは他のユーザーエージェントによって定義され、そのコンテキストによって変わることがあります。例えば、取得するものが HTML ページ、画像、動画、スクリプトなどに変わります。アドレスバーで指定した文書を取得するときと <img>, <video>, <audio> 要素でリンクしたものを取得するときで異なります。ブラウザーはこのヘッダーで、最適と思われる値を自由に使用できます。一般的なブラウザーの既定値の包括的な一覧があります。Accept-CH ヘッダー 
Experimental

メモ:
これはクライアントヒント (Client Hints) と呼ばれる実験的な技術の一部であり、現在は Chrome 46 以降が実装しています。 Device-Memory の値は Chrome 61 以降が実装しています。

Accept-CH は実験的なもので、サーバーが適切なリソースを選択するために使用できる設定データを羅列します。有効な値は以下のとおりです。



値
意味




Device-Memory
端末に搭載されている RAM のおおよその量を示します。この値は、 2 の整数乗を 1024 で割った近似値です。たとえば、 512 メガバイトは 0.5 として報告されます。


Viewport-Width
レイアウトビューポートの幅を CSS ピクセルで示します。


Width
リソースの幅を物理ピクセルで示します（言い換えると、画像の本来の幅です）。


Accept-CH-Lifetime ヘッダー
メモ:
これはクライアントヒント (Client Hints) と呼ばれる実験的な技術の一部であり、 Chrome 61 以降でのみ利用できます。

Accept-CH-Lifetime ヘッダーは、 Accept-CH ヘッダーの Device-Memory 値と共に使用され、端末がメモリーの量をサーバーと共有することを許可すべき時間を示します。値はミリ秒単位で与えられ、使用は任意です。Accept-Encoding ヘッダーAccept-Encoding ヘッダーは、コンテンツの受け入れ可能なエンコーディング（対応する圧縮方式）を定義します。この値は、エンコーディングの優先度を示す Q 値のリスト (例: br, gzip;q=0.8) です。既定値 identity は（ほかに指定されていなければ）優先度が最低です。
HTTP メッセージの圧縮はウェブサイトのパフォーマンスを向上させるためにもっとも有力な手段のひとつであり、転送するデータのサイズを削減して利用可能な帯域を有効活用します。ブラウザーは常にこのヘッダーを送信し、またサーバーはこのヘッダーを受け入れるように設定して、圧縮を行うべきです。Accept-Language ヘッダーAccept-Language ヘッダーは、ユーザーの言語設定を示すために使用します。これは、品質係数を伴う値のリストです（例: "de, en;q=0.7"）。既定値はたいてい、ユーザーエージェントのグラフィカルインターフェイスの言語に従いますが、ほとんどのブラウザーでは異なる言語を設定できます。
設定に基づくエントロピーが高まるため、変更された値はユーザーのフィンガープリントとして使用される可能性があります。値を変更することは推奨されておらず、ウェブサイトは、この値がユーザーの本当の希望を反映していると信じてはいけません。このヘッダーで言語検出を行うと、使い勝手を損なう可能性があるため、サイトのデザイナーは使用することを避けてください。

サイトデザイナーは常に、サーバーが選択した言語を変える手段を、例えばサイト上に言語切り替えメニューを提供するなりして提供するべきです。多くのユーザーエージェントは Accept-Language ヘッダーに、ユーザーインターフェイス言語に合わせた既定値を提供します。エンドユーザーは大抵、この設定を変更しません。変更する方法を知らなかったり、コンピューティング環境の都合で変更できなかったりするからです。
サーバーが選択した言語をユーザーが変更したら、サイトは言語検出を使用せず、明示的に指定された言語に従うべきです。言い換えると、このヘッダーを使用して適切な言語を選択するのは、サイトの入口のページだけとするべきです。
User-Agent ヘッダー
メモ:
コンテンツの選択にこのヘッダーを使用することは、正当な使用方法ですが、ユーザーエージェントがどの機能に対応しているかを判断するためにこのヘッダーを頼ることは悪い習慣であると考えられています。

User-Agent ヘッダーは、リクエストを送信するブラウザーを識別します。この文字列には、空白区切りで製品トークンやコメントのリストが含まれることがあります。
製品トークンは Firefox/4.0.1 のように、名称、スラッシュ '/'、バージョン番号で構成されます。ユーザーエージェントは好きなだけこれを入れることができます。コメントは、括弧で囲まれた任意の文字列です。当然ながら、その文字列内で括弧を使用することはできません。コメントの内部形式は標準化されておらず、従って各ブラウザーがさまざまなトークンをセミコロン ';' 区切りで入れています。Vary レスポンスヘッダークライアントが送信する前出の Accept-* ヘッダーとは対照的に、 Vary HTTP ヘッダーはウェブサーバーがレスポンスで送信します。これは、サーバーがサーバー駆動型コンテンツネゴシエーションで使用したヘッダーのリストを示します。このヘッダーはネゴシエーションを再現できるように、判断基準のキャッシュを知らせるために必要であり、キャッシュが機能を果たすようにするとともに、ユーザーに誤ったコンテンツを提供することを防ぎます。
特別な値 '*' は、サーバー駆動型コンテンツネゴシエーションで適切なコンテンツを選ぶために、ヘッダーで与えられていない情報も使用することを表します。
Vary ヘッダーは HTTP バージョン 1.1 で追加され、キャッシュが適切に働くようにするためのものです。サーバー駆動型コンテンツネゴシエーションで動作させるためには、転送されたコンテンツを選択するためにサーバーが使用した基準をキャッシュが知らなければなりません。この方法で、キャッシュはコンテンツ選択のアルゴリズムを再生することを可能にして、サーバーへさらにリクエストを行うことなく適切なコンテンツを直接提供できるでしょう。当然ながらワイルドカード '*' は、背後にある要素をキャッシュで知ることができないため、キャッシュの生成を妨げます。詳しくは、 HTTP キャッシュ > 変化するレスポンスを参照してください。エージェント駆動型ネゴシエーションサーバー駆動型ネゴシエーションには、うまくスケーリングできないという欠点があります。ネゴシエーションでは、ひとつの機能に対してひとつのヘッダーを使用します。画面サイズ、解像度、または他の軸を使用したい場合は、新たな HTTP ヘッダーを作成する必要があります。このヘッダーを、すべてのリクエストで送信しなければなりません。ヘッダーが少ない場合は問題にはなりませんが、ヘッダーの数が増えると、最終的にはメッセージの大きさがパフォーマンスに影響を与える可能性があります。多くの詳細なヘッダーを送信するとエントロピーも多く送信されますので、 HTTP フィンガープリンティングの可能性やそれに伴うプライバシーの懸念が増大します。
HTTP では、もうひとつのネゴシエーション方法であるエージェント駆動型ネゴシエーションまたはリアクティブネゴシエーションが利用できます。この場合、サーバーはあいまいなリクエストに直面したときに、利用可能な代替リソースへのリンクを含むページを送り返します。ユーザーはそのリソースを提示され、使用するリソースを選択します。

残念ながら HTTP 標準では、使用可能なリソースを選択するためのページの様式を定めていないため、このプロセスを自動化することができません。この方法は、サーバー駆動型ネゴシエーションのフォールバックのほかにも、スクリプト、特に JavaScript のリダイレクトで常に使われています。ネゴシエーション基準を確認した後、スクリプトがリダイレクトを実行します。第二の問題点は、実際のリソースを取り出すために複数のリクエストが必要であるため、ユーザーがリソースを利用可能になるのが遅くなることです。Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on 2025年4月12日 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nコンテンツネゴシエーションHTTP においてコンテンツネゴシエーション (content negotiation) は、同じ URI におけるさまざまな表現のリソースを提供するために使用する仕組みであり、ユーザーエージェントはどのリソースがユーザーにもっとも適しているか（例えば文書の言語はどれか、画像形式はどれか、コンテンツエンコーディングはどれか）を指定することができます。

メモ: WHATWG のウィキページには、 HTTP コンテンツネゴシエーションの短所がいくつか書かれています。 HTML では、コンテンツネゴシエーションの代替として、例えば <source> 要素を提供しています。
コンテンツネゴシエーションの原理特定の文書はリソース (resource) と呼ばれます。クライアントがリソースを取得したいときは、 URL でリクエストします。サーバーはこの URL を使用して、表現 (representation) と呼ばれる利用可能な変化形–特定の表現をクライアントに返します。それぞれの表現を含むリソース全体が一つの特定の URL を持ちます。コンテンツネゴシエーションは、リソースが呼び出されたときに特定の表現を選択する方法を定めます。クライアントサーバーの間でネゴシエーションする方法がいくつかあります。

最適な表現は、以下の 2 つの仕組みのいずれかによって識別されます。

クライアントによる特定の HTTP ヘッダー (サーバー駆動型ネゴシエーションまたはプロアクティブネゴシエーション)。これは、特定の種類のリソースでネゴシエーションを行う標準的な方法です。
サーバーによる 300 (Multiple Choices)、406 (Not Acceptable)、415 (Unsupported Media Type) のいずれかの HTTP レスポンスコード（エージェント駆動型ネゴシエーションまたはリアクティブネゴシエーション）。これはフォールバック機構として使用します。

数年来、透過的コンテンツネゴシエーション (transparent content negotiation) や Alternates ヘッダーといった他のコンテンツネゴシエーションが提案されてきました。これらは支持を得られず、破棄されました。サーバー駆動型コンテンツネゴシエーションサーバー駆動型コンテンツネゴシエーションまたはプロアクティブコンテンツネゴシエーションでは、ブラウザー（または他の種類のユーザー エージェント）はいくつかの HTTP ヘッダーを URL と一緒に送信します。これらのヘッダーには、ユーザーが希望する選択肢を記述します。サーバーはこれらをヒントとして使い、内部アルゴリズムがクライアントに提供する最適なコンテンツを選択します。適切なリソースを提供できない場合、 406 (Not Acceptable) または 415 (Unsupported Media Type) で応答し、対応しているメディアタイプのヘッダーを設定します（たとえば、POST と PATCH リクエストに対しては、それぞれ Accept-Post または Accept-Patch を使用します）。このアルゴリズムはサーバーに依存し、標準では定義されていません。 Apache ネゴシエーションアルゴリズム をご覧ください。

HTTP/1.1 標準では、サーバー駆動型ネゴシエーションを開始する標準ヘッダーの一覧（例えば Accept, Accept-Encoding, Accept-Language）を定義しています。厳密に言えば User-Agent はこの一覧に含まれていませんが、リクエストしたリソースの特定の表現を送信するために使用されることがあります。ただし、これはよい習慣ではないと考えられています。サーバーはどのヘッダーを実際にコンテンツネゴシエーションで使用したかを示すために Vary ヘッダー（あるいは、より的確な関係があるレスポンスヘッダー）を使用します。これにより、キャッシュが適切に機能します。
さらに、ネゴシエーションに使用できるヘッダーを追加する実験的な提案があり、クライアントヒントと呼ばれています。クライアントヒントは、ユーザーエージェントを実行している端末がどのようなものか（例えば、デスクトップコンピューターかモバイル端末か）を伝えます。
サーバー駆動型コンテンツネゴシエーションは、リソースの特定の表現を決定するためのもっとも一般的な方法ですが、いくつか欠点があります。

サーバーは、ブラウザーのことをすべて知っているわけではありません。クライアント拡張を加えても、ブラウザーの機能を完全には把握できません。クライアントが選択するリアクティブコンテンツネゴシエーションとは異なり、サーバーの選択は常に少し独断的です。
クライアントが提供する情報はかなり冗長であり（HTTP/2 のヘッダー圧縮は、この問題を緩和します）、またプライバシーのリスク（HTTP フィンガープリンティング）もあります。
指定されたリソースの複数の表現を送信すると、共有キャッシュの効率が下がります。また、サーバーの実装がより複雑になります。
Accept ヘッダーAccept ヘッダーは、エージェントが処理することを望むメディアリソースの MIME タイプを羅列します。これはカンマ区切りの MIME タイプのリストで、それぞれの MIME タイプは、別の MIME タイプとの相対的な優先度を示す引数である品質係数と結びつけられています。
Accept ヘッダーは、ブラウザーまたは他のユーザーエージェントによって定義され、そのコンテキストによって変わることがあります。例えば、取得するものが HTML ページ、画像、動画、スクリプトなどに変わります。アドレスバーで指定した文書を取得するときと <img>, <video>, <audio> 要素でリンクしたものを取得するときで異なります。ブラウザーはこのヘッダーで、最適と思われる値を自由に使用できます。一般的なブラウザーの既定値の包括的な一覧があります。Accept-CH ヘッダー 
Experimental

メモ:
これはクライアントヒント (Client Hints) と呼ばれる実験的な技術の一部であり、現在は Chrome 46 以降が実装しています。 Device-Memory の値は Chrome 61 以降が実装しています。

Accept-CH は実験的なもので、サーバーが適切なリソースを選択するために使用できる設定データを羅列します。有効な値は以下のとおりです。



値
意味




Device-Memory
端末に搭載されている RAM のおおよその量を示します。この値は、 2 の整数乗を 1024 で割った近似値です。たとえば、 512 メガバイトは 0.5 として報告されます。


Viewport-Width
レイアウトビューポートの幅を CSS ピクセルで示します。


Width
リソースの幅を物理ピクセルで示します（言い換えると、画像の本来の幅です）。


Accept-CH-Lifetime ヘッダー
メモ:
これはクライアントヒント (Client Hints) と呼ばれる実験的な技術の一部であり、 Chrome 61 以降でのみ利用できます。

Accept-CH-Lifetime ヘッダーは、 Accept-CH ヘッダーの Device-Memory 値と共に使用され、端末がメモリーの量をサーバーと共有することを許可すべき時間を示します。値はミリ秒単位で与えられ、使用は任意です。Accept-Encoding ヘッダーAccept-Encoding ヘッダーは、コンテンツの受け入れ可能なエンコーディング（対応する圧縮方式）を定義します。この値は、エンコーディングの優先度を示す Q 値のリスト (例: br, gzip;q=0.8) です。既定値 identity は（ほかに指定されていなければ）優先度が最低です。
HTTP メッセージの圧縮はウェブサイトのパフォーマンスを向上させるためにもっとも有力な手段のひとつであり、転送するデータのサイズを削減して利用可能な帯域を有効活用します。ブラウザーは常にこのヘッダーを送信し、またサーバーはこのヘッダーを受け入れるように設定して、圧縮を行うべきです。Accept-Language ヘッダーAccept-Language ヘッダーは、ユーザーの言語設定を示すために使用します。これは、品質係数を伴う値のリストです（例: "de, en;q=0.7"）。既定値はたいてい、ユーザーエージェントのグラフィカルインターフェイスの言語に従いますが、ほとんどのブラウザーでは異なる言語を設定できます。
設定に基づくエントロピーが高まるため、変更された値はユーザーのフィンガープリントとして使用される可能性があります。値を変更することは推奨されておらず、ウェブサイトは、この値がユーザーの本当の希望を反映していると信じてはいけません。このヘッダーで言語検出を行うと、使い勝手を損なう可能性があるため、サイトのデザイナーは使用することを避けてください。

サイトデザイナーは常に、サーバーが選択した言語を変える手段を、例えばサイト上に言語切り替えメニューを提供するなりして提供するべきです。多くのユーザーエージェントは Accept-Language ヘッダーに、ユーザーインターフェイス言語に合わせた既定値を提供します。エンドユーザーは大抵、この設定を変更しません。変更する方法を知らなかったり、コンピューティング環境の都合で変更できなかったりするからです。
サーバーが選択した言語をユーザーが変更したら、サイトは言語検出を使用せず、明示的に指定された言語に従うべきです。言い換えると、このヘッダーを使用して適切な言語を選択するのは、サイトの入口のページだけとするべきです。
User-Agent ヘッダー
メモ:
コンテンツの選択にこのヘッダーを使用することは、正当な使用方法ですが、ユーザーエージェントがどの機能に対応しているかを判断するためにこのヘッダーを頼ることは悪い習慣であると考えられています。

User-Agent ヘッダーは、リクエストを送信するブラウザーを識別します。この文字列には、空白区切りで製品トークンやコメントのリストが含まれることがあります。
製品トークンは Firefox/4.0.1 のように、名称、スラッシュ '/'、バージョン番号で構成されます。ユーザーエージェントは好きなだけこれを入れることができます。コメントは、括弧で囲まれた任意の文字列です。当然ながら、その文字列内で括弧を使用することはできません。コメントの内部形式は標準化されておらず、従って各ブラウザーがさまざまなトークンをセミコロン ';' 区切りで入れています。Vary レスポンスヘッダークライアントが送信する前出の Accept-* ヘッダーとは対照的に、 Vary HTTP ヘッダーはウェブサーバーがレスポンスで送信します。これは、サーバーがサーバー駆動型コンテンツネゴシエーションで使用したヘッダーのリストを示します。このヘッダーはネゴシエーションを再現できるように、判断基準のキャッシュを知らせるために必要であり、キャッシュが機能を果たすようにするとともに、ユーザーに誤ったコンテンツを提供することを防ぎます。
特別な値 '*' は、サーバー駆動型コンテンツネゴシエーションで適切なコンテンツを選ぶために、ヘッダーで与えられていない情報も使用することを表します。
Vary ヘッダーは HTTP バージョン 1.1 で追加され、キャッシュが適切に働くようにするためのものです。サーバー駆動型コンテンツネゴシエーションで動作させるためには、転送されたコンテンツを選択するためにサーバーが使用した基準をキャッシュが知らなければなりません。この方法で、キャッシュはコンテンツ選択のアルゴリズムを再生することを可能にして、サーバーへさらにリクエストを行うことなく適切なコンテンツを直接提供できるでしょう。当然ながらワイルドカード '*' は、背後にある要素をキャッシュで知ることができないため、キャッシュの生成を妨げます。詳しくは、 HTTP キャッシュ > 変化するレスポンスを参照してください。エージェント駆動型ネゴシエーションサーバー駆動型ネゴシエーションには、うまくスケーリングできないという欠点があります。ネゴシエーションでは、ひとつの機能に対してひとつのヘッダーを使用します。画面サイズ、解像度、または他の軸を使用したい場合は、新たな HTTP ヘッダーを作成する必要があります。このヘッダーを、すべてのリクエストで送信しなければなりません。ヘッダーが少ない場合は問題にはなりませんが、ヘッダーの数が増えると、最終的にはメッセージの大きさがパフォーマンスに影響を与える可能性があります。多くの詳細なヘッダーを送信するとエントロピーも多く送信されますので、 HTTP フィンガープリンティングの可能性やそれに伴うプライバシーの懸念が増大します。
HTTP では、もうひとつのネゴシエーション方法であるエージェント駆動型ネゴシエーションまたはリアクティブネゴシエーションが利用できます。この場合、サーバーはあいまいなリクエストに直面したときに、利用可能な代替リソースへのリンクを含むページを送り返します。ユーザーはそのリソースを提示され、使用するリソースを選択します。

残念ながら HTTP 標準では、使用可能なリソースを選択するためのページの様式を定めていないため、このプロセスを自動化することができません。この方法は、サーバー駆動型ネゴシエーションのフォールバックのほかにも、スクリプト、特に JavaScript のリダイレクトで常に使われています。ネゴシエーション基準を確認した後、スクリプトがリダイレクトを実行します。第二の問題点は、実際のリソースを取り出すために複数のリクエストが必要であるため、ユーザーがリソースを利用可能になるのが遅くなることです。Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on 2025年4月12日 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\n콘텐츠 협상HTTP에서 콘텐츠 협상(Content negotiation)이란 동일한 URI에서 리소스의 서로 다른 버전을 제공하기 위해 사용하는 메커니즘으로, 사용자 에이전트가 사용자에게 제일 잘 맞는 것이 무엇인지(예를 들어, 문서의 언어, 이미지 포맷 혹은 컨텐츠 인코딩에 있어 어떤 것이 적절한지)를 명시할 수 있습니다.콘텐츠 협상의 원칙우리는 특정 문서를 리소스라고 부릅니다. 클라이언트가 리소스를 내려받길 원할 경우, 그것의 URL을 사용하여 요청합니다. 서버는 리소스가 제공하는 여러 변형들 중 하나를 선택하기 위해 이런 URL을 사용하며 (각각의 변형을 프레젠테이션이라고 부릅니다) 클라이언트에게 해당 리소스의 특정 프레젠테이션을 반환합니다. 프레젠테이션들에 더해, 전체 리소스들은 특유의 URL을 가집니다. 리소스가 호출됐을 때 특정 프레젠테이션을 선택하는 방법은 콘텐츠 협상에 의해 결정되며 클라이언트와 서버 간의 협상에는 몇 가지 방식이 존재합니다.

가장 잘 맞는 프레젠테이션의 결정은 다음 두 개의 메커니즘 중 하나를 통해 이루어집니다:

클라이언트가 보내는 특정 HTTP 헤더를 이용하는 방법(서버 주도 협상 혹은 주도적인 협상)으로, 특정 종류의 리소스에 대한 표준 협상 방법입니다.
서버에 의해 전달되는 300 (다중 선택) 혹은 406 (허용되지 않음) HTTP 응답 코드를 이용하는 방법(에이전트 주도 협상 혹은 리액티브 협상)으로, 폴백 메커니즘으로써 사용됩니다.

수년 간, 투명한 콘텐츠 협상과 Alternates 헤더와 같은 다른 콘텐츠 협상 제안들이 제안되어 왔습니다. 그런 제안들은 관심을 끄는데 실패했고 결국 버려졌습니다.서버 주도 콘텐츠 협상서버 주도 콘텐츠 협상 혹은 주도적인 협상에 있어서, 브라우저(혹은 사용자 에이전트라면 어떤 다른 종류든지)는 URL을 이용해 몇 개의 HTTP 헤더를 전송합니다. 이런 헤더들은 사용자의 우선적인 선택을 나타냅니다. 서버는 그것들을 힌트로써 사용하며 내부 알고리즘은 클라이언트로 서브하기 위한 최선의 컨텐츠를 선택하게 됩니다. 이 알고리즘은 서버 특유의 것이며 표준으로 정의된 것은 아닙니다. 예를 위해, Apache 2.2 협상 알고리즘을 참고하시기 바랍니다.

HTTP/1.1 표준은 서버 주도 협상을 시작하는 표준 헤더 목록(Accept, Accept-Charset, Accept-Encoding, Accept-Language)을 정의하고 있습니다. 엄밀히 말하자면 User-Agent이 리스트 내에 없긴 하지만, 해당 헤더는, 좋은 관례가 아니라고 판단될지라도, 때때로 요청된 리소스의 특정 프레젠테이션을 전송하는데 사용되기도 합니다. 서버는 실제로 콘텐츠 협상에 있어 어떤 헤더가 사용될 지 (더 엄밀히 말하자면 연관된 응답 헤더) 가리키기 위해 Vary 헤더를 사용하므로 캐시는 최적으로 동작하게 됩니다.
이것과 더불어, 클라이언트 힌트라고 부르는 헤더들을 이용 가능한 헤더 목록에 추가하려는 실험적인 제안도 존재합니다. 클라이언트 힌트는 사용자 에이전트가 실행 중인 기기의 종류가 무엇인지를 알려줍니다(예를 들어, 데스크톱 컴퓨터인지 모바일 기기인지)
서버 주도 콘텐츠 협상이 리소스의 특정 프레젠테이션에 동의하기 위한 가장 일반적인 방법이긴 하지만, 몇 가지 결점을 가지고 있습니다:

서버는 브라우저에 대한 전체적인 지식을 가지고 있지 않습니다. 클라이언트 힌트 확장이 있더라도, 서버는 브라우저의 수용 능력에 대한 완벽한 정보를 가지고 있진 않습니다. 클라이언트가 선택하는 리액티브 콘텐츠 협상과는 다르게, 서버 선택은 항상 다소 임의적입니다.
클라이언트에 의한 정보는 상당히 장황하며(HTTP/2 헤더 압축은 이런 문제를 완화시킵니다) 사생활 침해에 대한 위협을 가지고 있습니다(HTTP 핑거프린팅).
주어진 리소스의 몇몇 프레젠테이션이 전송되므로, 샤드된 캐시들은 덜 효율적이며 서버 구현은 좀 더 복잡해집니다.
Accept 헤더Accept 헤더는 에이전트가 처리하고자 하는 미디어 리소스의 MIME 타입을 나열합니다. 그것은 MIME 타입을 쉼표로 구분한 목록이며, 각각 품질 인자와 함께 나열되어 있으며, 다른 MIME 타입 사이의 상대적인 선호도를 나타내는 파라메터이기도 합니다.
Accept 헤더는 브라우저나 다른 에이전트에 의해 정의되며 HTML 페이지 혹은 이미지나 비디오 또는 스크립트들을 가져오는 것처럼, 컨텍스트에 따라 다양해질 수 있습니다: 주소창에 입력된 문서를 내려 받을 때와 <img>, <video> 혹은 <audio> 엘리먼트를 통해 링크된 요소를 내려받을 때가 다릅니다. 브라우저는 그들이 판단하기에 가장 적절한 헤더의 값을 마음껏 사용할 것입니다. 일반적인 브라우저를 위한 기본적인 값의 전체 목록을 참고하기 바랍니다.Accept-CH 헤더 
Experimental

참고 :
이것은 클라이언트 힌트라고 불리는 실험적인 기술의 일부로 현재 크롬 46과 그 이후 버전에서만 구현되어 있습니다.

실험적인 Accept-CH는 적합한 응답을 선택하기 위해 서버가 사용할 수 있는 설정 데이터를 나열합니다. 유효한 값들은 다음과 같습니다:



값
의미




DPR
클라이언트 기기의 픽셀 비율(ratio)을 가르킵니다.


Viewport-Width
CSS 픽셀에서의 레이아웃 뷰포트를 가리킵니다.


Width
물리적인 픽셀에서의 리소스 너비를 가리킵니다(다시 말해 이미지의 고유 사이즈).


Accept-Charset 헤더Accept-Charset 헤더는 사용자 에이너트가 어떤 종류의 캐릭터 인코딩을 이해할 수 있는지를 서버에게 알려줍니다. 전통적으로, 그것은 브라우저에 대해 각 지역을 위해 서로 다른 값을 설정하는데 사용되어 왔습니다. 예로 들자면, 서부 유럽 지역을 위해서는 ISO-8859-1,utf-8;q=0.7,*;q=0.7처럼 설정했었습니다.
UTF-8이 현재는 잘 지원되고 있고 인코딩 캐릭터로써 선호하는 방식이 되고 있는 상황에서, 더 적은 설정 기반의 엔트로피(불확실성)를 통해 좀 더 나은 개인정보 보호를 보장하기 위해, 대부분의 브라우저들은 Accept-Charset 헤더를 생략하고 있습니다. Internet Explorer 8, Safari 5, Opera 11 그리고 Firefox 10은 이 헤더를 폐기했습니다.Accept-Encoding 헤더Accept-Encoding 헤더는 수용 가능한 (압축을 지원하는) 컨텐츠 인코딩을 정의하고 있습니다. 값은 인코딩 값의 우선 순위를 가리키는 q 인자 목록(예를 들어, : br, gzip;q=0.8)입니다. 기본값 identity는 가장 낮은 우선 순위입니다(선언된 것이 없는 경우).
HTTP 메시지 압축은 웹 사이트의 성능을 높이는 가장 중요한 방법이며, 전송 데이터의 크기를 줄여주며 가용할 수 있는 대역폭을 더 좋은 상태로 만들어줍니다; 브라우저는 항상 이 헤더를 전송하며 서버는 그것을 받아들이고 압축을 사용하도록 구성되어 있어야 합니다.Accept-Language 헤더Accept-Language 헤더는 사용자가 선호하는 언어를 가리키는데 사용됩니다. 그것은 품질 인자를 가진 값 목록입니다("de, en;q=0.7"). 기본 값은 사용자 에이전트의 그래픽 인터페이스 언어와 관련하여 설정되지만, 대부분의 브라우저들은 다른 언어 설정을 허용합니다.
구성 기반의 엔트로피의 증가로, 사용자 판별에 수정된 값을 사용할 수 없고, 그것을 수정하는 것은 권장되지 않으며 웹 사이트는 사용자의 실제 요구를 반영하기 위해 이 값을 신뢰할 수 없습니다. 이 헤더를 통해 감지된 언어가 좋지 않은 사용자 경험을 유발할 수도 있으므로 사이트 설계자는 해당 헤더 값을 맹신해서는 안 됩니다:

사이트 설계자들은 서버에서 선택한 언어가 아닌 다른 언어를 선택할 수 있는 방법을 제공해야 합니다. 예를 들자면 사이트 상에 언어 메뉴를 제공하는 것이죠. 대부분의 사용자 에이전트들은 사용자 인터페이스 언어에서 차용된 값을 Accept-Language 헤더의 기본값으로 제공하는데, 최종 사용자는, 예를 들어서 인터넷 카페 같은데서, 대게 어떻게 하는지 몰라서, 혹은 그것이 가능한지 몰라서, 그것을 수정하지 않습니다.
사용자가 서버가 선택한 언어를 재정의하고 나면, 사이트는 더 이상 언어 감지를 사용해서는 안되며 명시적으로 선택된 언어를 인정해야 합니다. 다시 말하자면, 사이트의 엔트리 페이지에서만 이 헤더를 사용하여 적당한 언어를 선택해야 합니다.
User-Agent 헤더
참고 :
컨텐츠를 선택함에 있어 이 헤더를 정당하게 사용한다고 할지라도, 사용자 에이전트가 지원하는 것이 무엇인지를 정의하려고 이 헤더에 의지하는 것은 나쁜 습관으로 간주됩니다.

User-Agent 헤더는 요청을 전송하는 브라우저를 식별하게 해줍니다. 이 문자열은 공백 문자로 구분된 *제품 토큰(product tokens)*과 코멘트 목록을 포함합니다.
*제품 토큰(product token)*은 Firefox/4.0.1처럼 브라우저 이름 뒤에 '/'와 버전 번호가 오는 이름입니다. 사용자가 에이전트가 원하는 만큼 많은 수의 이름이 올 수 있습니다. 코멘트는 둥근 괄호를 경계로 하는 자유 문자열입니다. 분명한 것은 괄호가 문자열 안에서는 사용될 수 없다는 것입니다. 코멘트의 내부 형식은 표준으로 정해진 것은 없으나 몇몇 브라우저들은 ';'로 구분하여 그 안에 몇 개의 토큰을 넣습니다.Vary 응답 헤더이전에 봤던 클라이언트에 의해 전송되는 Accept-* 헤더들과는 달리, Vary HTTP 헤더는 웹 서버에 의한 응답 내로 전달됩니다. 이 헤더는 서버 주도 콘텐츠 협상의 과정 중에 서버에 의해 사용되는 헤더들의 목록을 나타냅니다. 이 헤더는 결정 기준 캐시를 알리기 위해 필요하므로 사용자에게 잘못된 컨텐츠를 제공하는 일을 방지하는 동안 캐시가 가동되게 허용하도록 캐시를 복제할 수 있습니다.
특별한 값인 '*'은 서버 주도 콘텐츠 협상이 적합한 컨텐츠 선택을 위해 헤더로 전달되지 않은 정보도 사용한다는 것을 의미합니다.
Vary 헤더는 HTTP 1.1 버전에서 추가되었으며 캐시를 적절하게 동작하도록 허용하는 일이 불필요합니다. 캐시는, 에이전트 주도 콘텐츠 협상과 함께 동작하도록 하기 위해, 전송된 컨텐츠를 선택하도록 서버에 의해 사용되었던 기준이 어떤 것인지 알 필요가 있습니다. 그런 방법으로, 캐시는 알고리즘을 재연할 수 있으며 서버에 추가적인 요청없이도 수용 가능한 컨텐츠를 직접 서브할 수 있게 될 것입니다. 확실히, 캐시는 무슨 요소가 뒤에 있는지 알 수 없으므로, '*' 와일드카드는 현재 일어나고 있는 일들로부터 캐시되는 것을 방지합니다.에이전트 주도 협상서버 주도 협상은 몇 가지 결점을 가지고 있습니다: 그것은 확장하기에 불리합니다. 협상 내에서 사용하는 기능 당 한 가지 헤더가 존재해야 합니다. 만약 스크린 크기, 해상도 혹은 또 다른 치수를 사용하고자 한다면, 새로운 HTTP 헤더가 반드시 만들어져야 합니다. 헤더의 전송은 반드시 모든 요청 상에서 이루어져야 합니다. 이것은 몇몇 헤더들에 있어서는 그리 문제될 것은 아니지만, 그런 헤더들이 결국 증가하여, 메시지 사이즈가 성능에 악영향이 끼치는 상황이 올 수도 있습니다. 전송하는 헤더가 정확하면 정확할수록, 그만큼의 불확실성이 더 전송되고, 더 많은 HTTP 흔적을 남기며 관련된 개인정보 문제들을 불러옵니다.
HTTP의 초창기부터, 프로토콜은 또 다른 협상 유형을 허용했습니다: 에이전트 주도 협상 혹은 리액티브 협상. 이 협상에서, 애매모호한 요청과 맞닥뜨렸을 경우, 서버는 사용 가능한 대체 리소스들에 대한 링크를 포함하고 있는 페이지를 회신하게 됩니다. 사용자는 해당 리소스들을 표시하고 사용하려는 리소스를 선택하게 됩니다.

불행하게도, HTTP 표준은 사용 가능한 리소스 중에서 선택하도록 허용하는 페이지의 형식을 명시하지 않고 있고, 이것이 선택 과정의 자동화를 막고 있습니다. 게다가 서버 주도 협상으로의 회귀로, 이 방법은 스크립팅, 특히 JavaScript 리다이렉션과 함께 거의 항상 사용됩니다: 협상 기준을 점검하고 난 뒤에, 스크립트는 리다이렉션을 실행합니다. 두번째 문제는 실제 리소스를 가져오는데 한 개 이상의 요청이 필요해서, 사용자에게는 리소스 효용성이 떨어진다는 것입니다.\n\n콘텐츠 협상HTTP에서 콘텐츠 협상(Content negotiation)이란 동일한 URI에서 리소스의 서로 다른 버전을 제공하기 위해 사용하는 메커니즘으로, 사용자 에이전트가 사용자에게 제일 잘 맞는 것이 무엇인지(예를 들어, 문서의 언어, 이미지 포맷 혹은 컨텐츠 인코딩에 있어 어떤 것이 적절한지)를 명시할 수 있습니다.콘텐츠 협상의 원칙우리는 특정 문서를 리소스라고 부릅니다. 클라이언트가 리소스를 내려받길 원할 경우, 그것의 URL을 사용하여 요청합니다. 서버는 리소스가 제공하는 여러 변형들 중 하나를 선택하기 위해 이런 URL을 사용하며 (각각의 변형을 프레젠테이션이라고 부릅니다) 클라이언트에게 해당 리소스의 특정 프레젠테이션을 반환합니다. 프레젠테이션들에 더해, 전체 리소스들은 특유의 URL을 가집니다. 리소스가 호출됐을 때 특정 프레젠테이션을 선택하는 방법은 콘텐츠 협상에 의해 결정되며 클라이언트와 서버 간의 협상에는 몇 가지 방식이 존재합니다.

가장 잘 맞는 프레젠테이션의 결정은 다음 두 개의 메커니즘 중 하나를 통해 이루어집니다:

클라이언트가 보내는 특정 HTTP 헤더를 이용하는 방법(서버 주도 협상 혹은 주도적인 협상)으로, 특정 종류의 리소스에 대한 표준 협상 방법입니다.
서버에 의해 전달되는 300 (다중 선택) 혹은 406 (허용되지 않음) HTTP 응답 코드를 이용하는 방법(에이전트 주도 협상 혹은 리액티브 협상)으로, 폴백 메커니즘으로써 사용됩니다.

수년 간, 투명한 콘텐츠 협상과 Alternates 헤더와 같은 다른 콘텐츠 협상 제안들이 제안되어 왔습니다. 그런 제안들은 관심을 끄는데 실패했고 결국 버려졌습니다.서버 주도 콘텐츠 협상서버 주도 콘텐츠 협상 혹은 주도적인 협상에 있어서, 브라우저(혹은 사용자 에이전트라면 어떤 다른 종류든지)는 URL을 이용해 몇 개의 HTTP 헤더를 전송합니다. 이런 헤더들은 사용자의 우선적인 선택을 나타냅니다. 서버는 그것들을 힌트로써 사용하며 내부 알고리즘은 클라이언트로 서브하기 위한 최선의 컨텐츠를 선택하게 됩니다. 이 알고리즘은 서버 특유의 것이며 표준으로 정의된 것은 아닙니다. 예를 위해, Apache 2.2 협상 알고리즘을 참고하시기 바랍니다.

HTTP/1.1 표준은 서버 주도 협상을 시작하는 표준 헤더 목록(Accept, Accept-Charset, Accept-Encoding, Accept-Language)을 정의하고 있습니다. 엄밀히 말하자면 User-Agent이 리스트 내에 없긴 하지만, 해당 헤더는, 좋은 관례가 아니라고 판단될지라도, 때때로 요청된 리소스의 특정 프레젠테이션을 전송하는데 사용되기도 합니다. 서버는 실제로 콘텐츠 협상에 있어 어떤 헤더가 사용될 지 (더 엄밀히 말하자면 연관된 응답 헤더) 가리키기 위해 Vary 헤더를 사용하므로 캐시는 최적으로 동작하게 됩니다.
이것과 더불어, 클라이언트 힌트라고 부르는 헤더들을 이용 가능한 헤더 목록에 추가하려는 실험적인 제안도 존재합니다. 클라이언트 힌트는 사용자 에이전트가 실행 중인 기기의 종류가 무엇인지를 알려줍니다(예를 들어, 데스크톱 컴퓨터인지 모바일 기기인지)
서버 주도 콘텐츠 협상이 리소스의 특정 프레젠테이션에 동의하기 위한 가장 일반적인 방법이긴 하지만, 몇 가지 결점을 가지고 있습니다:

서버는 브라우저에 대한 전체적인 지식을 가지고 있지 않습니다. 클라이언트 힌트 확장이 있더라도, 서버는 브라우저의 수용 능력에 대한 완벽한 정보를 가지고 있진 않습니다. 클라이언트가 선택하는 리액티브 콘텐츠 협상과는 다르게, 서버 선택은 항상 다소 임의적입니다.
클라이언트에 의한 정보는 상당히 장황하며(HTTP/2 헤더 압축은 이런 문제를 완화시킵니다) 사생활 침해에 대한 위협을 가지고 있습니다(HTTP 핑거프린팅).
주어진 리소스의 몇몇 프레젠테이션이 전송되므로, 샤드된 캐시들은 덜 효율적이며 서버 구현은 좀 더 복잡해집니다.
Accept 헤더Accept 헤더는 에이전트가 처리하고자 하는 미디어 리소스의 MIME 타입을 나열합니다. 그것은 MIME 타입을 쉼표로 구분한 목록이며, 각각 품질 인자와 함께 나열되어 있으며, 다른 MIME 타입 사이의 상대적인 선호도를 나타내는 파라메터이기도 합니다.
Accept 헤더는 브라우저나 다른 에이전트에 의해 정의되며 HTML 페이지 혹은 이미지나 비디오 또는 스크립트들을 가져오는 것처럼, 컨텍스트에 따라 다양해질 수 있습니다: 주소창에 입력된 문서를 내려 받을 때와 <img>, <video> 혹은 <audio> 엘리먼트를 통해 링크된 요소를 내려받을 때가 다릅니다. 브라우저는 그들이 판단하기에 가장 적절한 헤더의 값을 마음껏 사용할 것입니다. 일반적인 브라우저를 위한 기본적인 값의 전체 목록을 참고하기 바랍니다.Accept-CH 헤더 
Experimental

참고 :
이것은 클라이언트 힌트라고 불리는 실험적인 기술의 일부로 현재 크롬 46과 그 이후 버전에서만 구현되어 있습니다.

실험적인 Accept-CH는 적합한 응답을 선택하기 위해 서버가 사용할 수 있는 설정 데이터를 나열합니다. 유효한 값들은 다음과 같습니다:



값
의미




DPR
클라이언트 기기의 픽셀 비율(ratio)을 가르킵니다.


Viewport-Width
CSS 픽셀에서의 레이아웃 뷰포트를 가리킵니다.


Width
물리적인 픽셀에서의 리소스 너비를 가리킵니다(다시 말해 이미지의 고유 사이즈).


Accept-Charset 헤더Accept-Charset 헤더는 사용자 에이너트가 어떤 종류의 캐릭터 인코딩을 이해할 수 있는지를 서버에게 알려줍니다. 전통적으로, 그것은 브라우저에 대해 각 지역을 위해 서로 다른 값을 설정하는데 사용되어 왔습니다. 예로 들자면, 서부 유럽 지역을 위해서는 ISO-8859-1,utf-8;q=0.7,*;q=0.7처럼 설정했었습니다.
UTF-8이 현재는 잘 지원되고 있고 인코딩 캐릭터로써 선호하는 방식이 되고 있는 상황에서, 더 적은 설정 기반의 엔트로피(불확실성)를 통해 좀 더 나은 개인정보 보호를 보장하기 위해, 대부분의 브라우저들은 Accept-Charset 헤더를 생략하고 있습니다. Internet Explorer 8, Safari 5, Opera 11 그리고 Firefox 10은 이 헤더를 폐기했습니다.Accept-Encoding 헤더Accept-Encoding 헤더는 수용 가능한 (압축을 지원하는) 컨텐츠 인코딩을 정의하고 있습니다. 값은 인코딩 값의 우선 순위를 가리키는 q 인자 목록(예를 들어, : br, gzip;q=0.8)입니다. 기본값 identity는 가장 낮은 우선 순위입니다(선언된 것이 없는 경우).
HTTP 메시지 압축은 웹 사이트의 성능을 높이는 가장 중요한 방법이며, 전송 데이터의 크기를 줄여주며 가용할 수 있는 대역폭을 더 좋은 상태로 만들어줍니다; 브라우저는 항상 이 헤더를 전송하며 서버는 그것을 받아들이고 압축을 사용하도록 구성되어 있어야 합니다.Accept-Language 헤더Accept-Language 헤더는 사용자가 선호하는 언어를 가리키는데 사용됩니다. 그것은 품질 인자를 가진 값 목록입니다("de, en;q=0.7"). 기본 값은 사용자 에이전트의 그래픽 인터페이스 언어와 관련하여 설정되지만, 대부분의 브라우저들은 다른 언어 설정을 허용합니다.
구성 기반의 엔트로피의 증가로, 사용자 판별에 수정된 값을 사용할 수 없고, 그것을 수정하는 것은 권장되지 않으며 웹 사이트는 사용자의 실제 요구를 반영하기 위해 이 값을 신뢰할 수 없습니다. 이 헤더를 통해 감지된 언어가 좋지 않은 사용자 경험을 유발할 수도 있으므로 사이트 설계자는 해당 헤더 값을 맹신해서는 안 됩니다:

사이트 설계자들은 서버에서 선택한 언어가 아닌 다른 언어를 선택할 수 있는 방법을 제공해야 합니다. 예를 들자면 사이트 상에 언어 메뉴를 제공하는 것이죠. 대부분의 사용자 에이전트들은 사용자 인터페이스 언어에서 차용된 값을 Accept-Language 헤더의 기본값으로 제공하는데, 최종 사용자는, 예를 들어서 인터넷 카페 같은데서, 대게 어떻게 하는지 몰라서, 혹은 그것이 가능한지 몰라서, 그것을 수정하지 않습니다.
사용자가 서버가 선택한 언어를 재정의하고 나면, 사이트는 더 이상 언어 감지를 사용해서는 안되며 명시적으로 선택된 언어를 인정해야 합니다. 다시 말하자면, 사이트의 엔트리 페이지에서만 이 헤더를 사용하여 적당한 언어를 선택해야 합니다.
User-Agent 헤더
참고 :
컨텐츠를 선택함에 있어 이 헤더를 정당하게 사용한다고 할지라도, 사용자 에이전트가 지원하는 것이 무엇인지를 정의하려고 이 헤더에 의지하는 것은 나쁜 습관으로 간주됩니다.

User-Agent 헤더는 요청을 전송하는 브라우저를 식별하게 해줍니다. 이 문자열은 공백 문자로 구분된 *제품 토큰(product tokens)*과 코멘트 목록을 포함합니다.
*제품 토큰(product token)*은 Firefox/4.0.1처럼 브라우저 이름 뒤에 '/'와 버전 번호가 오는 이름입니다. 사용자가 에이전트가 원하는 만큼 많은 수의 이름이 올 수 있습니다. 코멘트는 둥근 괄호를 경계로 하는 자유 문자열입니다. 분명한 것은 괄호가 문자열 안에서는 사용될 수 없다는 것입니다. 코멘트의 내부 형식은 표준으로 정해진 것은 없으나 몇몇 브라우저들은 ';'로 구분하여 그 안에 몇 개의 토큰을 넣습니다.Vary 응답 헤더이전에 봤던 클라이언트에 의해 전송되는 Accept-* 헤더들과는 달리, Vary HTTP 헤더는 웹 서버에 의한 응답 내로 전달됩니다. 이 헤더는 서버 주도 콘텐츠 협상의 과정 중에 서버에 의해 사용되는 헤더들의 목록을 나타냅니다. 이 헤더는 결정 기준 캐시를 알리기 위해 필요하므로 사용자에게 잘못된 컨텐츠를 제공하는 일을 방지하는 동안 캐시가 가동되게 허용하도록 캐시를 복제할 수 있습니다.
특별한 값인 '*'은 서버 주도 콘텐츠 협상이 적합한 컨텐츠 선택을 위해 헤더로 전달되지 않은 정보도 사용한다는 것을 의미합니다.
Vary 헤더는 HTTP 1.1 버전에서 추가되었으며 캐시를 적절하게 동작하도록 허용하는 일이 불필요합니다. 캐시는, 에이전트 주도 콘텐츠 협상과 함께 동작하도록 하기 위해, 전송된 컨텐츠를 선택하도록 서버에 의해 사용되었던 기준이 어떤 것인지 알 필요가 있습니다. 그런 방법으로, 캐시는 알고리즘을 재연할 수 있으며 서버에 추가적인 요청없이도 수용 가능한 컨텐츠를 직접 서브할 수 있게 될 것입니다. 확실히, 캐시는 무슨 요소가 뒤에 있는지 알 수 없으므로, '*' 와일드카드는 현재 일어나고 있는 일들로부터 캐시되는 것을 방지합니다.에이전트 주도 협상서버 주도 협상은 몇 가지 결점을 가지고 있습니다: 그것은 확장하기에 불리합니다. 협상 내에서 사용하는 기능 당 한 가지 헤더가 존재해야 합니다. 만약 스크린 크기, 해상도 혹은 또 다른 치수를 사용하고자 한다면, 새로운 HTTP 헤더가 반드시 만들어져야 합니다. 헤더의 전송은 반드시 모든 요청 상에서 이루어져야 합니다. 이것은 몇몇 헤더들에 있어서는 그리 문제될 것은 아니지만, 그런 헤더들이 결국 증가하여, 메시지 사이즈가 성능에 악영향이 끼치는 상황이 올 수도 있습니다. 전송하는 헤더가 정확하면 정확할수록, 그만큼의 불확실성이 더 전송되고, 더 많은 HTTP 흔적을 남기며 관련된 개인정보 문제들을 불러옵니다.
HTTP의 초창기부터, 프로토콜은 또 다른 협상 유형을 허용했습니다: 에이전트 주도 협상 혹은 리액티브 협상. 이 협상에서, 애매모호한 요청과 맞닥뜨렸을 경우, 서버는 사용 가능한 대체 리소스들에 대한 링크를 포함하고 있는 페이지를 회신하게 됩니다. 사용자는 해당 리소스들을 표시하고 사용하려는 리소스를 선택하게 됩니다.

불행하게도, HTTP 표준은 사용 가능한 리소스 중에서 선택하도록 허용하는 페이지의 형식을 명시하지 않고 있고, 이것이 선택 과정의 자동화를 막고 있습니다. 게다가 서버 주도 협상으로의 회귀로, 이 방법은 스크립팅, 특히 JavaScript 리다이렉션과 함께 거의 항상 사용됩니다: 협상 기준을 점검하고 난 뒤에, 스크립트는 리다이렉션을 실행합니다. 두번째 문제는 실제 리소스를 가져오는데 한 개 이상의 요청이 필요해서, 사용자에게는 리소스 효용성이 떨어진다는 것입니다.Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on 1970년 1월 1일 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n콘텐츠 협상HTTP에서 콘텐츠 협상(Content negotiation)이란 동일한 URI에서 리소스의 서로 다른 버전을 제공하기 위해 사용하는 메커니즘으로, 사용자 에이전트가 사용자에게 제일 잘 맞는 것이 무엇인지(예를 들어, 문서의 언어, 이미지 포맷 혹은 컨텐츠 인코딩에 있어 어떤 것이 적절한지)를 명시할 수 있습니다.콘텐츠 협상의 원칙우리는 특정 문서를 리소스라고 부릅니다. 클라이언트가 리소스를 내려받길 원할 경우, 그것의 URL을 사용하여 요청합니다. 서버는 리소스가 제공하는 여러 변형들 중 하나를 선택하기 위해 이런 URL을 사용하며 (각각의 변형을 프레젠테이션이라고 부릅니다) 클라이언트에게 해당 리소스의 특정 프레젠테이션을 반환합니다. 프레젠테이션들에 더해, 전체 리소스들은 특유의 URL을 가집니다. 리소스가 호출됐을 때 특정 프레젠테이션을 선택하는 방법은 콘텐츠 협상에 의해 결정되며 클라이언트와 서버 간의 협상에는 몇 가지 방식이 존재합니다.

가장 잘 맞는 프레젠테이션의 결정은 다음 두 개의 메커니즘 중 하나를 통해 이루어집니다:

클라이언트가 보내는 특정 HTTP 헤더를 이용하는 방법(서버 주도 협상 혹은 주도적인 협상)으로, 특정 종류의 리소스에 대한 표준 협상 방법입니다.
서버에 의해 전달되는 300 (다중 선택) 혹은 406 (허용되지 않음) HTTP 응답 코드를 이용하는 방법(에이전트 주도 협상 혹은 리액티브 협상)으로, 폴백 메커니즘으로써 사용됩니다.

수년 간, 투명한 콘텐츠 협상과 Alternates 헤더와 같은 다른 콘텐츠 협상 제안들이 제안되어 왔습니다. 그런 제안들은 관심을 끄는데 실패했고 결국 버려졌습니다.서버 주도 콘텐츠 협상서버 주도 콘텐츠 협상 혹은 주도적인 협상에 있어서, 브라우저(혹은 사용자 에이전트라면 어떤 다른 종류든지)는 URL을 이용해 몇 개의 HTTP 헤더를 전송합니다. 이런 헤더들은 사용자의 우선적인 선택을 나타냅니다. 서버는 그것들을 힌트로써 사용하며 내부 알고리즘은 클라이언트로 서브하기 위한 최선의 컨텐츠를 선택하게 됩니다. 이 알고리즘은 서버 특유의 것이며 표준으로 정의된 것은 아닙니다. 예를 위해, Apache 2.2 협상 알고리즘을 참고하시기 바랍니다.

HTTP/1.1 표준은 서버 주도 협상을 시작하는 표준 헤더 목록(Accept, Accept-Charset, Accept-Encoding, Accept-Language)을 정의하고 있습니다. 엄밀히 말하자면 User-Agent이 리스트 내에 없긴 하지만, 해당 헤더는, 좋은 관례가 아니라고 판단될지라도, 때때로 요청된 리소스의 특정 프레젠테이션을 전송하는데 사용되기도 합니다. 서버는 실제로 콘텐츠 협상에 있어 어떤 헤더가 사용될 지 (더 엄밀히 말하자면 연관된 응답 헤더) 가리키기 위해 Vary 헤더를 사용하므로 캐시는 최적으로 동작하게 됩니다.
이것과 더불어, 클라이언트 힌트라고 부르는 헤더들을 이용 가능한 헤더 목록에 추가하려는 실험적인 제안도 존재합니다. 클라이언트 힌트는 사용자 에이전트가 실행 중인 기기의 종류가 무엇인지를 알려줍니다(예를 들어, 데스크톱 컴퓨터인지 모바일 기기인지)
서버 주도 콘텐츠 협상이 리소스의 특정 프레젠테이션에 동의하기 위한 가장 일반적인 방법이긴 하지만, 몇 가지 결점을 가지고 있습니다:

서버는 브라우저에 대한 전체적인 지식을 가지고 있지 않습니다. 클라이언트 힌트 확장이 있더라도, 서버는 브라우저의 수용 능력에 대한 완벽한 정보를 가지고 있진 않습니다. 클라이언트가 선택하는 리액티브 콘텐츠 협상과는 다르게, 서버 선택은 항상 다소 임의적입니다.
클라이언트에 의한 정보는 상당히 장황하며(HTTP/2 헤더 압축은 이런 문제를 완화시킵니다) 사생활 침해에 대한 위협을 가지고 있습니다(HTTP 핑거프린팅).
주어진 리소스의 몇몇 프레젠테이션이 전송되므로, 샤드된 캐시들은 덜 효율적이며 서버 구현은 좀 더 복잡해집니다.
Accept 헤더Accept 헤더는 에이전트가 처리하고자 하는 미디어 리소스의 MIME 타입을 나열합니다. 그것은 MIME 타입을 쉼표로 구분한 목록이며, 각각 품질 인자와 함께 나열되어 있으며, 다른 MIME 타입 사이의 상대적인 선호도를 나타내는 파라메터이기도 합니다.
Accept 헤더는 브라우저나 다른 에이전트에 의해 정의되며 HTML 페이지 혹은 이미지나 비디오 또는 스크립트들을 가져오는 것처럼, 컨텍스트에 따라 다양해질 수 있습니다: 주소창에 입력된 문서를 내려 받을 때와 <img>, <video> 혹은 <audio> 엘리먼트를 통해 링크된 요소를 내려받을 때가 다릅니다. 브라우저는 그들이 판단하기에 가장 적절한 헤더의 값을 마음껏 사용할 것입니다. 일반적인 브라우저를 위한 기본적인 값의 전체 목록을 참고하기 바랍니다.Accept-CH 헤더 
Experimental

참고 :
이것은 클라이언트 힌트라고 불리는 실험적인 기술의 일부로 현재 크롬 46과 그 이후 버전에서만 구현되어 있습니다.

실험적인 Accept-CH는 적합한 응답을 선택하기 위해 서버가 사용할 수 있는 설정 데이터를 나열합니다. 유효한 값들은 다음과 같습니다:



값
의미




DPR
클라이언트 기기의 픽셀 비율(ratio)을 가르킵니다.


Viewport-Width
CSS 픽셀에서의 레이아웃 뷰포트를 가리킵니다.


Width
물리적인 픽셀에서의 리소스 너비를 가리킵니다(다시 말해 이미지의 고유 사이즈).


Accept-Charset 헤더Accept-Charset 헤더는 사용자 에이너트가 어떤 종류의 캐릭터 인코딩을 이해할 수 있는지를 서버에게 알려줍니다. 전통적으로, 그것은 브라우저에 대해 각 지역을 위해 서로 다른 값을 설정하는데 사용되어 왔습니다. 예로 들자면, 서부 유럽 지역을 위해서는 ISO-8859-1,utf-8;q=0.7,*;q=0.7처럼 설정했었습니다.
UTF-8이 현재는 잘 지원되고 있고 인코딩 캐릭터로써 선호하는 방식이 되고 있는 상황에서, 더 적은 설정 기반의 엔트로피(불확실성)를 통해 좀 더 나은 개인정보 보호를 보장하기 위해, 대부분의 브라우저들은 Accept-Charset 헤더를 생략하고 있습니다. Internet Explorer 8, Safari 5, Opera 11 그리고 Firefox 10은 이 헤더를 폐기했습니다.Accept-Encoding 헤더Accept-Encoding 헤더는 수용 가능한 (압축을 지원하는) 컨텐츠 인코딩을 정의하고 있습니다. 값은 인코딩 값의 우선 순위를 가리키는 q 인자 목록(예를 들어, : br, gzip;q=0.8)입니다. 기본값 identity는 가장 낮은 우선 순위입니다(선언된 것이 없는 경우).
HTTP 메시지 압축은 웹 사이트의 성능을 높이는 가장 중요한 방법이며, 전송 데이터의 크기를 줄여주며 가용할 수 있는 대역폭을 더 좋은 상태로 만들어줍니다; 브라우저는 항상 이 헤더를 전송하며 서버는 그것을 받아들이고 압축을 사용하도록 구성되어 있어야 합니다.Accept-Language 헤더Accept-Language 헤더는 사용자가 선호하는 언어를 가리키는데 사용됩니다. 그것은 품질 인자를 가진 값 목록입니다("de, en;q=0.7"). 기본 값은 사용자 에이전트의 그래픽 인터페이스 언어와 관련하여 설정되지만, 대부분의 브라우저들은 다른 언어 설정을 허용합니다.
구성 기반의 엔트로피의 증가로, 사용자 판별에 수정된 값을 사용할 수 없고, 그것을 수정하는 것은 권장되지 않으며 웹 사이트는 사용자의 실제 요구를 반영하기 위해 이 값을 신뢰할 수 없습니다. 이 헤더를 통해 감지된 언어가 좋지 않은 사용자 경험을 유발할 수도 있으므로 사이트 설계자는 해당 헤더 값을 맹신해서는 안 됩니다:

사이트 설계자들은 서버에서 선택한 언어가 아닌 다른 언어를 선택할 수 있는 방법을 제공해야 합니다. 예를 들자면 사이트 상에 언어 메뉴를 제공하는 것이죠. 대부분의 사용자 에이전트들은 사용자 인터페이스 언어에서 차용된 값을 Accept-Language 헤더의 기본값으로 제공하는데, 최종 사용자는, 예를 들어서 인터넷 카페 같은데서, 대게 어떻게 하는지 몰라서, 혹은 그것이 가능한지 몰라서, 그것을 수정하지 않습니다.
사용자가 서버가 선택한 언어를 재정의하고 나면, 사이트는 더 이상 언어 감지를 사용해서는 안되며 명시적으로 선택된 언어를 인정해야 합니다. 다시 말하자면, 사이트의 엔트리 페이지에서만 이 헤더를 사용하여 적당한 언어를 선택해야 합니다.
User-Agent 헤더
참고 :
컨텐츠를 선택함에 있어 이 헤더를 정당하게 사용한다고 할지라도, 사용자 에이전트가 지원하는 것이 무엇인지를 정의하려고 이 헤더에 의지하는 것은 나쁜 습관으로 간주됩니다.

User-Agent 헤더는 요청을 전송하는 브라우저를 식별하게 해줍니다. 이 문자열은 공백 문자로 구분된 *제품 토큰(product tokens)*과 코멘트 목록을 포함합니다.
*제품 토큰(product token)*은 Firefox/4.0.1처럼 브라우저 이름 뒤에 '/'와 버전 번호가 오는 이름입니다. 사용자가 에이전트가 원하는 만큼 많은 수의 이름이 올 수 있습니다. 코멘트는 둥근 괄호를 경계로 하는 자유 문자열입니다. 분명한 것은 괄호가 문자열 안에서는 사용될 수 없다는 것입니다. 코멘트의 내부 형식은 표준으로 정해진 것은 없으나 몇몇 브라우저들은 ';'로 구분하여 그 안에 몇 개의 토큰을 넣습니다.Vary 응답 헤더이전에 봤던 클라이언트에 의해 전송되는 Accept-* 헤더들과는 달리, Vary HTTP 헤더는 웹 서버에 의한 응답 내로 전달됩니다. 이 헤더는 서버 주도 콘텐츠 협상의 과정 중에 서버에 의해 사용되는 헤더들의 목록을 나타냅니다. 이 헤더는 결정 기준 캐시를 알리기 위해 필요하므로 사용자에게 잘못된 컨텐츠를 제공하는 일을 방지하는 동안 캐시가 가동되게 허용하도록 캐시를 복제할 수 있습니다.
특별한 값인 '*'은 서버 주도 콘텐츠 협상이 적합한 컨텐츠 선택을 위해 헤더로 전달되지 않은 정보도 사용한다는 것을 의미합니다.
Vary 헤더는 HTTP 1.1 버전에서 추가되었으며 캐시를 적절하게 동작하도록 허용하는 일이 불필요합니다. 캐시는, 에이전트 주도 콘텐츠 협상과 함께 동작하도록 하기 위해, 전송된 컨텐츠를 선택하도록 서버에 의해 사용되었던 기준이 어떤 것인지 알 필요가 있습니다. 그런 방법으로, 캐시는 알고리즘을 재연할 수 있으며 서버에 추가적인 요청없이도 수용 가능한 컨텐츠를 직접 서브할 수 있게 될 것입니다. 확실히, 캐시는 무슨 요소가 뒤에 있는지 알 수 없으므로, '*' 와일드카드는 현재 일어나고 있는 일들로부터 캐시되는 것을 방지합니다.에이전트 주도 협상서버 주도 협상은 몇 가지 결점을 가지고 있습니다: 그것은 확장하기에 불리합니다. 협상 내에서 사용하는 기능 당 한 가지 헤더가 존재해야 합니다. 만약 스크린 크기, 해상도 혹은 또 다른 치수를 사용하고자 한다면, 새로운 HTTP 헤더가 반드시 만들어져야 합니다. 헤더의 전송은 반드시 모든 요청 상에서 이루어져야 합니다. 이것은 몇몇 헤더들에 있어서는 그리 문제될 것은 아니지만, 그런 헤더들이 결국 증가하여, 메시지 사이즈가 성능에 악영향이 끼치는 상황이 올 수도 있습니다. 전송하는 헤더가 정확하면 정확할수록, 그만큼의 불확실성이 더 전송되고, 더 많은 HTTP 흔적을 남기며 관련된 개인정보 문제들을 불러옵니다.
HTTP의 초창기부터, 프로토콜은 또 다른 협상 유형을 허용했습니다: 에이전트 주도 협상 혹은 리액티브 협상. 이 협상에서, 애매모호한 요청과 맞닥뜨렸을 경우, 서버는 사용 가능한 대체 리소스들에 대한 링크를 포함하고 있는 페이지를 회신하게 됩니다. 사용자는 해당 리소스들을 표시하고 사용하려는 리소스를 선택하게 됩니다.

불행하게도, HTTP 표준은 사용 가능한 리소스 중에서 선택하도록 허용하는 페이지의 형식을 명시하지 않고 있고, 이것이 선택 과정의 자동화를 막고 있습니다. 게다가 서버 주도 협상으로의 회귀로, 이 방법은 스크립팅, 특히 JavaScript 리다이렉션과 함께 거의 항상 사용됩니다: 협상 기준을 점검하고 난 뒤에, 스크립트는 리다이렉션을 실행합니다. 두번째 문제는 실제 리소스를 가져오는데 한 개 이상의 요청이 필요해서, 사용자에게는 리소스 효용성이 떨어진다는 것입니다.Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on 1970년 1월 1일 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nNegociação de conteúdoNo HTTP, negociação de conteúdo é o mecanismo que é usado para servir diferentesrepresentações de um recurso no mesmo URI, de forma que o agente do usuáriopossa especificar qual é a melhor representação adequada ao usuário(por exemplo, qual idioma de um documento, qual formato de imagem ouqual codificação de conteúdo)Princípios da negociação do conteúdoUm documento específico é denominado recurso. Quando um cliente quer obtê-lo, ele o requisita usando sua URL. O servidor usa esta URL para escolherum das variantes que ele provê - cada variante sendo chamada de representação - e retorna essa representação específica para o cliente. O recurso de forma geral, bem como suas representações, têm uma URL específica. Como uma representação específica é escolhida quando um recurso é chamado é determinado pela negociação de conteúdo e existem algumas maneiras de negociar entre entre o cliente e o servidor.

A determinação da representação mais adequada é feita através de um dos dois mecanismos:

Cabeçalhos HTTP específicos pelo cliente (negociação com base no servidor ou negociação pró-ativa)
Os códigos de resposta do servidor {HTTPStatus("300")}} (Múltiplas escolhas) or 406 (Não aceitável) (negociação baseada no agente ou negociação reativa), que são usados como mecanimos de reserva (fallback).

Ao longo dos anos, outras propostas de negociação de conteúdo, como negociação de conteúdo transparente e o cabeçalho Alternates foram propostas. Elas falharam em ganhar apoio e foram abandonadas.Negociação baseada no servidorNa negociação baseada no servidor, ou negociação proativa, o navegador (ou outro tipo de agente do usuário) envia diversos cabeçalhos HTTP junto com a URL. Estes cabeçalhos descrevem a escolha preferida do usuário. O servidor usa-os como sugestões e um algoritmo intero escolhe o melhor conteúdo para ser servido ao usuário. O algoritmo é específico para cada servidor e não é definido no padrão. Veja, por-exemplo, o algoritmo de negociação do Apache 2.2.

O padrão HTTP/1.1 define uma lista de cabeçalhos-padrão que iniciam a negociação baseada no servidor (Accept, Accept-Charset, Accept-Encoding, Accept-Language). Apesar do User-Agent não estar formalmente na lista, ele é, às vezes, também usado para enviar uma representação específica do recurso requisitado, apesar disso não ser considerado uma boa prática. O servidor usa o cabeçalho Vary para indicar quais cebeçalhos de fato foram usados na negociação do conteúdo (ou, mais precisamente, nos cabeçahos de resposta associados), de forma que caches possam funcionar de forma otimizada.
Além desses, existe uma proposta experimental para adicionar mais cabeçalhos à lista dos disponíveis, as chamadas sugestões do cliente. Sugestões do cliente indicam qual é o tipo do dispositivo em que o agente do usuário roda (por-exemplo, se é um computador de mesa ou um dispositivo móvel).
Mesmo sendo a negociação com base no servidor a forma mais comum de concordar com uma representação específica de um recurso, ela ainda assim tem algumas desvantagens:

O servidor não tem conhecimento total sobre o navegador. Mesmo com a extensão das Sugestões do cliente, o servidor continua sem saber completamente quais são as capacidades do navegador. Diferente da negociação de conteúdo reativa, onde o cliente faz uma escolha, a escolha do servidor é, até certo ponto, arbitrária.
A informação do cliente é bastante verbosa (a compressão de cabeçalhos do HTTP/2 mitiga este problema) e um risco à privacidade (impressão digital HTTP).
Como diversas representações de um recurso são enviadas, caches compartilhados são menos eficiantes e, implementações de servidor, mais complexas.
The Accept headerThe Accept header lists the MIME types of media resources that the agent is willing to process. It is comma-separated lists of MIME types, each combined with a quality factor, a parameter indicating the relative degree of preference between the different MIME types.
The Accept header is defined by the browser, or any other user-agent, and can vary according to the context, like fetching an HTML page or an image, a video, or a script: It is different when fetching a document entered in the address bar or an element linked via an <img>, <video> or <audio> element. Browsers are free to use the value of the header that they think is the most adequate; an exhaustive list of default values for common browsers is available.The Accept-CH header 
Experimental

Nota:
This is part of an experimental technology called Client Hints. Initial support is in Chrome 46 or later. The Device-Memory value is in Chrome 61 or later.

The experimental Accept-CH lists configuration data that can be used by the server to select an appropriate response. Valid values are:



Value
Meaning




Device-Memory
Indicates the approximate amount of device RAM. This value is an approximation given by rounding to the nearest power of 2 and dividing that number by 1024. For example, 512 megabytes will be reported as 0.5.


DPR
Indicates the client's device pixel ratio.


Viewport-Width
Indicates the layout viewport width in CSS pixels.


Width
Indicates the resource width in physical pixels (in other words the intrinsic size of an image).


The Accept-Charset headerThe Accept-Charset header indicates to the server what kinds of character encodings are understood by the user-agent. Traditionally, it was set to a different value for each locale for the browser, like ISO-8859-1,utf-8;q=0.7,*;q=0.7 for a Western European locale.
With UTF-8 now being well-supported, being the preferred way of encoding characters, and to guarantee better privacy through less configuration-based entropy, browsers omit the Accept-Charset header: Internet Explorer 8, Safari 5, Opera 11, Firefox 10 and Chrome 27 have abandoned this header.The Accept-CH-Lifetime header
Nota:
This is part of an experimental technology called Client Hints and is only available in Chrome 61 or later.

The Accept-CH-Lifetime header is used with the Device-Memory value of the Accept-CH header and indicates the amount of time the device should opt-in to sharing the amount of device memory with the server. The value is given in miliseconds and it's use is optional.The Accept-Encoding headerThe Accept-Encoding header defines the acceptable content-encoding (supported compressions). The value is a q-factor list (e.g.: br, gzip;q=0.8) that indicates the priority of the encoding values. The default value identity is at the lowest priority (unless otherwise declared).
Compressing HTTP messages is one of the most important ways to improve the performance of a Web site, it shrinks the size of the data transmitted and makes better use of the available bandwidth; browsers always send this header and the server should be configured to abide to it and to use compression.The Accept-Language headerThe Accept-Language header is used to indicate the language preference of the user. It is a list of values with quality factors (like: "de, en;q=0.7"). A default value is often set according the language of the graphical interface of the user agent, but most browsers allow to set different language preferences.
Due to the configuration-based entropy increase, a modified value can be used to fingerprint the user, it is not recommended to change it and a Web site cannot trust this value to reflect the actual wish of the user. Site designers must not be over-zealous by using language detection via this header as it can lead to a poor user experience:

They should always provide a way to overcome the server-chosen language, e.g., by providing a language menu on the site. Most user-agents provide a default value for the Accept-Language header, adapted to the user interface language and end users often do not modify it, either by not knowing how, or by not being able to do it, as in an Internet café for instance.
Once a user has overridden the server-chosen language, a site should no longer use language detection and should stick with the explicitly-chosen language. In other words, only entry pages of a site should select the proper language using this header.
The User-Agent header
Nota:
Though there are legitimate uses of this header for selecting content, it is considered bad practice to rely on it to define what features are supported by the user agent.

The User-Agent header identifies the browser sending the request. This string may contain a space-separated list of product tokens and comments.
A product token is a name followed by a '/' and a version number, like Firefox/4.0.1. There may be as many of them as the user-agent wants. A comment is a free string delimited by parentheses. Obviously parentheses cannot be used in that string. The inner format of a comment is not defined by the standard, though several browser put several tokens in it, separated by ';'.The Vary response headerIn opposition to the previous Accept-* headers which are sent by the client, the Vary HTTP header is sent by the web server in its response. It indicates the list of headers used by the server during the server-driven content negotiation phase. The header is needed in order to inform the cache of the decision criteria so that it can reproduce it, allowing the cache to be functional while preventing serving erroneous content to the user.
The special value of '*' means that the server-driven content negotiation also uses information not conveyed in a header to choose the appropriate content.
The Vary header was added in the version 1.1 of HTTP and is necessary in order to allow caches to work appropriately. A cache, in order to work with server-driven content negotiation, needs to know which criteria was used by the server to select the transmitted content. That way, the cache can replay the algorithm and will be able to serve acceptable content directly, without more request to the server. Obviously, the wildcard '*' prevents caching from occurring, as the cache cannot know what element is behind it.Agent-driven negotiationServer-driven negotiation suffers from a few downsides: it doesn't scale well. There is one header per feature used in the negotiation. If you want to use screen size, resolution or other dimensions, a new HTTP header must be created. Sending of the headers must be done on every request. This is not too problematic with few headers, but with the eventual multiplications of them, the message size would lead to a decrease in performance. The more precise headers are sent, the more entropy is sent, allowing for more HTTP fingerprinting and corresponding privacy concern.
From the beginnings of HTTP, the protocol allowed another negotiation type: agent-driven negotiation or reactive negotiation. In this negotiation, when facing an ambiguous request, the server sends back a page containing links to the available alternative resources. The user is presented the resources and choose the one to use.

Unfortunately, the HTTP standard does not specify the format of the page allowing to choose between the available resource, which prevents to easily automatize the process. Besides falling back to the server-driven negotiation, this method is almost always used in conjunction with scripting, especially with JavaScript redirection: after having checked for the negotiation criteria, the script performs the redirection. A second problem is that one more request is needed in order to fetch the real resource, slowing the availability of the resource to the user.\n\nNegociação de conteúdoNo HTTP, negociação de conteúdo é o mecanismo que é usado para servir diferentesrepresentações de um recurso no mesmo URI, de forma que o agente do usuáriopossa especificar qual é a melhor representação adequada ao usuário(por exemplo, qual idioma de um documento, qual formato de imagem ouqual codificação de conteúdo)Princípios da negociação do conteúdoUm documento específico é denominado recurso. Quando um cliente quer obtê-lo, ele o requisita usando sua URL. O servidor usa esta URL para escolherum das variantes que ele provê - cada variante sendo chamada de representação - e retorna essa representação específica para o cliente. O recurso de forma geral, bem como suas representações, têm uma URL específica. Como uma representação específica é escolhida quando um recurso é chamado é determinado pela negociação de conteúdo e existem algumas maneiras de negociar entre entre o cliente e o servidor.

A determinação da representação mais adequada é feita através de um dos dois mecanismos:

Cabeçalhos HTTP específicos pelo cliente (negociação com base no servidor ou negociação pró-ativa)
Os códigos de resposta do servidor {HTTPStatus("300")}} (Múltiplas escolhas) or 406 (Não aceitável) (negociação baseada no agente ou negociação reativa), que são usados como mecanimos de reserva (fallback).

Ao longo dos anos, outras propostas de negociação de conteúdo, como negociação de conteúdo transparente e o cabeçalho Alternates foram propostas. Elas falharam em ganhar apoio e foram abandonadas.Negociação baseada no servidorNa negociação baseada no servidor, ou negociação proativa, o navegador (ou outro tipo de agente do usuário) envia diversos cabeçalhos HTTP junto com a URL. Estes cabeçalhos descrevem a escolha preferida do usuário. O servidor usa-os como sugestões e um algoritmo intero escolhe o melhor conteúdo para ser servido ao usuário. O algoritmo é específico para cada servidor e não é definido no padrão. Veja, por-exemplo, o algoritmo de negociação do Apache 2.2.

O padrão HTTP/1.1 define uma lista de cabeçalhos-padrão que iniciam a negociação baseada no servidor (Accept, Accept-Charset, Accept-Encoding, Accept-Language). Apesar do User-Agent não estar formalmente na lista, ele é, às vezes, também usado para enviar uma representação específica do recurso requisitado, apesar disso não ser considerado uma boa prática. O servidor usa o cabeçalho Vary para indicar quais cebeçalhos de fato foram usados na negociação do conteúdo (ou, mais precisamente, nos cabeçahos de resposta associados), de forma que caches possam funcionar de forma otimizada.
Além desses, existe uma proposta experimental para adicionar mais cabeçalhos à lista dos disponíveis, as chamadas sugestões do cliente. Sugestões do cliente indicam qual é o tipo do dispositivo em que o agente do usuário roda (por-exemplo, se é um computador de mesa ou um dispositivo móvel).
Mesmo sendo a negociação com base no servidor a forma mais comum de concordar com uma representação específica de um recurso, ela ainda assim tem algumas desvantagens:

O servidor não tem conhecimento total sobre o navegador. Mesmo com a extensão das Sugestões do cliente, o servidor continua sem saber completamente quais são as capacidades do navegador. Diferente da negociação de conteúdo reativa, onde o cliente faz uma escolha, a escolha do servidor é, até certo ponto, arbitrária.
A informação do cliente é bastante verbosa (a compressão de cabeçalhos do HTTP/2 mitiga este problema) e um risco à privacidade (impressão digital HTTP).
Como diversas representações de um recurso são enviadas, caches compartilhados são menos eficiantes e, implementações de servidor, mais complexas.
The Accept headerThe Accept header lists the MIME types of media resources that the agent is willing to process. It is comma-separated lists of MIME types, each combined with a quality factor, a parameter indicating the relative degree of preference between the different MIME types.
The Accept header is defined by the browser, or any other user-agent, and can vary according to the context, like fetching an HTML page or an image, a video, or a script: It is different when fetching a document entered in the address bar or an element linked via an <img>, <video> or <audio> element. Browsers are free to use the value of the header that they think is the most adequate; an exhaustive list of default values for common browsers is available.The Accept-CH header 
Experimental

Nota:
This is part of an experimental technology called Client Hints. Initial support is in Chrome 46 or later. The Device-Memory value is in Chrome 61 or later.

The experimental Accept-CH lists configuration data that can be used by the server to select an appropriate response. Valid values are:



Value
Meaning




Device-Memory
Indicates the approximate amount of device RAM. This value is an approximation given by rounding to the nearest power of 2 and dividing that number by 1024. For example, 512 megabytes will be reported as 0.5.


DPR
Indicates the client's device pixel ratio.


Viewport-Width
Indicates the layout viewport width in CSS pixels.


Width
Indicates the resource width in physical pixels (in other words the intrinsic size of an image).


The Accept-Charset headerThe Accept-Charset header indicates to the server what kinds of character encodings are understood by the user-agent. Traditionally, it was set to a different value for each locale for the browser, like ISO-8859-1,utf-8;q=0.7,*;q=0.7 for a Western European locale.
With UTF-8 now being well-supported, being the preferred way of encoding characters, and to guarantee better privacy through less configuration-based entropy, browsers omit the Accept-Charset header: Internet Explorer 8, Safari 5, Opera 11, Firefox 10 and Chrome 27 have abandoned this header.The Accept-CH-Lifetime header
Nota:
This is part of an experimental technology called Client Hints and is only available in Chrome 61 or later.

The Accept-CH-Lifetime header is used with the Device-Memory value of the Accept-CH header and indicates the amount of time the device should opt-in to sharing the amount of device memory with the server. The value is given in miliseconds and it's use is optional.The Accept-Encoding headerThe Accept-Encoding header defines the acceptable content-encoding (supported compressions). The value is a q-factor list (e.g.: br, gzip;q=0.8) that indicates the priority of the encoding values. The default value identity is at the lowest priority (unless otherwise declared).
Compressing HTTP messages is one of the most important ways to improve the performance of a Web site, it shrinks the size of the data transmitted and makes better use of the available bandwidth; browsers always send this header and the server should be configured to abide to it and to use compression.The Accept-Language headerThe Accept-Language header is used to indicate the language preference of the user. It is a list of values with quality factors (like: "de, en;q=0.7"). A default value is often set according the language of the graphical interface of the user agent, but most browsers allow to set different language preferences.
Due to the configuration-based entropy increase, a modified value can be used to fingerprint the user, it is not recommended to change it and a Web site cannot trust this value to reflect the actual wish of the user. Site designers must not be over-zealous by using language detection via this header as it can lead to a poor user experience:

They should always provide a way to overcome the server-chosen language, e.g., by providing a language menu on the site. Most user-agents provide a default value for the Accept-Language header, adapted to the user interface language and end users often do not modify it, either by not knowing how, or by not being able to do it, as in an Internet café for instance.
Once a user has overridden the server-chosen language, a site should no longer use language detection and should stick with the explicitly-chosen language. In other words, only entry pages of a site should select the proper language using this header.
The User-Agent header
Nota:
Though there are legitimate uses of this header for selecting content, it is considered bad practice to rely on it to define what features are supported by the user agent.

The User-Agent header identifies the browser sending the request. This string may contain a space-separated list of product tokens and comments.
A product token is a name followed by a '/' and a version number, like Firefox/4.0.1. There may be as many of them as the user-agent wants. A comment is a free string delimited by parentheses. Obviously parentheses cannot be used in that string. The inner format of a comment is not defined by the standard, though several browser put several tokens in it, separated by ';'.The Vary response headerIn opposition to the previous Accept-* headers which are sent by the client, the Vary HTTP header is sent by the web server in its response. It indicates the list of headers used by the server during the server-driven content negotiation phase. The header is needed in order to inform the cache of the decision criteria so that it can reproduce it, allowing the cache to be functional while preventing serving erroneous content to the user.
The special value of '*' means that the server-driven content negotiation also uses information not conveyed in a header to choose the appropriate content.
The Vary header was added in the version 1.1 of HTTP and is necessary in order to allow caches to work appropriately. A cache, in order to work with server-driven content negotiation, needs to know which criteria was used by the server to select the transmitted content. That way, the cache can replay the algorithm and will be able to serve acceptable content directly, without more request to the server. Obviously, the wildcard '*' prevents caching from occurring, as the cache cannot know what element is behind it.Agent-driven negotiationServer-driven negotiation suffers from a few downsides: it doesn't scale well. There is one header per feature used in the negotiation. If you want to use screen size, resolution or other dimensions, a new HTTP header must be created. Sending of the headers must be done on every request. This is not too problematic with few headers, but with the eventual multiplications of them, the message size would lead to a decrease in performance. The more precise headers are sent, the more entropy is sent, allowing for more HTTP fingerprinting and corresponding privacy concern.
From the beginnings of HTTP, the protocol allowed another negotiation type: agent-driven negotiation or reactive negotiation. In this negotiation, when facing an ambiguous request, the server sends back a page containing links to the available alternative resources. The user is presented the resources and choose the one to use.

Unfortunately, the HTTP standard does not specify the format of the page allowing to choose between the available resource, which prevents to easily automatize the process. Besides falling back to the server-driven negotiation, this method is almost always used in conjunction with scripting, especially with JavaScript redirection: after having checked for the negotiation criteria, the script performs the redirection. A second problem is that one more request is needed in order to fetch the real resource, slowing the availability of the resource to the user.Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on 16 de mar. de 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nNegociação de conteúdoNo HTTP, negociação de conteúdo é o mecanismo que é usado para servir diferentesrepresentações de um recurso no mesmo URI, de forma que o agente do usuáriopossa especificar qual é a melhor representação adequada ao usuário(por exemplo, qual idioma de um documento, qual formato de imagem ouqual codificação de conteúdo)Princípios da negociação do conteúdoUm documento específico é denominado recurso. Quando um cliente quer obtê-lo, ele o requisita usando sua URL. O servidor usa esta URL para escolherum das variantes que ele provê - cada variante sendo chamada de representação - e retorna essa representação específica para o cliente. O recurso de forma geral, bem como suas representações, têm uma URL específica. Como uma representação específica é escolhida quando um recurso é chamado é determinado pela negociação de conteúdo e existem algumas maneiras de negociar entre entre o cliente e o servidor.

A determinação da representação mais adequada é feita através de um dos dois mecanismos:

Cabeçalhos HTTP específicos pelo cliente (negociação com base no servidor ou negociação pró-ativa)
Os códigos de resposta do servidor {HTTPStatus("300")}} (Múltiplas escolhas) or 406 (Não aceitável) (negociação baseada no agente ou negociação reativa), que são usados como mecanimos de reserva (fallback).

Ao longo dos anos, outras propostas de negociação de conteúdo, como negociação de conteúdo transparente e o cabeçalho Alternates foram propostas. Elas falharam em ganhar apoio e foram abandonadas.Negociação baseada no servidorNa negociação baseada no servidor, ou negociação proativa, o navegador (ou outro tipo de agente do usuário) envia diversos cabeçalhos HTTP junto com a URL. Estes cabeçalhos descrevem a escolha preferida do usuário. O servidor usa-os como sugestões e um algoritmo intero escolhe o melhor conteúdo para ser servido ao usuário. O algoritmo é específico para cada servidor e não é definido no padrão. Veja, por-exemplo, o algoritmo de negociação do Apache 2.2.

O padrão HTTP/1.1 define uma lista de cabeçalhos-padrão que iniciam a negociação baseada no servidor (Accept, Accept-Charset, Accept-Encoding, Accept-Language). Apesar do User-Agent não estar formalmente na lista, ele é, às vezes, também usado para enviar uma representação específica do recurso requisitado, apesar disso não ser considerado uma boa prática. O servidor usa o cabeçalho Vary para indicar quais cebeçalhos de fato foram usados na negociação do conteúdo (ou, mais precisamente, nos cabeçahos de resposta associados), de forma que caches possam funcionar de forma otimizada.
Além desses, existe uma proposta experimental para adicionar mais cabeçalhos à lista dos disponíveis, as chamadas sugestões do cliente. Sugestões do cliente indicam qual é o tipo do dispositivo em que o agente do usuário roda (por-exemplo, se é um computador de mesa ou um dispositivo móvel).
Mesmo sendo a negociação com base no servidor a forma mais comum de concordar com uma representação específica de um recurso, ela ainda assim tem algumas desvantagens:

O servidor não tem conhecimento total sobre o navegador. Mesmo com a extensão das Sugestões do cliente, o servidor continua sem saber completamente quais são as capacidades do navegador. Diferente da negociação de conteúdo reativa, onde o cliente faz uma escolha, a escolha do servidor é, até certo ponto, arbitrária.
A informação do cliente é bastante verbosa (a compressão de cabeçalhos do HTTP/2 mitiga este problema) e um risco à privacidade (impressão digital HTTP).
Como diversas representações de um recurso são enviadas, caches compartilhados são menos eficiantes e, implementações de servidor, mais complexas.
The Accept headerThe Accept header lists the MIME types of media resources that the agent is willing to process. It is comma-separated lists of MIME types, each combined with a quality factor, a parameter indicating the relative degree of preference between the different MIME types.
The Accept header is defined by the browser, or any other user-agent, and can vary according to the context, like fetching an HTML page or an image, a video, or a script: It is different when fetching a document entered in the address bar or an element linked via an <img>, <video> or <audio> element. Browsers are free to use the value of the header that they think is the most adequate; an exhaustive list of default values for common browsers is available.The Accept-CH header 
Experimental

Nota:
This is part of an experimental technology called Client Hints. Initial support is in Chrome 46 or later. The Device-Memory value is in Chrome 61 or later.

The experimental Accept-CH lists configuration data that can be used by the server to select an appropriate response. Valid values are:



Value
Meaning




Device-Memory
Indicates the approximate amount of device RAM. This value is an approximation given by rounding to the nearest power of 2 and dividing that number by 1024. For example, 512 megabytes will be reported as 0.5.


DPR
Indicates the client's device pixel ratio.


Viewport-Width
Indicates the layout viewport width in CSS pixels.


Width
Indicates the resource width in physical pixels (in other words the intrinsic size of an image).


The Accept-Charset headerThe Accept-Charset header indicates to the server what kinds of character encodings are understood by the user-agent. Traditionally, it was set to a different value for each locale for the browser, like ISO-8859-1,utf-8;q=0.7,*;q=0.7 for a Western European locale.
With UTF-8 now being well-supported, being the preferred way of encoding characters, and to guarantee better privacy through less configuration-based entropy, browsers omit the Accept-Charset header: Internet Explorer 8, Safari 5, Opera 11, Firefox 10 and Chrome 27 have abandoned this header.The Accept-CH-Lifetime header
Nota:
This is part of an experimental technology called Client Hints and is only available in Chrome 61 or later.

The Accept-CH-Lifetime header is used with the Device-Memory value of the Accept-CH header and indicates the amount of time the device should opt-in to sharing the amount of device memory with the server. The value is given in miliseconds and it's use is optional.The Accept-Encoding headerThe Accept-Encoding header defines the acceptable content-encoding (supported compressions). The value is a q-factor list (e.g.: br, gzip;q=0.8) that indicates the priority of the encoding values. The default value identity is at the lowest priority (unless otherwise declared).
Compressing HTTP messages is one of the most important ways to improve the performance of a Web site, it shrinks the size of the data transmitted and makes better use of the available bandwidth; browsers always send this header and the server should be configured to abide to it and to use compression.The Accept-Language headerThe Accept-Language header is used to indicate the language preference of the user. It is a list of values with quality factors (like: "de, en;q=0.7"). A default value is often set according the language of the graphical interface of the user agent, but most browsers allow to set different language preferences.
Due to the configuration-based entropy increase, a modified value can be used to fingerprint the user, it is not recommended to change it and a Web site cannot trust this value to reflect the actual wish of the user. Site designers must not be over-zealous by using language detection via this header as it can lead to a poor user experience:

They should always provide a way to overcome the server-chosen language, e.g., by providing a language menu on the site. Most user-agents provide a default value for the Accept-Language header, adapted to the user interface language and end users often do not modify it, either by not knowing how, or by not being able to do it, as in an Internet café for instance.
Once a user has overridden the server-chosen language, a site should no longer use language detection and should stick with the explicitly-chosen language. In other words, only entry pages of a site should select the proper language using this header.
The User-Agent header
Nota:
Though there are legitimate uses of this header for selecting content, it is considered bad practice to rely on it to define what features are supported by the user agent.

The User-Agent header identifies the browser sending the request. This string may contain a space-separated list of product tokens and comments.
A product token is a name followed by a '/' and a version number, like Firefox/4.0.1. There may be as many of them as the user-agent wants. A comment is a free string delimited by parentheses. Obviously parentheses cannot be used in that string. The inner format of a comment is not defined by the standard, though several browser put several tokens in it, separated by ';'.The Vary response headerIn opposition to the previous Accept-* headers which are sent by the client, the Vary HTTP header is sent by the web server in its response. It indicates the list of headers used by the server during the server-driven content negotiation phase. The header is needed in order to inform the cache of the decision criteria so that it can reproduce it, allowing the cache to be functional while preventing serving erroneous content to the user.
The special value of '*' means that the server-driven content negotiation also uses information not conveyed in a header to choose the appropriate content.
The Vary header was added in the version 1.1 of HTTP and is necessary in order to allow caches to work appropriately. A cache, in order to work with server-driven content negotiation, needs to know which criteria was used by the server to select the transmitted content. That way, the cache can replay the algorithm and will be able to serve acceptable content directly, without more request to the server. Obviously, the wildcard '*' prevents caching from occurring, as the cache cannot know what element is behind it.Agent-driven negotiationServer-driven negotiation suffers from a few downsides: it doesn't scale well. There is one header per feature used in the negotiation. If you want to use screen size, resolution or other dimensions, a new HTTP header must be created. Sending of the headers must be done on every request. This is not too problematic with few headers, but with the eventual multiplications of them, the message size would lead to a decrease in performance. The more precise headers are sent, the more entropy is sent, allowing for more HTTP fingerprinting and corresponding privacy concern.
From the beginnings of HTTP, the protocol allowed another negotiation type: agent-driven negotiation or reactive negotiation. In this negotiation, when facing an ambiguous request, the server sends back a page containing links to the available alternative resources. The user is presented the resources and choose the one to use.

Unfortunately, the HTTP standard does not specify the format of the page allowing to choose between the available resource, which prevents to easily automatize the process. Besides falling back to the server-driven negotiation, this method is almost always used in conjunction with scripting, especially with JavaScript redirection: after having checked for the negotiation criteria, the script performs the redirection. A second problem is that one more request is needed in order to fetch the real resource, slowing the availability of the resource to the user.Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on 16 de mar. de 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nСогласование контентаВ HTTP, согласование контента - это механизм используемый для отображения различных представлений ресурса по тому же URI, так чтобы клиент мог указать, что лучше подходит для пользователя (например, желаемый язык документа, формат изображения, или кодировку текста).Принципы согласования контентаКонкретный документ называется ресурсом. Когда клиент хочет его получить, он запрашивает его используя его URL. Сервер использует этот URL, чтобы выбрать один из возможных вариантов - каждый вариант, называется представлением, – и возвращает этот вариант клиенту. Ресурс в общем, а также каждое из представлений, имеют определённый URL. Выбор конкретного представления при вызове ресурса определяется механизмом согласования контента и существует несколько способов согласования между клиентом и сервером.

Определение наиболее подходящего представления производится с помощью одного из двух механизмов:

Конкретные HTTP-заголовки клиента (согласование на основе сервера или упреждающее согласование), что является стандартным способом согласования определённого вида ресурса.
HTTP коды ответа 300 (Multiple Choices) или 406 (Not Acceptable) (согласование на основе агента или реактивное согласование), используемые в качестве резервных механизмов.

На протяжении многих лет предлагались и другие предложения по согласованию содержания, такие как прозрачное согласование контента и Alternates заголовок. Они не смогли получить достаточной поддержки и были заброшены.Согласование на основе сервераВ согласовании на стороне сервера или упреждающем согласовании, браузер (или любое другое клиентское приложение) посылает несколько заголовков HTTP наряду с URL. Эти заголовки описывают предпочтения пользователя. Сервер использует их в качестве подсказок для внутреннего алгоритма, который выбирает наиболее подходящее представление ресурса, чтобы предоставить его клиенту. Реализация алгоритма в стандарт не входит и полностью зависит от сервера. Для примера, смотрите алгоритм согласования Apache 2.2.

Стандарт HTTP/1.1 определяет список стандартных заголовков которые используются в этом механизме согласования – (Accept, Accept-Encoding, Accept-Language). Хотя, строго говоря, User-Agent не находится в этом списке, в некоторых случаях он используется, чтобы послать определённое представление запрошенного ресурса, несмотря на то, что это и не является хорошей практикой. Сервер использует заголовок Vary чтобы обозначить, какие заголовки он использовал для согласования (точнее, ассоциированные с ними заголовки ответа), чтобы кеширование работало оптимально.
В дополнение к этим, есть предложение добавить больше заголовков в список доступным, так называемые Подсказки Клиента (Client Hints). Они будут предоставлять информацию о типе устройства на котором они используются (например, будет это настольный компьютер или мобильное устройство).
Согласование на стороне сервера является самым популярным способом согласования контента, но у него есть несколько недостатков:

У сервера нет всей информации о клиентском приложении. Даже с расширением Client Hints сервер не может знать всех возможностей браузера. В отличие от реактивного согласования, где клиент совершает выбор, выбор сервера всегда остаётся в каком-то смысле произвольным.
Информация, полученная от клиента, довольно подробная (сжатие заголовков протокола HTTP/2 отчасти решает эту проблему) и является источником утечки конфиденциальности (идентификация по HTTP).
С увеличением количества представлений падает эффективность общих кешей и усложняется реализация сервера.
Заголовок AcceptЗаголовок Accept перечисляет MIME типы содержимого ресурса, которые клиент желает получить. Он представляет список MIME типов, разделённый запятыми, каждый из которых, опционально, снабжён коэффициентом желательности – параметром, определяющим относительный уровень желательности среди разных MIME типов.
Accept определяется браузером, или любым другим клиентом, и может изменяться в зависимости от контекста, например, при получении страницы HTML, изображения, видео или скрипта – его содержимое будет различаться при запросе документа из строки адреса, через тег <img>, <video> или <audio>. Браузеры могут использовать любое значение, которые они считают наиболее подходящим; можете ознакомиться со списком значений по умолчанию, используемых распространёнными браузерами.Заголовок Accept-CH 
Экспериментальная возможность

Примечание:
Это экспериментальная технология под названием Подсказки Клиента (Client Hints),, которую поддерживает только Chrome 46 и более поздние версии.

Экспериментальный заголовок Accept-CH перечисляет конфигурацию клиента, которая может быть использована сервером для выбора подходящего ответа. Определённые значения:



Value
Meaning




DPR
Указывает соотношение логических пикселей к физическим на устройстве.


Viewport-Width
Указывает ширину окна отображения.


Width
Указывает ширину ресурса в физических пикселях (другими словами собственный размер изображения).


Заголовок Accept-EncodingThe Accept-Encoding header defines the acceptable content-encoding (supported compressions). The value is a q-factor list (e.g.: br, gzip;q=0.8) that indicates the priority of the encoding values. The default value identity is at the lowest priority (unless otherwise declared).
Compressing HTTP messages is one of the most important ways to improve the performance of a Web site, it shrinks the size of the data transmitted and makes better use of the available bandwidth; browsers always send this header and the server should be configured to abide to it and to use compression.Заголовок Accept-LanguageThe Accept-Language header is used to indicate the language preference of the user. It is a list of values with quality factors (like: "de, en;q=0.7"). A default value is often set according the language of the graphical interface of the user agent, but most browsers allow to set different language preferences.
Due to the configuration-based entropy increase, a modified value can be used to fingerprint the user, it is not recommended to change it and a Web site cannot trust this value to reflect the actual wish of the user. Site designers must not be over-zealous by using language detection via this header as it can lead to a poor user experience:

They should always provide a way to overcome the server-chosen language, e.g., by providing a language menu on the site. Most user-agents provide a default value for the Accept-Language header, adapted to the user interface language and end users often do not modify it, either by not knowing how, or by not being able to do it, as in an Internet café for instance.
Once a user has overridden the server-chosen language, a site should no longer use language detection and should stick with the explicitly-chosen language. In other words, only entry pages of a site should select the proper language using this header.
Заголовок User-Agent
Примечание:
Though there are legitimate uses of this header for selecting content, it is considered bad practice to rely on it to define what features are supported by the user agent.

The User-Agent header identifies the browser sending the request. This string may contain a space-separated list of product tokens and comments.
A product token is a name followed by a '/' and a version number, like Firefox/4.0.1. There may be as many of them as the user-agent wants. A comment is a free string delimited by parentheses. Obviously parentheses cannot be used in that string. The inner format of a comment is not defined by the standard, though several browser put several tokens in it, separated by ';'.The Vary response headerIn opposition to the previous Accept-* headers which are sent by the client, the Vary HTTP header is sent by the web server in its response. It indicates the list of headers used by the server during the server-driven content negotiation phase. The header is needed in order to inform the cache of the decision criteria so that can reproduce it, allowing the cache to be functional while preventing serving erroneous content to the user.
The special value of '*' means that the server-driven content negotiation also uses information not conveyed in a header to choose the appropriate content.
The Vary header was added in the version 1.1 of HTTP and is necessary in order to allow caches to work appropriately. A cache, in order to work with agent-driven content negotiation, needs to know which criteria was used by the server to select the transmitted content. That way, the cache can replay the algorithm and will be able to serve acceptable content directly, without more request to the server. Obviously, the wildcard '*' prevents caching from occurring, as the cache cannot know what element is behind it.Согласование на основе агентаServer-driven negotiation suffers from a few downsides: it doesn't scale well. There is one header per feature used in the negotiation. If you want to use screen size, resolution or other dimensions, a new HTTP header must be created. Sending of the headers must be done on every request. This is not too problematic with few headers, but with the eventual multiplications of them, the message size would lead to a decrease in performance. The more precise headers are sent, the more entropy is sent, allowing for more HTTP fingerprinting and corresponding privacy concern.
From the beginnings of HTTP, the protocol allowed another negotiation type: agent-driven negotiation or reactive negotiation. In this negotiation, when facing an ambiguous request, the server sends back a page containing links to the available alternative resources. The user is presented the resources and choose the one to use.

Unfortunately, the HTTP standard does not specify the format of the page allowing to choose between the available resource, which prevents to easily automatize the process. Besides falling back to the server-driven negotiation, this method is almost always used in conjunction with scripting, especially with JavaScript redirection: after having checked for the negotiation criteria, the script performs the redirection. A second problem is that one more request is needed in order to fetch the real resource, slowing the availability of the resource to the user.\n\nСогласование контентаВ HTTP, согласование контента - это механизм используемый для отображения различных представлений ресурса по тому же URI, так чтобы клиент мог указать, что лучше подходит для пользователя (например, желаемый язык документа, формат изображения, или кодировку текста).Принципы согласования контентаКонкретный документ называется ресурсом. Когда клиент хочет его получить, он запрашивает его используя его URL. Сервер использует этот URL, чтобы выбрать один из возможных вариантов - каждый вариант, называется представлением, – и возвращает этот вариант клиенту. Ресурс в общем, а также каждое из представлений, имеют определённый URL. Выбор конкретного представления при вызове ресурса определяется механизмом согласования контента и существует несколько способов согласования между клиентом и сервером.

Определение наиболее подходящего представления производится с помощью одного из двух механизмов:

Конкретные HTTP-заголовки клиента (согласование на основе сервера или упреждающее согласование), что является стандартным способом согласования определённого вида ресурса.
HTTP коды ответа 300 (Multiple Choices) или 406 (Not Acceptable) (согласование на основе агента или реактивное согласование), используемые в качестве резервных механизмов.

На протяжении многих лет предлагались и другие предложения по согласованию содержания, такие как прозрачное согласование контента и Alternates заголовок. Они не смогли получить достаточной поддержки и были заброшены.Согласование на основе сервераВ согласовании на стороне сервера или упреждающем согласовании, браузер (или любое другое клиентское приложение) посылает несколько заголовков HTTP наряду с URL. Эти заголовки описывают предпочтения пользователя. Сервер использует их в качестве подсказок для внутреннего алгоритма, который выбирает наиболее подходящее представление ресурса, чтобы предоставить его клиенту. Реализация алгоритма в стандарт не входит и полностью зависит от сервера. Для примера, смотрите алгоритм согласования Apache 2.2.

Стандарт HTTP/1.1 определяет список стандартных заголовков которые используются в этом механизме согласования – (Accept, Accept-Encoding, Accept-Language). Хотя, строго говоря, User-Agent не находится в этом списке, в некоторых случаях он используется, чтобы послать определённое представление запрошенного ресурса, несмотря на то, что это и не является хорошей практикой. Сервер использует заголовок Vary чтобы обозначить, какие заголовки он использовал для согласования (точнее, ассоциированные с ними заголовки ответа), чтобы кеширование работало оптимально.
В дополнение к этим, есть предложение добавить больше заголовков в список доступным, так называемые Подсказки Клиента (Client Hints). Они будут предоставлять информацию о типе устройства на котором они используются (например, будет это настольный компьютер или мобильное устройство).
Согласование на стороне сервера является самым популярным способом согласования контента, но у него есть несколько недостатков:

У сервера нет всей информации о клиентском приложении. Даже с расширением Client Hints сервер не может знать всех возможностей браузера. В отличие от реактивного согласования, где клиент совершает выбор, выбор сервера всегда остаётся в каком-то смысле произвольным.
Информация, полученная от клиента, довольно подробная (сжатие заголовков протокола HTTP/2 отчасти решает эту проблему) и является источником утечки конфиденциальности (идентификация по HTTP).
С увеличением количества представлений падает эффективность общих кешей и усложняется реализация сервера.
Заголовок AcceptЗаголовок Accept перечисляет MIME типы содержимого ресурса, которые клиент желает получить. Он представляет список MIME типов, разделённый запятыми, каждый из которых, опционально, снабжён коэффициентом желательности – параметром, определяющим относительный уровень желательности среди разных MIME типов.
Accept определяется браузером, или любым другим клиентом, и может изменяться в зависимости от контекста, например, при получении страницы HTML, изображения, видео или скрипта – его содержимое будет различаться при запросе документа из строки адреса, через тег <img>, <video> или <audio>. Браузеры могут использовать любое значение, которые они считают наиболее подходящим; можете ознакомиться со списком значений по умолчанию, используемых распространёнными браузерами.Заголовок Accept-CH 
Экспериментальная возможность

Примечание:
Это экспериментальная технология под названием Подсказки Клиента (Client Hints),, которую поддерживает только Chrome 46 и более поздние версии.

Экспериментальный заголовок Accept-CH перечисляет конфигурацию клиента, которая может быть использована сервером для выбора подходящего ответа. Определённые значения:



Value
Meaning




DPR
Указывает соотношение логических пикселей к физическим на устройстве.


Viewport-Width
Указывает ширину окна отображения.


Width
Указывает ширину ресурса в физических пикселях (другими словами собственный размер изображения).


Заголовок Accept-EncodingThe Accept-Encoding header defines the acceptable content-encoding (supported compressions). The value is a q-factor list (e.g.: br, gzip;q=0.8) that indicates the priority of the encoding values. The default value identity is at the lowest priority (unless otherwise declared).
Compressing HTTP messages is one of the most important ways to improve the performance of a Web site, it shrinks the size of the data transmitted and makes better use of the available bandwidth; browsers always send this header and the server should be configured to abide to it and to use compression.Заголовок Accept-LanguageThe Accept-Language header is used to indicate the language preference of the user. It is a list of values with quality factors (like: "de, en;q=0.7"). A default value is often set according the language of the graphical interface of the user agent, but most browsers allow to set different language preferences.
Due to the configuration-based entropy increase, a modified value can be used to fingerprint the user, it is not recommended to change it and a Web site cannot trust this value to reflect the actual wish of the user. Site designers must not be over-zealous by using language detection via this header as it can lead to a poor user experience:

They should always provide a way to overcome the server-chosen language, e.g., by providing a language menu on the site. Most user-agents provide a default value for the Accept-Language header, adapted to the user interface language and end users often do not modify it, either by not knowing how, or by not being able to do it, as in an Internet café for instance.
Once a user has overridden the server-chosen language, a site should no longer use language detection and should stick with the explicitly-chosen language. In other words, only entry pages of a site should select the proper language using this header.
Заголовок User-Agent
Примечание:
Though there are legitimate uses of this header for selecting content, it is considered bad practice to rely on it to define what features are supported by the user agent.

The User-Agent header identifies the browser sending the request. This string may contain a space-separated list of product tokens and comments.
A product token is a name followed by a '/' and a version number, like Firefox/4.0.1. There may be as many of them as the user-agent wants. A comment is a free string delimited by parentheses. Obviously parentheses cannot be used in that string. The inner format of a comment is not defined by the standard, though several browser put several tokens in it, separated by ';'.The Vary response headerIn opposition to the previous Accept-* headers which are sent by the client, the Vary HTTP header is sent by the web server in its response. It indicates the list of headers used by the server during the server-driven content negotiation phase. The header is needed in order to inform the cache of the decision criteria so that can reproduce it, allowing the cache to be functional while preventing serving erroneous content to the user.
The special value of '*' means that the server-driven content negotiation also uses information not conveyed in a header to choose the appropriate content.
The Vary header was added in the version 1.1 of HTTP and is necessary in order to allow caches to work appropriately. A cache, in order to work with agent-driven content negotiation, needs to know which criteria was used by the server to select the transmitted content. That way, the cache can replay the algorithm and will be able to serve acceptable content directly, without more request to the server. Obviously, the wildcard '*' prevents caching from occurring, as the cache cannot know what element is behind it.Согласование на основе агентаServer-driven negotiation suffers from a few downsides: it doesn't scale well. There is one header per feature used in the negotiation. If you want to use screen size, resolution or other dimensions, a new HTTP header must be created. Sending of the headers must be done on every request. This is not too problematic with few headers, but with the eventual multiplications of them, the message size would lead to a decrease in performance. The more precise headers are sent, the more entropy is sent, allowing for more HTTP fingerprinting and corresponding privacy concern.
From the beginnings of HTTP, the protocol allowed another negotiation type: agent-driven negotiation or reactive negotiation. In this negotiation, when facing an ambiguous request, the server sends back a page containing links to the available alternative resources. The user is presented the resources and choose the one to use.

Unfortunately, the HTTP standard does not specify the format of the page allowing to choose between the available resource, which prevents to easily automatize the process. Besides falling back to the server-driven negotiation, this method is almost always used in conjunction with scripting, especially with JavaScript redirection: after having checked for the negotiation criteria, the script performs the redirection. A second problem is that one more request is needed in order to fetch the real resource, slowing the availability of the resource to the user.Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on 24 мар. 2025 г. by MDN contributors.View this page on GitHub • Report a problem with this content\n\nСогласование контентаВ HTTP, согласование контента - это механизм используемый для отображения различных представлений ресурса по тому же URI, так чтобы клиент мог указать, что лучше подходит для пользователя (например, желаемый язык документа, формат изображения, или кодировку текста).Принципы согласования контентаКонкретный документ называется ресурсом. Когда клиент хочет его получить, он запрашивает его используя его URL. Сервер использует этот URL, чтобы выбрать один из возможных вариантов - каждый вариант, называется представлением, – и возвращает этот вариант клиенту. Ресурс в общем, а также каждое из представлений, имеют определённый URL. Выбор конкретного представления при вызове ресурса определяется механизмом согласования контента и существует несколько способов согласования между клиентом и сервером.

Определение наиболее подходящего представления производится с помощью одного из двух механизмов:

Конкретные HTTP-заголовки клиента (согласование на основе сервера или упреждающее согласование), что является стандартным способом согласования определённого вида ресурса.
HTTP коды ответа 300 (Multiple Choices) или 406 (Not Acceptable) (согласование на основе агента или реактивное согласование), используемые в качестве резервных механизмов.

На протяжении многих лет предлагались и другие предложения по согласованию содержания, такие как прозрачное согласование контента и Alternates заголовок. Они не смогли получить достаточной поддержки и были заброшены.Согласование на основе сервераВ согласовании на стороне сервера или упреждающем согласовании, браузер (или любое другое клиентское приложение) посылает несколько заголовков HTTP наряду с URL. Эти заголовки описывают предпочтения пользователя. Сервер использует их в качестве подсказок для внутреннего алгоритма, который выбирает наиболее подходящее представление ресурса, чтобы предоставить его клиенту. Реализация алгоритма в стандарт не входит и полностью зависит от сервера. Для примера, смотрите алгоритм согласования Apache 2.2.

Стандарт HTTP/1.1 определяет список стандартных заголовков которые используются в этом механизме согласования – (Accept, Accept-Encoding, Accept-Language). Хотя, строго говоря, User-Agent не находится в этом списке, в некоторых случаях он используется, чтобы послать определённое представление запрошенного ресурса, несмотря на то, что это и не является хорошей практикой. Сервер использует заголовок Vary чтобы обозначить, какие заголовки он использовал для согласования (точнее, ассоциированные с ними заголовки ответа), чтобы кеширование работало оптимально.
В дополнение к этим, есть предложение добавить больше заголовков в список доступным, так называемые Подсказки Клиента (Client Hints). Они будут предоставлять информацию о типе устройства на котором они используются (например, будет это настольный компьютер или мобильное устройство).
Согласование на стороне сервера является самым популярным способом согласования контента, но у него есть несколько недостатков:

У сервера нет всей информации о клиентском приложении. Даже с расширением Client Hints сервер не может знать всех возможностей браузера. В отличие от реактивного согласования, где клиент совершает выбор, выбор сервера всегда остаётся в каком-то смысле произвольным.
Информация, полученная от клиента, довольно подробная (сжатие заголовков протокола HTTP/2 отчасти решает эту проблему) и является источником утечки конфиденциальности (идентификация по HTTP).
С увеличением количества представлений падает эффективность общих кешей и усложняется реализация сервера.
Заголовок AcceptЗаголовок Accept перечисляет MIME типы содержимого ресурса, которые клиент желает получить. Он представляет список MIME типов, разделённый запятыми, каждый из которых, опционально, снабжён коэффициентом желательности – параметром, определяющим относительный уровень желательности среди разных MIME типов.
Accept определяется браузером, или любым другим клиентом, и может изменяться в зависимости от контекста, например, при получении страницы HTML, изображения, видео или скрипта – его содержимое будет различаться при запросе документа из строки адреса, через тег <img>, <video> или <audio>. Браузеры могут использовать любое значение, которые они считают наиболее подходящим; можете ознакомиться со списком значений по умолчанию, используемых распространёнными браузерами.Заголовок Accept-CH 
Экспериментальная возможность

Примечание:
Это экспериментальная технология под названием Подсказки Клиента (Client Hints),, которую поддерживает только Chrome 46 и более поздние версии.

Экспериментальный заголовок Accept-CH перечисляет конфигурацию клиента, которая может быть использована сервером для выбора подходящего ответа. Определённые значения:



Value
Meaning




DPR
Указывает соотношение логических пикселей к физическим на устройстве.


Viewport-Width
Указывает ширину окна отображения.


Width
Указывает ширину ресурса в физических пикселях (другими словами собственный размер изображения).


Заголовок Accept-EncodingThe Accept-Encoding header defines the acceptable content-encoding (supported compressions). The value is a q-factor list (e.g.: br, gzip;q=0.8) that indicates the priority of the encoding values. The default value identity is at the lowest priority (unless otherwise declared).
Compressing HTTP messages is one of the most important ways to improve the performance of a Web site, it shrinks the size of the data transmitted and makes better use of the available bandwidth; browsers always send this header and the server should be configured to abide to it and to use compression.Заголовок Accept-LanguageThe Accept-Language header is used to indicate the language preference of the user. It is a list of values with quality factors (like: "de, en;q=0.7"). A default value is often set according the language of the graphical interface of the user agent, but most browsers allow to set different language preferences.
Due to the configuration-based entropy increase, a modified value can be used to fingerprint the user, it is not recommended to change it and a Web site cannot trust this value to reflect the actual wish of the user. Site designers must not be over-zealous by using language detection via this header as it can lead to a poor user experience:

They should always provide a way to overcome the server-chosen language, e.g., by providing a language menu on the site. Most user-agents provide a default value for the Accept-Language header, adapted to the user interface language and end users often do not modify it, either by not knowing how, or by not being able to do it, as in an Internet café for instance.
Once a user has overridden the server-chosen language, a site should no longer use language detection and should stick with the explicitly-chosen language. In other words, only entry pages of a site should select the proper language using this header.
Заголовок User-Agent
Примечание:
Though there are legitimate uses of this header for selecting content, it is considered bad practice to rely on it to define what features are supported by the user agent.

The User-Agent header identifies the browser sending the request. This string may contain a space-separated list of product tokens and comments.
A product token is a name followed by a '/' and a version number, like Firefox/4.0.1. There may be as many of them as the user-agent wants. A comment is a free string delimited by parentheses. Obviously parentheses cannot be used in that string. The inner format of a comment is not defined by the standard, though several browser put several tokens in it, separated by ';'.The Vary response headerIn opposition to the previous Accept-* headers which are sent by the client, the Vary HTTP header is sent by the web server in its response. It indicates the list of headers used by the server during the server-driven content negotiation phase. The header is needed in order to inform the cache of the decision criteria so that can reproduce it, allowing the cache to be functional while preventing serving erroneous content to the user.
The special value of '*' means that the server-driven content negotiation also uses information not conveyed in a header to choose the appropriate content.
The Vary header was added in the version 1.1 of HTTP and is necessary in order to allow caches to work appropriately. A cache, in order to work with agent-driven content negotiation, needs to know which criteria was used by the server to select the transmitted content. That way, the cache can replay the algorithm and will be able to serve acceptable content directly, without more request to the server. Obviously, the wildcard '*' prevents caching from occurring, as the cache cannot know what element is behind it.Согласование на основе агентаServer-driven negotiation suffers from a few downsides: it doesn't scale well. There is one header per feature used in the negotiation. If you want to use screen size, resolution or other dimensions, a new HTTP header must be created. Sending of the headers must be done on every request. This is not too problematic with few headers, but with the eventual multiplications of them, the message size would lead to a decrease in performance. The more precise headers are sent, the more entropy is sent, allowing for more HTTP fingerprinting and corresponding privacy concern.
From the beginnings of HTTP, the protocol allowed another negotiation type: agent-driven negotiation or reactive negotiation. In this negotiation, when facing an ambiguous request, the server sends back a page containing links to the available alternative resources. The user is presented the resources and choose the one to use.

Unfortunately, the HTTP standard does not specify the format of the page allowing to choose between the available resource, which prevents to easily automatize the process. Besides falling back to the server-driven negotiation, this method is almost always used in conjunction with scripting, especially with JavaScript redirection: after having checked for the negotiation criteria, the script performs the redirection. A second problem is that one more request is needed in order to fetch the real resource, slowing the availability of the resource to the user.Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on 24 мар. 2025 г. by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\n内容协商在 HTTP 协议中，**内容协商**是一种机制，用于为同一 URI 提供资源不同的表示形式，以帮助用户代理指定最适合用户的表示形式（例如，哪种文档语言、哪种图片格式或者哪种内容编码）。

备注：
你可以在来自 WHATWG 的维基页面发现 HTTP 内容协商的一些缺点。HTML5 提供其他的选择来进行内容协商，例如 <source> 元素。
内容协商的基本原则一份特定的文件被称为一项资源。当客户端获取资源的时候，会使用其对应的 URL 发送请求。服务器通过这个 URL 来选择它指向的资源的某一可用的变体——每一个变体称为一种表示形式——然后将这个选定的表示形式返回给客户端。整个资源，以及它的各种表示形式，共享一个特定的 URL。当访问某项资源的时候，内容协商会决定如何选择一种指定的表示形式。客户端和服务器端之间存在多种协商方式。

最佳表示形式的选取可以通过两种机制实现：

客户端设置特定的 HTTP 标头（又称为服务端驱动型内容协商或者主动内容协商），这是进行内容协商的标准方式。
服务器返回 300（Multiple Choices）或者 406（Not Acceptable）、415（Unsupported Media Type）HTTP 响应状态码 （又称为代理驱动型协商或者响应式协商），这种方式一般用作备选方案。

随着时间的推移，也有其他一些内容协商的提案被提出来，比如透明内容协商以及 Alternates 标头。但是它们都没有获得人们的认可从而被遗弃。服务端驱动型内容协商机制在服务端驱动型内容协商或者主动内容协商中，浏览器（或者其他任何类型的用户代理）会随同 URL 发送一系列的 HTTP 标头。这些标头描述了用户倾向的选择。服务器则以此为线索，通过内部算法来选择最佳方案提供给客户端。如果它不能提供一个合适的资源，它可能使用 406（Not Acceptable）、415（Unsupported Media Type）进行响应并为其支持的媒体类型设置标头（例如，分别对 POST 和 PATCH 请求使用 Accept-Post 或 Accept-Patch 标头）。相关算法与具体的服务器相关，并没有在规范中进行规定。例如这里有一份 Apache 服务器的内容协商算法。

HTTP/1.1 规范指定了一系列的标准标头用于启动服务端驱动型内容协商（Accept、Accept-Encoding、Accept-Language）。尽管严格来说 User-Agent 并不在此列，有时候它还是会被用来确定给客户端发送的所请求资源的特定表示形式，不过这种做法不提倡使用。服务器会使用 Vary 标头来说明实际上哪些标头被用作内容协商的参考依据（确切来说是与之相关的响应标头），这样可以使缓存的运作更有效。
除此之外，有一个向可供选择的列表中增加更多标头的实验性提案，称为客户端提示（Client Hint）。客户端示意机制可以告知运行用户代理的设备类型（例如，是桌面计算机还是移动设备）。
即便服务端驱动型内容协商机制是最常用的对资源特定表示形式进行协商的方式，它也存在如下几个缺点：

服务器对浏览器并非全知全能。即便是有了客户端示意扩展，也依然无法获取关于浏览器能力的全部信息。与客户端进行选择的代理驱动型内容协商机制不同，服务器端的选择总是显得有点武断。
客户端提供的信息相当冗长（HTTP/2 协议的标头压缩机制缓解了这个问题），并且存在隐私风险（HTTP 指纹识别技术）。
因为给定的资源需要返回不同的表示形式，共享缓存的效率会降低，而服务器端的实现会越来越复杂。
Accept 标头Accept 标头列举了用户代理希望接收的媒体资源的 MIME 类型。其中不同的 MIME 类型之间用逗号分隔，同时每一种 MIME 类型会配有一个品质因数（quality factor），该参数明确了不同 MIME 类型之间的相对优先级。
Accept 标头的值由浏览器或其他类型的用户代理确定，并且会由于上下文环境的不同而不同。比如在获取 HTML 页面、图片文件、视频文件或者是脚本文件的时候，无论是通过在地址栏中输入资源地址来获取还是通过 <img>、<video> 或 <audio> 元素引用都是不一样的。浏览器可以自由使用它们认为最为合适的标头值；这里有一份常见浏览器 Accept 标头默认值的完整列表。Accept-CH 标头
实验性

备注：
这是被称为客户端提示的实验性技术方案的一部分，目前仅在 Chrome 46 及以后的版本中得到了实现。Device-Memory 值在 Chrome 61 或更高版本中。

该实验性标头 Accept-CH 列出了服务器可以用来选择合适响应的配置数据。合法值如下：



值
含义




Device-Memory
标明客户端设备的内存大小。该值是个估计值，设备的实际内存值会向 2 的次方取整，且除以 1024。比如 512MB 的内存对应的值为 0.5。


Viewport-Width
标明用 CSS 像素数值表示的布局视口（layout viewport）宽度。


Width
标明用物理像素值表示的资源宽度（换句话说就是一张图片的固有大小）。


Accept-Encoding 标头Accept-Encoding 标头明确说明了（接收端）可以接受的内容编码形式（所支持的压缩算法）。该标头的值是一个 Q 因子清单（例如 br, gzip;q=0.8），用来提示不同编码类型值的优先级顺序。默认值 identity 的优先级最低（除非声明为其他优先级）。
将 HTTP 消息进行压缩是一种最重要的提升 Web 站点性能的方法。该方法会减小所要传输的数据量的大小，节省可用带宽。浏览器总是会发送该标头，服务器则应该配置为接受它，并且采用一定的压缩方案。Accept-Language 标头Accept-Language 标头用来提示用户期望获得的自然语言的优先顺序。该标头的值是一个 Q 因子清单（例如 de, en;q=0.7）。用户代理的图形界面上所采用的语言通常可以用来设置为默认值，但是大多数浏览器允许设置不同优先级的语言选项。
由于基于配置信息的信息熵的增加，修改后的值可以用作识别用户的指纹，所以不建议对其进行修改，不过这样的话 Web 站点也就不能依赖该值来揭示用户的真实期望。站点设计者不能过度热衷于通过这个标头来进行语言检测，因为它可能会导致糟糕的用户体验：

站点设计者应该总是提供一种方式来使用户能够覆盖由服务器端选择的语言，例如在页面上提供一个用于语言选择的按钮。大多数用户代理会为 Accept-Language 标头提供一个默认值，该值采用的是用户界面的显示的语言。通常终端用户不能对其进行修改，或者是不知道该怎么修改，或者在他们计算机的环境中无法进行修改。
一旦用户覆盖了服务器端选择的语言选项，站点就不应该再使用语言检测技术，而应该忠于明确选择的语言选项。换句话说，只有站点的入口页面应该使用这个标头来选择合适的语言。
User-Agent 标头
备注：
尽管使用该标头来进行内容选择是合理的，但是依赖这个标头来确定用户代理都支持哪些功能特性通常被认为是一个糟糕的做法。

User-Agent 标头可以用来识别发送请求的浏览器。该字符串中包含有用空格间隔的产品标记符及注释的清单。
产品标记符由产品名称、后面紧跟的“/”以及产品版本号构成，例如 Firefox/4.0.1。用户代理可以随意添加多少产品标记符都可以。注释是一个用括号分隔的自由形式的字符串。显然括号本身不能用在该字符串中。规范没有规定注释的内部格式，不过一些浏览器会把一些标记符放置在里面，不同的标记符之间使用“;”分隔。Vary 响应标头与前面列举的 Accept-* 形式的由客户端发送的标头相反，Vary 标头是由服务器在响应中发送的。它指示了服务器在服务端驱动型内容协商阶段所使用的标头清单。Vary 标头是必要的，它用于将决策的规范告知缓存，这样它就可以进行复现。这将使缓存发挥它的作用，同时确保缓存可以向用户提供正确的内容。
特殊值“*”意味着在服务端驱动型内容协商过程中同时采纳了未在标头中传递的信息来选择合适的内容。
Vary 标头是在 HTTP 协议的 1.1 版本中新添加的，它是为了使缓存恰当地工作。缓存为了能够与服务端驱动型内容协商机制协同工作，需要知道服务器选择传送内容的规范。这样的话，缓存服务器就可以重复该算法，直接提供恰当的内容，而不需要向服务器发送更多的请求。显然，通配符“*”阻碍了缓存机制发挥作用，因为缓存并不知道该通配符究竟指代哪些元素。有关更多信息，请参见 HTTP 缓存 > Vary 响应。代理驱动型内容协商机制服务端驱动型内容协商也有一些缺点：它不能很好的扩展。在协商机制中，每一个特性需要对应一个标头。如果想要使用屏幕大小、分辨率或者其他方面的特性，就需要创建一个新的 HTTP 标头。而且在每一次请求中都必须发送这些标头。在标头很少的时候，这并不是问题，但是随着数量的增多，消息的体积会导致性能的下降。带有精确信息的标头发送的越多，信息熵就会越大，也就准许了更多 HTTP 指纹识别行为，以及与此相关的隐私问题的发生。
从 HTTP 协议制定之初，该协议就准许另外一种协商机制：代理驱动型内容协商，或称为响应式协商。在这种协商机制中，当面临不明确的请求时，服务器会返回一个页面，其中包含了可供选择的资源的链接。资源呈现给用户，由用户做出选择。

不幸的是，HTTP 标准没有明确指定提供可选资源链接的页面的格式，这阻碍了该过程的无痛自动化。除了退回至服务端驱动型内容协商外，这种自动化方法几乎无一例外都是通过脚本技术来完成的，尤其是 JavaScript 重定向技术：在检测了协商的条件之后，脚本会触发重定向动作。另外一个问题是，为了获得实际的资源，需要额外发送一次请求，减慢了将资源呈现给用户的速度。\n\n内容协商在 HTTP 协议中，**内容协商**是一种机制，用于为同一 URI 提供资源不同的表示形式，以帮助用户代理指定最适合用户的表示形式（例如，哪种文档语言、哪种图片格式或者哪种内容编码）。

备注：
你可以在来自 WHATWG 的维基页面发现 HTTP 内容协商的一些缺点。HTML5 提供其他的选择来进行内容协商，例如 <source> 元素。
内容协商的基本原则一份特定的文件被称为一项资源。当客户端获取资源的时候，会使用其对应的 URL 发送请求。服务器通过这个 URL 来选择它指向的资源的某一可用的变体——每一个变体称为一种表示形式——然后将这个选定的表示形式返回给客户端。整个资源，以及它的各种表示形式，共享一个特定的 URL。当访问某项资源的时候，内容协商会决定如何选择一种指定的表示形式。客户端和服务器端之间存在多种协商方式。

最佳表示形式的选取可以通过两种机制实现：

客户端设置特定的 HTTP 标头（又称为服务端驱动型内容协商或者主动内容协商），这是进行内容协商的标准方式。
服务器返回 300（Multiple Choices）或者 406（Not Acceptable）、415（Unsupported Media Type）HTTP 响应状态码 （又称为代理驱动型协商或者响应式协商），这种方式一般用作备选方案。

随着时间的推移，也有其他一些内容协商的提案被提出来，比如透明内容协商以及 Alternates 标头。但是它们都没有获得人们的认可从而被遗弃。服务端驱动型内容协商机制在服务端驱动型内容协商或者主动内容协商中，浏览器（或者其他任何类型的用户代理）会随同 URL 发送一系列的 HTTP 标头。这些标头描述了用户倾向的选择。服务器则以此为线索，通过内部算法来选择最佳方案提供给客户端。如果它不能提供一个合适的资源，它可能使用 406（Not Acceptable）、415（Unsupported Media Type）进行响应并为其支持的媒体类型设置标头（例如，分别对 POST 和 PATCH 请求使用 Accept-Post 或 Accept-Patch 标头）。相关算法与具体的服务器相关，并没有在规范中进行规定。例如这里有一份 Apache 服务器的内容协商算法。

HTTP/1.1 规范指定了一系列的标准标头用于启动服务端驱动型内容协商（Accept、Accept-Encoding、Accept-Language）。尽管严格来说 User-Agent 并不在此列，有时候它还是会被用来确定给客户端发送的所请求资源的特定表示形式，不过这种做法不提倡使用。服务器会使用 Vary 标头来说明实际上哪些标头被用作内容协商的参考依据（确切来说是与之相关的响应标头），这样可以使缓存的运作更有效。
除此之外，有一个向可供选择的列表中增加更多标头的实验性提案，称为客户端提示（Client Hint）。客户端示意机制可以告知运行用户代理的设备类型（例如，是桌面计算机还是移动设备）。
即便服务端驱动型内容协商机制是最常用的对资源特定表示形式进行协商的方式，它也存在如下几个缺点：

服务器对浏览器并非全知全能。即便是有了客户端示意扩展，也依然无法获取关于浏览器能力的全部信息。与客户端进行选择的代理驱动型内容协商机制不同，服务器端的选择总是显得有点武断。
客户端提供的信息相当冗长（HTTP/2 协议的标头压缩机制缓解了这个问题），并且存在隐私风险（HTTP 指纹识别技术）。
因为给定的资源需要返回不同的表示形式，共享缓存的效率会降低，而服务器端的实现会越来越复杂。
Accept 标头Accept 标头列举了用户代理希望接收的媒体资源的 MIME 类型。其中不同的 MIME 类型之间用逗号分隔，同时每一种 MIME 类型会配有一个品质因数（quality factor），该参数明确了不同 MIME 类型之间的相对优先级。
Accept 标头的值由浏览器或其他类型的用户代理确定，并且会由于上下文环境的不同而不同。比如在获取 HTML 页面、图片文件、视频文件或者是脚本文件的时候，无论是通过在地址栏中输入资源地址来获取还是通过 <img>、<video> 或 <audio> 元素引用都是不一样的。浏览器可以自由使用它们认为最为合适的标头值；这里有一份常见浏览器 Accept 标头默认值的完整列表。Accept-CH 标头
实验性

备注：
这是被称为客户端提示的实验性技术方案的一部分，目前仅在 Chrome 46 及以后的版本中得到了实现。Device-Memory 值在 Chrome 61 或更高版本中。

该实验性标头 Accept-CH 列出了服务器可以用来选择合适响应的配置数据。合法值如下：



值
含义




Device-Memory
标明客户端设备的内存大小。该值是个估计值，设备的实际内存值会向 2 的次方取整，且除以 1024。比如 512MB 的内存对应的值为 0.5。


Viewport-Width
标明用 CSS 像素数值表示的布局视口（layout viewport）宽度。


Width
标明用物理像素值表示的资源宽度（换句话说就是一张图片的固有大小）。


Accept-Encoding 标头Accept-Encoding 标头明确说明了（接收端）可以接受的内容编码形式（所支持的压缩算法）。该标头的值是一个 Q 因子清单（例如 br, gzip;q=0.8），用来提示不同编码类型值的优先级顺序。默认值 identity 的优先级最低（除非声明为其他优先级）。
将 HTTP 消息进行压缩是一种最重要的提升 Web 站点性能的方法。该方法会减小所要传输的数据量的大小，节省可用带宽。浏览器总是会发送该标头，服务器则应该配置为接受它，并且采用一定的压缩方案。Accept-Language 标头Accept-Language 标头用来提示用户期望获得的自然语言的优先顺序。该标头的值是一个 Q 因子清单（例如 de, en;q=0.7）。用户代理的图形界面上所采用的语言通常可以用来设置为默认值，但是大多数浏览器允许设置不同优先级的语言选项。
由于基于配置信息的信息熵的增加，修改后的值可以用作识别用户的指纹，所以不建议对其进行修改，不过这样的话 Web 站点也就不能依赖该值来揭示用户的真实期望。站点设计者不能过度热衷于通过这个标头来进行语言检测，因为它可能会导致糟糕的用户体验：

站点设计者应该总是提供一种方式来使用户能够覆盖由服务器端选择的语言，例如在页面上提供一个用于语言选择的按钮。大多数用户代理会为 Accept-Language 标头提供一个默认值，该值采用的是用户界面的显示的语言。通常终端用户不能对其进行修改，或者是不知道该怎么修改，或者在他们计算机的环境中无法进行修改。
一旦用户覆盖了服务器端选择的语言选项，站点就不应该再使用语言检测技术，而应该忠于明确选择的语言选项。换句话说，只有站点的入口页面应该使用这个标头来选择合适的语言。
User-Agent 标头
备注：
尽管使用该标头来进行内容选择是合理的，但是依赖这个标头来确定用户代理都支持哪些功能特性通常被认为是一个糟糕的做法。

User-Agent 标头可以用来识别发送请求的浏览器。该字符串中包含有用空格间隔的产品标记符及注释的清单。
产品标记符由产品名称、后面紧跟的“/”以及产品版本号构成，例如 Firefox/4.0.1。用户代理可以随意添加多少产品标记符都可以。注释是一个用括号分隔的自由形式的字符串。显然括号本身不能用在该字符串中。规范没有规定注释的内部格式，不过一些浏览器会把一些标记符放置在里面，不同的标记符之间使用“;”分隔。Vary 响应标头与前面列举的 Accept-* 形式的由客户端发送的标头相反，Vary 标头是由服务器在响应中发送的。它指示了服务器在服务端驱动型内容协商阶段所使用的标头清单。Vary 标头是必要的，它用于将决策的规范告知缓存，这样它就可以进行复现。这将使缓存发挥它的作用，同时确保缓存可以向用户提供正确的内容。
特殊值“*”意味着在服务端驱动型内容协商过程中同时采纳了未在标头中传递的信息来选择合适的内容。
Vary 标头是在 HTTP 协议的 1.1 版本中新添加的，它是为了使缓存恰当地工作。缓存为了能够与服务端驱动型内容协商机制协同工作，需要知道服务器选择传送内容的规范。这样的话，缓存服务器就可以重复该算法，直接提供恰当的内容，而不需要向服务器发送更多的请求。显然，通配符“*”阻碍了缓存机制发挥作用，因为缓存并不知道该通配符究竟指代哪些元素。有关更多信息，请参见 HTTP 缓存 > Vary 响应。代理驱动型内容协商机制服务端驱动型内容协商也有一些缺点：它不能很好的扩展。在协商机制中，每一个特性需要对应一个标头。如果想要使用屏幕大小、分辨率或者其他方面的特性，就需要创建一个新的 HTTP 标头。而且在每一次请求中都必须发送这些标头。在标头很少的时候，这并不是问题，但是随着数量的增多，消息的体积会导致性能的下降。带有精确信息的标头发送的越多，信息熵就会越大，也就准许了更多 HTTP 指纹识别行为，以及与此相关的隐私问题的发生。
从 HTTP 协议制定之初，该协议就准许另外一种协商机制：代理驱动型内容协商，或称为响应式协商。在这种协商机制中，当面临不明确的请求时，服务器会返回一个页面，其中包含了可供选择的资源的链接。资源呈现给用户，由用户做出选择。

不幸的是，HTTP 标准没有明确指定提供可选资源链接的页面的格式，这阻碍了该过程的无痛自动化。除了退回至服务端驱动型内容协商外，这种自动化方法几乎无一例外都是通过脚本技术来完成的，尤其是 JavaScript 重定向技术：在检测了协商的条件之后，脚本会触发重定向动作。另外一个问题是，为了获得实际的资源，需要额外发送一次请求，减慢了将资源呈现给用户的速度。Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on 2025年4月13日 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n内容协商在 HTTP 协议中，**内容协商**是一种机制，用于为同一 URI 提供资源不同的表示形式，以帮助用户代理指定最适合用户的表示形式（例如，哪种文档语言、哪种图片格式或者哪种内容编码）。

备注：
你可以在来自 WHATWG 的维基页面发现 HTTP 内容协商的一些缺点。HTML5 提供其他的选择来进行内容协商，例如 <source> 元素。
内容协商的基本原则一份特定的文件被称为一项资源。当客户端获取资源的时候，会使用其对应的 URL 发送请求。服务器通过这个 URL 来选择它指向的资源的某一可用的变体——每一个变体称为一种表示形式——然后将这个选定的表示形式返回给客户端。整个资源，以及它的各种表示形式，共享一个特定的 URL。当访问某项资源的时候，内容协商会决定如何选择一种指定的表示形式。客户端和服务器端之间存在多种协商方式。

最佳表示形式的选取可以通过两种机制实现：

客户端设置特定的 HTTP 标头（又称为服务端驱动型内容协商或者主动内容协商），这是进行内容协商的标准方式。
服务器返回 300（Multiple Choices）或者 406（Not Acceptable）、415（Unsupported Media Type）HTTP 响应状态码 （又称为代理驱动型协商或者响应式协商），这种方式一般用作备选方案。

随着时间的推移，也有其他一些内容协商的提案被提出来，比如透明内容协商以及 Alternates 标头。但是它们都没有获得人们的认可从而被遗弃。服务端驱动型内容协商机制在服务端驱动型内容协商或者主动内容协商中，浏览器（或者其他任何类型的用户代理）会随同 URL 发送一系列的 HTTP 标头。这些标头描述了用户倾向的选择。服务器则以此为线索，通过内部算法来选择最佳方案提供给客户端。如果它不能提供一个合适的资源，它可能使用 406（Not Acceptable）、415（Unsupported Media Type）进行响应并为其支持的媒体类型设置标头（例如，分别对 POST 和 PATCH 请求使用 Accept-Post 或 Accept-Patch 标头）。相关算法与具体的服务器相关，并没有在规范中进行规定。例如这里有一份 Apache 服务器的内容协商算法。

HTTP/1.1 规范指定了一系列的标准标头用于启动服务端驱动型内容协商（Accept、Accept-Encoding、Accept-Language）。尽管严格来说 User-Agent 并不在此列，有时候它还是会被用来确定给客户端发送的所请求资源的特定表示形式，不过这种做法不提倡使用。服务器会使用 Vary 标头来说明实际上哪些标头被用作内容协商的参考依据（确切来说是与之相关的响应标头），这样可以使缓存的运作更有效。
除此之外，有一个向可供选择的列表中增加更多标头的实验性提案，称为客户端提示（Client Hint）。客户端示意机制可以告知运行用户代理的设备类型（例如，是桌面计算机还是移动设备）。
即便服务端驱动型内容协商机制是最常用的对资源特定表示形式进行协商的方式，它也存在如下几个缺点：

服务器对浏览器并非全知全能。即便是有了客户端示意扩展，也依然无法获取关于浏览器能力的全部信息。与客户端进行选择的代理驱动型内容协商机制不同，服务器端的选择总是显得有点武断。
客户端提供的信息相当冗长（HTTP/2 协议的标头压缩机制缓解了这个问题），并且存在隐私风险（HTTP 指纹识别技术）。
因为给定的资源需要返回不同的表示形式，共享缓存的效率会降低，而服务器端的实现会越来越复杂。
Accept 标头Accept 标头列举了用户代理希望接收的媒体资源的 MIME 类型。其中不同的 MIME 类型之间用逗号分隔，同时每一种 MIME 类型会配有一个品质因数（quality factor），该参数明确了不同 MIME 类型之间的相对优先级。
Accept 标头的值由浏览器或其他类型的用户代理确定，并且会由于上下文环境的不同而不同。比如在获取 HTML 页面、图片文件、视频文件或者是脚本文件的时候，无论是通过在地址栏中输入资源地址来获取还是通过 <img>、<video> 或 <audio> 元素引用都是不一样的。浏览器可以自由使用它们认为最为合适的标头值；这里有一份常见浏览器 Accept 标头默认值的完整列表。Accept-CH 标头
实验性

备注：
这是被称为客户端提示的实验性技术方案的一部分，目前仅在 Chrome 46 及以后的版本中得到了实现。Device-Memory 值在 Chrome 61 或更高版本中。

该实验性标头 Accept-CH 列出了服务器可以用来选择合适响应的配置数据。合法值如下：



值
含义




Device-Memory
标明客户端设备的内存大小。该值是个估计值，设备的实际内存值会向 2 的次方取整，且除以 1024。比如 512MB 的内存对应的值为 0.5。


Viewport-Width
标明用 CSS 像素数值表示的布局视口（layout viewport）宽度。


Width
标明用物理像素值表示的资源宽度（换句话说就是一张图片的固有大小）。


Accept-Encoding 标头Accept-Encoding 标头明确说明了（接收端）可以接受的内容编码形式（所支持的压缩算法）。该标头的值是一个 Q 因子清单（例如 br, gzip;q=0.8），用来提示不同编码类型值的优先级顺序。默认值 identity 的优先级最低（除非声明为其他优先级）。
将 HTTP 消息进行压缩是一种最重要的提升 Web 站点性能的方法。该方法会减小所要传输的数据量的大小，节省可用带宽。浏览器总是会发送该标头，服务器则应该配置为接受它，并且采用一定的压缩方案。Accept-Language 标头Accept-Language 标头用来提示用户期望获得的自然语言的优先顺序。该标头的值是一个 Q 因子清单（例如 de, en;q=0.7）。用户代理的图形界面上所采用的语言通常可以用来设置为默认值，但是大多数浏览器允许设置不同优先级的语言选项。
由于基于配置信息的信息熵的增加，修改后的值可以用作识别用户的指纹，所以不建议对其进行修改，不过这样的话 Web 站点也就不能依赖该值来揭示用户的真实期望。站点设计者不能过度热衷于通过这个标头来进行语言检测，因为它可能会导致糟糕的用户体验：

站点设计者应该总是提供一种方式来使用户能够覆盖由服务器端选择的语言，例如在页面上提供一个用于语言选择的按钮。大多数用户代理会为 Accept-Language 标头提供一个默认值，该值采用的是用户界面的显示的语言。通常终端用户不能对其进行修改，或者是不知道该怎么修改，或者在他们计算机的环境中无法进行修改。
一旦用户覆盖了服务器端选择的语言选项，站点就不应该再使用语言检测技术，而应该忠于明确选择的语言选项。换句话说，只有站点的入口页面应该使用这个标头来选择合适的语言。
User-Agent 标头
备注：
尽管使用该标头来进行内容选择是合理的，但是依赖这个标头来确定用户代理都支持哪些功能特性通常被认为是一个糟糕的做法。

User-Agent 标头可以用来识别发送请求的浏览器。该字符串中包含有用空格间隔的产品标记符及注释的清单。
产品标记符由产品名称、后面紧跟的“/”以及产品版本号构成，例如 Firefox/4.0.1。用户代理可以随意添加多少产品标记符都可以。注释是一个用括号分隔的自由形式的字符串。显然括号本身不能用在该字符串中。规范没有规定注释的内部格式，不过一些浏览器会把一些标记符放置在里面，不同的标记符之间使用“;”分隔。Vary 响应标头与前面列举的 Accept-* 形式的由客户端发送的标头相反，Vary 标头是由服务器在响应中发送的。它指示了服务器在服务端驱动型内容协商阶段所使用的标头清单。Vary 标头是必要的，它用于将决策的规范告知缓存，这样它就可以进行复现。这将使缓存发挥它的作用，同时确保缓存可以向用户提供正确的内容。
特殊值“*”意味着在服务端驱动型内容协商过程中同时采纳了未在标头中传递的信息来选择合适的内容。
Vary 标头是在 HTTP 协议的 1.1 版本中新添加的，它是为了使缓存恰当地工作。缓存为了能够与服务端驱动型内容协商机制协同工作，需要知道服务器选择传送内容的规范。这样的话，缓存服务器就可以重复该算法，直接提供恰当的内容，而不需要向服务器发送更多的请求。显然，通配符“*”阻碍了缓存机制发挥作用，因为缓存并不知道该通配符究竟指代哪些元素。有关更多信息，请参见 HTTP 缓存 > Vary 响应。代理驱动型内容协商机制服务端驱动型内容协商也有一些缺点：它不能很好的扩展。在协商机制中，每一个特性需要对应一个标头。如果想要使用屏幕大小、分辨率或者其他方面的特性，就需要创建一个新的 HTTP 标头。而且在每一次请求中都必须发送这些标头。在标头很少的时候，这并不是问题，但是随着数量的增多，消息的体积会导致性能的下降。带有精确信息的标头发送的越多，信息熵就会越大，也就准许了更多 HTTP 指纹识别行为，以及与此相关的隐私问题的发生。
从 HTTP 协议制定之初，该协议就准许另外一种协商机制：代理驱动型内容协商，或称为响应式协商。在这种协商机制中，当面临不明确的请求时，服务器会返回一个页面，其中包含了可供选择的资源的链接。资源呈现给用户，由用户做出选择。

不幸的是，HTTP 标准没有明确指定提供可选资源链接的页面的格式，这阻碍了该过程的无痛自动化。除了退回至服务端驱动型内容协商外，这种自动化方法几乎无一例外都是通过脚本技术来完成的，尤其是 JavaScript 重定向技术：在检测了协商的条件之后，脚本会触发重定向动作。另外一个问题是，为了获得实际的资源，需要额外发送一次请求，减慢了将资源呈现给用户的速度。Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on 2025年4月13日 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nContent negotiationIn HTTP, content negotiation is the mechanism that is used for serving different representations of a resource to the same URI to help the user agent specify which representation is best suited for the user (for example, which document language, which image format, or which content encoding).

Note:
You'll find some disadvantages of HTTP content negotiation in a wiki page from WHATWG. HTML provides alternatives to content negotiation via, for example, the <source> element.
Principles of content negotiationA specific document is called a resource. When a client wants to obtain a resource, the client requests it via a URL. The server uses this URL to choose one of the variants available–each variant is called a representation–and returns a specific representation to the client. The overall resource, as well as each of the representations, has a specific URL. Content negotiation determines how a specific representation is chosen when the resource is called. There are several ways of negotiating between the client and the server.

The best-suited representation is identified through one of two mechanisms:

Specific HTTP headers by the client (server-driven negotiation or proactive negotiation), which is the standard way of negotiating a specific kind of resource.
The 300 (Multiple Choices) or 406 (Not Acceptable), 415 (Unsupported Media Type) HTTP response codes by the server (agent-driven negotiation or reactive negotiation), that are used as fallback mechanisms.

Over the years, other content negotiation proposals, like transparent content negotiation and the Alternates header, have been proposed. They failed to get traction and were abandoned.Server-driven content negotiationIn server-driven content negotiation, or proactive content negotiation, the browser (or any other kind of user agent) sends several HTTP headers along with the URL. These headers describe the user's preferred choice. The server uses them as hints and an internal algorithm chooses the best content to serve to the client. If it can't provide a suitable resource, it might respond with 406 (Not Acceptable) or 415 (Unsupported Media Type) and set headers for the types of media that it does support (e.g., using the Accept-Post or Accept-Patch for POST and PATCH requests, respectively). The algorithm is server-specific and not defined in the standard. See the Apache negotiation algorithm.

The HTTP/1.1 standard defines list of the standard headers that start server-driven negotiation (such as Accept, Accept-Encoding, and Accept-Language). Though User-Agent isn't in this list, it's sometimes also used to send a specific representation of the requested resource. However, this isn't always considered a good practice. The server uses the Vary header to indicate which headers it actually used for content negotiation (or more precisely, the associated request headers), so that caches can work optimally.
In addition to these, there's an experimental proposal to add more headers to the list of available headers, called client hints. Client hints advertise what kind of device the user agent runs on (for example, a desktop computer or a mobile device).
Even if server-driven content negotiation is the most common way to agree on a specific representation of a resource, it has several drawbacks:

The server doesn't have total knowledge of the browser. Even with the Client Hints extension, it doesn't have a complete knowledge of the capabilities of the browser. Unlike reactive content negotiation where the client makes the choice, the server choice is always somewhat arbitrary.
The information from the client is quite verbose (HTTP/2 header compression mitigates this problem) and a privacy risk (HTTP fingerprinting).
As several representations of a given resource are sent, shared caches are less efficient and server implementations are more complex.
The Accept headerThe Accept header lists the MIME types of media resources that the agent is willing to process. This is a comma-separated list of MIME types, each combined with a quality factor, a parameter that indicates the relative degree of preference between the different MIME types.
The Accept header is defined by the browser, or any other user agent, and can vary according to the context. For example, fetching an HTML page or an image, a video, or a script. It's different when fetching a document entered in the address bar or an element linked via an <img>, <video>, or <audio> element. Browsers are free to use the value of the header that they think is the most adequate; an exhaustive list of default values for common browsers is available.The Accept-CH header
Note:
This is part of an experimental technology called Client Hints. Initial support comes in Chrome 46 or later. The Device-Memory value is in Chrome 61 or later.

The experimental Accept-CH lists configuration data that the server can use to select an appropriate response. Valid values are:



Value
Meaning




Device-Memory
Indicates the approximate amount of device RAM. This value is an approximation given by rounding to the nearest power of 2 and dividing that number by 1024. For example, 512 megabytes will be reported as 0.5.


Viewport-Width
Indicates the layout viewport width in CSS pixels.


Width
Indicates the resource width in physical pixels (in other words the intrinsic size of an image).


The Accept-Encoding headerThe Accept-Encoding header defines the acceptable content encoding (supported compressions). The value is a q-factor list (e.g., br, gzip;q=0.8) that indicates the priority of the encoding values. The default value identity is at the lowest priority (unless otherwise noted).
Compressing HTTP messages is one of the most important ways to improve the performance of a website. It shrinks the size of the data transmitted and makes better use of the available bandwidth. Browsers always send this header and the server should be configured to use compression.The Accept-Language headerThe Accept-Language header is used to indicate the language preference of the user. It's a list of values with quality factors (e.g., de, en;q=0.7). A default value is often set according to the language of the graphical interface of the user agent, but most browsers allow different language preferences to be set.
Due to the configuration-based entropy increase, a modified value can be used to fingerprint the user. It's not recommended to change it and a website can't trust this value to reflect the actual intention of the user. It's best for site designers to avoid using language detection via this header as it can lead to a poor user experience.

They should always provide a way to override the server-chosen language, e.g., by providing a language menu on the site. Most user agents provide a default value for the Accept-Language header that's adapted to the user interface language. End users often don't modify it because they either don't know how or aren't able to do so based on their computing environment.
Once a user has overridden the server-chosen language, a site should no longer use language detection and should stick with the explicitly chosen language. In other words, only entry pages for a site should use this header to select the proper language.
The User-Agent header
Note:
Though there are legitimate uses of this header for selecting content, it's considered bad practice to rely on it to define what features are supported by the user agent.

The User-Agent header identifies the browser sending the request. This string may contain a space-separated list of product tokens and comments.
A product token is a name followed by a / and a version number, like Firefox/4.0.1. The user agent can include as many of these as it wants. A comment is an optional string delimited by parentheses. The information provided in a comment isn't standardized, though several browsers add several tokens to it separated by ;.The Vary response headerIn contrast to the previous Accept-* headers, which are sent by the client, the Vary HTTP header is sent by the web server in its response. It indicates the list of headers the server uses during the server-driven content negotiation phase. The Vary header is needed to inform the cache of the decision criteria so that it can reproduce it. This allows the cache to be functional while ensuring that the right content is served to the user.
The special value * means that the server-driven content negotiation also uses information not conveyed in a header to choose the appropriate content.
The Vary header was added in version 1.1 of HTTP and allows caches to work appropriately. To work with server-driven content negotiation, a cache needs to know which criteria the server used to select the transmitted content. That way, the cache can replay the algorithm and will be able to serve acceptable content directly, without more requests to the server. Obviously, the wildcard * prevents caching from occurring, as the cache can't know what element is behind it. For more information, see HTTP caching > Varying responses.Agent-driven negotiationServer-driven negotiation has a few drawbacks: it doesn't scale well. One header per feature is used in the negotiation. If you want to use screen size, resolution, or other dimensions, you need to create a new HTTP header. The headers must then be sent with every request. This isn't an issue if there are only a few headers, but as the number of headers increases, the message size could eventually affect performance. The more precisely headers are sent, the more entropy is sent, allowing for more HTTP fingerprinting and corresponding privacy concerns.
HTTP allows another negotiation type: agent-driven negotiation or reactive negotiation. In this case, the server sends back a page that contains links to the available alternative resources when faced with an ambiguous request. The user is presented the resources and chooses the one to use.

Unfortunately, the HTTP standard doesn't specify the format of the page for choosing between the available resources, which prevents the process from being automated. Besides falling back to the server-driven negotiation, this method is almost always used with scripting, especially with JavaScript redirection: after having checked for the negotiation criteria, the script performs the redirection. A second problem is that one more request is needed to fetch the real resource, slowing the availability of the resource to the user.See also
Caching\n\nContent negotiationIn HTTP, content negotiation is the mechanism that is used for serving different representations of a resource to the same URI to help the user agent specify which representation is best suited for the user (for example, which document language, which image format, or which content encoding).

Note:
You'll find some disadvantages of HTTP content negotiation in a wiki page from WHATWG. HTML provides alternatives to content negotiation via, for example, the <source> element.
Principles of content negotiationA specific document is called a resource. When a client wants to obtain a resource, the client requests it via a URL. The server uses this URL to choose one of the variants available–each variant is called a representation–and returns a specific representation to the client. The overall resource, as well as each of the representations, has a specific URL. Content negotiation determines how a specific representation is chosen when the resource is called. There are several ways of negotiating between the client and the server.

The best-suited representation is identified through one of two mechanisms:

Specific HTTP headers by the client (server-driven negotiation or proactive negotiation), which is the standard way of negotiating a specific kind of resource.
The 300 (Multiple Choices) or 406 (Not Acceptable), 415 (Unsupported Media Type) HTTP response codes by the server (agent-driven negotiation or reactive negotiation), that are used as fallback mechanisms.

Over the years, other content negotiation proposals, like transparent content negotiation and the Alternates header, have been proposed. They failed to get traction and were abandoned.Server-driven content negotiationIn server-driven content negotiation, or proactive content negotiation, the browser (or any other kind of user agent) sends several HTTP headers along with the URL. These headers describe the user's preferred choice. The server uses them as hints and an internal algorithm chooses the best content to serve to the client. If it can't provide a suitable resource, it might respond with 406 (Not Acceptable) or 415 (Unsupported Media Type) and set headers for the types of media that it does support (e.g., using the Accept-Post or Accept-Patch for POST and PATCH requests, respectively). The algorithm is server-specific and not defined in the standard. See the Apache negotiation algorithm.

The HTTP/1.1 standard defines list of the standard headers that start server-driven negotiation (such as Accept, Accept-Encoding, and Accept-Language). Though User-Agent isn't in this list, it's sometimes also used to send a specific representation of the requested resource. However, this isn't always considered a good practice. The server uses the Vary header to indicate which headers it actually used for content negotiation (or more precisely, the associated request headers), so that caches can work optimally.
In addition to these, there's an experimental proposal to add more headers to the list of available headers, called client hints. Client hints advertise what kind of device the user agent runs on (for example, a desktop computer or a mobile device).
Even if server-driven content negotiation is the most common way to agree on a specific representation of a resource, it has several drawbacks:

The server doesn't have total knowledge of the browser. Even with the Client Hints extension, it doesn't have a complete knowledge of the capabilities of the browser. Unlike reactive content negotiation where the client makes the choice, the server choice is always somewhat arbitrary.
The information from the client is quite verbose (HTTP/2 header compression mitigates this problem) and a privacy risk (HTTP fingerprinting).
As several representations of a given resource are sent, shared caches are less efficient and server implementations are more complex.
The Accept headerThe Accept header lists the MIME types of media resources that the agent is willing to process. This is a comma-separated list of MIME types, each combined with a quality factor, a parameter that indicates the relative degree of preference between the different MIME types.
The Accept header is defined by the browser, or any other user agent, and can vary according to the context. For example, fetching an HTML page or an image, a video, or a script. It's different when fetching a document entered in the address bar or an element linked via an <img>, <video>, or <audio> element. Browsers are free to use the value of the header that they think is the most adequate; an exhaustive list of default values for common browsers is available.The Accept-CH header
Note:
This is part of an experimental technology called Client Hints. Initial support comes in Chrome 46 or later. The Device-Memory value is in Chrome 61 or later.

The experimental Accept-CH lists configuration data that the server can use to select an appropriate response. Valid values are:



Value
Meaning




Device-Memory
Indicates the approximate amount of device RAM. This value is an approximation given by rounding to the nearest power of 2 and dividing that number by 1024. For example, 512 megabytes will be reported as 0.5.


Viewport-Width
Indicates the layout viewport width in CSS pixels.


Width
Indicates the resource width in physical pixels (in other words the intrinsic size of an image).


The Accept-Encoding headerThe Accept-Encoding header defines the acceptable content encoding (supported compressions). The value is a q-factor list (e.g., br, gzip;q=0.8) that indicates the priority of the encoding values. The default value identity is at the lowest priority (unless otherwise noted).
Compressing HTTP messages is one of the most important ways to improve the performance of a website. It shrinks the size of the data transmitted and makes better use of the available bandwidth. Browsers always send this header and the server should be configured to use compression.The Accept-Language headerThe Accept-Language header is used to indicate the language preference of the user. It's a list of values with quality factors (e.g., de, en;q=0.7). A default value is often set according to the language of the graphical interface of the user agent, but most browsers allow different language preferences to be set.
Due to the configuration-based entropy increase, a modified value can be used to fingerprint the user. It's not recommended to change it and a website can't trust this value to reflect the actual intention of the user. It's best for site designers to avoid using language detection via this header as it can lead to a poor user experience.

They should always provide a way to override the server-chosen language, e.g., by providing a language menu on the site. Most user agents provide a default value for the Accept-Language header that's adapted to the user interface language. End users often don't modify it because they either don't know how or aren't able to do so based on their computing environment.
Once a user has overridden the server-chosen language, a site should no longer use language detection and should stick with the explicitly chosen language. In other words, only entry pages for a site should use this header to select the proper language.
The User-Agent header
Note:
Though there are legitimate uses of this header for selecting content, it's considered bad practice to rely on it to define what features are supported by the user agent.

The User-Agent header identifies the browser sending the request. This string may contain a space-separated list of product tokens and comments.
A product token is a name followed by a / and a version number, like Firefox/4.0.1. The user agent can include as many of these as it wants. A comment is an optional string delimited by parentheses. The information provided in a comment isn't standardized, though several browsers add several tokens to it separated by ;.The Vary response headerIn contrast to the previous Accept-* headers, which are sent by the client, the Vary HTTP header is sent by the web server in its response. It indicates the list of headers the server uses during the server-driven content negotiation phase. The Vary header is needed to inform the cache of the decision criteria so that it can reproduce it. This allows the cache to be functional while ensuring that the right content is served to the user.
The special value * means that the server-driven content negotiation also uses information not conveyed in a header to choose the appropriate content.
The Vary header was added in version 1.1 of HTTP and allows caches to work appropriately. To work with server-driven content negotiation, a cache needs to know which criteria the server used to select the transmitted content. That way, the cache can replay the algorithm and will be able to serve acceptable content directly, without more requests to the server. Obviously, the wildcard * prevents caching from occurring, as the cache can't know what element is behind it. For more information, see HTTP caching > Varying responses.Agent-driven negotiationServer-driven negotiation has a few drawbacks: it doesn't scale well. One header per feature is used in the negotiation. If you want to use screen size, resolution, or other dimensions, you need to create a new HTTP header. The headers must then be sent with every request. This isn't an issue if there are only a few headers, but as the number of headers increases, the message size could eventually affect performance. The more precisely headers are sent, the more entropy is sent, allowing for more HTTP fingerprinting and corresponding privacy concerns.
HTTP allows another negotiation type: agent-driven negotiation or reactive negotiation. In this case, the server sends back a page that contains links to the available alternative resources when faced with an ambiguous request. The user is presented the resources and chooses the one to use.

Unfortunately, the HTTP standard doesn't specify the format of the page for choosing between the available resources, which prevents the process from being automated. Besides falling back to the server-driven negotiation, this method is almost always used with scripting, especially with JavaScript redirection: after having checked for the negotiation criteria, the script performs the redirection. A second problem is that one more request is needed to fetch the real resource, slowing the availability of the resource to the user.See also
Caching
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Apr 10, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nContent negotiationIn HTTP, content negotiation is the mechanism that is used for serving different representations of a resource to the same URI to help the user agent specify which representation is best suited for the user (for example, which document language, which image format, or which content encoding).

Note:
You'll find some disadvantages of HTTP content negotiation in a wiki page from WHATWG. HTML provides alternatives to content negotiation via, for example, the <source> element.
Principles of content negotiationA specific document is called a resource. When a client wants to obtain a resource, the client requests it via a URL. The server uses this URL to choose one of the variants available–each variant is called a representation–and returns a specific representation to the client. The overall resource, as well as each of the representations, has a specific URL. Content negotiation determines how a specific representation is chosen when the resource is called. There are several ways of negotiating between the client and the server.

The best-suited representation is identified through one of two mechanisms:

Specific HTTP headers by the client (server-driven negotiation or proactive negotiation), which is the standard way of negotiating a specific kind of resource.
The 300 (Multiple Choices) or 406 (Not Acceptable), 415 (Unsupported Media Type) HTTP response codes by the server (agent-driven negotiation or reactive negotiation), that are used as fallback mechanisms.

Over the years, other content negotiation proposals, like transparent content negotiation and the Alternates header, have been proposed. They failed to get traction and were abandoned.Server-driven content negotiationIn server-driven content negotiation, or proactive content negotiation, the browser (or any other kind of user agent) sends several HTTP headers along with the URL. These headers describe the user's preferred choice. The server uses them as hints and an internal algorithm chooses the best content to serve to the client. If it can't provide a suitable resource, it might respond with 406 (Not Acceptable) or 415 (Unsupported Media Type) and set headers for the types of media that it does support (e.g., using the Accept-Post or Accept-Patch for POST and PATCH requests, respectively). The algorithm is server-specific and not defined in the standard. See the Apache negotiation algorithm.

The HTTP/1.1 standard defines list of the standard headers that start server-driven negotiation (such as Accept, Accept-Encoding, and Accept-Language). Though User-Agent isn't in this list, it's sometimes also used to send a specific representation of the requested resource. However, this isn't always considered a good practice. The server uses the Vary header to indicate which headers it actually used for content negotiation (or more precisely, the associated request headers), so that caches can work optimally.
In addition to these, there's an experimental proposal to add more headers to the list of available headers, called client hints. Client hints advertise what kind of device the user agent runs on (for example, a desktop computer or a mobile device).
Even if server-driven content negotiation is the most common way to agree on a specific representation of a resource, it has several drawbacks:

The server doesn't have total knowledge of the browser. Even with the Client Hints extension, it doesn't have a complete knowledge of the capabilities of the browser. Unlike reactive content negotiation where the client makes the choice, the server choice is always somewhat arbitrary.
The information from the client is quite verbose (HTTP/2 header compression mitigates this problem) and a privacy risk (HTTP fingerprinting).
As several representations of a given resource are sent, shared caches are less efficient and server implementations are more complex.
The Accept headerThe Accept header lists the MIME types of media resources that the agent is willing to process. This is a comma-separated list of MIME types, each combined with a quality factor, a parameter that indicates the relative degree of preference between the different MIME types.
The Accept header is defined by the browser, or any other user agent, and can vary according to the context. For example, fetching an HTML page or an image, a video, or a script. It's different when fetching a document entered in the address bar or an element linked via an <img>, <video>, or <audio> element. Browsers are free to use the value of the header that they think is the most adequate; an exhaustive list of default values for common browsers is available.The Accept-CH header
Note:
This is part of an experimental technology called Client Hints. Initial support comes in Chrome 46 or later. The Device-Memory value is in Chrome 61 or later.

The experimental Accept-CH lists configuration data that the server can use to select an appropriate response. Valid values are:



Value
Meaning




Device-Memory
Indicates the approximate amount of device RAM. This value is an approximation given by rounding to the nearest power of 2 and dividing that number by 1024. For example, 512 megabytes will be reported as 0.5.


Viewport-Width
Indicates the layout viewport width in CSS pixels.


Width
Indicates the resource width in physical pixels (in other words the intrinsic size of an image).


The Accept-Encoding headerThe Accept-Encoding header defines the acceptable content encoding (supported compressions). The value is a q-factor list (e.g., br, gzip;q=0.8) that indicates the priority of the encoding values. The default value identity is at the lowest priority (unless otherwise noted).
Compressing HTTP messages is one of the most important ways to improve the performance of a website. It shrinks the size of the data transmitted and makes better use of the available bandwidth. Browsers always send this header and the server should be configured to use compression.The Accept-Language headerThe Accept-Language header is used to indicate the language preference of the user. It's a list of values with quality factors (e.g., de, en;q=0.7). A default value is often set according to the language of the graphical interface of the user agent, but most browsers allow different language preferences to be set.
Due to the configuration-based entropy increase, a modified value can be used to fingerprint the user. It's not recommended to change it and a website can't trust this value to reflect the actual intention of the user. It's best for site designers to avoid using language detection via this header as it can lead to a poor user experience.

They should always provide a way to override the server-chosen language, e.g., by providing a language menu on the site. Most user agents provide a default value for the Accept-Language header that's adapted to the user interface language. End users often don't modify it because they either don't know how or aren't able to do so based on their computing environment.
Once a user has overridden the server-chosen language, a site should no longer use language detection and should stick with the explicitly chosen language. In other words, only entry pages for a site should use this header to select the proper language.
The User-Agent header
Note:
Though there are legitimate uses of this header for selecting content, it's considered bad practice to rely on it to define what features are supported by the user agent.

The User-Agent header identifies the browser sending the request. This string may contain a space-separated list of product tokens and comments.
A product token is a name followed by a / and a version number, like Firefox/4.0.1. The user agent can include as many of these as it wants. A comment is an optional string delimited by parentheses. The information provided in a comment isn't standardized, though several browsers add several tokens to it separated by ;.The Vary response headerIn contrast to the previous Accept-* headers, which are sent by the client, the Vary HTTP header is sent by the web server in its response. It indicates the list of headers the server uses during the server-driven content negotiation phase. The Vary header is needed to inform the cache of the decision criteria so that it can reproduce it. This allows the cache to be functional while ensuring that the right content is served to the user.
The special value * means that the server-driven content negotiation also uses information not conveyed in a header to choose the appropriate content.
The Vary header was added in version 1.1 of HTTP and allows caches to work appropriately. To work with server-driven content negotiation, a cache needs to know which criteria the server used to select the transmitted content. That way, the cache can replay the algorithm and will be able to serve acceptable content directly, without more requests to the server. Obviously, the wildcard * prevents caching from occurring, as the cache can't know what element is behind it. For more information, see HTTP caching > Varying responses.Agent-driven negotiationServer-driven negotiation has a few drawbacks: it doesn't scale well. One header per feature is used in the negotiation. If you want to use screen size, resolution, or other dimensions, you need to create a new HTTP header. The headers must then be sent with every request. This isn't an issue if there are only a few headers, but as the number of headers increases, the message size could eventually affect performance. The more precisely headers are sent, the more entropy is sent, allowing for more HTTP fingerprinting and corresponding privacy concerns.
HTTP allows another negotiation type: agent-driven negotiation or reactive negotiation. In this case, the server sends back a page that contains links to the available alternative resources when faced with an ambiguous request. The user is presented the resources and chooses the one to use.

Unfortunately, the HTTP standard doesn't specify the format of the page for choosing between the available resources, which prevents the process from being automated. Besides falling back to the server-driven negotiation, this method is almost always used with scripting, especially with JavaScript redirection: after having checked for the negotiation criteria, the script performs the redirection. A second problem is that one more request is needed to fetch the real resource, slowing the availability of the resource to the user.See also
Caching
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Apr 10, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nContent negotiationIn HTTP, content negotiation is the mechanism that is used for serving different representations of a resource to the same URI to help the user agent specify which representation is best suited for the user (for example, which document language, which image format, or which content encoding).

Note:
You'll find some disadvantages of HTTP content negotiation in a wiki page from WHATWG. HTML provides alternatives to content negotiation via, for example, the <source> element.
Principles of content negotiationA specific document is called a resource. When a client wants to obtain a resource, the client requests it via a URL. The server uses this URL to choose one of the variants available–each variant is called a representation–and returns a specific representation to the client. The overall resource, as well as each of the representations, has a specific URL. Content negotiation determines how a specific representation is chosen when the resource is called. There are several ways of negotiating between the client and the server.

The best-suited representation is identified through one of two mechanisms:

Specific HTTP headers by the client (server-driven negotiation or proactive negotiation), which is the standard way of negotiating a specific kind of resource.
The 300 (Multiple Choices) or 406 (Not Acceptable), 415 (Unsupported Media Type) HTTP response codes by the server (agent-driven negotiation or reactive negotiation), that are used as fallback mechanisms.

Over the years, other content negotiation proposals, like transparent content negotiation and the Alternates header, have been proposed. They failed to get traction and were abandoned.Server-driven content negotiationIn server-driven content negotiation, or proactive content negotiation, the browser (or any other kind of user agent) sends several HTTP headers along with the URL. These headers describe the user's preferred choice. The server uses them as hints and an internal algorithm chooses the best content to serve to the client. If it can't provide a suitable resource, it might respond with 406 (Not Acceptable) or 415 (Unsupported Media Type) and set headers for the types of media that it does support (e.g., using the Accept-Post or Accept-Patch for POST and PATCH requests, respectively). The algorithm is server-specific and not defined in the standard. See the Apache negotiation algorithm.

The HTTP/1.1 standard defines list of the standard headers that start server-driven negotiation (such as Accept, Accept-Encoding, and Accept-Language). Though User-Agent isn't in this list, it's sometimes also used to send a specific representation of the requested resource. However, this isn't always considered a good practice. The server uses the Vary header to indicate which headers it actually used for content negotiation (or more precisely, the associated request headers), so that caches can work optimally.
In addition to these, there's an experimental proposal to add more headers to the list of available headers, called client hints. Client hints advertise what kind of device the user agent runs on (for example, a desktop computer or a mobile device).
Even if server-driven content negotiation is the most common way to agree on a specific representation of a resource, it has several drawbacks:

The server doesn't have total knowledge of the browser. Even with the Client Hints extension, it doesn't have a complete knowledge of the capabilities of the browser. Unlike reactive content negotiation where the client makes the choice, the server choice is always somewhat arbitrary.
The information from the client is quite verbose (HTTP/2 header compression mitigates this problem) and a privacy risk (HTTP fingerprinting).
As several representations of a given resource are sent, shared caches are less efficient and server implementations are more complex.
The Accept headerThe Accept header lists the MIME types of media resources that the agent is willing to process. This is a comma-separated list of MIME types, each combined with a quality factor, a parameter that indicates the relative degree of preference between the different MIME types.
The Accept header is defined by the browser, or any other user agent, and can vary according to the context. For example, fetching an HTML page or an image, a video, or a script. It's different when fetching a document entered in the address bar or an element linked via an <img>, <video>, or <audio> element. Browsers are free to use the value of the header that they think is the most adequate; an exhaustive list of default values for common browsers is available.The Accept-CH header
Note:
This is part of an experimental technology called Client Hints. Initial support comes in Chrome 46 or later. The Device-Memory value is in Chrome 61 or later.

The experimental Accept-CH lists configuration data that the server can use to select an appropriate response. Valid values are:



Value
Meaning




Device-Memory
Indicates the approximate amount of device RAM. This value is an approximation given by rounding to the nearest power of 2 and dividing that number by 1024. For example, 512 megabytes will be reported as 0.5.


Viewport-Width
Indicates the layout viewport width in CSS pixels.


Width
Indicates the resource width in physical pixels (in other words the intrinsic size of an image).


The Accept-Encoding headerThe Accept-Encoding header defines the acceptable content encoding (supported compressions). The value is a q-factor list (e.g., br, gzip;q=0.8) that indicates the priority of the encoding values. The default value identity is at the lowest priority (unless otherwise noted).
Compressing HTTP messages is one of the most important ways to improve the performance of a website. It shrinks the size of the data transmitted and makes better use of the available bandwidth. Browsers always send this header and the server should be configured to use compression.The Accept-Language headerThe Accept-Language header is used to indicate the language preference of the user. It's a list of values with quality factors (e.g., de, en;q=0.7). A default value is often set according to the language of the graphical interface of the user agent, but most browsers allow different language preferences to be set.
Due to the configuration-based entropy increase, a modified value can be used to fingerprint the user. It's not recommended to change it and a website can't trust this value to reflect the actual intention of the user. It's best for site designers to avoid using language detection via this header as it can lead to a poor user experience.

They should always provide a way to override the server-chosen language, e.g., by providing a language menu on the site. Most user agents provide a default value for the Accept-Language header that's adapted to the user interface language. End users often don't modify it because they either don't know how or aren't able to do so based on their computing environment.
Once a user has overridden the server-chosen language, a site should no longer use language detection and should stick with the explicitly chosen language. In other words, only entry pages for a site should use this header to select the proper language.
The User-Agent header
Note:
Though there are legitimate uses of this header for selecting content, it's considered bad practice to rely on it to define what features are supported by the user agent.

The User-Agent header identifies the browser sending the request. This string may contain a space-separated list of product tokens and comments.
A product token is a name followed by a / and a version number, like Firefox/4.0.1. The user agent can include as many of these as it wants. A comment is an optional string delimited by parentheses. The information provided in a comment isn't standardized, though several browsers add several tokens to it separated by ;.The Vary response headerIn contrast to the previous Accept-* headers, which are sent by the client, the Vary HTTP header is sent by the web server in its response. It indicates the list of headers the server uses during the server-driven content negotiation phase. The Vary header is needed to inform the cache of the decision criteria so that it can reproduce it. This allows the cache to be functional while ensuring that the right content is served to the user.
The special value * means that the server-driven content negotiation also uses information not conveyed in a header to choose the appropriate content.
The Vary header was added in version 1.1 of HTTP and allows caches to work appropriately. To work with server-driven content negotiation, a cache needs to know which criteria the server used to select the transmitted content. That way, the cache can replay the algorithm and will be able to serve acceptable content directly, without more requests to the server. Obviously, the wildcard * prevents caching from occurring, as the cache can't know what element is behind it. For more information, see HTTP caching > Varying responses.Agent-driven negotiationServer-driven negotiation has a few drawbacks: it doesn't scale well. One header per feature is used in the negotiation. If you want to use screen size, resolution, or other dimensions, you need to create a new HTTP header. The headers must then be sent with every request. This isn't an issue if there are only a few headers, but as the number of headers increases, the message size could eventually affect performance. The more precisely headers are sent, the more entropy is sent, allowing for more HTTP fingerprinting and corresponding privacy concerns.
HTTP allows another negotiation type: agent-driven negotiation or reactive negotiation. In this case, the server sends back a page that contains links to the available alternative resources when faced with an ambiguous request. The user is presented the resources and chooses the one to use.

Unfortunately, the HTTP standard doesn't specify the format of the page for choosing between the available resources, which prevents the process from being automated. Besides falling back to the server-driven negotiation, this method is almost always used with scripting, especially with JavaScript redirection: after having checked for the negotiation criteria, the script performs the redirection. A second problem is that one more request is needed to fetch the real resource, slowing the availability of the resource to the user.See also
Caching\n\nContent negotiationIn HTTP, content negotiation is the mechanism that is used for serving different representations of a resource to the same URI to help the user agent specify which representation is best suited for the user (for example, which document language, which image format, or which content encoding).

Note:
You'll find some disadvantages of HTTP content negotiation in a wiki page from WHATWG. HTML provides alternatives to content negotiation via, for example, the <source> element.
Principles of content negotiationA specific document is called a resource. When a client wants to obtain a resource, the client requests it via a URL. The server uses this URL to choose one of the variants available–each variant is called a representation–and returns a specific representation to the client. The overall resource, as well as each of the representations, has a specific URL. Content negotiation determines how a specific representation is chosen when the resource is called. There are several ways of negotiating between the client and the server.

The best-suited representation is identified through one of two mechanisms:

Specific HTTP headers by the client (server-driven negotiation or proactive negotiation), which is the standard way of negotiating a specific kind of resource.
The 300 (Multiple Choices) or 406 (Not Acceptable), 415 (Unsupported Media Type) HTTP response codes by the server (agent-driven negotiation or reactive negotiation), that are used as fallback mechanisms.

Over the years, other content negotiation proposals, like transparent content negotiation and the Alternates header, have been proposed. They failed to get traction and were abandoned.Server-driven content negotiationIn server-driven content negotiation, or proactive content negotiation, the browser (or any other kind of user agent) sends several HTTP headers along with the URL. These headers describe the user's preferred choice. The server uses them as hints and an internal algorithm chooses the best content to serve to the client. If it can't provide a suitable resource, it might respond with 406 (Not Acceptable) or 415 (Unsupported Media Type) and set headers for the types of media that it does support (e.g., using the Accept-Post or Accept-Patch for POST and PATCH requests, respectively). The algorithm is server-specific and not defined in the standard. See the Apache negotiation algorithm.

The HTTP/1.1 standard defines list of the standard headers that start server-driven negotiation (such as Accept, Accept-Encoding, and Accept-Language). Though User-Agent isn't in this list, it's sometimes also used to send a specific representation of the requested resource. However, this isn't always considered a good practice. The server uses the Vary header to indicate which headers it actually used for content negotiation (or more precisely, the associated request headers), so that caches can work optimally.
In addition to these, there's an experimental proposal to add more headers to the list of available headers, called client hints. Client hints advertise what kind of device the user agent runs on (for example, a desktop computer or a mobile device).
Even if server-driven content negotiation is the most common way to agree on a specific representation of a resource, it has several drawbacks:

The server doesn't have total knowledge of the browser. Even with the Client Hints extension, it doesn't have a complete knowledge of the capabilities of the browser. Unlike reactive content negotiation where the client makes the choice, the server choice is always somewhat arbitrary.
The information from the client is quite verbose (HTTP/2 header compression mitigates this problem) and a privacy risk (HTTP fingerprinting).
As several representations of a given resource are sent, shared caches are less efficient and server implementations are more complex.
The Accept headerThe Accept header lists the MIME types of media resources that the agent is willing to process. This is a comma-separated list of MIME types, each combined with a quality factor, a parameter that indicates the relative degree of preference between the different MIME types.
The Accept header is defined by the browser, or any other user agent, and can vary according to the context. For example, fetching an HTML page or an image, a video, or a script. It's different when fetching a document entered in the address bar or an element linked via an <img>, <video>, or <audio> element. Browsers are free to use the value of the header that they think is the most adequate; an exhaustive list of default values for common browsers is available.The Accept-CH header
Note:
This is part of an experimental technology called Client Hints. Initial support comes in Chrome 46 or later. The Device-Memory value is in Chrome 61 or later.

The experimental Accept-CH lists configuration data that the server can use to select an appropriate response. Valid values are:



Value
Meaning




Device-Memory
Indicates the approximate amount of device RAM. This value is an approximation given by rounding to the nearest power of 2 and dividing that number by 1024. For example, 512 megabytes will be reported as 0.5.


Viewport-Width
Indicates the layout viewport width in CSS pixels.


Width
Indicates the resource width in physical pixels (in other words the intrinsic size of an image).


The Accept-Encoding headerThe Accept-Encoding header defines the acceptable content encoding (supported compressions). The value is a q-factor list (e.g., br, gzip;q=0.8) that indicates the priority of the encoding values. The default value identity is at the lowest priority (unless otherwise noted).
Compressing HTTP messages is one of the most important ways to improve the performance of a website. It shrinks the size of the data transmitted and makes better use of the available bandwidth. Browsers always send this header and the server should be configured to use compression.The Accept-Language headerThe Accept-Language header is used to indicate the language preference of the user. It's a list of values with quality factors (e.g., de, en;q=0.7). A default value is often set according to the language of the graphical interface of the user agent, but most browsers allow different language preferences to be set.
Due to the configuration-based entropy increase, a modified value can be used to fingerprint the user. It's not recommended to change it and a website can't trust this value to reflect the actual intention of the user. It's best for site designers to avoid using language detection via this header as it can lead to a poor user experience.

They should always provide a way to override the server-chosen language, e.g., by providing a language menu on the site. Most user agents provide a default value for the Accept-Language header that's adapted to the user interface language. End users often don't modify it because they either don't know how or aren't able to do so based on their computing environment.
Once a user has overridden the server-chosen language, a site should no longer use language detection and should stick with the explicitly chosen language. In other words, only entry pages for a site should use this header to select the proper language.
The User-Agent header
Note:
Though there are legitimate uses of this header for selecting content, it's considered bad practice to rely on it to define what features are supported by the user agent.

The User-Agent header identifies the browser sending the request. This string may contain a space-separated list of product tokens and comments.
A product token is a name followed by a / and a version number, like Firefox/4.0.1. The user agent can include as many of these as it wants. A comment is an optional string delimited by parentheses. The information provided in a comment isn't standardized, though several browsers add several tokens to it separated by ;.The Vary response headerIn contrast to the previous Accept-* headers, which are sent by the client, the Vary HTTP header is sent by the web server in its response. It indicates the list of headers the server uses during the server-driven content negotiation phase. The Vary header is needed to inform the cache of the decision criteria so that it can reproduce it. This allows the cache to be functional while ensuring that the right content is served to the user.
The special value * means that the server-driven content negotiation also uses information not conveyed in a header to choose the appropriate content.
The Vary header was added in version 1.1 of HTTP and allows caches to work appropriately. To work with server-driven content negotiation, a cache needs to know which criteria the server used to select the transmitted content. That way, the cache can replay the algorithm and will be able to serve acceptable content directly, without more requests to the server. Obviously, the wildcard * prevents caching from occurring, as the cache can't know what element is behind it. For more information, see HTTP caching > Varying responses.Agent-driven negotiationServer-driven negotiation has a few drawbacks: it doesn't scale well. One header per feature is used in the negotiation. If you want to use screen size, resolution, or other dimensions, you need to create a new HTTP header. The headers must then be sent with every request. This isn't an issue if there are only a few headers, but as the number of headers increases, the message size could eventually affect performance. The more precisely headers are sent, the more entropy is sent, allowing for more HTTP fingerprinting and corresponding privacy concerns.
HTTP allows another negotiation type: agent-driven negotiation or reactive negotiation. In this case, the server sends back a page that contains links to the available alternative resources when faced with an ambiguous request. The user is presented the resources and chooses the one to use.

Unfortunately, the HTTP standard doesn't specify the format of the page for choosing between the available resources, which prevents the process from being automated. Besides falling back to the server-driven negotiation, this method is almost always used with scripting, especially with JavaScript redirection: after having checked for the negotiation criteria, the script performs the redirection. A second problem is that one more request is needed to fetch the real resource, slowing the availability of the resource to the user.See also
Caching
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Apr 10, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nContent negotiationIn HTTP, content negotiation is the mechanism that is used for serving different representations of a resource to the same URI to help the user agent specify which representation is best suited for the user (for example, which document language, which image format, or which content encoding).

Note:
You'll find some disadvantages of HTTP content negotiation in a wiki page from WHATWG. HTML provides alternatives to content negotiation via, for example, the <source> element.
Principles of content negotiationA specific document is called a resource. When a client wants to obtain a resource, the client requests it via a URL. The server uses this URL to choose one of the variants available–each variant is called a representation–and returns a specific representation to the client. The overall resource, as well as each of the representations, has a specific URL. Content negotiation determines how a specific representation is chosen when the resource is called. There are several ways of negotiating between the client and the server.

The best-suited representation is identified through one of two mechanisms:

Specific HTTP headers by the client (server-driven negotiation or proactive negotiation), which is the standard way of negotiating a specific kind of resource.
The 300 (Multiple Choices) or 406 (Not Acceptable), 415 (Unsupported Media Type) HTTP response codes by the server (agent-driven negotiation or reactive negotiation), that are used as fallback mechanisms.

Over the years, other content negotiation proposals, like transparent content negotiation and the Alternates header, have been proposed. They failed to get traction and were abandoned.Server-driven content negotiationIn server-driven content negotiation, or proactive content negotiation, the browser (or any other kind of user agent) sends several HTTP headers along with the URL. These headers describe the user's preferred choice. The server uses them as hints and an internal algorithm chooses the best content to serve to the client. If it can't provide a suitable resource, it might respond with 406 (Not Acceptable) or 415 (Unsupported Media Type) and set headers for the types of media that it does support (e.g., using the Accept-Post or Accept-Patch for POST and PATCH requests, respectively). The algorithm is server-specific and not defined in the standard. See the Apache negotiation algorithm.

The HTTP/1.1 standard defines list of the standard headers that start server-driven negotiation (such as Accept, Accept-Encoding, and Accept-Language). Though User-Agent isn't in this list, it's sometimes also used to send a specific representation of the requested resource. However, this isn't always considered a good practice. The server uses the Vary header to indicate which headers it actually used for content negotiation (or more precisely, the associated request headers), so that caches can work optimally.
In addition to these, there's an experimental proposal to add more headers to the list of available headers, called client hints. Client hints advertise what kind of device the user agent runs on (for example, a desktop computer or a mobile device).
Even if server-driven content negotiation is the most common way to agree on a specific representation of a resource, it has several drawbacks:

The server doesn't have total knowledge of the browser. Even with the Client Hints extension, it doesn't have a complete knowledge of the capabilities of the browser. Unlike reactive content negotiation where the client makes the choice, the server choice is always somewhat arbitrary.
The information from the client is quite verbose (HTTP/2 header compression mitigates this problem) and a privacy risk (HTTP fingerprinting).
As several representations of a given resource are sent, shared caches are less efficient and server implementations are more complex.
The Accept headerThe Accept header lists the MIME types of media resources that the agent is willing to process. This is a comma-separated list of MIME types, each combined with a quality factor, a parameter that indicates the relative degree of preference between the different MIME types.
The Accept header is defined by the browser, or any other user agent, and can vary according to the context. For example, fetching an HTML page or an image, a video, or a script. It's different when fetching a document entered in the address bar or an element linked via an <img>, <video>, or <audio> element. Browsers are free to use the value of the header that they think is the most adequate; an exhaustive list of default values for common browsers is available.The Accept-CH header
Note:
This is part of an experimental technology called Client Hints. Initial support comes in Chrome 46 or later. The Device-Memory value is in Chrome 61 or later.

The experimental Accept-CH lists configuration data that the server can use to select an appropriate response. Valid values are:



Value
Meaning




Device-Memory
Indicates the approximate amount of device RAM. This value is an approximation given by rounding to the nearest power of 2 and dividing that number by 1024. For example, 512 megabytes will be reported as 0.5.


Viewport-Width
Indicates the layout viewport width in CSS pixels.


Width
Indicates the resource width in physical pixels (in other words the intrinsic size of an image).


The Accept-Encoding headerThe Accept-Encoding header defines the acceptable content encoding (supported compressions). The value is a q-factor list (e.g., br, gzip;q=0.8) that indicates the priority of the encoding values. The default value identity is at the lowest priority (unless otherwise noted).
Compressing HTTP messages is one of the most important ways to improve the performance of a website. It shrinks the size of the data transmitted and makes better use of the available bandwidth. Browsers always send this header and the server should be configured to use compression.The Accept-Language headerThe Accept-Language header is used to indicate the language preference of the user. It's a list of values with quality factors (e.g., de, en;q=0.7). A default value is often set according to the language of the graphical interface of the user agent, but most browsers allow different language preferences to be set.
Due to the configuration-based entropy increase, a modified value can be used to fingerprint the user. It's not recommended to change it and a website can't trust this value to reflect the actual intention of the user. It's best for site designers to avoid using language detection via this header as it can lead to a poor user experience.

They should always provide a way to override the server-chosen language, e.g., by providing a language menu on the site. Most user agents provide a default value for the Accept-Language header that's adapted to the user interface language. End users often don't modify it because they either don't know how or aren't able to do so based on their computing environment.
Once a user has overridden the server-chosen language, a site should no longer use language detection and should stick with the explicitly chosen language. In other words, only entry pages for a site should use this header to select the proper language.
The User-Agent header
Note:
Though there are legitimate uses of this header for selecting content, it's considered bad practice to rely on it to define what features are supported by the user agent.

The User-Agent header identifies the browser sending the request. This string may contain a space-separated list of product tokens and comments.
A product token is a name followed by a / and a version number, like Firefox/4.0.1. The user agent can include as many of these as it wants. A comment is an optional string delimited by parentheses. The information provided in a comment isn't standardized, though several browsers add several tokens to it separated by ;.The Vary response headerIn contrast to the previous Accept-* headers, which are sent by the client, the Vary HTTP header is sent by the web server in its response. It indicates the list of headers the server uses during the server-driven content negotiation phase. The Vary header is needed to inform the cache of the decision criteria so that it can reproduce it. This allows the cache to be functional while ensuring that the right content is served to the user.
The special value * means that the server-driven content negotiation also uses information not conveyed in a header to choose the appropriate content.
The Vary header was added in version 1.1 of HTTP and allows caches to work appropriately. To work with server-driven content negotiation, a cache needs to know which criteria the server used to select the transmitted content. That way, the cache can replay the algorithm and will be able to serve acceptable content directly, without more requests to the server. Obviously, the wildcard * prevents caching from occurring, as the cache can't know what element is behind it. For more information, see HTTP caching > Varying responses.Agent-driven negotiationServer-driven negotiation has a few drawbacks: it doesn't scale well. One header per feature is used in the negotiation. If you want to use screen size, resolution, or other dimensions, you need to create a new HTTP header. The headers must then be sent with every request. This isn't an issue if there are only a few headers, but as the number of headers increases, the message size could eventually affect performance. The more precisely headers are sent, the more entropy is sent, allowing for more HTTP fingerprinting and corresponding privacy concerns.
HTTP allows another negotiation type: agent-driven negotiation or reactive negotiation. In this case, the server sends back a page that contains links to the available alternative resources when faced with an ambiguous request. The user is presented the resources and chooses the one to use.

Unfortunately, the HTTP standard doesn't specify the format of the page for choosing between the available resources, which prevents the process from being automated. Besides falling back to the server-driven negotiation, this method is almost always used with scripting, especially with JavaScript redirection: after having checked for the negotiation criteria, the script performs the redirection. A second problem is that one more request is needed to fetch the real resource, slowing the availability of the resource to the user.See also
Caching
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Apr 10, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nContent negotiationIn HTTP, content negotiation is the mechanism that is used for serving different representations of a resource to the same URI to help the user agent specify which representation is best suited for the user (for example, which document language, which image format, or which content encoding).

Note:
You'll find some disadvantages of HTTP content negotiation in a wiki page from WHATWG. HTML provides alternatives to content negotiation via, for example, the <source> element.
Principles of content negotiationA specific document is called a resource. When a client wants to obtain a resource, the client requests it via a URL. The server uses this URL to choose one of the variants available–each variant is called a representation–and returns a specific representation to the client. The overall resource, as well as each of the representations, has a specific URL. Content negotiation determines how a specific representation is chosen when the resource is called. There are several ways of negotiating between the client and the server.

The best-suited representation is identified through one of two mechanisms:

Specific HTTP headers by the client (server-driven negotiation or proactive negotiation), which is the standard way of negotiating a specific kind of resource.
The 300 (Multiple Choices) or 406 (Not Acceptable), 415 (Unsupported Media Type) HTTP response codes by the server (agent-driven negotiation or reactive negotiation), that are used as fallback mechanisms.

Over the years, other content negotiation proposals, like transparent content negotiation and the Alternates header, have been proposed. They failed to get traction and were abandoned.Server-driven content negotiationIn server-driven content negotiation, or proactive content negotiation, the browser (or any other kind of user agent) sends several HTTP headers along with the URL. These headers describe the user's preferred choice. The server uses them as hints and an internal algorithm chooses the best content to serve to the client. If it can't provide a suitable resource, it might respond with 406 (Not Acceptable) or 415 (Unsupported Media Type) and set headers for the types of media that it does support (e.g., using the Accept-Post or Accept-Patch for POST and PATCH requests, respectively). The algorithm is server-specific and not defined in the standard. See the Apache negotiation algorithm.

The HTTP/1.1 standard defines list of the standard headers that start server-driven negotiation (such as Accept, Accept-Encoding, and Accept-Language). Though User-Agent isn't in this list, it's sometimes also used to send a specific representation of the requested resource. However, this isn't always considered a good practice. The server uses the Vary header to indicate which headers it actually used for content negotiation (or more precisely, the associated request headers), so that caches can work optimally.
In addition to these, there's an experimental proposal to add more headers to the list of available headers, called client hints. Client hints advertise what kind of device the user agent runs on (for example, a desktop computer or a mobile device).
Even if server-driven content negotiation is the most common way to agree on a specific representation of a resource, it has several drawbacks:

The server doesn't have total knowledge of the browser. Even with the Client Hints extension, it doesn't have a complete knowledge of the capabilities of the browser. Unlike reactive content negotiation where the client makes the choice, the server choice is always somewhat arbitrary.
The information from the client is quite verbose (HTTP/2 header compression mitigates this problem) and a privacy risk (HTTP fingerprinting).
As several representations of a given resource are sent, shared caches are less efficient and server implementations are more complex.
The Accept headerThe Accept header lists the MIME types of media resources that the agent is willing to process. This is a comma-separated list of MIME types, each combined with a quality factor, a parameter that indicates the relative degree of preference between the different MIME types.
The Accept header is defined by the browser, or any other user agent, and can vary according to the context. For example, fetching an HTML page or an image, a video, or a script. It's different when fetching a document entered in the address bar or an element linked via an <img>, <video>, or <audio> element. Browsers are free to use the value of the header that they think is the most adequate; an exhaustive list of default values for common browsers is available.The Accept-CH header
Note:
This is part of an experimental technology called Client Hints. Initial support comes in Chrome 46 or later. The Device-Memory value is in Chrome 61 or later.

The experimental Accept-CH lists configuration data that the server can use to select an appropriate response. Valid values are:



Value
Meaning




Device-Memory
Indicates the approximate amount of device RAM. This value is an approximation given by rounding to the nearest power of 2 and dividing that number by 1024. For example, 512 megabytes will be reported as 0.5.


Viewport-Width
Indicates the layout viewport width in CSS pixels.


Width
Indicates the resource width in physical pixels (in other words the intrinsic size of an image).


The Accept-Encoding headerThe Accept-Encoding header defines the acceptable content encoding (supported compressions). The value is a q-factor list (e.g., br, gzip;q=0.8) that indicates the priority of the encoding values. The default value identity is at the lowest priority (unless otherwise noted).
Compressing HTTP messages is one of the most important ways to improve the performance of a website. It shrinks the size of the data transmitted and makes better use of the available bandwidth. Browsers always send this header and the server should be configured to use compression.The Accept-Language headerThe Accept-Language header is used to indicate the language preference of the user. It's a list of values with quality factors (e.g., de, en;q=0.7). A default value is often set according to the language of the graphical interface of the user agent, but most browsers allow different language preferences to be set.
Due to the configuration-based entropy increase, a modified value can be used to fingerprint the user. It's not recommended to change it and a website can't trust this value to reflect the actual intention of the user. It's best for site designers to avoid using language detection via this header as it can lead to a poor user experience.

They should always provide a way to override the server-chosen language, e.g., by providing a language menu on the site. Most user agents provide a default value for the Accept-Language header that's adapted to the user interface language. End users often don't modify it because they either don't know how or aren't able to do so based on their computing environment.
Once a user has overridden the server-chosen language, a site should no longer use language detection and should stick with the explicitly chosen language. In other words, only entry pages for a site should use this header to select the proper language.
The User-Agent header
Note:
Though there are legitimate uses of this header for selecting content, it's considered bad practice to rely on it to define what features are supported by the user agent.

The User-Agent header identifies the browser sending the request. This string may contain a space-separated list of product tokens and comments.
A product token is a name followed by a / and a version number, like Firefox/4.0.1. The user agent can include as many of these as it wants. A comment is an optional string delimited by parentheses. The information provided in a comment isn't standardized, though several browsers add several tokens to it separated by ;.The Vary response headerIn contrast to the previous Accept-* headers, which are sent by the client, the Vary HTTP header is sent by the web server in its response. It indicates the list of headers the server uses during the server-driven content negotiation phase. The Vary header is needed to inform the cache of the decision criteria so that it can reproduce it. This allows the cache to be functional while ensuring that the right content is served to the user.
The special value * means that the server-driven content negotiation also uses information not conveyed in a header to choose the appropriate content.
The Vary header was added in version 1.1 of HTTP and allows caches to work appropriately. To work with server-driven content negotiation, a cache needs to know which criteria the server used to select the transmitted content. That way, the cache can replay the algorithm and will be able to serve acceptable content directly, without more requests to the server. Obviously, the wildcard * prevents caching from occurring, as the cache can't know what element is behind it. For more information, see HTTP caching > Varying responses.Agent-driven negotiationServer-driven negotiation has a few drawbacks: it doesn't scale well. One header per feature is used in the negotiation. If you want to use screen size, resolution, or other dimensions, you need to create a new HTTP header. The headers must then be sent with every request. This isn't an issue if there are only a few headers, but as the number of headers increases, the message size could eventually affect performance. The more precisely headers are sent, the more entropy is sent, allowing for more HTTP fingerprinting and corresponding privacy concerns.
HTTP allows another negotiation type: agent-driven negotiation or reactive negotiation. In this case, the server sends back a page that contains links to the available alternative resources when faced with an ambiguous request. The user is presented the resources and chooses the one to use.

Unfortunately, the HTTP standard doesn't specify the format of the page for choosing between the available resources, which prevents the process from being automated. Besides falling back to the server-driven negotiation, this method is almost always used with scripting, especially with JavaScript redirection: after having checked for the negotiation criteria, the script performs the redirection. A second problem is that one more request is needed to fetch the real resource, slowing the availability of the resource to the user.See also
Caching\n\nContent negotiationIn HTTP, content negotiation is the mechanism that is used for serving different representations of a resource to the same URI to help the user agent specify which representation is best suited for the user (for example, which document language, which image format, or which content encoding).

Note:
You'll find some disadvantages of HTTP content negotiation in a wiki page from WHATWG. HTML provides alternatives to content negotiation via, for example, the <source> element.
Principles of content negotiationA specific document is called a resource. When a client wants to obtain a resource, the client requests it via a URL. The server uses this URL to choose one of the variants available–each variant is called a representation–and returns a specific representation to the client. The overall resource, as well as each of the representations, has a specific URL. Content negotiation determines how a specific representation is chosen when the resource is called. There are several ways of negotiating between the client and the server.

The best-suited representation is identified through one of two mechanisms:

Specific HTTP headers by the client (server-driven negotiation or proactive negotiation), which is the standard way of negotiating a specific kind of resource.
The 300 (Multiple Choices) or 406 (Not Acceptable), 415 (Unsupported Media Type) HTTP response codes by the server (agent-driven negotiation or reactive negotiation), that are used as fallback mechanisms.

Over the years, other content negotiation proposals, like transparent content negotiation and the Alternates header, have been proposed. They failed to get traction and were abandoned.Server-driven content negotiationIn server-driven content negotiation, or proactive content negotiation, the browser (or any other kind of user agent) sends several HTTP headers along with the URL. These headers describe the user's preferred choice. The server uses them as hints and an internal algorithm chooses the best content to serve to the client. If it can't provide a suitable resource, it might respond with 406 (Not Acceptable) or 415 (Unsupported Media Type) and set headers for the types of media that it does support (e.g., using the Accept-Post or Accept-Patch for POST and PATCH requests, respectively). The algorithm is server-specific and not defined in the standard. See the Apache negotiation algorithm.

The HTTP/1.1 standard defines list of the standard headers that start server-driven negotiation (such as Accept, Accept-Encoding, and Accept-Language). Though User-Agent isn't in this list, it's sometimes also used to send a specific representation of the requested resource. However, this isn't always considered a good practice. The server uses the Vary header to indicate which headers it actually used for content negotiation (or more precisely, the associated request headers), so that caches can work optimally.
In addition to these, there's an experimental proposal to add more headers to the list of available headers, called client hints. Client hints advertise what kind of device the user agent runs on (for example, a desktop computer or a mobile device).
Even if server-driven content negotiation is the most common way to agree on a specific representation of a resource, it has several drawbacks:

The server doesn't have total knowledge of the browser. Even with the Client Hints extension, it doesn't have a complete knowledge of the capabilities of the browser. Unlike reactive content negotiation where the client makes the choice, the server choice is always somewhat arbitrary.
The information from the client is quite verbose (HTTP/2 header compression mitigates this problem) and a privacy risk (HTTP fingerprinting).
As several representations of a given resource are sent, shared caches are less efficient and server implementations are more complex.
The Accept headerThe Accept header lists the MIME types of media resources that the agent is willing to process. This is a comma-separated list of MIME types, each combined with a quality factor, a parameter that indicates the relative degree of preference between the different MIME types.
The Accept header is defined by the browser, or any other user agent, and can vary according to the context. For example, fetching an HTML page or an image, a video, or a script. It's different when fetching a document entered in the address bar or an element linked via an <img>, <video>, or <audio> element. Browsers are free to use the value of the header that they think is the most adequate; an exhaustive list of default values for common browsers is available.The Accept-CH header
Note:
This is part of an experimental technology called Client Hints. Initial support comes in Chrome 46 or later. The Device-Memory value is in Chrome 61 or later.

The experimental Accept-CH lists configuration data that the server can use to select an appropriate response. Valid values are:



Value
Meaning




Device-Memory
Indicates the approximate amount of device RAM. This value is an approximation given by rounding to the nearest power of 2 and dividing that number by 1024. For example, 512 megabytes will be reported as 0.5.


Viewport-Width
Indicates the layout viewport width in CSS pixels.


Width
Indicates the resource width in physical pixels (in other words the intrinsic size of an image).


The Accept-Encoding headerThe Accept-Encoding header defines the acceptable content encoding (supported compressions). The value is a q-factor list (e.g., br, gzip;q=0.8) that indicates the priority of the encoding values. The default value identity is at the lowest priority (unless otherwise noted).
Compressing HTTP messages is one of the most important ways to improve the performance of a website. It shrinks the size of the data transmitted and makes better use of the available bandwidth. Browsers always send this header and the server should be configured to use compression.The Accept-Language headerThe Accept-Language header is used to indicate the language preference of the user. It's a list of values with quality factors (e.g., de, en;q=0.7). A default value is often set according to the language of the graphical interface of the user agent, but most browsers allow different language preferences to be set.
Due to the configuration-based entropy increase, a modified value can be used to fingerprint the user. It's not recommended to change it and a website can't trust this value to reflect the actual intention of the user. It's best for site designers to avoid using language detection via this header as it can lead to a poor user experience.

They should always provide a way to override the server-chosen language, e.g., by providing a language menu on the site. Most user agents provide a default value for the Accept-Language header that's adapted to the user interface language. End users often don't modify it because they either don't know how or aren't able to do so based on their computing environment.
Once a user has overridden the server-chosen language, a site should no longer use language detection and should stick with the explicitly chosen language. In other words, only entry pages for a site should use this header to select the proper language.
The User-Agent header
Note:
Though there are legitimate uses of this header for selecting content, it's considered bad practice to rely on it to define what features are supported by the user agent.

The User-Agent header identifies the browser sending the request. This string may contain a space-separated list of product tokens and comments.
A product token is a name followed by a / and a version number, like Firefox/4.0.1. The user agent can include as many of these as it wants. A comment is an optional string delimited by parentheses. The information provided in a comment isn't standardized, though several browsers add several tokens to it separated by ;.The Vary response headerIn contrast to the previous Accept-* headers, which are sent by the client, the Vary HTTP header is sent by the web server in its response. It indicates the list of headers the server uses during the server-driven content negotiation phase. The Vary header is needed to inform the cache of the decision criteria so that it can reproduce it. This allows the cache to be functional while ensuring that the right content is served to the user.
The special value * means that the server-driven content negotiation also uses information not conveyed in a header to choose the appropriate content.
The Vary header was added in version 1.1 of HTTP and allows caches to work appropriately. To work with server-driven content negotiation, a cache needs to know which criteria the server used to select the transmitted content. That way, the cache can replay the algorithm and will be able to serve acceptable content directly, without more requests to the server. Obviously, the wildcard * prevents caching from occurring, as the cache can't know what element is behind it. For more information, see HTTP caching > Varying responses.Agent-driven negotiationServer-driven negotiation has a few drawbacks: it doesn't scale well. One header per feature is used in the negotiation. If you want to use screen size, resolution, or other dimensions, you need to create a new HTTP header. The headers must then be sent with every request. This isn't an issue if there are only a few headers, but as the number of headers increases, the message size could eventually affect performance. The more precisely headers are sent, the more entropy is sent, allowing for more HTTP fingerprinting and corresponding privacy concerns.
HTTP allows another negotiation type: agent-driven negotiation or reactive negotiation. In this case, the server sends back a page that contains links to the available alternative resources when faced with an ambiguous request. The user is presented the resources and chooses the one to use.

Unfortunately, the HTTP standard doesn't specify the format of the page for choosing between the available resources, which prevents the process from being automated. Besides falling back to the server-driven negotiation, this method is almost always used with scripting, especially with JavaScript redirection: after having checked for the negotiation criteria, the script performs the redirection. A second problem is that one more request is needed to fetch the real resource, slowing the availability of the resource to the user.See also
Caching
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Apr 10, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nContent negotiationIn HTTP, content negotiation is the mechanism that is used for serving different representations of a resource to the same URI to help the user agent specify which representation is best suited for the user (for example, which document language, which image format, or which content encoding).

Note:
You'll find some disadvantages of HTTP content negotiation in a wiki page from WHATWG. HTML provides alternatives to content negotiation via, for example, the <source> element.
Principles of content negotiationA specific document is called a resource. When a client wants to obtain a resource, the client requests it via a URL. The server uses this URL to choose one of the variants available–each variant is called a representation–and returns a specific representation to the client. The overall resource, as well as each of the representations, has a specific URL. Content negotiation determines how a specific representation is chosen when the resource is called. There are several ways of negotiating between the client and the server.

The best-suited representation is identified through one of two mechanisms:

Specific HTTP headers by the client (server-driven negotiation or proactive negotiation), which is the standard way of negotiating a specific kind of resource.
The 300 (Multiple Choices) or 406 (Not Acceptable), 415 (Unsupported Media Type) HTTP response codes by the server (agent-driven negotiation or reactive negotiation), that are used as fallback mechanisms.

Over the years, other content negotiation proposals, like transparent content negotiation and the Alternates header, have been proposed. They failed to get traction and were abandoned.Server-driven content negotiationIn server-driven content negotiation, or proactive content negotiation, the browser (or any other kind of user agent) sends several HTTP headers along with the URL. These headers describe the user's preferred choice. The server uses them as hints and an internal algorithm chooses the best content to serve to the client. If it can't provide a suitable resource, it might respond with 406 (Not Acceptable) or 415 (Unsupported Media Type) and set headers for the types of media that it does support (e.g., using the Accept-Post or Accept-Patch for POST and PATCH requests, respectively). The algorithm is server-specific and not defined in the standard. See the Apache negotiation algorithm.

The HTTP/1.1 standard defines list of the standard headers that start server-driven negotiation (such as Accept, Accept-Encoding, and Accept-Language). Though User-Agent isn't in this list, it's sometimes also used to send a specific representation of the requested resource. However, this isn't always considered a good practice. The server uses the Vary header to indicate which headers it actually used for content negotiation (or more precisely, the associated request headers), so that caches can work optimally.
In addition to these, there's an experimental proposal to add more headers to the list of available headers, called client hints. Client hints advertise what kind of device the user agent runs on (for example, a desktop computer or a mobile device).
Even if server-driven content negotiation is the most common way to agree on a specific representation of a resource, it has several drawbacks:

The server doesn't have total knowledge of the browser. Even with the Client Hints extension, it doesn't have a complete knowledge of the capabilities of the browser. Unlike reactive content negotiation where the client makes the choice, the server choice is always somewhat arbitrary.
The information from the client is quite verbose (HTTP/2 header compression mitigates this problem) and a privacy risk (HTTP fingerprinting).
As several representations of a given resource are sent, shared caches are less efficient and server implementations are more complex.
The Accept headerThe Accept header lists the MIME types of media resources that the agent is willing to process. This is a comma-separated list of MIME types, each combined with a quality factor, a parameter that indicates the relative degree of preference between the different MIME types.
The Accept header is defined by the browser, or any other user agent, and can vary according to the context. For example, fetching an HTML page or an image, a video, or a script. It's different when fetching a document entered in the address bar or an element linked via an <img>, <video>, or <audio> element. Browsers are free to use the value of the header that they think is the most adequate; an exhaustive list of default values for common browsers is available.The Accept-CH header
Note:
This is part of an experimental technology called Client Hints. Initial support comes in Chrome 46 or later. The Device-Memory value is in Chrome 61 or later.

The experimental Accept-CH lists configuration data that the server can use to select an appropriate response. Valid values are:



Value
Meaning




Device-Memory
Indicates the approximate amount of device RAM. This value is an approximation given by rounding to the nearest power of 2 and dividing that number by 1024. For example, 512 megabytes will be reported as 0.5.


Viewport-Width
Indicates the layout viewport width in CSS pixels.


Width
Indicates the resource width in physical pixels (in other words the intrinsic size of an image).


The Accept-Encoding headerThe Accept-Encoding header defines the acceptable content encoding (supported compressions). The value is a q-factor list (e.g., br, gzip;q=0.8) that indicates the priority of the encoding values. The default value identity is at the lowest priority (unless otherwise noted).
Compressing HTTP messages is one of the most important ways to improve the performance of a website. It shrinks the size of the data transmitted and makes better use of the available bandwidth. Browsers always send this header and the server should be configured to use compression.The Accept-Language headerThe Accept-Language header is used to indicate the language preference of the user. It's a list of values with quality factors (e.g., de, en;q=0.7). A default value is often set according to the language of the graphical interface of the user agent, but most browsers allow different language preferences to be set.
Due to the configuration-based entropy increase, a modified value can be used to fingerprint the user. It's not recommended to change it and a website can't trust this value to reflect the actual intention of the user. It's best for site designers to avoid using language detection via this header as it can lead to a poor user experience.

They should always provide a way to override the server-chosen language, e.g., by providing a language menu on the site. Most user agents provide a default value for the Accept-Language header that's adapted to the user interface language. End users often don't modify it because they either don't know how or aren't able to do so based on their computing environment.
Once a user has overridden the server-chosen language, a site should no longer use language detection and should stick with the explicitly chosen language. In other words, only entry pages for a site should use this header to select the proper language.
The User-Agent header
Note:
Though there are legitimate uses of this header for selecting content, it's considered bad practice to rely on it to define what features are supported by the user agent.

The User-Agent header identifies the browser sending the request. This string may contain a space-separated list of product tokens and comments.
A product token is a name followed by a / and a version number, like Firefox/4.0.1. The user agent can include as many of these as it wants. A comment is an optional string delimited by parentheses. The information provided in a comment isn't standardized, though several browsers add several tokens to it separated by ;.The Vary response headerIn contrast to the previous Accept-* headers, which are sent by the client, the Vary HTTP header is sent by the web server in its response. It indicates the list of headers the server uses during the server-driven content negotiation phase. The Vary header is needed to inform the cache of the decision criteria so that it can reproduce it. This allows the cache to be functional while ensuring that the right content is served to the user.
The special value * means that the server-driven content negotiation also uses information not conveyed in a header to choose the appropriate content.
The Vary header was added in version 1.1 of HTTP and allows caches to work appropriately. To work with server-driven content negotiation, a cache needs to know which criteria the server used to select the transmitted content. That way, the cache can replay the algorithm and will be able to serve acceptable content directly, without more requests to the server. Obviously, the wildcard * prevents caching from occurring, as the cache can't know what element is behind it. For more information, see HTTP caching > Varying responses.Agent-driven negotiationServer-driven negotiation has a few drawbacks: it doesn't scale well. One header per feature is used in the negotiation. If you want to use screen size, resolution, or other dimensions, you need to create a new HTTP header. The headers must then be sent with every request. This isn't an issue if there are only a few headers, but as the number of headers increases, the message size could eventually affect performance. The more precisely headers are sent, the more entropy is sent, allowing for more HTTP fingerprinting and corresponding privacy concerns.
HTTP allows another negotiation type: agent-driven negotiation or reactive negotiation. In this case, the server sends back a page that contains links to the available alternative resources when faced with an ambiguous request. The user is presented the resources and chooses the one to use.

Unfortunately, the HTTP standard doesn't specify the format of the page for choosing between the available resources, which prevents the process from being automated. Besides falling back to the server-driven negotiation, this method is almost always used with scripting, especially with JavaScript redirection: after having checked for the negotiation criteria, the script performs the redirection. A second problem is that one more request is needed to fetch the real resource, slowing the availability of the resource to the user.See also
Caching
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Apr 10, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nContent negotiationIn HTTP, content negotiation is the mechanism that is used for serving different representations of a resource to the same URI to help the user agent specify which representation is best suited for the user (for example, which document language, which image format, or which content encoding).

Note:
You'll find some disadvantages of HTTP content negotiation in a wiki page from WHATWG. HTML provides alternatives to content negotiation via, for example, the <source> element.
Principles of content negotiationA specific document is called a resource. When a client wants to obtain a resource, the client requests it via a URL. The server uses this URL to choose one of the variants available–each variant is called a representation–and returns a specific representation to the client. The overall resource, as well as each of the representations, has a specific URL. Content negotiation determines how a specific representation is chosen when the resource is called. There are several ways of negotiating between the client and the server.

The best-suited representation is identified through one of two mechanisms:

Specific HTTP headers by the client (server-driven negotiation or proactive negotiation), which is the standard way of negotiating a specific kind of resource.
The 300 (Multiple Choices) or 406 (Not Acceptable), 415 (Unsupported Media Type) HTTP response codes by the server (agent-driven negotiation or reactive negotiation), that are used as fallback mechanisms.

Over the years, other content negotiation proposals, like transparent content negotiation and the Alternates header, have been proposed. They failed to get traction and were abandoned.Server-driven content negotiationIn server-driven content negotiation, or proactive content negotiation, the browser (or any other kind of user agent) sends several HTTP headers along with the URL. These headers describe the user's preferred choice. The server uses them as hints and an internal algorithm chooses the best content to serve to the client. If it can't provide a suitable resource, it might respond with 406 (Not Acceptable) or 415 (Unsupported Media Type) and set headers for the types of media that it does support (e.g., using the Accept-Post or Accept-Patch for POST and PATCH requests, respectively). The algorithm is server-specific and not defined in the standard. See the Apache negotiation algorithm.

The HTTP/1.1 standard defines list of the standard headers that start server-driven negotiation (such as Accept, Accept-Encoding, and Accept-Language). Though User-Agent isn't in this list, it's sometimes also used to send a specific representation of the requested resource. However, this isn't always considered a good practice. The server uses the Vary header to indicate which headers it actually used for content negotiation (or more precisely, the associated request headers), so that caches can work optimally.
In addition to these, there's an experimental proposal to add more headers to the list of available headers, called client hints. Client hints advertise what kind of device the user agent runs on (for example, a desktop computer or a mobile device).
Even if server-driven content negotiation is the most common way to agree on a specific representation of a resource, it has several drawbacks:

The server doesn't have total knowledge of the browser. Even with the Client Hints extension, it doesn't have a complete knowledge of the capabilities of the browser. Unlike reactive content negotiation where the client makes the choice, the server choice is always somewhat arbitrary.
The information from the client is quite verbose (HTTP/2 header compression mitigates this problem) and a privacy risk (HTTP fingerprinting).
As several representations of a given resource are sent, shared caches are less efficient and server implementations are more complex.
The Accept headerThe Accept header lists the MIME types of media resources that the agent is willing to process. This is a comma-separated list of MIME types, each combined with a quality factor, a parameter that indicates the relative degree of preference between the different MIME types.
The Accept header is defined by the browser, or any other user agent, and can vary according to the context. For example, fetching an HTML page or an image, a video, or a script. It's different when fetching a document entered in the address bar or an element linked via an <img>, <video>, or <audio> element. Browsers are free to use the value of the header that they think is the most adequate; an exhaustive list of default values for common browsers is available.The Accept-CH header
Note:
This is part of an experimental technology called Client Hints. Initial support comes in Chrome 46 or later. The Device-Memory value is in Chrome 61 or later.

The experimental Accept-CH lists configuration data that the server can use to select an appropriate response. Valid values are:



Value
Meaning




Device-Memory
Indicates the approximate amount of device RAM. This value is an approximation given by rounding to the nearest power of 2 and dividing that number by 1024. For example, 512 megabytes will be reported as 0.5.


Viewport-Width
Indicates the layout viewport width in CSS pixels.


Width
Indicates the resource width in physical pixels (in other words the intrinsic size of an image).


The Accept-Encoding headerThe Accept-Encoding header defines the acceptable content encoding (supported compressions). The value is a q-factor list (e.g., br, gzip;q=0.8) that indicates the priority of the encoding values. The default value identity is at the lowest priority (unless otherwise noted).
Compressing HTTP messages is one of the most important ways to improve the performance of a website. It shrinks the size of the data transmitted and makes better use of the available bandwidth. Browsers always send this header and the server should be configured to use compression.The Accept-Language headerThe Accept-Language header is used to indicate the language preference of the user. It's a list of values with quality factors (e.g., de, en;q=0.7). A default value is often set according to the language of the graphical interface of the user agent, but most browsers allow different language preferences to be set.
Due to the configuration-based entropy increase, a modified value can be used to fingerprint the user. It's not recommended to change it and a website can't trust this value to reflect the actual intention of the user. It's best for site designers to avoid using language detection via this header as it can lead to a poor user experience.

They should always provide a way to override the server-chosen language, e.g., by providing a language menu on the site. Most user agents provide a default value for the Accept-Language header that's adapted to the user interface language. End users often don't modify it because they either don't know how or aren't able to do so based on their computing environment.
Once a user has overridden the server-chosen language, a site should no longer use language detection and should stick with the explicitly chosen language. In other words, only entry pages for a site should use this header to select the proper language.
The User-Agent header
Note:
Though there are legitimate uses of this header for selecting content, it's considered bad practice to rely on it to define what features are supported by the user agent.

The User-Agent header identifies the browser sending the request. This string may contain a space-separated list of product tokens and comments.
A product token is a name followed by a / and a version number, like Firefox/4.0.1. The user agent can include as many of these as it wants. A comment is an optional string delimited by parentheses. The information provided in a comment isn't standardized, though several browsers add several tokens to it separated by ;.The Vary response headerIn contrast to the previous Accept-* headers, which are sent by the client, the Vary HTTP header is sent by the web server in its response. It indicates the list of headers the server uses during the server-driven content negotiation phase. The Vary header is needed to inform the cache of the decision criteria so that it can reproduce it. This allows the cache to be functional while ensuring that the right content is served to the user.
The special value * means that the server-driven content negotiation also uses information not conveyed in a header to choose the appropriate content.
The Vary header was added in version 1.1 of HTTP and allows caches to work appropriately. To work with server-driven content negotiation, a cache needs to know which criteria the server used to select the transmitted content. That way, the cache can replay the algorithm and will be able to serve acceptable content directly, without more requests to the server. Obviously, the wildcard * prevents caching from occurring, as the cache can't know what element is behind it. For more information, see HTTP caching > Varying responses.Agent-driven negotiationServer-driven negotiation has a few drawbacks: it doesn't scale well. One header per feature is used in the negotiation. If you want to use screen size, resolution, or other dimensions, you need to create a new HTTP header. The headers must then be sent with every request. This isn't an issue if there are only a few headers, but as the number of headers increases, the message size could eventually affect performance. The more precisely headers are sent, the more entropy is sent, allowing for more HTTP fingerprinting and corresponding privacy concerns.
HTTP allows another negotiation type: agent-driven negotiation or reactive negotiation. In this case, the server sends back a page that contains links to the available alternative resources when faced with an ambiguous request. The user is presented the resources and chooses the one to use.

Unfortunately, the HTTP standard doesn't specify the format of the page for choosing between the available resources, which prevents the process from being automated. Besides falling back to the server-driven negotiation, this method is almost always used with scripting, especially with JavaScript redirection: after having checked for the negotiation criteria, the script performs the redirection. A second problem is that one more request is needed to fetch the real resource, slowing the availability of the resource to the user.See also
Caching\n\nContent negotiationIn HTTP, content negotiation is the mechanism that is used for serving different representations of a resource to the same URI to help the user agent specify which representation is best suited for the user (for example, which document language, which image format, or which content encoding).

Note:
You'll find some disadvantages of HTTP content negotiation in a wiki page from WHATWG. HTML provides alternatives to content negotiation via, for example, the <source> element.
Principles of content negotiationA specific document is called a resource. When a client wants to obtain a resource, the client requests it via a URL. The server uses this URL to choose one of the variants available–each variant is called a representation–and returns a specific representation to the client. The overall resource, as well as each of the representations, has a specific URL. Content negotiation determines how a specific representation is chosen when the resource is called. There are several ways of negotiating between the client and the server.

The best-suited representation is identified through one of two mechanisms:

Specific HTTP headers by the client (server-driven negotiation or proactive negotiation), which is the standard way of negotiating a specific kind of resource.
The 300 (Multiple Choices) or 406 (Not Acceptable), 415 (Unsupported Media Type) HTTP response codes by the server (agent-driven negotiation or reactive negotiation), that are used as fallback mechanisms.

Over the years, other content negotiation proposals, like transparent content negotiation and the Alternates header, have been proposed. They failed to get traction and were abandoned.Server-driven content negotiationIn server-driven content negotiation, or proactive content negotiation, the browser (or any other kind of user agent) sends several HTTP headers along with the URL. These headers describe the user's preferred choice. The server uses them as hints and an internal algorithm chooses the best content to serve to the client. If it can't provide a suitable resource, it might respond with 406 (Not Acceptable) or 415 (Unsupported Media Type) and set headers for the types of media that it does support (e.g., using the Accept-Post or Accept-Patch for POST and PATCH requests, respectively). The algorithm is server-specific and not defined in the standard. See the Apache negotiation algorithm.

The HTTP/1.1 standard defines list of the standard headers that start server-driven negotiation (such as Accept, Accept-Encoding, and Accept-Language). Though User-Agent isn't in this list, it's sometimes also used to send a specific representation of the requested resource. However, this isn't always considered a good practice. The server uses the Vary header to indicate which headers it actually used for content negotiation (or more precisely, the associated request headers), so that caches can work optimally.
In addition to these, there's an experimental proposal to add more headers to the list of available headers, called client hints. Client hints advertise what kind of device the user agent runs on (for example, a desktop computer or a mobile device).
Even if server-driven content negotiation is the most common way to agree on a specific representation of a resource, it has several drawbacks:

The server doesn't have total knowledge of the browser. Even with the Client Hints extension, it doesn't have a complete knowledge of the capabilities of the browser. Unlike reactive content negotiation where the client makes the choice, the server choice is always somewhat arbitrary.
The information from the client is quite verbose (HTTP/2 header compression mitigates this problem) and a privacy risk (HTTP fingerprinting).
As several representations of a given resource are sent, shared caches are less efficient and server implementations are more complex.
The Accept headerThe Accept header lists the MIME types of media resources that the agent is willing to process. This is a comma-separated list of MIME types, each combined with a quality factor, a parameter that indicates the relative degree of preference between the different MIME types.
The Accept header is defined by the browser, or any other user agent, and can vary according to the context. For example, fetching an HTML page or an image, a video, or a script. It's different when fetching a document entered in the address bar or an element linked via an <img>, <video>, or <audio> element. Browsers are free to use the value of the header that they think is the most adequate; an exhaustive list of default values for common browsers is available.The Accept-CH header
Note:
This is part of an experimental technology called Client Hints. Initial support comes in Chrome 46 or later. The Device-Memory value is in Chrome 61 or later.

The experimental Accept-CH lists configuration data that the server can use to select an appropriate response. Valid values are:



Value
Meaning




Device-Memory
Indicates the approximate amount of device RAM. This value is an approximation given by rounding to the nearest power of 2 and dividing that number by 1024. For example, 512 megabytes will be reported as 0.5.


Viewport-Width
Indicates the layout viewport width in CSS pixels.


Width
Indicates the resource width in physical pixels (in other words the intrinsic size of an image).


The Accept-Encoding headerThe Accept-Encoding header defines the acceptable content encoding (supported compressions). The value is a q-factor list (e.g., br, gzip;q=0.8) that indicates the priority of the encoding values. The default value identity is at the lowest priority (unless otherwise noted).
Compressing HTTP messages is one of the most important ways to improve the performance of a website. It shrinks the size of the data transmitted and makes better use of the available bandwidth. Browsers always send this header and the server should be configured to use compression.The Accept-Language headerThe Accept-Language header is used to indicate the language preference of the user. It's a list of values with quality factors (e.g., de, en;q=0.7). A default value is often set according to the language of the graphical interface of the user agent, but most browsers allow different language preferences to be set.
Due to the configuration-based entropy increase, a modified value can be used to fingerprint the user. It's not recommended to change it and a website can't trust this value to reflect the actual intention of the user. It's best for site designers to avoid using language detection via this header as it can lead to a poor user experience.

They should always provide a way to override the server-chosen language, e.g., by providing a language menu on the site. Most user agents provide a default value for the Accept-Language header that's adapted to the user interface language. End users often don't modify it because they either don't know how or aren't able to do so based on their computing environment.
Once a user has overridden the server-chosen language, a site should no longer use language detection and should stick with the explicitly chosen language. In other words, only entry pages for a site should use this header to select the proper language.
The User-Agent header
Note:
Though there are legitimate uses of this header for selecting content, it's considered bad practice to rely on it to define what features are supported by the user agent.

The User-Agent header identifies the browser sending the request. This string may contain a space-separated list of product tokens and comments.
A product token is a name followed by a / and a version number, like Firefox/4.0.1. The user agent can include as many of these as it wants. A comment is an optional string delimited by parentheses. The information provided in a comment isn't standardized, though several browsers add several tokens to it separated by ;.The Vary response headerIn contrast to the previous Accept-* headers, which are sent by the client, the Vary HTTP header is sent by the web server in its response. It indicates the list of headers the server uses during the server-driven content negotiation phase. The Vary header is needed to inform the cache of the decision criteria so that it can reproduce it. This allows the cache to be functional while ensuring that the right content is served to the user.
The special value * means that the server-driven content negotiation also uses information not conveyed in a header to choose the appropriate content.
The Vary header was added in version 1.1 of HTTP and allows caches to work appropriately. To work with server-driven content negotiation, a cache needs to know which criteria the server used to select the transmitted content. That way, the cache can replay the algorithm and will be able to serve acceptable content directly, without more requests to the server. Obviously, the wildcard * prevents caching from occurring, as the cache can't know what element is behind it. For more information, see HTTP caching > Varying responses.Agent-driven negotiationServer-driven negotiation has a few drawbacks: it doesn't scale well. One header per feature is used in the negotiation. If you want to use screen size, resolution, or other dimensions, you need to create a new HTTP header. The headers must then be sent with every request. This isn't an issue if there are only a few headers, but as the number of headers increases, the message size could eventually affect performance. The more precisely headers are sent, the more entropy is sent, allowing for more HTTP fingerprinting and corresponding privacy concerns.
HTTP allows another negotiation type: agent-driven negotiation or reactive negotiation. In this case, the server sends back a page that contains links to the available alternative resources when faced with an ambiguous request. The user is presented the resources and chooses the one to use.

Unfortunately, the HTTP standard doesn't specify the format of the page for choosing between the available resources, which prevents the process from being automated. Besides falling back to the server-driven negotiation, this method is almost always used with scripting, especially with JavaScript redirection: after having checked for the negotiation criteria, the script performs the redirection. A second problem is that one more request is needed to fetch the real resource, slowing the availability of the resource to the user.See also
Caching
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Apr 10, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nContent negotiationIn HTTP, content negotiation is the mechanism that is used for serving different representations of a resource to the same URI to help the user agent specify which representation is best suited for the user (for example, which document language, which image format, or which content encoding).

Note:
You'll find some disadvantages of HTTP content negotiation in a wiki page from WHATWG. HTML provides alternatives to content negotiation via, for example, the <source> element.
Principles of content negotiationA specific document is called a resource. When a client wants to obtain a resource, the client requests it via a URL. The server uses this URL to choose one of the variants available–each variant is called a representation–and returns a specific representation to the client. The overall resource, as well as each of the representations, has a specific URL. Content negotiation determines how a specific representation is chosen when the resource is called. There are several ways of negotiating between the client and the server.

The best-suited representation is identified through one of two mechanisms:

Specific HTTP headers by the client (server-driven negotiation or proactive negotiation), which is the standard way of negotiating a specific kind of resource.
The 300 (Multiple Choices) or 406 (Not Acceptable), 415 (Unsupported Media Type) HTTP response codes by the server (agent-driven negotiation or reactive negotiation), that are used as fallback mechanisms.

Over the years, other content negotiation proposals, like transparent content negotiation and the Alternates header, have been proposed. They failed to get traction and were abandoned.Server-driven content negotiationIn server-driven content negotiation, or proactive content negotiation, the browser (or any other kind of user agent) sends several HTTP headers along with the URL. These headers describe the user's preferred choice. The server uses them as hints and an internal algorithm chooses the best content to serve to the client. If it can't provide a suitable resource, it might respond with 406 (Not Acceptable) or 415 (Unsupported Media Type) and set headers for the types of media that it does support (e.g., using the Accept-Post or Accept-Patch for POST and PATCH requests, respectively). The algorithm is server-specific and not defined in the standard. See the Apache negotiation algorithm.

The HTTP/1.1 standard defines list of the standard headers that start server-driven negotiation (such as Accept, Accept-Encoding, and Accept-Language). Though User-Agent isn't in this list, it's sometimes also used to send a specific representation of the requested resource. However, this isn't always considered a good practice. The server uses the Vary header to indicate which headers it actually used for content negotiation (or more precisely, the associated request headers), so that caches can work optimally.
In addition to these, there's an experimental proposal to add more headers to the list of available headers, called client hints. Client hints advertise what kind of device the user agent runs on (for example, a desktop computer or a mobile device).
Even if server-driven content negotiation is the most common way to agree on a specific representation of a resource, it has several drawbacks:

The server doesn't have total knowledge of the browser. Even with the Client Hints extension, it doesn't have a complete knowledge of the capabilities of the browser. Unlike reactive content negotiation where the client makes the choice, the server choice is always somewhat arbitrary.
The information from the client is quite verbose (HTTP/2 header compression mitigates this problem) and a privacy risk (HTTP fingerprinting).
As several representations of a given resource are sent, shared caches are less efficient and server implementations are more complex.
The Accept headerThe Accept header lists the MIME types of media resources that the agent is willing to process. This is a comma-separated list of MIME types, each combined with a quality factor, a parameter that indicates the relative degree of preference between the different MIME types.
The Accept header is defined by the browser, or any other user agent, and can vary according to the context. For example, fetching an HTML page or an image, a video, or a script. It's different when fetching a document entered in the address bar or an element linked via an <img>, <video>, or <audio> element. Browsers are free to use the value of the header that they think is the most adequate; an exhaustive list of default values for common browsers is available.The Accept-CH header
Note:
This is part of an experimental technology called Client Hints. Initial support comes in Chrome 46 or later. The Device-Memory value is in Chrome 61 or later.

The experimental Accept-CH lists configuration data that the server can use to select an appropriate response. Valid values are:



Value
Meaning




Device-Memory
Indicates the approximate amount of device RAM. This value is an approximation given by rounding to the nearest power of 2 and dividing that number by 1024. For example, 512 megabytes will be reported as 0.5.


Viewport-Width
Indicates the layout viewport width in CSS pixels.


Width
Indicates the resource width in physical pixels (in other words the intrinsic size of an image).


The Accept-Encoding headerThe Accept-Encoding header defines the acceptable content encoding (supported compressions). The value is a q-factor list (e.g., br, gzip;q=0.8) that indicates the priority of the encoding values. The default value identity is at the lowest priority (unless otherwise noted).
Compressing HTTP messages is one of the most important ways to improve the performance of a website. It shrinks the size of the data transmitted and makes better use of the available bandwidth. Browsers always send this header and the server should be configured to use compression.The Accept-Language headerThe Accept-Language header is used to indicate the language preference of the user. It's a list of values with quality factors (e.g., de, en;q=0.7). A default value is often set according to the language of the graphical interface of the user agent, but most browsers allow different language preferences to be set.
Due to the configuration-based entropy increase, a modified value can be used to fingerprint the user. It's not recommended to change it and a website can't trust this value to reflect the actual intention of the user. It's best for site designers to avoid using language detection via this header as it can lead to a poor user experience.

They should always provide a way to override the server-chosen language, e.g., by providing a language menu on the site. Most user agents provide a default value for the Accept-Language header that's adapted to the user interface language. End users often don't modify it because they either don't know how or aren't able to do so based on their computing environment.
Once a user has overridden the server-chosen language, a site should no longer use language detection and should stick with the explicitly chosen language. In other words, only entry pages for a site should use this header to select the proper language.
The User-Agent header
Note:
Though there are legitimate uses of this header for selecting content, it's considered bad practice to rely on it to define what features are supported by the user agent.

The User-Agent header identifies the browser sending the request. This string may contain a space-separated list of product tokens and comments.
A product token is a name followed by a / and a version number, like Firefox/4.0.1. The user agent can include as many of these as it wants. A comment is an optional string delimited by parentheses. The information provided in a comment isn't standardized, though several browsers add several tokens to it separated by ;.The Vary response headerIn contrast to the previous Accept-* headers, which are sent by the client, the Vary HTTP header is sent by the web server in its response. It indicates the list of headers the server uses during the server-driven content negotiation phase. The Vary header is needed to inform the cache of the decision criteria so that it can reproduce it. This allows the cache to be functional while ensuring that the right content is served to the user.
The special value * means that the server-driven content negotiation also uses information not conveyed in a header to choose the appropriate content.
The Vary header was added in version 1.1 of HTTP and allows caches to work appropriately. To work with server-driven content negotiation, a cache needs to know which criteria the server used to select the transmitted content. That way, the cache can replay the algorithm and will be able to serve acceptable content directly, without more requests to the server. Obviously, the wildcard * prevents caching from occurring, as the cache can't know what element is behind it. For more information, see HTTP caching > Varying responses.Agent-driven negotiationServer-driven negotiation has a few drawbacks: it doesn't scale well. One header per feature is used in the negotiation. If you want to use screen size, resolution, or other dimensions, you need to create a new HTTP header. The headers must then be sent with every request. This isn't an issue if there are only a few headers, but as the number of headers increases, the message size could eventually affect performance. The more precisely headers are sent, the more entropy is sent, allowing for more HTTP fingerprinting and corresponding privacy concerns.
HTTP allows another negotiation type: agent-driven negotiation or reactive negotiation. In this case, the server sends back a page that contains links to the available alternative resources when faced with an ambiguous request. The user is presented the resources and chooses the one to use.

Unfortunately, the HTTP standard doesn't specify the format of the page for choosing between the available resources, which prevents the process from being automated. Besides falling back to the server-driven negotiation, this method is almost always used with scripting, especially with JavaScript redirection: after having checked for the negotiation criteria, the script performs the redirection. A second problem is that one more request is needed to fetch the real resource, slowing the availability of the resource to the user.See also
Caching
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Apr 10, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nAn overview of HTTPHTTP is a protocol for fetching resources such as HTML documents.
It is the foundation of any data exchange on the Web and it is a client-server protocol, which means requests are initiated by the recipient, usually the Web browser.
A complete document is typically constructed from resources such as text content, layout instructions, images, videos, scripts, and more.

Clients and servers communicate by exchanging individual messages (as opposed to a stream of data).
The messages sent by the client are called requests and the messages sent by the server as an answer are called responses.

Designed in the early 1990s, HTTP is an extensible protocol which has evolved over time.
It is an application layer protocol that is sent over TCP, or over a TLS-encrypted TCP connection, though any reliable transport protocol could theoretically be used.
Due to its extensibility, it is used to not only fetch hypertext documents, but also images and videos or to post content to servers, like with HTML form results.
HTTP can also be used to fetch parts of documents to update Web pages on demand.Components of HTTP-based systemsHTTP is a client-server protocol: requests are sent by one entity, the user-agent (or a proxy on behalf of it).
Most of the time the user-agent is a Web browser, but it can be anything, for example, a robot that crawls the Web to populate and maintain a search engine index.
Each individual request is sent to a server, which handles it and provides an answer called the response.
Between the client and the server there are numerous entities, collectively called proxies, which perform different operations and act as gateways or caches, for example.

In reality, there are more computers between a browser and the server handling the request: there are routers, modems, and more.
Thanks to the layered design of the Web, these are hidden in the network and transport layers.
HTTP is on top, at the application layer.
Although important for diagnosing network problems, the underlying layers are mostly irrelevant to the description of HTTP.Client: the user-agentThe user-agent is any tool that acts on behalf of the user.
This role is primarily performed by the Web browser, but it may also be performed by programs used by engineers and Web developers to debug their applications.
The browser is always the entity initiating the request.
It is never the server (though some mechanisms have been added over the years to simulate server-initiated messages).
To display a Web page, the browser sends an original request to fetch the HTML document that represents the page.
It then parses this file, making additional requests corresponding to execution scripts, layout information (CSS) to display, and sub-resources contained within the page (usually images and videos).
The Web browser then combines these resources to present the complete document, the Web page.
Scripts executed by the browser can fetch more resources in later phases and the browser updates the Web page accordingly.
A Web page is a hypertext document.
This means some parts of the displayed content are links, which can be activated (usually by a click of the mouse) to fetch a new Web page, allowing the user to direct their user-agent and navigate through the Web.
The browser translates these directions into HTTP requests, and further interprets the HTTP responses to present the user with a clear response.The Web serverOn the opposite side of the communication channel is the server, which serves the document as requested by the client.
A server appears as only a single machine virtually; but it may actually be a collection of servers sharing the load (load balancing), or other software (such as caches, a database server, or e-commerce servers), totally or partially generating the document on demand.
A server is not necessarily a single machine, but several server software instances can be hosted on the same machine.
With HTTP/1.1 and the Host header, they may even share the same IP address.ProxiesBetween the Web browser and the server, numerous computers and machines relay the HTTP messages.
Due to the layered structure of the Web stack, most of these operate at the transport, network or physical levels, becoming transparent at the HTTP layer and potentially having a significant impact on performance.
Those operating at the application layers are generally called proxies.
These can be transparent, forwarding on the requests they receive without altering them in any way, or non-transparent, in which case they will change the request in some way before passing it along to the server.
Proxies may perform numerous functions:

caching (the cache can be public or private, like the browser cache)
filtering (like an antivirus scan or parental controls)
load balancing (to allow multiple servers to serve different requests)
authentication (to control access to different resources)
logging (allowing the storage of historical information)
Basic aspects of HTTPHTTP is simpleHTTP is generally designed to be human-readable, even with the added complexity introduced in HTTP/2 by encapsulating HTTP messages into frames.
HTTP messages can be read and understood by humans, providing easier testing for developers, and reduced complexity for newcomers.HTTP is extensibleIntroduced in HTTP/1.0, HTTP headers make this protocol easy to extend and experiment with.
New functionality can even be introduced by an agreement between a client and a server about a new header's semantics.HTTP is stateless, but not sessionlessHTTP is stateless: there is no link between two requests being successively carried out on the same connection.
This immediately has the prospect of being problematic for users attempting to interact with certain pages coherently, for example, using e-commerce shopping baskets.
But while the core of HTTP itself is stateless, HTTP cookies allow the use of stateful sessions.
Using header extensibility, HTTP Cookies are added to the workflow, allowing session creation on each HTTP request to share the same context, or the same state.HTTP and connectionsA connection is controlled at the transport layer, and therefore fundamentally out of scope for HTTP.
HTTP doesn't require the underlying transport protocol to be connection-based; it only requires it to be reliable, or not lose messages (at minimum, presenting an error in such cases).
Among the two most common transport protocols on the Internet, TCP is reliable and UDP isn't.
HTTP therefore relies on the TCP standard, which is connection-based.
Before a client and server can exchange an HTTP request/response pair, they must establish a TCP connection, a process which requires several round-trips.
The default behavior of HTTP/1.0 is to open a separate TCP connection for each HTTP request/response pair.
This is less efficient than sharing a single TCP connection when multiple requests are sent in close succession.
In order to mitigate this flaw, HTTP/1.1 introduced pipelining (which proved difficult to implement) and persistent connections: the underlying TCP connection can be partially controlled using the Connection header.
HTTP/2 went a step further by multiplexing messages over a single connection, helping keep the connection warm and more efficient.
Experiments are in progress to design a better transport protocol more suited to HTTP.
For example, Google is experimenting with QUIC which builds on UDP to provide a more reliable and efficient transport protocol.What can be controlled by HTTPThis extensible nature of HTTP has, over time, allowed for more control and functionality of the Web.
Cache and authentication methods were functions handled early in HTTP history.
The ability to relax the origin constraint, by contrast, was only added in the 2010s.
Here is a list of common features controllable with HTTP:

Caching:
How documents are cached can be controlled by HTTP.
The server can instruct proxies and clients about what to cache and for how long.
The client can instruct intermediate cache proxies to ignore the stored document.
Relaxing the origin constraint:
To prevent snooping and other privacy invasions, Web browsers enforce strict separation between websites.
Only pages from the same origin can access all the information of a Web page.
Though such a constraint is a burden to the server, HTTP headers can relax this strict separation on the server side, allowing a document to become a patchwork of information sourced from different domains; there could even be security-related reasons to do so.
Authentication:
Some pages may be protected so that only specific users can access them.
Basic authentication may be provided by HTTP, either using the WWW-Authenticate and similar headers, or by setting a specific session using HTTP cookies.
Proxy and tunneling:
Servers or clients are often located on intranets and hide their true IP address from other computers.
HTTP requests then go through proxies to cross this network barrier.
Not all proxies are HTTP proxies.
The SOCKS protocol, for example, operates at a lower level.
Other protocols, like ftp, can be handled by these proxies.
Sessions:
Using HTTP cookies allows you to link requests with the state of the server.
This creates sessions, despite basic HTTP being a state-less protocol.
This is useful not only for e-commerce shopping baskets, but also for any site allowing user configuration of the output.
HTTP flowWhen a client wants to communicate with a server, either the final server or an intermediate proxy, it performs the following steps:


Open a TCP connection: The TCP connection is used to send a request, or several, and receive an answer.
The client may open a new connection, reuse an existing connection, or open several TCP connections to the servers.


Send an HTTP message: HTTP messages (before HTTP/2) are human-readable.
With HTTP/2, these messages are encapsulated in frames, making them impossible to read directly, but the principle remains the same.
For example:
httpGET / HTTP/1.1
Host: developer.mozilla.org
Accept-Language: fr



Read the response sent by the server, such as:
httpHTTP/1.1 200 OK
Date: Sat, 09 Oct 2010 14:28:02 GMT
Server: Apache
Last-Modified: Tue, 01 Dec 2009 20:18:22 GMT
ETag: "51142bc1-7449-479b075b2891b"
Accept-Ranges: bytes
Content-Length: 29769
Content-Type: text/html

<!doctype html>… (here come the 29769 bytes of the requested web page)



Close or reuse the connection for further requests.


If HTTP pipelining is activated, several requests can be sent without waiting for the first response to be fully received.
HTTP pipelining has proven difficult to implement in existing networks, where old pieces of software coexist with modern versions.
HTTP pipelining has been superseded in HTTP/2 with more robust multiplexing requests within a frame.HTTP MessagesHTTP messages, as defined in HTTP/1.1 and earlier, are human-readable.
In HTTP/2, these messages are embedded into a binary structure, a frame, allowing optimizations like compression of headers and multiplexing.
Even if only part of the original HTTP message is sent in this version of HTTP, the semantics of each message is unchanged and the client reconstitutes (virtually) the original HTTP/1.1 request.
It is therefore useful to comprehend HTTP/2 messages in the HTTP/1.1 format.
There are two types of HTTP messages, requests and responses, each with its own format.RequestsAn example HTTP request:

Requests consist of the following elements:

An HTTP method, usually a verb like GET, POST, or a noun like OPTIONS or HEAD that defines the operation the client wants to perform.
Typically, a client wants to fetch a resource (using GET) or post the value of an HTML form (using POST), though more operations may be needed in other cases.
The path of the resource to fetch; the URL of the resource stripped from elements that are obvious from the context, for example without the protocol (http://), the domain (here, developer.mozilla.org), or the TCP port (here, 80).
The version of the HTTP protocol.
Optional headers that convey additional information for the servers.
A body, for some methods like POST, similar to those in responses, which contain the resource sent.
ResponsesAn example response:

Responses consist of the following elements:

The version of the HTTP protocol they follow.
A status code, indicating if the request was successful or not, and why.
A status message, a non-authoritative short description of the status code.
HTTP headers, like those for requests.
Optionally, a body containing the fetched resource.
APIs based on HTTPThe most commonly used API based on HTTP is the Fetch API, which can be used to make HTTP requests from JavaScript. The Fetch API replaces the XMLHttpRequest API.
Another API, server-sent events, is a one-way service that allows a server to send events to the client, using HTTP as a transport mechanism.
Using the EventSource interface, the client opens a connection and establishes event handlers.
The client browser automatically converts the messages that arrive on the HTTP stream into appropriate Event objects. Then it delivers them to the event handlers that have been registered for the events' type if known, or to the onmessage event handler if no type-specific event handler was established.ConclusionHTTP is an extensible protocol that is easy to use.
The client-server structure, combined with the ability to add headers, allows HTTP to advance along with the extended capabilities of the Web.
Though HTTP/2 adds some complexity by embedding HTTP messages in frames to improve performance, the basic structure of messages has stayed the same since HTTP/1.0.
Session flow remains basic, allowing it to be investigated and debugged with a HTTP network monitor.See also
Evolution of HTTP
Glossary terms:

HTTP
HTTP/2
QUIC\n\nAn overview of HTTPHTTP is a protocol for fetching resources such as HTML documents.
It is the foundation of any data exchange on the Web and it is a client-server protocol, which means requests are initiated by the recipient, usually the Web browser.
A complete document is typically constructed from resources such as text content, layout instructions, images, videos, scripts, and more.

Clients and servers communicate by exchanging individual messages (as opposed to a stream of data).
The messages sent by the client are called requests and the messages sent by the server as an answer are called responses.

Designed in the early 1990s, HTTP is an extensible protocol which has evolved over time.
It is an application layer protocol that is sent over TCP, or over a TLS-encrypted TCP connection, though any reliable transport protocol could theoretically be used.
Due to its extensibility, it is used to not only fetch hypertext documents, but also images and videos or to post content to servers, like with HTML form results.
HTTP can also be used to fetch parts of documents to update Web pages on demand.Components of HTTP-based systemsHTTP is a client-server protocol: requests are sent by one entity, the user-agent (or a proxy on behalf of it).
Most of the time the user-agent is a Web browser, but it can be anything, for example, a robot that crawls the Web to populate and maintain a search engine index.
Each individual request is sent to a server, which handles it and provides an answer called the response.
Between the client and the server there are numerous entities, collectively called proxies, which perform different operations and act as gateways or caches, for example.

In reality, there are more computers between a browser and the server handling the request: there are routers, modems, and more.
Thanks to the layered design of the Web, these are hidden in the network and transport layers.
HTTP is on top, at the application layer.
Although important for diagnosing network problems, the underlying layers are mostly irrelevant to the description of HTTP.Client: the user-agentThe user-agent is any tool that acts on behalf of the user.
This role is primarily performed by the Web browser, but it may also be performed by programs used by engineers and Web developers to debug their applications.
The browser is always the entity initiating the request.
It is never the server (though some mechanisms have been added over the years to simulate server-initiated messages).
To display a Web page, the browser sends an original request to fetch the HTML document that represents the page.
It then parses this file, making additional requests corresponding to execution scripts, layout information (CSS) to display, and sub-resources contained within the page (usually images and videos).
The Web browser then combines these resources to present the complete document, the Web page.
Scripts executed by the browser can fetch more resources in later phases and the browser updates the Web page accordingly.
A Web page is a hypertext document.
This means some parts of the displayed content are links, which can be activated (usually by a click of the mouse) to fetch a new Web page, allowing the user to direct their user-agent and navigate through the Web.
The browser translates these directions into HTTP requests, and further interprets the HTTP responses to present the user with a clear response.The Web serverOn the opposite side of the communication channel is the server, which serves the document as requested by the client.
A server appears as only a single machine virtually; but it may actually be a collection of servers sharing the load (load balancing), or other software (such as caches, a database server, or e-commerce servers), totally or partially generating the document on demand.
A server is not necessarily a single machine, but several server software instances can be hosted on the same machine.
With HTTP/1.1 and the Host header, they may even share the same IP address.ProxiesBetween the Web browser and the server, numerous computers and machines relay the HTTP messages.
Due to the layered structure of the Web stack, most of these operate at the transport, network or physical levels, becoming transparent at the HTTP layer and potentially having a significant impact on performance.
Those operating at the application layers are generally called proxies.
These can be transparent, forwarding on the requests they receive without altering them in any way, or non-transparent, in which case they will change the request in some way before passing it along to the server.
Proxies may perform numerous functions:

caching (the cache can be public or private, like the browser cache)
filtering (like an antivirus scan or parental controls)
load balancing (to allow multiple servers to serve different requests)
authentication (to control access to different resources)
logging (allowing the storage of historical information)
Basic aspects of HTTPHTTP is simpleHTTP is generally designed to be human-readable, even with the added complexity introduced in HTTP/2 by encapsulating HTTP messages into frames.
HTTP messages can be read and understood by humans, providing easier testing for developers, and reduced complexity for newcomers.HTTP is extensibleIntroduced in HTTP/1.0, HTTP headers make this protocol easy to extend and experiment with.
New functionality can even be introduced by an agreement between a client and a server about a new header's semantics.HTTP is stateless, but not sessionlessHTTP is stateless: there is no link between two requests being successively carried out on the same connection.
This immediately has the prospect of being problematic for users attempting to interact with certain pages coherently, for example, using e-commerce shopping baskets.
But while the core of HTTP itself is stateless, HTTP cookies allow the use of stateful sessions.
Using header extensibility, HTTP Cookies are added to the workflow, allowing session creation on each HTTP request to share the same context, or the same state.HTTP and connectionsA connection is controlled at the transport layer, and therefore fundamentally out of scope for HTTP.
HTTP doesn't require the underlying transport protocol to be connection-based; it only requires it to be reliable, or not lose messages (at minimum, presenting an error in such cases).
Among the two most common transport protocols on the Internet, TCP is reliable and UDP isn't.
HTTP therefore relies on the TCP standard, which is connection-based.
Before a client and server can exchange an HTTP request/response pair, they must establish a TCP connection, a process which requires several round-trips.
The default behavior of HTTP/1.0 is to open a separate TCP connection for each HTTP request/response pair.
This is less efficient than sharing a single TCP connection when multiple requests are sent in close succession.
In order to mitigate this flaw, HTTP/1.1 introduced pipelining (which proved difficult to implement) and persistent connections: the underlying TCP connection can be partially controlled using the Connection header.
HTTP/2 went a step further by multiplexing messages over a single connection, helping keep the connection warm and more efficient.
Experiments are in progress to design a better transport protocol more suited to HTTP.
For example, Google is experimenting with QUIC which builds on UDP to provide a more reliable and efficient transport protocol.What can be controlled by HTTPThis extensible nature of HTTP has, over time, allowed for more control and functionality of the Web.
Cache and authentication methods were functions handled early in HTTP history.
The ability to relax the origin constraint, by contrast, was only added in the 2010s.
Here is a list of common features controllable with HTTP:

Caching:
How documents are cached can be controlled by HTTP.
The server can instruct proxies and clients about what to cache and for how long.
The client can instruct intermediate cache proxies to ignore the stored document.
Relaxing the origin constraint:
To prevent snooping and other privacy invasions, Web browsers enforce strict separation between websites.
Only pages from the same origin can access all the information of a Web page.
Though such a constraint is a burden to the server, HTTP headers can relax this strict separation on the server side, allowing a document to become a patchwork of information sourced from different domains; there could even be security-related reasons to do so.
Authentication:
Some pages may be protected so that only specific users can access them.
Basic authentication may be provided by HTTP, either using the WWW-Authenticate and similar headers, or by setting a specific session using HTTP cookies.
Proxy and tunneling:
Servers or clients are often located on intranets and hide their true IP address from other computers.
HTTP requests then go through proxies to cross this network barrier.
Not all proxies are HTTP proxies.
The SOCKS protocol, for example, operates at a lower level.
Other protocols, like ftp, can be handled by these proxies.
Sessions:
Using HTTP cookies allows you to link requests with the state of the server.
This creates sessions, despite basic HTTP being a state-less protocol.
This is useful not only for e-commerce shopping baskets, but also for any site allowing user configuration of the output.
HTTP flowWhen a client wants to communicate with a server, either the final server or an intermediate proxy, it performs the following steps:


Open a TCP connection: The TCP connection is used to send a request, or several, and receive an answer.
The client may open a new connection, reuse an existing connection, or open several TCP connections to the servers.


Send an HTTP message: HTTP messages (before HTTP/2) are human-readable.
With HTTP/2, these messages are encapsulated in frames, making them impossible to read directly, but the principle remains the same.
For example:
httpGET / HTTP/1.1
Host: developer.mozilla.org
Accept-Language: fr



Read the response sent by the server, such as:
httpHTTP/1.1 200 OK
Date: Sat, 09 Oct 2010 14:28:02 GMT
Server: Apache
Last-Modified: Tue, 01 Dec 2009 20:18:22 GMT
ETag: "51142bc1-7449-479b075b2891b"
Accept-Ranges: bytes
Content-Length: 29769
Content-Type: text/html

<!doctype html>… (here come the 29769 bytes of the requested web page)



Close or reuse the connection for further requests.


If HTTP pipelining is activated, several requests can be sent without waiting for the first response to be fully received.
HTTP pipelining has proven difficult to implement in existing networks, where old pieces of software coexist with modern versions.
HTTP pipelining has been superseded in HTTP/2 with more robust multiplexing requests within a frame.HTTP MessagesHTTP messages, as defined in HTTP/1.1 and earlier, are human-readable.
In HTTP/2, these messages are embedded into a binary structure, a frame, allowing optimizations like compression of headers and multiplexing.
Even if only part of the original HTTP message is sent in this version of HTTP, the semantics of each message is unchanged and the client reconstitutes (virtually) the original HTTP/1.1 request.
It is therefore useful to comprehend HTTP/2 messages in the HTTP/1.1 format.
There are two types of HTTP messages, requests and responses, each with its own format.RequestsAn example HTTP request:

Requests consist of the following elements:

An HTTP method, usually a verb like GET, POST, or a noun like OPTIONS or HEAD that defines the operation the client wants to perform.
Typically, a client wants to fetch a resource (using GET) or post the value of an HTML form (using POST), though more operations may be needed in other cases.
The path of the resource to fetch; the URL of the resource stripped from elements that are obvious from the context, for example without the protocol (http://), the domain (here, developer.mozilla.org), or the TCP port (here, 80).
The version of the HTTP protocol.
Optional headers that convey additional information for the servers.
A body, for some methods like POST, similar to those in responses, which contain the resource sent.
ResponsesAn example response:

Responses consist of the following elements:

The version of the HTTP protocol they follow.
A status code, indicating if the request was successful or not, and why.
A status message, a non-authoritative short description of the status code.
HTTP headers, like those for requests.
Optionally, a body containing the fetched resource.
APIs based on HTTPThe most commonly used API based on HTTP is the Fetch API, which can be used to make HTTP requests from JavaScript. The Fetch API replaces the XMLHttpRequest API.
Another API, server-sent events, is a one-way service that allows a server to send events to the client, using HTTP as a transport mechanism.
Using the EventSource interface, the client opens a connection and establishes event handlers.
The client browser automatically converts the messages that arrive on the HTTP stream into appropriate Event objects. Then it delivers them to the event handlers that have been registered for the events' type if known, or to the onmessage event handler if no type-specific event handler was established.ConclusionHTTP is an extensible protocol that is easy to use.
The client-server structure, combined with the ability to add headers, allows HTTP to advance along with the extended capabilities of the Web.
Though HTTP/2 adds some complexity by embedding HTTP messages in frames to improve performance, the basic structure of messages has stayed the same since HTTP/1.0.
Session flow remains basic, allowing it to be investigated and debugged with a HTTP network monitor.See also
Evolution of HTTP
Glossary terms:

HTTP
HTTP/2
QUIC


Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 14, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nAn overview of HTTPHTTP is a protocol for fetching resources such as HTML documents.
It is the foundation of any data exchange on the Web and it is a client-server protocol, which means requests are initiated by the recipient, usually the Web browser.
A complete document is typically constructed from resources such as text content, layout instructions, images, videos, scripts, and more.

Clients and servers communicate by exchanging individual messages (as opposed to a stream of data).
The messages sent by the client are called requests and the messages sent by the server as an answer are called responses.

Designed in the early 1990s, HTTP is an extensible protocol which has evolved over time.
It is an application layer protocol that is sent over TCP, or over a TLS-encrypted TCP connection, though any reliable transport protocol could theoretically be used.
Due to its extensibility, it is used to not only fetch hypertext documents, but also images and videos or to post content to servers, like with HTML form results.
HTTP can also be used to fetch parts of documents to update Web pages on demand.Components of HTTP-based systemsHTTP is a client-server protocol: requests are sent by one entity, the user-agent (or a proxy on behalf of it).
Most of the time the user-agent is a Web browser, but it can be anything, for example, a robot that crawls the Web to populate and maintain a search engine index.
Each individual request is sent to a server, which handles it and provides an answer called the response.
Between the client and the server there are numerous entities, collectively called proxies, which perform different operations and act as gateways or caches, for example.

In reality, there are more computers between a browser and the server handling the request: there are routers, modems, and more.
Thanks to the layered design of the Web, these are hidden in the network and transport layers.
HTTP is on top, at the application layer.
Although important for diagnosing network problems, the underlying layers are mostly irrelevant to the description of HTTP.Client: the user-agentThe user-agent is any tool that acts on behalf of the user.
This role is primarily performed by the Web browser, but it may also be performed by programs used by engineers and Web developers to debug their applications.
The browser is always the entity initiating the request.
It is never the server (though some mechanisms have been added over the years to simulate server-initiated messages).
To display a Web page, the browser sends an original request to fetch the HTML document that represents the page.
It then parses this file, making additional requests corresponding to execution scripts, layout information (CSS) to display, and sub-resources contained within the page (usually images and videos).
The Web browser then combines these resources to present the complete document, the Web page.
Scripts executed by the browser can fetch more resources in later phases and the browser updates the Web page accordingly.
A Web page is a hypertext document.
This means some parts of the displayed content are links, which can be activated (usually by a click of the mouse) to fetch a new Web page, allowing the user to direct their user-agent and navigate through the Web.
The browser translates these directions into HTTP requests, and further interprets the HTTP responses to present the user with a clear response.The Web serverOn the opposite side of the communication channel is the server, which serves the document as requested by the client.
A server appears as only a single machine virtually; but it may actually be a collection of servers sharing the load (load balancing), or other software (such as caches, a database server, or e-commerce servers), totally or partially generating the document on demand.
A server is not necessarily a single machine, but several server software instances can be hosted on the same machine.
With HTTP/1.1 and the Host header, they may even share the same IP address.ProxiesBetween the Web browser and the server, numerous computers and machines relay the HTTP messages.
Due to the layered structure of the Web stack, most of these operate at the transport, network or physical levels, becoming transparent at the HTTP layer and potentially having a significant impact on performance.
Those operating at the application layers are generally called proxies.
These can be transparent, forwarding on the requests they receive without altering them in any way, or non-transparent, in which case they will change the request in some way before passing it along to the server.
Proxies may perform numerous functions:

caching (the cache can be public or private, like the browser cache)
filtering (like an antivirus scan or parental controls)
load balancing (to allow multiple servers to serve different requests)
authentication (to control access to different resources)
logging (allowing the storage of historical information)
Basic aspects of HTTPHTTP is simpleHTTP is generally designed to be human-readable, even with the added complexity introduced in HTTP/2 by encapsulating HTTP messages into frames.
HTTP messages can be read and understood by humans, providing easier testing for developers, and reduced complexity for newcomers.HTTP is extensibleIntroduced in HTTP/1.0, HTTP headers make this protocol easy to extend and experiment with.
New functionality can even be introduced by an agreement between a client and a server about a new header's semantics.HTTP is stateless, but not sessionlessHTTP is stateless: there is no link between two requests being successively carried out on the same connection.
This immediately has the prospect of being problematic for users attempting to interact with certain pages coherently, for example, using e-commerce shopping baskets.
But while the core of HTTP itself is stateless, HTTP cookies allow the use of stateful sessions.
Using header extensibility, HTTP Cookies are added to the workflow, allowing session creation on each HTTP request to share the same context, or the same state.HTTP and connectionsA connection is controlled at the transport layer, and therefore fundamentally out of scope for HTTP.
HTTP doesn't require the underlying transport protocol to be connection-based; it only requires it to be reliable, or not lose messages (at minimum, presenting an error in such cases).
Among the two most common transport protocols on the Internet, TCP is reliable and UDP isn't.
HTTP therefore relies on the TCP standard, which is connection-based.
Before a client and server can exchange an HTTP request/response pair, they must establish a TCP connection, a process which requires several round-trips.
The default behavior of HTTP/1.0 is to open a separate TCP connection for each HTTP request/response pair.
This is less efficient than sharing a single TCP connection when multiple requests are sent in close succession.
In order to mitigate this flaw, HTTP/1.1 introduced pipelining (which proved difficult to implement) and persistent connections: the underlying TCP connection can be partially controlled using the Connection header.
HTTP/2 went a step further by multiplexing messages over a single connection, helping keep the connection warm and more efficient.
Experiments are in progress to design a better transport protocol more suited to HTTP.
For example, Google is experimenting with QUIC which builds on UDP to provide a more reliable and efficient transport protocol.What can be controlled by HTTPThis extensible nature of HTTP has, over time, allowed for more control and functionality of the Web.
Cache and authentication methods were functions handled early in HTTP history.
The ability to relax the origin constraint, by contrast, was only added in the 2010s.
Here is a list of common features controllable with HTTP:

Caching:
How documents are cached can be controlled by HTTP.
The server can instruct proxies and clients about what to cache and for how long.
The client can instruct intermediate cache proxies to ignore the stored document.
Relaxing the origin constraint:
To prevent snooping and other privacy invasions, Web browsers enforce strict separation between websites.
Only pages from the same origin can access all the information of a Web page.
Though such a constraint is a burden to the server, HTTP headers can relax this strict separation on the server side, allowing a document to become a patchwork of information sourced from different domains; there could even be security-related reasons to do so.
Authentication:
Some pages may be protected so that only specific users can access them.
Basic authentication may be provided by HTTP, either using the WWW-Authenticate and similar headers, or by setting a specific session using HTTP cookies.
Proxy and tunneling:
Servers or clients are often located on intranets and hide their true IP address from other computers.
HTTP requests then go through proxies to cross this network barrier.
Not all proxies are HTTP proxies.
The SOCKS protocol, for example, operates at a lower level.
Other protocols, like ftp, can be handled by these proxies.
Sessions:
Using HTTP cookies allows you to link requests with the state of the server.
This creates sessions, despite basic HTTP being a state-less protocol.
This is useful not only for e-commerce shopping baskets, but also for any site allowing user configuration of the output.
HTTP flowWhen a client wants to communicate with a server, either the final server or an intermediate proxy, it performs the following steps:


Open a TCP connection: The TCP connection is used to send a request, or several, and receive an answer.
The client may open a new connection, reuse an existing connection, or open several TCP connections to the servers.


Send an HTTP message: HTTP messages (before HTTP/2) are human-readable.
With HTTP/2, these messages are encapsulated in frames, making them impossible to read directly, but the principle remains the same.
For example:
httpGET / HTTP/1.1
Host: developer.mozilla.org
Accept-Language: fr



Read the response sent by the server, such as:
httpHTTP/1.1 200 OK
Date: Sat, 09 Oct 2010 14:28:02 GMT
Server: Apache
Last-Modified: Tue, 01 Dec 2009 20:18:22 GMT
ETag: "51142bc1-7449-479b075b2891b"
Accept-Ranges: bytes
Content-Length: 29769
Content-Type: text/html

<!doctype html>… (here come the 29769 bytes of the requested web page)



Close or reuse the connection for further requests.


If HTTP pipelining is activated, several requests can be sent without waiting for the first response to be fully received.
HTTP pipelining has proven difficult to implement in existing networks, where old pieces of software coexist with modern versions.
HTTP pipelining has been superseded in HTTP/2 with more robust multiplexing requests within a frame.HTTP MessagesHTTP messages, as defined in HTTP/1.1 and earlier, are human-readable.
In HTTP/2, these messages are embedded into a binary structure, a frame, allowing optimizations like compression of headers and multiplexing.
Even if only part of the original HTTP message is sent in this version of HTTP, the semantics of each message is unchanged and the client reconstitutes (virtually) the original HTTP/1.1 request.
It is therefore useful to comprehend HTTP/2 messages in the HTTP/1.1 format.
There are two types of HTTP messages, requests and responses, each with its own format.RequestsAn example HTTP request:

Requests consist of the following elements:

An HTTP method, usually a verb like GET, POST, or a noun like OPTIONS or HEAD that defines the operation the client wants to perform.
Typically, a client wants to fetch a resource (using GET) or post the value of an HTML form (using POST), though more operations may be needed in other cases.
The path of the resource to fetch; the URL of the resource stripped from elements that are obvious from the context, for example without the protocol (http://), the domain (here, developer.mozilla.org), or the TCP port (here, 80).
The version of the HTTP protocol.
Optional headers that convey additional information for the servers.
A body, for some methods like POST, similar to those in responses, which contain the resource sent.
ResponsesAn example response:

Responses consist of the following elements:

The version of the HTTP protocol they follow.
A status code, indicating if the request was successful or not, and why.
A status message, a non-authoritative short description of the status code.
HTTP headers, like those for requests.
Optionally, a body containing the fetched resource.
APIs based on HTTPThe most commonly used API based on HTTP is the Fetch API, which can be used to make HTTP requests from JavaScript. The Fetch API replaces the XMLHttpRequest API.
Another API, server-sent events, is a one-way service that allows a server to send events to the client, using HTTP as a transport mechanism.
Using the EventSource interface, the client opens a connection and establishes event handlers.
The client browser automatically converts the messages that arrive on the HTTP stream into appropriate Event objects. Then it delivers them to the event handlers that have been registered for the events' type if known, or to the onmessage event handler if no type-specific event handler was established.ConclusionHTTP is an extensible protocol that is easy to use.
The client-server structure, combined with the ability to add headers, allows HTTP to advance along with the extended capabilities of the Web.
Though HTTP/2 adds some complexity by embedding HTTP messages in frames to improve performance, the basic structure of messages has stayed the same since HTTP/1.0.
Session flow remains basic, allowing it to be investigated and debugged with a HTTP network monitor.See also
Evolution of HTTP
Glossary terms:

HTTP
HTTP/2
QUIC


Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 14, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nEvolution of HTTPHTTP (HyperText Transfer Protocol) is the underlying protocol of the World Wide Web. Developed by Tim Berners-Lee and his team between 1989-1991, HTTP has gone through many changes that have helped maintain its simplicity while shaping its flexibility. Keep reading to learn how HTTP evolved from a protocol designed to exchange files in a semitrusted laboratory environment into a modern internet maze that carries images and videos in high resolution and 3D.Invention of the World Wide WebIn 1989, while working at CERN, Tim Berners-Lee wrote a proposal to build a hypertext system over the internet. Initially called the Mesh, it was later renamed the World Wide Web during its implementation in 1990. Built over the existing TCP and IP protocols, it consisted of 4 building blocks:

A textual format to represent hypertext documents, the HyperText Markup Language (HTML).
A protocol to exchange these documents, the HyperText Transfer Protocol (HTTP).
A client to display (and edit) these documents, the first web browser called the WorldWideWeb.
A server to give access to the document, an early version of httpd.

These four building blocks were completed by the end of 1990, and the first servers were running outside of CERN by early 1991. On August 6, 1991, Tim Berners-Lee posted on the public alt.hypertext newsgroup. This is now considered to be the official start of the World Wide Web as a public project.
The HTTP protocol used in those early phases was very simple. It was later dubbed HTTP/0.9 and is sometimes called the one-line protocol.HTTP/0.9 – The one-line protocolThe initial version of HTTP had no version number; it was later called 0.9 to differentiate it from later versions. HTTP/0.9 was extremely simple: requests consisted of a single line and started with the only possible method GET followed by the path to the resource. The full URL wasn't included as the protocol, server, and port weren't necessary once connected to the server.
httpGET /my-page.html

The response was extremely simple, too: it only consisted of the file itself.
html<html>
  An text-only web page
</html>

Unlike subsequent evolutions, there were no HTTP headers. This meant that only HTML files could be transmitted. There were no status or error codes. If there was a problem, a specific HTML file was generated and included a description of the problem for human consumption.HTTP/1.0 – Building extensibilityHTTP/0.9 was very limited, but browsers and servers quickly made it more versatile:

Versioning information was sent within each request (HTTP/1.0 was appended to the GET line).
A status code line was also sent at the beginning of a response. This allowed the browser itself to recognize the success or failure of a request and adapt its behavior accordingly. For example, updating or using its local cache in a specific way.
The concept of HTTP headers was introduced for both requests and responses. Metadata could be transmitted and the protocol became extremely flexible and extensible.
Documents other than plain HTML files could be transmitted thanks to the Content-Type header.

At this point in time, a typical request and response looked like this:
httpGET /my-page.html HTTP/1.0
User-Agent: NCSA_Mosaic/2.0 (Windows 3.1)

HTTP/1.0 200 OK
Date: Tue, 15 Nov 1994 08:12:31 GMT
Server: CERN/3.0 libwww/2.17
Content-Type: text/html
<HTML>
A page with an image
  <IMG SRC="/my-image.gif">
</HTML>

It was followed by a second connection and a request to fetch the image (with the corresponding response):
httpGET /my-image.gif HTTP/1.0
User-Agent: NCSA_Mosaic/2.0 (Windows 3.1)

HTTP/1.0 200 OK
Date: Tue, 15 Nov 1994 08:12:32 GMT
Server: CERN/3.0 libwww/2.17
Content-Type: text/gif
(image content)

Between 1991-1995, these were introduced with a try-and-see approach. A server and a browser would add a feature and see if it got traction. Interoperability problems were common. In an effort to solve these issues, an informational document that described the common practices was published in November 1996. This was known as RFC 1945 and defined HTTP/1.0.HTTP/1.1 – The standardized protocolIn the meantime, proper standardization was in progress. This happened in parallel to the diverse implementations of HTTP/1.0. The first standardized version of HTTP, HTTP/1.1, was published in early 1997, only a few months after HTTP/1.0.
HTTP/1.1 clarified ambiguities and introduced numerous improvements:

A connection could be reused, which saved time. It no longer needed to be opened multiple times to display the resources embedded in the single original document.
Pipelining was added. This allowed a second request to be sent before the answer to the first one was fully transmitted. This lowered the latency of the communication.
Chunked responses were also supported.
Additional cache control mechanisms were introduced.
Content negotiation, including language, encoding, and type, was introduced. A client and a server could now agree on which content to exchange.
Thanks to the Host header, the ability to host different domains from the same IP address allowed server collocation.

A typical flow of requests, all through one single connection, looked like this:
httpGET /en-US/docs/Glossary/CORS-safelisted_request_header HTTP/1.1
Host: developer.mozilla.org
User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.9; rv:50.0) Gecko/20100101 Firefox/50.0
Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
Accept-Language: en-US,en;q=0.5
Accept-Encoding: gzip, deflate, br
Referer: https://developer.mozilla.org/en-US/docs/Glossary/CORS-safelisted_request_header

HTTP/1.1 200 OK
Connection: Keep-Alive
Content-Encoding: gzip
Content-Type: text/html; charset=utf-8
Date: Wed, 20 Jul 2016 10:55:30 GMT
Etag: "547fa7e369ef56031dd3bff2ace9fc0832eb251a"
Keep-Alive: timeout=5, max=1000
Last-Modified: Tue, 19 Jul 2016 00:59:33 GMT
Server: Apache
Transfer-Encoding: chunked
Vary: Cookie, Accept-Encoding

(content)

GET /static/img/header-background.png HTTP/1.1
Host: developer.mozilla.org
User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.9; rv:50.0) Gecko/20100101 Firefox/50.0
Accept: */*
Accept-Language: en-US,en;q=0.5
Accept-Encoding: gzip, deflate, br
Referer: https://developer.mozilla.org/en-US/docs/Glossary/CORS-safelisted_request_header

HTTP/1.1 200 OK
Age: 9578461
Cache-Control: public, max-age=315360000
Connection: keep-alive
Content-Length: 3077
Content-Type: image/png
Date: Thu, 31 Mar 2016 13:34:46 GMT
Last-Modified: Wed, 21 Oct 2015 18:27:50 GMT
Server: Apache

(image content of 3077 bytes)

HTTP/1.1 was first published as RFC 2068 in January 1997.More than two decades of developmentThe extensibility of HTTP made it easy to create new headers and methods. Even though the HTTP/1.1 protocol was refined over two revisions, RFC 2616 published in June 1999 and RFC 7230-RFC 7235 published in June 2014 before the release of HTTP/2, it was extremely stable for more than 15 years. HTTP/1.1 was updated again in 2022 with RFC 9110. Not only was HTTP/1.1 updated, but all of HTTP was revised and is now split into the following documents: semantics (RFC 9110), caching (RFC 9111) applying to all HTTP versions, and HTTP/1.1 (RFC 9112), HTTP/2 (RFC 9113), and HTTP/3 (RFC 9114). In addition, the specification finally achieved the status of Internet Standard (STD 97), whereas before it was always a proposed/draft standard.Using HTTP for secure transmissionsThe largest change to HTTP was made at the end of 1994. Instead of sending HTTP over a basic TCP/IP stack, the computer-services company Netscape Communications created an additional encrypted transmission layer on top of it: SSL. SSL 1.0 was never released to the public, but SSL 2.0 and its successor SSL 3.0 allowed for the creation of e-commerce websites. To do this, they encrypted and guaranteed the authenticity of the messages exchanged between the server and client. SSL was eventually standardized and became TLS.
During the same time period, it became clear that an encrypted transport layer was needed. The web was no longer a mostly academic network, and instead became a jungle where advertisers, random individuals, and criminals competed for as much private data as possible. As the applications built over HTTP became more powerful and required access to private information like address books, email, and user location, TLS became necessary outside the e-commerce use case.Using HTTP for complex applicationsTim Berners-Lee didn't originally envision HTTP as a read-only medium. He wanted to create a web where people could add and move documents remotely—a kind of distributed file system. Around 1996, HTTP was extended to allow authoring, and a standard called WebDAV was created. It grew to include specific applications like CardDAV for handling address book entries and CalDAV for dealing with calendars. But all these *DAV extensions had a flaw: they were only usable when implemented by the servers.
In 2000, a new pattern for using HTTP was designed: representational state transfer (or REST). The API wasn't based on the new HTTP methods, but instead relied on access to specific URIs with basic HTTP/1.1 methods. This allowed any web application to let an API retrieve and modify its data without having to update the browsers or the servers. All necessary information was embedded in the files that the websites served through standard HTTP/1.1. The drawback of the REST model was that each website defined its own nonstandard RESTful API and had total control of it. This differed from the *DAV extensions where clients and servers were interoperable. RESTful APIs became very common in the 2010s.
Since 2005, more APIs have become available to web pages. Several of these APIs create extensions to the HTTP protocol for specific purposes:

Server-sent events, where the server can push occasional messages to the browser.
WebSocket, a new protocol that can be set up by upgrading an existing HTTP connection.
Relaxing the security-model of the webHTTP is independent of the web security model, known as the same-origin policy. In fact, the current web security model was developed after the creation of HTTP! Over the years, it proved useful to lift some restrictions of this policy under certain constraints. The server transmitted how much and when to lift such restrictions to the client using a new set of HTTP headers. These were defined in specifications like Cross-Origin Resource Sharing (CORS) and the Content Security Policy (CSP).
In addition to these large extensions, many other headers were added, sometimes only experimentally. Notable headers are the Do Not Track (DNT) header to control privacy, X-Frame-Options, and Upgrade-Insecure-Requests but many more exist.HTTP/2 – A protocol for greater performanceOver the years, web pages became more complex. Some of them were even applications in their own right. More visual media was displayed and the volume and size of scripts adding interactivity also increased. Much more data was transmitted over significantly more HTTP requests and this created more complexity and overhead for HTTP/1.1 connections. To account for this, Google implemented an experimental protocol SPDY in the early 2010s. This alternative way of exchanging data between client and server amassed interest from developers working on both browsers and servers. SPDY defined an increase in responsiveness and solved the problem of duplicate data transmission, serving as the foundation for the HTTP/2 protocol.
The HTTP/2 protocol differs from HTTP/1.1 in a few ways:

It's a binary protocol rather than a text protocol. It can't be read and created manually. Despite this hurdle, it allows for the implementation of improved optimization techniques.
It's a multiplexed protocol. Parallel requests can be made over the same connection, removing the constraints of the HTTP/1.x protocol.
It compresses headers. As these are often similar among a set of requests, this removes the duplication and overhead of data transmitted.

Officially standardized in May 2015, HTTP/2 use peaked in January 2022 at 46.9% of all websites (see these stats). High-traffic websites showed the most rapid adoption in an effort to save on data transfer overhead and subsequent budgets.
This rapid adoption was likely because HTTP/2 didn't require changes to websites and applications. To use it, only an up-to-date server that communicated with a recent browser was necessary. Only a limited set of groups was needed to trigger adoption, and as legacy browser and server versions were renewed, usage was naturally increased, without significant work for web developers.Post-HTTP/2 evolutionHTTP's extensibility is still being used to add new features. Notably, we can cite new extensions of the HTTP protocol that appeared in 2016:

Support for Alt-Svc allowed the dissociation of the identification and the location of a given resource. This meant a smarter CDN caching mechanism.
The introduction of client hints allowed the browser or client to proactively communicate information about its requirements and hardware constraints to the server.
The introduction of security-related prefixes in the Cookie header helped guarantee that secure cookies couldn't be altered.
HTTP/3 - HTTP over QUICThe next major version of HTTP, HTTP/3 has the same semantics as earlier versions of HTTP but uses QUIC instead of TCP for the transport layer portion. By October 2022, 26% of all websites were using HTTP/3.
QUIC is designed to provide much lower latency for HTTP connections. Like HTTP/2, it is a multiplexed protocol, but HTTP/2 runs over a single TCP connection, so packet loss detection and retransmission handled at the TCP layer can block all streams. QUIC runs multiple streams over UDP and implements packet loss detection and retransmission independently for each stream, so that if an error occurs, only the stream with data in that packet is blocked.
Defined in RFC 9114, HTTP/3 is supported by most major browsers including Chromium (and its variants such as Chrome and Edge) and Firefox.See also
Connection management in HTTP/1.x
Protocol upgrade mechanism
HTTP resources and specifications
Glossary terms:

HTTP
HTTP/2
QUIC
Round Trip Time (RTT)
TCP slow start
Transmission Control Protocol (TCP)\n\nEvolution of HTTPHTTP (HyperText Transfer Protocol) is the underlying protocol of the World Wide Web. Developed by Tim Berners-Lee and his team between 1989-1991, HTTP has gone through many changes that have helped maintain its simplicity while shaping its flexibility. Keep reading to learn how HTTP evolved from a protocol designed to exchange files in a semitrusted laboratory environment into a modern internet maze that carries images and videos in high resolution and 3D.Invention of the World Wide WebIn 1989, while working at CERN, Tim Berners-Lee wrote a proposal to build a hypertext system over the internet. Initially called the Mesh, it was later renamed the World Wide Web during its implementation in 1990. Built over the existing TCP and IP protocols, it consisted of 4 building blocks:

A textual format to represent hypertext documents, the HyperText Markup Language (HTML).
A protocol to exchange these documents, the HyperText Transfer Protocol (HTTP).
A client to display (and edit) these documents, the first web browser called the WorldWideWeb.
A server to give access to the document, an early version of httpd.

These four building blocks were completed by the end of 1990, and the first servers were running outside of CERN by early 1991. On August 6, 1991, Tim Berners-Lee posted on the public alt.hypertext newsgroup. This is now considered to be the official start of the World Wide Web as a public project.
The HTTP protocol used in those early phases was very simple. It was later dubbed HTTP/0.9 and is sometimes called the one-line protocol.HTTP/0.9 – The one-line protocolThe initial version of HTTP had no version number; it was later called 0.9 to differentiate it from later versions. HTTP/0.9 was extremely simple: requests consisted of a single line and started with the only possible method GET followed by the path to the resource. The full URL wasn't included as the protocol, server, and port weren't necessary once connected to the server.
httpGET /my-page.html

The response was extremely simple, too: it only consisted of the file itself.
html<html>
  An text-only web page
</html>

Unlike subsequent evolutions, there were no HTTP headers. This meant that only HTML files could be transmitted. There were no status or error codes. If there was a problem, a specific HTML file was generated and included a description of the problem for human consumption.HTTP/1.0 – Building extensibilityHTTP/0.9 was very limited, but browsers and servers quickly made it more versatile:

Versioning information was sent within each request (HTTP/1.0 was appended to the GET line).
A status code line was also sent at the beginning of a response. This allowed the browser itself to recognize the success or failure of a request and adapt its behavior accordingly. For example, updating or using its local cache in a specific way.
The concept of HTTP headers was introduced for both requests and responses. Metadata could be transmitted and the protocol became extremely flexible and extensible.
Documents other than plain HTML files could be transmitted thanks to the Content-Type header.

At this point in time, a typical request and response looked like this:
httpGET /my-page.html HTTP/1.0
User-Agent: NCSA_Mosaic/2.0 (Windows 3.1)

HTTP/1.0 200 OK
Date: Tue, 15 Nov 1994 08:12:31 GMT
Server: CERN/3.0 libwww/2.17
Content-Type: text/html
<HTML>
A page with an image
  <IMG SRC="/my-image.gif">
</HTML>

It was followed by a second connection and a request to fetch the image (with the corresponding response):
httpGET /my-image.gif HTTP/1.0
User-Agent: NCSA_Mosaic/2.0 (Windows 3.1)

HTTP/1.0 200 OK
Date: Tue, 15 Nov 1994 08:12:32 GMT
Server: CERN/3.0 libwww/2.17
Content-Type: text/gif
(image content)

Between 1991-1995, these were introduced with a try-and-see approach. A server and a browser would add a feature and see if it got traction. Interoperability problems were common. In an effort to solve these issues, an informational document that described the common practices was published in November 1996. This was known as RFC 1945 and defined HTTP/1.0.HTTP/1.1 – The standardized protocolIn the meantime, proper standardization was in progress. This happened in parallel to the diverse implementations of HTTP/1.0. The first standardized version of HTTP, HTTP/1.1, was published in early 1997, only a few months after HTTP/1.0.
HTTP/1.1 clarified ambiguities and introduced numerous improvements:

A connection could be reused, which saved time. It no longer needed to be opened multiple times to display the resources embedded in the single original document.
Pipelining was added. This allowed a second request to be sent before the answer to the first one was fully transmitted. This lowered the latency of the communication.
Chunked responses were also supported.
Additional cache control mechanisms were introduced.
Content negotiation, including language, encoding, and type, was introduced. A client and a server could now agree on which content to exchange.
Thanks to the Host header, the ability to host different domains from the same IP address allowed server collocation.

A typical flow of requests, all through one single connection, looked like this:
httpGET /en-US/docs/Glossary/CORS-safelisted_request_header HTTP/1.1
Host: developer.mozilla.org
User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.9; rv:50.0) Gecko/20100101 Firefox/50.0
Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
Accept-Language: en-US,en;q=0.5
Accept-Encoding: gzip, deflate, br
Referer: https://developer.mozilla.org/en-US/docs/Glossary/CORS-safelisted_request_header

HTTP/1.1 200 OK
Connection: Keep-Alive
Content-Encoding: gzip
Content-Type: text/html; charset=utf-8
Date: Wed, 20 Jul 2016 10:55:30 GMT
Etag: "547fa7e369ef56031dd3bff2ace9fc0832eb251a"
Keep-Alive: timeout=5, max=1000
Last-Modified: Tue, 19 Jul 2016 00:59:33 GMT
Server: Apache
Transfer-Encoding: chunked
Vary: Cookie, Accept-Encoding

(content)

GET /static/img/header-background.png HTTP/1.1
Host: developer.mozilla.org
User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.9; rv:50.0) Gecko/20100101 Firefox/50.0
Accept: */*
Accept-Language: en-US,en;q=0.5
Accept-Encoding: gzip, deflate, br
Referer: https://developer.mozilla.org/en-US/docs/Glossary/CORS-safelisted_request_header

HTTP/1.1 200 OK
Age: 9578461
Cache-Control: public, max-age=315360000
Connection: keep-alive
Content-Length: 3077
Content-Type: image/png
Date: Thu, 31 Mar 2016 13:34:46 GMT
Last-Modified: Wed, 21 Oct 2015 18:27:50 GMT
Server: Apache

(image content of 3077 bytes)

HTTP/1.1 was first published as RFC 2068 in January 1997.More than two decades of developmentThe extensibility of HTTP made it easy to create new headers and methods. Even though the HTTP/1.1 protocol was refined over two revisions, RFC 2616 published in June 1999 and RFC 7230-RFC 7235 published in June 2014 before the release of HTTP/2, it was extremely stable for more than 15 years. HTTP/1.1 was updated again in 2022 with RFC 9110. Not only was HTTP/1.1 updated, but all of HTTP was revised and is now split into the following documents: semantics (RFC 9110), caching (RFC 9111) applying to all HTTP versions, and HTTP/1.1 (RFC 9112), HTTP/2 (RFC 9113), and HTTP/3 (RFC 9114). In addition, the specification finally achieved the status of Internet Standard (STD 97), whereas before it was always a proposed/draft standard.Using HTTP for secure transmissionsThe largest change to HTTP was made at the end of 1994. Instead of sending HTTP over a basic TCP/IP stack, the computer-services company Netscape Communications created an additional encrypted transmission layer on top of it: SSL. SSL 1.0 was never released to the public, but SSL 2.0 and its successor SSL 3.0 allowed for the creation of e-commerce websites. To do this, they encrypted and guaranteed the authenticity of the messages exchanged between the server and client. SSL was eventually standardized and became TLS.
During the same time period, it became clear that an encrypted transport layer was needed. The web was no longer a mostly academic network, and instead became a jungle where advertisers, random individuals, and criminals competed for as much private data as possible. As the applications built over HTTP became more powerful and required access to private information like address books, email, and user location, TLS became necessary outside the e-commerce use case.Using HTTP for complex applicationsTim Berners-Lee didn't originally envision HTTP as a read-only medium. He wanted to create a web where people could add and move documents remotely—a kind of distributed file system. Around 1996, HTTP was extended to allow authoring, and a standard called WebDAV was created. It grew to include specific applications like CardDAV for handling address book entries and CalDAV for dealing with calendars. But all these *DAV extensions had a flaw: they were only usable when implemented by the servers.
In 2000, a new pattern for using HTTP was designed: representational state transfer (or REST). The API wasn't based on the new HTTP methods, but instead relied on access to specific URIs with basic HTTP/1.1 methods. This allowed any web application to let an API retrieve and modify its data without having to update the browsers or the servers. All necessary information was embedded in the files that the websites served through standard HTTP/1.1. The drawback of the REST model was that each website defined its own nonstandard RESTful API and had total control of it. This differed from the *DAV extensions where clients and servers were interoperable. RESTful APIs became very common in the 2010s.
Since 2005, more APIs have become available to web pages. Several of these APIs create extensions to the HTTP protocol for specific purposes:

Server-sent events, where the server can push occasional messages to the browser.
WebSocket, a new protocol that can be set up by upgrading an existing HTTP connection.
Relaxing the security-model of the webHTTP is independent of the web security model, known as the same-origin policy. In fact, the current web security model was developed after the creation of HTTP! Over the years, it proved useful to lift some restrictions of this policy under certain constraints. The server transmitted how much and when to lift such restrictions to the client using a new set of HTTP headers. These were defined in specifications like Cross-Origin Resource Sharing (CORS) and the Content Security Policy (CSP).
In addition to these large extensions, many other headers were added, sometimes only experimentally. Notable headers are the Do Not Track (DNT) header to control privacy, X-Frame-Options, and Upgrade-Insecure-Requests but many more exist.HTTP/2 – A protocol for greater performanceOver the years, web pages became more complex. Some of them were even applications in their own right. More visual media was displayed and the volume and size of scripts adding interactivity also increased. Much more data was transmitted over significantly more HTTP requests and this created more complexity and overhead for HTTP/1.1 connections. To account for this, Google implemented an experimental protocol SPDY in the early 2010s. This alternative way of exchanging data between client and server amassed interest from developers working on both browsers and servers. SPDY defined an increase in responsiveness and solved the problem of duplicate data transmission, serving as the foundation for the HTTP/2 protocol.
The HTTP/2 protocol differs from HTTP/1.1 in a few ways:

It's a binary protocol rather than a text protocol. It can't be read and created manually. Despite this hurdle, it allows for the implementation of improved optimization techniques.
It's a multiplexed protocol. Parallel requests can be made over the same connection, removing the constraints of the HTTP/1.x protocol.
It compresses headers. As these are often similar among a set of requests, this removes the duplication and overhead of data transmitted.

Officially standardized in May 2015, HTTP/2 use peaked in January 2022 at 46.9% of all websites (see these stats). High-traffic websites showed the most rapid adoption in an effort to save on data transfer overhead and subsequent budgets.
This rapid adoption was likely because HTTP/2 didn't require changes to websites and applications. To use it, only an up-to-date server that communicated with a recent browser was necessary. Only a limited set of groups was needed to trigger adoption, and as legacy browser and server versions were renewed, usage was naturally increased, without significant work for web developers.Post-HTTP/2 evolutionHTTP's extensibility is still being used to add new features. Notably, we can cite new extensions of the HTTP protocol that appeared in 2016:

Support for Alt-Svc allowed the dissociation of the identification and the location of a given resource. This meant a smarter CDN caching mechanism.
The introduction of client hints allowed the browser or client to proactively communicate information about its requirements and hardware constraints to the server.
The introduction of security-related prefixes in the Cookie header helped guarantee that secure cookies couldn't be altered.
HTTP/3 - HTTP over QUICThe next major version of HTTP, HTTP/3 has the same semantics as earlier versions of HTTP but uses QUIC instead of TCP for the transport layer portion. By October 2022, 26% of all websites were using HTTP/3.
QUIC is designed to provide much lower latency for HTTP connections. Like HTTP/2, it is a multiplexed protocol, but HTTP/2 runs over a single TCP connection, so packet loss detection and retransmission handled at the TCP layer can block all streams. QUIC runs multiple streams over UDP and implements packet loss detection and retransmission independently for each stream, so that if an error occurs, only the stream with data in that packet is blocked.
Defined in RFC 9114, HTTP/3 is supported by most major browsers including Chromium (and its variants such as Chrome and Edge) and Firefox.See also
Connection management in HTTP/1.x
Protocol upgrade mechanism
HTTP resources and specifications
Glossary terms:

HTTP
HTTP/2
QUIC
Round Trip Time (RTT)
TCP slow start
Transmission Control Protocol (TCP)


Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 14, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nEvolution of HTTPHTTP (HyperText Transfer Protocol) is the underlying protocol of the World Wide Web. Developed by Tim Berners-Lee and his team between 1989-1991, HTTP has gone through many changes that have helped maintain its simplicity while shaping its flexibility. Keep reading to learn how HTTP evolved from a protocol designed to exchange files in a semitrusted laboratory environment into a modern internet maze that carries images and videos in high resolution and 3D.Invention of the World Wide WebIn 1989, while working at CERN, Tim Berners-Lee wrote a proposal to build a hypertext system over the internet. Initially called the Mesh, it was later renamed the World Wide Web during its implementation in 1990. Built over the existing TCP and IP protocols, it consisted of 4 building blocks:

A textual format to represent hypertext documents, the HyperText Markup Language (HTML).
A protocol to exchange these documents, the HyperText Transfer Protocol (HTTP).
A client to display (and edit) these documents, the first web browser called the WorldWideWeb.
A server to give access to the document, an early version of httpd.

These four building blocks were completed by the end of 1990, and the first servers were running outside of CERN by early 1991. On August 6, 1991, Tim Berners-Lee posted on the public alt.hypertext newsgroup. This is now considered to be the official start of the World Wide Web as a public project.
The HTTP protocol used in those early phases was very simple. It was later dubbed HTTP/0.9 and is sometimes called the one-line protocol.HTTP/0.9 – The one-line protocolThe initial version of HTTP had no version number; it was later called 0.9 to differentiate it from later versions. HTTP/0.9 was extremely simple: requests consisted of a single line and started with the only possible method GET followed by the path to the resource. The full URL wasn't included as the protocol, server, and port weren't necessary once connected to the server.
httpGET /my-page.html

The response was extremely simple, too: it only consisted of the file itself.
html<html>
  An text-only web page
</html>

Unlike subsequent evolutions, there were no HTTP headers. This meant that only HTML files could be transmitted. There were no status or error codes. If there was a problem, a specific HTML file was generated and included a description of the problem for human consumption.HTTP/1.0 – Building extensibilityHTTP/0.9 was very limited, but browsers and servers quickly made it more versatile:

Versioning information was sent within each request (HTTP/1.0 was appended to the GET line).
A status code line was also sent at the beginning of a response. This allowed the browser itself to recognize the success or failure of a request and adapt its behavior accordingly. For example, updating or using its local cache in a specific way.
The concept of HTTP headers was introduced for both requests and responses. Metadata could be transmitted and the protocol became extremely flexible and extensible.
Documents other than plain HTML files could be transmitted thanks to the Content-Type header.

At this point in time, a typical request and response looked like this:
httpGET /my-page.html HTTP/1.0
User-Agent: NCSA_Mosaic/2.0 (Windows 3.1)

HTTP/1.0 200 OK
Date: Tue, 15 Nov 1994 08:12:31 GMT
Server: CERN/3.0 libwww/2.17
Content-Type: text/html
<HTML>
A page with an image
  <IMG SRC="/my-image.gif">
</HTML>

It was followed by a second connection and a request to fetch the image (with the corresponding response):
httpGET /my-image.gif HTTP/1.0
User-Agent: NCSA_Mosaic/2.0 (Windows 3.1)

HTTP/1.0 200 OK
Date: Tue, 15 Nov 1994 08:12:32 GMT
Server: CERN/3.0 libwww/2.17
Content-Type: text/gif
(image content)

Between 1991-1995, these were introduced with a try-and-see approach. A server and a browser would add a feature and see if it got traction. Interoperability problems were common. In an effort to solve these issues, an informational document that described the common practices was published in November 1996. This was known as RFC 1945 and defined HTTP/1.0.HTTP/1.1 – The standardized protocolIn the meantime, proper standardization was in progress. This happened in parallel to the diverse implementations of HTTP/1.0. The first standardized version of HTTP, HTTP/1.1, was published in early 1997, only a few months after HTTP/1.0.
HTTP/1.1 clarified ambiguities and introduced numerous improvements:

A connection could be reused, which saved time. It no longer needed to be opened multiple times to display the resources embedded in the single original document.
Pipelining was added. This allowed a second request to be sent before the answer to the first one was fully transmitted. This lowered the latency of the communication.
Chunked responses were also supported.
Additional cache control mechanisms were introduced.
Content negotiation, including language, encoding, and type, was introduced. A client and a server could now agree on which content to exchange.
Thanks to the Host header, the ability to host different domains from the same IP address allowed server collocation.

A typical flow of requests, all through one single connection, looked like this:
httpGET /en-US/docs/Glossary/CORS-safelisted_request_header HTTP/1.1
Host: developer.mozilla.org
User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.9; rv:50.0) Gecko/20100101 Firefox/50.0
Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
Accept-Language: en-US,en;q=0.5
Accept-Encoding: gzip, deflate, br
Referer: https://developer.mozilla.org/en-US/docs/Glossary/CORS-safelisted_request_header

HTTP/1.1 200 OK
Connection: Keep-Alive
Content-Encoding: gzip
Content-Type: text/html; charset=utf-8
Date: Wed, 20 Jul 2016 10:55:30 GMT
Etag: "547fa7e369ef56031dd3bff2ace9fc0832eb251a"
Keep-Alive: timeout=5, max=1000
Last-Modified: Tue, 19 Jul 2016 00:59:33 GMT
Server: Apache
Transfer-Encoding: chunked
Vary: Cookie, Accept-Encoding

(content)

GET /static/img/header-background.png HTTP/1.1
Host: developer.mozilla.org
User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.9; rv:50.0) Gecko/20100101 Firefox/50.0
Accept: */*
Accept-Language: en-US,en;q=0.5
Accept-Encoding: gzip, deflate, br
Referer: https://developer.mozilla.org/en-US/docs/Glossary/CORS-safelisted_request_header

HTTP/1.1 200 OK
Age: 9578461
Cache-Control: public, max-age=315360000
Connection: keep-alive
Content-Length: 3077
Content-Type: image/png
Date: Thu, 31 Mar 2016 13:34:46 GMT
Last-Modified: Wed, 21 Oct 2015 18:27:50 GMT
Server: Apache

(image content of 3077 bytes)

HTTP/1.1 was first published as RFC 2068 in January 1997.More than two decades of developmentThe extensibility of HTTP made it easy to create new headers and methods. Even though the HTTP/1.1 protocol was refined over two revisions, RFC 2616 published in June 1999 and RFC 7230-RFC 7235 published in June 2014 before the release of HTTP/2, it was extremely stable for more than 15 years. HTTP/1.1 was updated again in 2022 with RFC 9110. Not only was HTTP/1.1 updated, but all of HTTP was revised and is now split into the following documents: semantics (RFC 9110), caching (RFC 9111) applying to all HTTP versions, and HTTP/1.1 (RFC 9112), HTTP/2 (RFC 9113), and HTTP/3 (RFC 9114). In addition, the specification finally achieved the status of Internet Standard (STD 97), whereas before it was always a proposed/draft standard.Using HTTP for secure transmissionsThe largest change to HTTP was made at the end of 1994. Instead of sending HTTP over a basic TCP/IP stack, the computer-services company Netscape Communications created an additional encrypted transmission layer on top of it: SSL. SSL 1.0 was never released to the public, but SSL 2.0 and its successor SSL 3.0 allowed for the creation of e-commerce websites. To do this, they encrypted and guaranteed the authenticity of the messages exchanged between the server and client. SSL was eventually standardized and became TLS.
During the same time period, it became clear that an encrypted transport layer was needed. The web was no longer a mostly academic network, and instead became a jungle where advertisers, random individuals, and criminals competed for as much private data as possible. As the applications built over HTTP became more powerful and required access to private information like address books, email, and user location, TLS became necessary outside the e-commerce use case.Using HTTP for complex applicationsTim Berners-Lee didn't originally envision HTTP as a read-only medium. He wanted to create a web where people could add and move documents remotely—a kind of distributed file system. Around 1996, HTTP was extended to allow authoring, and a standard called WebDAV was created. It grew to include specific applications like CardDAV for handling address book entries and CalDAV for dealing with calendars. But all these *DAV extensions had a flaw: they were only usable when implemented by the servers.
In 2000, a new pattern for using HTTP was designed: representational state transfer (or REST). The API wasn't based on the new HTTP methods, but instead relied on access to specific URIs with basic HTTP/1.1 methods. This allowed any web application to let an API retrieve and modify its data without having to update the browsers or the servers. All necessary information was embedded in the files that the websites served through standard HTTP/1.1. The drawback of the REST model was that each website defined its own nonstandard RESTful API and had total control of it. This differed from the *DAV extensions where clients and servers were interoperable. RESTful APIs became very common in the 2010s.
Since 2005, more APIs have become available to web pages. Several of these APIs create extensions to the HTTP protocol for specific purposes:

Server-sent events, where the server can push occasional messages to the browser.
WebSocket, a new protocol that can be set up by upgrading an existing HTTP connection.
Relaxing the security-model of the webHTTP is independent of the web security model, known as the same-origin policy. In fact, the current web security model was developed after the creation of HTTP! Over the years, it proved useful to lift some restrictions of this policy under certain constraints. The server transmitted how much and when to lift such restrictions to the client using a new set of HTTP headers. These were defined in specifications like Cross-Origin Resource Sharing (CORS) and the Content Security Policy (CSP).
In addition to these large extensions, many other headers were added, sometimes only experimentally. Notable headers are the Do Not Track (DNT) header to control privacy, X-Frame-Options, and Upgrade-Insecure-Requests but many more exist.HTTP/2 – A protocol for greater performanceOver the years, web pages became more complex. Some of them were even applications in their own right. More visual media was displayed and the volume and size of scripts adding interactivity also increased. Much more data was transmitted over significantly more HTTP requests and this created more complexity and overhead for HTTP/1.1 connections. To account for this, Google implemented an experimental protocol SPDY in the early 2010s. This alternative way of exchanging data between client and server amassed interest from developers working on both browsers and servers. SPDY defined an increase in responsiveness and solved the problem of duplicate data transmission, serving as the foundation for the HTTP/2 protocol.
The HTTP/2 protocol differs from HTTP/1.1 in a few ways:

It's a binary protocol rather than a text protocol. It can't be read and created manually. Despite this hurdle, it allows for the implementation of improved optimization techniques.
It's a multiplexed protocol. Parallel requests can be made over the same connection, removing the constraints of the HTTP/1.x protocol.
It compresses headers. As these are often similar among a set of requests, this removes the duplication and overhead of data transmitted.

Officially standardized in May 2015, HTTP/2 use peaked in January 2022 at 46.9% of all websites (see these stats). High-traffic websites showed the most rapid adoption in an effort to save on data transfer overhead and subsequent budgets.
This rapid adoption was likely because HTTP/2 didn't require changes to websites and applications. To use it, only an up-to-date server that communicated with a recent browser was necessary. Only a limited set of groups was needed to trigger adoption, and as legacy browser and server versions were renewed, usage was naturally increased, without significant work for web developers.Post-HTTP/2 evolutionHTTP's extensibility is still being used to add new features. Notably, we can cite new extensions of the HTTP protocol that appeared in 2016:

Support for Alt-Svc allowed the dissociation of the identification and the location of a given resource. This meant a smarter CDN caching mechanism.
The introduction of client hints allowed the browser or client to proactively communicate information about its requirements and hardware constraints to the server.
The introduction of security-related prefixes in the Cookie header helped guarantee that secure cookies couldn't be altered.
HTTP/3 - HTTP over QUICThe next major version of HTTP, HTTP/3 has the same semantics as earlier versions of HTTP but uses QUIC instead of TCP for the transport layer portion. By October 2022, 26% of all websites were using HTTP/3.
QUIC is designed to provide much lower latency for HTTP connections. Like HTTP/2, it is a multiplexed protocol, but HTTP/2 runs over a single TCP connection, so packet loss detection and retransmission handled at the TCP layer can block all streams. QUIC runs multiple streams over UDP and implements packet loss detection and retransmission independently for each stream, so that if an error occurs, only the stream with data in that packet is blocked.
Defined in RFC 9114, HTTP/3 is supported by most major browsers including Chromium (and its variants such as Chrome and Edge) and Firefox.See also
Connection management in HTTP/1.x
Protocol upgrade mechanism
HTTP resources and specifications
Glossary terms:

HTTP
HTTP/2
QUIC
Round Trip Time (RTT)
TCP slow start
Transmission Control Protocol (TCP)


Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 14, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nA typical HTTP sessionIn client-server protocols, like HTTP, sessions consist of three phases:

The client establishes a TCP connection (or the appropriate connection if the transport layer is not TCP).
The client sends its request, and waits for the answer.
The server processes the request, sending back its answer, providing a status code and appropriate data.

As of HTTP/1.1, the connection is no longer closed after completing the third phase, and the client is now granted a further request: this means the second and third phases can now be performed any number of times.Establishing a connectionIn client-server protocols, it is the client which establishes the connection. Opening a connection in HTTP means initiating a connection in the underlying transport layer, usually this is TCP.
With TCP the default port, for an HTTP server on a computer, is port 80. Other ports can also be used, like 8000 or 8080. The URL of a page to fetch contains both the domain name, and the port number, though the latter can be omitted if it is 80. See the URL reference for more details.

Note:
The client-server model does not allow the server to send data to the client without an explicit request for it. However, various Web APIs enable this use case, including the Push API, Server-sent events, and the WebSockets API.
Sending a client requestOnce the connection is established, the user-agent can send the request (a user-agent is typically a web browser, but can be anything else, a crawler, for example). A client request consists of text directives, separated by CRLF (carriage return, followed by line feed), divided into three blocks:


The first line contains a request method followed by its parameters:

the path of the document, as an absolute URL without the protocol or domain name
the HTTP protocol version



Subsequent lines represent an HTTP header, giving the server information about what type of data is appropriate (for example, what language, what MIME types), or other data altering its behavior (for example, not sending an answer if it is already cached). These HTTP headers form a block which ends with an empty line.


The final block is an optional data block, which may contain further data mainly used by the POST method.

Example requestsFetching the root page of developer.mozilla.org, (https://developer.mozilla.org/), and telling the server that the user-agent would prefer the page in French, if possible:
httpGET / HTTP/1.1
Host: developer.mozilla.org
Accept-Language: fr

Observe that final empty line, this separates the data block from the header block. As there is no Content-Length provided in an HTTP header, this data block is presented empty, marking the end of the headers, allowing the server to process the request the moment it receives this empty line.
For example, sending the result of a form:
httpPOST /contact_form.php HTTP/1.1
Host: developer.mozilla.org
Content-Length: 64
Content-Type: application/x-www-form-urlencoded

name=Joe%20User&request=Send%20me%20one%20of%20your%20catalogue
Request methodsHTTP defines a set of request methods indicating the desired action to be performed upon a resource. Although they can also be nouns, these requests methods are sometimes referred as HTTP verbs. The most common requests are GET and POST:

The GET method requests a data representation of the specified resource. Requests using GET should only retrieve data.
The POST method sends data to a server so it may change its state. This is the method often used for HTML Forms.
Structure of a server responseAfter the connected agent has sent its request, the web server processes it, and ultimately returns a response. Similar to a client request, a server response is formed of text directives, separated by CRLF, though divided into three blocks:

The first line, the status line, consists of an acknowledgment of the HTTP version used, followed by a response status code (and its brief meaning in human-readable text).
Subsequent lines represent specific HTTP headers, giving the client information about the data sent (for example, type, data size, compression algorithm used, hints about caching). Similarly to the block of HTTP headers for a client request, these HTTP headers form a block ending with an empty line.
The final block is a data block, which contains the optional data.
Example responsesSuccessful web page response:
httpHTTP/1.1 200 OK
Content-Type: text/html; charset=utf-8
Content-Length: 55743
Connection: keep-alive
Cache-Control: s-maxage=300, public, max-age=0
Content-Language: en-US
Date: Thu, 06 Dec 2018 17:37:18 GMT
ETag: "2e77ad1dc6ab0b53a2996dfd4653c1c3"
Server: meinheld/0.6.1
Strict-Transport-Security: max-age=63072000
X-Content-Type-Options: nosniff
X-Frame-Options: DENY
X-XSS-Protection: 1; mode=block
Vary: Accept-Encoding,Cookie
Age: 7

<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <title>A basic webpage</title>
</head>
<body>
  <h1>Basic HTML webpage</h1>
  <p>Hello, world!</p>
</body>
</html>

Notification that the requested resource has permanently moved:
httpHTTP/1.1 301 Moved Permanently
Server: Apache/2.4.37 (Red Hat)
Content-Type: text/html; charset=utf-8
Date: Thu, 06 Dec 2018 17:33:08 GMT
Location: https://developer.mozilla.org/ (this is the new link to the resource; it is expected that the user-agent will fetch it)
Keep-Alive: timeout=15, max=98
Accept-Ranges: bytes
Via: Moz-Cache-zlb05
Connection: Keep-Alive
Content-Length: 325 (the content contains a default page to display if the user-agent is not able to follow the link)

<!doctype html>… (contains a site-customized page helping the user to find the missing resource)

Notification that the requested resource doesn't exist:
httpHTTP/1.1 404 Not Found
Content-Type: text/html; charset=utf-8
Content-Length: 38217
Connection: keep-alive
Cache-Control: no-cache, no-store, must-revalidate, max-age=0
Content-Language: en-US
Date: Thu, 06 Dec 2018 17:35:13 GMT
Expires: Thu, 06 Dec 2018 17:35:13 GMT
Server: meinheld/0.6.1
Strict-Transport-Security: max-age=63072000
X-Content-Type-Options: nosniff
X-Frame-Options: DENY
X-XSS-Protection: 1; mode=block
Vary: Accept-Encoding,Cookie
X-Cache: Error from cloudfront

<!doctype html>… (contains a site-customized page helping the user to find the missing resource)
Response status codesHTTP response status codes indicate if a specific HTTP request has been successfully completed. Responses are grouped into five classes: informational responses, successful responses, redirects, client errors, and server errors.

200: OK. The request has succeeded.
301: Moved Permanently. This response code means that the URI of requested resource has been changed.
404: Not Found. The server cannot find the requested resource.
See also
URLs
HTTP headers
HTTP request methods
HTTP response status codes\n\nA typical HTTP sessionIn client-server protocols, like HTTP, sessions consist of three phases:

The client establishes a TCP connection (or the appropriate connection if the transport layer is not TCP).
The client sends its request, and waits for the answer.
The server processes the request, sending back its answer, providing a status code and appropriate data.

As of HTTP/1.1, the connection is no longer closed after completing the third phase, and the client is now granted a further request: this means the second and third phases can now be performed any number of times.Establishing a connectionIn client-server protocols, it is the client which establishes the connection. Opening a connection in HTTP means initiating a connection in the underlying transport layer, usually this is TCP.
With TCP the default port, for an HTTP server on a computer, is port 80. Other ports can also be used, like 8000 or 8080. The URL of a page to fetch contains both the domain name, and the port number, though the latter can be omitted if it is 80. See the URL reference for more details.

Note:
The client-server model does not allow the server to send data to the client without an explicit request for it. However, various Web APIs enable this use case, including the Push API, Server-sent events, and the WebSockets API.
Sending a client requestOnce the connection is established, the user-agent can send the request (a user-agent is typically a web browser, but can be anything else, a crawler, for example). A client request consists of text directives, separated by CRLF (carriage return, followed by line feed), divided into three blocks:


The first line contains a request method followed by its parameters:

the path of the document, as an absolute URL without the protocol or domain name
the HTTP protocol version



Subsequent lines represent an HTTP header, giving the server information about what type of data is appropriate (for example, what language, what MIME types), or other data altering its behavior (for example, not sending an answer if it is already cached). These HTTP headers form a block which ends with an empty line.


The final block is an optional data block, which may contain further data mainly used by the POST method.

Example requestsFetching the root page of developer.mozilla.org, (https://developer.mozilla.org/), and telling the server that the user-agent would prefer the page in French, if possible:
httpGET / HTTP/1.1
Host: developer.mozilla.org
Accept-Language: fr

Observe that final empty line, this separates the data block from the header block. As there is no Content-Length provided in an HTTP header, this data block is presented empty, marking the end of the headers, allowing the server to process the request the moment it receives this empty line.
For example, sending the result of a form:
httpPOST /contact_form.php HTTP/1.1
Host: developer.mozilla.org
Content-Length: 64
Content-Type: application/x-www-form-urlencoded

name=Joe%20User&request=Send%20me%20one%20of%20your%20catalogue
Request methodsHTTP defines a set of request methods indicating the desired action to be performed upon a resource. Although they can also be nouns, these requests methods are sometimes referred as HTTP verbs. The most common requests are GET and POST:

The GET method requests a data representation of the specified resource. Requests using GET should only retrieve data.
The POST method sends data to a server so it may change its state. This is the method often used for HTML Forms.
Structure of a server responseAfter the connected agent has sent its request, the web server processes it, and ultimately returns a response. Similar to a client request, a server response is formed of text directives, separated by CRLF, though divided into three blocks:

The first line, the status line, consists of an acknowledgment of the HTTP version used, followed by a response status code (and its brief meaning in human-readable text).
Subsequent lines represent specific HTTP headers, giving the client information about the data sent (for example, type, data size, compression algorithm used, hints about caching). Similarly to the block of HTTP headers for a client request, these HTTP headers form a block ending with an empty line.
The final block is a data block, which contains the optional data.
Example responsesSuccessful web page response:
httpHTTP/1.1 200 OK
Content-Type: text/html; charset=utf-8
Content-Length: 55743
Connection: keep-alive
Cache-Control: s-maxage=300, public, max-age=0
Content-Language: en-US
Date: Thu, 06 Dec 2018 17:37:18 GMT
ETag: "2e77ad1dc6ab0b53a2996dfd4653c1c3"
Server: meinheld/0.6.1
Strict-Transport-Security: max-age=63072000
X-Content-Type-Options: nosniff
X-Frame-Options: DENY
X-XSS-Protection: 1; mode=block
Vary: Accept-Encoding,Cookie
Age: 7

<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <title>A basic webpage</title>
</head>
<body>
  <h1>Basic HTML webpage</h1>
  <p>Hello, world!</p>
</body>
</html>

Notification that the requested resource has permanently moved:
httpHTTP/1.1 301 Moved Permanently
Server: Apache/2.4.37 (Red Hat)
Content-Type: text/html; charset=utf-8
Date: Thu, 06 Dec 2018 17:33:08 GMT
Location: https://developer.mozilla.org/ (this is the new link to the resource; it is expected that the user-agent will fetch it)
Keep-Alive: timeout=15, max=98
Accept-Ranges: bytes
Via: Moz-Cache-zlb05
Connection: Keep-Alive
Content-Length: 325 (the content contains a default page to display if the user-agent is not able to follow the link)

<!doctype html>… (contains a site-customized page helping the user to find the missing resource)

Notification that the requested resource doesn't exist:
httpHTTP/1.1 404 Not Found
Content-Type: text/html; charset=utf-8
Content-Length: 38217
Connection: keep-alive
Cache-Control: no-cache, no-store, must-revalidate, max-age=0
Content-Language: en-US
Date: Thu, 06 Dec 2018 17:35:13 GMT
Expires: Thu, 06 Dec 2018 17:35:13 GMT
Server: meinheld/0.6.1
Strict-Transport-Security: max-age=63072000
X-Content-Type-Options: nosniff
X-Frame-Options: DENY
X-XSS-Protection: 1; mode=block
Vary: Accept-Encoding,Cookie
X-Cache: Error from cloudfront

<!doctype html>… (contains a site-customized page helping the user to find the missing resource)
Response status codesHTTP response status codes indicate if a specific HTTP request has been successfully completed. Responses are grouped into five classes: informational responses, successful responses, redirects, client errors, and server errors.

200: OK. The request has succeeded.
301: Moved Permanently. This response code means that the URI of requested resource has been changed.
404: Not Found. The server cannot find the requested resource.
See also
URLs
HTTP headers
HTTP request methods
HTTP response status codes
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 14, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nA typical HTTP sessionIn client-server protocols, like HTTP, sessions consist of three phases:

The client establishes a TCP connection (or the appropriate connection if the transport layer is not TCP).
The client sends its request, and waits for the answer.
The server processes the request, sending back its answer, providing a status code and appropriate data.

As of HTTP/1.1, the connection is no longer closed after completing the third phase, and the client is now granted a further request: this means the second and third phases can now be performed any number of times.Establishing a connectionIn client-server protocols, it is the client which establishes the connection. Opening a connection in HTTP means initiating a connection in the underlying transport layer, usually this is TCP.
With TCP the default port, for an HTTP server on a computer, is port 80. Other ports can also be used, like 8000 or 8080. The URL of a page to fetch contains both the domain name, and the port number, though the latter can be omitted if it is 80. See the URL reference for more details.

Note:
The client-server model does not allow the server to send data to the client without an explicit request for it. However, various Web APIs enable this use case, including the Push API, Server-sent events, and the WebSockets API.
Sending a client requestOnce the connection is established, the user-agent can send the request (a user-agent is typically a web browser, but can be anything else, a crawler, for example). A client request consists of text directives, separated by CRLF (carriage return, followed by line feed), divided into three blocks:


The first line contains a request method followed by its parameters:

the path of the document, as an absolute URL without the protocol or domain name
the HTTP protocol version



Subsequent lines represent an HTTP header, giving the server information about what type of data is appropriate (for example, what language, what MIME types), or other data altering its behavior (for example, not sending an answer if it is already cached). These HTTP headers form a block which ends with an empty line.


The final block is an optional data block, which may contain further data mainly used by the POST method.

Example requestsFetching the root page of developer.mozilla.org, (https://developer.mozilla.org/), and telling the server that the user-agent would prefer the page in French, if possible:
httpGET / HTTP/1.1
Host: developer.mozilla.org
Accept-Language: fr

Observe that final empty line, this separates the data block from the header block. As there is no Content-Length provided in an HTTP header, this data block is presented empty, marking the end of the headers, allowing the server to process the request the moment it receives this empty line.
For example, sending the result of a form:
httpPOST /contact_form.php HTTP/1.1
Host: developer.mozilla.org
Content-Length: 64
Content-Type: application/x-www-form-urlencoded

name=Joe%20User&request=Send%20me%20one%20of%20your%20catalogue
Request methodsHTTP defines a set of request methods indicating the desired action to be performed upon a resource. Although they can also be nouns, these requests methods are sometimes referred as HTTP verbs. The most common requests are GET and POST:

The GET method requests a data representation of the specified resource. Requests using GET should only retrieve data.
The POST method sends data to a server so it may change its state. This is the method often used for HTML Forms.
Structure of a server responseAfter the connected agent has sent its request, the web server processes it, and ultimately returns a response. Similar to a client request, a server response is formed of text directives, separated by CRLF, though divided into three blocks:

The first line, the status line, consists of an acknowledgment of the HTTP version used, followed by a response status code (and its brief meaning in human-readable text).
Subsequent lines represent specific HTTP headers, giving the client information about the data sent (for example, type, data size, compression algorithm used, hints about caching). Similarly to the block of HTTP headers for a client request, these HTTP headers form a block ending with an empty line.
The final block is a data block, which contains the optional data.
Example responsesSuccessful web page response:
httpHTTP/1.1 200 OK
Content-Type: text/html; charset=utf-8
Content-Length: 55743
Connection: keep-alive
Cache-Control: s-maxage=300, public, max-age=0
Content-Language: en-US
Date: Thu, 06 Dec 2018 17:37:18 GMT
ETag: "2e77ad1dc6ab0b53a2996dfd4653c1c3"
Server: meinheld/0.6.1
Strict-Transport-Security: max-age=63072000
X-Content-Type-Options: nosniff
X-Frame-Options: DENY
X-XSS-Protection: 1; mode=block
Vary: Accept-Encoding,Cookie
Age: 7

<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <title>A basic webpage</title>
</head>
<body>
  <h1>Basic HTML webpage</h1>
  <p>Hello, world!</p>
</body>
</html>

Notification that the requested resource has permanently moved:
httpHTTP/1.1 301 Moved Permanently
Server: Apache/2.4.37 (Red Hat)
Content-Type: text/html; charset=utf-8
Date: Thu, 06 Dec 2018 17:33:08 GMT
Location: https://developer.mozilla.org/ (this is the new link to the resource; it is expected that the user-agent will fetch it)
Keep-Alive: timeout=15, max=98
Accept-Ranges: bytes
Via: Moz-Cache-zlb05
Connection: Keep-Alive
Content-Length: 325 (the content contains a default page to display if the user-agent is not able to follow the link)

<!doctype html>… (contains a site-customized page helping the user to find the missing resource)

Notification that the requested resource doesn't exist:
httpHTTP/1.1 404 Not Found
Content-Type: text/html; charset=utf-8
Content-Length: 38217
Connection: keep-alive
Cache-Control: no-cache, no-store, must-revalidate, max-age=0
Content-Language: en-US
Date: Thu, 06 Dec 2018 17:35:13 GMT
Expires: Thu, 06 Dec 2018 17:35:13 GMT
Server: meinheld/0.6.1
Strict-Transport-Security: max-age=63072000
X-Content-Type-Options: nosniff
X-Frame-Options: DENY
X-XSS-Protection: 1; mode=block
Vary: Accept-Encoding,Cookie
X-Cache: Error from cloudfront

<!doctype html>… (contains a site-customized page helping the user to find the missing resource)
Response status codesHTTP response status codes indicate if a specific HTTP request has been successfully completed. Responses are grouped into five classes: informational responses, successful responses, redirects, client errors, and server errors.

200: OK. The request has succeeded.
301: Moved Permanently. This response code means that the URI of requested resource has been changed.
404: Not Found. The server cannot find the requested resource.
See also
URLs
HTTP headers
HTTP request methods
HTTP response status codes
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 14, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nHTTP messagesHTTP messages are the mechanism used to exchange data between a server and a client in the HTTP protocol.
There are two types of messages: requests sent by the client to trigger an action on the server, and responses, the answer that the server sends in response to a request.
Developers rarely, if ever, build HTTP messages from scratch.
Applications such as a browser, proxy, or web server use software designed to create HTTP messages in a reliable and efficient way.
How messages are created or transformed is controlled via APIs in browsers, configuration files for proxies or servers, or other interfaces.
In HTTP protocol versions up to HTTP/2, messages are text-based, and are relatively straightforward to read and understand after you've familiarized yourself with the format.
In HTTP/2, messages are wrapped in binary framing, which makes them slightly harder to read without certain tools.
However the underlying semantics of the protocol are the same, so you can learn the structure and meaning of HTTP messages based on the text-based format of HTTP/1.x messages, and apply this understanding to HTTP/2 and beyond.
This guide uses HTTP/1.1 messages for readability, and explains the structure of HTTP messages using the HTTP/1.1 format.
We highlight some differences that you might need for describing HTTP/2 in the final section.

Note:
You can see HTTP messages in a browser's Network tab in the developer tools, or if you print HTTP messages to the console using CLI tools such as curl, for example.
Anatomy of an HTTP messageTo understand how HTTP messages work, we'll look at HTTP/1.1 messages and examine the structure.
The following illustration shows what messages in HTTP/1.1 look like:

Both requests and responses share a similar structure:

A start-line is a single line that describes the HTTP version along with the request method or the outcome of the request.
An optional set of HTTP headers containing metadata that describes the message. For example, a request for a resource might include the allowed formats of that resource, while the response might include headers to indicate the actual format returned.
An empty line indicating the metadata of the message is complete.
An optional body containing data associated with the message. This might be POST data to send to the server in a request, or some resource returned to the client in a response.
Whether a message contains a body or not is determined by the start-line and HTTP headers.

The start-line and headers of the HTTP message are collectively known as the head of the requests, and the part afterwards that contains its content is known as the body.HTTP requestsLet's look at the following example HTTP POST request that's sent after a user submits a form on a web page:
httpPOST /users HTTP/1.1
Host: example.com
Content-Type: application/x-www-form-urlencoded
Content-Length: 50

name=FirstName%20LastName&email=bsmth%40example.com

The start-line in HTTP/1.x requests (POST /users HTTP/1.1 in the example above) is called a "request-line" and is made of three parts:
http<method> <request-target> <protocol>


<method>

The HTTP method (also known as an HTTP verb) is one of a set of defined words that describes the meaning of the request and the desired outcome.
For example, GET indicates that the client would like to receive a resource in return, and POST means that the client is sending data to a server.

<request-target>

The request target is usually an absolute or relative URL, and is characterized by the context of the request.
The format of the request target depends on the HTTP method used and the request context.
It is described in more detail in the Request targets section below.

<protocol>

The HTTP version, which defines the structure of the remaining message, acting as an indicator of the expected version to use for the response.
This is almost always HTTP/1.1, as HTTP/0.9 and HTTP/1.0 are obsolete.
In HTTP/2 and above, the protocol version isn't included in messages since it is understood from the connection setup.

Request targetsThere are a few ways of describing a request target, but by far the most common is the "origin form".
Here's a list of the types of targets and when they are used:


In origin form, the recipient combines an absolute path with the information in the Host header.
A query string can be appended to the path for additional information (usually in key=value format).
This is used with GET, POST, HEAD, and OPTIONS methods:
httpGET /en-US/docs/Web/HTTP/Guides/Messages HTTP/1.1



The absolute form is a complete URL, including the authority, and is used with GET when connecting to a proxy:
httpGET https://developer.mozilla.org/en-US/docs/Web/HTTP/Guides/Messages HTTP/1.1



The authority form is the authority and port separated by a colon (:).
It is only used with the CONNECT method when setting up an HTTP tunnel:
httpCONNECT developer.mozilla.org:443 HTTP/1.1



The asterisk form is only used with OPTIONS when you want to represent the server as a whole (*) as opposed to a named resource:
httpOPTIONS * HTTP/1.1


Request headersHeaders are metadata sent with a request after the start line and before the body.
In the form submission example above, they are the following lines of the message:
httpHost: example.com
Content-Type: application/x-www-form-urlencoded
Content-Length: 50

In HTTP/1.x, each header is a case-insensitive string followed by a colon (:) and a value whose format depends on the header.
The whole header, including the value, consists of one single line.
This line can be quite long in some cases, such as the Cookie header.

Some headers are exclusively used in requests, while others can be sent in both requests and responses, or might have a more specific categorization:

Request headers provide additional context to a request or add extra logic to how it should be treated by a server (e.g., conditional requests).
Representation headers are sent in a request if the message has a body, and they describe the original form of the message data and any encoding applied.
This allows the recipient to understand how to reconstruct the resource as it was before it was transmitted over the network.
Request bodyThe request body is the part of a request that carries information to the server.
Only PATCH, POST, and PUT requests have a body.
In the form submission example, this part is the body:
httpname=FirstName%20LastName&email=bsmth%40example.com

The body in the form submission request contains a relatively small amount of information as key=value pairs, but a request body could contain other types of data that the server expects:
json{
  "firstName": "Brian",
  "lastName": "Smith",
  "email": "bsmth@example.com",
  "more": "data"
}

or data in multiple parts:
http--delimiter123
Content-Disposition: form-data; name="field1"

value1
--delimiter123
Content-Disposition: form-data; name="field2"; filename="example.txt"

Text file contents
--delimiter123--
HTTP responsesResponses are the HTTP messages a server sends back in reply to a request.
The response lets the client know what the outcome of the request was.
Here's an example HTTP/1.1 response to a POST request that created a new user:
httpHTTP/1.1 201 Created
Content-Type: application/json
Location: http://example.com/users/123

{
  "message": "New user created",
  "user": {
    "id": 123,
    "firstName": "Example",
    "lastName": "Person",
    "email": "bsmth@example.com"
  }
}

The start-line (HTTP/1.1 201 Created above) is called a "status line" in responses, and has three parts:
http<protocol> <status-code> <status-text>


<protocol>

The HTTP version of the remaining message.

<status-code>

A numeric status code that indicates whether the request succeeded or failed.
Common status codes are 200, 404, or 302.

<status-text>

The status text is a brief, purely informational, textual description of the status code to help a human understand the HTTP message.

Response headersResponse headers are the metadata sent with a response.
In HTTP/1.x, each header is a case-insensitive string followed by a colon (:) and a value whose format depends upon which header is used.

Like request headers, there are many different headers that can appear in responses, and they are categorized as:

Response headers that give additional context about the message or add extra logic to how the client should make subsequent requests.
For example, headers like Server include information about the server software, while Date includes when the response was generated.
There is also information about the resource being returned, such as its content type (Content-Type), or how it should be cached (Cache-Control).
Representation headers if the message has a body, they describe the form of the message data and any encoding applied.
For example, the same resource might be formatted in a particular media type such as XML or JSON, localized to a particular written language or geographical region, and/or compressed or otherwise encoded for transmission.
This allows a recipient to understand how to reconstruct the resource as it was before it was transmitted over the network.
Response bodyA response body is included in most messages when responding to a client.
In successful requests, the response body contains the data that the client asked for in a GET request.
If there are problems with the client's request, it's common for the response body to describe why the request failed, and hint as to whether it's permanent or temporary.
Response bodies may be:

Single-resource bodies defined by the two headers: Content-Type and Content-Length, or of unknown length and encoded in chunks with Transfer-Encoding set to chunked.
Multiple-resource bodies, consisting of a body that contains multiple parts, each containing a different piece of information.
Multipart bodies are typically associated with HTML Forms, but may also be sent in response to Range requests.

Responses with a status code that answers the request without the need to include message content, such as 201 Created or 204 No Content, do not have a body.HTTP/2 messagesHTTP/1.x uses text-based messages that are straightforward to read and construct, but as a result have a few downsides.
You can compress message bodies using gzip or other compression algorithms, but not headers.
Headers are often similar or identical in a client-server interaction, but they are repeated in successive messages on a connection.
There are many known methods to compress repetitive text that are very efficient, which leaves a large amount of bandwidth savings unutilized.
HTTP/1.x also has a problem called head-of-line (HOL) blocking, where a client has to wait for a response from the server before sending the next request.
HTTP pipelining tried to work around this, but poor support and complexity means it's rarely used and difficult to get right.
Several connections need to be opened to send requests concurrently; and warm (established and busy) connections are more efficient than cold ones due to TCP slow start.
In HTTP/1.1 if you want to make two requests in parallel, you have to open two connections:

This means that browsers are limited in the number of resources that they can download and render at the same time, which has typically been limited to 6 parallel connections.
HTTP/2 allows you to use a single TCP connection for multiple requests and responses at the same time.
This is done by wrapping messages into a binary frame and sending the requests and responses in a numbered stream on a connection.
Data and header frames are handled separately, which allows headers to be compressed via an algorithm called HPACK.
Using the same TCP connection to handle multiple requests at the same time is called multiplexing.

Requests are not necessarily sequential: stream 9 doesn't have to wait for stream 7 to finish, for instance.
The data from multiple streams are usually interleaved on the connection, so stream 9 and 7 can be received by the client at the same time.
There's a mechanism for the protocol to set a priority for each stream or resource.
Low-priority resources take up less bandwidth than higher-priority resources when they're being sent over different streams, or they could effectively be sent sequentially on the same connection if there are critical resources that should be handled first.
In general, despite all of the improvements and abstractions added over HTTP/1.x, virtually no changes are needed in the APIs used by developers to make use of HTTP/2 over HTTP/1.x.
When HTTP/2 is available in both the browser and the server, it is switched on and used automatically.Pseudo-headersOne notable change to messages in HTTP/2 are the use of pseudo-headers.
Where HTTP/1.x used the message start-line, HTTP/2 uses special pseudo-header fields beginning with :.
In requests, there are the following pseudo-headers:

:method - the HTTP method.
:scheme - the scheme portion of the target URI, which is often HTTP(S).
:authority - the authority portion of the target URI.
:path - the path and query parts of the target URI.

In responses, there is only one pseudo-header, and that's the :status which provides the code of the response.
We can make a HTTP/2 request using nghttp to fetch example.com, which will print out the request in a form that's more readable.
You can make the request using this command where the -n option discards the downloaded data and -v is for 'verbose' output, showing reception and transmission of frames:
bashnghttp -nv https://www.example.com

If you look down through the output, you'll see the timing for each frame transmitted and received:
[  0.123] <send|recv> <frame-type> <frame-details>

We don't have to go into too much detail on this output, but look out for the HEADERS frame in the format [  0.123] send HEADERS frame ....
In the lines after the header transmission, you will see the following lines:
http[  0.447] send HEADERS frame ...
          ...
          :method: GET
          :path: /
          :scheme: https
          :authority: www.example.com
          accept: */*
          accept-encoding: gzip, deflate
          user-agent: nghttp2/1.61.0

This should look familiar if you're already comfortable working with HTTP/1.x and the concepts covered in the earlier section of this guide still apply.
This is the binary frame with the GET request for example.com, converted into a readable form by nghttp.
If you look further down the output of the command, you will see the :status pseudo-header in one of the streams received from the server:
http[  0.433] recv (stream_id=13) :status: 200
[  0.433] recv (stream_id=13) content-encoding: gzip
[  0.433] recv (stream_id=13) age: 112721
[  0.433] recv (stream_id=13) cache-control: max-age=604800
[  0.433] recv (stream_id=13) content-type: text/html; charset=UTF-8
[  0.433] recv (stream_id=13) date: Fri, 13 Sep 2024 12:56:07 GMT
[  0.433] recv (stream_id=13) etag: "3147526947+gzip"
...

And if you remove the timing and stream ID from this message, it should be even more familiar:
http:status: 200
content-encoding: gzip
age: 112721

Digging further into message frames, stream IDs and how the connection is managed is beyond the scope of this guide, but for the purpose of understanding and debugging HTTP/2 messages, you should be well-equipped using the knowledge and tools in this article.ConclusionThis guide provides a general overview of the anatomy of HTTP messages, using the HTTP/1.1 format for illustration.
We also explored HTTP/2 message framing, which introduces a layer between the HTTP/1.x syntax and the underlying transport protocol without fundamentally modifying HTTP's semantics.
HTTP/2 was introduced to solve the head-of-line blocking issues present in HTTP/1.x by enabling multiplexing of requests.
One issue that remained in HTTP/2 is that even though head-of-line blocking was fixed in the protocol level, there is still a performance bottleneck due to head-of-line blocking within TCP (at the transport level).
HTTP/3 addresses this limitation by using QUIC, a protocol built on UDP, instead of TCP.
This change improves performance, reduces connection setup time, and enhances stability on degraded or unreliable networks.
HTTP/3 retains the same core HTTP semantics, so features like request methods, status codes, and headers remain consistent across all three major HTTP versions.
If you understand HTTP/1.1's semantics, you already have a solid foundation for grasping HTTP/2 and HTTP/3.
The main difference lies in how these semantics are implemented at the transport level.
By following the examples and concepts in this guide, you should now feel equipped to work with HTTP and understand the meaning of messages, and how applications use HTTP to send and receive data.See also
Evolution of HTTP
Protocol upgrade mechanism
Glossary terms:

HTTP
HTTP/2
QUIC\n\nHTTP messagesHTTP messages are the mechanism used to exchange data between a server and a client in the HTTP protocol.
There are two types of messages: requests sent by the client to trigger an action on the server, and responses, the answer that the server sends in response to a request.
Developers rarely, if ever, build HTTP messages from scratch.
Applications such as a browser, proxy, or web server use software designed to create HTTP messages in a reliable and efficient way.
How messages are created or transformed is controlled via APIs in browsers, configuration files for proxies or servers, or other interfaces.
In HTTP protocol versions up to HTTP/2, messages are text-based, and are relatively straightforward to read and understand after you've familiarized yourself with the format.
In HTTP/2, messages are wrapped in binary framing, which makes them slightly harder to read without certain tools.
However the underlying semantics of the protocol are the same, so you can learn the structure and meaning of HTTP messages based on the text-based format of HTTP/1.x messages, and apply this understanding to HTTP/2 and beyond.
This guide uses HTTP/1.1 messages for readability, and explains the structure of HTTP messages using the HTTP/1.1 format.
We highlight some differences that you might need for describing HTTP/2 in the final section.

Note:
You can see HTTP messages in a browser's Network tab in the developer tools, or if you print HTTP messages to the console using CLI tools such as curl, for example.
Anatomy of an HTTP messageTo understand how HTTP messages work, we'll look at HTTP/1.1 messages and examine the structure.
The following illustration shows what messages in HTTP/1.1 look like:

Both requests and responses share a similar structure:

A start-line is a single line that describes the HTTP version along with the request method or the outcome of the request.
An optional set of HTTP headers containing metadata that describes the message. For example, a request for a resource might include the allowed formats of that resource, while the response might include headers to indicate the actual format returned.
An empty line indicating the metadata of the message is complete.
An optional body containing data associated with the message. This might be POST data to send to the server in a request, or some resource returned to the client in a response.
Whether a message contains a body or not is determined by the start-line and HTTP headers.

The start-line and headers of the HTTP message are collectively known as the head of the requests, and the part afterwards that contains its content is known as the body.HTTP requestsLet's look at the following example HTTP POST request that's sent after a user submits a form on a web page:
httpPOST /users HTTP/1.1
Host: example.com
Content-Type: application/x-www-form-urlencoded
Content-Length: 50

name=FirstName%20LastName&email=bsmth%40example.com

The start-line in HTTP/1.x requests (POST /users HTTP/1.1 in the example above) is called a "request-line" and is made of three parts:
http<method> <request-target> <protocol>


<method>

The HTTP method (also known as an HTTP verb) is one of a set of defined words that describes the meaning of the request and the desired outcome.
For example, GET indicates that the client would like to receive a resource in return, and POST means that the client is sending data to a server.

<request-target>

The request target is usually an absolute or relative URL, and is characterized by the context of the request.
The format of the request target depends on the HTTP method used and the request context.
It is described in more detail in the Request targets section below.

<protocol>

The HTTP version, which defines the structure of the remaining message, acting as an indicator of the expected version to use for the response.
This is almost always HTTP/1.1, as HTTP/0.9 and HTTP/1.0 are obsolete.
In HTTP/2 and above, the protocol version isn't included in messages since it is understood from the connection setup.

Request targetsThere are a few ways of describing a request target, but by far the most common is the "origin form".
Here's a list of the types of targets and when they are used:


In origin form, the recipient combines an absolute path with the information in the Host header.
A query string can be appended to the path for additional information (usually in key=value format).
This is used with GET, POST, HEAD, and OPTIONS methods:
httpGET /en-US/docs/Web/HTTP/Guides/Messages HTTP/1.1



The absolute form is a complete URL, including the authority, and is used with GET when connecting to a proxy:
httpGET https://developer.mozilla.org/en-US/docs/Web/HTTP/Guides/Messages HTTP/1.1



The authority form is the authority and port separated by a colon (:).
It is only used with the CONNECT method when setting up an HTTP tunnel:
httpCONNECT developer.mozilla.org:443 HTTP/1.1



The asterisk form is only used with OPTIONS when you want to represent the server as a whole (*) as opposed to a named resource:
httpOPTIONS * HTTP/1.1


Request headersHeaders are metadata sent with a request after the start line and before the body.
In the form submission example above, they are the following lines of the message:
httpHost: example.com
Content-Type: application/x-www-form-urlencoded
Content-Length: 50

In HTTP/1.x, each header is a case-insensitive string followed by a colon (:) and a value whose format depends on the header.
The whole header, including the value, consists of one single line.
This line can be quite long in some cases, such as the Cookie header.

Some headers are exclusively used in requests, while others can be sent in both requests and responses, or might have a more specific categorization:

Request headers provide additional context to a request or add extra logic to how it should be treated by a server (e.g., conditional requests).
Representation headers are sent in a request if the message has a body, and they describe the original form of the message data and any encoding applied.
This allows the recipient to understand how to reconstruct the resource as it was before it was transmitted over the network.
Request bodyThe request body is the part of a request that carries information to the server.
Only PATCH, POST, and PUT requests have a body.
In the form submission example, this part is the body:
httpname=FirstName%20LastName&email=bsmth%40example.com

The body in the form submission request contains a relatively small amount of information as key=value pairs, but a request body could contain other types of data that the server expects:
json{
  "firstName": "Brian",
  "lastName": "Smith",
  "email": "bsmth@example.com",
  "more": "data"
}

or data in multiple parts:
http--delimiter123
Content-Disposition: form-data; name="field1"

value1
--delimiter123
Content-Disposition: form-data; name="field2"; filename="example.txt"

Text file contents
--delimiter123--
HTTP responsesResponses are the HTTP messages a server sends back in reply to a request.
The response lets the client know what the outcome of the request was.
Here's an example HTTP/1.1 response to a POST request that created a new user:
httpHTTP/1.1 201 Created
Content-Type: application/json
Location: http://example.com/users/123

{
  "message": "New user created",
  "user": {
    "id": 123,
    "firstName": "Example",
    "lastName": "Person",
    "email": "bsmth@example.com"
  }
}

The start-line (HTTP/1.1 201 Created above) is called a "status line" in responses, and has three parts:
http<protocol> <status-code> <status-text>


<protocol>

The HTTP version of the remaining message.

<status-code>

A numeric status code that indicates whether the request succeeded or failed.
Common status codes are 200, 404, or 302.

<status-text>

The status text is a brief, purely informational, textual description of the status code to help a human understand the HTTP message.

Response headersResponse headers are the metadata sent with a response.
In HTTP/1.x, each header is a case-insensitive string followed by a colon (:) and a value whose format depends upon which header is used.

Like request headers, there are many different headers that can appear in responses, and they are categorized as:

Response headers that give additional context about the message or add extra logic to how the client should make subsequent requests.
For example, headers like Server include information about the server software, while Date includes when the response was generated.
There is also information about the resource being returned, such as its content type (Content-Type), or how it should be cached (Cache-Control).
Representation headers if the message has a body, they describe the form of the message data and any encoding applied.
For example, the same resource might be formatted in a particular media type such as XML or JSON, localized to a particular written language or geographical region, and/or compressed or otherwise encoded for transmission.
This allows a recipient to understand how to reconstruct the resource as it was before it was transmitted over the network.
Response bodyA response body is included in most messages when responding to a client.
In successful requests, the response body contains the data that the client asked for in a GET request.
If there are problems with the client's request, it's common for the response body to describe why the request failed, and hint as to whether it's permanent or temporary.
Response bodies may be:

Single-resource bodies defined by the two headers: Content-Type and Content-Length, or of unknown length and encoded in chunks with Transfer-Encoding set to chunked.
Multiple-resource bodies, consisting of a body that contains multiple parts, each containing a different piece of information.
Multipart bodies are typically associated with HTML Forms, but may also be sent in response to Range requests.

Responses with a status code that answers the request without the need to include message content, such as 201 Created or 204 No Content, do not have a body.HTTP/2 messagesHTTP/1.x uses text-based messages that are straightforward to read and construct, but as a result have a few downsides.
You can compress message bodies using gzip or other compression algorithms, but not headers.
Headers are often similar or identical in a client-server interaction, but they are repeated in successive messages on a connection.
There are many known methods to compress repetitive text that are very efficient, which leaves a large amount of bandwidth savings unutilized.
HTTP/1.x also has a problem called head-of-line (HOL) blocking, where a client has to wait for a response from the server before sending the next request.
HTTP pipelining tried to work around this, but poor support and complexity means it's rarely used and difficult to get right.
Several connections need to be opened to send requests concurrently; and warm (established and busy) connections are more efficient than cold ones due to TCP slow start.
In HTTP/1.1 if you want to make two requests in parallel, you have to open two connections:

This means that browsers are limited in the number of resources that they can download and render at the same time, which has typically been limited to 6 parallel connections.
HTTP/2 allows you to use a single TCP connection for multiple requests and responses at the same time.
This is done by wrapping messages into a binary frame and sending the requests and responses in a numbered stream on a connection.
Data and header frames are handled separately, which allows headers to be compressed via an algorithm called HPACK.
Using the same TCP connection to handle multiple requests at the same time is called multiplexing.

Requests are not necessarily sequential: stream 9 doesn't have to wait for stream 7 to finish, for instance.
The data from multiple streams are usually interleaved on the connection, so stream 9 and 7 can be received by the client at the same time.
There's a mechanism for the protocol to set a priority for each stream or resource.
Low-priority resources take up less bandwidth than higher-priority resources when they're being sent over different streams, or they could effectively be sent sequentially on the same connection if there are critical resources that should be handled first.
In general, despite all of the improvements and abstractions added over HTTP/1.x, virtually no changes are needed in the APIs used by developers to make use of HTTP/2 over HTTP/1.x.
When HTTP/2 is available in both the browser and the server, it is switched on and used automatically.Pseudo-headersOne notable change to messages in HTTP/2 are the use of pseudo-headers.
Where HTTP/1.x used the message start-line, HTTP/2 uses special pseudo-header fields beginning with :.
In requests, there are the following pseudo-headers:

:method - the HTTP method.
:scheme - the scheme portion of the target URI, which is often HTTP(S).
:authority - the authority portion of the target URI.
:path - the path and query parts of the target URI.

In responses, there is only one pseudo-header, and that's the :status which provides the code of the response.
We can make a HTTP/2 request using nghttp to fetch example.com, which will print out the request in a form that's more readable.
You can make the request using this command where the -n option discards the downloaded data and -v is for 'verbose' output, showing reception and transmission of frames:
bashnghttp -nv https://www.example.com

If you look down through the output, you'll see the timing for each frame transmitted and received:
[  0.123] <send|recv> <frame-type> <frame-details>

We don't have to go into too much detail on this output, but look out for the HEADERS frame in the format [  0.123] send HEADERS frame ....
In the lines after the header transmission, you will see the following lines:
http[  0.447] send HEADERS frame ...
          ...
          :method: GET
          :path: /
          :scheme: https
          :authority: www.example.com
          accept: */*
          accept-encoding: gzip, deflate
          user-agent: nghttp2/1.61.0

This should look familiar if you're already comfortable working with HTTP/1.x and the concepts covered in the earlier section of this guide still apply.
This is the binary frame with the GET request for example.com, converted into a readable form by nghttp.
If you look further down the output of the command, you will see the :status pseudo-header in one of the streams received from the server:
http[  0.433] recv (stream_id=13) :status: 200
[  0.433] recv (stream_id=13) content-encoding: gzip
[  0.433] recv (stream_id=13) age: 112721
[  0.433] recv (stream_id=13) cache-control: max-age=604800
[  0.433] recv (stream_id=13) content-type: text/html; charset=UTF-8
[  0.433] recv (stream_id=13) date: Fri, 13 Sep 2024 12:56:07 GMT
[  0.433] recv (stream_id=13) etag: "3147526947+gzip"
...

And if you remove the timing and stream ID from this message, it should be even more familiar:
http:status: 200
content-encoding: gzip
age: 112721

Digging further into message frames, stream IDs and how the connection is managed is beyond the scope of this guide, but for the purpose of understanding and debugging HTTP/2 messages, you should be well-equipped using the knowledge and tools in this article.ConclusionThis guide provides a general overview of the anatomy of HTTP messages, using the HTTP/1.1 format for illustration.
We also explored HTTP/2 message framing, which introduces a layer between the HTTP/1.x syntax and the underlying transport protocol without fundamentally modifying HTTP's semantics.
HTTP/2 was introduced to solve the head-of-line blocking issues present in HTTP/1.x by enabling multiplexing of requests.
One issue that remained in HTTP/2 is that even though head-of-line blocking was fixed in the protocol level, there is still a performance bottleneck due to head-of-line blocking within TCP (at the transport level).
HTTP/3 addresses this limitation by using QUIC, a protocol built on UDP, instead of TCP.
This change improves performance, reduces connection setup time, and enhances stability on degraded or unreliable networks.
HTTP/3 retains the same core HTTP semantics, so features like request methods, status codes, and headers remain consistent across all three major HTTP versions.
If you understand HTTP/1.1's semantics, you already have a solid foundation for grasping HTTP/2 and HTTP/3.
The main difference lies in how these semantics are implemented at the transport level.
By following the examples and concepts in this guide, you should now feel equipped to work with HTTP and understand the meaning of messages, and how applications use HTTP to send and receive data.See also
Evolution of HTTP
Protocol upgrade mechanism
Glossary terms:

HTTP
HTTP/2
QUIC


Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 22, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nHTTP messagesHTTP messages are the mechanism used to exchange data between a server and a client in the HTTP protocol.
There are two types of messages: requests sent by the client to trigger an action on the server, and responses, the answer that the server sends in response to a request.
Developers rarely, if ever, build HTTP messages from scratch.
Applications such as a browser, proxy, or web server use software designed to create HTTP messages in a reliable and efficient way.
How messages are created or transformed is controlled via APIs in browsers, configuration files for proxies or servers, or other interfaces.
In HTTP protocol versions up to HTTP/2, messages are text-based, and are relatively straightforward to read and understand after you've familiarized yourself with the format.
In HTTP/2, messages are wrapped in binary framing, which makes them slightly harder to read without certain tools.
However the underlying semantics of the protocol are the same, so you can learn the structure and meaning of HTTP messages based on the text-based format of HTTP/1.x messages, and apply this understanding to HTTP/2 and beyond.
This guide uses HTTP/1.1 messages for readability, and explains the structure of HTTP messages using the HTTP/1.1 format.
We highlight some differences that you might need for describing HTTP/2 in the final section.

Note:
You can see HTTP messages in a browser's Network tab in the developer tools, or if you print HTTP messages to the console using CLI tools such as curl, for example.
Anatomy of an HTTP messageTo understand how HTTP messages work, we'll look at HTTP/1.1 messages and examine the structure.
The following illustration shows what messages in HTTP/1.1 look like:

Both requests and responses share a similar structure:

A start-line is a single line that describes the HTTP version along with the request method or the outcome of the request.
An optional set of HTTP headers containing metadata that describes the message. For example, a request for a resource might include the allowed formats of that resource, while the response might include headers to indicate the actual format returned.
An empty line indicating the metadata of the message is complete.
An optional body containing data associated with the message. This might be POST data to send to the server in a request, or some resource returned to the client in a response.
Whether a message contains a body or not is determined by the start-line and HTTP headers.

The start-line and headers of the HTTP message are collectively known as the head of the requests, and the part afterwards that contains its content is known as the body.HTTP requestsLet's look at the following example HTTP POST request that's sent after a user submits a form on a web page:
httpPOST /users HTTP/1.1
Host: example.com
Content-Type: application/x-www-form-urlencoded
Content-Length: 50

name=FirstName%20LastName&email=bsmth%40example.com

The start-line in HTTP/1.x requests (POST /users HTTP/1.1 in the example above) is called a "request-line" and is made of three parts:
http<method> <request-target> <protocol>


<method>

The HTTP method (also known as an HTTP verb) is one of a set of defined words that describes the meaning of the request and the desired outcome.
For example, GET indicates that the client would like to receive a resource in return, and POST means that the client is sending data to a server.

<request-target>

The request target is usually an absolute or relative URL, and is characterized by the context of the request.
The format of the request target depends on the HTTP method used and the request context.
It is described in more detail in the Request targets section below.

<protocol>

The HTTP version, which defines the structure of the remaining message, acting as an indicator of the expected version to use for the response.
This is almost always HTTP/1.1, as HTTP/0.9 and HTTP/1.0 are obsolete.
In HTTP/2 and above, the protocol version isn't included in messages since it is understood from the connection setup.

Request targetsThere are a few ways of describing a request target, but by far the most common is the "origin form".
Here's a list of the types of targets and when they are used:


In origin form, the recipient combines an absolute path with the information in the Host header.
A query string can be appended to the path for additional information (usually in key=value format).
This is used with GET, POST, HEAD, and OPTIONS methods:
httpGET /en-US/docs/Web/HTTP/Guides/Messages HTTP/1.1



The absolute form is a complete URL, including the authority, and is used with GET when connecting to a proxy:
httpGET https://developer.mozilla.org/en-US/docs/Web/HTTP/Guides/Messages HTTP/1.1



The authority form is the authority and port separated by a colon (:).
It is only used with the CONNECT method when setting up an HTTP tunnel:
httpCONNECT developer.mozilla.org:443 HTTP/1.1



The asterisk form is only used with OPTIONS when you want to represent the server as a whole (*) as opposed to a named resource:
httpOPTIONS * HTTP/1.1


Request headersHeaders are metadata sent with a request after the start line and before the body.
In the form submission example above, they are the following lines of the message:
httpHost: example.com
Content-Type: application/x-www-form-urlencoded
Content-Length: 50

In HTTP/1.x, each header is a case-insensitive string followed by a colon (:) and a value whose format depends on the header.
The whole header, including the value, consists of one single line.
This line can be quite long in some cases, such as the Cookie header.

Some headers are exclusively used in requests, while others can be sent in both requests and responses, or might have a more specific categorization:

Request headers provide additional context to a request or add extra logic to how it should be treated by a server (e.g., conditional requests).
Representation headers are sent in a request if the message has a body, and they describe the original form of the message data and any encoding applied.
This allows the recipient to understand how to reconstruct the resource as it was before it was transmitted over the network.
Request bodyThe request body is the part of a request that carries information to the server.
Only PATCH, POST, and PUT requests have a body.
In the form submission example, this part is the body:
httpname=FirstName%20LastName&email=bsmth%40example.com

The body in the form submission request contains a relatively small amount of information as key=value pairs, but a request body could contain other types of data that the server expects:
json{
  "firstName": "Brian",
  "lastName": "Smith",
  "email": "bsmth@example.com",
  "more": "data"
}

or data in multiple parts:
http--delimiter123
Content-Disposition: form-data; name="field1"

value1
--delimiter123
Content-Disposition: form-data; name="field2"; filename="example.txt"

Text file contents
--delimiter123--
HTTP responsesResponses are the HTTP messages a server sends back in reply to a request.
The response lets the client know what the outcome of the request was.
Here's an example HTTP/1.1 response to a POST request that created a new user:
httpHTTP/1.1 201 Created
Content-Type: application/json
Location: http://example.com/users/123

{
  "message": "New user created",
  "user": {
    "id": 123,
    "firstName": "Example",
    "lastName": "Person",
    "email": "bsmth@example.com"
  }
}

The start-line (HTTP/1.1 201 Created above) is called a "status line" in responses, and has three parts:
http<protocol> <status-code> <status-text>


<protocol>

The HTTP version of the remaining message.

<status-code>

A numeric status code that indicates whether the request succeeded or failed.
Common status codes are 200, 404, or 302.

<status-text>

The status text is a brief, purely informational, textual description of the status code to help a human understand the HTTP message.

Response headersResponse headers are the metadata sent with a response.
In HTTP/1.x, each header is a case-insensitive string followed by a colon (:) and a value whose format depends upon which header is used.

Like request headers, there are many different headers that can appear in responses, and they are categorized as:

Response headers that give additional context about the message or add extra logic to how the client should make subsequent requests.
For example, headers like Server include information about the server software, while Date includes when the response was generated.
There is also information about the resource being returned, such as its content type (Content-Type), or how it should be cached (Cache-Control).
Representation headers if the message has a body, they describe the form of the message data and any encoding applied.
For example, the same resource might be formatted in a particular media type such as XML or JSON, localized to a particular written language or geographical region, and/or compressed or otherwise encoded for transmission.
This allows a recipient to understand how to reconstruct the resource as it was before it was transmitted over the network.
Response bodyA response body is included in most messages when responding to a client.
In successful requests, the response body contains the data that the client asked for in a GET request.
If there are problems with the client's request, it's common for the response body to describe why the request failed, and hint as to whether it's permanent or temporary.
Response bodies may be:

Single-resource bodies defined by the two headers: Content-Type and Content-Length, or of unknown length and encoded in chunks with Transfer-Encoding set to chunked.
Multiple-resource bodies, consisting of a body that contains multiple parts, each containing a different piece of information.
Multipart bodies are typically associated with HTML Forms, but may also be sent in response to Range requests.

Responses with a status code that answers the request without the need to include message content, such as 201 Created or 204 No Content, do not have a body.HTTP/2 messagesHTTP/1.x uses text-based messages that are straightforward to read and construct, but as a result have a few downsides.
You can compress message bodies using gzip or other compression algorithms, but not headers.
Headers are often similar or identical in a client-server interaction, but they are repeated in successive messages on a connection.
There are many known methods to compress repetitive text that are very efficient, which leaves a large amount of bandwidth savings unutilized.
HTTP/1.x also has a problem called head-of-line (HOL) blocking, where a client has to wait for a response from the server before sending the next request.
HTTP pipelining tried to work around this, but poor support and complexity means it's rarely used and difficult to get right.
Several connections need to be opened to send requests concurrently; and warm (established and busy) connections are more efficient than cold ones due to TCP slow start.
In HTTP/1.1 if you want to make two requests in parallel, you have to open two connections:

This means that browsers are limited in the number of resources that they can download and render at the same time, which has typically been limited to 6 parallel connections.
HTTP/2 allows you to use a single TCP connection for multiple requests and responses at the same time.
This is done by wrapping messages into a binary frame and sending the requests and responses in a numbered stream on a connection.
Data and header frames are handled separately, which allows headers to be compressed via an algorithm called HPACK.
Using the same TCP connection to handle multiple requests at the same time is called multiplexing.

Requests are not necessarily sequential: stream 9 doesn't have to wait for stream 7 to finish, for instance.
The data from multiple streams are usually interleaved on the connection, so stream 9 and 7 can be received by the client at the same time.
There's a mechanism for the protocol to set a priority for each stream or resource.
Low-priority resources take up less bandwidth than higher-priority resources when they're being sent over different streams, or they could effectively be sent sequentially on the same connection if there are critical resources that should be handled first.
In general, despite all of the improvements and abstractions added over HTTP/1.x, virtually no changes are needed in the APIs used by developers to make use of HTTP/2 over HTTP/1.x.
When HTTP/2 is available in both the browser and the server, it is switched on and used automatically.Pseudo-headersOne notable change to messages in HTTP/2 are the use of pseudo-headers.
Where HTTP/1.x used the message start-line, HTTP/2 uses special pseudo-header fields beginning with :.
In requests, there are the following pseudo-headers:

:method - the HTTP method.
:scheme - the scheme portion of the target URI, which is often HTTP(S).
:authority - the authority portion of the target URI.
:path - the path and query parts of the target URI.

In responses, there is only one pseudo-header, and that's the :status which provides the code of the response.
We can make a HTTP/2 request using nghttp to fetch example.com, which will print out the request in a form that's more readable.
You can make the request using this command where the -n option discards the downloaded data and -v is for 'verbose' output, showing reception and transmission of frames:
bashnghttp -nv https://www.example.com

If you look down through the output, you'll see the timing for each frame transmitted and received:
[  0.123] <send|recv> <frame-type> <frame-details>

We don't have to go into too much detail on this output, but look out for the HEADERS frame in the format [  0.123] send HEADERS frame ....
In the lines after the header transmission, you will see the following lines:
http[  0.447] send HEADERS frame ...
          ...
          :method: GET
          :path: /
          :scheme: https
          :authority: www.example.com
          accept: */*
          accept-encoding: gzip, deflate
          user-agent: nghttp2/1.61.0

This should look familiar if you're already comfortable working with HTTP/1.x and the concepts covered in the earlier section of this guide still apply.
This is the binary frame with the GET request for example.com, converted into a readable form by nghttp.
If you look further down the output of the command, you will see the :status pseudo-header in one of the streams received from the server:
http[  0.433] recv (stream_id=13) :status: 200
[  0.433] recv (stream_id=13) content-encoding: gzip
[  0.433] recv (stream_id=13) age: 112721
[  0.433] recv (stream_id=13) cache-control: max-age=604800
[  0.433] recv (stream_id=13) content-type: text/html; charset=UTF-8
[  0.433] recv (stream_id=13) date: Fri, 13 Sep 2024 12:56:07 GMT
[  0.433] recv (stream_id=13) etag: "3147526947+gzip"
...

And if you remove the timing and stream ID from this message, it should be even more familiar:
http:status: 200
content-encoding: gzip
age: 112721

Digging further into message frames, stream IDs and how the connection is managed is beyond the scope of this guide, but for the purpose of understanding and debugging HTTP/2 messages, you should be well-equipped using the knowledge and tools in this article.ConclusionThis guide provides a general overview of the anatomy of HTTP messages, using the HTTP/1.1 format for illustration.
We also explored HTTP/2 message framing, which introduces a layer between the HTTP/1.x syntax and the underlying transport protocol without fundamentally modifying HTTP's semantics.
HTTP/2 was introduced to solve the head-of-line blocking issues present in HTTP/1.x by enabling multiplexing of requests.
One issue that remained in HTTP/2 is that even though head-of-line blocking was fixed in the protocol level, there is still a performance bottleneck due to head-of-line blocking within TCP (at the transport level).
HTTP/3 addresses this limitation by using QUIC, a protocol built on UDP, instead of TCP.
This change improves performance, reduces connection setup time, and enhances stability on degraded or unreliable networks.
HTTP/3 retains the same core HTTP semantics, so features like request methods, status codes, and headers remain consistent across all three major HTTP versions.
If you understand HTTP/1.1's semantics, you already have a solid foundation for grasping HTTP/2 and HTTP/3.
The main difference lies in how these semantics are implemented at the transport level.
By following the examples and concepts in this guide, you should now feel equipped to work with HTTP and understand the meaning of messages, and how applications use HTTP to send and receive data.See also
Evolution of HTTP
Protocol upgrade mechanism
Glossary terms:

HTTP
HTTP/2
QUIC


Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 22, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nMIME types (IANA media types)A media type (also known as a Multipurpose Internet Mail Extensions or MIME type) indicates the nature and format of a document, file, or assortment of bytes.
MIME types are defined and standardized in IETF's RFC 6838.
The Internet Assigned Numbers Authority (IANA) is responsible for all official MIME types, and you can find the most up-to-date and complete list at their Media Types page.

Warning:
Browsers use the MIME type, not the file extension, to determine how to process a URL,
so it's important that web servers send the correct MIME type in the response's Content-Type header.
If this is not correctly configured, browsers are likely to misinterpret the contents of files, sites will not work correctly, and downloaded files may be mishandled.
Structure of a MIME typeA MIME type most commonly consists of just two parts: a type and a subtype, separated by a slash (/) — with no whitespace between:
type/subtype

The type represents the general category into which the data type falls, such as video or text.
The subtype identifies the exact kind of data of the specified type the MIME type represents.
For example, for the MIME type text, the subtype might be plain (plain text), html (HTML source code), or calendar (for iCalendar/.ics) files.
Each type has its own set of possible subtypes. A MIME type always has both a type and a subtype, never just one or the other.
An optional parameter can be added to provide additional details:
type/subtype;parameter=value

For example, for any MIME type whose main type is text, you can add the optional charset parameter to specify the character set used for the
characters in the data.
If no charset is specified, the default is ASCII (US-ASCII) unless overridden by the user agent's settings.
To specify a UTF-8 text file, the MIME type text/plain;charset=UTF-8 is used.
MIME types are case-insensitive but are traditionally written in lowercase. The parameter values can be case-sensitive.TypesThere are two classes of type: discrete and multipart.
Discrete types are types which represent a single file or medium, such as a single text or music file, or a single video.
A multipart type represents a document that's comprised of multiple component parts, each of which may have its own individual MIME type; or, a multipart type may encapsulate multiple files being sent together in one transaction.
For example, multipart MIME types are used when attaching multiple files to an email.
Discrete types
The discrete types currently registered with the IANA are:

application

Any kind of binary data that doesn't fall explicitly into one of the other types;
either data that will be executed or interpreted in some way or binary data that requires a specific application or category of application to use.
Generic binary data (or binary data whose true type is unknown) is application/octet-stream.
Other common examples include application/pdf, application/pkcs8, and application/zip.
(See application type registry at IANA)

audio

Audio or music data. Examples include audio/mpeg,
audio/vorbis.
(See audio type registry at IANA)

example

Reserved for use as a placeholder in examples showing how to use MIME types.
These should never be used outside of sample code listings and documentation.
example can also be used as a subtype;
for instance, in an example related to working with audio on the web, the MIME type audio/example can be used to indicate that the type is a placeholder and should be replaced with an appropriate one when using the code in the real world.

font

Font/typeface data. Common examples include font/woff, font/ttf, and font/otf.
(See font type registry at IANA)

image

Image or graphical data including both bitmap and vector still images as well as
animated versions of still image formats such as animated GIF or APNG.
Common examples are image/jpeg, image/png, and image/svg+xml.
(See image type registry at IANA)

model

Model data for a 3D object or scene. Examples include model/3mf and model/vrml.
(See model type registry at IANA)

text

Text-only data including any human-readable content, source code, or textual data such as comma-separated value (CSV) formatted data.
Examples include: text/plain, text/csv, and text/html.
(See text type registry at IANA)

video

Video data or files, such as MP4 movies (video/mp4).
(See video type registry at IANA)


For text documents without a specific subtype, text/plain should be used.
Similarly, for binary documents without a specific or known subtype, application/octet-stream should be used.
Multipart types
Multipart types indicate a category of document broken into
pieces, often with different MIME types; they can also be used — especially in email
scenarios — to represent multiple, separate files which are all part of the same
transaction. They represent a composite document.
Except for multipart/form-data, used in the POST method of HTML Forms, and multipart/byteranges, used with 206 Partial Content to send part of a document, HTTP doesn't handle multipart documents in a special way: the message is transmitted to the browser (which will likely
show a "Save As" window if it doesn't know how to display the document).
There are two multipart types:

message

A message that encapsulates other messages. This can be used, for instance, to represent an email that includes a forwarded message as part of its data,
or to allow sending very large messages in chunks as if it were multiple messages.
Examples include message/rfc822 (for forwarded or replied-to message quoting) and message/partial to allow breaking a large message into smaller ones automatically to be reassembled by the recipient.
(See message type registry at IANA)

multipart

Data that consists of multiple components which may individually have different MIME types.
Examples include multipart/form-data (for data produced using the FormData API) and multipart/byteranges (defined in RFC 7233, section 5.4.1 and used with HTTP's 206
"Partial Content" response returned when the fetched data is only part of the content, such as is delivered using the Range header).
(See multipart type registry at IANA)

Important MIME types for Web developersapplication/octet-streamThis is the default for binary files. As it means unknown binary file, browsers usually don't execute it, or even ask if it should be executed. They treat it as if the Content-Disposition header was set to attachment, and propose a "Save As" dialog.text/plainThis is the default for textual files. Even if it really means "unknown textual file," browsers assume they can display it.

Note: text/plain does not mean "any kind of textual data."
If they expect a specific kind of textual data, they will likely not consider it a match.
Specifically if they download a text/plain file from a <link> element declaring a CSS file, they will not recognize it as a valid CSS file if presented with text/plain.
The CSS mime type text/css must be used.
text/cssCSS files used to style a Web page must be sent with text/css.
If a server doesn't recognize the .css suffix for CSS files, it may send them with text/plain or application/octet-stream MIME types.
If so, they won't be recognized as CSS by most browsers and will be ignored.text/htmlAll HTML content should be served with this type. Alternative MIME types for XHTML (like application/xhtml+xml) are mostly useless nowadays.

Note:
Use application/xml or application/xhtml+xml if you want XML's strict parsing rules, <![CDATA[…]]> sections, or elements that aren't from HTML/SVG/MathML namespaces.
text/javascriptPer the IANA Media Types registry, RFC 9239, and the HTML specification, JavaScript content should always be served using the MIME type text/javascript.
No other MIME types are considered valid for JavaScript, and using any MIME type other than text/javascript may result in scripts that do not load or run.
You may find some JavaScript content incorrectly served with a charset parameter as part of the MIME type — as an attempt to specify the character set for the script content.
That charset parameter isn't valid for JavaScript content, and in most cases will result in a script failing to load.application/jsonJavaScript Object Notation (JSON) is a standard text-based format for representing structured data based on JavaScript object syntax.
It is commonly used for transmitting data in web applications.
Legacy JavaScript MIME types
In addition to the text/javascript MIME type, for historical reasons, the MIME Sniffing Standard
(the definition of how browsers should interpret MIME types and figure
out what to do with content that doesn't have a valid one) also allows JavaScript to be served using any of the following legacy JavaScript MIME types:

application/javascript 
Deprecated

application/ecmascript 
Deprecated

application/x-ecmascript 
Non-standard

application/x-javascript 
Non-standard

text/ecmascript 
Deprecated

text/javascript1.0 
Non-standard

text/javascript1.1 
Non-standard

text/javascript1.2 
Non-standard

text/javascript1.3 
Non-standard

text/javascript1.4 
Non-standard

text/javascript1.5 
Non-standard

text/jscript 
Non-standard

text/livescript 
Non-standard

text/x-ecmascript 
Non-standard

text/x-javascript 
Non-standard



Note:
Even though any given user agent may support any or all of these, you should only use text/javascript.
It's the only MIME type guaranteed to work now and into the future.
Image typesFiles whose MIME type is image contain image data.
The subtype specifies which specific image file format the data represents.
The following image types are used commonly enough to be considered safe for use on web pages:

image/apng: Animated Portable Network Graphics (APNG)
image/avif : AV1 Image File Format (AVIF)
image/gif: Graphics Interchange Format (GIF)
image/jpeg: Joint Photographic Expert Group image (JPEG)
image/png: Portable Network Graphics (PNG)
image/svg+xml: Scalable Vector Graphics (SVG)
image/webp: Web Picture format (WEBP)

The Image file type and format guide provides information and recommendations about when to use the different image formats.Audio and video typesAs is the case for images, HTML doesn't mandate that web browsers support any specific file and codec types for the <audio> and <video> elements, so it's important to consider your target audience and the range of browsers (and versions of those browsers) they may be using when choosing the file type and codecs to use for media.
Our media container formats guide provides a list of the file types that are commonly supported by web browsers,
including information about what their special use cases may be, any drawbacks they have, and compatibility information, along with other details.
The audio codec and video codec guides list the various codecs that web browsers often support, providing compatibility details along with technical information such as how many audio channels they support, what sort of compression is used, and what bit rates and so forth they're useful at.
The codecs used by WebRTC guide expands upon this by specifically covering the codecs supported by the major web browsers, so you can choose the codecs that best cover the range of browsers you wish to support.
As for MIME types of audio or video files, they typically specify the container format (file type).
The optional codecs parameter can be added to the MIME type to further specify which codecs to use and what options were used to encode the media, such as codec profile, level, or other such information.
For more information on common media types, see the Common MIME types page.multipart/form-dataThe multipart/form-data type can be used when sending the values of a completed HTML Form from browser to server.
As a multipart document format, it consists of different parts, delimited by a boundary (a string starting with a double dash --).
Each part is its own entity with its own HTTP headers, Content-Disposition, and Content-Type for file uploading fields.
httpContent-Type: multipart/form-data; boundary=aBoundaryString
(other headers associated with the multipart document as a whole)

--aBoundaryString
Content-Disposition: form-data; name="myFile"; filename="img.jpg"
Content-Type: image/jpeg

(data)
--aBoundaryString
Content-Disposition: form-data; name="myField"

(data)
--aBoundaryString
(more subparts)
--aBoundaryString--

The following <form>:
html<form
  action="http://localhost:8000/"
  method="post"
  enctype="multipart/form-data">
  <label>Name: <input name="myTextField" value="Test" /></label>
  <label><input type="checkbox" name="myCheckBox" /> Check</label>
  <label>
    Upload file: <input type="file" name="myFile" value="test.txt" />
  </label>
  <button>Send the file</button>
</form>

will send this message:
httpPOST / HTTP/1.1
Host: localhost:8000
User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.9; rv:50.0) Gecko/20100101 Firefox/50.0
Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
Accept-Language: en-US,en;q=0.5
Accept-Encoding: gzip, deflate
Connection: keep-alive
Upgrade-Insecure-Requests: 1
Content-Type: multipart/form-data; boundary=---------------------------8721656041911415653955004498
Content-Length: 465

-----------------------------8721656041911415653955004498
Content-Disposition: form-data; name="myTextField"

Test
-----------------------------8721656041911415653955004498
Content-Disposition: form-data; name="myCheckBox"

on
-----------------------------8721656041911415653955004498
Content-Disposition: form-data; name="myFile"; filename="test.txt"
Content-Type: text/plain

Simple file.
-----------------------------8721656041911415653955004498--
multipart/byterangesThe multipart/byteranges MIME type is used to send partial responses to the browser.
When the 206 Partial Content status code is sent, this MIME type indicates that the document is composed of several parts, one for each of the
requested ranges. Like other multipart types, the Content-Type uses a boundary to separate the pieces.
Each piece has a Content-Type header with its actual type and a Content-Range of the range it represents.
httpHTTP/1.1 206 Partial Content
Accept-Ranges: bytes
Content-Type: multipart/byteranges; boundary=3d6b6a416f9b5
Content-Length: 385

--3d6b6a416f9b5
Content-Type: text/html
Content-Range: bytes 100-200/1270

eta http-equiv="Content-type" content="text/html; charset=utf-8" />
    <meta name="viewport" content
--3d6b6a416f9b5
Content-Type: text/html
Content-Range: bytes 300-400/1270

-color: #f0f0f2;
        margin: 0;
        padding: 0;
        font-family: "Open Sans", "Helvetica
--3d6b6a416f9b5--
Importance of setting the correct MIME typeSome server configurations may use the associated MIME type to perform optimizations, such as file concatenation, compression, or caching. See h5bp/server-configs-apache for an example of an Apache configuration that compresses files of certain MIME types.
Most web servers send unrecognized resources as the application/octet-stream MIME type.
For security reasons, most browsers do not allow setting a custom default action (like "Open in Word") for such resources, forcing the user to save it to disk to use it.
Some common incorrect server configurations:

RAR-compressed files.
In this case, the ideal would be the true type of the original files; this is often impossible as .RAR files can hold several resources of different types.
In this case, configure the server to send application/x-rar-compressed.
Audio and video.
Only resources with the correct MIME Type will be played in <video> or <audio> elements.
Be sure to specify the correct media type for audio and video.
Proprietary file types.
A specific type like application/vnd.mspowerpoint lets users open such files automatically in the presentation software of their choice.
MIME sniffingIn the absence of a MIME type, or in certain cases where browsers believe they are incorrect, browsers may perform MIME sniffing — guessing the correct MIME type by looking at the bytes of the resource.
Each browser performs MIME sniffing differently and under different circumstances.
(For example, Safari will look at the file extension in the URL if the sent MIME type is unsuitable.)
There are security concerns as some MIME types represent executable content.
Servers can prevent MIME sniffing by sending the X-Content-Type-Options header.Other methods of conveying document typeMIME types are not the only way to convey document type information:

Filename suffixes are sometimes used, especially on Microsoft Windows.
Not all operating systems consider these suffixes meaningful (such as Linux and macOS), and there is no guarantee they are correct.
Magic numbers. The syntax of different formats allows file-type inference by looking at their byte structure.
For example, GIF files start with the 47 49 46 38 39 hexadecimal value (GIF89), and PNG files with 89 50 4E 47 (.PNG).
Not all file types have magic numbers, so this is not 100% reliable either.
See also
Web media technologies
Guide to media types used on the web
Properly configuring server MIME types\n\nMIME types (IANA media types)A media type (also known as a Multipurpose Internet Mail Extensions or MIME type) indicates the nature and format of a document, file, or assortment of bytes.
MIME types are defined and standardized in IETF's RFC 6838.
The Internet Assigned Numbers Authority (IANA) is responsible for all official MIME types, and you can find the most up-to-date and complete list at their Media Types page.

Warning:
Browsers use the MIME type, not the file extension, to determine how to process a URL,
so it's important that web servers send the correct MIME type in the response's Content-Type header.
If this is not correctly configured, browsers are likely to misinterpret the contents of files, sites will not work correctly, and downloaded files may be mishandled.
Structure of a MIME typeA MIME type most commonly consists of just two parts: a type and a subtype, separated by a slash (/) — with no whitespace between:
type/subtype

The type represents the general category into which the data type falls, such as video or text.
The subtype identifies the exact kind of data of the specified type the MIME type represents.
For example, for the MIME type text, the subtype might be plain (plain text), html (HTML source code), or calendar (for iCalendar/.ics) files.
Each type has its own set of possible subtypes. A MIME type always has both a type and a subtype, never just one or the other.
An optional parameter can be added to provide additional details:
type/subtype;parameter=value

For example, for any MIME type whose main type is text, you can add the optional charset parameter to specify the character set used for the
characters in the data.
If no charset is specified, the default is ASCII (US-ASCII) unless overridden by the user agent's settings.
To specify a UTF-8 text file, the MIME type text/plain;charset=UTF-8 is used.
MIME types are case-insensitive but are traditionally written in lowercase. The parameter values can be case-sensitive.TypesThere are two classes of type: discrete and multipart.
Discrete types are types which represent a single file or medium, such as a single text or music file, or a single video.
A multipart type represents a document that's comprised of multiple component parts, each of which may have its own individual MIME type; or, a multipart type may encapsulate multiple files being sent together in one transaction.
For example, multipart MIME types are used when attaching multiple files to an email.
Discrete types
The discrete types currently registered with the IANA are:

application

Any kind of binary data that doesn't fall explicitly into one of the other types;
either data that will be executed or interpreted in some way or binary data that requires a specific application or category of application to use.
Generic binary data (or binary data whose true type is unknown) is application/octet-stream.
Other common examples include application/pdf, application/pkcs8, and application/zip.
(See application type registry at IANA)

audio

Audio or music data. Examples include audio/mpeg,
audio/vorbis.
(See audio type registry at IANA)

example

Reserved for use as a placeholder in examples showing how to use MIME types.
These should never be used outside of sample code listings and documentation.
example can also be used as a subtype;
for instance, in an example related to working with audio on the web, the MIME type audio/example can be used to indicate that the type is a placeholder and should be replaced with an appropriate one when using the code in the real world.

font

Font/typeface data. Common examples include font/woff, font/ttf, and font/otf.
(See font type registry at IANA)

image

Image or graphical data including both bitmap and vector still images as well as
animated versions of still image formats such as animated GIF or APNG.
Common examples are image/jpeg, image/png, and image/svg+xml.
(See image type registry at IANA)

model

Model data for a 3D object or scene. Examples include model/3mf and model/vrml.
(See model type registry at IANA)

text

Text-only data including any human-readable content, source code, or textual data such as comma-separated value (CSV) formatted data.
Examples include: text/plain, text/csv, and text/html.
(See text type registry at IANA)

video

Video data or files, such as MP4 movies (video/mp4).
(See video type registry at IANA)


For text documents without a specific subtype, text/plain should be used.
Similarly, for binary documents without a specific or known subtype, application/octet-stream should be used.
Multipart types
Multipart types indicate a category of document broken into
pieces, often with different MIME types; they can also be used — especially in email
scenarios — to represent multiple, separate files which are all part of the same
transaction. They represent a composite document.
Except for multipart/form-data, used in the POST method of HTML Forms, and multipart/byteranges, used with 206 Partial Content to send part of a document, HTTP doesn't handle multipart documents in a special way: the message is transmitted to the browser (which will likely
show a "Save As" window if it doesn't know how to display the document).
There are two multipart types:

message

A message that encapsulates other messages. This can be used, for instance, to represent an email that includes a forwarded message as part of its data,
or to allow sending very large messages in chunks as if it were multiple messages.
Examples include message/rfc822 (for forwarded or replied-to message quoting) and message/partial to allow breaking a large message into smaller ones automatically to be reassembled by the recipient.
(See message type registry at IANA)

multipart

Data that consists of multiple components which may individually have different MIME types.
Examples include multipart/form-data (for data produced using the FormData API) and multipart/byteranges (defined in RFC 7233, section 5.4.1 and used with HTTP's 206
"Partial Content" response returned when the fetched data is only part of the content, such as is delivered using the Range header).
(See multipart type registry at IANA)

Important MIME types for Web developersapplication/octet-streamThis is the default for binary files. As it means unknown binary file, browsers usually don't execute it, or even ask if it should be executed. They treat it as if the Content-Disposition header was set to attachment, and propose a "Save As" dialog.text/plainThis is the default for textual files. Even if it really means "unknown textual file," browsers assume they can display it.

Note: text/plain does not mean "any kind of textual data."
If they expect a specific kind of textual data, they will likely not consider it a match.
Specifically if they download a text/plain file from a <link> element declaring a CSS file, they will not recognize it as a valid CSS file if presented with text/plain.
The CSS mime type text/css must be used.
text/cssCSS files used to style a Web page must be sent with text/css.
If a server doesn't recognize the .css suffix for CSS files, it may send them with text/plain or application/octet-stream MIME types.
If so, they won't be recognized as CSS by most browsers and will be ignored.text/htmlAll HTML content should be served with this type. Alternative MIME types for XHTML (like application/xhtml+xml) are mostly useless nowadays.

Note:
Use application/xml or application/xhtml+xml if you want XML's strict parsing rules, <![CDATA[…]]> sections, or elements that aren't from HTML/SVG/MathML namespaces.
text/javascriptPer the IANA Media Types registry, RFC 9239, and the HTML specification, JavaScript content should always be served using the MIME type text/javascript.
No other MIME types are considered valid for JavaScript, and using any MIME type other than text/javascript may result in scripts that do not load or run.
You may find some JavaScript content incorrectly served with a charset parameter as part of the MIME type — as an attempt to specify the character set for the script content.
That charset parameter isn't valid for JavaScript content, and in most cases will result in a script failing to load.application/jsonJavaScript Object Notation (JSON) is a standard text-based format for representing structured data based on JavaScript object syntax.
It is commonly used for transmitting data in web applications.
Legacy JavaScript MIME types
In addition to the text/javascript MIME type, for historical reasons, the MIME Sniffing Standard
(the definition of how browsers should interpret MIME types and figure
out what to do with content that doesn't have a valid one) also allows JavaScript to be served using any of the following legacy JavaScript MIME types:

application/javascript 
Deprecated

application/ecmascript 
Deprecated

application/x-ecmascript 
Non-standard

application/x-javascript 
Non-standard

text/ecmascript 
Deprecated

text/javascript1.0 
Non-standard

text/javascript1.1 
Non-standard

text/javascript1.2 
Non-standard

text/javascript1.3 
Non-standard

text/javascript1.4 
Non-standard

text/javascript1.5 
Non-standard

text/jscript 
Non-standard

text/livescript 
Non-standard

text/x-ecmascript 
Non-standard

text/x-javascript 
Non-standard



Note:
Even though any given user agent may support any or all of these, you should only use text/javascript.
It's the only MIME type guaranteed to work now and into the future.
Image typesFiles whose MIME type is image contain image data.
The subtype specifies which specific image file format the data represents.
The following image types are used commonly enough to be considered safe for use on web pages:

image/apng: Animated Portable Network Graphics (APNG)
image/avif : AV1 Image File Format (AVIF)
image/gif: Graphics Interchange Format (GIF)
image/jpeg: Joint Photographic Expert Group image (JPEG)
image/png: Portable Network Graphics (PNG)
image/svg+xml: Scalable Vector Graphics (SVG)
image/webp: Web Picture format (WEBP)

The Image file type and format guide provides information and recommendations about when to use the different image formats.Audio and video typesAs is the case for images, HTML doesn't mandate that web browsers support any specific file and codec types for the <audio> and <video> elements, so it's important to consider your target audience and the range of browsers (and versions of those browsers) they may be using when choosing the file type and codecs to use for media.
Our media container formats guide provides a list of the file types that are commonly supported by web browsers,
including information about what their special use cases may be, any drawbacks they have, and compatibility information, along with other details.
The audio codec and video codec guides list the various codecs that web browsers often support, providing compatibility details along with technical information such as how many audio channels they support, what sort of compression is used, and what bit rates and so forth they're useful at.
The codecs used by WebRTC guide expands upon this by specifically covering the codecs supported by the major web browsers, so you can choose the codecs that best cover the range of browsers you wish to support.
As for MIME types of audio or video files, they typically specify the container format (file type).
The optional codecs parameter can be added to the MIME type to further specify which codecs to use and what options were used to encode the media, such as codec profile, level, or other such information.
For more information on common media types, see the Common MIME types page.multipart/form-dataThe multipart/form-data type can be used when sending the values of a completed HTML Form from browser to server.
As a multipart document format, it consists of different parts, delimited by a boundary (a string starting with a double dash --).
Each part is its own entity with its own HTTP headers, Content-Disposition, and Content-Type for file uploading fields.
httpContent-Type: multipart/form-data; boundary=aBoundaryString
(other headers associated with the multipart document as a whole)

--aBoundaryString
Content-Disposition: form-data; name="myFile"; filename="img.jpg"
Content-Type: image/jpeg

(data)
--aBoundaryString
Content-Disposition: form-data; name="myField"

(data)
--aBoundaryString
(more subparts)
--aBoundaryString--

The following <form>:
html<form
  action="http://localhost:8000/"
  method="post"
  enctype="multipart/form-data">
  <label>Name: <input name="myTextField" value="Test" /></label>
  <label><input type="checkbox" name="myCheckBox" /> Check</label>
  <label>
    Upload file: <input type="file" name="myFile" value="test.txt" />
  </label>
  <button>Send the file</button>
</form>

will send this message:
httpPOST / HTTP/1.1
Host: localhost:8000
User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.9; rv:50.0) Gecko/20100101 Firefox/50.0
Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
Accept-Language: en-US,en;q=0.5
Accept-Encoding: gzip, deflate
Connection: keep-alive
Upgrade-Insecure-Requests: 1
Content-Type: multipart/form-data; boundary=---------------------------8721656041911415653955004498
Content-Length: 465

-----------------------------8721656041911415653955004498
Content-Disposition: form-data; name="myTextField"

Test
-----------------------------8721656041911415653955004498
Content-Disposition: form-data; name="myCheckBox"

on
-----------------------------8721656041911415653955004498
Content-Disposition: form-data; name="myFile"; filename="test.txt"
Content-Type: text/plain

Simple file.
-----------------------------8721656041911415653955004498--
multipart/byterangesThe multipart/byteranges MIME type is used to send partial responses to the browser.
When the 206 Partial Content status code is sent, this MIME type indicates that the document is composed of several parts, one for each of the
requested ranges. Like other multipart types, the Content-Type uses a boundary to separate the pieces.
Each piece has a Content-Type header with its actual type and a Content-Range of the range it represents.
httpHTTP/1.1 206 Partial Content
Accept-Ranges: bytes
Content-Type: multipart/byteranges; boundary=3d6b6a416f9b5
Content-Length: 385

--3d6b6a416f9b5
Content-Type: text/html
Content-Range: bytes 100-200/1270

eta http-equiv="Content-type" content="text/html; charset=utf-8" />
    <meta name="viewport" content
--3d6b6a416f9b5
Content-Type: text/html
Content-Range: bytes 300-400/1270

-color: #f0f0f2;
        margin: 0;
        padding: 0;
        font-family: "Open Sans", "Helvetica
--3d6b6a416f9b5--
Importance of setting the correct MIME typeSome server configurations may use the associated MIME type to perform optimizations, such as file concatenation, compression, or caching. See h5bp/server-configs-apache for an example of an Apache configuration that compresses files of certain MIME types.
Most web servers send unrecognized resources as the application/octet-stream MIME type.
For security reasons, most browsers do not allow setting a custom default action (like "Open in Word") for such resources, forcing the user to save it to disk to use it.
Some common incorrect server configurations:

RAR-compressed files.
In this case, the ideal would be the true type of the original files; this is often impossible as .RAR files can hold several resources of different types.
In this case, configure the server to send application/x-rar-compressed.
Audio and video.
Only resources with the correct MIME Type will be played in <video> or <audio> elements.
Be sure to specify the correct media type for audio and video.
Proprietary file types.
A specific type like application/vnd.mspowerpoint lets users open such files automatically in the presentation software of their choice.
MIME sniffingIn the absence of a MIME type, or in certain cases where browsers believe they are incorrect, browsers may perform MIME sniffing — guessing the correct MIME type by looking at the bytes of the resource.
Each browser performs MIME sniffing differently and under different circumstances.
(For example, Safari will look at the file extension in the URL if the sent MIME type is unsuitable.)
There are security concerns as some MIME types represent executable content.
Servers can prevent MIME sniffing by sending the X-Content-Type-Options header.Other methods of conveying document typeMIME types are not the only way to convey document type information:

Filename suffixes are sometimes used, especially on Microsoft Windows.
Not all operating systems consider these suffixes meaningful (such as Linux and macOS), and there is no guarantee they are correct.
Magic numbers. The syntax of different formats allows file-type inference by looking at their byte structure.
For example, GIF files start with the 47 49 46 38 39 hexadecimal value (GIF89), and PNG files with 89 50 4E 47 (.PNG).
Not all file types have magic numbers, so this is not 100% reliable either.
See also
Web media technologies
Guide to media types used on the web
Properly configuring server MIME types
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nMIME types (IANA media types)A media type (also known as a Multipurpose Internet Mail Extensions or MIME type) indicates the nature and format of a document, file, or assortment of bytes.
MIME types are defined and standardized in IETF's RFC 6838.
The Internet Assigned Numbers Authority (IANA) is responsible for all official MIME types, and you can find the most up-to-date and complete list at their Media Types page.

Warning:
Browsers use the MIME type, not the file extension, to determine how to process a URL,
so it's important that web servers send the correct MIME type in the response's Content-Type header.
If this is not correctly configured, browsers are likely to misinterpret the contents of files, sites will not work correctly, and downloaded files may be mishandled.
Structure of a MIME typeA MIME type most commonly consists of just two parts: a type and a subtype, separated by a slash (/) — with no whitespace between:
type/subtype

The type represents the general category into which the data type falls, such as video or text.
The subtype identifies the exact kind of data of the specified type the MIME type represents.
For example, for the MIME type text, the subtype might be plain (plain text), html (HTML source code), or calendar (for iCalendar/.ics) files.
Each type has its own set of possible subtypes. A MIME type always has both a type and a subtype, never just one or the other.
An optional parameter can be added to provide additional details:
type/subtype;parameter=value

For example, for any MIME type whose main type is text, you can add the optional charset parameter to specify the character set used for the
characters in the data.
If no charset is specified, the default is ASCII (US-ASCII) unless overridden by the user agent's settings.
To specify a UTF-8 text file, the MIME type text/plain;charset=UTF-8 is used.
MIME types are case-insensitive but are traditionally written in lowercase. The parameter values can be case-sensitive.TypesThere are two classes of type: discrete and multipart.
Discrete types are types which represent a single file or medium, such as a single text or music file, or a single video.
A multipart type represents a document that's comprised of multiple component parts, each of which may have its own individual MIME type; or, a multipart type may encapsulate multiple files being sent together in one transaction.
For example, multipart MIME types are used when attaching multiple files to an email.
Discrete types
The discrete types currently registered with the IANA are:

application

Any kind of binary data that doesn't fall explicitly into one of the other types;
either data that will be executed or interpreted in some way or binary data that requires a specific application or category of application to use.
Generic binary data (or binary data whose true type is unknown) is application/octet-stream.
Other common examples include application/pdf, application/pkcs8, and application/zip.
(See application type registry at IANA)

audio

Audio or music data. Examples include audio/mpeg,
audio/vorbis.
(See audio type registry at IANA)

example

Reserved for use as a placeholder in examples showing how to use MIME types.
These should never be used outside of sample code listings and documentation.
example can also be used as a subtype;
for instance, in an example related to working with audio on the web, the MIME type audio/example can be used to indicate that the type is a placeholder and should be replaced with an appropriate one when using the code in the real world.

font

Font/typeface data. Common examples include font/woff, font/ttf, and font/otf.
(See font type registry at IANA)

image

Image or graphical data including both bitmap and vector still images as well as
animated versions of still image formats such as animated GIF or APNG.
Common examples are image/jpeg, image/png, and image/svg+xml.
(See image type registry at IANA)

model

Model data for a 3D object or scene. Examples include model/3mf and model/vrml.
(See model type registry at IANA)

text

Text-only data including any human-readable content, source code, or textual data such as comma-separated value (CSV) formatted data.
Examples include: text/plain, text/csv, and text/html.
(See text type registry at IANA)

video

Video data or files, such as MP4 movies (video/mp4).
(See video type registry at IANA)


For text documents without a specific subtype, text/plain should be used.
Similarly, for binary documents without a specific or known subtype, application/octet-stream should be used.
Multipart types
Multipart types indicate a category of document broken into
pieces, often with different MIME types; they can also be used — especially in email
scenarios — to represent multiple, separate files which are all part of the same
transaction. They represent a composite document.
Except for multipart/form-data, used in the POST method of HTML Forms, and multipart/byteranges, used with 206 Partial Content to send part of a document, HTTP doesn't handle multipart documents in a special way: the message is transmitted to the browser (which will likely
show a "Save As" window if it doesn't know how to display the document).
There are two multipart types:

message

A message that encapsulates other messages. This can be used, for instance, to represent an email that includes a forwarded message as part of its data,
or to allow sending very large messages in chunks as if it were multiple messages.
Examples include message/rfc822 (for forwarded or replied-to message quoting) and message/partial to allow breaking a large message into smaller ones automatically to be reassembled by the recipient.
(See message type registry at IANA)

multipart

Data that consists of multiple components which may individually have different MIME types.
Examples include multipart/form-data (for data produced using the FormData API) and multipart/byteranges (defined in RFC 7233, section 5.4.1 and used with HTTP's 206
"Partial Content" response returned when the fetched data is only part of the content, such as is delivered using the Range header).
(See multipart type registry at IANA)

Important MIME types for Web developersapplication/octet-streamThis is the default for binary files. As it means unknown binary file, browsers usually don't execute it, or even ask if it should be executed. They treat it as if the Content-Disposition header was set to attachment, and propose a "Save As" dialog.text/plainThis is the default for textual files. Even if it really means "unknown textual file," browsers assume they can display it.

Note: text/plain does not mean "any kind of textual data."
If they expect a specific kind of textual data, they will likely not consider it a match.
Specifically if they download a text/plain file from a <link> element declaring a CSS file, they will not recognize it as a valid CSS file if presented with text/plain.
The CSS mime type text/css must be used.
text/cssCSS files used to style a Web page must be sent with text/css.
If a server doesn't recognize the .css suffix for CSS files, it may send them with text/plain or application/octet-stream MIME types.
If so, they won't be recognized as CSS by most browsers and will be ignored.text/htmlAll HTML content should be served with this type. Alternative MIME types for XHTML (like application/xhtml+xml) are mostly useless nowadays.

Note:
Use application/xml or application/xhtml+xml if you want XML's strict parsing rules, <![CDATA[…]]> sections, or elements that aren't from HTML/SVG/MathML namespaces.
text/javascriptPer the IANA Media Types registry, RFC 9239, and the HTML specification, JavaScript content should always be served using the MIME type text/javascript.
No other MIME types are considered valid for JavaScript, and using any MIME type other than text/javascript may result in scripts that do not load or run.
You may find some JavaScript content incorrectly served with a charset parameter as part of the MIME type — as an attempt to specify the character set for the script content.
That charset parameter isn't valid for JavaScript content, and in most cases will result in a script failing to load.application/jsonJavaScript Object Notation (JSON) is a standard text-based format for representing structured data based on JavaScript object syntax.
It is commonly used for transmitting data in web applications.
Legacy JavaScript MIME types
In addition to the text/javascript MIME type, for historical reasons, the MIME Sniffing Standard
(the definition of how browsers should interpret MIME types and figure
out what to do with content that doesn't have a valid one) also allows JavaScript to be served using any of the following legacy JavaScript MIME types:

application/javascript 
Deprecated

application/ecmascript 
Deprecated

application/x-ecmascript 
Non-standard

application/x-javascript 
Non-standard

text/ecmascript 
Deprecated

text/javascript1.0 
Non-standard

text/javascript1.1 
Non-standard

text/javascript1.2 
Non-standard

text/javascript1.3 
Non-standard

text/javascript1.4 
Non-standard

text/javascript1.5 
Non-standard

text/jscript 
Non-standard

text/livescript 
Non-standard

text/x-ecmascript 
Non-standard

text/x-javascript 
Non-standard



Note:
Even though any given user agent may support any or all of these, you should only use text/javascript.
It's the only MIME type guaranteed to work now and into the future.
Image typesFiles whose MIME type is image contain image data.
The subtype specifies which specific image file format the data represents.
The following image types are used commonly enough to be considered safe for use on web pages:

image/apng: Animated Portable Network Graphics (APNG)
image/avif : AV1 Image File Format (AVIF)
image/gif: Graphics Interchange Format (GIF)
image/jpeg: Joint Photographic Expert Group image (JPEG)
image/png: Portable Network Graphics (PNG)
image/svg+xml: Scalable Vector Graphics (SVG)
image/webp: Web Picture format (WEBP)

The Image file type and format guide provides information and recommendations about when to use the different image formats.Audio and video typesAs is the case for images, HTML doesn't mandate that web browsers support any specific file and codec types for the <audio> and <video> elements, so it's important to consider your target audience and the range of browsers (and versions of those browsers) they may be using when choosing the file type and codecs to use for media.
Our media container formats guide provides a list of the file types that are commonly supported by web browsers,
including information about what their special use cases may be, any drawbacks they have, and compatibility information, along with other details.
The audio codec and video codec guides list the various codecs that web browsers often support, providing compatibility details along with technical information such as how many audio channels they support, what sort of compression is used, and what bit rates and so forth they're useful at.
The codecs used by WebRTC guide expands upon this by specifically covering the codecs supported by the major web browsers, so you can choose the codecs that best cover the range of browsers you wish to support.
As for MIME types of audio or video files, they typically specify the container format (file type).
The optional codecs parameter can be added to the MIME type to further specify which codecs to use and what options were used to encode the media, such as codec profile, level, or other such information.
For more information on common media types, see the Common MIME types page.multipart/form-dataThe multipart/form-data type can be used when sending the values of a completed HTML Form from browser to server.
As a multipart document format, it consists of different parts, delimited by a boundary (a string starting with a double dash --).
Each part is its own entity with its own HTTP headers, Content-Disposition, and Content-Type for file uploading fields.
httpContent-Type: multipart/form-data; boundary=aBoundaryString
(other headers associated with the multipart document as a whole)

--aBoundaryString
Content-Disposition: form-data; name="myFile"; filename="img.jpg"
Content-Type: image/jpeg

(data)
--aBoundaryString
Content-Disposition: form-data; name="myField"

(data)
--aBoundaryString
(more subparts)
--aBoundaryString--

The following <form>:
html<form
  action="http://localhost:8000/"
  method="post"
  enctype="multipart/form-data">
  <label>Name: <input name="myTextField" value="Test" /></label>
  <label><input type="checkbox" name="myCheckBox" /> Check</label>
  <label>
    Upload file: <input type="file" name="myFile" value="test.txt" />
  </label>
  <button>Send the file</button>
</form>

will send this message:
httpPOST / HTTP/1.1
Host: localhost:8000
User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.9; rv:50.0) Gecko/20100101 Firefox/50.0
Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
Accept-Language: en-US,en;q=0.5
Accept-Encoding: gzip, deflate
Connection: keep-alive
Upgrade-Insecure-Requests: 1
Content-Type: multipart/form-data; boundary=---------------------------8721656041911415653955004498
Content-Length: 465

-----------------------------8721656041911415653955004498
Content-Disposition: form-data; name="myTextField"

Test
-----------------------------8721656041911415653955004498
Content-Disposition: form-data; name="myCheckBox"

on
-----------------------------8721656041911415653955004498
Content-Disposition: form-data; name="myFile"; filename="test.txt"
Content-Type: text/plain

Simple file.
-----------------------------8721656041911415653955004498--
multipart/byterangesThe multipart/byteranges MIME type is used to send partial responses to the browser.
When the 206 Partial Content status code is sent, this MIME type indicates that the document is composed of several parts, one for each of the
requested ranges. Like other multipart types, the Content-Type uses a boundary to separate the pieces.
Each piece has a Content-Type header with its actual type and a Content-Range of the range it represents.
httpHTTP/1.1 206 Partial Content
Accept-Ranges: bytes
Content-Type: multipart/byteranges; boundary=3d6b6a416f9b5
Content-Length: 385

--3d6b6a416f9b5
Content-Type: text/html
Content-Range: bytes 100-200/1270

eta http-equiv="Content-type" content="text/html; charset=utf-8" />
    <meta name="viewport" content
--3d6b6a416f9b5
Content-Type: text/html
Content-Range: bytes 300-400/1270

-color: #f0f0f2;
        margin: 0;
        padding: 0;
        font-family: "Open Sans", "Helvetica
--3d6b6a416f9b5--
Importance of setting the correct MIME typeSome server configurations may use the associated MIME type to perform optimizations, such as file concatenation, compression, or caching. See h5bp/server-configs-apache for an example of an Apache configuration that compresses files of certain MIME types.
Most web servers send unrecognized resources as the application/octet-stream MIME type.
For security reasons, most browsers do not allow setting a custom default action (like "Open in Word") for such resources, forcing the user to save it to disk to use it.
Some common incorrect server configurations:

RAR-compressed files.
In this case, the ideal would be the true type of the original files; this is often impossible as .RAR files can hold several resources of different types.
In this case, configure the server to send application/x-rar-compressed.
Audio and video.
Only resources with the correct MIME Type will be played in <video> or <audio> elements.
Be sure to specify the correct media type for audio and video.
Proprietary file types.
A specific type like application/vnd.mspowerpoint lets users open such files automatically in the presentation software of their choice.
MIME sniffingIn the absence of a MIME type, or in certain cases where browsers believe they are incorrect, browsers may perform MIME sniffing — guessing the correct MIME type by looking at the bytes of the resource.
Each browser performs MIME sniffing differently and under different circumstances.
(For example, Safari will look at the file extension in the URL if the sent MIME type is unsuitable.)
There are security concerns as some MIME types represent executable content.
Servers can prevent MIME sniffing by sending the X-Content-Type-Options header.Other methods of conveying document typeMIME types are not the only way to convey document type information:

Filename suffixes are sometimes used, especially on Microsoft Windows.
Not all operating systems consider these suffixes meaningful (such as Linux and macOS), and there is no guarantee they are correct.
Magic numbers. The syntax of different formats allows file-type inference by looking at their byte structure.
For example, GIF files start with the 47 49 46 38 39 hexadecimal value (GIF89), and PNG files with 89 50 4E 47 (.PNG).
Not all file types have magic numbers, so this is not 100% reliable either.
See also
Web media technologies
Guide to media types used on the web
Properly configuring server MIME types
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nCompression in HTTPCompression is an important way to increase the performance of a website. For some documents, size reduction of up to 70% lowers the bandwidth capacity needs. Over the years, algorithms also got more efficient, and new ones are supported by clients and servers.
In practice, web developers don't need to implement compression mechanisms, both browsers and servers have it implemented already, but they have to be sure that the server is configured adequately. Compression happens at three different levels:

first some file formats are compressed with specific optimized methods,
then general compression can happen at the HTTP level (the resource is transmitted compressed from end to end),
and finally compression can be defined at the connection level, between two nodes of an HTTP connection.
File format compressionEach data type has some redundancy, that is wasted space, in it. If text can typically have as much as 60% redundancy, this rate can be much higher for some other media like audio and video. Unlike text, these other media types use a lot of space to store their data and the need to optimize storage and regain space was apparent very early. Engineers designed the optimized compression algorithm used by file formats designed for this specific purpose. Compression algorithms used for files can be grouped into two broad categories:

Loss-less compression, where the compression-decompression cycle doesn't alter the data that is recovered. It matches (byte to byte) with the original.
For images, gif or png are using lossless compression.
Lossy compression, where the cycle alters the original data in a (hopefully) imperceptible way for the user.
Video formats on the Web are lossy; the jpeg image format is also lossy.

Some formats can be used for both loss-less or lossy compression, like webp, and usually lossy algorithm can be configured to compress more or less, which then of course leads to less or more quality. For better performance of a website, it is ideal to compress as much as possible, while keeping an acceptable level of quality. For images, an image generated by a tool could be not optimized enough for the Web; it is recommended to use tools that will compress as much as possible with the required quality. There are numerous tools that are specialized for this.
Lossy compression algorithms are usually more efficient than loss-less ones.

Note:
As compression works better on a specific kind of files, it usually provides nothing to compress them a second time. In fact, this is often counterproductive as the cost of the overhead (algorithms usually need a dictionary that adds to the initial size) can be higher than the extra gain in compression resulting in a larger file. Do not use the two following techniques for files in a compressed format.
End-to-end compressionFor compression, end-to-end compression is where the largest performance improvements of websites reside. End-to-end compression refers to a compression of the body of a message that is done by the server and will last unchanged until it reaches the client. Whatever the intermediate nodes are, they leave the body untouched.


All modern browsers and servers do support it and the only thing to negotiate is the compression algorithm to use. These algorithms are optimized for text. In the 1990s, compression technology was advancing at a rapid pace and numerous successive algorithms have been added to the set of possible choices. Nowadays, only two are relevant: gzip, the most common one, and br the new challenger.
To select the algorithm to use, browsers and servers use proactive content negotiation. The browser sends an Accept-Encoding header with the algorithm it supports and its order of precedence, the server picks one, uses it to compress the body of the response and uses the Content-Encoding header to tell the browser the algorithm it has chosen. As content negotiation has been used to choose a representation based on its encoding, the server must send a Vary header containing at least Accept-Encoding alongside this header in the response; that way, caches will be able to cache the different representations of the resource.


As compression brings significant performance improvements, it is recommended to activate it for all files except already compressed ones like images, audio files and videos.
Apache supports compression and uses mod_deflate; for Nginx there is ngx_http_gzip_module; for IIS, the <httpCompression> element.Compression dictionary transportModern compression formats such as Brotli compression and Zstandard compression can use dictionaries of frequently used data to further increase compression over just referencing those from within the file being compressed. Typically, for HTTP responses, this uses the predefined static dictionary included in that format (for example the Brotli static dictionary is available in the source code).
Compression Dictionary Transport enables a developer to specify a resource which can be used as a dictionary for future requests. This can either be a specific dictionary file, or an existing resource (for example, using app.v1.js as a dictionary when downloading app.v2.js). This typically improves compression and therefore load time. In the app.vX.js example, most of the download would consist of only the delta between the two versions, and the common bytes could be referenced from the original app.v1.js file that is already downloaded.Hop-by-hop compressionHop-by-hop compression, though similar to end-to-end compression, differs by one fundamental element: the compression doesn't happen on the resource in the server, creating a specific representation that is then transmitted, but on the body of the message between any two nodes on the path between the client and the server. Connections between successive intermediate nodes may apply a different compression.


To do this, HTTP uses a mechanism similar to the content negotiation for end-to-end compression: the node transmitting the request advertizes its will using the TE header and the other node chooses the adequate method, applies it, and indicates its choice with the Transfer-Encoding header.


In practice, hop-by-hop compression is transparent for the server and the client, and is rarely used. TE and Transfer-Encoding are mostly used to send a response by chunks, allowing to start transmitting a resource without knowing its length.
Note that using Transfer-Encoding and compression at the hop level is so rare that most servers, like Apache, Nginx, or IIS, have no easy way to configure it. Such configuration usually happens at the proxy level.See also
Compression Dictionary Transport guide
Glossary terms:

Brotli compression
Gzip compression
Lossless compression
Lossy compression
Zstandard compression
Compression Dictionary Transport\n\nCompression in HTTPCompression is an important way to increase the performance of a website. For some documents, size reduction of up to 70% lowers the bandwidth capacity needs. Over the years, algorithms also got more efficient, and new ones are supported by clients and servers.
In practice, web developers don't need to implement compression mechanisms, both browsers and servers have it implemented already, but they have to be sure that the server is configured adequately. Compression happens at three different levels:

first some file formats are compressed with specific optimized methods,
then general compression can happen at the HTTP level (the resource is transmitted compressed from end to end),
and finally compression can be defined at the connection level, between two nodes of an HTTP connection.
File format compressionEach data type has some redundancy, that is wasted space, in it. If text can typically have as much as 60% redundancy, this rate can be much higher for some other media like audio and video. Unlike text, these other media types use a lot of space to store their data and the need to optimize storage and regain space was apparent very early. Engineers designed the optimized compression algorithm used by file formats designed for this specific purpose. Compression algorithms used for files can be grouped into two broad categories:

Loss-less compression, where the compression-decompression cycle doesn't alter the data that is recovered. It matches (byte to byte) with the original.
For images, gif or png are using lossless compression.
Lossy compression, where the cycle alters the original data in a (hopefully) imperceptible way for the user.
Video formats on the Web are lossy; the jpeg image format is also lossy.

Some formats can be used for both loss-less or lossy compression, like webp, and usually lossy algorithm can be configured to compress more or less, which then of course leads to less or more quality. For better performance of a website, it is ideal to compress as much as possible, while keeping an acceptable level of quality. For images, an image generated by a tool could be not optimized enough for the Web; it is recommended to use tools that will compress as much as possible with the required quality. There are numerous tools that are specialized for this.
Lossy compression algorithms are usually more efficient than loss-less ones.

Note:
As compression works better on a specific kind of files, it usually provides nothing to compress them a second time. In fact, this is often counterproductive as the cost of the overhead (algorithms usually need a dictionary that adds to the initial size) can be higher than the extra gain in compression resulting in a larger file. Do not use the two following techniques for files in a compressed format.
End-to-end compressionFor compression, end-to-end compression is where the largest performance improvements of websites reside. End-to-end compression refers to a compression of the body of a message that is done by the server and will last unchanged until it reaches the client. Whatever the intermediate nodes are, they leave the body untouched.


All modern browsers and servers do support it and the only thing to negotiate is the compression algorithm to use. These algorithms are optimized for text. In the 1990s, compression technology was advancing at a rapid pace and numerous successive algorithms have been added to the set of possible choices. Nowadays, only two are relevant: gzip, the most common one, and br the new challenger.
To select the algorithm to use, browsers and servers use proactive content negotiation. The browser sends an Accept-Encoding header with the algorithm it supports and its order of precedence, the server picks one, uses it to compress the body of the response and uses the Content-Encoding header to tell the browser the algorithm it has chosen. As content negotiation has been used to choose a representation based on its encoding, the server must send a Vary header containing at least Accept-Encoding alongside this header in the response; that way, caches will be able to cache the different representations of the resource.


As compression brings significant performance improvements, it is recommended to activate it for all files except already compressed ones like images, audio files and videos.
Apache supports compression and uses mod_deflate; for Nginx there is ngx_http_gzip_module; for IIS, the <httpCompression> element.Compression dictionary transportModern compression formats such as Brotli compression and Zstandard compression can use dictionaries of frequently used data to further increase compression over just referencing those from within the file being compressed. Typically, for HTTP responses, this uses the predefined static dictionary included in that format (for example the Brotli static dictionary is available in the source code).
Compression Dictionary Transport enables a developer to specify a resource which can be used as a dictionary for future requests. This can either be a specific dictionary file, or an existing resource (for example, using app.v1.js as a dictionary when downloading app.v2.js). This typically improves compression and therefore load time. In the app.vX.js example, most of the download would consist of only the delta between the two versions, and the common bytes could be referenced from the original app.v1.js file that is already downloaded.Hop-by-hop compressionHop-by-hop compression, though similar to end-to-end compression, differs by one fundamental element: the compression doesn't happen on the resource in the server, creating a specific representation that is then transmitted, but on the body of the message between any two nodes on the path between the client and the server. Connections between successive intermediate nodes may apply a different compression.


To do this, HTTP uses a mechanism similar to the content negotiation for end-to-end compression: the node transmitting the request advertizes its will using the TE header and the other node chooses the adequate method, applies it, and indicates its choice with the Transfer-Encoding header.


In practice, hop-by-hop compression is transparent for the server and the client, and is rarely used. TE and Transfer-Encoding are mostly used to send a response by chunks, allowing to start transmitting a resource without knowing its length.
Note that using Transfer-Encoding and compression at the hop level is so rare that most servers, like Apache, Nginx, or IIS, have no easy way to configure it. Such configuration usually happens at the proxy level.See also
Compression Dictionary Transport guide
Glossary terms:

Brotli compression
Gzip compression
Lossless compression
Lossy compression
Zstandard compression
Compression Dictionary Transport


Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Apr 1, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nCompression in HTTPCompression is an important way to increase the performance of a website. For some documents, size reduction of up to 70% lowers the bandwidth capacity needs. Over the years, algorithms also got more efficient, and new ones are supported by clients and servers.
In practice, web developers don't need to implement compression mechanisms, both browsers and servers have it implemented already, but they have to be sure that the server is configured adequately. Compression happens at three different levels:

first some file formats are compressed with specific optimized methods,
then general compression can happen at the HTTP level (the resource is transmitted compressed from end to end),
and finally compression can be defined at the connection level, between two nodes of an HTTP connection.
File format compressionEach data type has some redundancy, that is wasted space, in it. If text can typically have as much as 60% redundancy, this rate can be much higher for some other media like audio and video. Unlike text, these other media types use a lot of space to store their data and the need to optimize storage and regain space was apparent very early. Engineers designed the optimized compression algorithm used by file formats designed for this specific purpose. Compression algorithms used for files can be grouped into two broad categories:

Loss-less compression, where the compression-decompression cycle doesn't alter the data that is recovered. It matches (byte to byte) with the original.
For images, gif or png are using lossless compression.
Lossy compression, where the cycle alters the original data in a (hopefully) imperceptible way for the user.
Video formats on the Web are lossy; the jpeg image format is also lossy.

Some formats can be used for both loss-less or lossy compression, like webp, and usually lossy algorithm can be configured to compress more or less, which then of course leads to less or more quality. For better performance of a website, it is ideal to compress as much as possible, while keeping an acceptable level of quality. For images, an image generated by a tool could be not optimized enough for the Web; it is recommended to use tools that will compress as much as possible with the required quality. There are numerous tools that are specialized for this.
Lossy compression algorithms are usually more efficient than loss-less ones.

Note:
As compression works better on a specific kind of files, it usually provides nothing to compress them a second time. In fact, this is often counterproductive as the cost of the overhead (algorithms usually need a dictionary that adds to the initial size) can be higher than the extra gain in compression resulting in a larger file. Do not use the two following techniques for files in a compressed format.
End-to-end compressionFor compression, end-to-end compression is where the largest performance improvements of websites reside. End-to-end compression refers to a compression of the body of a message that is done by the server and will last unchanged until it reaches the client. Whatever the intermediate nodes are, they leave the body untouched.


All modern browsers and servers do support it and the only thing to negotiate is the compression algorithm to use. These algorithms are optimized for text. In the 1990s, compression technology was advancing at a rapid pace and numerous successive algorithms have been added to the set of possible choices. Nowadays, only two are relevant: gzip, the most common one, and br the new challenger.
To select the algorithm to use, browsers and servers use proactive content negotiation. The browser sends an Accept-Encoding header with the algorithm it supports and its order of precedence, the server picks one, uses it to compress the body of the response and uses the Content-Encoding header to tell the browser the algorithm it has chosen. As content negotiation has been used to choose a representation based on its encoding, the server must send a Vary header containing at least Accept-Encoding alongside this header in the response; that way, caches will be able to cache the different representations of the resource.


As compression brings significant performance improvements, it is recommended to activate it for all files except already compressed ones like images, audio files and videos.
Apache supports compression and uses mod_deflate; for Nginx there is ngx_http_gzip_module; for IIS, the <httpCompression> element.Compression dictionary transportModern compression formats such as Brotli compression and Zstandard compression can use dictionaries of frequently used data to further increase compression over just referencing those from within the file being compressed. Typically, for HTTP responses, this uses the predefined static dictionary included in that format (for example the Brotli static dictionary is available in the source code).
Compression Dictionary Transport enables a developer to specify a resource which can be used as a dictionary for future requests. This can either be a specific dictionary file, or an existing resource (for example, using app.v1.js as a dictionary when downloading app.v2.js). This typically improves compression and therefore load time. In the app.vX.js example, most of the download would consist of only the delta between the two versions, and the common bytes could be referenced from the original app.v1.js file that is already downloaded.Hop-by-hop compressionHop-by-hop compression, though similar to end-to-end compression, differs by one fundamental element: the compression doesn't happen on the resource in the server, creating a specific representation that is then transmitted, but on the body of the message between any two nodes on the path between the client and the server. Connections between successive intermediate nodes may apply a different compression.


To do this, HTTP uses a mechanism similar to the content negotiation for end-to-end compression: the node transmitting the request advertizes its will using the TE header and the other node chooses the adequate method, applies it, and indicates its choice with the Transfer-Encoding header.


In practice, hop-by-hop compression is transparent for the server and the client, and is rarely used. TE and Transfer-Encoding are mostly used to send a response by chunks, allowing to start transmitting a resource without knowing its length.
Note that using Transfer-Encoding and compression at the hop level is so rare that most servers, like Apache, Nginx, or IIS, have no easy way to configure it. Such configuration usually happens at the proxy level.See also
Compression Dictionary Transport guide
Glossary terms:

Brotli compression
Gzip compression
Lossless compression
Lossy compression
Zstandard compression
Compression Dictionary Transport


Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Apr 1, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nCompression Dictionary TransportExperimental: This is an experimental technologyCheck the Browser compatibility table carefully before using this in production.
Compression Dictionary Transport is a way of using a shared compression dictionary to dramatically reduce the transport size of HTTP responses.OverviewCompression algorithms are used in HTTP to reduce the size of resources downloaded over the network, reducing bandwidth cost and the time taken to load pages. Lossless HTTP compression algorithms work by finding redundancy in the source: for example, places where text like the string "function" is repeated. They then include just one copy of the redundant string, and replace occurrences of it in the resource with references to that copy. Since the references are shorter than the string, the compressed version is shorter.

Note:
A previous attempt at this technology was called SDCH (Shared Dictionary Compression for HTTP) but was never widely supported and was removed in 2017. Compression Dictionary Transport is a better-specified and more robust implementation with broader industry consensus.

For example, take this JavaScript:
jsfunction a() {
  console.log("Hello World!");
}

function b() {
  console.log("I am here");
}

This could be compressed by replacing repeated strings with references to a previous location and number of characters, like this:
function a() {
  console.log("Hello World!");
}

[0:9]b[10:20]I am here[42:46]

In this example, [0:9] refers to copying the 9 characters starting at character 0. Note this is a simplified example to demonstrate the concept and the actual algorithms are more complex than this.
Clients can then reverse the compression after download to recreate the original, uncompressed resource.Compression dictionariesAlgorithms like Brotli compression and Zstandard compression achieve even greater efficiency by allowing the use of dictionaries of commonly encountered strings, so you don't need any copies of them in the compressed resource. These algorithms ship with a predefined default dictionary that is used when compressing HTTP responses.
Compression Dictionary Transport builds on this by enabling you to provide your own dictionary which is especially applicable to a particular set of resources. The compression algorithm can then reference it as a source of bytes when compressing and decompressing the resource.
Assuming the references from the previous example are included in that common dictionary, this could be further reduced to this:
[d0:9]a[d10:20]Hello World![d42:46]
[d0:9]b[d10:20]I am here[d42:46]

The dictionary can either be a separate resource that is only required for Compression Dictionary Transport, or it can be a resource that the website needs anyway.
For example, suppose your website uses a JavaScript library. You would typically load a specific version of the library, and might include the version name in the name of the library, like <script src="my-library.v1.js">. When the browser loads your page, it will fetch a copy of the library as a subresource.
If you then update to v2 of the library, most of the library's code will probably have stayed the same. So sites can greatly reduce the size of the download for my-library.v2.js by telling the browser to use my-library.v1.js as a compression dictionary for my-library.v2.js. Then all strings that are common between v1 and v2 don't need to be included in the download for v2, because the browser already has them. Most of the download size of my-library.v2.js is then just the delta between the two versions.
Compression Dictionary Transport can achieve an order of magnitude more compression than compression using a default built-in dictionary: see Compression dictionary transport examples for some real-life results.Dictionary formatA compression dictionary is a "raw" file that does not follow any specific format, nor have a specific MIME type. They are regular files that can be used to compress other files with similar content and so can be text files or even binary. For example, WASM binary files are large resources that can also benefit from delta compression.Existing resource as a dictionaryTo use a resource as a dictionary, the server should include the Use-As-Dictionary header in the response that provides the resource:
httpUse-As-Dictionary: match="/js/app.*.js"

The value of this header indicates the resources that can use this resource as a dictionary: in this case, that includes any resources whose URLs match the given pattern.
When a resource is later requested that matches the given pattern (for example, app.v2.js), the request will include a SHA-256 hash of the available dictionary in the Available-Dictionary header, along with dcb and/or dcz values in the Accept-Encoding header (for delta compression using Brotli or ZStandard as appropriate):
httpAccept-Encoding: gzip, br, zstd, dcb, dcz
Available-Dictionary: :pZGm1Av0IEBKARczz7exkNYsZb8LzaMrV7J32a2fFG4=:

The server can then respond with an appropriately-encoded response with the chosen content encoding given in the Content-Encoding header:
httpContent-Encoding: dcb

If the response is cacheable, it must include a Vary header to prevent caches serving dictionary-compressed resources to clients that don't support them or serving the response compressed with the wrong dictionary:
httpVary: accept-encoding, available-dictionary

An optional id can also be provided in the Use-As-Dictionary header, to allow the server to more easily find the dictionary file if they do not store the diction by the hash:
httpUse-As-Dictionary: match="/js/app.*.js", id="dictionary-12345"

If this is provided, the value will be sent in future requests in the Dictionary-ID header:
httpAccept-Encoding: gzip, br, zstd, dcb, dcz
Available-Dictionary: :pZGm1Av0IEBKARczz7exkNYsZb8LzaMrV7J32a2fFG4=:
Dictionary-ID: "dictionary-12345"

The server must still check the hash from the Available-Dictionary header — the Dictionary-ID is additional information for the server to identify the dictionary but does not replace the need for the Available-Dictionary header.Separate dictionaryAn HTML document can also provide a compression dictionary to the browser which isn't a resource that the browser is downloading anyway via an element such as a <script> tag. There are two methods to do this:


Include a <link> element whose rel attribute is set to compression-dictionary:
html<link rel="compression-dictionary" href="/dictionary.dat" />



Reference the dictionary using the Link header:
httpLink: </dictionary.dat>; rel="compression-dictionary"



This dictionary is then downloaded by the browser during idle time, and that response must include the Use-As-Dictionary header:
httpUse-As-Dictionary: match="/js/app.*.js"

From here the process is similar to the previous example when a matching resources is requested.Creating dictionary-compressed responsesDictionary-compressed responses can use either the Brotli or ZStandard algorithms, with two extra requirements: they must also include a magic header and embedded dictionary hash.
Dictionary-compressed resources can be created dynamically, but for static resources it can be better to create these in advance at build time. When using prior versions as dictionaries, this will require deciding how many delta-compressed versions to create — for the last version only, or for the last X versions for some value of X.
Given a dictionary file named dictionary.text and a file to compress named data.text, the following Bash command will compress the file using Brotli, producing a compressed file named data.txt.dcb:
bashecho -en '\xffDCB' > data.txt.dcb && \
openssl dgst -sha256 -binary dictionary.txt >> data.txt.dcb && \
brotli --stdout -D dictionary.txt data.txt >> data.txt.dcb

Given the same input files, the following Bash command will compress the file using ZStandard, producing a compressed file named data.txt.dcz:
bashecho -en '\x5e\x2a\x4d\x18\x20\x00\x00\x00' > data.txt.dcz && \
openssl dgst -sha256 -binary dictionary.txt >> data.txt.dcz && \
zstd -D dictionary.txt -f -o tmp.zstd data.txt && \
cat tmp.zstd >> data.txt.dcz

Note that you will need OpenSSL installed locally as well as Brotli or ZStandard.RestrictionsCompression algorithms are at risk of security attacks, so there are a number of restrictions for Compression Dictionary Transport, including:

Dictionaries must same-origin with the resource using the dictionary.
Dictionary-compressed resources must be same-origin with the document origin, or follow the CORS rules, and so be requested with the crossorigin attribute and served with an appropriate Access-Control-Allow-Origin header.
Dictionaries are bound by the usual HTTP Cache partitioning and so cannot be shared between origins even if they download the same resources. The dictionary will need to be downloaded again for each origin.

Additionally, dictionaries could themselves become tracking vectors so browsers may restrict this feature when cookies are disabled or when other extra privacy protections are enabled.SpecificationsSpecificationCompression Dictionary Transport Browser compatibilityhtml.elements.link.rel.compression-dictionaryhttp.headers.Accept-Encoding.dcbhttp.headers.Accept-Encoding.dczhttp.headers.Available-Dictionaryhttp.headers.Content-Encoding.dcbhttp.headers.Content-Encoding.dczhttp.headers.Dictionary-IDhttp.headers.Use-As-DictionarySee also
Glossary terms:

Brotli compression
Zstandard compression


<link rel="compression-dictionary">
Accept-encoding
Content-encoding
Available-Dictionary
Dictionary-ID
Use-As-Dictionary
Draft specification
Resources for Compression Dictionary Transport\n\nCompression Dictionary TransportExperimental: This is an experimental technologyCheck the Browser compatibility table carefully before using this in production.
Compression Dictionary Transport is a way of using a shared compression dictionary to dramatically reduce the transport size of HTTP responses.OverviewCompression algorithms are used in HTTP to reduce the size of resources downloaded over the network, reducing bandwidth cost and the time taken to load pages. Lossless HTTP compression algorithms work by finding redundancy in the source: for example, places where text like the string "function" is repeated. They then include just one copy of the redundant string, and replace occurrences of it in the resource with references to that copy. Since the references are shorter than the string, the compressed version is shorter.

Note:
A previous attempt at this technology was called SDCH (Shared Dictionary Compression for HTTP) but was never widely supported and was removed in 2017. Compression Dictionary Transport is a better-specified and more robust implementation with broader industry consensus.

For example, take this JavaScript:
jsfunction a() {
  console.log("Hello World!");
}

function b() {
  console.log("I am here");
}

This could be compressed by replacing repeated strings with references to a previous location and number of characters, like this:
function a() {
  console.log("Hello World!");
}

[0:9]b[10:20]I am here[42:46]

In this example, [0:9] refers to copying the 9 characters starting at character 0. Note this is a simplified example to demonstrate the concept and the actual algorithms are more complex than this.
Clients can then reverse the compression after download to recreate the original, uncompressed resource.Compression dictionariesAlgorithms like Brotli compression and Zstandard compression achieve even greater efficiency by allowing the use of dictionaries of commonly encountered strings, so you don't need any copies of them in the compressed resource. These algorithms ship with a predefined default dictionary that is used when compressing HTTP responses.
Compression Dictionary Transport builds on this by enabling you to provide your own dictionary which is especially applicable to a particular set of resources. The compression algorithm can then reference it as a source of bytes when compressing and decompressing the resource.
Assuming the references from the previous example are included in that common dictionary, this could be further reduced to this:
[d0:9]a[d10:20]Hello World![d42:46]
[d0:9]b[d10:20]I am here[d42:46]

The dictionary can either be a separate resource that is only required for Compression Dictionary Transport, or it can be a resource that the website needs anyway.
For example, suppose your website uses a JavaScript library. You would typically load a specific version of the library, and might include the version name in the name of the library, like <script src="my-library.v1.js">. When the browser loads your page, it will fetch a copy of the library as a subresource.
If you then update to v2 of the library, most of the library's code will probably have stayed the same. So sites can greatly reduce the size of the download for my-library.v2.js by telling the browser to use my-library.v1.js as a compression dictionary for my-library.v2.js. Then all strings that are common between v1 and v2 don't need to be included in the download for v2, because the browser already has them. Most of the download size of my-library.v2.js is then just the delta between the two versions.
Compression Dictionary Transport can achieve an order of magnitude more compression than compression using a default built-in dictionary: see Compression dictionary transport examples for some real-life results.Dictionary formatA compression dictionary is a "raw" file that does not follow any specific format, nor have a specific MIME type. They are regular files that can be used to compress other files with similar content and so can be text files or even binary. For example, WASM binary files are large resources that can also benefit from delta compression.Existing resource as a dictionaryTo use a resource as a dictionary, the server should include the Use-As-Dictionary header in the response that provides the resource:
httpUse-As-Dictionary: match="/js/app.*.js"

The value of this header indicates the resources that can use this resource as a dictionary: in this case, that includes any resources whose URLs match the given pattern.
When a resource is later requested that matches the given pattern (for example, app.v2.js), the request will include a SHA-256 hash of the available dictionary in the Available-Dictionary header, along with dcb and/or dcz values in the Accept-Encoding header (for delta compression using Brotli or ZStandard as appropriate):
httpAccept-Encoding: gzip, br, zstd, dcb, dcz
Available-Dictionary: :pZGm1Av0IEBKARczz7exkNYsZb8LzaMrV7J32a2fFG4=:

The server can then respond with an appropriately-encoded response with the chosen content encoding given in the Content-Encoding header:
httpContent-Encoding: dcb

If the response is cacheable, it must include a Vary header to prevent caches serving dictionary-compressed resources to clients that don't support them or serving the response compressed with the wrong dictionary:
httpVary: accept-encoding, available-dictionary

An optional id can also be provided in the Use-As-Dictionary header, to allow the server to more easily find the dictionary file if they do not store the diction by the hash:
httpUse-As-Dictionary: match="/js/app.*.js", id="dictionary-12345"

If this is provided, the value will be sent in future requests in the Dictionary-ID header:
httpAccept-Encoding: gzip, br, zstd, dcb, dcz
Available-Dictionary: :pZGm1Av0IEBKARczz7exkNYsZb8LzaMrV7J32a2fFG4=:
Dictionary-ID: "dictionary-12345"

The server must still check the hash from the Available-Dictionary header — the Dictionary-ID is additional information for the server to identify the dictionary but does not replace the need for the Available-Dictionary header.Separate dictionaryAn HTML document can also provide a compression dictionary to the browser which isn't a resource that the browser is downloading anyway via an element such as a <script> tag. There are two methods to do this:


Include a <link> element whose rel attribute is set to compression-dictionary:
html<link rel="compression-dictionary" href="/dictionary.dat" />



Reference the dictionary using the Link header:
httpLink: </dictionary.dat>; rel="compression-dictionary"



This dictionary is then downloaded by the browser during idle time, and that response must include the Use-As-Dictionary header:
httpUse-As-Dictionary: match="/js/app.*.js"

From here the process is similar to the previous example when a matching resources is requested.Creating dictionary-compressed responsesDictionary-compressed responses can use either the Brotli or ZStandard algorithms, with two extra requirements: they must also include a magic header and embedded dictionary hash.
Dictionary-compressed resources can be created dynamically, but for static resources it can be better to create these in advance at build time. When using prior versions as dictionaries, this will require deciding how many delta-compressed versions to create — for the last version only, or for the last X versions for some value of X.
Given a dictionary file named dictionary.text and a file to compress named data.text, the following Bash command will compress the file using Brotli, producing a compressed file named data.txt.dcb:
bashecho -en '\xffDCB' > data.txt.dcb && \
openssl dgst -sha256 -binary dictionary.txt >> data.txt.dcb && \
brotli --stdout -D dictionary.txt data.txt >> data.txt.dcb

Given the same input files, the following Bash command will compress the file using ZStandard, producing a compressed file named data.txt.dcz:
bashecho -en '\x5e\x2a\x4d\x18\x20\x00\x00\x00' > data.txt.dcz && \
openssl dgst -sha256 -binary dictionary.txt >> data.txt.dcz && \
zstd -D dictionary.txt -f -o tmp.zstd data.txt && \
cat tmp.zstd >> data.txt.dcz

Note that you will need OpenSSL installed locally as well as Brotli or ZStandard.RestrictionsCompression algorithms are at risk of security attacks, so there are a number of restrictions for Compression Dictionary Transport, including:

Dictionaries must same-origin with the resource using the dictionary.
Dictionary-compressed resources must be same-origin with the document origin, or follow the CORS rules, and so be requested with the crossorigin attribute and served with an appropriate Access-Control-Allow-Origin header.
Dictionaries are bound by the usual HTTP Cache partitioning and so cannot be shared between origins even if they download the same resources. The dictionary will need to be downloaded again for each origin.

Additionally, dictionaries could themselves become tracking vectors so browsers may restrict this feature when cookies are disabled or when other extra privacy protections are enabled.SpecificationsSpecificationCompression Dictionary Transport Browser compatibilityhtml.elements.link.rel.compression-dictionaryhttp.headers.Accept-Encoding.dcbhttp.headers.Accept-Encoding.dczhttp.headers.Available-Dictionaryhttp.headers.Content-Encoding.dcbhttp.headers.Content-Encoding.dczhttp.headers.Dictionary-IDhttp.headers.Use-As-DictionarySee also
Glossary terms:

Brotli compression
Zstandard compression


<link rel="compression-dictionary">
Accept-encoding
Content-encoding
Available-Dictionary
Dictionary-ID
Use-As-Dictionary
Draft specification
Resources for Compression Dictionary Transport
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Apr 10, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nCompression Dictionary TransportExperimental: This is an experimental technologyCheck the Browser compatibility table carefully before using this in production.
Compression Dictionary Transport is a way of using a shared compression dictionary to dramatically reduce the transport size of HTTP responses.OverviewCompression algorithms are used in HTTP to reduce the size of resources downloaded over the network, reducing bandwidth cost and the time taken to load pages. Lossless HTTP compression algorithms work by finding redundancy in the source: for example, places where text like the string "function" is repeated. They then include just one copy of the redundant string, and replace occurrences of it in the resource with references to that copy. Since the references are shorter than the string, the compressed version is shorter.

Note:
A previous attempt at this technology was called SDCH (Shared Dictionary Compression for HTTP) but was never widely supported and was removed in 2017. Compression Dictionary Transport is a better-specified and more robust implementation with broader industry consensus.

For example, take this JavaScript:
jsfunction a() {
  console.log("Hello World!");
}

function b() {
  console.log("I am here");
}

This could be compressed by replacing repeated strings with references to a previous location and number of characters, like this:
function a() {
  console.log("Hello World!");
}

[0:9]b[10:20]I am here[42:46]

In this example, [0:9] refers to copying the 9 characters starting at character 0. Note this is a simplified example to demonstrate the concept and the actual algorithms are more complex than this.
Clients can then reverse the compression after download to recreate the original, uncompressed resource.Compression dictionariesAlgorithms like Brotli compression and Zstandard compression achieve even greater efficiency by allowing the use of dictionaries of commonly encountered strings, so you don't need any copies of them in the compressed resource. These algorithms ship with a predefined default dictionary that is used when compressing HTTP responses.
Compression Dictionary Transport builds on this by enabling you to provide your own dictionary which is especially applicable to a particular set of resources. The compression algorithm can then reference it as a source of bytes when compressing and decompressing the resource.
Assuming the references from the previous example are included in that common dictionary, this could be further reduced to this:
[d0:9]a[d10:20]Hello World![d42:46]
[d0:9]b[d10:20]I am here[d42:46]

The dictionary can either be a separate resource that is only required for Compression Dictionary Transport, or it can be a resource that the website needs anyway.
For example, suppose your website uses a JavaScript library. You would typically load a specific version of the library, and might include the version name in the name of the library, like <script src="my-library.v1.js">. When the browser loads your page, it will fetch a copy of the library as a subresource.
If you then update to v2 of the library, most of the library's code will probably have stayed the same. So sites can greatly reduce the size of the download for my-library.v2.js by telling the browser to use my-library.v1.js as a compression dictionary for my-library.v2.js. Then all strings that are common between v1 and v2 don't need to be included in the download for v2, because the browser already has them. Most of the download size of my-library.v2.js is then just the delta between the two versions.
Compression Dictionary Transport can achieve an order of magnitude more compression than compression using a default built-in dictionary: see Compression dictionary transport examples for some real-life results.Dictionary formatA compression dictionary is a "raw" file that does not follow any specific format, nor have a specific MIME type. They are regular files that can be used to compress other files with similar content and so can be text files or even binary. For example, WASM binary files are large resources that can also benefit from delta compression.Existing resource as a dictionaryTo use a resource as a dictionary, the server should include the Use-As-Dictionary header in the response that provides the resource:
httpUse-As-Dictionary: match="/js/app.*.js"

The value of this header indicates the resources that can use this resource as a dictionary: in this case, that includes any resources whose URLs match the given pattern.
When a resource is later requested that matches the given pattern (for example, app.v2.js), the request will include a SHA-256 hash of the available dictionary in the Available-Dictionary header, along with dcb and/or dcz values in the Accept-Encoding header (for delta compression using Brotli or ZStandard as appropriate):
httpAccept-Encoding: gzip, br, zstd, dcb, dcz
Available-Dictionary: :pZGm1Av0IEBKARczz7exkNYsZb8LzaMrV7J32a2fFG4=:

The server can then respond with an appropriately-encoded response with the chosen content encoding given in the Content-Encoding header:
httpContent-Encoding: dcb

If the response is cacheable, it must include a Vary header to prevent caches serving dictionary-compressed resources to clients that don't support them or serving the response compressed with the wrong dictionary:
httpVary: accept-encoding, available-dictionary

An optional id can also be provided in the Use-As-Dictionary header, to allow the server to more easily find the dictionary file if they do not store the diction by the hash:
httpUse-As-Dictionary: match="/js/app.*.js", id="dictionary-12345"

If this is provided, the value will be sent in future requests in the Dictionary-ID header:
httpAccept-Encoding: gzip, br, zstd, dcb, dcz
Available-Dictionary: :pZGm1Av0IEBKARczz7exkNYsZb8LzaMrV7J32a2fFG4=:
Dictionary-ID: "dictionary-12345"

The server must still check the hash from the Available-Dictionary header — the Dictionary-ID is additional information for the server to identify the dictionary but does not replace the need for the Available-Dictionary header.Separate dictionaryAn HTML document can also provide a compression dictionary to the browser which isn't a resource that the browser is downloading anyway via an element such as a <script> tag. There are two methods to do this:


Include a <link> element whose rel attribute is set to compression-dictionary:
html<link rel="compression-dictionary" href="/dictionary.dat" />



Reference the dictionary using the Link header:
httpLink: </dictionary.dat>; rel="compression-dictionary"



This dictionary is then downloaded by the browser during idle time, and that response must include the Use-As-Dictionary header:
httpUse-As-Dictionary: match="/js/app.*.js"

From here the process is similar to the previous example when a matching resources is requested.Creating dictionary-compressed responsesDictionary-compressed responses can use either the Brotli or ZStandard algorithms, with two extra requirements: they must also include a magic header and embedded dictionary hash.
Dictionary-compressed resources can be created dynamically, but for static resources it can be better to create these in advance at build time. When using prior versions as dictionaries, this will require deciding how many delta-compressed versions to create — for the last version only, or for the last X versions for some value of X.
Given a dictionary file named dictionary.text and a file to compress named data.text, the following Bash command will compress the file using Brotli, producing a compressed file named data.txt.dcb:
bashecho -en '\xffDCB' > data.txt.dcb && \
openssl dgst -sha256 -binary dictionary.txt >> data.txt.dcb && \
brotli --stdout -D dictionary.txt data.txt >> data.txt.dcb

Given the same input files, the following Bash command will compress the file using ZStandard, producing a compressed file named data.txt.dcz:
bashecho -en '\x5e\x2a\x4d\x18\x20\x00\x00\x00' > data.txt.dcz && \
openssl dgst -sha256 -binary dictionary.txt >> data.txt.dcz && \
zstd -D dictionary.txt -f -o tmp.zstd data.txt && \
cat tmp.zstd >> data.txt.dcz

Note that you will need OpenSSL installed locally as well as Brotli or ZStandard.RestrictionsCompression algorithms are at risk of security attacks, so there are a number of restrictions for Compression Dictionary Transport, including:

Dictionaries must same-origin with the resource using the dictionary.
Dictionary-compressed resources must be same-origin with the document origin, or follow the CORS rules, and so be requested with the crossorigin attribute and served with an appropriate Access-Control-Allow-Origin header.
Dictionaries are bound by the usual HTTP Cache partitioning and so cannot be shared between origins even if they download the same resources. The dictionary will need to be downloaded again for each origin.

Additionally, dictionaries could themselves become tracking vectors so browsers may restrict this feature when cookies are disabled or when other extra privacy protections are enabled.SpecificationsSpecificationCompression Dictionary Transport Browser compatibilityhtml.elements.link.rel.compression-dictionaryhttp.headers.Accept-Encoding.dcbhttp.headers.Accept-Encoding.dczhttp.headers.Available-Dictionaryhttp.headers.Content-Encoding.dcbhttp.headers.Content-Encoding.dczhttp.headers.Dictionary-IDhttp.headers.Use-As-DictionarySee also
Glossary terms:

Brotli compression
Zstandard compression


<link rel="compression-dictionary">
Accept-encoding
Content-encoding
Available-Dictionary
Dictionary-ID
Use-As-Dictionary
Draft specification
Resources for Compression Dictionary Transport
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Apr 10, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nHTTP cachingThe HTTP cache stores a response associated with a request and reuses the stored response for subsequent requests.
There are several advantages to reusability. First, since there is no need to deliver the request to the origin server, then the closer the client and cache are, the faster the response will be. The most typical example is when the browser itself stores a cache for browser requests.
Also, when a response is reusable, the origin server does not need to process the request — so it does not need to parse and route the request, restore the session based on the cookie, query the DB for results, or render the template engine. That reduces the load on the server.
Proper operation of the cache is critical to the health of the system.Types of cachesIn the HTTP Caching spec, there are two main types of caches: private caches and shared caches.Private cachesA private cache is a cache tied to a specific client — typically a browser cache. Since the stored response is not shared with other clients, a private cache can store a personalized response for that user.
On the other hand, if personalized contents are stored in a cache other than a private cache, then other users may be able to retrieve those contents — which may cause unintentional information leakage.
If a response contains personalized content and you want to store the response only in the private cache, you must specify a private directive.
httpCache-Control: private

Personalized contents are usually controlled by cookies, but the presence of a cookie does not always indicate that it is private, and thus a cookie alone does not make the response private.Shared cacheThe shared cache is located between the client and the server and can store responses that can be shared among users. And shared caches can be further sub-classified into proxy caches and managed caches.
Proxy caches
In addition to the function of access control, some proxies implement caching to reduce traffic out of the network. This is usually not managed by the service developer, so it must be controlled by appropriate HTTP headers and so on. However, in the past, outdated proxy-cache implementations — such as implementations that do not properly understand the HTTP Caching standard — have often caused problems for developers.
Kitchen-sink headers like the following are used to try to work around "old and not updated proxy cache" implementations that do not understand current HTTP Caching spec directives like no-store.
httpCache-Control: no-store, no-cache, max-age=0, must-revalidate, proxy-revalidate

However, in recent years, as HTTPS has become more common and client/server communication has become encrypted, proxy caches in the path can only tunnel a response and can't behave as a cache, in many cases. So in that scenario, there is no need to worry about outdated proxy cache implementations that cannot even see the response.
On the other hand, if a TLS bridge proxy decrypts all communications in a person-in-the-middle manner by installing a certificate from a CA (certificate authority) managed by the organization on the PC, and performs access control, etc. — it is possible to see the contents of the response and cache it. However, since CT (certificate transparency) has become widespread in recent years, and some browsers only allow certificates issued with an SCT (signed certificate timestamp), this method requires the application of an enterprise policy. In such a controlled environment, there is no need to worry about the proxy cache being "out of date and not updated".
Managed caches
Managed caches are explicitly deployed by service developers to offload the origin server and to deliver content efficiently. Examples include reverse proxies, CDNs, and service workers in combination with the Cache API.
The characteristics of managed caches vary depending on the product deployed. In most cases, you can control the cache's behavior through the Cache-Control header and your own configuration files or dashboards.
For example, the HTTP Caching specification essentially does not define a way to explicitly delete a cache — but with a managed cache, the stored response can be deleted at any time through dashboard operations, API calls, restarts, and so on. That allows for a more proactive caching strategy.
It is also possible to ignore the standard HTTP Caching spec protocols in favor of explicit manipulation. For example, the following can be specified to opt-out of a private cache or proxy cache, while using your own strategy to cache only in a managed cache.
httpCache-Control: no-store

For example, Varnish Cache uses VCL (Varnish Configuration Language, a type of DSL) logic to handle cache storage, while service workers in combination with the Cache API allow you to create that logic in JavaScript.
That means if a managed cache intentionally ignores a no-store directive, there is no need to perceive it as being "non-compliant" with the standard. What you should do is, avoid using kitchen-sink headers, but carefully read the documentation of whatever managed-cache mechanism you're using, and ensure you're controlling the cache properly in the ways provided by the mechanism you've chosen to use.
Note that some CDNs provide their own headers that are effective only for that CDN (for example, Surrogate-Control). Currently, work is underway to define a CDN-Cache-Control header to standardize those.
Heuristic cachingHTTP is designed to cache as much as possible, so even if no Cache-Control is given, responses will get stored and reused if certain conditions are met. This is called heuristic caching.
For example, take the following response. This response was last updated 1 year ago.
httpHTTP/1.1 200 OK
Content-Type: text/html
Content-Length: 1024
Date: Tue, 22 Feb 2022 22:22:22 GMT
Last-Modified: Tue, 22 Feb 2021 22:22:22 GMT

<!doctype html>
…

It is heuristically known that content which has not been updated for a full year will not be updated for some time after that. Therefore, the client stores this response (despite the lack of max-age) and reuses it for a while. How long to reuse is up to the implementation, but the specification recommends about 10% (in this case 0.1 year) of the time after storing.
Heuristic caching is a workaround that came before Cache-Control support became widely adopted, and basically all responses should explicitly specify a Cache-Control header.Fresh and stale based on ageStored HTTP responses have two states: fresh and stale. The fresh state usually indicates that the response is still valid and can be reused, while the stale state means that the cached response has already expired.
The criterion for determining when a response is fresh and when it is stale is age. In HTTP, age is the time elapsed since the response was generated. This is similar to the TTL in other caching mechanisms.
Take the following example response (604800 seconds is one week):
httpHTTP/1.1 200 OK
Content-Type: text/html
Content-Length: 1024
Date: Tue, 22 Feb 2022 22:22:22 GMT
Cache-Control: max-age=604800

<!doctype html>
…

The cache that stored the example response calculates the time elapsed since the response was generated and uses the result as the response's age.
For the example response, the meaning of max-age is the following:

If the age of the response is less than one week, the response is fresh.
If the age of the response is more than one week, the response is stale.

As long as the stored response remains fresh, it will be used to fulfill client requests.
When a response is stored in a shared cache, it is possible to tell the client the age of the response. Continuing with the example, if the shared cache stored the response for one day, the shared cache would send the following response to subsequent client requests.
httpHTTP/1.1 200 OK
Content-Type: text/html
Content-Length: 1024
Date: Tue, 22 Feb 2022 22:22:22 GMT
Cache-Control: max-age=604800
Age: 86400

<!doctype html>
…

The client which receives that response will find it to be fresh for the remaining 518400 seconds, the difference between the response's max-age and Age.Expires or max-ageIn HTTP/1.0, freshness used to be specified by the Expires header.
The Expires header specifies the lifetime of the cache using an explicit time rather than by specifying an elapsed time.
httpExpires: Tue, 28 Feb 2022 22:22:22 GMT

However, the time format is difficult to parse, many implementation bugs were found, and it is possible to induce problems by intentionally shifting the system clock; therefore, max-age — for specifying an elapsed time — was adopted for Cache-Control in HTTP/1.1.
If both Expires and Cache-Control: max-age are available, max-age is defined to be preferred. So it is not necessary to provide Expires now that HTTP/1.1 is widely used.VaryThe way that responses are distinguished from one another is essentially based on their URLs:



URL
Response body




https://example.com/index.html
<!doctype html>...


https://example.com/style.css
body { ...


https://example.com/script.js
function main () { ...



But the contents of responses are not always the same, even if they have the same URL. Especially when content negotiation is performed, the response from the server can depend on the values of the Accept, Accept-Language, and Accept-Encoding request headers.
For example, for English content returned with an Accept-Language: en header and cached, it is undesirable to then reuse that cached response for requests that have an Accept-Language: ja request header. In this case, you can cause the responses to be cached separately — based on language — by adding Accept-Language to the value of the Vary header.
httpVary: Accept-Language

That causes the cache to be keyed based on a composite of the response URL and the Accept-Language request header — rather than being based just on the response URL.



URL
Accept-Language
Response body




https://example.com/index.html
ja-JP
<!doctype html>...


https://example.com/index.html
en-US
<!doctype html>...


https://example.com/style.css
ja-JP
body { ...


https://example.com/script.js
ja-JP
function main () { ...



Also, if you are providing content optimization (for example, for responsive design) based on the user agent, you may be tempted to include User-Agent in the value of the Vary header. However, the User-Agent request header generally has a very large number of variations, which drastically reduces the chance that the cache will be reused. So if possible, instead consider a way to vary behavior based on feature detection rather than based on the User-Agent request header.
For applications that employ cookies to prevent others from reusing cached personalized content, you should specify Cache-Control: private instead of specifying a cookie for Vary.ValidationStale responses are not immediately discarded. HTTP has a mechanism to transform a stale response into a fresh one by asking the origin server. This is called validation, or sometimes, revalidation.
Validation is done by using a conditional request that includes an If-Modified-Since or If-None-Match request header.If-Modified-SinceThe following response was generated at 22:22:22 and has a max-age of 1 hour, so you know that it is fresh until 23:22:22.
httpHTTP/1.1 200 OK
Content-Type: text/html
Content-Length: 1024
Date: Tue, 22 Feb 2022 22:22:22 GMT
Last-Modified: Tue, 22 Feb 2022 22:00:00 GMT
Cache-Control: max-age=3600

<!doctype html>
…

At 23:22:22, the response becomes stale and the cache cannot be reused. So the request below shows a client sending a request with an If-Modified-Since request header, to ask the server if there have been any changes made since the specified time.
httpGET /index.html HTTP/1.1
Host: example.com
Accept: text/html
If-Modified-Since: Tue, 22 Feb 2022 22:00:00 GMT

The server will respond with 304 Not Modified if the content has not changed since the specified time.
Since this response only indicates "no change", there is no response body — there's just a status code — so the transfer size is extremely small.
httpHTTP/1.1 304 Not Modified
Content-Type: text/html
Date: Tue, 22 Feb 2022 23:22:22 GMT
Last-Modified: Tue, 22 Feb 2022 22:00:00 GMT
Cache-Control: max-age=3600

Upon receiving that response, the client reverts the stored stale response back to being fresh and can reuse it during the remaining 1 hour.
The server can obtain the modification time from the operating-system file system, which is relatively easy to do for the case of serving static files. However, there are some problems; for example, the time format is complex and difficult to parse, and distributed servers have difficulty synchronizing file-update times.
To solve such problems, the ETag response header was standardized as an alternative.ETag/If-None-MatchThe value of the ETag response header is an arbitrary value generated by the server. There are no restrictions on how the server must generate the value, so servers are free to set the value based on whatever means they choose — such as a hash of the body contents or a version number.
As an example, if a hash value is used for the ETag header and the hash value of the index.html resource is 33a64df5, the response will be as follows:
httpHTTP/1.1 200 OK
Content-Type: text/html
Content-Length: 1024
Date: Tue, 22 Feb 2022 22:22:22 GMT
ETag: "33a64df5"
Cache-Control: max-age=3600

<!doctype html>
…

If that response is stale, the client takes the value of the ETag response header for the cached response, and puts it into the If-None-Match request header, to ask the server if the resource has been modified:
httpGET /index.html HTTP/1.1
Host: example.com
Accept: text/html
If-None-Match: "33a64df5"

The server will return 304 Not Modified if the value of the ETag header it determines for the requested resource is the same as the If-None-Match value in the request.
But if the server determines the requested resource should now have a different ETag value, the server will instead respond with a 200 OK and the latest version of the resource.

Note:
RFC9110 prefers that servers send both ETag and Last-Modified for a 200 response if possible.
During cache revalidation, if both If-Modified-Since and If-None-Match are present, then If-None-Match takes precedence for the validator.
If you are only considering caching, you may think that Last-Modified is unnecessary.
However, Last-Modified is not just useful for caching; it is a standard HTTP header that is also used by content-management (CMS) systems to display the last-modified time, by crawlers to adjust crawl frequency, and for other various purposes.
So considering the overall HTTP ecosystem, it is better to provide both ETag and Last-Modified.
Force RevalidationIf you do not want a response to be reused, but instead want to always fetch the latest content from the server, you can use the no-cache directive to force validation.
By adding Cache-Control: no-cache to the response along with Last-Modified and ETag — as shown below — the client will receive a 200 OK response if the requested resource has been updated, or will otherwise receive a 304 Not Modified response if the requested resource has not been updated.
httpHTTP/1.1 200 OK
Content-Type: text/html
Content-Length: 1024
Date: Tue, 22 Feb 2022 22:22:22 GMT
Last-Modified: Tue, 22 Feb 2022 22:00:00 GMT
ETag: "deadbeef"
Cache-Control: no-cache

<!doctype html>
…

It is often stated that the combination of max-age=0 and must-revalidate has the same meaning as no-cache.
httpCache-Control: max-age=0, must-revalidate

max-age=0 means that the response is immediately stale, and must-revalidate means that it must not be reused without revalidation once it is stale — so, in combination, the semantics seem to be the same as no-cache.
However, that usage of max-age=0 is a remnant of the fact that many implementations prior to HTTP/1.1 were unable to handle the no-cache directive — and so to deal with that limitation, max-age=0 was used as a workaround.
But now that HTTP/1.1-conformant servers are widely deployed, there's no reason to ever use that max-age=0 and must-revalidate combination — you should instead just use no-cache.Don't cacheThe no-cache directive does not prevent the storing of responses but instead prevents the reuse of responses without revalidation.
If you don't want a response stored in any cache, use no-store.
httpCache-Control: no-store

However, in general, a "do not cache" requirement in practice amounts to the following set of circumstances:

Don't want the response stored by anyone other than the specific client, for privacy reasons.
Want to provide up-to-date information always.
Don't know what could happen in outdated implementations.

Under that set of circumstances, no-store is not always the most-appropriate directive.
The following sections look at the circumstances in more detail.Do not share with othersIt would be problematic if a response with personalized content is unexpectedly visible to other users of a cache.
In such a case, using the private directive will cause the personalized response to only be stored with the specific client and not be leaked to any other user of the cache.
httpCache-Control: private

In such a case, even if no-store is given, private must also be given.Provide up-to-date content every timeThe no-store directive prevents a response from being stored, but does not delete any already-stored response for the same URL.
In other words, if there is an old response already stored for a particular URL, returning no-store will not prevent the old response from being reused.
However, a no-cache directive will force the client to send a validation request before reusing any stored response.
httpCache-Control: no-cache

If the server does not support conditional requests, you can force the client to access the server every time and always get the latest response with 200 OK.Dealing with outdated implementationsAs a workaround for outdated implementations that ignore no-store, you may see kitchen-sink headers such as the following being used.
httpCache-Control: no-store, no-cache, max-age=0, must-revalidate, proxy-revalidate

It is recommended to use no-cache as an alternative for dealing with such outdated implementations, and it is not a problem if no-cache is given from the beginning, since the server will always receive the request.
If it is the shared cache that you are concerned about, you can make sure to prevent unintended caching by also adding private:
httpCache-Control: no-cache, private
What's lost by no-storeYou may think adding no-store would be the right way to opt-out of caching.
However, it's not recommended to grant no-store liberally, because you lose many advantages that HTTP and browsers have, including the browser's back/forward cache.
Therefore, to get the advantages of the full feature set of the web platform, prefer the use of no-cache in combination with private.Reload and force reloadValidation can be performed for requests as well as responses.
The reload and force reload actions are common examples of validation performed from the browser side.ReloadFor recovering from window corruption or updating to the latest version of the resource, browsers provide a reload function for users.
A simplified view of the HTTP request sent during a browser reload looks as follows:
httpGET / HTTP/1.1
Host: example.com
Cache-Control: max-age=0
If-None-Match: "deadbeef"
If-Modified-Since: Tue, 22 Feb 2022 20:20:20 GMT

(The requests from Chrome, Edge, and Firefox look very much like the above; the requests from Safari will look a bit different.)
The max-age=0 directive in the request specifies "reuse of responses with an age of 0 or less" — so, in effect, intermediately stored responses are not reused.
As a result, a request is validated by If-None-Match and If-Modified-Since.
That behavior is also defined in the Fetch standard and can be reproduced in JavaScript by calling fetch() with the cache mode set to no-cache (note that reload is not the right mode for this case):
js// Note: "reload" is not the right mode for a normal reload; "no-cache" is
fetch("/", { cache: "no-cache" });
Force reloadBrowsers use max-age=0 during reloads for backward-compatibility reasons — because many outdated implementations prior to HTTP/1.1 did not understand no-cache. But no-cache is fine now in this use case, and force reload is an additional way to bypass cached responses.
The HTTP Request during a browser force reload looks as follows:
httpGET / HTTP/1.1
Host: example.com
Pragma: no-cache
Cache-Control: no-cache

(The requests from Chrome, Edge, and Firefox look very much like the above; the requests from Safari will look a bit different.)
Since that's not a conditional request with no-cache, you can be sure you'll get a 200 OK from the origin server.
That behavior is also defined in the Fetch standard and can be reproduced in JavaScript by calling fetch() with the cache mode set to reload (note that it's not force-reload):
js// Note: "reload" — rather than "no-cache" — is the right mode for a "force reload"
fetch("/", { cache: "reload" });
Avoiding revalidationContent that never changes should be given a long max-age by using cache busting — that is, by including a version number, hash value, etc., in the request URL.
However, when the user reloads, a revalidation request is sent even though the server knows that the content is immutable.
To prevent that, the immutable directive can be used to explicitly indicate that revalidation is not required because the content never changes.
httpCache-Control: max-age=31536000, immutable

That prevents unnecessary revalidation during reloads.
Note that, instead of implementing that directive, Chrome has changed its implementation so that revalidation is not performed during reloads for subresources.Deleting stored responsesThere is no way to delete responses on an intermediate server that have been stored with a long max-age.
Imagine that the following response from https://example.com/ was stored.
httpHTTP/1.1 200 OK
Content-Type: text/html
Content-Length: 1024
Cache-Control: max-age=31536000

<!doctype html>
…

You may want to overwrite that response once it expired on the server, but there is nothing the server can do once the response is stored — since no more requests reach the server due to caching.
One of the methods mentioned in the specification is to send a request for the same URL with an unsafe method such as POST, but for many clients that is difficult to do.
The Clear-Site-Data: cache header and directive value can be used to clear browser caches — but has no effect on intermediate caches.
Otherwise responses will remain in the browser cache until max-age expires, unless the user manually performs a reload, force-reload, or clear-history action.
Caching reduces access to the server, which means that the server loses control of that URL. If the server does not want to lose control of a URL — for example, in the case that a resource is frequently updated — you should add no-cache so that the server will always receive requests and send the intended responses.Request collapseThe shared cache is primarily located before the origin server and is intended to reduce traffic to the origin server.
Thus, if multiple identical requests arrive at a shared cache at the same time, the intermediate cache will forward a single request on behalf of itself to the origin, which can then reuse the result for all clients. This is called request collapse.
Request collapse occurs when requests are arriving at the same time, so even if max-age=0 or no-cache is given in the response, it will be reused.
If the response is personalized to a particular user and you do not want it to be shared in collapse, you should add the private directive:
Common caching patternsThere are many directives in the Cache-Control spec, and it may be difficult to understand all of them. But most websites can be covered by a combination of a handful of patterns.
This section describes the common patterns in designing caches.Default settingsAs mentioned above, the default behavior for caching (that is, for a response without Cache-Control) is not simply "don't cache" but implicit caching according to so-called "heuristic caching".
To avoid that heuristic caching, it's preferable to explicitly give all responses a default Cache-Control header.
To ensure that by default the latest versions of resources will always be transferred, it's common practice to make the default Cache-Control value include no-cache:
httpCache-Control: no-cache

In addition, if the service implements cookies or other login methods, and the content is personalized for each user, private must be given too, to prevent sharing with other users:
httpCache-Control: no-cache, private
Cache BustingThe resources that work best with caching are static immutable files whose contents never change. And for resources that do change, it is a common best practice to change the URL each time the content changes, so that the URL unit can be cached for a longer period.
As an example, consider the following HTML:
html<script src="bundle.js"></script>
<link rel="stylesheet" href="build.css" />
<body>
  hello
</body>

In modern web development, JavaScript and CSS resources are frequently updated as development progresses. Also, if the versions of JavaScript and CSS resources that a client uses are out of sync, the display will break.
So the HTML above makes it difficult to cache bundle.js and build.css with max-age.
Therefore, you can serve the JavaScript and CSS with URLs that include a changing part based on a version number or hash value. Some of the ways to do that are shown below.
# version in filename
bundle.v123.js

# version in query
bundle.js?v=123

# hash in filename
bundle.YsAIAAAA-QG4G6kCMAMBAAAAAAAoK.js

# hash in query
bundle.js?v=YsAIAAAA-QG4G6kCMAMBAAAAAAAoK

Since the cache distinguishes resources from one another based on their URLs, the cache will not be reused again if the URL changes when a resource is updated.
html<script src="bundle.v123.js"></script>
<link rel="stylesheet" href="build.v123.css" />
<body>
  hello
</body>

With that design, both JavaScript and CSS resources can be cached for a long time. So how long should max-age be set to? The QPACK specification provides an answer to that question.
QPACK is a standard for compressing HTTP header fields, with tables of commonly-used field values defined.
Some commonly-used cache-header values are shown below.
36 cache-control max-age=0
37 cache-control max-age=604800
38 cache-control max-age=2592000
39 cache-control no-cache
40 cache-control no-store
41 cache-control public, max-age=31536000

If you select one of those numbered options, you can compress values in 1 byte when transferred via HTTP3.
Numbers 37, 38, and 41 are for periods of one week, one month, and one year.
Because the cache removes old entries when new entries are saved, the probability that a stored response still exists after one week is not that high — even if max-age is set to 1 week. Therefore, in practice, it does not make much difference which one you choose.
Note that number 41 has the longest max-age (1 year), but with public.
The public value has the effect of making the response storable even if the Authorization header is present.

Note:
The public directive should only be used if there is a need to store the response when the Authorization header is set.
It is not required otherwise, because a response will be stored in the shared cache as long as max-age is given.

So if the response is personalized with basic authentication, the presence of public may cause problems. If you are concerned about that, you can choose the second-longest value, 38 (1 month).
http# response for bundle.v123.js

# If you never personalize responses via Authorization
Cache-Control: public, max-age=31536000

# If you can't be certain
Cache-Control: max-age=2592000
ValidationDon't forget to set the Last-Modified and ETag headers, so that you don't have to re-transmit a resource when reloading. It's easy to generate those headers for pre-built static files.
The ETag value here may be a hash of the file.
http# response for bundle.v123.js
Last-Modified: Tue, 22 Feb 2022 20:20:20 GMT
ETag: "YsAIAAAA-QG4G6kCMAMBAAAAAAAoK"

In addition, immutable can be added to prevent validation on reload.
The combined result is shown below.
http# bundle.v123.js
HTTP/1.1 200 OK
Content-Type: text/javascript
Content-Length: 1024
Cache-Control: public, max-age=31536000, immutable
Last-Modified: Tue, 22 Feb 2022 20:20:20 GMT
ETag: "YsAIAAAA-QG4G6kCMAMBAAAAAAAoK"

Cache busting is a technique to make a response cacheable over a long period by changing the URL when the content changes. The technique can be applied to all subresources, such as images.

Note:
When evaluating the use of immutable and QPACK:
If you're concerned that immutable changes the predefined value provided by QPACK, consider that
in this case, the immutable part can be encoded separately by splitting the Cache-Control value into two lines — though this is dependent on the encoding algorithm a particular QPACK implementation uses.

httpCache-Control: public, max-age=31536000
Cache-Control: immutable
Main resourcesUnlike subresources, main resources cannot be cache busted because their URLs can't be decorated in the same way that subresource URLs can be.
If the following HTML itself is stored, the latest version cannot be displayed even if the content is updated on the server side.
html<script src="bundle.v123.js"></script>
<link rel="stylesheet" href="build.v123.css" />
<body>
  hello
</body>

For that case, no-cache would be appropriate — rather than no-store — since we don't want to store HTML, but instead just want it to always be up-to-date.
Furthermore, adding Last-Modified and ETag will allow clients to send conditional requests, and a 304 Not Modified can be returned if there have been no updates to the HTML:
httpHTTP/1.1 200 OK
Content-Type: text/html
Content-Length: 1024
Cache-Control: no-cache
Last-Modified: Tue, 22 Feb 2022 20:20:20 GMT
ETag: "AAPuIbAOdvAGEETbgAAAAAAABAAE"

That setting is appropriate for non-personalized HTML, but for a response that gets personalized using cookies — for example, after a login — don't forget to also specify private:
httpHTTP/1.1 200 OK
Content-Type: text/html
Content-Length: 1024
Cache-Control: no-cache, private
Last-Modified: Tue, 22 Feb 2022 20:20:20 GMT
ETag: "AAPuIbAOdvAGEETbgAAAAAAABAAE"
Set-Cookie: __Host-SID=AHNtAyt3fvJrUL5g5tnGwER; Secure; Path=/; HttpOnly

The same can be used for favicon.ico, manifest.json, .well-known, and API endpoints whose URLs cannot be changed using cache busting.
Most web content can be covered by a combination of the two patterns described above.More about managed cachesWith the method described in previous sections, subresources can be cached for a long time by using cache busting, but main resources (which are usually HTML documents) can't be.
Caching main resources is difficult because, using just standard directives from the HTTP Caching specification, there's no way to actively delete cache contents when content is updated on the server.
However, it is possible by deploying a managed cache such as a CDN or service worker.
For example, a CDN that allows cache purging via an API or dashboard operation would allow for a more aggressive caching strategy by storing the main resource and explicitly purging the relevant cache only when an update occurs on the server.
A service worker could do the same if it could delete the contents in the Cache API when an update occurs on the server.
For more information, see the documentation for your CDN, and consult the service worker documentation.See also
RFC 9111: Hypertext Transfer Protocol (HTTP/1.1): Caching
Caching Tutorial - Mark Nottingham\n\nHTTP cachingThe HTTP cache stores a response associated with a request and reuses the stored response for subsequent requests.
There are several advantages to reusability. First, since there is no need to deliver the request to the origin server, then the closer the client and cache are, the faster the response will be. The most typical example is when the browser itself stores a cache for browser requests.
Also, when a response is reusable, the origin server does not need to process the request — so it does not need to parse and route the request, restore the session based on the cookie, query the DB for results, or render the template engine. That reduces the load on the server.
Proper operation of the cache is critical to the health of the system.Types of cachesIn the HTTP Caching spec, there are two main types of caches: private caches and shared caches.Private cachesA private cache is a cache tied to a specific client — typically a browser cache. Since the stored response is not shared with other clients, a private cache can store a personalized response for that user.
On the other hand, if personalized contents are stored in a cache other than a private cache, then other users may be able to retrieve those contents — which may cause unintentional information leakage.
If a response contains personalized content and you want to store the response only in the private cache, you must specify a private directive.
httpCache-Control: private

Personalized contents are usually controlled by cookies, but the presence of a cookie does not always indicate that it is private, and thus a cookie alone does not make the response private.Shared cacheThe shared cache is located between the client and the server and can store responses that can be shared among users. And shared caches can be further sub-classified into proxy caches and managed caches.
Proxy caches
In addition to the function of access control, some proxies implement caching to reduce traffic out of the network. This is usually not managed by the service developer, so it must be controlled by appropriate HTTP headers and so on. However, in the past, outdated proxy-cache implementations — such as implementations that do not properly understand the HTTP Caching standard — have often caused problems for developers.
Kitchen-sink headers like the following are used to try to work around "old and not updated proxy cache" implementations that do not understand current HTTP Caching spec directives like no-store.
httpCache-Control: no-store, no-cache, max-age=0, must-revalidate, proxy-revalidate

However, in recent years, as HTTPS has become more common and client/server communication has become encrypted, proxy caches in the path can only tunnel a response and can't behave as a cache, in many cases. So in that scenario, there is no need to worry about outdated proxy cache implementations that cannot even see the response.
On the other hand, if a TLS bridge proxy decrypts all communications in a person-in-the-middle manner by installing a certificate from a CA (certificate authority) managed by the organization on the PC, and performs access control, etc. — it is possible to see the contents of the response and cache it. However, since CT (certificate transparency) has become widespread in recent years, and some browsers only allow certificates issued with an SCT (signed certificate timestamp), this method requires the application of an enterprise policy. In such a controlled environment, there is no need to worry about the proxy cache being "out of date and not updated".
Managed caches
Managed caches are explicitly deployed by service developers to offload the origin server and to deliver content efficiently. Examples include reverse proxies, CDNs, and service workers in combination with the Cache API.
The characteristics of managed caches vary depending on the product deployed. In most cases, you can control the cache's behavior through the Cache-Control header and your own configuration files or dashboards.
For example, the HTTP Caching specification essentially does not define a way to explicitly delete a cache — but with a managed cache, the stored response can be deleted at any time through dashboard operations, API calls, restarts, and so on. That allows for a more proactive caching strategy.
It is also possible to ignore the standard HTTP Caching spec protocols in favor of explicit manipulation. For example, the following can be specified to opt-out of a private cache or proxy cache, while using your own strategy to cache only in a managed cache.
httpCache-Control: no-store

For example, Varnish Cache uses VCL (Varnish Configuration Language, a type of DSL) logic to handle cache storage, while service workers in combination with the Cache API allow you to create that logic in JavaScript.
That means if a managed cache intentionally ignores a no-store directive, there is no need to perceive it as being "non-compliant" with the standard. What you should do is, avoid using kitchen-sink headers, but carefully read the documentation of whatever managed-cache mechanism you're using, and ensure you're controlling the cache properly in the ways provided by the mechanism you've chosen to use.
Note that some CDNs provide their own headers that are effective only for that CDN (for example, Surrogate-Control). Currently, work is underway to define a CDN-Cache-Control header to standardize those.
Heuristic cachingHTTP is designed to cache as much as possible, so even if no Cache-Control is given, responses will get stored and reused if certain conditions are met. This is called heuristic caching.
For example, take the following response. This response was last updated 1 year ago.
httpHTTP/1.1 200 OK
Content-Type: text/html
Content-Length: 1024
Date: Tue, 22 Feb 2022 22:22:22 GMT
Last-Modified: Tue, 22 Feb 2021 22:22:22 GMT

<!doctype html>
…

It is heuristically known that content which has not been updated for a full year will not be updated for some time after that. Therefore, the client stores this response (despite the lack of max-age) and reuses it for a while. How long to reuse is up to the implementation, but the specification recommends about 10% (in this case 0.1 year) of the time after storing.
Heuristic caching is a workaround that came before Cache-Control support became widely adopted, and basically all responses should explicitly specify a Cache-Control header.Fresh and stale based on ageStored HTTP responses have two states: fresh and stale. The fresh state usually indicates that the response is still valid and can be reused, while the stale state means that the cached response has already expired.
The criterion for determining when a response is fresh and when it is stale is age. In HTTP, age is the time elapsed since the response was generated. This is similar to the TTL in other caching mechanisms.
Take the following example response (604800 seconds is one week):
httpHTTP/1.1 200 OK
Content-Type: text/html
Content-Length: 1024
Date: Tue, 22 Feb 2022 22:22:22 GMT
Cache-Control: max-age=604800

<!doctype html>
…

The cache that stored the example response calculates the time elapsed since the response was generated and uses the result as the response's age.
For the example response, the meaning of max-age is the following:

If the age of the response is less than one week, the response is fresh.
If the age of the response is more than one week, the response is stale.

As long as the stored response remains fresh, it will be used to fulfill client requests.
When a response is stored in a shared cache, it is possible to tell the client the age of the response. Continuing with the example, if the shared cache stored the response for one day, the shared cache would send the following response to subsequent client requests.
httpHTTP/1.1 200 OK
Content-Type: text/html
Content-Length: 1024
Date: Tue, 22 Feb 2022 22:22:22 GMT
Cache-Control: max-age=604800
Age: 86400

<!doctype html>
…

The client which receives that response will find it to be fresh for the remaining 518400 seconds, the difference between the response's max-age and Age.Expires or max-ageIn HTTP/1.0, freshness used to be specified by the Expires header.
The Expires header specifies the lifetime of the cache using an explicit time rather than by specifying an elapsed time.
httpExpires: Tue, 28 Feb 2022 22:22:22 GMT

However, the time format is difficult to parse, many implementation bugs were found, and it is possible to induce problems by intentionally shifting the system clock; therefore, max-age — for specifying an elapsed time — was adopted for Cache-Control in HTTP/1.1.
If both Expires and Cache-Control: max-age are available, max-age is defined to be preferred. So it is not necessary to provide Expires now that HTTP/1.1 is widely used.VaryThe way that responses are distinguished from one another is essentially based on their URLs:



URL
Response body




https://example.com/index.html
<!doctype html>...


https://example.com/style.css
body { ...


https://example.com/script.js
function main () { ...



But the contents of responses are not always the same, even if they have the same URL. Especially when content negotiation is performed, the response from the server can depend on the values of the Accept, Accept-Language, and Accept-Encoding request headers.
For example, for English content returned with an Accept-Language: en header and cached, it is undesirable to then reuse that cached response for requests that have an Accept-Language: ja request header. In this case, you can cause the responses to be cached separately — based on language — by adding Accept-Language to the value of the Vary header.
httpVary: Accept-Language

That causes the cache to be keyed based on a composite of the response URL and the Accept-Language request header — rather than being based just on the response URL.



URL
Accept-Language
Response body




https://example.com/index.html
ja-JP
<!doctype html>...


https://example.com/index.html
en-US
<!doctype html>...


https://example.com/style.css
ja-JP
body { ...


https://example.com/script.js
ja-JP
function main () { ...



Also, if you are providing content optimization (for example, for responsive design) based on the user agent, you may be tempted to include User-Agent in the value of the Vary header. However, the User-Agent request header generally has a very large number of variations, which drastically reduces the chance that the cache will be reused. So if possible, instead consider a way to vary behavior based on feature detection rather than based on the User-Agent request header.
For applications that employ cookies to prevent others from reusing cached personalized content, you should specify Cache-Control: private instead of specifying a cookie for Vary.ValidationStale responses are not immediately discarded. HTTP has a mechanism to transform a stale response into a fresh one by asking the origin server. This is called validation, or sometimes, revalidation.
Validation is done by using a conditional request that includes an If-Modified-Since or If-None-Match request header.If-Modified-SinceThe following response was generated at 22:22:22 and has a max-age of 1 hour, so you know that it is fresh until 23:22:22.
httpHTTP/1.1 200 OK
Content-Type: text/html
Content-Length: 1024
Date: Tue, 22 Feb 2022 22:22:22 GMT
Last-Modified: Tue, 22 Feb 2022 22:00:00 GMT
Cache-Control: max-age=3600

<!doctype html>
…

At 23:22:22, the response becomes stale and the cache cannot be reused. So the request below shows a client sending a request with an If-Modified-Since request header, to ask the server if there have been any changes made since the specified time.
httpGET /index.html HTTP/1.1
Host: example.com
Accept: text/html
If-Modified-Since: Tue, 22 Feb 2022 22:00:00 GMT

The server will respond with 304 Not Modified if the content has not changed since the specified time.
Since this response only indicates "no change", there is no response body — there's just a status code — so the transfer size is extremely small.
httpHTTP/1.1 304 Not Modified
Content-Type: text/html
Date: Tue, 22 Feb 2022 23:22:22 GMT
Last-Modified: Tue, 22 Feb 2022 22:00:00 GMT
Cache-Control: max-age=3600

Upon receiving that response, the client reverts the stored stale response back to being fresh and can reuse it during the remaining 1 hour.
The server can obtain the modification time from the operating-system file system, which is relatively easy to do for the case of serving static files. However, there are some problems; for example, the time format is complex and difficult to parse, and distributed servers have difficulty synchronizing file-update times.
To solve such problems, the ETag response header was standardized as an alternative.ETag/If-None-MatchThe value of the ETag response header is an arbitrary value generated by the server. There are no restrictions on how the server must generate the value, so servers are free to set the value based on whatever means they choose — such as a hash of the body contents or a version number.
As an example, if a hash value is used for the ETag header and the hash value of the index.html resource is 33a64df5, the response will be as follows:
httpHTTP/1.1 200 OK
Content-Type: text/html
Content-Length: 1024
Date: Tue, 22 Feb 2022 22:22:22 GMT
ETag: "33a64df5"
Cache-Control: max-age=3600

<!doctype html>
…

If that response is stale, the client takes the value of the ETag response header for the cached response, and puts it into the If-None-Match request header, to ask the server if the resource has been modified:
httpGET /index.html HTTP/1.1
Host: example.com
Accept: text/html
If-None-Match: "33a64df5"

The server will return 304 Not Modified if the value of the ETag header it determines for the requested resource is the same as the If-None-Match value in the request.
But if the server determines the requested resource should now have a different ETag value, the server will instead respond with a 200 OK and the latest version of the resource.

Note:
RFC9110 prefers that servers send both ETag and Last-Modified for a 200 response if possible.
During cache revalidation, if both If-Modified-Since and If-None-Match are present, then If-None-Match takes precedence for the validator.
If you are only considering caching, you may think that Last-Modified is unnecessary.
However, Last-Modified is not just useful for caching; it is a standard HTTP header that is also used by content-management (CMS) systems to display the last-modified time, by crawlers to adjust crawl frequency, and for other various purposes.
So considering the overall HTTP ecosystem, it is better to provide both ETag and Last-Modified.
Force RevalidationIf you do not want a response to be reused, but instead want to always fetch the latest content from the server, you can use the no-cache directive to force validation.
By adding Cache-Control: no-cache to the response along with Last-Modified and ETag — as shown below — the client will receive a 200 OK response if the requested resource has been updated, or will otherwise receive a 304 Not Modified response if the requested resource has not been updated.
httpHTTP/1.1 200 OK
Content-Type: text/html
Content-Length: 1024
Date: Tue, 22 Feb 2022 22:22:22 GMT
Last-Modified: Tue, 22 Feb 2022 22:00:00 GMT
ETag: "deadbeef"
Cache-Control: no-cache

<!doctype html>
…

It is often stated that the combination of max-age=0 and must-revalidate has the same meaning as no-cache.
httpCache-Control: max-age=0, must-revalidate

max-age=0 means that the response is immediately stale, and must-revalidate means that it must not be reused without revalidation once it is stale — so, in combination, the semantics seem to be the same as no-cache.
However, that usage of max-age=0 is a remnant of the fact that many implementations prior to HTTP/1.1 were unable to handle the no-cache directive — and so to deal with that limitation, max-age=0 was used as a workaround.
But now that HTTP/1.1-conformant servers are widely deployed, there's no reason to ever use that max-age=0 and must-revalidate combination — you should instead just use no-cache.Don't cacheThe no-cache directive does not prevent the storing of responses but instead prevents the reuse of responses without revalidation.
If you don't want a response stored in any cache, use no-store.
httpCache-Control: no-store

However, in general, a "do not cache" requirement in practice amounts to the following set of circumstances:

Don't want the response stored by anyone other than the specific client, for privacy reasons.
Want to provide up-to-date information always.
Don't know what could happen in outdated implementations.

Under that set of circumstances, no-store is not always the most-appropriate directive.
The following sections look at the circumstances in more detail.Do not share with othersIt would be problematic if a response with personalized content is unexpectedly visible to other users of a cache.
In such a case, using the private directive will cause the personalized response to only be stored with the specific client and not be leaked to any other user of the cache.
httpCache-Control: private

In such a case, even if no-store is given, private must also be given.Provide up-to-date content every timeThe no-store directive prevents a response from being stored, but does not delete any already-stored response for the same URL.
In other words, if there is an old response already stored for a particular URL, returning no-store will not prevent the old response from being reused.
However, a no-cache directive will force the client to send a validation request before reusing any stored response.
httpCache-Control: no-cache

If the server does not support conditional requests, you can force the client to access the server every time and always get the latest response with 200 OK.Dealing with outdated implementationsAs a workaround for outdated implementations that ignore no-store, you may see kitchen-sink headers such as the following being used.
httpCache-Control: no-store, no-cache, max-age=0, must-revalidate, proxy-revalidate

It is recommended to use no-cache as an alternative for dealing with such outdated implementations, and it is not a problem if no-cache is given from the beginning, since the server will always receive the request.
If it is the shared cache that you are concerned about, you can make sure to prevent unintended caching by also adding private:
httpCache-Control: no-cache, private
What's lost by no-storeYou may think adding no-store would be the right way to opt-out of caching.
However, it's not recommended to grant no-store liberally, because you lose many advantages that HTTP and browsers have, including the browser's back/forward cache.
Therefore, to get the advantages of the full feature set of the web platform, prefer the use of no-cache in combination with private.Reload and force reloadValidation can be performed for requests as well as responses.
The reload and force reload actions are common examples of validation performed from the browser side.ReloadFor recovering from window corruption or updating to the latest version of the resource, browsers provide a reload function for users.
A simplified view of the HTTP request sent during a browser reload looks as follows:
httpGET / HTTP/1.1
Host: example.com
Cache-Control: max-age=0
If-None-Match: "deadbeef"
If-Modified-Since: Tue, 22 Feb 2022 20:20:20 GMT

(The requests from Chrome, Edge, and Firefox look very much like the above; the requests from Safari will look a bit different.)
The max-age=0 directive in the request specifies "reuse of responses with an age of 0 or less" — so, in effect, intermediately stored responses are not reused.
As a result, a request is validated by If-None-Match and If-Modified-Since.
That behavior is also defined in the Fetch standard and can be reproduced in JavaScript by calling fetch() with the cache mode set to no-cache (note that reload is not the right mode for this case):
js// Note: "reload" is not the right mode for a normal reload; "no-cache" is
fetch("/", { cache: "no-cache" });
Force reloadBrowsers use max-age=0 during reloads for backward-compatibility reasons — because many outdated implementations prior to HTTP/1.1 did not understand no-cache. But no-cache is fine now in this use case, and force reload is an additional way to bypass cached responses.
The HTTP Request during a browser force reload looks as follows:
httpGET / HTTP/1.1
Host: example.com
Pragma: no-cache
Cache-Control: no-cache

(The requests from Chrome, Edge, and Firefox look very much like the above; the requests from Safari will look a bit different.)
Since that's not a conditional request with no-cache, you can be sure you'll get a 200 OK from the origin server.
That behavior is also defined in the Fetch standard and can be reproduced in JavaScript by calling fetch() with the cache mode set to reload (note that it's not force-reload):
js// Note: "reload" — rather than "no-cache" — is the right mode for a "force reload"
fetch("/", { cache: "reload" });
Avoiding revalidationContent that never changes should be given a long max-age by using cache busting — that is, by including a version number, hash value, etc., in the request URL.
However, when the user reloads, a revalidation request is sent even though the server knows that the content is immutable.
To prevent that, the immutable directive can be used to explicitly indicate that revalidation is not required because the content never changes.
httpCache-Control: max-age=31536000, immutable

That prevents unnecessary revalidation during reloads.
Note that, instead of implementing that directive, Chrome has changed its implementation so that revalidation is not performed during reloads for subresources.Deleting stored responsesThere is no way to delete responses on an intermediate server that have been stored with a long max-age.
Imagine that the following response from https://example.com/ was stored.
httpHTTP/1.1 200 OK
Content-Type: text/html
Content-Length: 1024
Cache-Control: max-age=31536000

<!doctype html>
…

You may want to overwrite that response once it expired on the server, but there is nothing the server can do once the response is stored — since no more requests reach the server due to caching.
One of the methods mentioned in the specification is to send a request for the same URL with an unsafe method such as POST, but for many clients that is difficult to do.
The Clear-Site-Data: cache header and directive value can be used to clear browser caches — but has no effect on intermediate caches.
Otherwise responses will remain in the browser cache until max-age expires, unless the user manually performs a reload, force-reload, or clear-history action.
Caching reduces access to the server, which means that the server loses control of that URL. If the server does not want to lose control of a URL — for example, in the case that a resource is frequently updated — you should add no-cache so that the server will always receive requests and send the intended responses.Request collapseThe shared cache is primarily located before the origin server and is intended to reduce traffic to the origin server.
Thus, if multiple identical requests arrive at a shared cache at the same time, the intermediate cache will forward a single request on behalf of itself to the origin, which can then reuse the result for all clients. This is called request collapse.
Request collapse occurs when requests are arriving at the same time, so even if max-age=0 or no-cache is given in the response, it will be reused.
If the response is personalized to a particular user and you do not want it to be shared in collapse, you should add the private directive:
Common caching patternsThere are many directives in the Cache-Control spec, and it may be difficult to understand all of them. But most websites can be covered by a combination of a handful of patterns.
This section describes the common patterns in designing caches.Default settingsAs mentioned above, the default behavior for caching (that is, for a response without Cache-Control) is not simply "don't cache" but implicit caching according to so-called "heuristic caching".
To avoid that heuristic caching, it's preferable to explicitly give all responses a default Cache-Control header.
To ensure that by default the latest versions of resources will always be transferred, it's common practice to make the default Cache-Control value include no-cache:
httpCache-Control: no-cache

In addition, if the service implements cookies or other login methods, and the content is personalized for each user, private must be given too, to prevent sharing with other users:
httpCache-Control: no-cache, private
Cache BustingThe resources that work best with caching are static immutable files whose contents never change. And for resources that do change, it is a common best practice to change the URL each time the content changes, so that the URL unit can be cached for a longer period.
As an example, consider the following HTML:
html<script src="bundle.js"></script>
<link rel="stylesheet" href="build.css" />
<body>
  hello
</body>

In modern web development, JavaScript and CSS resources are frequently updated as development progresses. Also, if the versions of JavaScript and CSS resources that a client uses are out of sync, the display will break.
So the HTML above makes it difficult to cache bundle.js and build.css with max-age.
Therefore, you can serve the JavaScript and CSS with URLs that include a changing part based on a version number or hash value. Some of the ways to do that are shown below.
# version in filename
bundle.v123.js

# version in query
bundle.js?v=123

# hash in filename
bundle.YsAIAAAA-QG4G6kCMAMBAAAAAAAoK.js

# hash in query
bundle.js?v=YsAIAAAA-QG4G6kCMAMBAAAAAAAoK

Since the cache distinguishes resources from one another based on their URLs, the cache will not be reused again if the URL changes when a resource is updated.
html<script src="bundle.v123.js"></script>
<link rel="stylesheet" href="build.v123.css" />
<body>
  hello
</body>

With that design, both JavaScript and CSS resources can be cached for a long time. So how long should max-age be set to? The QPACK specification provides an answer to that question.
QPACK is a standard for compressing HTTP header fields, with tables of commonly-used field values defined.
Some commonly-used cache-header values are shown below.
36 cache-control max-age=0
37 cache-control max-age=604800
38 cache-control max-age=2592000
39 cache-control no-cache
40 cache-control no-store
41 cache-control public, max-age=31536000

If you select one of those numbered options, you can compress values in 1 byte when transferred via HTTP3.
Numbers 37, 38, and 41 are for periods of one week, one month, and one year.
Because the cache removes old entries when new entries are saved, the probability that a stored response still exists after one week is not that high — even if max-age is set to 1 week. Therefore, in practice, it does not make much difference which one you choose.
Note that number 41 has the longest max-age (1 year), but with public.
The public value has the effect of making the response storable even if the Authorization header is present.

Note:
The public directive should only be used if there is a need to store the response when the Authorization header is set.
It is not required otherwise, because a response will be stored in the shared cache as long as max-age is given.

So if the response is personalized with basic authentication, the presence of public may cause problems. If you are concerned about that, you can choose the second-longest value, 38 (1 month).
http# response for bundle.v123.js

# If you never personalize responses via Authorization
Cache-Control: public, max-age=31536000

# If you can't be certain
Cache-Control: max-age=2592000
ValidationDon't forget to set the Last-Modified and ETag headers, so that you don't have to re-transmit a resource when reloading. It's easy to generate those headers for pre-built static files.
The ETag value here may be a hash of the file.
http# response for bundle.v123.js
Last-Modified: Tue, 22 Feb 2022 20:20:20 GMT
ETag: "YsAIAAAA-QG4G6kCMAMBAAAAAAAoK"

In addition, immutable can be added to prevent validation on reload.
The combined result is shown below.
http# bundle.v123.js
HTTP/1.1 200 OK
Content-Type: text/javascript
Content-Length: 1024
Cache-Control: public, max-age=31536000, immutable
Last-Modified: Tue, 22 Feb 2022 20:20:20 GMT
ETag: "YsAIAAAA-QG4G6kCMAMBAAAAAAAoK"

Cache busting is a technique to make a response cacheable over a long period by changing the URL when the content changes. The technique can be applied to all subresources, such as images.

Note:
When evaluating the use of immutable and QPACK:
If you're concerned that immutable changes the predefined value provided by QPACK, consider that
in this case, the immutable part can be encoded separately by splitting the Cache-Control value into two lines — though this is dependent on the encoding algorithm a particular QPACK implementation uses.

httpCache-Control: public, max-age=31536000
Cache-Control: immutable
Main resourcesUnlike subresources, main resources cannot be cache busted because their URLs can't be decorated in the same way that subresource URLs can be.
If the following HTML itself is stored, the latest version cannot be displayed even if the content is updated on the server side.
html<script src="bundle.v123.js"></script>
<link rel="stylesheet" href="build.v123.css" />
<body>
  hello
</body>

For that case, no-cache would be appropriate — rather than no-store — since we don't want to store HTML, but instead just want it to always be up-to-date.
Furthermore, adding Last-Modified and ETag will allow clients to send conditional requests, and a 304 Not Modified can be returned if there have been no updates to the HTML:
httpHTTP/1.1 200 OK
Content-Type: text/html
Content-Length: 1024
Cache-Control: no-cache
Last-Modified: Tue, 22 Feb 2022 20:20:20 GMT
ETag: "AAPuIbAOdvAGEETbgAAAAAAABAAE"

That setting is appropriate for non-personalized HTML, but for a response that gets personalized using cookies — for example, after a login — don't forget to also specify private:
httpHTTP/1.1 200 OK
Content-Type: text/html
Content-Length: 1024
Cache-Control: no-cache, private
Last-Modified: Tue, 22 Feb 2022 20:20:20 GMT
ETag: "AAPuIbAOdvAGEETbgAAAAAAABAAE"
Set-Cookie: __Host-SID=AHNtAyt3fvJrUL5g5tnGwER; Secure; Path=/; HttpOnly

The same can be used for favicon.ico, manifest.json, .well-known, and API endpoints whose URLs cannot be changed using cache busting.
Most web content can be covered by a combination of the two patterns described above.More about managed cachesWith the method described in previous sections, subresources can be cached for a long time by using cache busting, but main resources (which are usually HTML documents) can't be.
Caching main resources is difficult because, using just standard directives from the HTTP Caching specification, there's no way to actively delete cache contents when content is updated on the server.
However, it is possible by deploying a managed cache such as a CDN or service worker.
For example, a CDN that allows cache purging via an API or dashboard operation would allow for a more aggressive caching strategy by storing the main resource and explicitly purging the relevant cache only when an update occurs on the server.
A service worker could do the same if it could delete the contents in the Cache API when an update occurs on the server.
For more information, see the documentation for your CDN, and consult the service worker documentation.See also
RFC 9111: Hypertext Transfer Protocol (HTTP/1.1): Caching
Caching Tutorial - Mark Nottingham
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Apr 24, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nHTTP cachingThe HTTP cache stores a response associated with a request and reuses the stored response for subsequent requests.
There are several advantages to reusability. First, since there is no need to deliver the request to the origin server, then the closer the client and cache are, the faster the response will be. The most typical example is when the browser itself stores a cache for browser requests.
Also, when a response is reusable, the origin server does not need to process the request — so it does not need to parse and route the request, restore the session based on the cookie, query the DB for results, or render the template engine. That reduces the load on the server.
Proper operation of the cache is critical to the health of the system.Types of cachesIn the HTTP Caching spec, there are two main types of caches: private caches and shared caches.Private cachesA private cache is a cache tied to a specific client — typically a browser cache. Since the stored response is not shared with other clients, a private cache can store a personalized response for that user.
On the other hand, if personalized contents are stored in a cache other than a private cache, then other users may be able to retrieve those contents — which may cause unintentional information leakage.
If a response contains personalized content and you want to store the response only in the private cache, you must specify a private directive.
httpCache-Control: private

Personalized contents are usually controlled by cookies, but the presence of a cookie does not always indicate that it is private, and thus a cookie alone does not make the response private.Shared cacheThe shared cache is located between the client and the server and can store responses that can be shared among users. And shared caches can be further sub-classified into proxy caches and managed caches.
Proxy caches
In addition to the function of access control, some proxies implement caching to reduce traffic out of the network. This is usually not managed by the service developer, so it must be controlled by appropriate HTTP headers and so on. However, in the past, outdated proxy-cache implementations — such as implementations that do not properly understand the HTTP Caching standard — have often caused problems for developers.
Kitchen-sink headers like the following are used to try to work around "old and not updated proxy cache" implementations that do not understand current HTTP Caching spec directives like no-store.
httpCache-Control: no-store, no-cache, max-age=0, must-revalidate, proxy-revalidate

However, in recent years, as HTTPS has become more common and client/server communication has become encrypted, proxy caches in the path can only tunnel a response and can't behave as a cache, in many cases. So in that scenario, there is no need to worry about outdated proxy cache implementations that cannot even see the response.
On the other hand, if a TLS bridge proxy decrypts all communications in a person-in-the-middle manner by installing a certificate from a CA (certificate authority) managed by the organization on the PC, and performs access control, etc. — it is possible to see the contents of the response and cache it. However, since CT (certificate transparency) has become widespread in recent years, and some browsers only allow certificates issued with an SCT (signed certificate timestamp), this method requires the application of an enterprise policy. In such a controlled environment, there is no need to worry about the proxy cache being "out of date and not updated".
Managed caches
Managed caches are explicitly deployed by service developers to offload the origin server and to deliver content efficiently. Examples include reverse proxies, CDNs, and service workers in combination with the Cache API.
The characteristics of managed caches vary depending on the product deployed. In most cases, you can control the cache's behavior through the Cache-Control header and your own configuration files or dashboards.
For example, the HTTP Caching specification essentially does not define a way to explicitly delete a cache — but with a managed cache, the stored response can be deleted at any time through dashboard operations, API calls, restarts, and so on. That allows for a more proactive caching strategy.
It is also possible to ignore the standard HTTP Caching spec protocols in favor of explicit manipulation. For example, the following can be specified to opt-out of a private cache or proxy cache, while using your own strategy to cache only in a managed cache.
httpCache-Control: no-store

For example, Varnish Cache uses VCL (Varnish Configuration Language, a type of DSL) logic to handle cache storage, while service workers in combination with the Cache API allow you to create that logic in JavaScript.
That means if a managed cache intentionally ignores a no-store directive, there is no need to perceive it as being "non-compliant" with the standard. What you should do is, avoid using kitchen-sink headers, but carefully read the documentation of whatever managed-cache mechanism you're using, and ensure you're controlling the cache properly in the ways provided by the mechanism you've chosen to use.
Note that some CDNs provide their own headers that are effective only for that CDN (for example, Surrogate-Control). Currently, work is underway to define a CDN-Cache-Control header to standardize those.
Heuristic cachingHTTP is designed to cache as much as possible, so even if no Cache-Control is given, responses will get stored and reused if certain conditions are met. This is called heuristic caching.
For example, take the following response. This response was last updated 1 year ago.
httpHTTP/1.1 200 OK
Content-Type: text/html
Content-Length: 1024
Date: Tue, 22 Feb 2022 22:22:22 GMT
Last-Modified: Tue, 22 Feb 2021 22:22:22 GMT

<!doctype html>
…

It is heuristically known that content which has not been updated for a full year will not be updated for some time after that. Therefore, the client stores this response (despite the lack of max-age) and reuses it for a while. How long to reuse is up to the implementation, but the specification recommends about 10% (in this case 0.1 year) of the time after storing.
Heuristic caching is a workaround that came before Cache-Control support became widely adopted, and basically all responses should explicitly specify a Cache-Control header.Fresh and stale based on ageStored HTTP responses have two states: fresh and stale. The fresh state usually indicates that the response is still valid and can be reused, while the stale state means that the cached response has already expired.
The criterion for determining when a response is fresh and when it is stale is age. In HTTP, age is the time elapsed since the response was generated. This is similar to the TTL in other caching mechanisms.
Take the following example response (604800 seconds is one week):
httpHTTP/1.1 200 OK
Content-Type: text/html
Content-Length: 1024
Date: Tue, 22 Feb 2022 22:22:22 GMT
Cache-Control: max-age=604800

<!doctype html>
…

The cache that stored the example response calculates the time elapsed since the response was generated and uses the result as the response's age.
For the example response, the meaning of max-age is the following:

If the age of the response is less than one week, the response is fresh.
If the age of the response is more than one week, the response is stale.

As long as the stored response remains fresh, it will be used to fulfill client requests.
When a response is stored in a shared cache, it is possible to tell the client the age of the response. Continuing with the example, if the shared cache stored the response for one day, the shared cache would send the following response to subsequent client requests.
httpHTTP/1.1 200 OK
Content-Type: text/html
Content-Length: 1024
Date: Tue, 22 Feb 2022 22:22:22 GMT
Cache-Control: max-age=604800
Age: 86400

<!doctype html>
…

The client which receives that response will find it to be fresh for the remaining 518400 seconds, the difference between the response's max-age and Age.Expires or max-ageIn HTTP/1.0, freshness used to be specified by the Expires header.
The Expires header specifies the lifetime of the cache using an explicit time rather than by specifying an elapsed time.
httpExpires: Tue, 28 Feb 2022 22:22:22 GMT

However, the time format is difficult to parse, many implementation bugs were found, and it is possible to induce problems by intentionally shifting the system clock; therefore, max-age — for specifying an elapsed time — was adopted for Cache-Control in HTTP/1.1.
If both Expires and Cache-Control: max-age are available, max-age is defined to be preferred. So it is not necessary to provide Expires now that HTTP/1.1 is widely used.VaryThe way that responses are distinguished from one another is essentially based on their URLs:



URL
Response body




https://example.com/index.html
<!doctype html>...


https://example.com/style.css
body { ...


https://example.com/script.js
function main () { ...



But the contents of responses are not always the same, even if they have the same URL. Especially when content negotiation is performed, the response from the server can depend on the values of the Accept, Accept-Language, and Accept-Encoding request headers.
For example, for English content returned with an Accept-Language: en header and cached, it is undesirable to then reuse that cached response for requests that have an Accept-Language: ja request header. In this case, you can cause the responses to be cached separately — based on language — by adding Accept-Language to the value of the Vary header.
httpVary: Accept-Language

That causes the cache to be keyed based on a composite of the response URL and the Accept-Language request header — rather than being based just on the response URL.



URL
Accept-Language
Response body




https://example.com/index.html
ja-JP
<!doctype html>...


https://example.com/index.html
en-US
<!doctype html>...


https://example.com/style.css
ja-JP
body { ...


https://example.com/script.js
ja-JP
function main () { ...



Also, if you are providing content optimization (for example, for responsive design) based on the user agent, you may be tempted to include User-Agent in the value of the Vary header. However, the User-Agent request header generally has a very large number of variations, which drastically reduces the chance that the cache will be reused. So if possible, instead consider a way to vary behavior based on feature detection rather than based on the User-Agent request header.
For applications that employ cookies to prevent others from reusing cached personalized content, you should specify Cache-Control: private instead of specifying a cookie for Vary.ValidationStale responses are not immediately discarded. HTTP has a mechanism to transform a stale response into a fresh one by asking the origin server. This is called validation, or sometimes, revalidation.
Validation is done by using a conditional request that includes an If-Modified-Since or If-None-Match request header.If-Modified-SinceThe following response was generated at 22:22:22 and has a max-age of 1 hour, so you know that it is fresh until 23:22:22.
httpHTTP/1.1 200 OK
Content-Type: text/html
Content-Length: 1024
Date: Tue, 22 Feb 2022 22:22:22 GMT
Last-Modified: Tue, 22 Feb 2022 22:00:00 GMT
Cache-Control: max-age=3600

<!doctype html>
…

At 23:22:22, the response becomes stale and the cache cannot be reused. So the request below shows a client sending a request with an If-Modified-Since request header, to ask the server if there have been any changes made since the specified time.
httpGET /index.html HTTP/1.1
Host: example.com
Accept: text/html
If-Modified-Since: Tue, 22 Feb 2022 22:00:00 GMT

The server will respond with 304 Not Modified if the content has not changed since the specified time.
Since this response only indicates "no change", there is no response body — there's just a status code — so the transfer size is extremely small.
httpHTTP/1.1 304 Not Modified
Content-Type: text/html
Date: Tue, 22 Feb 2022 23:22:22 GMT
Last-Modified: Tue, 22 Feb 2022 22:00:00 GMT
Cache-Control: max-age=3600

Upon receiving that response, the client reverts the stored stale response back to being fresh and can reuse it during the remaining 1 hour.
The server can obtain the modification time from the operating-system file system, which is relatively easy to do for the case of serving static files. However, there are some problems; for example, the time format is complex and difficult to parse, and distributed servers have difficulty synchronizing file-update times.
To solve such problems, the ETag response header was standardized as an alternative.ETag/If-None-MatchThe value of the ETag response header is an arbitrary value generated by the server. There are no restrictions on how the server must generate the value, so servers are free to set the value based on whatever means they choose — such as a hash of the body contents or a version number.
As an example, if a hash value is used for the ETag header and the hash value of the index.html resource is 33a64df5, the response will be as follows:
httpHTTP/1.1 200 OK
Content-Type: text/html
Content-Length: 1024
Date: Tue, 22 Feb 2022 22:22:22 GMT
ETag: "33a64df5"
Cache-Control: max-age=3600

<!doctype html>
…

If that response is stale, the client takes the value of the ETag response header for the cached response, and puts it into the If-None-Match request header, to ask the server if the resource has been modified:
httpGET /index.html HTTP/1.1
Host: example.com
Accept: text/html
If-None-Match: "33a64df5"

The server will return 304 Not Modified if the value of the ETag header it determines for the requested resource is the same as the If-None-Match value in the request.
But if the server determines the requested resource should now have a different ETag value, the server will instead respond with a 200 OK and the latest version of the resource.

Note:
RFC9110 prefers that servers send both ETag and Last-Modified for a 200 response if possible.
During cache revalidation, if both If-Modified-Since and If-None-Match are present, then If-None-Match takes precedence for the validator.
If you are only considering caching, you may think that Last-Modified is unnecessary.
However, Last-Modified is not just useful for caching; it is a standard HTTP header that is also used by content-management (CMS) systems to display the last-modified time, by crawlers to adjust crawl frequency, and for other various purposes.
So considering the overall HTTP ecosystem, it is better to provide both ETag and Last-Modified.
Force RevalidationIf you do not want a response to be reused, but instead want to always fetch the latest content from the server, you can use the no-cache directive to force validation.
By adding Cache-Control: no-cache to the response along with Last-Modified and ETag — as shown below — the client will receive a 200 OK response if the requested resource has been updated, or will otherwise receive a 304 Not Modified response if the requested resource has not been updated.
httpHTTP/1.1 200 OK
Content-Type: text/html
Content-Length: 1024
Date: Tue, 22 Feb 2022 22:22:22 GMT
Last-Modified: Tue, 22 Feb 2022 22:00:00 GMT
ETag: "deadbeef"
Cache-Control: no-cache

<!doctype html>
…

It is often stated that the combination of max-age=0 and must-revalidate has the same meaning as no-cache.
httpCache-Control: max-age=0, must-revalidate

max-age=0 means that the response is immediately stale, and must-revalidate means that it must not be reused without revalidation once it is stale — so, in combination, the semantics seem to be the same as no-cache.
However, that usage of max-age=0 is a remnant of the fact that many implementations prior to HTTP/1.1 were unable to handle the no-cache directive — and so to deal with that limitation, max-age=0 was used as a workaround.
But now that HTTP/1.1-conformant servers are widely deployed, there's no reason to ever use that max-age=0 and must-revalidate combination — you should instead just use no-cache.Don't cacheThe no-cache directive does not prevent the storing of responses but instead prevents the reuse of responses without revalidation.
If you don't want a response stored in any cache, use no-store.
httpCache-Control: no-store

However, in general, a "do not cache" requirement in practice amounts to the following set of circumstances:

Don't want the response stored by anyone other than the specific client, for privacy reasons.
Want to provide up-to-date information always.
Don't know what could happen in outdated implementations.

Under that set of circumstances, no-store is not always the most-appropriate directive.
The following sections look at the circumstances in more detail.Do not share with othersIt would be problematic if a response with personalized content is unexpectedly visible to other users of a cache.
In such a case, using the private directive will cause the personalized response to only be stored with the specific client and not be leaked to any other user of the cache.
httpCache-Control: private

In such a case, even if no-store is given, private must also be given.Provide up-to-date content every timeThe no-store directive prevents a response from being stored, but does not delete any already-stored response for the same URL.
In other words, if there is an old response already stored for a particular URL, returning no-store will not prevent the old response from being reused.
However, a no-cache directive will force the client to send a validation request before reusing any stored response.
httpCache-Control: no-cache

If the server does not support conditional requests, you can force the client to access the server every time and always get the latest response with 200 OK.Dealing with outdated implementationsAs a workaround for outdated implementations that ignore no-store, you may see kitchen-sink headers such as the following being used.
httpCache-Control: no-store, no-cache, max-age=0, must-revalidate, proxy-revalidate

It is recommended to use no-cache as an alternative for dealing with such outdated implementations, and it is not a problem if no-cache is given from the beginning, since the server will always receive the request.
If it is the shared cache that you are concerned about, you can make sure to prevent unintended caching by also adding private:
httpCache-Control: no-cache, private
What's lost by no-storeYou may think adding no-store would be the right way to opt-out of caching.
However, it's not recommended to grant no-store liberally, because you lose many advantages that HTTP and browsers have, including the browser's back/forward cache.
Therefore, to get the advantages of the full feature set of the web platform, prefer the use of no-cache in combination with private.Reload and force reloadValidation can be performed for requests as well as responses.
The reload and force reload actions are common examples of validation performed from the browser side.ReloadFor recovering from window corruption or updating to the latest version of the resource, browsers provide a reload function for users.
A simplified view of the HTTP request sent during a browser reload looks as follows:
httpGET / HTTP/1.1
Host: example.com
Cache-Control: max-age=0
If-None-Match: "deadbeef"
If-Modified-Since: Tue, 22 Feb 2022 20:20:20 GMT

(The requests from Chrome, Edge, and Firefox look very much like the above; the requests from Safari will look a bit different.)
The max-age=0 directive in the request specifies "reuse of responses with an age of 0 or less" — so, in effect, intermediately stored responses are not reused.
As a result, a request is validated by If-None-Match and If-Modified-Since.
That behavior is also defined in the Fetch standard and can be reproduced in JavaScript by calling fetch() with the cache mode set to no-cache (note that reload is not the right mode for this case):
js// Note: "reload" is not the right mode for a normal reload; "no-cache" is
fetch("/", { cache: "no-cache" });
Force reloadBrowsers use max-age=0 during reloads for backward-compatibility reasons — because many outdated implementations prior to HTTP/1.1 did not understand no-cache. But no-cache is fine now in this use case, and force reload is an additional way to bypass cached responses.
The HTTP Request during a browser force reload looks as follows:
httpGET / HTTP/1.1
Host: example.com
Pragma: no-cache
Cache-Control: no-cache

(The requests from Chrome, Edge, and Firefox look very much like the above; the requests from Safari will look a bit different.)
Since that's not a conditional request with no-cache, you can be sure you'll get a 200 OK from the origin server.
That behavior is also defined in the Fetch standard and can be reproduced in JavaScript by calling fetch() with the cache mode set to reload (note that it's not force-reload):
js// Note: "reload" — rather than "no-cache" — is the right mode for a "force reload"
fetch("/", { cache: "reload" });
Avoiding revalidationContent that never changes should be given a long max-age by using cache busting — that is, by including a version number, hash value, etc., in the request URL.
However, when the user reloads, a revalidation request is sent even though the server knows that the content is immutable.
To prevent that, the immutable directive can be used to explicitly indicate that revalidation is not required because the content never changes.
httpCache-Control: max-age=31536000, immutable

That prevents unnecessary revalidation during reloads.
Note that, instead of implementing that directive, Chrome has changed its implementation so that revalidation is not performed during reloads for subresources.Deleting stored responsesThere is no way to delete responses on an intermediate server that have been stored with a long max-age.
Imagine that the following response from https://example.com/ was stored.
httpHTTP/1.1 200 OK
Content-Type: text/html
Content-Length: 1024
Cache-Control: max-age=31536000

<!doctype html>
…

You may want to overwrite that response once it expired on the server, but there is nothing the server can do once the response is stored — since no more requests reach the server due to caching.
One of the methods mentioned in the specification is to send a request for the same URL with an unsafe method such as POST, but for many clients that is difficult to do.
The Clear-Site-Data: cache header and directive value can be used to clear browser caches — but has no effect on intermediate caches.
Otherwise responses will remain in the browser cache until max-age expires, unless the user manually performs a reload, force-reload, or clear-history action.
Caching reduces access to the server, which means that the server loses control of that URL. If the server does not want to lose control of a URL — for example, in the case that a resource is frequently updated — you should add no-cache so that the server will always receive requests and send the intended responses.Request collapseThe shared cache is primarily located before the origin server and is intended to reduce traffic to the origin server.
Thus, if multiple identical requests arrive at a shared cache at the same time, the intermediate cache will forward a single request on behalf of itself to the origin, which can then reuse the result for all clients. This is called request collapse.
Request collapse occurs when requests are arriving at the same time, so even if max-age=0 or no-cache is given in the response, it will be reused.
If the response is personalized to a particular user and you do not want it to be shared in collapse, you should add the private directive:
Common caching patternsThere are many directives in the Cache-Control spec, and it may be difficult to understand all of them. But most websites can be covered by a combination of a handful of patterns.
This section describes the common patterns in designing caches.Default settingsAs mentioned above, the default behavior for caching (that is, for a response without Cache-Control) is not simply "don't cache" but implicit caching according to so-called "heuristic caching".
To avoid that heuristic caching, it's preferable to explicitly give all responses a default Cache-Control header.
To ensure that by default the latest versions of resources will always be transferred, it's common practice to make the default Cache-Control value include no-cache:
httpCache-Control: no-cache

In addition, if the service implements cookies or other login methods, and the content is personalized for each user, private must be given too, to prevent sharing with other users:
httpCache-Control: no-cache, private
Cache BustingThe resources that work best with caching are static immutable files whose contents never change. And for resources that do change, it is a common best practice to change the URL each time the content changes, so that the URL unit can be cached for a longer period.
As an example, consider the following HTML:
html<script src="bundle.js"></script>
<link rel="stylesheet" href="build.css" />
<body>
  hello
</body>

In modern web development, JavaScript and CSS resources are frequently updated as development progresses. Also, if the versions of JavaScript and CSS resources that a client uses are out of sync, the display will break.
So the HTML above makes it difficult to cache bundle.js and build.css with max-age.
Therefore, you can serve the JavaScript and CSS with URLs that include a changing part based on a version number or hash value. Some of the ways to do that are shown below.
# version in filename
bundle.v123.js

# version in query
bundle.js?v=123

# hash in filename
bundle.YsAIAAAA-QG4G6kCMAMBAAAAAAAoK.js

# hash in query
bundle.js?v=YsAIAAAA-QG4G6kCMAMBAAAAAAAoK

Since the cache distinguishes resources from one another based on their URLs, the cache will not be reused again if the URL changes when a resource is updated.
html<script src="bundle.v123.js"></script>
<link rel="stylesheet" href="build.v123.css" />
<body>
  hello
</body>

With that design, both JavaScript and CSS resources can be cached for a long time. So how long should max-age be set to? The QPACK specification provides an answer to that question.
QPACK is a standard for compressing HTTP header fields, with tables of commonly-used field values defined.
Some commonly-used cache-header values are shown below.
36 cache-control max-age=0
37 cache-control max-age=604800
38 cache-control max-age=2592000
39 cache-control no-cache
40 cache-control no-store
41 cache-control public, max-age=31536000

If you select one of those numbered options, you can compress values in 1 byte when transferred via HTTP3.
Numbers 37, 38, and 41 are for periods of one week, one month, and one year.
Because the cache removes old entries when new entries are saved, the probability that a stored response still exists after one week is not that high — even if max-age is set to 1 week. Therefore, in practice, it does not make much difference which one you choose.
Note that number 41 has the longest max-age (1 year), but with public.
The public value has the effect of making the response storable even if the Authorization header is present.

Note:
The public directive should only be used if there is a need to store the response when the Authorization header is set.
It is not required otherwise, because a response will be stored in the shared cache as long as max-age is given.

So if the response is personalized with basic authentication, the presence of public may cause problems. If you are concerned about that, you can choose the second-longest value, 38 (1 month).
http# response for bundle.v123.js

# If you never personalize responses via Authorization
Cache-Control: public, max-age=31536000

# If you can't be certain
Cache-Control: max-age=2592000
ValidationDon't forget to set the Last-Modified and ETag headers, so that you don't have to re-transmit a resource when reloading. It's easy to generate those headers for pre-built static files.
The ETag value here may be a hash of the file.
http# response for bundle.v123.js
Last-Modified: Tue, 22 Feb 2022 20:20:20 GMT
ETag: "YsAIAAAA-QG4G6kCMAMBAAAAAAAoK"

In addition, immutable can be added to prevent validation on reload.
The combined result is shown below.
http# bundle.v123.js
HTTP/1.1 200 OK
Content-Type: text/javascript
Content-Length: 1024
Cache-Control: public, max-age=31536000, immutable
Last-Modified: Tue, 22 Feb 2022 20:20:20 GMT
ETag: "YsAIAAAA-QG4G6kCMAMBAAAAAAAoK"

Cache busting is a technique to make a response cacheable over a long period by changing the URL when the content changes. The technique can be applied to all subresources, such as images.

Note:
When evaluating the use of immutable and QPACK:
If you're concerned that immutable changes the predefined value provided by QPACK, consider that
in this case, the immutable part can be encoded separately by splitting the Cache-Control value into two lines — though this is dependent on the encoding algorithm a particular QPACK implementation uses.

httpCache-Control: public, max-age=31536000
Cache-Control: immutable
Main resourcesUnlike subresources, main resources cannot be cache busted because their URLs can't be decorated in the same way that subresource URLs can be.
If the following HTML itself is stored, the latest version cannot be displayed even if the content is updated on the server side.
html<script src="bundle.v123.js"></script>
<link rel="stylesheet" href="build.v123.css" />
<body>
  hello
</body>

For that case, no-cache would be appropriate — rather than no-store — since we don't want to store HTML, but instead just want it to always be up-to-date.
Furthermore, adding Last-Modified and ETag will allow clients to send conditional requests, and a 304 Not Modified can be returned if there have been no updates to the HTML:
httpHTTP/1.1 200 OK
Content-Type: text/html
Content-Length: 1024
Cache-Control: no-cache
Last-Modified: Tue, 22 Feb 2022 20:20:20 GMT
ETag: "AAPuIbAOdvAGEETbgAAAAAAABAAE"

That setting is appropriate for non-personalized HTML, but for a response that gets personalized using cookies — for example, after a login — don't forget to also specify private:
httpHTTP/1.1 200 OK
Content-Type: text/html
Content-Length: 1024
Cache-Control: no-cache, private
Last-Modified: Tue, 22 Feb 2022 20:20:20 GMT
ETag: "AAPuIbAOdvAGEETbgAAAAAAABAAE"
Set-Cookie: __Host-SID=AHNtAyt3fvJrUL5g5tnGwER; Secure; Path=/; HttpOnly

The same can be used for favicon.ico, manifest.json, .well-known, and API endpoints whose URLs cannot be changed using cache busting.
Most web content can be covered by a combination of the two patterns described above.More about managed cachesWith the method described in previous sections, subresources can be cached for a long time by using cache busting, but main resources (which are usually HTML documents) can't be.
Caching main resources is difficult because, using just standard directives from the HTTP Caching specification, there's no way to actively delete cache contents when content is updated on the server.
However, it is possible by deploying a managed cache such as a CDN or service worker.
For example, a CDN that allows cache purging via an API or dashboard operation would allow for a more aggressive caching strategy by storing the main resource and explicitly purging the relevant cache only when an update occurs on the server.
A service worker could do the same if it could delete the contents in the Cache API when an update occurs on the server.
For more information, see the documentation for your CDN, and consult the service worker documentation.See also
RFC 9111: Hypertext Transfer Protocol (HTTP/1.1): Caching
Caching Tutorial - Mark Nottingham
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Apr 24, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nHTTP authenticationHTTP provides a general framework for access control and authentication.
This page is an introduction to the HTTP framework for authentication, and shows how to restrict access to your server using the HTTP "Basic" scheme.The general HTTP authentication frameworkRFC 7235 defines the HTTP authentication framework, which can be used by a server to challenge a client request, and by a client to provide authentication information.
The challenge and response flow works like this:

The server responds to a client with a 401 (Unauthorized) response status and provides information on how to authorize with a WWW-Authenticate response header containing at least one challenge.
A client that wants to authenticate itself with the server can then do so by including an Authorization request header with the credentials.
Usually a client will present a password prompt to the user and will then issue the request including the correct Authorization header.


The general message flow above is the same for most (if not all) authentication schemes.
The actual information in the headers and the way it is encoded does change!

Warning:
The "Basic" authentication scheme used in the diagram above sends the credentials encoded but not encrypted.
This would be completely insecure unless the exchange was over a secure connection (HTTPS/TLS).
Proxy authenticationThe same challenge and response mechanism can be used for proxy authentication.
As both resource authentication and proxy authentication can coexist, a different set of headers and status codes is needed. In the case of proxies, the challenging status code is 407 (Proxy Authentication Required), the Proxy-Authenticate response header contains at least one challenge applicable to the proxy, and the Proxy-Authorization request header is used for providing the credentials to the proxy server.Access forbiddenIf a (proxy) server receives invalid credentials, it should respond with a 401 Unauthorized or with a 407 Proxy Authentication Required, and the user may send a new request or replace the Authorization header field.
If a (proxy) server receives valid credentials that are inadequate to access a given resource, the server should respond with the 403 Forbidden status code. Unlike 401 Unauthorized or 407 Proxy Authentication Required, authentication is impossible for this user and browsers will not propose a new attempt.
In all cases, the server may prefer returning a 404 Not Found status code, to hide the existence of the page to a user without adequate privileges or not correctly authenticated.Authentication of cross-origin imagesA potential security hole (that has since been fixed in browsers) was authentication of cross-site images.
From Firefox 59 onwards, image resources loaded from different origins to the current document are no longer able to trigger HTTP authentication dialogs (Firefox bug 1423146), preventing user credentials being stolen if attackers were able to embed an arbitrary image into a third-party page.Character encoding of HTTP authenticationBrowsers use utf-8 encoding for usernames and passwords.
Firefox once used ISO-8859-1, but changed to utf-8 for parity with other browsers and to avoid potential problems as described in Firefox bug 1419658.WWW-Authenticate and Proxy-Authenticate headersThe WWW-Authenticate and Proxy-Authenticate response headers define the authentication method that should be used to gain access to a resource. They must specify which authentication scheme is used, so that the client that wishes to authorize knows how to provide the credentials.
The syntax for these headers is the following:
httpWWW-Authenticate: <type> realm=<realm>
Proxy-Authenticate: <type> realm=<realm>

Here, <type> is the authentication scheme ("Basic" is the most common scheme and introduced below). The realm is used to describe the protected area or to indicate the scope of protection. This could be a message like "Access to the staging site" or similar, so that the user knows to which space they are trying to get access to.Authorization and Proxy-Authorization headersThe Authorization and Proxy-Authorization request headers contain the credentials to authenticate a user agent with a (proxy) server. Here, the <type> is needed again followed by the credentials, which can be encoded or encrypted depending on which authentication scheme is used.
httpAuthorization: <type> <credentials>
Proxy-Authorization: <type> <credentials>
Authentication schemesThe general HTTP authentication framework is the base for a number of authentication schemes.
IANA maintains a list of authentication schemes, but there are other schemes offered by host services, such as Amazon AWS.
Some common authentication schemes include:

Basic

See RFC 7617, base64-encoded credentials. More information below.

Bearer

See RFC 6750, bearer tokens to access OAuth 2.0-protected resources

Digest

See RFC 7616. Firefox 93 and later support the SHA-256 algorithm. Previous versions only support MD5 hashing (not recommended).

HOBA

See RFC 7486, Section 3, HTTP Origin-Bound Authentication, digital-signature-based

Mutual

See RFC 8120

Negotiate / NTLM

See RFC4599

VAPID

See RFC 8292

SCRAM

See RFC 7804

AWS4-HMAC-SHA256

See AWS docs. This scheme is used for AWS3 server authentication.


Schemes can differ in security strength and in their availability in client or server software.
The "Basic" authentication scheme offers very poor security, but is widely supported and easy to set up.
It is introduced in more detail below.Basic authentication schemeThe "Basic" HTTP authentication scheme is defined in RFC 7617, which transmits credentials as user ID/password pairs, encoded using base64.Security of basic authenticationAs the user ID and password are passed over the network as clear text (it is base64 encoded, but base64 is a reversible encoding), the basic authentication scheme is not secure. HTTPS/TLS should be used with basic authentication. Without these additional security enhancements, basic authentication should not be used to protect sensitive or valuable information.Restricting access with Apache and basic authenticationTo password-protect a directory on an Apache server, you will need a .htaccess and a .htpasswd file.
The .htaccess file typically looks like this:
apacheconfAuthType Basic
AuthName "Access to the staging site"
AuthUserFile /path/to/.htpasswd
Require valid-user

The .htaccess file references a .htpasswd file in which each line consists of a username and a password separated by a colon (:). You cannot see the actual passwords as they are hashed (using MD5-based hashing, in this case). Note that you can name your .htpasswd file differently if you like, but keep in mind this file shouldn't be accessible to anyone. (Apache is usually configured to prevent access to .ht* files).
apacheconfaladdin:$apr1$ZjTqBB3f$IF9gdYAGlMrs2fuINjHsz.
user2:$apr1$O04r.y2H$/vEkesPhVInBByJUkXitA/
Restricting access with Nginx and basic authenticationFor Nginx, you will need to specify a location that you are going to protect and the auth_basic directive that provides the name to the password-protected area.
The auth_basic_user_file directive then points to a .htpasswd file containing the encrypted user credentials, just like in the Apache example above.
apacheconflocation /status {
    auth_basic           "Access to the staging site";
    auth_basic_user_file /etc/apache2/.htpasswd;
}
Access using credentials in the URLMany clients also let you avoid the login prompt by using an encoded URL containing the username and the password like this:
https://username:password@www.example.com/

The use of these URLs is deprecated.
In Chrome, the username:password@ part in URLs is removed from subresource URLs for security reasons. In Firefox, it is checked if the site actually requires authentication and if not, Firefox will warn the user with a prompt "You are about to log in to the site www.example.com with the username username, but the website does not require authentication. This may be an attempt to trick you." In case the site does require authentication, Firefox will still ask for user confirmation "You are about to log in to the site www.example.com with the username username." before sending the credentials to the site. Note that Firefox sends the request without credentials in both cases before showing the prompt in order to determine whether the site requires authentication.See also
WWW-Authenticate
Authorization
Proxy-Authorization
Proxy-Authenticate
401, 403, 407\n\nHTTP authenticationHTTP provides a general framework for access control and authentication.
This page is an introduction to the HTTP framework for authentication, and shows how to restrict access to your server using the HTTP "Basic" scheme.The general HTTP authentication frameworkRFC 7235 defines the HTTP authentication framework, which can be used by a server to challenge a client request, and by a client to provide authentication information.
The challenge and response flow works like this:

The server responds to a client with a 401 (Unauthorized) response status and provides information on how to authorize with a WWW-Authenticate response header containing at least one challenge.
A client that wants to authenticate itself with the server can then do so by including an Authorization request header with the credentials.
Usually a client will present a password prompt to the user and will then issue the request including the correct Authorization header.


The general message flow above is the same for most (if not all) authentication schemes.
The actual information in the headers and the way it is encoded does change!

Warning:
The "Basic" authentication scheme used in the diagram above sends the credentials encoded but not encrypted.
This would be completely insecure unless the exchange was over a secure connection (HTTPS/TLS).
Proxy authenticationThe same challenge and response mechanism can be used for proxy authentication.
As both resource authentication and proxy authentication can coexist, a different set of headers and status codes is needed. In the case of proxies, the challenging status code is 407 (Proxy Authentication Required), the Proxy-Authenticate response header contains at least one challenge applicable to the proxy, and the Proxy-Authorization request header is used for providing the credentials to the proxy server.Access forbiddenIf a (proxy) server receives invalid credentials, it should respond with a 401 Unauthorized or with a 407 Proxy Authentication Required, and the user may send a new request or replace the Authorization header field.
If a (proxy) server receives valid credentials that are inadequate to access a given resource, the server should respond with the 403 Forbidden status code. Unlike 401 Unauthorized or 407 Proxy Authentication Required, authentication is impossible for this user and browsers will not propose a new attempt.
In all cases, the server may prefer returning a 404 Not Found status code, to hide the existence of the page to a user without adequate privileges or not correctly authenticated.Authentication of cross-origin imagesA potential security hole (that has since been fixed in browsers) was authentication of cross-site images.
From Firefox 59 onwards, image resources loaded from different origins to the current document are no longer able to trigger HTTP authentication dialogs (Firefox bug 1423146), preventing user credentials being stolen if attackers were able to embed an arbitrary image into a third-party page.Character encoding of HTTP authenticationBrowsers use utf-8 encoding for usernames and passwords.
Firefox once used ISO-8859-1, but changed to utf-8 for parity with other browsers and to avoid potential problems as described in Firefox bug 1419658.WWW-Authenticate and Proxy-Authenticate headersThe WWW-Authenticate and Proxy-Authenticate response headers define the authentication method that should be used to gain access to a resource. They must specify which authentication scheme is used, so that the client that wishes to authorize knows how to provide the credentials.
The syntax for these headers is the following:
httpWWW-Authenticate: <type> realm=<realm>
Proxy-Authenticate: <type> realm=<realm>

Here, <type> is the authentication scheme ("Basic" is the most common scheme and introduced below). The realm is used to describe the protected area or to indicate the scope of protection. This could be a message like "Access to the staging site" or similar, so that the user knows to which space they are trying to get access to.Authorization and Proxy-Authorization headersThe Authorization and Proxy-Authorization request headers contain the credentials to authenticate a user agent with a (proxy) server. Here, the <type> is needed again followed by the credentials, which can be encoded or encrypted depending on which authentication scheme is used.
httpAuthorization: <type> <credentials>
Proxy-Authorization: <type> <credentials>
Authentication schemesThe general HTTP authentication framework is the base for a number of authentication schemes.
IANA maintains a list of authentication schemes, but there are other schemes offered by host services, such as Amazon AWS.
Some common authentication schemes include:

Basic

See RFC 7617, base64-encoded credentials. More information below.

Bearer

See RFC 6750, bearer tokens to access OAuth 2.0-protected resources

Digest

See RFC 7616. Firefox 93 and later support the SHA-256 algorithm. Previous versions only support MD5 hashing (not recommended).

HOBA

See RFC 7486, Section 3, HTTP Origin-Bound Authentication, digital-signature-based

Mutual

See RFC 8120

Negotiate / NTLM

See RFC4599

VAPID

See RFC 8292

SCRAM

See RFC 7804

AWS4-HMAC-SHA256

See AWS docs. This scheme is used for AWS3 server authentication.


Schemes can differ in security strength and in their availability in client or server software.
The "Basic" authentication scheme offers very poor security, but is widely supported and easy to set up.
It is introduced in more detail below.Basic authentication schemeThe "Basic" HTTP authentication scheme is defined in RFC 7617, which transmits credentials as user ID/password pairs, encoded using base64.Security of basic authenticationAs the user ID and password are passed over the network as clear text (it is base64 encoded, but base64 is a reversible encoding), the basic authentication scheme is not secure. HTTPS/TLS should be used with basic authentication. Without these additional security enhancements, basic authentication should not be used to protect sensitive or valuable information.Restricting access with Apache and basic authenticationTo password-protect a directory on an Apache server, you will need a .htaccess and a .htpasswd file.
The .htaccess file typically looks like this:
apacheconfAuthType Basic
AuthName "Access to the staging site"
AuthUserFile /path/to/.htpasswd
Require valid-user

The .htaccess file references a .htpasswd file in which each line consists of a username and a password separated by a colon (:). You cannot see the actual passwords as they are hashed (using MD5-based hashing, in this case). Note that you can name your .htpasswd file differently if you like, but keep in mind this file shouldn't be accessible to anyone. (Apache is usually configured to prevent access to .ht* files).
apacheconfaladdin:$apr1$ZjTqBB3f$IF9gdYAGlMrs2fuINjHsz.
user2:$apr1$O04r.y2H$/vEkesPhVInBByJUkXitA/
Restricting access with Nginx and basic authenticationFor Nginx, you will need to specify a location that you are going to protect and the auth_basic directive that provides the name to the password-protected area.
The auth_basic_user_file directive then points to a .htpasswd file containing the encrypted user credentials, just like in the Apache example above.
apacheconflocation /status {
    auth_basic           "Access to the staging site";
    auth_basic_user_file /etc/apache2/.htpasswd;
}
Access using credentials in the URLMany clients also let you avoid the login prompt by using an encoded URL containing the username and the password like this:
https://username:password@www.example.com/

The use of these URLs is deprecated.
In Chrome, the username:password@ part in URLs is removed from subresource URLs for security reasons. In Firefox, it is checked if the site actually requires authentication and if not, Firefox will warn the user with a prompt "You are about to log in to the site www.example.com with the username username, but the website does not require authentication. This may be an attempt to trick you." In case the site does require authentication, Firefox will still ask for user confirmation "You are about to log in to the site www.example.com with the username username." before sending the credentials to the site. Note that Firefox sends the request without credentials in both cases before showing the prompt in order to determine whether the site requires authentication.See also
WWW-Authenticate
Authorization
Proxy-Authorization
Proxy-Authenticate
401, 403, 407
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nHTTP authenticationHTTP provides a general framework for access control and authentication.
This page is an introduction to the HTTP framework for authentication, and shows how to restrict access to your server using the HTTP "Basic" scheme.The general HTTP authentication frameworkRFC 7235 defines the HTTP authentication framework, which can be used by a server to challenge a client request, and by a client to provide authentication information.
The challenge and response flow works like this:

The server responds to a client with a 401 (Unauthorized) response status and provides information on how to authorize with a WWW-Authenticate response header containing at least one challenge.
A client that wants to authenticate itself with the server can then do so by including an Authorization request header with the credentials.
Usually a client will present a password prompt to the user and will then issue the request including the correct Authorization header.


The general message flow above is the same for most (if not all) authentication schemes.
The actual information in the headers and the way it is encoded does change!

Warning:
The "Basic" authentication scheme used in the diagram above sends the credentials encoded but not encrypted.
This would be completely insecure unless the exchange was over a secure connection (HTTPS/TLS).
Proxy authenticationThe same challenge and response mechanism can be used for proxy authentication.
As both resource authentication and proxy authentication can coexist, a different set of headers and status codes is needed. In the case of proxies, the challenging status code is 407 (Proxy Authentication Required), the Proxy-Authenticate response header contains at least one challenge applicable to the proxy, and the Proxy-Authorization request header is used for providing the credentials to the proxy server.Access forbiddenIf a (proxy) server receives invalid credentials, it should respond with a 401 Unauthorized or with a 407 Proxy Authentication Required, and the user may send a new request or replace the Authorization header field.
If a (proxy) server receives valid credentials that are inadequate to access a given resource, the server should respond with the 403 Forbidden status code. Unlike 401 Unauthorized or 407 Proxy Authentication Required, authentication is impossible for this user and browsers will not propose a new attempt.
In all cases, the server may prefer returning a 404 Not Found status code, to hide the existence of the page to a user without adequate privileges or not correctly authenticated.Authentication of cross-origin imagesA potential security hole (that has since been fixed in browsers) was authentication of cross-site images.
From Firefox 59 onwards, image resources loaded from different origins to the current document are no longer able to trigger HTTP authentication dialogs (Firefox bug 1423146), preventing user credentials being stolen if attackers were able to embed an arbitrary image into a third-party page.Character encoding of HTTP authenticationBrowsers use utf-8 encoding for usernames and passwords.
Firefox once used ISO-8859-1, but changed to utf-8 for parity with other browsers and to avoid potential problems as described in Firefox bug 1419658.WWW-Authenticate and Proxy-Authenticate headersThe WWW-Authenticate and Proxy-Authenticate response headers define the authentication method that should be used to gain access to a resource. They must specify which authentication scheme is used, so that the client that wishes to authorize knows how to provide the credentials.
The syntax for these headers is the following:
httpWWW-Authenticate: <type> realm=<realm>
Proxy-Authenticate: <type> realm=<realm>

Here, <type> is the authentication scheme ("Basic" is the most common scheme and introduced below). The realm is used to describe the protected area or to indicate the scope of protection. This could be a message like "Access to the staging site" or similar, so that the user knows to which space they are trying to get access to.Authorization and Proxy-Authorization headersThe Authorization and Proxy-Authorization request headers contain the credentials to authenticate a user agent with a (proxy) server. Here, the <type> is needed again followed by the credentials, which can be encoded or encrypted depending on which authentication scheme is used.
httpAuthorization: <type> <credentials>
Proxy-Authorization: <type> <credentials>
Authentication schemesThe general HTTP authentication framework is the base for a number of authentication schemes.
IANA maintains a list of authentication schemes, but there are other schemes offered by host services, such as Amazon AWS.
Some common authentication schemes include:

Basic

See RFC 7617, base64-encoded credentials. More information below.

Bearer

See RFC 6750, bearer tokens to access OAuth 2.0-protected resources

Digest

See RFC 7616. Firefox 93 and later support the SHA-256 algorithm. Previous versions only support MD5 hashing (not recommended).

HOBA

See RFC 7486, Section 3, HTTP Origin-Bound Authentication, digital-signature-based

Mutual

See RFC 8120

Negotiate / NTLM

See RFC4599

VAPID

See RFC 8292

SCRAM

See RFC 7804

AWS4-HMAC-SHA256

See AWS docs. This scheme is used for AWS3 server authentication.


Schemes can differ in security strength and in their availability in client or server software.
The "Basic" authentication scheme offers very poor security, but is widely supported and easy to set up.
It is introduced in more detail below.Basic authentication schemeThe "Basic" HTTP authentication scheme is defined in RFC 7617, which transmits credentials as user ID/password pairs, encoded using base64.Security of basic authenticationAs the user ID and password are passed over the network as clear text (it is base64 encoded, but base64 is a reversible encoding), the basic authentication scheme is not secure. HTTPS/TLS should be used with basic authentication. Without these additional security enhancements, basic authentication should not be used to protect sensitive or valuable information.Restricting access with Apache and basic authenticationTo password-protect a directory on an Apache server, you will need a .htaccess and a .htpasswd file.
The .htaccess file typically looks like this:
apacheconfAuthType Basic
AuthName "Access to the staging site"
AuthUserFile /path/to/.htpasswd
Require valid-user

The .htaccess file references a .htpasswd file in which each line consists of a username and a password separated by a colon (:). You cannot see the actual passwords as they are hashed (using MD5-based hashing, in this case). Note that you can name your .htpasswd file differently if you like, but keep in mind this file shouldn't be accessible to anyone. (Apache is usually configured to prevent access to .ht* files).
apacheconfaladdin:$apr1$ZjTqBB3f$IF9gdYAGlMrs2fuINjHsz.
user2:$apr1$O04r.y2H$/vEkesPhVInBByJUkXitA/
Restricting access with Nginx and basic authenticationFor Nginx, you will need to specify a location that you are going to protect and the auth_basic directive that provides the name to the password-protected area.
The auth_basic_user_file directive then points to a .htpasswd file containing the encrypted user credentials, just like in the Apache example above.
apacheconflocation /status {
    auth_basic           "Access to the staging site";
    auth_basic_user_file /etc/apache2/.htpasswd;
}
Access using credentials in the URLMany clients also let you avoid the login prompt by using an encoded URL containing the username and the password like this:
https://username:password@www.example.com/

The use of these URLs is deprecated.
In Chrome, the username:password@ part in URLs is removed from subresource URLs for security reasons. In Firefox, it is checked if the site actually requires authentication and if not, Firefox will warn the user with a prompt "You are about to log in to the site www.example.com with the username username, but the website does not require authentication. This may be an attempt to trick you." In case the site does require authentication, Firefox will still ask for user confirmation "You are about to log in to the site www.example.com with the username username." before sending the credentials to the site. Note that Firefox sends the request without credentials in both cases before showing the prompt in order to determine whether the site requires authentication.See also
WWW-Authenticate
Authorization
Proxy-Authorization
Proxy-Authenticate
401, 403, 407
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nUsing HTTP cookiesA cookie (also known as a web cookie or browser cookie) is a small piece of data a server sends to a user's web browser. The browser may store cookies, create new cookies, modify existing ones, and send them back to the same server with later requests. Cookies enable web applications to store limited amounts of data and remember state information; by default the HTTP protocol is stateless.
In this article we will explore the main uses of cookies, explain best practices for using them, and look at their privacy and security implications.What cookies are used forTypically, the server will use the contents of HTTP cookies to determine whether different requests come from the same browser/user and then issue a personalized or generic response as appropriate. The following describes a basic user sign-in system:

The user sends sign-in credentials to the server, for example via a form submission.
If the credentials are correct, the server updates the UI to indicate that the user is signed in, and responds with a cookie containing a session ID that records their sign-in status on the browser.
At a later time, the user moves to a different page on the same site. The browser sends the cookie containing the session ID along with the corresponding request to indicate that it still thinks the user is signed in.
The server checks the session ID and, if it is still valid, sends the user a personalized version of the new page. If it is not valid, the session ID is deleted and the user is shown a generic version of the page (or perhaps shown an "access denied" message and asked to sign in again).


Cookies are mainly used for three purposes:

Session management: User sign-in status, shopping cart contents, game scores, or any other user session-related details that the server needs to remember.
Personalization: User preferences such as display language and UI theme.
Tracking: Recording and analyzing user behavior.
Data storageIn the early days of the web when there was no other option, cookies were used for general client-side data storage purposes. Modern storage APIs are now recommended, for example the Web Storage API (localStorage and sessionStorage) and IndexedDB.
They are designed with storage in mind, never send data to the server, and don't come with other drawbacks of using cookies for storage:

Browsers are generally limited to a maximum number of cookies per domain (varies by browser, generally in the hundreds), and a maximum size per cookie (usually 4KB). Storage APIs can store larger amounts of data.
Cookies are sent with every request, so they can worsen performance (for example on slow mobile data connections), especially if you have a lot of cookies set.


Note:
To see stored cookies (and other storage that a web page is using) you can use the Storage Inspector in Firefox Developer Tools, or the Application panel in Chrome Developer Tools.
Creating, removing, and updating cookiesAfter receiving an HTTP request, a server can send one or more Set-Cookie headers with the response, each one of which will set a separate cookie. A cookie is set by specifying a name-value pair like this:
httpSet-Cookie: <cookie-name>=<cookie-value>

The following HTTP response instructs the receiving browser to store a pair of cookies:
httpHTTP/2.0 200 OK
Content-Type: text/html
Set-Cookie: yummy_cookie=chocolate
Set-Cookie: tasty_cookie=strawberry

[page content]


Note:
Find out how to use the Set-Cookie header in various server-side languages/frameworks: PHP, Node.js, Python, Ruby on Rails.

When a new request is made, the browser usually sends previously stored cookies for the current domain back to the server within a Cookie HTTP header:
httpGET /sample_page.html HTTP/2.0
Host: www.example.org
Cookie: yummy_cookie=chocolate; tasty_cookie=strawberry
Removal: defining the lifetime of a cookieYou can specify an expiration date or time period after which the cookie should be deleted and no longer sent. Depending on the attributes set within the Set-Cookie header when the cookies are created, they can be either permanent or session cookies:


Permanent cookies are deleted after the date specified in the Expires attribute:
httpSet-Cookie: id=a3fWa; Expires=Thu, 31 Oct 2021 07:28:00 GMT;

or after the period specified in the Max-Age attribute:
httpSet-Cookie: id=a3fWa; Max-Age=2592000


Note: Expires has been available for longer than Max-Age, however Max-Age is less error-prone, and takes precedence when both are set. The rationale behind this is that when you set an Expires date and time, they're relative to the client the cookie is being set on. If the server is set to a different time, this could cause errors.



Session cookies — cookies without a Max-Age or Expires attribute – are deleted when the current session ends. The browser defines when the "current session" ends, and some browsers use session restoring when restarting. This can cause session cookies to last indefinitely.

Note:
If your site authenticates users, it should regenerate and resend session cookies, even ones that already exist, whenever a user authenticates. This approach helps prevent session fixation attacks, where a third-party can reuse a user's session.



There are some techniques designed to recreate cookies after they're deleted. These are known as "zombie" cookies. These techniques violate the principles of user privacy and control, may violate data privacy regulations, and could expose a website using them to legal liability.Updating cookie valuesTo update a cookie via HTTP, the server can send a Set-Cookie header with the existing cookie's name and a new value. For example:
httpSet-Cookie: id=new-value

There are several reasons why you might want to do this, for example if a user has updated their preferences and the application wants to reflect the changes in client-side data (you could also do this with a client-side storage mechanism such as Web Storage).
Updating cookies via JavaScript
In the browser, you can create new cookies via JavaScript using the Document.cookie property, or the asynchronous Cookie Store API. Note that all examples below use Document.cookie, as it is the most widely supported/established option.
jsdocument.cookie = "yummy_cookie=chocolate";
document.cookie = "tasty_cookie=strawberry";

You can also access existing cookies and set new values for them, provided the HttpOnly attribute isn't set on them (i.e., in the Set-Cookie header that created it):
jsconsole.log(document.cookie);
// logs "yummy_cookie=chocolate; tasty_cookie=strawberry"

document.cookie = "yummy_cookie=blueberry";

console.log(document.cookie);
// logs "tasty_cookie=strawberry; yummy_cookie=blueberry"

Note that, for security purposes, you can't change cookie values by sending an updated Cookie header directly when initiating a request, i.e., via fetch() or XMLHttpRequest. Note that there are also good reasons why you shouldn't allow JavaScript to modify cookies — i.e., set HttpOnly during creation. See the Security section for more details.SecurityWhen you store information in cookies, by default all cookie values are visible to, and can be changed by, the end user. You really don't want your cookies to be misused — for example accessed/modified by bad actors, or sent to domains where they shouldn't be sent. The potential consequences can range from annoying — apps not working or exhibiting strange behavior — to catastrophic. A criminal could for example steal a session ID and use it to set a cookie that makes it look like they are logged in as someone else, taking control of their bank or e-commerce account in the process.
You can secure your cookies in a variety of ways, which are reviewed in this section.Block access to your cookiesYou can ensure that cookies are sent securely and aren't accessed by unintended parties or scripts in one of two ways: with the Secure attribute and the HttpOnly attribute:
httpSet-Cookie: id=a3fWa; Expires=Thu, 21 Oct 2021 07:28:00 GMT; Secure; HttpOnly



A cookie with the Secure attribute is only sent to the server with an encrypted request over the HTTPS protocol. It's never sent with unsecured HTTP (except on localhost), which means man-in-the-middle attackers can't access it easily. Insecure sites (with http: in the URL) can't set cookies with the Secure attribute. However, don't assume that Secure prevents all access to sensitive information in cookies. For example, someone with access to the client's hard disk (or JavaScript if the HttpOnly attribute isn't set) can read and modify the information.


A cookie with the HttpOnly attribute can't be accessed by JavaScript, for example using Document.cookie; it can only be accessed when it reaches the server. Cookies that persist user sessions for example should have the HttpOnly attribute set — it would be really insecure to make them available to JavaScript. This precaution helps mitigate cross-site scripting (XSS) attacks.



Note:
Depending on the application, you may want to use an opaque identifier that the server looks up rather than storing sensitive information directly in cookies, or investigate alternative authentication/confidentiality mechanisms such as JSON Web Tokens.
Define where cookies are sentThe Domain and Path attributes define the scope of a cookie: what URLs the cookies are sent to.


The Domain attribute specifies which server can receive a cookie. If specified, cookies are available on the specified server and its subdomains. For example, if you set Domain=mozilla.org from mozilla.org, cookies are available on that domain and subdomains like developer.mozilla.org.
httpSet-Cookie: id=a3fWa; Expires=Thu, 21 Oct 2021 07:28:00 GMT; Secure; HttpOnly; Domain=mozilla.org

If the Set-Cookie header does not specify a Domain attribute, the cookies are available on the server that sets it but not on its subdomains. Therefore, specifying Domain is less restrictive than omitting it.
Note that a server can only set the Domain attribute to its own domain or a parent domain, not to a subdomain or some other domain.
So, for example, a server with domain foo.example.com could set the attribute to example.com or foo.example.com, but not bar.foo.example.com or elsewhere.com (the cookies would still be sent to subdomains such as bar.foo.example.com though).
See Invalid domains for more details.


The Path attribute indicates a URL path that must exist in the requested URL in order to send the Cookie header. For example:
httpSet-Cookie: id=a3fWa; Expires=Thu, 21 Oct 2021 07:28:00 GMT; Secure; HttpOnly; Path=/docs

The %x2F ("/") character is considered a directory separator, and subdirectories match as well. For example, if you set Path=/docs, these request paths match:

/docs
/docs/
/docs/Web/
/docs/Web/HTTP

But these request paths don't:

/
/docsets
/fr/docs


Note:
The path attribute lets you control what cookies the browser sends based on the different parts of a site.
It is not intended as a security measure, and does not protect against unauthorized reading of the cookie from a different path.


Controlling third-party cookies with SameSiteThe SameSite attribute lets servers specify whether/when cookies are sent with cross-site requests — i.e., third-party cookies. Cross-site requests are requests where the site (the registrable domain) and/or the scheme (http or https) do not match the site the user is currently visiting. This includes requests sent when links are clicked on other sites to navigate to your site, and any request sent by embedded third-party content.
SameSite helps to prevent leakage of information, preserving user privacy and providing some protection against cross-site request forgery attacks. It takes three possible values: Strict, Lax, and None:


Strict causes the browser to only send the cookie in response to requests originating from the cookie's origin site. This should be used when you have cookies relating to functionality that will always be behind an initial navigation, such as authentication or storing shopping cart information.
httpSet-Cookie: cart=110045_77895_53420; SameSite=Strict


Note:
Cookies that are used for sensitive information should also have a short lifetime.



Lax is similar, except the browser also sends the cookie when the user navigates to the cookie's origin site (even if the user is coming from a different site). This is useful for cookies affecting the display of a site — for example you might have partner product information along with an affiliate link on your website. When that link is followed to the partner website, they might want to set a cookie stating that the affiliate link was followed, which displays a reward banner and provides a discount if the product is purchased.
httpSet-Cookie: affiliate=e4rt45dw; SameSite=Lax



None specifies that cookies are sent on both originating and cross-site requests. This is useful if you want to send cookies along with requests made from third-party content embedded in other sites, for example, ad-tech or analytics providers. Note that if SameSite=None is set then the Secure attribute must also be set — SameSite=None requires a secure context.
httpSet-Cookie: widget_session=7yjgj57e4n3d; SameSite=None; Secure; HttpOnly



If no SameSite attribute is set, the cookie is treated as Lax by default.Cookie prefixesBecause of the design of the cookie mechanism, a server can't confirm that a cookie was set from a secure origin or even tell where a cookie was originally set.
A vulnerable application on a subdomain can set a cookie with the Domain attribute, which gives access to that cookie on all other subdomains. This mechanism can be abused in a session fixation attack. See session fixation for primary mitigation methods.
As a defense-in-depth measure, however, you can use cookie prefixes to assert specific facts about the cookie. Two prefixes are available:

__Host-: If a cookie name has this prefix, it's accepted in a Set-Cookie header only if it's also marked with the Secure attribute, was sent from a secure origin, does not include a Domain attribute, and has the Path attribute set to /. In other words, the cookie is domain-locked.
__Secure-: If a cookie name has this prefix, it's accepted in a Set-Cookie header only if it's marked with the Secure attribute and was sent from a secure origin. This is weaker than the __Host- prefix.

The browser will reject cookies with these prefixes that don't comply with their restrictions. This ensures that subdomain-created cookies with prefixes are either confined to a subdomain or ignored completely. As the application server only checks for a specific cookie name when determining if the user is authenticated or a CSRF token is correct, this effectively acts as a defense measure against session fixation.

Note:
On the server, the web application must check for the full cookie name including the prefix. User agents do not strip the prefix from the cookie before sending it in a request's Cookie header.

For more information about cookie prefixes and the current state of browser support, see the Prefixes section of the Set-Cookie reference article.Privacy and trackingEarlier on we talked about how the SameSite attribute can be used to control when third-party cookies are sent, and that this can help preserve user privacy. Privacy is a very important consideration when building websites which, when done right, can build trust with your users. If done badly, it can completely erode that trust and cause all kinds of other problems.
Third-party cookies can be set by third-party content embedded in sites via <iframe>s. They have many legitimate uses include sharing user profile information, counting ad impressions, or collecting analytics across different related domains.
However, third-party cookies can also be used to create creepy, invasive user experiences. A third-party server can create a profile of a user's browsing history and habits based on cookies sent to it by the same browser when accessing multiple sites. The classic example is when you search for product information on one site and are then chased around the web by adverts for similar products wherever you go.
Browser vendors know that users don't like this behavior, and as a result have all started to block third-party cookies by default, or at least made plans to go in that direction. Third-party cookies (or just tracking cookies) may also be blocked by other browser settings or extensions.

Note:
Cookie blocking can cause some third-party components (such as social media widgets) not to function as intended. As browsers impose further restrictions on third-party cookies, developers should start to look at ways to reduce their reliance on them.

See our Third-party cookies article for detailed information on third-party cookies, the issues associated with them, and what alternatives are available. See our Privacy landing page for more information on privacy in general.Cookie-related regulationsLegislation or regulations that cover the use of cookies include:

The General Data Privacy Regulation (GDPR) in the European Union
The ePrivacy Directive in the EU
The California Consumer Privacy Act

These regulations have global reach. They apply to any site on the World Wide Web that users from these jurisdictions access (the EU and California, with the caveat that California's law applies only to entities with gross revenue over 25 million USD, among things).
These regulations include requirements such as:

Notifying users that your site uses cookies.
Allowing users to opt out of receiving some or all cookies.
Allowing users to use the bulk of your service without receiving cookies.

There may be other regulations that govern the use of cookies in your locality. The burden is on you to know and comply with these regulations. There are companies that offer "cookie banner" code that helps you comply with these regulations.

Note:
Companies should disclose the types of cookies they use on their sites for transparency purposes and to comply with regulations. For example, see Google's notice on the types of cookies it uses and Mozilla's Websites, Communications & Cookies Privacy Notice.
See also
Related HTTP headers: Set-Cookie, Cookie
Related JavaScript APIs: Document.cookie, Navigator.cookieEnabled, Cookie Store API
Third-party cookies
Cookie specification: RFC 6265
Cookies, the GDPR, and the ePrivacy Directive\n\nUsing HTTP cookiesA cookie (also known as a web cookie or browser cookie) is a small piece of data a server sends to a user's web browser. The browser may store cookies, create new cookies, modify existing ones, and send them back to the same server with later requests. Cookies enable web applications to store limited amounts of data and remember state information; by default the HTTP protocol is stateless.
In this article we will explore the main uses of cookies, explain best practices for using them, and look at their privacy and security implications.What cookies are used forTypically, the server will use the contents of HTTP cookies to determine whether different requests come from the same browser/user and then issue a personalized or generic response as appropriate. The following describes a basic user sign-in system:

The user sends sign-in credentials to the server, for example via a form submission.
If the credentials are correct, the server updates the UI to indicate that the user is signed in, and responds with a cookie containing a session ID that records their sign-in status on the browser.
At a later time, the user moves to a different page on the same site. The browser sends the cookie containing the session ID along with the corresponding request to indicate that it still thinks the user is signed in.
The server checks the session ID and, if it is still valid, sends the user a personalized version of the new page. If it is not valid, the session ID is deleted and the user is shown a generic version of the page (or perhaps shown an "access denied" message and asked to sign in again).


Cookies are mainly used for three purposes:

Session management: User sign-in status, shopping cart contents, game scores, or any other user session-related details that the server needs to remember.
Personalization: User preferences such as display language and UI theme.
Tracking: Recording and analyzing user behavior.
Data storageIn the early days of the web when there was no other option, cookies were used for general client-side data storage purposes. Modern storage APIs are now recommended, for example the Web Storage API (localStorage and sessionStorage) and IndexedDB.
They are designed with storage in mind, never send data to the server, and don't come with other drawbacks of using cookies for storage:

Browsers are generally limited to a maximum number of cookies per domain (varies by browser, generally in the hundreds), and a maximum size per cookie (usually 4KB). Storage APIs can store larger amounts of data.
Cookies are sent with every request, so they can worsen performance (for example on slow mobile data connections), especially if you have a lot of cookies set.


Note:
To see stored cookies (and other storage that a web page is using) you can use the Storage Inspector in Firefox Developer Tools, or the Application panel in Chrome Developer Tools.
Creating, removing, and updating cookiesAfter receiving an HTTP request, a server can send one or more Set-Cookie headers with the response, each one of which will set a separate cookie. A cookie is set by specifying a name-value pair like this:
httpSet-Cookie: <cookie-name>=<cookie-value>

The following HTTP response instructs the receiving browser to store a pair of cookies:
httpHTTP/2.0 200 OK
Content-Type: text/html
Set-Cookie: yummy_cookie=chocolate
Set-Cookie: tasty_cookie=strawberry

[page content]


Note:
Find out how to use the Set-Cookie header in various server-side languages/frameworks: PHP, Node.js, Python, Ruby on Rails.

When a new request is made, the browser usually sends previously stored cookies for the current domain back to the server within a Cookie HTTP header:
httpGET /sample_page.html HTTP/2.0
Host: www.example.org
Cookie: yummy_cookie=chocolate; tasty_cookie=strawberry
Removal: defining the lifetime of a cookieYou can specify an expiration date or time period after which the cookie should be deleted and no longer sent. Depending on the attributes set within the Set-Cookie header when the cookies are created, they can be either permanent or session cookies:


Permanent cookies are deleted after the date specified in the Expires attribute:
httpSet-Cookie: id=a3fWa; Expires=Thu, 31 Oct 2021 07:28:00 GMT;

or after the period specified in the Max-Age attribute:
httpSet-Cookie: id=a3fWa; Max-Age=2592000


Note: Expires has been available for longer than Max-Age, however Max-Age is less error-prone, and takes precedence when both are set. The rationale behind this is that when you set an Expires date and time, they're relative to the client the cookie is being set on. If the server is set to a different time, this could cause errors.



Session cookies — cookies without a Max-Age or Expires attribute – are deleted when the current session ends. The browser defines when the "current session" ends, and some browsers use session restoring when restarting. This can cause session cookies to last indefinitely.

Note:
If your site authenticates users, it should regenerate and resend session cookies, even ones that already exist, whenever a user authenticates. This approach helps prevent session fixation attacks, where a third-party can reuse a user's session.



There are some techniques designed to recreate cookies after they're deleted. These are known as "zombie" cookies. These techniques violate the principles of user privacy and control, may violate data privacy regulations, and could expose a website using them to legal liability.Updating cookie valuesTo update a cookie via HTTP, the server can send a Set-Cookie header with the existing cookie's name and a new value. For example:
httpSet-Cookie: id=new-value

There are several reasons why you might want to do this, for example if a user has updated their preferences and the application wants to reflect the changes in client-side data (you could also do this with a client-side storage mechanism such as Web Storage).
Updating cookies via JavaScript
In the browser, you can create new cookies via JavaScript using the Document.cookie property, or the asynchronous Cookie Store API. Note that all examples below use Document.cookie, as it is the most widely supported/established option.
jsdocument.cookie = "yummy_cookie=chocolate";
document.cookie = "tasty_cookie=strawberry";

You can also access existing cookies and set new values for them, provided the HttpOnly attribute isn't set on them (i.e., in the Set-Cookie header that created it):
jsconsole.log(document.cookie);
// logs "yummy_cookie=chocolate; tasty_cookie=strawberry"

document.cookie = "yummy_cookie=blueberry";

console.log(document.cookie);
// logs "tasty_cookie=strawberry; yummy_cookie=blueberry"

Note that, for security purposes, you can't change cookie values by sending an updated Cookie header directly when initiating a request, i.e., via fetch() or XMLHttpRequest. Note that there are also good reasons why you shouldn't allow JavaScript to modify cookies — i.e., set HttpOnly during creation. See the Security section for more details.SecurityWhen you store information in cookies, by default all cookie values are visible to, and can be changed by, the end user. You really don't want your cookies to be misused — for example accessed/modified by bad actors, or sent to domains where they shouldn't be sent. The potential consequences can range from annoying — apps not working or exhibiting strange behavior — to catastrophic. A criminal could for example steal a session ID and use it to set a cookie that makes it look like they are logged in as someone else, taking control of their bank or e-commerce account in the process.
You can secure your cookies in a variety of ways, which are reviewed in this section.Block access to your cookiesYou can ensure that cookies are sent securely and aren't accessed by unintended parties or scripts in one of two ways: with the Secure attribute and the HttpOnly attribute:
httpSet-Cookie: id=a3fWa; Expires=Thu, 21 Oct 2021 07:28:00 GMT; Secure; HttpOnly



A cookie with the Secure attribute is only sent to the server with an encrypted request over the HTTPS protocol. It's never sent with unsecured HTTP (except on localhost), which means man-in-the-middle attackers can't access it easily. Insecure sites (with http: in the URL) can't set cookies with the Secure attribute. However, don't assume that Secure prevents all access to sensitive information in cookies. For example, someone with access to the client's hard disk (or JavaScript if the HttpOnly attribute isn't set) can read and modify the information.


A cookie with the HttpOnly attribute can't be accessed by JavaScript, for example using Document.cookie; it can only be accessed when it reaches the server. Cookies that persist user sessions for example should have the HttpOnly attribute set — it would be really insecure to make them available to JavaScript. This precaution helps mitigate cross-site scripting (XSS) attacks.



Note:
Depending on the application, you may want to use an opaque identifier that the server looks up rather than storing sensitive information directly in cookies, or investigate alternative authentication/confidentiality mechanisms such as JSON Web Tokens.
Define where cookies are sentThe Domain and Path attributes define the scope of a cookie: what URLs the cookies are sent to.


The Domain attribute specifies which server can receive a cookie. If specified, cookies are available on the specified server and its subdomains. For example, if you set Domain=mozilla.org from mozilla.org, cookies are available on that domain and subdomains like developer.mozilla.org.
httpSet-Cookie: id=a3fWa; Expires=Thu, 21 Oct 2021 07:28:00 GMT; Secure; HttpOnly; Domain=mozilla.org

If the Set-Cookie header does not specify a Domain attribute, the cookies are available on the server that sets it but not on its subdomains. Therefore, specifying Domain is less restrictive than omitting it.
Note that a server can only set the Domain attribute to its own domain or a parent domain, not to a subdomain or some other domain.
So, for example, a server with domain foo.example.com could set the attribute to example.com or foo.example.com, but not bar.foo.example.com or elsewhere.com (the cookies would still be sent to subdomains such as bar.foo.example.com though).
See Invalid domains for more details.


The Path attribute indicates a URL path that must exist in the requested URL in order to send the Cookie header. For example:
httpSet-Cookie: id=a3fWa; Expires=Thu, 21 Oct 2021 07:28:00 GMT; Secure; HttpOnly; Path=/docs

The %x2F ("/") character is considered a directory separator, and subdirectories match as well. For example, if you set Path=/docs, these request paths match:

/docs
/docs/
/docs/Web/
/docs/Web/HTTP

But these request paths don't:

/
/docsets
/fr/docs


Note:
The path attribute lets you control what cookies the browser sends based on the different parts of a site.
It is not intended as a security measure, and does not protect against unauthorized reading of the cookie from a different path.


Controlling third-party cookies with SameSiteThe SameSite attribute lets servers specify whether/when cookies are sent with cross-site requests — i.e., third-party cookies. Cross-site requests are requests where the site (the registrable domain) and/or the scheme (http or https) do not match the site the user is currently visiting. This includes requests sent when links are clicked on other sites to navigate to your site, and any request sent by embedded third-party content.
SameSite helps to prevent leakage of information, preserving user privacy and providing some protection against cross-site request forgery attacks. It takes three possible values: Strict, Lax, and None:


Strict causes the browser to only send the cookie in response to requests originating from the cookie's origin site. This should be used when you have cookies relating to functionality that will always be behind an initial navigation, such as authentication or storing shopping cart information.
httpSet-Cookie: cart=110045_77895_53420; SameSite=Strict


Note:
Cookies that are used for sensitive information should also have a short lifetime.



Lax is similar, except the browser also sends the cookie when the user navigates to the cookie's origin site (even if the user is coming from a different site). This is useful for cookies affecting the display of a site — for example you might have partner product information along with an affiliate link on your website. When that link is followed to the partner website, they might want to set a cookie stating that the affiliate link was followed, which displays a reward banner and provides a discount if the product is purchased.
httpSet-Cookie: affiliate=e4rt45dw; SameSite=Lax



None specifies that cookies are sent on both originating and cross-site requests. This is useful if you want to send cookies along with requests made from third-party content embedded in other sites, for example, ad-tech or analytics providers. Note that if SameSite=None is set then the Secure attribute must also be set — SameSite=None requires a secure context.
httpSet-Cookie: widget_session=7yjgj57e4n3d; SameSite=None; Secure; HttpOnly



If no SameSite attribute is set, the cookie is treated as Lax by default.Cookie prefixesBecause of the design of the cookie mechanism, a server can't confirm that a cookie was set from a secure origin or even tell where a cookie was originally set.
A vulnerable application on a subdomain can set a cookie with the Domain attribute, which gives access to that cookie on all other subdomains. This mechanism can be abused in a session fixation attack. See session fixation for primary mitigation methods.
As a defense-in-depth measure, however, you can use cookie prefixes to assert specific facts about the cookie. Two prefixes are available:

__Host-: If a cookie name has this prefix, it's accepted in a Set-Cookie header only if it's also marked with the Secure attribute, was sent from a secure origin, does not include a Domain attribute, and has the Path attribute set to /. In other words, the cookie is domain-locked.
__Secure-: If a cookie name has this prefix, it's accepted in a Set-Cookie header only if it's marked with the Secure attribute and was sent from a secure origin. This is weaker than the __Host- prefix.

The browser will reject cookies with these prefixes that don't comply with their restrictions. This ensures that subdomain-created cookies with prefixes are either confined to a subdomain or ignored completely. As the application server only checks for a specific cookie name when determining if the user is authenticated or a CSRF token is correct, this effectively acts as a defense measure against session fixation.

Note:
On the server, the web application must check for the full cookie name including the prefix. User agents do not strip the prefix from the cookie before sending it in a request's Cookie header.

For more information about cookie prefixes and the current state of browser support, see the Prefixes section of the Set-Cookie reference article.Privacy and trackingEarlier on we talked about how the SameSite attribute can be used to control when third-party cookies are sent, and that this can help preserve user privacy. Privacy is a very important consideration when building websites which, when done right, can build trust with your users. If done badly, it can completely erode that trust and cause all kinds of other problems.
Third-party cookies can be set by third-party content embedded in sites via <iframe>s. They have many legitimate uses include sharing user profile information, counting ad impressions, or collecting analytics across different related domains.
However, third-party cookies can also be used to create creepy, invasive user experiences. A third-party server can create a profile of a user's browsing history and habits based on cookies sent to it by the same browser when accessing multiple sites. The classic example is when you search for product information on one site and are then chased around the web by adverts for similar products wherever you go.
Browser vendors know that users don't like this behavior, and as a result have all started to block third-party cookies by default, or at least made plans to go in that direction. Third-party cookies (or just tracking cookies) may also be blocked by other browser settings or extensions.

Note:
Cookie blocking can cause some third-party components (such as social media widgets) not to function as intended. As browsers impose further restrictions on third-party cookies, developers should start to look at ways to reduce their reliance on them.

See our Third-party cookies article for detailed information on third-party cookies, the issues associated with them, and what alternatives are available. See our Privacy landing page for more information on privacy in general.Cookie-related regulationsLegislation or regulations that cover the use of cookies include:

The General Data Privacy Regulation (GDPR) in the European Union
The ePrivacy Directive in the EU
The California Consumer Privacy Act

These regulations have global reach. They apply to any site on the World Wide Web that users from these jurisdictions access (the EU and California, with the caveat that California's law applies only to entities with gross revenue over 25 million USD, among things).
These regulations include requirements such as:

Notifying users that your site uses cookies.
Allowing users to opt out of receiving some or all cookies.
Allowing users to use the bulk of your service without receiving cookies.

There may be other regulations that govern the use of cookies in your locality. The burden is on you to know and comply with these regulations. There are companies that offer "cookie banner" code that helps you comply with these regulations.

Note:
Companies should disclose the types of cookies they use on their sites for transparency purposes and to comply with regulations. For example, see Google's notice on the types of cookies it uses and Mozilla's Websites, Communications & Cookies Privacy Notice.
See also
Related HTTP headers: Set-Cookie, Cookie
Related JavaScript APIs: Document.cookie, Navigator.cookieEnabled, Cookie Store API
Third-party cookies
Cookie specification: RFC 6265
Cookies, the GDPR, and the ePrivacy Directive
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Apr 8, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nUsing HTTP cookiesA cookie (also known as a web cookie or browser cookie) is a small piece of data a server sends to a user's web browser. The browser may store cookies, create new cookies, modify existing ones, and send them back to the same server with later requests. Cookies enable web applications to store limited amounts of data and remember state information; by default the HTTP protocol is stateless.
In this article we will explore the main uses of cookies, explain best practices for using them, and look at their privacy and security implications.What cookies are used forTypically, the server will use the contents of HTTP cookies to determine whether different requests come from the same browser/user and then issue a personalized or generic response as appropriate. The following describes a basic user sign-in system:

The user sends sign-in credentials to the server, for example via a form submission.
If the credentials are correct, the server updates the UI to indicate that the user is signed in, and responds with a cookie containing a session ID that records their sign-in status on the browser.
At a later time, the user moves to a different page on the same site. The browser sends the cookie containing the session ID along with the corresponding request to indicate that it still thinks the user is signed in.
The server checks the session ID and, if it is still valid, sends the user a personalized version of the new page. If it is not valid, the session ID is deleted and the user is shown a generic version of the page (or perhaps shown an "access denied" message and asked to sign in again).


Cookies are mainly used for three purposes:

Session management: User sign-in status, shopping cart contents, game scores, or any other user session-related details that the server needs to remember.
Personalization: User preferences such as display language and UI theme.
Tracking: Recording and analyzing user behavior.
Data storageIn the early days of the web when there was no other option, cookies were used for general client-side data storage purposes. Modern storage APIs are now recommended, for example the Web Storage API (localStorage and sessionStorage) and IndexedDB.
They are designed with storage in mind, never send data to the server, and don't come with other drawbacks of using cookies for storage:

Browsers are generally limited to a maximum number of cookies per domain (varies by browser, generally in the hundreds), and a maximum size per cookie (usually 4KB). Storage APIs can store larger amounts of data.
Cookies are sent with every request, so they can worsen performance (for example on slow mobile data connections), especially if you have a lot of cookies set.


Note:
To see stored cookies (and other storage that a web page is using) you can use the Storage Inspector in Firefox Developer Tools, or the Application panel in Chrome Developer Tools.
Creating, removing, and updating cookiesAfter receiving an HTTP request, a server can send one or more Set-Cookie headers with the response, each one of which will set a separate cookie. A cookie is set by specifying a name-value pair like this:
httpSet-Cookie: <cookie-name>=<cookie-value>

The following HTTP response instructs the receiving browser to store a pair of cookies:
httpHTTP/2.0 200 OK
Content-Type: text/html
Set-Cookie: yummy_cookie=chocolate
Set-Cookie: tasty_cookie=strawberry

[page content]


Note:
Find out how to use the Set-Cookie header in various server-side languages/frameworks: PHP, Node.js, Python, Ruby on Rails.

When a new request is made, the browser usually sends previously stored cookies for the current domain back to the server within a Cookie HTTP header:
httpGET /sample_page.html HTTP/2.0
Host: www.example.org
Cookie: yummy_cookie=chocolate; tasty_cookie=strawberry
Removal: defining the lifetime of a cookieYou can specify an expiration date or time period after which the cookie should be deleted and no longer sent. Depending on the attributes set within the Set-Cookie header when the cookies are created, they can be either permanent or session cookies:


Permanent cookies are deleted after the date specified in the Expires attribute:
httpSet-Cookie: id=a3fWa; Expires=Thu, 31 Oct 2021 07:28:00 GMT;

or after the period specified in the Max-Age attribute:
httpSet-Cookie: id=a3fWa; Max-Age=2592000


Note: Expires has been available for longer than Max-Age, however Max-Age is less error-prone, and takes precedence when both are set. The rationale behind this is that when you set an Expires date and time, they're relative to the client the cookie is being set on. If the server is set to a different time, this could cause errors.



Session cookies — cookies without a Max-Age or Expires attribute – are deleted when the current session ends. The browser defines when the "current session" ends, and some browsers use session restoring when restarting. This can cause session cookies to last indefinitely.

Note:
If your site authenticates users, it should regenerate and resend session cookies, even ones that already exist, whenever a user authenticates. This approach helps prevent session fixation attacks, where a third-party can reuse a user's session.



There are some techniques designed to recreate cookies after they're deleted. These are known as "zombie" cookies. These techniques violate the principles of user privacy and control, may violate data privacy regulations, and could expose a website using them to legal liability.Updating cookie valuesTo update a cookie via HTTP, the server can send a Set-Cookie header with the existing cookie's name and a new value. For example:
httpSet-Cookie: id=new-value

There are several reasons why you might want to do this, for example if a user has updated their preferences and the application wants to reflect the changes in client-side data (you could also do this with a client-side storage mechanism such as Web Storage).
Updating cookies via JavaScript
In the browser, you can create new cookies via JavaScript using the Document.cookie property, or the asynchronous Cookie Store API. Note that all examples below use Document.cookie, as it is the most widely supported/established option.
jsdocument.cookie = "yummy_cookie=chocolate";
document.cookie = "tasty_cookie=strawberry";

You can also access existing cookies and set new values for them, provided the HttpOnly attribute isn't set on them (i.e., in the Set-Cookie header that created it):
jsconsole.log(document.cookie);
// logs "yummy_cookie=chocolate; tasty_cookie=strawberry"

document.cookie = "yummy_cookie=blueberry";

console.log(document.cookie);
// logs "tasty_cookie=strawberry; yummy_cookie=blueberry"

Note that, for security purposes, you can't change cookie values by sending an updated Cookie header directly when initiating a request, i.e., via fetch() or XMLHttpRequest. Note that there are also good reasons why you shouldn't allow JavaScript to modify cookies — i.e., set HttpOnly during creation. See the Security section for more details.SecurityWhen you store information in cookies, by default all cookie values are visible to, and can be changed by, the end user. You really don't want your cookies to be misused — for example accessed/modified by bad actors, or sent to domains where they shouldn't be sent. The potential consequences can range from annoying — apps not working or exhibiting strange behavior — to catastrophic. A criminal could for example steal a session ID and use it to set a cookie that makes it look like they are logged in as someone else, taking control of their bank or e-commerce account in the process.
You can secure your cookies in a variety of ways, which are reviewed in this section.Block access to your cookiesYou can ensure that cookies are sent securely and aren't accessed by unintended parties or scripts in one of two ways: with the Secure attribute and the HttpOnly attribute:
httpSet-Cookie: id=a3fWa; Expires=Thu, 21 Oct 2021 07:28:00 GMT; Secure; HttpOnly



A cookie with the Secure attribute is only sent to the server with an encrypted request over the HTTPS protocol. It's never sent with unsecured HTTP (except on localhost), which means man-in-the-middle attackers can't access it easily. Insecure sites (with http: in the URL) can't set cookies with the Secure attribute. However, don't assume that Secure prevents all access to sensitive information in cookies. For example, someone with access to the client's hard disk (or JavaScript if the HttpOnly attribute isn't set) can read and modify the information.


A cookie with the HttpOnly attribute can't be accessed by JavaScript, for example using Document.cookie; it can only be accessed when it reaches the server. Cookies that persist user sessions for example should have the HttpOnly attribute set — it would be really insecure to make them available to JavaScript. This precaution helps mitigate cross-site scripting (XSS) attacks.



Note:
Depending on the application, you may want to use an opaque identifier that the server looks up rather than storing sensitive information directly in cookies, or investigate alternative authentication/confidentiality mechanisms such as JSON Web Tokens.
Define where cookies are sentThe Domain and Path attributes define the scope of a cookie: what URLs the cookies are sent to.


The Domain attribute specifies which server can receive a cookie. If specified, cookies are available on the specified server and its subdomains. For example, if you set Domain=mozilla.org from mozilla.org, cookies are available on that domain and subdomains like developer.mozilla.org.
httpSet-Cookie: id=a3fWa; Expires=Thu, 21 Oct 2021 07:28:00 GMT; Secure; HttpOnly; Domain=mozilla.org

If the Set-Cookie header does not specify a Domain attribute, the cookies are available on the server that sets it but not on its subdomains. Therefore, specifying Domain is less restrictive than omitting it.
Note that a server can only set the Domain attribute to its own domain or a parent domain, not to a subdomain or some other domain.
So, for example, a server with domain foo.example.com could set the attribute to example.com or foo.example.com, but not bar.foo.example.com or elsewhere.com (the cookies would still be sent to subdomains such as bar.foo.example.com though).
See Invalid domains for more details.


The Path attribute indicates a URL path that must exist in the requested URL in order to send the Cookie header. For example:
httpSet-Cookie: id=a3fWa; Expires=Thu, 21 Oct 2021 07:28:00 GMT; Secure; HttpOnly; Path=/docs

The %x2F ("/") character is considered a directory separator, and subdirectories match as well. For example, if you set Path=/docs, these request paths match:

/docs
/docs/
/docs/Web/
/docs/Web/HTTP

But these request paths don't:

/
/docsets
/fr/docs


Note:
The path attribute lets you control what cookies the browser sends based on the different parts of a site.
It is not intended as a security measure, and does not protect against unauthorized reading of the cookie from a different path.


Controlling third-party cookies with SameSiteThe SameSite attribute lets servers specify whether/when cookies are sent with cross-site requests — i.e., third-party cookies. Cross-site requests are requests where the site (the registrable domain) and/or the scheme (http or https) do not match the site the user is currently visiting. This includes requests sent when links are clicked on other sites to navigate to your site, and any request sent by embedded third-party content.
SameSite helps to prevent leakage of information, preserving user privacy and providing some protection against cross-site request forgery attacks. It takes three possible values: Strict, Lax, and None:


Strict causes the browser to only send the cookie in response to requests originating from the cookie's origin site. This should be used when you have cookies relating to functionality that will always be behind an initial navigation, such as authentication or storing shopping cart information.
httpSet-Cookie: cart=110045_77895_53420; SameSite=Strict


Note:
Cookies that are used for sensitive information should also have a short lifetime.



Lax is similar, except the browser also sends the cookie when the user navigates to the cookie's origin site (even if the user is coming from a different site). This is useful for cookies affecting the display of a site — for example you might have partner product information along with an affiliate link on your website. When that link is followed to the partner website, they might want to set a cookie stating that the affiliate link was followed, which displays a reward banner and provides a discount if the product is purchased.
httpSet-Cookie: affiliate=e4rt45dw; SameSite=Lax



None specifies that cookies are sent on both originating and cross-site requests. This is useful if you want to send cookies along with requests made from third-party content embedded in other sites, for example, ad-tech or analytics providers. Note that if SameSite=None is set then the Secure attribute must also be set — SameSite=None requires a secure context.
httpSet-Cookie: widget_session=7yjgj57e4n3d; SameSite=None; Secure; HttpOnly



If no SameSite attribute is set, the cookie is treated as Lax by default.Cookie prefixesBecause of the design of the cookie mechanism, a server can't confirm that a cookie was set from a secure origin or even tell where a cookie was originally set.
A vulnerable application on a subdomain can set a cookie with the Domain attribute, which gives access to that cookie on all other subdomains. This mechanism can be abused in a session fixation attack. See session fixation for primary mitigation methods.
As a defense-in-depth measure, however, you can use cookie prefixes to assert specific facts about the cookie. Two prefixes are available:

__Host-: If a cookie name has this prefix, it's accepted in a Set-Cookie header only if it's also marked with the Secure attribute, was sent from a secure origin, does not include a Domain attribute, and has the Path attribute set to /. In other words, the cookie is domain-locked.
__Secure-: If a cookie name has this prefix, it's accepted in a Set-Cookie header only if it's marked with the Secure attribute and was sent from a secure origin. This is weaker than the __Host- prefix.

The browser will reject cookies with these prefixes that don't comply with their restrictions. This ensures that subdomain-created cookies with prefixes are either confined to a subdomain or ignored completely. As the application server only checks for a specific cookie name when determining if the user is authenticated or a CSRF token is correct, this effectively acts as a defense measure against session fixation.

Note:
On the server, the web application must check for the full cookie name including the prefix. User agents do not strip the prefix from the cookie before sending it in a request's Cookie header.

For more information about cookie prefixes and the current state of browser support, see the Prefixes section of the Set-Cookie reference article.Privacy and trackingEarlier on we talked about how the SameSite attribute can be used to control when third-party cookies are sent, and that this can help preserve user privacy. Privacy is a very important consideration when building websites which, when done right, can build trust with your users. If done badly, it can completely erode that trust and cause all kinds of other problems.
Third-party cookies can be set by third-party content embedded in sites via <iframe>s. They have many legitimate uses include sharing user profile information, counting ad impressions, or collecting analytics across different related domains.
However, third-party cookies can also be used to create creepy, invasive user experiences. A third-party server can create a profile of a user's browsing history and habits based on cookies sent to it by the same browser when accessing multiple sites. The classic example is when you search for product information on one site and are then chased around the web by adverts for similar products wherever you go.
Browser vendors know that users don't like this behavior, and as a result have all started to block third-party cookies by default, or at least made plans to go in that direction. Third-party cookies (or just tracking cookies) may also be blocked by other browser settings or extensions.

Note:
Cookie blocking can cause some third-party components (such as social media widgets) not to function as intended. As browsers impose further restrictions on third-party cookies, developers should start to look at ways to reduce their reliance on them.

See our Third-party cookies article for detailed information on third-party cookies, the issues associated with them, and what alternatives are available. See our Privacy landing page for more information on privacy in general.Cookie-related regulationsLegislation or regulations that cover the use of cookies include:

The General Data Privacy Regulation (GDPR) in the European Union
The ePrivacy Directive in the EU
The California Consumer Privacy Act

These regulations have global reach. They apply to any site on the World Wide Web that users from these jurisdictions access (the EU and California, with the caveat that California's law applies only to entities with gross revenue over 25 million USD, among things).
These regulations include requirements such as:

Notifying users that your site uses cookies.
Allowing users to opt out of receiving some or all cookies.
Allowing users to use the bulk of your service without receiving cookies.

There may be other regulations that govern the use of cookies in your locality. The burden is on you to know and comply with these regulations. There are companies that offer "cookie banner" code that helps you comply with these regulations.

Note:
Companies should disclose the types of cookies they use on their sites for transparency purposes and to comply with regulations. For example, see Google's notice on the types of cookies it uses and Mozilla's Websites, Communications & Cookies Privacy Notice.
See also
Related HTTP headers: Set-Cookie, Cookie
Related JavaScript APIs: Document.cookie, Navigator.cookieEnabled, Cookie Store API
Third-party cookies
Cookie specification: RFC 6265
Cookies, the GDPR, and the ePrivacy Directive
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Apr 8, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nRedirections in HTTPURL redirection, also known as URL forwarding, is a technique to give more than one URL address to a page, a form, a whole website, or a web application. HTTP has a special kind of response, called a HTTP redirect, for this operation.
Redirects accomplish numerous goals:

Temporary redirects during site maintenance or downtime
Permanent redirects to preserve existing links/bookmarks after changing the site's URLs, progress pages when uploading a file, etc.
PrincipleIn HTTP, redirection is triggered by a server sending a special redirect response to a request. Redirect responses have status codes that start with 3, and a Location header holding the URL to redirect to.
When browsers receive a redirect, they immediately load the new URL provided in the Location header. Besides the small performance hit of an additional round-trip, users rarely notice the redirection.


There are several types of redirects, sorted into three categories:

Permanent redirections
Temporary redirections
Special redirections
Permanent redirectionsThese redirections are meant to last forever. They imply that the original URL should no longer be used, and replaced with the new one. Search engine robots, RSS readers, and other crawlers will update the original URL for the resource.



Code
Text
Method handling
Typical use case




301
Moved Permanently
GET methods unchanged. Others may or may not be changed to GET. [1]
Reorganization of a website.


308
Permanent Redirect
Method and body not changed.
Reorganization of a website, with non-GET links/operations.



[1] The specification did not intend to allow method changes, but there are existing user agents that do change their method. 308 was created to remove the ambiguity of the behavior when using non-GET methods.Temporary redirectionsSometimes the requested resource can't be accessed from its canonical location, but it can be accessed from another place. In this case, a temporary redirect can be used.
Search engine robots and other crawlers don't memorize the new, temporary URL. Temporary redirections are also used when creating, updating, or deleting resources, to show temporary progress pages.



Code
Text
Method handling
Typical use case




302
Found
GET methods unchanged. Others may or may not be changed to GET. [2]
The Web page is temporarily unavailable for unforeseen reasons.


303
See Other
GET methods unchanged. Others changed to GET (body lost).
Used to redirect after a PUT or a POST, so that refreshing the result page doesn't re-trigger the operation.


307
Temporary Redirect
Method and body not changed
The Web page is temporarily unavailable for unforeseen reasons. Better than 302 when non-GET operations are available on the site.



[2] The specification did not intend to allow method changes, but there are existing user agents that do change their method. 307 was created to remove the ambiguity of the behavior when using non-GET methods.Special redirections304 (Not Modified) redirects a page to the locally cached copy (that was stale), and 300 (Multiple Choices) is a manual redirection: the body, presented by the browser as a Web page, lists the possible redirections and the user clicks on one to select it.



Code
Text
Typical use case




300
Multiple Choices
Not many: the choices are listed in an HTML page in the body. Machine-readable choices are encouraged to be sent as Link headers with rel=alternate.


304
Not Modified
Sent for revalidated conditional requests. Indicates that the cached response is still fresh and can be used.


Alternative way of specifying redirectionsHTTP redirects aren't the only way to define redirections. There are two others:

HTML redirections with the <meta> element
JavaScript redirections via the DOM
HTML redirectionsHTTP redirects are the best way to create redirections, but sometimes you don't have control over the server. In that case, try a <meta> element with its http-equiv attribute set to Refresh in the <head> of the page. When displaying the page, the browser will go to the indicated URL.
html<head>
  <meta http-equiv="Refresh" content="0; URL=https://example.com/" />
</head>

The content attribute should start with a number indicating how many seconds the browser should wait before redirecting to the given URL. Always set it to 0 for accessibility compliance.
Obviously, this method only works with HTML, and cannot be used for images or other types of content.JavaScript redirectionsRedirections in JavaScript are performed by setting a URL string to the window.location property, loading the new page:
jswindow.location = "https://example.com/";

Like HTML redirections, this can't work on all resources, and obviously, this will only work on clients that execute JavaScript. On the other hand, there are more possibilities: for example, you can trigger the redirect only if some conditions are met.Order of precedenceWith three ways to trigger redirections, several ways can be used at the same time. But which is applied first?

HTTP redirects always execute first — they exist when there is not even a transmitted page.
Somewhat surprisingly, JavaScript redirects execute next, before HTML redirects. This is because the <meta> redirect happens after the page is completely loaded, which is after all scripts have executed.
HTML redirects (<meta>) execute if there weren't any HTTP redirects or JavaScript redirects that were executed before the page was loaded.
If there is any JavaScript redirect that happens after the page is loaded (for example, on a button click), it will execute last if the page isn't already redirected by the previous methods.

When possible, use HTTP redirects and don't add <meta> element redirects. If someone changes the HTTP redirects but forgets to change the HTML redirects, the redirects will no longer be identical, which could cause an infinite loop or other nightmares.Use casesThere are numerous use cases for redirects, but as performance is impacted with every redirect, their use should be kept to a minimum.Domain aliasingIdeally, there is one location, and therefore one URL, for each resource. But there are reasons for alternative names for a resource:

Expanding the reach of your site

A common case is when a site resides at www.example.com, but accessing it from example.com should also work. Redirections for example.com to www.example.com are thus set up. You might also redirect from common synonyms or frequent typos of your domains.

Moving to a new domain

For example, your company was renamed, but you want existing links or bookmarks to still find you under the new name.

Forcing HTTPS

Requests to the http:// version of your site will redirect to the https:// version of your site.

Keeping links aliveWhen you restructure websites, URLs change. Even if you update your site's links to match the new URLs, you have no control over the URLs used by external resources.
You don't want to break these links, as they bring valuable users and help your SEO, so you set up redirects from the old URLs to the new ones.

Note:
This technique does work for internal links, but try to avoid having internal redirects. A redirect has a significant performance cost (as an extra HTTP request occurs). If you can avoid it by correcting internal links, you should fix those links instead.
Temporary responses to unsafe requestsUnsafe requests modify the state of the server and the user shouldn't resend them unintentionally.
Typically, you don't want your users to resend PUT, POST or DELETE requests. If you serve the response as the result of this request, a press of the reload button will resend the request (possibly after a confirmation message).
In this case, the server can send back a 303 (See Other) response for a URL that will contain the right information. If the reload button is pressed, only that page is redisplayed, without replaying the unsafe requests.Temporary responses to long requestsSome requests may need more time on the server, like DELETE requests that are scheduled for later processing. In this case, the response is a 303 (See Other) redirect that links to a page indicating that the action has been scheduled, and eventually informs about its progress, or allows to cancel it.Configuring redirects in common serversApacheRedirects can be set either in the server config file or in the .htaccess of each directory.
The mod_alias module has Redirect and RedirectMatch directives that set up 302 redirects by default:
apacheconf<VirtualHost *:443>
  ServerName example.com
  Redirect / https://www.example.com
</VirtualHost>

The URL https://example.com/ will be redirected to https://www.example.com/, as will any files or directories under it (https://example.com/some-page will be redirected to https://www.example.com/some-page)
RedirectMatch does the same, but takes a regular expression to define a collection of affected URLs:
apacheconfRedirectMatch ^/images/(.*)$ https://images.example.com/$1

All documents in the images/ directory will redirect to a different domain.
If you don't want a temporary redirect, an extra parameter (either the HTTP status code to use or the permanent keyword) can be used to set up a different redirect:
apacheconfRedirect permanent / https://www.example.com
# …acts the same as:
Redirect 301 / https://www.example.com

The mod_rewrite module can also create redirects. It is more flexible, but a bit more complex.NginxIn Nginx, you create a specific server block for the content you want to redirect:
nginxserver {
  listen 80;
  server_name example.com;
  return 301 $scheme://www.example.com$request_uri;
}

To apply a redirect to a directory or only certain pages, use the rewrite directive:
nginxrewrite ^/images/(.*)$ https://images.example.com/$1 redirect;
rewrite ^/images/(.*)$ https://images.example.com/$1 permanent;
IISIn IIS, you use the <httpRedirect> element to configure redirections.Redirection loopsRedirection loops happen when additional redirections follow the one that has already been followed. In other words, there is a loop that will never be finished and no page will ever be found.
Most of the time this is a server problem, and if the server can detect it, it will send back a 500 Internal Server Error. If you encounter such an error soon after modifying a server configuration, this is likely a redirection loop.
Sometimes, the server won't detect it: a redirection loop can spread over several servers which each don't have the full picture. In this case, browsers will detect it and display an error message. Firefox displays:

Firefox has detected that the server is redirecting the request for this address in a way that will never terminate.

…while Chrome displays:

This Webpage has a redirect loop

In both cases, the user can't do much (unless corruption is happening on their side, like a mismatch of cache or cookies).
It is important to avoid redirection loops, as they completely break the user experience.See also
3XX redirection response statuses
Location header
window.location property for redirection using JavaScript\n\nRedirections in HTTPURL redirection, also known as URL forwarding, is a technique to give more than one URL address to a page, a form, a whole website, or a web application. HTTP has a special kind of response, called a HTTP redirect, for this operation.
Redirects accomplish numerous goals:

Temporary redirects during site maintenance or downtime
Permanent redirects to preserve existing links/bookmarks after changing the site's URLs, progress pages when uploading a file, etc.
PrincipleIn HTTP, redirection is triggered by a server sending a special redirect response to a request. Redirect responses have status codes that start with 3, and a Location header holding the URL to redirect to.
When browsers receive a redirect, they immediately load the new URL provided in the Location header. Besides the small performance hit of an additional round-trip, users rarely notice the redirection.


There are several types of redirects, sorted into three categories:

Permanent redirections
Temporary redirections
Special redirections
Permanent redirectionsThese redirections are meant to last forever. They imply that the original URL should no longer be used, and replaced with the new one. Search engine robots, RSS readers, and other crawlers will update the original URL for the resource.



Code
Text
Method handling
Typical use case




301
Moved Permanently
GET methods unchanged. Others may or may not be changed to GET. [1]
Reorganization of a website.


308
Permanent Redirect
Method and body not changed.
Reorganization of a website, with non-GET links/operations.



[1] The specification did not intend to allow method changes, but there are existing user agents that do change their method. 308 was created to remove the ambiguity of the behavior when using non-GET methods.Temporary redirectionsSometimes the requested resource can't be accessed from its canonical location, but it can be accessed from another place. In this case, a temporary redirect can be used.
Search engine robots and other crawlers don't memorize the new, temporary URL. Temporary redirections are also used when creating, updating, or deleting resources, to show temporary progress pages.



Code
Text
Method handling
Typical use case




302
Found
GET methods unchanged. Others may or may not be changed to GET. [2]
The Web page is temporarily unavailable for unforeseen reasons.


303
See Other
GET methods unchanged. Others changed to GET (body lost).
Used to redirect after a PUT or a POST, so that refreshing the result page doesn't re-trigger the operation.


307
Temporary Redirect
Method and body not changed
The Web page is temporarily unavailable for unforeseen reasons. Better than 302 when non-GET operations are available on the site.



[2] The specification did not intend to allow method changes, but there are existing user agents that do change their method. 307 was created to remove the ambiguity of the behavior when using non-GET methods.Special redirections304 (Not Modified) redirects a page to the locally cached copy (that was stale), and 300 (Multiple Choices) is a manual redirection: the body, presented by the browser as a Web page, lists the possible redirections and the user clicks on one to select it.



Code
Text
Typical use case




300
Multiple Choices
Not many: the choices are listed in an HTML page in the body. Machine-readable choices are encouraged to be sent as Link headers with rel=alternate.


304
Not Modified
Sent for revalidated conditional requests. Indicates that the cached response is still fresh and can be used.


Alternative way of specifying redirectionsHTTP redirects aren't the only way to define redirections. There are two others:

HTML redirections with the <meta> element
JavaScript redirections via the DOM
HTML redirectionsHTTP redirects are the best way to create redirections, but sometimes you don't have control over the server. In that case, try a <meta> element with its http-equiv attribute set to Refresh in the <head> of the page. When displaying the page, the browser will go to the indicated URL.
html<head>
  <meta http-equiv="Refresh" content="0; URL=https://example.com/" />
</head>

The content attribute should start with a number indicating how many seconds the browser should wait before redirecting to the given URL. Always set it to 0 for accessibility compliance.
Obviously, this method only works with HTML, and cannot be used for images or other types of content.JavaScript redirectionsRedirections in JavaScript are performed by setting a URL string to the window.location property, loading the new page:
jswindow.location = "https://example.com/";

Like HTML redirections, this can't work on all resources, and obviously, this will only work on clients that execute JavaScript. On the other hand, there are more possibilities: for example, you can trigger the redirect only if some conditions are met.Order of precedenceWith three ways to trigger redirections, several ways can be used at the same time. But which is applied first?

HTTP redirects always execute first — they exist when there is not even a transmitted page.
Somewhat surprisingly, JavaScript redirects execute next, before HTML redirects. This is because the <meta> redirect happens after the page is completely loaded, which is after all scripts have executed.
HTML redirects (<meta>) execute if there weren't any HTTP redirects or JavaScript redirects that were executed before the page was loaded.
If there is any JavaScript redirect that happens after the page is loaded (for example, on a button click), it will execute last if the page isn't already redirected by the previous methods.

When possible, use HTTP redirects and don't add <meta> element redirects. If someone changes the HTTP redirects but forgets to change the HTML redirects, the redirects will no longer be identical, which could cause an infinite loop or other nightmares.Use casesThere are numerous use cases for redirects, but as performance is impacted with every redirect, their use should be kept to a minimum.Domain aliasingIdeally, there is one location, and therefore one URL, for each resource. But there are reasons for alternative names for a resource:

Expanding the reach of your site

A common case is when a site resides at www.example.com, but accessing it from example.com should also work. Redirections for example.com to www.example.com are thus set up. You might also redirect from common synonyms or frequent typos of your domains.

Moving to a new domain

For example, your company was renamed, but you want existing links or bookmarks to still find you under the new name.

Forcing HTTPS

Requests to the http:// version of your site will redirect to the https:// version of your site.

Keeping links aliveWhen you restructure websites, URLs change. Even if you update your site's links to match the new URLs, you have no control over the URLs used by external resources.
You don't want to break these links, as they bring valuable users and help your SEO, so you set up redirects from the old URLs to the new ones.

Note:
This technique does work for internal links, but try to avoid having internal redirects. A redirect has a significant performance cost (as an extra HTTP request occurs). If you can avoid it by correcting internal links, you should fix those links instead.
Temporary responses to unsafe requestsUnsafe requests modify the state of the server and the user shouldn't resend them unintentionally.
Typically, you don't want your users to resend PUT, POST or DELETE requests. If you serve the response as the result of this request, a press of the reload button will resend the request (possibly after a confirmation message).
In this case, the server can send back a 303 (See Other) response for a URL that will contain the right information. If the reload button is pressed, only that page is redisplayed, without replaying the unsafe requests.Temporary responses to long requestsSome requests may need more time on the server, like DELETE requests that are scheduled for later processing. In this case, the response is a 303 (See Other) redirect that links to a page indicating that the action has been scheduled, and eventually informs about its progress, or allows to cancel it.Configuring redirects in common serversApacheRedirects can be set either in the server config file or in the .htaccess of each directory.
The mod_alias module has Redirect and RedirectMatch directives that set up 302 redirects by default:
apacheconf<VirtualHost *:443>
  ServerName example.com
  Redirect / https://www.example.com
</VirtualHost>

The URL https://example.com/ will be redirected to https://www.example.com/, as will any files or directories under it (https://example.com/some-page will be redirected to https://www.example.com/some-page)
RedirectMatch does the same, but takes a regular expression to define a collection of affected URLs:
apacheconfRedirectMatch ^/images/(.*)$ https://images.example.com/$1

All documents in the images/ directory will redirect to a different domain.
If you don't want a temporary redirect, an extra parameter (either the HTTP status code to use or the permanent keyword) can be used to set up a different redirect:
apacheconfRedirect permanent / https://www.example.com
# …acts the same as:
Redirect 301 / https://www.example.com

The mod_rewrite module can also create redirects. It is more flexible, but a bit more complex.NginxIn Nginx, you create a specific server block for the content you want to redirect:
nginxserver {
  listen 80;
  server_name example.com;
  return 301 $scheme://www.example.com$request_uri;
}

To apply a redirect to a directory or only certain pages, use the rewrite directive:
nginxrewrite ^/images/(.*)$ https://images.example.com/$1 redirect;
rewrite ^/images/(.*)$ https://images.example.com/$1 permanent;
IISIn IIS, you use the <httpRedirect> element to configure redirections.Redirection loopsRedirection loops happen when additional redirections follow the one that has already been followed. In other words, there is a loop that will never be finished and no page will ever be found.
Most of the time this is a server problem, and if the server can detect it, it will send back a 500 Internal Server Error. If you encounter such an error soon after modifying a server configuration, this is likely a redirection loop.
Sometimes, the server won't detect it: a redirection loop can spread over several servers which each don't have the full picture. In this case, browsers will detect it and display an error message. Firefox displays:

Firefox has detected that the server is redirecting the request for this address in a way that will never terminate.

…while Chrome displays:

This Webpage has a redirect loop

In both cases, the user can't do much (unless corruption is happening on their side, like a mismatch of cache or cookies).
It is important to avoid redirection loops, as they completely break the user experience.See also
3XX redirection response statuses
Location header
window.location property for redirection using JavaScript
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Apr 10, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nRedirections in HTTPURL redirection, also known as URL forwarding, is a technique to give more than one URL address to a page, a form, a whole website, or a web application. HTTP has a special kind of response, called a HTTP redirect, for this operation.
Redirects accomplish numerous goals:

Temporary redirects during site maintenance or downtime
Permanent redirects to preserve existing links/bookmarks after changing the site's URLs, progress pages when uploading a file, etc.
PrincipleIn HTTP, redirection is triggered by a server sending a special redirect response to a request. Redirect responses have status codes that start with 3, and a Location header holding the URL to redirect to.
When browsers receive a redirect, they immediately load the new URL provided in the Location header. Besides the small performance hit of an additional round-trip, users rarely notice the redirection.


There are several types of redirects, sorted into three categories:

Permanent redirections
Temporary redirections
Special redirections
Permanent redirectionsThese redirections are meant to last forever. They imply that the original URL should no longer be used, and replaced with the new one. Search engine robots, RSS readers, and other crawlers will update the original URL for the resource.



Code
Text
Method handling
Typical use case




301
Moved Permanently
GET methods unchanged. Others may or may not be changed to GET. [1]
Reorganization of a website.


308
Permanent Redirect
Method and body not changed.
Reorganization of a website, with non-GET links/operations.



[1] The specification did not intend to allow method changes, but there are existing user agents that do change their method. 308 was created to remove the ambiguity of the behavior when using non-GET methods.Temporary redirectionsSometimes the requested resource can't be accessed from its canonical location, but it can be accessed from another place. In this case, a temporary redirect can be used.
Search engine robots and other crawlers don't memorize the new, temporary URL. Temporary redirections are also used when creating, updating, or deleting resources, to show temporary progress pages.



Code
Text
Method handling
Typical use case




302
Found
GET methods unchanged. Others may or may not be changed to GET. [2]
The Web page is temporarily unavailable for unforeseen reasons.


303
See Other
GET methods unchanged. Others changed to GET (body lost).
Used to redirect after a PUT or a POST, so that refreshing the result page doesn't re-trigger the operation.


307
Temporary Redirect
Method and body not changed
The Web page is temporarily unavailable for unforeseen reasons. Better than 302 when non-GET operations are available on the site.



[2] The specification did not intend to allow method changes, but there are existing user agents that do change their method. 307 was created to remove the ambiguity of the behavior when using non-GET methods.Special redirections304 (Not Modified) redirects a page to the locally cached copy (that was stale), and 300 (Multiple Choices) is a manual redirection: the body, presented by the browser as a Web page, lists the possible redirections and the user clicks on one to select it.



Code
Text
Typical use case




300
Multiple Choices
Not many: the choices are listed in an HTML page in the body. Machine-readable choices are encouraged to be sent as Link headers with rel=alternate.


304
Not Modified
Sent for revalidated conditional requests. Indicates that the cached response is still fresh and can be used.


Alternative way of specifying redirectionsHTTP redirects aren't the only way to define redirections. There are two others:

HTML redirections with the <meta> element
JavaScript redirections via the DOM
HTML redirectionsHTTP redirects are the best way to create redirections, but sometimes you don't have control over the server. In that case, try a <meta> element with its http-equiv attribute set to Refresh in the <head> of the page. When displaying the page, the browser will go to the indicated URL.
html<head>
  <meta http-equiv="Refresh" content="0; URL=https://example.com/" />
</head>

The content attribute should start with a number indicating how many seconds the browser should wait before redirecting to the given URL. Always set it to 0 for accessibility compliance.
Obviously, this method only works with HTML, and cannot be used for images or other types of content.JavaScript redirectionsRedirections in JavaScript are performed by setting a URL string to the window.location property, loading the new page:
jswindow.location = "https://example.com/";

Like HTML redirections, this can't work on all resources, and obviously, this will only work on clients that execute JavaScript. On the other hand, there are more possibilities: for example, you can trigger the redirect only if some conditions are met.Order of precedenceWith three ways to trigger redirections, several ways can be used at the same time. But which is applied first?

HTTP redirects always execute first — they exist when there is not even a transmitted page.
Somewhat surprisingly, JavaScript redirects execute next, before HTML redirects. This is because the <meta> redirect happens after the page is completely loaded, which is after all scripts have executed.
HTML redirects (<meta>) execute if there weren't any HTTP redirects or JavaScript redirects that were executed before the page was loaded.
If there is any JavaScript redirect that happens after the page is loaded (for example, on a button click), it will execute last if the page isn't already redirected by the previous methods.

When possible, use HTTP redirects and don't add <meta> element redirects. If someone changes the HTTP redirects but forgets to change the HTML redirects, the redirects will no longer be identical, which could cause an infinite loop or other nightmares.Use casesThere are numerous use cases for redirects, but as performance is impacted with every redirect, their use should be kept to a minimum.Domain aliasingIdeally, there is one location, and therefore one URL, for each resource. But there are reasons for alternative names for a resource:

Expanding the reach of your site

A common case is when a site resides at www.example.com, but accessing it from example.com should also work. Redirections for example.com to www.example.com are thus set up. You might also redirect from common synonyms or frequent typos of your domains.

Moving to a new domain

For example, your company was renamed, but you want existing links or bookmarks to still find you under the new name.

Forcing HTTPS

Requests to the http:// version of your site will redirect to the https:// version of your site.

Keeping links aliveWhen you restructure websites, URLs change. Even if you update your site's links to match the new URLs, you have no control over the URLs used by external resources.
You don't want to break these links, as they bring valuable users and help your SEO, so you set up redirects from the old URLs to the new ones.

Note:
This technique does work for internal links, but try to avoid having internal redirects. A redirect has a significant performance cost (as an extra HTTP request occurs). If you can avoid it by correcting internal links, you should fix those links instead.
Temporary responses to unsafe requestsUnsafe requests modify the state of the server and the user shouldn't resend them unintentionally.
Typically, you don't want your users to resend PUT, POST or DELETE requests. If you serve the response as the result of this request, a press of the reload button will resend the request (possibly after a confirmation message).
In this case, the server can send back a 303 (See Other) response for a URL that will contain the right information. If the reload button is pressed, only that page is redisplayed, without replaying the unsafe requests.Temporary responses to long requestsSome requests may need more time on the server, like DELETE requests that are scheduled for later processing. In this case, the response is a 303 (See Other) redirect that links to a page indicating that the action has been scheduled, and eventually informs about its progress, or allows to cancel it.Configuring redirects in common serversApacheRedirects can be set either in the server config file or in the .htaccess of each directory.
The mod_alias module has Redirect and RedirectMatch directives that set up 302 redirects by default:
apacheconf<VirtualHost *:443>
  ServerName example.com
  Redirect / https://www.example.com
</VirtualHost>

The URL https://example.com/ will be redirected to https://www.example.com/, as will any files or directories under it (https://example.com/some-page will be redirected to https://www.example.com/some-page)
RedirectMatch does the same, but takes a regular expression to define a collection of affected URLs:
apacheconfRedirectMatch ^/images/(.*)$ https://images.example.com/$1

All documents in the images/ directory will redirect to a different domain.
If you don't want a temporary redirect, an extra parameter (either the HTTP status code to use or the permanent keyword) can be used to set up a different redirect:
apacheconfRedirect permanent / https://www.example.com
# …acts the same as:
Redirect 301 / https://www.example.com

The mod_rewrite module can also create redirects. It is more flexible, but a bit more complex.NginxIn Nginx, you create a specific server block for the content you want to redirect:
nginxserver {
  listen 80;
  server_name example.com;
  return 301 $scheme://www.example.com$request_uri;
}

To apply a redirect to a directory or only certain pages, use the rewrite directive:
nginxrewrite ^/images/(.*)$ https://images.example.com/$1 redirect;
rewrite ^/images/(.*)$ https://images.example.com/$1 permanent;
IISIn IIS, you use the <httpRedirect> element to configure redirections.Redirection loopsRedirection loops happen when additional redirections follow the one that has already been followed. In other words, there is a loop that will never be finished and no page will ever be found.
Most of the time this is a server problem, and if the server can detect it, it will send back a 500 Internal Server Error. If you encounter such an error soon after modifying a server configuration, this is likely a redirection loop.
Sometimes, the server won't detect it: a redirection loop can spread over several servers which each don't have the full picture. In this case, browsers will detect it and display an error message. Firefox displays:

Firefox has detected that the server is redirecting the request for this address in a way that will never terminate.

…while Chrome displays:

This Webpage has a redirect loop

In both cases, the user can't do much (unless corruption is happening on their side, like a mismatch of cache or cookies).
It is important to avoid redirection loops, as they completely break the user experience.See also
3XX redirection response statuses
Location header
window.location property for redirection using JavaScript
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Apr 10, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nHTTP conditional requestsHTTP has a concept of conditional requests, where the result, and even the success of a request, can be controlled by comparing the affected resources with a validator.
These requests are useful for validating cached content, ensuring that it is only fetched if it differs from the copy that is already available to the browser.
Conditional requests are also useful for ensuring the integrity of a document when resuming a download, or preventing lost updates when uploading or modifying a document on the server.PrinciplesHTTP conditional requests are requests that are executed differently, depending on the value of specific headers. These headers define a precondition, and the result of the request will be different if the precondition is matched or not.
The different behaviors are defined by the method of the request used, and by the set of headers used for a precondition:

for safe methods, like GET, which usually tries to fetch a document, the conditional request can be used to send back the document, if relevant only. Therefore, this spares bandwidth.
for unsafe methods, like PUT, which usually uploads a document, the conditional request can be used to upload the document, only if the original it is based on is the same as that stored on the server.
ValidatorsAll conditional headers try to check if the resource stored on the server matches a specific version. To achieve this, the conditional requests need to indicate the version of the resource. As comparing the whole resource byte to byte is impracticable, and not always what is wanted, the request transmits a value describing the version. Such values are called validators, and are of two kinds:

the date of last modification of the document, the last-modified date.
an opaque string, uniquely identifying each version, called the entity tag, or the ETag.

Comparing versions of the same resource is a bit tricky: depending on the context, there are two kinds of equality checks:

Strong validation is used when byte to byte identity is expected, for example when resuming a download.
Weak validation is used when the user-agent only needs to determine if two resources have the same content. The resources may be considered the same even if minor differences exist, such as different ads or a footer with a different date.

The kind of validation is independent of the validator used. Both Last-Modified and ETag allow both types of validation, though the complexity to implement it on the server side may vary. HTTP uses strong validation by default, and it specifies when weak validation can be used.Strong validationStrong validation consists of guaranteeing that the resource is, byte to byte, identical to the one it is compared to. This is mandatory for some conditional headers, and the default for the others. Strong validation is very strict and may be difficult to guarantee at the server level, but it does guarantee no data loss at any time, sometimes at the expense of performance.
It is quite difficult to have a unique identifier for strong validation with Last-Modified. Often this is done using an ETag with the MD5 hash of the resource (or a derivative).

Note:
Because a change of content encoding requires a change to an ETag, some servers modify ETags when compressing responses from an origin server (reverse proxies, for example).
Apache Server appends the name of the compression method (-gzip) to ETags by default, but this is configurable using the DeflateAlterETag directive.
Weak validationWeak validation differs from strong validation, as it considers two versions of the document as identical if the content is equivalent. For example, a page that would differ from another only by a different date in its footer, or different advertising, would be considered identical to the other with weak validation. These same two versions are considered different when using strong validation. Building a system of ETags that uses weak validation is very useful for optimizing cache performance, but may be complex, as it involves knowing the importance of the different elements of a page.Conditional headersSeveral HTTP headers, called conditional headers, lead to conditional requests. These are:

If-Match

Succeeds if the ETag of the distant resource is equal to one listed in this header. It performs a strong validation.

If-None-Match

Succeeds if the ETag of the distant resource is different to each listed in this header. It performs a weak validation.

If-Modified-Since

Succeeds if the Last-Modified date of the distant resource is more recent than the one given in this header.

If-Unmodified-Since

Succeeds if the Last-Modified date of the distant resource is older or the same as the one given in this header.

If-Range

Similar to If-Match, or If-Unmodified-Since, but can have only one single ETag or one date. If it fails, the range request fails, and instead of a 206 Partial Content response, a 200 OK is sent with the complete resource.

Use casesCache updateThe most common use case for conditional requests is updating a cache. With an empty cache, or without a cache, the requested resource is sent back with a status of 200 OK.

Together with the resource, the validators are sent in the headers. In this example, both Last-Modified and ETag are sent, but it could equally have been only one of them. These validators are cached with the resource (like all headers) and will be used to craft conditional requests, once the cache becomes stale.
As long as the cache is not stale, no requests are issued at all. But once it has become stale, this is mostly controlled by the Cache-Control header, the client doesn't use the cached value directly but issues a conditional request. The value of the validator is used as a parameter of the If-Modified-Since and If-None-Match headers.
If the resource has not changed, the server sends back a 304 Not Modified response. This makes the cache fresh again, and the client uses the cached resource. Although there is a response/request round-trip that consumes some resources, this is more efficient than to transmit the whole resource over the wire again.

If the resource has changed, the server just sends back a 200 OK response, with the new version of the resource (as though the request wasn't conditional).
The client uses this new resource (and caches it).

Besides the setting of the validators on the server side, this mechanism is transparent: all browsers manage a cache and send such conditional requests without any special work to be done by Web developers.Integrity of a partial downloadPartial downloading of files is a functionality of HTTP that allows resuming previous operations, saving bandwidth and time, by keeping the already obtained information:

A server supporting partial downloads broadcasts this by sending the Accept-Ranges header. Once this happens, the client can resume a download by sending a Ranges header with the missing ranges:

The principle is simple, but there is one potential problem: if the downloaded resource has been modified between both downloads, the obtained ranges will correspond to two different versions of the resource, and the final document will be corrupted.
To prevent this, conditional requests are used. For ranges, there are two ways of doing this. The more flexible one makes use of If-Unmodified-Since and If-Match and the server returns an error if the precondition fails; the client then restarts the download from the beginning:

Even if this method works, it adds an extra response/request exchange when the document has been changed. This impairs performance, and HTTP has a specific header to avoid this scenario: If-Range:

This solution is more efficient, but slightly less flexible, as only one ETag can be used in the condition. Rarely is such additional flexibility needed.Avoiding the lost update problem with optimistic lockingA common operation in Web applications is to update a remote document. This is very common in any file system or source control applications, but any application that allows to store remote resources needs such a mechanism. Common websites, like wikis and other CMS, have such a need.
With the PUT method you are able to implement this. The client first reads the original files, modifies them, and finally pushes them to the server:

Unfortunately, things get a little inaccurate as soon as we take into account concurrency. While a client is locally modifying its new copy of the resource, a second client can fetch the same resource and do the same on its copy. What happens next is very unfortunate: when they commit back to the server, the modifications from the first client are discarded by the next client push, as this second client is unaware of the first client's changes to the resource. The decision on who wins is not communicated to the other party. Which client's changes are to be kept, will vary with the speed they commit; this depends on the performance of the clients, of the server, and even of the human editing the document at the client. The winner will change from one time to the next. This is a race condition and leads to problematic behaviors, which are difficult to detect and to debug:

There is no way to deal with this problem without annoying one of the two clients. However, lost updates and race conditions are to be avoided. We want predictable results, and expect that the clients are notified when their changes are rejected.
Conditional requests allow implementing the optimistic locking algorithm (used by most wikis or source control systems). The concept is to allow all clients to get copies of the resource, then let them modify it locally, controlling concurrency by successfully allowing the first client to submit an update. All subsequent updates, based on the now obsolete version of the resource, are rejected:

This is implemented using the If-Match or If-Unmodified-Since headers. If the ETag doesn't match the original file, or if the file has been modified since it has been obtained, the change is rejected with a 412 Precondition Failed error. It is then up to the client to deal with the error: either by notifying the user to start again (this time on the newest version), or by showing the user a diff of both versions, helping them decide which changes they wish to keep.Dealing with the first upload of a resourceThe first upload of a resource is an edge case of the previous. Like any update of a resource, it is subject to a race condition if two clients try to perform at similar times. To prevent this, conditional requests can be used: by adding If-None-Match with the special value of *, representing any ETag. The request will succeed, only if the resource didn't exist before:

If-None-Match will only work with HTTP/1.1 (and later) compliant servers. If unsure if the server will be compliant, you need first to issue a HEAD request to the resource to check this.ConclusionConditional requests are a key feature of HTTP, and allow the building of efficient and complex applications. For caching or resuming downloads, the only work required for webmasters is to configure the server correctly; setting correct ETags in some environments can be tricky. Once achieved, the browser will serve the expected conditional requests.
For locking mechanisms, it is the opposite: Web developers need to issue a request with the proper headers, while webmasters can mostly rely on the application to carry out the checks for them.
In both cases it's clear, conditional requests are a fundamental feature behind the Web.See also
304 Not Modified
If-None-Match
Apache Server mod_deflate.c transforms ETags during compression\n\nHTTP conditional requestsHTTP has a concept of conditional requests, where the result, and even the success of a request, can be controlled by comparing the affected resources with a validator.
These requests are useful for validating cached content, ensuring that it is only fetched if it differs from the copy that is already available to the browser.
Conditional requests are also useful for ensuring the integrity of a document when resuming a download, or preventing lost updates when uploading or modifying a document on the server.PrinciplesHTTP conditional requests are requests that are executed differently, depending on the value of specific headers. These headers define a precondition, and the result of the request will be different if the precondition is matched or not.
The different behaviors are defined by the method of the request used, and by the set of headers used for a precondition:

for safe methods, like GET, which usually tries to fetch a document, the conditional request can be used to send back the document, if relevant only. Therefore, this spares bandwidth.
for unsafe methods, like PUT, which usually uploads a document, the conditional request can be used to upload the document, only if the original it is based on is the same as that stored on the server.
ValidatorsAll conditional headers try to check if the resource stored on the server matches a specific version. To achieve this, the conditional requests need to indicate the version of the resource. As comparing the whole resource byte to byte is impracticable, and not always what is wanted, the request transmits a value describing the version. Such values are called validators, and are of two kinds:

the date of last modification of the document, the last-modified date.
an opaque string, uniquely identifying each version, called the entity tag, or the ETag.

Comparing versions of the same resource is a bit tricky: depending on the context, there are two kinds of equality checks:

Strong validation is used when byte to byte identity is expected, for example when resuming a download.
Weak validation is used when the user-agent only needs to determine if two resources have the same content. The resources may be considered the same even if minor differences exist, such as different ads or a footer with a different date.

The kind of validation is independent of the validator used. Both Last-Modified and ETag allow both types of validation, though the complexity to implement it on the server side may vary. HTTP uses strong validation by default, and it specifies when weak validation can be used.Strong validationStrong validation consists of guaranteeing that the resource is, byte to byte, identical to the one it is compared to. This is mandatory for some conditional headers, and the default for the others. Strong validation is very strict and may be difficult to guarantee at the server level, but it does guarantee no data loss at any time, sometimes at the expense of performance.
It is quite difficult to have a unique identifier for strong validation with Last-Modified. Often this is done using an ETag with the MD5 hash of the resource (or a derivative).

Note:
Because a change of content encoding requires a change to an ETag, some servers modify ETags when compressing responses from an origin server (reverse proxies, for example).
Apache Server appends the name of the compression method (-gzip) to ETags by default, but this is configurable using the DeflateAlterETag directive.
Weak validationWeak validation differs from strong validation, as it considers two versions of the document as identical if the content is equivalent. For example, a page that would differ from another only by a different date in its footer, or different advertising, would be considered identical to the other with weak validation. These same two versions are considered different when using strong validation. Building a system of ETags that uses weak validation is very useful for optimizing cache performance, but may be complex, as it involves knowing the importance of the different elements of a page.Conditional headersSeveral HTTP headers, called conditional headers, lead to conditional requests. These are:

If-Match

Succeeds if the ETag of the distant resource is equal to one listed in this header. It performs a strong validation.

If-None-Match

Succeeds if the ETag of the distant resource is different to each listed in this header. It performs a weak validation.

If-Modified-Since

Succeeds if the Last-Modified date of the distant resource is more recent than the one given in this header.

If-Unmodified-Since

Succeeds if the Last-Modified date of the distant resource is older or the same as the one given in this header.

If-Range

Similar to If-Match, or If-Unmodified-Since, but can have only one single ETag or one date. If it fails, the range request fails, and instead of a 206 Partial Content response, a 200 OK is sent with the complete resource.

Use casesCache updateThe most common use case for conditional requests is updating a cache. With an empty cache, or without a cache, the requested resource is sent back with a status of 200 OK.

Together with the resource, the validators are sent in the headers. In this example, both Last-Modified and ETag are sent, but it could equally have been only one of them. These validators are cached with the resource (like all headers) and will be used to craft conditional requests, once the cache becomes stale.
As long as the cache is not stale, no requests are issued at all. But once it has become stale, this is mostly controlled by the Cache-Control header, the client doesn't use the cached value directly but issues a conditional request. The value of the validator is used as a parameter of the If-Modified-Since and If-None-Match headers.
If the resource has not changed, the server sends back a 304 Not Modified response. This makes the cache fresh again, and the client uses the cached resource. Although there is a response/request round-trip that consumes some resources, this is more efficient than to transmit the whole resource over the wire again.

If the resource has changed, the server just sends back a 200 OK response, with the new version of the resource (as though the request wasn't conditional).
The client uses this new resource (and caches it).

Besides the setting of the validators on the server side, this mechanism is transparent: all browsers manage a cache and send such conditional requests without any special work to be done by Web developers.Integrity of a partial downloadPartial downloading of files is a functionality of HTTP that allows resuming previous operations, saving bandwidth and time, by keeping the already obtained information:

A server supporting partial downloads broadcasts this by sending the Accept-Ranges header. Once this happens, the client can resume a download by sending a Ranges header with the missing ranges:

The principle is simple, but there is one potential problem: if the downloaded resource has been modified between both downloads, the obtained ranges will correspond to two different versions of the resource, and the final document will be corrupted.
To prevent this, conditional requests are used. For ranges, there are two ways of doing this. The more flexible one makes use of If-Unmodified-Since and If-Match and the server returns an error if the precondition fails; the client then restarts the download from the beginning:

Even if this method works, it adds an extra response/request exchange when the document has been changed. This impairs performance, and HTTP has a specific header to avoid this scenario: If-Range:

This solution is more efficient, but slightly less flexible, as only one ETag can be used in the condition. Rarely is such additional flexibility needed.Avoiding the lost update problem with optimistic lockingA common operation in Web applications is to update a remote document. This is very common in any file system or source control applications, but any application that allows to store remote resources needs such a mechanism. Common websites, like wikis and other CMS, have such a need.
With the PUT method you are able to implement this. The client first reads the original files, modifies them, and finally pushes them to the server:

Unfortunately, things get a little inaccurate as soon as we take into account concurrency. While a client is locally modifying its new copy of the resource, a second client can fetch the same resource and do the same on its copy. What happens next is very unfortunate: when they commit back to the server, the modifications from the first client are discarded by the next client push, as this second client is unaware of the first client's changes to the resource. The decision on who wins is not communicated to the other party. Which client's changes are to be kept, will vary with the speed they commit; this depends on the performance of the clients, of the server, and even of the human editing the document at the client. The winner will change from one time to the next. This is a race condition and leads to problematic behaviors, which are difficult to detect and to debug:

There is no way to deal with this problem without annoying one of the two clients. However, lost updates and race conditions are to be avoided. We want predictable results, and expect that the clients are notified when their changes are rejected.
Conditional requests allow implementing the optimistic locking algorithm (used by most wikis or source control systems). The concept is to allow all clients to get copies of the resource, then let them modify it locally, controlling concurrency by successfully allowing the first client to submit an update. All subsequent updates, based on the now obsolete version of the resource, are rejected:

This is implemented using the If-Match or If-Unmodified-Since headers. If the ETag doesn't match the original file, or if the file has been modified since it has been obtained, the change is rejected with a 412 Precondition Failed error. It is then up to the client to deal with the error: either by notifying the user to start again (this time on the newest version), or by showing the user a diff of both versions, helping them decide which changes they wish to keep.Dealing with the first upload of a resourceThe first upload of a resource is an edge case of the previous. Like any update of a resource, it is subject to a race condition if two clients try to perform at similar times. To prevent this, conditional requests can be used: by adding If-None-Match with the special value of *, representing any ETag. The request will succeed, only if the resource didn't exist before:

If-None-Match will only work with HTTP/1.1 (and later) compliant servers. If unsure if the server will be compliant, you need first to issue a HEAD request to the resource to check this.ConclusionConditional requests are a key feature of HTTP, and allow the building of efficient and complex applications. For caching or resuming downloads, the only work required for webmasters is to configure the server correctly; setting correct ETags in some environments can be tricky. Once achieved, the browser will serve the expected conditional requests.
For locking mechanisms, it is the opposite: Web developers need to issue a request with the proper headers, while webmasters can mostly rely on the application to carry out the checks for them.
In both cases it's clear, conditional requests are a fundamental feature behind the Web.See also
304 Not Modified
If-None-Match
Apache Server mod_deflate.c transforms ETags during compression
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 14, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nHTTP conditional requestsHTTP has a concept of conditional requests, where the result, and even the success of a request, can be controlled by comparing the affected resources with a validator.
These requests are useful for validating cached content, ensuring that it is only fetched if it differs from the copy that is already available to the browser.
Conditional requests are also useful for ensuring the integrity of a document when resuming a download, or preventing lost updates when uploading or modifying a document on the server.PrinciplesHTTP conditional requests are requests that are executed differently, depending on the value of specific headers. These headers define a precondition, and the result of the request will be different if the precondition is matched or not.
The different behaviors are defined by the method of the request used, and by the set of headers used for a precondition:

for safe methods, like GET, which usually tries to fetch a document, the conditional request can be used to send back the document, if relevant only. Therefore, this spares bandwidth.
for unsafe methods, like PUT, which usually uploads a document, the conditional request can be used to upload the document, only if the original it is based on is the same as that stored on the server.
ValidatorsAll conditional headers try to check if the resource stored on the server matches a specific version. To achieve this, the conditional requests need to indicate the version of the resource. As comparing the whole resource byte to byte is impracticable, and not always what is wanted, the request transmits a value describing the version. Such values are called validators, and are of two kinds:

the date of last modification of the document, the last-modified date.
an opaque string, uniquely identifying each version, called the entity tag, or the ETag.

Comparing versions of the same resource is a bit tricky: depending on the context, there are two kinds of equality checks:

Strong validation is used when byte to byte identity is expected, for example when resuming a download.
Weak validation is used when the user-agent only needs to determine if two resources have the same content. The resources may be considered the same even if minor differences exist, such as different ads or a footer with a different date.

The kind of validation is independent of the validator used. Both Last-Modified and ETag allow both types of validation, though the complexity to implement it on the server side may vary. HTTP uses strong validation by default, and it specifies when weak validation can be used.Strong validationStrong validation consists of guaranteeing that the resource is, byte to byte, identical to the one it is compared to. This is mandatory for some conditional headers, and the default for the others. Strong validation is very strict and may be difficult to guarantee at the server level, but it does guarantee no data loss at any time, sometimes at the expense of performance.
It is quite difficult to have a unique identifier for strong validation with Last-Modified. Often this is done using an ETag with the MD5 hash of the resource (or a derivative).

Note:
Because a change of content encoding requires a change to an ETag, some servers modify ETags when compressing responses from an origin server (reverse proxies, for example).
Apache Server appends the name of the compression method (-gzip) to ETags by default, but this is configurable using the DeflateAlterETag directive.
Weak validationWeak validation differs from strong validation, as it considers two versions of the document as identical if the content is equivalent. For example, a page that would differ from another only by a different date in its footer, or different advertising, would be considered identical to the other with weak validation. These same two versions are considered different when using strong validation. Building a system of ETags that uses weak validation is very useful for optimizing cache performance, but may be complex, as it involves knowing the importance of the different elements of a page.Conditional headersSeveral HTTP headers, called conditional headers, lead to conditional requests. These are:

If-Match

Succeeds if the ETag of the distant resource is equal to one listed in this header. It performs a strong validation.

If-None-Match

Succeeds if the ETag of the distant resource is different to each listed in this header. It performs a weak validation.

If-Modified-Since

Succeeds if the Last-Modified date of the distant resource is more recent than the one given in this header.

If-Unmodified-Since

Succeeds if the Last-Modified date of the distant resource is older or the same as the one given in this header.

If-Range

Similar to If-Match, or If-Unmodified-Since, but can have only one single ETag or one date. If it fails, the range request fails, and instead of a 206 Partial Content response, a 200 OK is sent with the complete resource.

Use casesCache updateThe most common use case for conditional requests is updating a cache. With an empty cache, or without a cache, the requested resource is sent back with a status of 200 OK.

Together with the resource, the validators are sent in the headers. In this example, both Last-Modified and ETag are sent, but it could equally have been only one of them. These validators are cached with the resource (like all headers) and will be used to craft conditional requests, once the cache becomes stale.
As long as the cache is not stale, no requests are issued at all. But once it has become stale, this is mostly controlled by the Cache-Control header, the client doesn't use the cached value directly but issues a conditional request. The value of the validator is used as a parameter of the If-Modified-Since and If-None-Match headers.
If the resource has not changed, the server sends back a 304 Not Modified response. This makes the cache fresh again, and the client uses the cached resource. Although there is a response/request round-trip that consumes some resources, this is more efficient than to transmit the whole resource over the wire again.

If the resource has changed, the server just sends back a 200 OK response, with the new version of the resource (as though the request wasn't conditional).
The client uses this new resource (and caches it).

Besides the setting of the validators on the server side, this mechanism is transparent: all browsers manage a cache and send such conditional requests without any special work to be done by Web developers.Integrity of a partial downloadPartial downloading of files is a functionality of HTTP that allows resuming previous operations, saving bandwidth and time, by keeping the already obtained information:

A server supporting partial downloads broadcasts this by sending the Accept-Ranges header. Once this happens, the client can resume a download by sending a Ranges header with the missing ranges:

The principle is simple, but there is one potential problem: if the downloaded resource has been modified between both downloads, the obtained ranges will correspond to two different versions of the resource, and the final document will be corrupted.
To prevent this, conditional requests are used. For ranges, there are two ways of doing this. The more flexible one makes use of If-Unmodified-Since and If-Match and the server returns an error if the precondition fails; the client then restarts the download from the beginning:

Even if this method works, it adds an extra response/request exchange when the document has been changed. This impairs performance, and HTTP has a specific header to avoid this scenario: If-Range:

This solution is more efficient, but slightly less flexible, as only one ETag can be used in the condition. Rarely is such additional flexibility needed.Avoiding the lost update problem with optimistic lockingA common operation in Web applications is to update a remote document. This is very common in any file system or source control applications, but any application that allows to store remote resources needs such a mechanism. Common websites, like wikis and other CMS, have such a need.
With the PUT method you are able to implement this. The client first reads the original files, modifies them, and finally pushes them to the server:

Unfortunately, things get a little inaccurate as soon as we take into account concurrency. While a client is locally modifying its new copy of the resource, a second client can fetch the same resource and do the same on its copy. What happens next is very unfortunate: when they commit back to the server, the modifications from the first client are discarded by the next client push, as this second client is unaware of the first client's changes to the resource. The decision on who wins is not communicated to the other party. Which client's changes are to be kept, will vary with the speed they commit; this depends on the performance of the clients, of the server, and even of the human editing the document at the client. The winner will change from one time to the next. This is a race condition and leads to problematic behaviors, which are difficult to detect and to debug:

There is no way to deal with this problem without annoying one of the two clients. However, lost updates and race conditions are to be avoided. We want predictable results, and expect that the clients are notified when their changes are rejected.
Conditional requests allow implementing the optimistic locking algorithm (used by most wikis or source control systems). The concept is to allow all clients to get copies of the resource, then let them modify it locally, controlling concurrency by successfully allowing the first client to submit an update. All subsequent updates, based on the now obsolete version of the resource, are rejected:

This is implemented using the If-Match or If-Unmodified-Since headers. If the ETag doesn't match the original file, or if the file has been modified since it has been obtained, the change is rejected with a 412 Precondition Failed error. It is then up to the client to deal with the error: either by notifying the user to start again (this time on the newest version), or by showing the user a diff of both versions, helping them decide which changes they wish to keep.Dealing with the first upload of a resourceThe first upload of a resource is an edge case of the previous. Like any update of a resource, it is subject to a race condition if two clients try to perform at similar times. To prevent this, conditional requests can be used: by adding If-None-Match with the special value of *, representing any ETag. The request will succeed, only if the resource didn't exist before:

If-None-Match will only work with HTTP/1.1 (and later) compliant servers. If unsure if the server will be compliant, you need first to issue a HEAD request to the resource to check this.ConclusionConditional requests are a key feature of HTTP, and allow the building of efficient and complex applications. For caching or resuming downloads, the only work required for webmasters is to configure the server correctly; setting correct ETags in some environments can be tricky. Once achieved, the browser will serve the expected conditional requests.
For locking mechanisms, it is the opposite: Web developers need to issue a request with the proper headers, while webmasters can mostly rely on the application to carry out the checks for them.
In both cases it's clear, conditional requests are a fundamental feature behind the Web.See also
304 Not Modified
If-None-Match
Apache Server mod_deflate.c transforms ETags during compression
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 14, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nHTTP range requestsAn HTTP Range request asks the server to send parts of a resource back to a client.
Range requests are useful for various clients, including media players that support random access, data tools that require only part of a large file, and download managers that let users pause and resume a download.Checking if a server supports partial requestsIf an HTTP response includes the Accept-Ranges header with any value other than none, the server supports range requests.
If responses omit the Accept-Ranges header, it indicates the server doesn't support partial requests.
If range requests are not supported, applications can adapt to this condition; for instance, download managers can disable pause buttons that relied on range requests to resume a download.
To check if a server supports range requests, you can issue a HEAD request to inspect headers without requesting the resource in full.
If you use curl, you can use the -I flag to make a HEAD request:
bashcurl -I https://i.imgur.com/z4d4kWk.jpg

This will produce the following HTTP request:
httpHEAD /z4d4kWk.jpg HTTP/2
Host: i.imgur.com
User-Agent: curl/8.7.1
Accept: */*

The response only contains headers and doesn't include a response body:
httpHTTP/2 200
content-type: image/jpeg
last-modified: Thu, 02 Feb 2017 11:15:53 GMT
…
accept-ranges: bytes
content-length: 146515

In this response, Accept-Ranges: bytes indicates that 'bytes' can be used as units to define a range (currently, no other unit is possible).
The Content-Length header is also helpful as it indicates the total size of the image if you were to make the same request using the GET method instead.Requesting a specific range from a serverIf the server supports range requests, you can specify which part (or parts) of the document you want the server to return by including the Range header in a HTTP request.Single part rangesWe can request a single range from a resource using curl for illustration.
The -H option appends a header line to the request, which in this case is the Range header requesting the first 1024 bytes.
The last option is --output - which will allow printing the binary output to the terminal:
bashcurl https://i.imgur.com/z4d4kWk.jpg -i -H "Range: bytes=0-1023" --output -

The issued request looks like this:
httpGET /z4d4kWk.jpg HTTP/2
Host: i.imgur.com
User-Agent: curl/8.7.1
Accept: */*
Range: bytes=0-1023

The server responds with a 206 Partial Content status:
httpHTTP/2 206
content-type: image/jpeg
content-length: 1024
content-range: bytes 0-1023/146515
…

(binary content)

The Content-Length header indicates the size of the requested range, not the full size of the image.
The Content-Range response header indicates where this partial message belongs within the full resource.Multipart rangesThe Range header also allows you to get multiple ranges at once in a multipart document. The ranges are separated by a comma.
bashcurl http://www.example.com -i -H "Range: bytes=0-50, 100-150"

The server responds with the 206 Partial Content status as shown below.
The response contains a Content-Type header, indicating that a multipart byterange follows.
The boundary string (3d6b6a416f9b5 in this case) separates the body parts, each of which has its own Content-Type and Content-Range fields:
httpHTTP/1.1 206 Partial Content
Content-Type: multipart/byteranges; boundary=3d6b6a416f9b5
Content-Length: 282

--3d6b6a416f9b5
Content-Type: text/html
Content-Range: bytes 0-50/1270

<!doctype html>
<html lang="en-US">
<head>
    <title>Example Do
--3d6b6a416f9b5
Content-Type: text/html
Content-Range: bytes 100-150/1270

eta http-equiv="Content-type" content="text/html; c
--3d6b6a416f9b5--
Conditional range requestsWhen resuming to request more parts of a resource, you need to guarantee that the stored resource has not been modified since the last fragment has been received.
The If-Range HTTP request header makes a range request conditional: if the condition is fulfilled, the range request will be issued and the server sends back a 206 Partial Content answer with the appropriate body. If the condition is not fulfilled, the full resource is sent back, with a 200 OK status. This header can be used either with a Last-Modified validator, or with an ETag, but not with both.
httpIf-Range: Wed, 21 Oct 2015 07:28:00 GMT
Partial request responsesThere are three relevant statuses, when working with range requests:

A successful range request elicits a 206 Partial Content status from the server.
A range request that is out of bounds will result in a 416 Requested Range Not Satisfiable status, meaning that none of the range values overlap the extent of the resource. For example, the first-byte-pos of every range might be greater than the resource length.
If range requests are not supported, an 200 OK status is sent back and the entire response body is transmitted.
Comparison to chunked Transfer-EncodingThe Transfer-Encoding header allows chunked encoding, which is useful when larger amounts of data are sent to the client and the total size of the response is not known until the request has been fully processed. The server sends data to the client straight away without buffering the response or determining the exact length, which leads to improved latency. Range requests and chunking are compatible and can be used with or without each other.See also
Related status codes 200, 206, 416.
Related headers: Accept-Ranges, Range, Content-Range, If-Range, Transfer-Encoding.\n\nHTTP range requestsAn HTTP Range request asks the server to send parts of a resource back to a client.
Range requests are useful for various clients, including media players that support random access, data tools that require only part of a large file, and download managers that let users pause and resume a download.Checking if a server supports partial requestsIf an HTTP response includes the Accept-Ranges header with any value other than none, the server supports range requests.
If responses omit the Accept-Ranges header, it indicates the server doesn't support partial requests.
If range requests are not supported, applications can adapt to this condition; for instance, download managers can disable pause buttons that relied on range requests to resume a download.
To check if a server supports range requests, you can issue a HEAD request to inspect headers without requesting the resource in full.
If you use curl, you can use the -I flag to make a HEAD request:
bashcurl -I https://i.imgur.com/z4d4kWk.jpg

This will produce the following HTTP request:
httpHEAD /z4d4kWk.jpg HTTP/2
Host: i.imgur.com
User-Agent: curl/8.7.1
Accept: */*

The response only contains headers and doesn't include a response body:
httpHTTP/2 200
content-type: image/jpeg
last-modified: Thu, 02 Feb 2017 11:15:53 GMT
…
accept-ranges: bytes
content-length: 146515

In this response, Accept-Ranges: bytes indicates that 'bytes' can be used as units to define a range (currently, no other unit is possible).
The Content-Length header is also helpful as it indicates the total size of the image if you were to make the same request using the GET method instead.Requesting a specific range from a serverIf the server supports range requests, you can specify which part (or parts) of the document you want the server to return by including the Range header in a HTTP request.Single part rangesWe can request a single range from a resource using curl for illustration.
The -H option appends a header line to the request, which in this case is the Range header requesting the first 1024 bytes.
The last option is --output - which will allow printing the binary output to the terminal:
bashcurl https://i.imgur.com/z4d4kWk.jpg -i -H "Range: bytes=0-1023" --output -

The issued request looks like this:
httpGET /z4d4kWk.jpg HTTP/2
Host: i.imgur.com
User-Agent: curl/8.7.1
Accept: */*
Range: bytes=0-1023

The server responds with a 206 Partial Content status:
httpHTTP/2 206
content-type: image/jpeg
content-length: 1024
content-range: bytes 0-1023/146515
…

(binary content)

The Content-Length header indicates the size of the requested range, not the full size of the image.
The Content-Range response header indicates where this partial message belongs within the full resource.Multipart rangesThe Range header also allows you to get multiple ranges at once in a multipart document. The ranges are separated by a comma.
bashcurl http://www.example.com -i -H "Range: bytes=0-50, 100-150"

The server responds with the 206 Partial Content status as shown below.
The response contains a Content-Type header, indicating that a multipart byterange follows.
The boundary string (3d6b6a416f9b5 in this case) separates the body parts, each of which has its own Content-Type and Content-Range fields:
httpHTTP/1.1 206 Partial Content
Content-Type: multipart/byteranges; boundary=3d6b6a416f9b5
Content-Length: 282

--3d6b6a416f9b5
Content-Type: text/html
Content-Range: bytes 0-50/1270

<!doctype html>
<html lang="en-US">
<head>
    <title>Example Do
--3d6b6a416f9b5
Content-Type: text/html
Content-Range: bytes 100-150/1270

eta http-equiv="Content-type" content="text/html; c
--3d6b6a416f9b5--
Conditional range requestsWhen resuming to request more parts of a resource, you need to guarantee that the stored resource has not been modified since the last fragment has been received.
The If-Range HTTP request header makes a range request conditional: if the condition is fulfilled, the range request will be issued and the server sends back a 206 Partial Content answer with the appropriate body. If the condition is not fulfilled, the full resource is sent back, with a 200 OK status. This header can be used either with a Last-Modified validator, or with an ETag, but not with both.
httpIf-Range: Wed, 21 Oct 2015 07:28:00 GMT
Partial request responsesThere are three relevant statuses, when working with range requests:

A successful range request elicits a 206 Partial Content status from the server.
A range request that is out of bounds will result in a 416 Requested Range Not Satisfiable status, meaning that none of the range values overlap the extent of the resource. For example, the first-byte-pos of every range might be greater than the resource length.
If range requests are not supported, an 200 OK status is sent back and the entire response body is transmitted.
Comparison to chunked Transfer-EncodingThe Transfer-Encoding header allows chunked encoding, which is useful when larger amounts of data are sent to the client and the total size of the response is not known until the request has been fully processed. The server sends data to the client straight away without buffering the response or determining the exact length, which leads to improved latency. Range requests and chunking are compatible and can be used with or without each other.See also
Related status codes 200, 206, 416.
Related headers: Accept-Ranges, Range, Content-Range, If-Range, Transfer-Encoding.
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nHTTP range requestsAn HTTP Range request asks the server to send parts of a resource back to a client.
Range requests are useful for various clients, including media players that support random access, data tools that require only part of a large file, and download managers that let users pause and resume a download.Checking if a server supports partial requestsIf an HTTP response includes the Accept-Ranges header with any value other than none, the server supports range requests.
If responses omit the Accept-Ranges header, it indicates the server doesn't support partial requests.
If range requests are not supported, applications can adapt to this condition; for instance, download managers can disable pause buttons that relied on range requests to resume a download.
To check if a server supports range requests, you can issue a HEAD request to inspect headers without requesting the resource in full.
If you use curl, you can use the -I flag to make a HEAD request:
bashcurl -I https://i.imgur.com/z4d4kWk.jpg

This will produce the following HTTP request:
httpHEAD /z4d4kWk.jpg HTTP/2
Host: i.imgur.com
User-Agent: curl/8.7.1
Accept: */*

The response only contains headers and doesn't include a response body:
httpHTTP/2 200
content-type: image/jpeg
last-modified: Thu, 02 Feb 2017 11:15:53 GMT
…
accept-ranges: bytes
content-length: 146515

In this response, Accept-Ranges: bytes indicates that 'bytes' can be used as units to define a range (currently, no other unit is possible).
The Content-Length header is also helpful as it indicates the total size of the image if you were to make the same request using the GET method instead.Requesting a specific range from a serverIf the server supports range requests, you can specify which part (or parts) of the document you want the server to return by including the Range header in a HTTP request.Single part rangesWe can request a single range from a resource using curl for illustration.
The -H option appends a header line to the request, which in this case is the Range header requesting the first 1024 bytes.
The last option is --output - which will allow printing the binary output to the terminal:
bashcurl https://i.imgur.com/z4d4kWk.jpg -i -H "Range: bytes=0-1023" --output -

The issued request looks like this:
httpGET /z4d4kWk.jpg HTTP/2
Host: i.imgur.com
User-Agent: curl/8.7.1
Accept: */*
Range: bytes=0-1023

The server responds with a 206 Partial Content status:
httpHTTP/2 206
content-type: image/jpeg
content-length: 1024
content-range: bytes 0-1023/146515
…

(binary content)

The Content-Length header indicates the size of the requested range, not the full size of the image.
The Content-Range response header indicates where this partial message belongs within the full resource.Multipart rangesThe Range header also allows you to get multiple ranges at once in a multipart document. The ranges are separated by a comma.
bashcurl http://www.example.com -i -H "Range: bytes=0-50, 100-150"

The server responds with the 206 Partial Content status as shown below.
The response contains a Content-Type header, indicating that a multipart byterange follows.
The boundary string (3d6b6a416f9b5 in this case) separates the body parts, each of which has its own Content-Type and Content-Range fields:
httpHTTP/1.1 206 Partial Content
Content-Type: multipart/byteranges; boundary=3d6b6a416f9b5
Content-Length: 282

--3d6b6a416f9b5
Content-Type: text/html
Content-Range: bytes 0-50/1270

<!doctype html>
<html lang="en-US">
<head>
    <title>Example Do
--3d6b6a416f9b5
Content-Type: text/html
Content-Range: bytes 100-150/1270

eta http-equiv="Content-type" content="text/html; c
--3d6b6a416f9b5--
Conditional range requestsWhen resuming to request more parts of a resource, you need to guarantee that the stored resource has not been modified since the last fragment has been received.
The If-Range HTTP request header makes a range request conditional: if the condition is fulfilled, the range request will be issued and the server sends back a 206 Partial Content answer with the appropriate body. If the condition is not fulfilled, the full resource is sent back, with a 200 OK status. This header can be used either with a Last-Modified validator, or with an ETag, but not with both.
httpIf-Range: Wed, 21 Oct 2015 07:28:00 GMT
Partial request responsesThere are three relevant statuses, when working with range requests:

A successful range request elicits a 206 Partial Content status from the server.
A range request that is out of bounds will result in a 416 Requested Range Not Satisfiable status, meaning that none of the range values overlap the extent of the resource. For example, the first-byte-pos of every range might be greater than the resource length.
If range requests are not supported, an 200 OK status is sent back and the entire response body is transmitted.
Comparison to chunked Transfer-EncodingThe Transfer-Encoding header allows chunked encoding, which is useful when larger amounts of data are sent to the client and the total size of the response is not known until the request has been fully processed. The server sends data to the client straight away without buffering the response or determining the exact length, which leads to improved latency. Range requests and chunking are compatible and can be used with or without each other.See also
Related status codes 200, 206, 416.
Related headers: Accept-Ranges, Range, Content-Range, If-Range, Transfer-Encoding.
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nConnection management in HTTP/1.xConnection management is a key topic in HTTP: opening and maintaining connections largely impacts the performance of websites and Web applications. In HTTP/1.x, there are several models: short-lived connections, persistent connections, and HTTP pipelining.
HTTP mostly relies on TCP for its transport protocol, providing a connection between the client and the server. In its infancy, HTTP used a single model to handle such connections. These connections were short-lived: a new one created each time a request needed sending, and closed once the answer had been received.
This model held an innate limitation on performance: opening each TCP connection is a resource-consuming operation. Several messages must be exchanged between the client and the server. Network latency and bandwidth affect performance when a request needs sending. Modern Web pages require many requests (a dozen or more) to serve the amount of information needed, proving this earlier model inefficient.
Two newer models were created in HTTP/1.1. The persistent-connection model keeps connections opened between successive requests, reducing the time needed to open new connections. The HTTP pipelining model goes one step further, by sending several successive requests without even waiting for an answer, reducing much of the latency in the network.


Note:
HTTP/2 adds additional models for connection management.

It's important to note that connection management in HTTP applies to the connection between two consecutive nodes, which is hop-by-hop and not end-to-end. The model used in connections between a client and its first proxy may differ from the model between a proxy and the destination server (or any intermediate proxies). The HTTP headers involved in defining the connection model, like Connection and Keep-Alive, are hop-by-hop headers with their values able to be changed by intermediary nodes.
A related topic is the concept of HTTP connection upgrades, wherein an HTTP/1.1 connection is upgraded to a different protocol, such as TLS/1.0, WebSocket, or even HTTP/2 in cleartext. This protocol upgrade mechanism is documented in more detail elsewhere.Short-lived connectionsThe original model of HTTP, and the default one in HTTP/1.0, is short-lived connections. Each HTTP request is completed on its own connection; this means a TCP handshake happens before each HTTP request, and these are serialized.
The TCP handshake itself is time-consuming, but a TCP connection adapts to its load, becoming more efficient with more sustained (or warm) connections. Short-lived connections do not make use of this efficiency feature of TCP, and performance degrades from optimum by persisting to transmit over a new, cold connection.
This model is the default model used in HTTP/1.0 (if there is no Connection header, or if its value is set to close). In HTTP/1.1, this model is only used when the Connection header is sent with a value of close.

Note:
Unless dealing with a very old system, which doesn't support a persistent connection, there is no compelling reason to use this model.
Persistent connectionsShort-lived connections have two major hitches: the time taken to establish a new connection is significant, and performance of the underlying TCP connection gets better only when this connection has been in use for some time (warm connection). To ease these problems, the concept of a persistent connection has been designed, even prior to HTTP/1.1. Alternatively this may be called a keep-alive connection.
A persistent connection is one which remains open for a period of time, and can be reused for several requests, saving the need for a new TCP handshake, and utilizing TCP's performance enhancing capabilities. This connection will not stay open forever: idle connections are closed after some time (a server may use the Keep-Alive header to specify a minimum time the connection should be kept open).
Persistent connections also have drawbacks; even when idling they consume server resources, and under heavy load, DoS attacks can be conducted. In such cases, using non-persistent connections, which are closed as soon as they are idle, can provide better performance.
HTTP/1.0 connections are not persistent by default. Setting Connection to anything other than close, usually retry-after, will make them persistent.
In HTTP/1.1, persistence is the default, and the header is no longer needed (but it is often added as a defensive measure against cases requiring a fallback to HTTP/1.0).HTTP pipelining
Note:
HTTP pipelining is not activated by default in modern browsers:

Buggy proxies are still common and these lead to strange and erratic behaviors that Web developers cannot foresee and diagnose easily.
Pipelining is complex to implement correctly: the size of the resource being transferred, the effective RTT that will be used, as well as the effective bandwidth, have a direct incidence on the improvement provided by the pipeline. Without knowing these, important messages may be delayed behind unimportant ones. The notion of important even evolves during page layout! HTTP pipelining therefore brings a marginal improvement in most cases only.
Pipelining is subject to the head-of-line blocking.

For these reasons, pipelining has been superseded by a better algorithm, multiplexing, that is used by HTTP/2.

By default, HTTP requests are issued sequentially. The next request is only issued once the response to the current request has been received. As they are affected by network latencies and bandwidth limitations, this can result in significant delay before the next request is seen by the server.
Pipelining is the process to send successive requests, over the same persistent connection, without waiting for the answer. This avoids latency of the connection. Theoretically, performance could also be improved if two HTTP requests were to be packed into the same TCP message. The typical MSS (Maximum Segment Size), is big enough to contain several simple requests, although the demand in size of HTTP requests continues to grow.
Not all types of HTTP requests can be pipelined: only idempotent methods, that is GET, HEAD, PUT and DELETE, can be replayed safely. Should a failure happen, the pipeline content can be repeated.
Today, every HTTP/1.1-compliant proxy and server should support pipelining, though many have limitations in practice: a significant reason no modern browser activates this feature by default.Domain sharding
Note:
Unless you have a very specific immediate need, don't use this deprecated technique; switch to HTTP/2 instead. In HTTP/2, domain sharding is no longer useful: the HTTP/2 connection is able to handle parallel unprioritized requests very well. Domain sharding is even detrimental to performance. Most HTTP/2 implementations use a technique called connection coalescing to revert eventual domain sharding.

As an HTTP/1.x connection is serializing requests, even without any ordering, it can't be optimal without large enough available bandwidth. As a solution, browsers open several connections to each domain, sending parallel requests. Default was once 2 to 3 connections, but this has now increased to a more common use of 6 parallel connections. There is a risk of triggering DoS protection on the server side if attempting more than this number.
If the server wishes a faster website or application response, it is possible for the server to force the opening of more connections. For example, instead of having all resources on the same domain, say www.example.com, it could split over several domains, www1.example.com, www2.example.com, www3.example.com. Each of these domains resolves to the same server, and the Web browser will open 6 connections to each (in our example, boosting the connections to 18). This technique is called domain sharding.
ConclusionImproved connection management allows considerable boosting of performance in HTTP. With HTTP/1.1 or HTTP/1.0, using a persistent connection – at least until it becomes idle – leads to the best performance. However, the failure of pipelining has lead to designing superior connection management models, which have been incorporated into HTTP/2.See also
Evolution of HTTP
Glossary terms:

HTTP
HTTP/2
QUIC
Round Trip Time (RTT)
TCP slow start
TLS
Transmission Control Protocol (TCP)\n\nConnection management in HTTP/1.xConnection management is a key topic in HTTP: opening and maintaining connections largely impacts the performance of websites and Web applications. In HTTP/1.x, there are several models: short-lived connections, persistent connections, and HTTP pipelining.
HTTP mostly relies on TCP for its transport protocol, providing a connection between the client and the server. In its infancy, HTTP used a single model to handle such connections. These connections were short-lived: a new one created each time a request needed sending, and closed once the answer had been received.
This model held an innate limitation on performance: opening each TCP connection is a resource-consuming operation. Several messages must be exchanged between the client and the server. Network latency and bandwidth affect performance when a request needs sending. Modern Web pages require many requests (a dozen or more) to serve the amount of information needed, proving this earlier model inefficient.
Two newer models were created in HTTP/1.1. The persistent-connection model keeps connections opened between successive requests, reducing the time needed to open new connections. The HTTP pipelining model goes one step further, by sending several successive requests without even waiting for an answer, reducing much of the latency in the network.


Note:
HTTP/2 adds additional models for connection management.

It's important to note that connection management in HTTP applies to the connection between two consecutive nodes, which is hop-by-hop and not end-to-end. The model used in connections between a client and its first proxy may differ from the model between a proxy and the destination server (or any intermediate proxies). The HTTP headers involved in defining the connection model, like Connection and Keep-Alive, are hop-by-hop headers with their values able to be changed by intermediary nodes.
A related topic is the concept of HTTP connection upgrades, wherein an HTTP/1.1 connection is upgraded to a different protocol, such as TLS/1.0, WebSocket, or even HTTP/2 in cleartext. This protocol upgrade mechanism is documented in more detail elsewhere.Short-lived connectionsThe original model of HTTP, and the default one in HTTP/1.0, is short-lived connections. Each HTTP request is completed on its own connection; this means a TCP handshake happens before each HTTP request, and these are serialized.
The TCP handshake itself is time-consuming, but a TCP connection adapts to its load, becoming more efficient with more sustained (or warm) connections. Short-lived connections do not make use of this efficiency feature of TCP, and performance degrades from optimum by persisting to transmit over a new, cold connection.
This model is the default model used in HTTP/1.0 (if there is no Connection header, or if its value is set to close). In HTTP/1.1, this model is only used when the Connection header is sent with a value of close.

Note:
Unless dealing with a very old system, which doesn't support a persistent connection, there is no compelling reason to use this model.
Persistent connectionsShort-lived connections have two major hitches: the time taken to establish a new connection is significant, and performance of the underlying TCP connection gets better only when this connection has been in use for some time (warm connection). To ease these problems, the concept of a persistent connection has been designed, even prior to HTTP/1.1. Alternatively this may be called a keep-alive connection.
A persistent connection is one which remains open for a period of time, and can be reused for several requests, saving the need for a new TCP handshake, and utilizing TCP's performance enhancing capabilities. This connection will not stay open forever: idle connections are closed after some time (a server may use the Keep-Alive header to specify a minimum time the connection should be kept open).
Persistent connections also have drawbacks; even when idling they consume server resources, and under heavy load, DoS attacks can be conducted. In such cases, using non-persistent connections, which are closed as soon as they are idle, can provide better performance.
HTTP/1.0 connections are not persistent by default. Setting Connection to anything other than close, usually retry-after, will make them persistent.
In HTTP/1.1, persistence is the default, and the header is no longer needed (but it is often added as a defensive measure against cases requiring a fallback to HTTP/1.0).HTTP pipelining
Note:
HTTP pipelining is not activated by default in modern browsers:

Buggy proxies are still common and these lead to strange and erratic behaviors that Web developers cannot foresee and diagnose easily.
Pipelining is complex to implement correctly: the size of the resource being transferred, the effective RTT that will be used, as well as the effective bandwidth, have a direct incidence on the improvement provided by the pipeline. Without knowing these, important messages may be delayed behind unimportant ones. The notion of important even evolves during page layout! HTTP pipelining therefore brings a marginal improvement in most cases only.
Pipelining is subject to the head-of-line blocking.

For these reasons, pipelining has been superseded by a better algorithm, multiplexing, that is used by HTTP/2.

By default, HTTP requests are issued sequentially. The next request is only issued once the response to the current request has been received. As they are affected by network latencies and bandwidth limitations, this can result in significant delay before the next request is seen by the server.
Pipelining is the process to send successive requests, over the same persistent connection, without waiting for the answer. This avoids latency of the connection. Theoretically, performance could also be improved if two HTTP requests were to be packed into the same TCP message. The typical MSS (Maximum Segment Size), is big enough to contain several simple requests, although the demand in size of HTTP requests continues to grow.
Not all types of HTTP requests can be pipelined: only idempotent methods, that is GET, HEAD, PUT and DELETE, can be replayed safely. Should a failure happen, the pipeline content can be repeated.
Today, every HTTP/1.1-compliant proxy and server should support pipelining, though many have limitations in practice: a significant reason no modern browser activates this feature by default.Domain sharding
Note:
Unless you have a very specific immediate need, don't use this deprecated technique; switch to HTTP/2 instead. In HTTP/2, domain sharding is no longer useful: the HTTP/2 connection is able to handle parallel unprioritized requests very well. Domain sharding is even detrimental to performance. Most HTTP/2 implementations use a technique called connection coalescing to revert eventual domain sharding.

As an HTTP/1.x connection is serializing requests, even without any ordering, it can't be optimal without large enough available bandwidth. As a solution, browsers open several connections to each domain, sending parallel requests. Default was once 2 to 3 connections, but this has now increased to a more common use of 6 parallel connections. There is a risk of triggering DoS protection on the server side if attempting more than this number.
If the server wishes a faster website or application response, it is possible for the server to force the opening of more connections. For example, instead of having all resources on the same domain, say www.example.com, it could split over several domains, www1.example.com, www2.example.com, www3.example.com. Each of these domains resolves to the same server, and the Web browser will open 6 connections to each (in our example, boosting the connections to 18). This technique is called domain sharding.
ConclusionImproved connection management allows considerable boosting of performance in HTTP. With HTTP/1.1 or HTTP/1.0, using a persistent connection – at least until it becomes idle – leads to the best performance. However, the failure of pipelining has lead to designing superior connection management models, which have been incorporated into HTTP/2.See also
Evolution of HTTP
Glossary terms:

HTTP
HTTP/2
QUIC
Round Trip Time (RTT)
TCP slow start
TLS
Transmission Control Protocol (TCP)


Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 14, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nConnection management in HTTP/1.xConnection management is a key topic in HTTP: opening and maintaining connections largely impacts the performance of websites and Web applications. In HTTP/1.x, there are several models: short-lived connections, persistent connections, and HTTP pipelining.
HTTP mostly relies on TCP for its transport protocol, providing a connection between the client and the server. In its infancy, HTTP used a single model to handle such connections. These connections were short-lived: a new one created each time a request needed sending, and closed once the answer had been received.
This model held an innate limitation on performance: opening each TCP connection is a resource-consuming operation. Several messages must be exchanged between the client and the server. Network latency and bandwidth affect performance when a request needs sending. Modern Web pages require many requests (a dozen or more) to serve the amount of information needed, proving this earlier model inefficient.
Two newer models were created in HTTP/1.1. The persistent-connection model keeps connections opened between successive requests, reducing the time needed to open new connections. The HTTP pipelining model goes one step further, by sending several successive requests without even waiting for an answer, reducing much of the latency in the network.


Note:
HTTP/2 adds additional models for connection management.

It's important to note that connection management in HTTP applies to the connection between two consecutive nodes, which is hop-by-hop and not end-to-end. The model used in connections between a client and its first proxy may differ from the model between a proxy and the destination server (or any intermediate proxies). The HTTP headers involved in defining the connection model, like Connection and Keep-Alive, are hop-by-hop headers with their values able to be changed by intermediary nodes.
A related topic is the concept of HTTP connection upgrades, wherein an HTTP/1.1 connection is upgraded to a different protocol, such as TLS/1.0, WebSocket, or even HTTP/2 in cleartext. This protocol upgrade mechanism is documented in more detail elsewhere.Short-lived connectionsThe original model of HTTP, and the default one in HTTP/1.0, is short-lived connections. Each HTTP request is completed on its own connection; this means a TCP handshake happens before each HTTP request, and these are serialized.
The TCP handshake itself is time-consuming, but a TCP connection adapts to its load, becoming more efficient with more sustained (or warm) connections. Short-lived connections do not make use of this efficiency feature of TCP, and performance degrades from optimum by persisting to transmit over a new, cold connection.
This model is the default model used in HTTP/1.0 (if there is no Connection header, or if its value is set to close). In HTTP/1.1, this model is only used when the Connection header is sent with a value of close.

Note:
Unless dealing with a very old system, which doesn't support a persistent connection, there is no compelling reason to use this model.
Persistent connectionsShort-lived connections have two major hitches: the time taken to establish a new connection is significant, and performance of the underlying TCP connection gets better only when this connection has been in use for some time (warm connection). To ease these problems, the concept of a persistent connection has been designed, even prior to HTTP/1.1. Alternatively this may be called a keep-alive connection.
A persistent connection is one which remains open for a period of time, and can be reused for several requests, saving the need for a new TCP handshake, and utilizing TCP's performance enhancing capabilities. This connection will not stay open forever: idle connections are closed after some time (a server may use the Keep-Alive header to specify a minimum time the connection should be kept open).
Persistent connections also have drawbacks; even when idling they consume server resources, and under heavy load, DoS attacks can be conducted. In such cases, using non-persistent connections, which are closed as soon as they are idle, can provide better performance.
HTTP/1.0 connections are not persistent by default. Setting Connection to anything other than close, usually retry-after, will make them persistent.
In HTTP/1.1, persistence is the default, and the header is no longer needed (but it is often added as a defensive measure against cases requiring a fallback to HTTP/1.0).HTTP pipelining
Note:
HTTP pipelining is not activated by default in modern browsers:

Buggy proxies are still common and these lead to strange and erratic behaviors that Web developers cannot foresee and diagnose easily.
Pipelining is complex to implement correctly: the size of the resource being transferred, the effective RTT that will be used, as well as the effective bandwidth, have a direct incidence on the improvement provided by the pipeline. Without knowing these, important messages may be delayed behind unimportant ones. The notion of important even evolves during page layout! HTTP pipelining therefore brings a marginal improvement in most cases only.
Pipelining is subject to the head-of-line blocking.

For these reasons, pipelining has been superseded by a better algorithm, multiplexing, that is used by HTTP/2.

By default, HTTP requests are issued sequentially. The next request is only issued once the response to the current request has been received. As they are affected by network latencies and bandwidth limitations, this can result in significant delay before the next request is seen by the server.
Pipelining is the process to send successive requests, over the same persistent connection, without waiting for the answer. This avoids latency of the connection. Theoretically, performance could also be improved if two HTTP requests were to be packed into the same TCP message. The typical MSS (Maximum Segment Size), is big enough to contain several simple requests, although the demand in size of HTTP requests continues to grow.
Not all types of HTTP requests can be pipelined: only idempotent methods, that is GET, HEAD, PUT and DELETE, can be replayed safely. Should a failure happen, the pipeline content can be repeated.
Today, every HTTP/1.1-compliant proxy and server should support pipelining, though many have limitations in practice: a significant reason no modern browser activates this feature by default.Domain sharding
Note:
Unless you have a very specific immediate need, don't use this deprecated technique; switch to HTTP/2 instead. In HTTP/2, domain sharding is no longer useful: the HTTP/2 connection is able to handle parallel unprioritized requests very well. Domain sharding is even detrimental to performance. Most HTTP/2 implementations use a technique called connection coalescing to revert eventual domain sharding.

As an HTTP/1.x connection is serializing requests, even without any ordering, it can't be optimal without large enough available bandwidth. As a solution, browsers open several connections to each domain, sending parallel requests. Default was once 2 to 3 connections, but this has now increased to a more common use of 6 parallel connections. There is a risk of triggering DoS protection on the server side if attempting more than this number.
If the server wishes a faster website or application response, it is possible for the server to force the opening of more connections. For example, instead of having all resources on the same domain, say www.example.com, it could split over several domains, www1.example.com, www2.example.com, www3.example.com. Each of these domains resolves to the same server, and the Web browser will open 6 connections to each (in our example, boosting the connections to 18). This technique is called domain sharding.
ConclusionImproved connection management allows considerable boosting of performance in HTTP. With HTTP/1.1 or HTTP/1.0, using a persistent connection – at least until it becomes idle – leads to the best performance. However, the failure of pipelining has lead to designing superior connection management models, which have been incorporated into HTTP/2.See also
Evolution of HTTP
Glossary terms:

HTTP
HTTP/2
QUIC
Round Trip Time (RTT)
TCP slow start
TLS
Transmission Control Protocol (TCP)


Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 14, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nProtocol upgrade mechanismThe HTTP/1.1 protocol provides a special mechanism that can be used to upgrade an already established connection to a different protocol, using the Upgrade header field.
This mechanism is optional; it cannot be used to insist on a protocol change. Implementations can choose not to take advantage of an upgrade even if they support the new protocol, and in practice, this mechanism is used mostly to bootstrap a WebSockets connection.
Note also that HTTP/2 explicitly disallows the use of this mechanism; it is specific to HTTP/1.1.Upgrading HTTP/1.1 ConnectionsThe Upgrade header field is used by clients to invite the server to switch to one of the listed protocols, in descending preference order.
Because Upgrade is a hop-by-hop header, it also needs to be listed in the Connection header field. This means that a typical request that includes Upgrade would look something like:
httpGET /index.html HTTP/1.1
Host: www.example.com
Connection: upgrade
Upgrade: example/1, foo/2

Other headers may be required depending on the requested protocol; for example, WebSocket upgrades allow additional headers to configure details about the WebSocket connection as well as to offer a degree of security in opening the connection. See Upgrading to a WebSocket connection for more details.
If the server decides to upgrade the connection, it sends back a 101 Switching Protocols response status with an Upgrade header that specifies the protocol(s) being switched to. If it does not (or cannot) upgrade the connection, it ignores the Upgrade header and sends back a regular response (for example, a 200 OK).
Right after sending the 101 status code, the server can begin speaking the new protocol, performing any additional protocol-specific handshakes as necessary. Effectively, the connection becomes a two-way pipe as soon as the upgraded response is complete, and the request that initiated the upgrade can be completed over the new protocol.Common uses for this mechanismHere we look at the most common use cases for the Upgrade header.Upgrading to a WebSocket connectionBy far, the most common use case for upgrading an HTTP connection is to use WebSockets, which are always implemented by upgrading an HTTP or HTTPS connection. Keep in mind that if you're opening a new connection using the WebSocket API, or any library that does WebSockets, most or all of this is done for you. For example, opening a WebSocket connection is a single method:
jswebSocket = new WebSocket("ws://destination.server.ext", "optionalProtocol");

The WebSocket() constructor does all the work of creating an initial HTTP/1.1 connection then handling the handshaking and upgrade process for you.

Note:
You can also use the "wss://" URL scheme to open a secure WebSocket connection.

If you need to create a WebSocket connection from scratch, you'll have to handle the handshaking process yourself. After creating the initial HTTP/1.1 session, you need to request the upgrade by adding to a standard request the Upgrade and Connection headers, as follows:
httpConnection: Upgrade
Upgrade: websocket
WebSocket-specific headersThe following headers are involved in the WebSocket upgrade process. Other than the Upgrade and Connection headers, the rest are generally optional or handled for you by the browser and server when they're talking to each other.
Sec-WebSocket-Extensions
Specifies one or more protocol-level WebSocket extensions to ask the server to use. Using more than one Sec-WebSocket-Extension header in a request is permitted; the result is the same as if you included all of the listed extensions in one such header.
httpSec-WebSocket-Extensions: extensions


extensions

A comma-separated list of extensions to request (or agree to support). These should be selected from the IANA WebSocket Extension Name Registry. Extensions which take parameters do so by using semicolon delineation.


For example:
httpSec-WebSocket-Extensions: superspeed, colormode; depth=16

Sec-WebSocket-Key
Provides information to the server which is needed in order to confirm that the client is entitled to request an upgrade to WebSocket. This header can be used when insecure (HTTP) clients wish to upgrade, in order to offer some degree of protection against abuse. The value of the key is computed using an algorithm defined in the WebSocket specification, so this does not provide security. Instead, it helps to prevent non-WebSocket clients from inadvertently, or through misuse, requesting a WebSocket connection. In essence, then, this key confirms that "Yes, I really mean to open a WebSocket connection."
This header is automatically added by clients that choose to use it; it cannot be added using the fetch() or XMLHttpRequest.setRequestHeader() methods.
httpSec-WebSocket-Key: key


key

The key for this request to upgrade. The client adds this if it wishes to do so, and the server will include in the response a key of its own, which the client will validate before delivering the upgrade response to you.


The server's response's Sec-WebSocket-Accept header will have a value computed based upon the specified key.
Sec-WebSocket-Protocol
The Sec-WebSocket-Protocol header specifies one or more WebSocket protocols that you wish to use, in order of preference. The first one that is supported by the server will be selected and returned by the server in a Sec-WebSocket-Protocol header included in the response. You can use this more than once in the header, as well; the result is the same as if you used a comma-delineated list of subprotocol identifiers in a single header.
httpSec-WebSocket-Protocol: subprotocols


subprotocols

A comma-separated list of subprotocol names, in the order of preference. The subprotocols may be selected from the IANA WebSocket Subprotocol Name Registry or may be a custom name jointly understood by the client and the server.


Sec-WebSocket-Version
Request header
Specifies the WebSocket protocol version the client wishes to use, so the server can confirm whether or not that version is supported on its end.
httpSec-WebSocket-Version: version


version

The WebSocket protocol version the client wishes to use when communicating with the server. This number should be the most recent version possible listed in the IANA WebSocket Version Number Registry. The most recent final version of the WebSocket protocol is version 13.


Response header
If the server can't communicate using the specified version of the WebSocket protocol, it will respond with an error (such as 426 Upgrade Required) that includes in its headers a Sec-WebSocket-Version header with a comma-separated list of the supported protocol versions. If the server does support the requested protocol version, no Sec-WebSocket-Version header is included in the response.
httpSec-WebSocket-Version: supportedVersions


supportedVersions

A comma-delineated list of the WebSocket protocol versions supported by the server.

Response-only headersThe response from the server may include these.
Sec-WebSocket-Accept
Included in the response message from the server during the opening handshake process when the server is willing to initiate a WebSocket connection. It will appear no more than once in the response headers.
httpSec-WebSocket-Accept: hash


hash

If a Sec-WebSocket-Key header was provided, the value of this header is computed by taking the value of the key, concatenating the string "258EAFA5-E914-47DA-95CA-C5AB0DC85B11" to it, taking the SHA-1 hash of that concatenated string, resulting in a 20-byte value. That value is then base64 encoded to obtain the value of this property.

SpecificationsSpecificationThe WebSocket Protocol Hypertext Transfer Protocol (HTTP/1.1): Message Syntax and Routing Hypertext Transfer Protocol Version 2 (HTTP/2) See also
WebSocket API
Evolution of HTTP
Glossary terms:

HTTP
HTTP/2
QUIC\n\nProtocol upgrade mechanismThe HTTP/1.1 protocol provides a special mechanism that can be used to upgrade an already established connection to a different protocol, using the Upgrade header field.
This mechanism is optional; it cannot be used to insist on a protocol change. Implementations can choose not to take advantage of an upgrade even if they support the new protocol, and in practice, this mechanism is used mostly to bootstrap a WebSockets connection.
Note also that HTTP/2 explicitly disallows the use of this mechanism; it is specific to HTTP/1.1.Upgrading HTTP/1.1 ConnectionsThe Upgrade header field is used by clients to invite the server to switch to one of the listed protocols, in descending preference order.
Because Upgrade is a hop-by-hop header, it also needs to be listed in the Connection header field. This means that a typical request that includes Upgrade would look something like:
httpGET /index.html HTTP/1.1
Host: www.example.com
Connection: upgrade
Upgrade: example/1, foo/2

Other headers may be required depending on the requested protocol; for example, WebSocket upgrades allow additional headers to configure details about the WebSocket connection as well as to offer a degree of security in opening the connection. See Upgrading to a WebSocket connection for more details.
If the server decides to upgrade the connection, it sends back a 101 Switching Protocols response status with an Upgrade header that specifies the protocol(s) being switched to. If it does not (or cannot) upgrade the connection, it ignores the Upgrade header and sends back a regular response (for example, a 200 OK).
Right after sending the 101 status code, the server can begin speaking the new protocol, performing any additional protocol-specific handshakes as necessary. Effectively, the connection becomes a two-way pipe as soon as the upgraded response is complete, and the request that initiated the upgrade can be completed over the new protocol.Common uses for this mechanismHere we look at the most common use cases for the Upgrade header.Upgrading to a WebSocket connectionBy far, the most common use case for upgrading an HTTP connection is to use WebSockets, which are always implemented by upgrading an HTTP or HTTPS connection. Keep in mind that if you're opening a new connection using the WebSocket API, or any library that does WebSockets, most or all of this is done for you. For example, opening a WebSocket connection is a single method:
jswebSocket = new WebSocket("ws://destination.server.ext", "optionalProtocol");

The WebSocket() constructor does all the work of creating an initial HTTP/1.1 connection then handling the handshaking and upgrade process for you.

Note:
You can also use the "wss://" URL scheme to open a secure WebSocket connection.

If you need to create a WebSocket connection from scratch, you'll have to handle the handshaking process yourself. After creating the initial HTTP/1.1 session, you need to request the upgrade by adding to a standard request the Upgrade and Connection headers, as follows:
httpConnection: Upgrade
Upgrade: websocket
WebSocket-specific headersThe following headers are involved in the WebSocket upgrade process. Other than the Upgrade and Connection headers, the rest are generally optional or handled for you by the browser and server when they're talking to each other.
Sec-WebSocket-Extensions
Specifies one or more protocol-level WebSocket extensions to ask the server to use. Using more than one Sec-WebSocket-Extension header in a request is permitted; the result is the same as if you included all of the listed extensions in one such header.
httpSec-WebSocket-Extensions: extensions


extensions

A comma-separated list of extensions to request (or agree to support). These should be selected from the IANA WebSocket Extension Name Registry. Extensions which take parameters do so by using semicolon delineation.


For example:
httpSec-WebSocket-Extensions: superspeed, colormode; depth=16

Sec-WebSocket-Key
Provides information to the server which is needed in order to confirm that the client is entitled to request an upgrade to WebSocket. This header can be used when insecure (HTTP) clients wish to upgrade, in order to offer some degree of protection against abuse. The value of the key is computed using an algorithm defined in the WebSocket specification, so this does not provide security. Instead, it helps to prevent non-WebSocket clients from inadvertently, or through misuse, requesting a WebSocket connection. In essence, then, this key confirms that "Yes, I really mean to open a WebSocket connection."
This header is automatically added by clients that choose to use it; it cannot be added using the fetch() or XMLHttpRequest.setRequestHeader() methods.
httpSec-WebSocket-Key: key


key

The key for this request to upgrade. The client adds this if it wishes to do so, and the server will include in the response a key of its own, which the client will validate before delivering the upgrade response to you.


The server's response's Sec-WebSocket-Accept header will have a value computed based upon the specified key.
Sec-WebSocket-Protocol
The Sec-WebSocket-Protocol header specifies one or more WebSocket protocols that you wish to use, in order of preference. The first one that is supported by the server will be selected and returned by the server in a Sec-WebSocket-Protocol header included in the response. You can use this more than once in the header, as well; the result is the same as if you used a comma-delineated list of subprotocol identifiers in a single header.
httpSec-WebSocket-Protocol: subprotocols


subprotocols

A comma-separated list of subprotocol names, in the order of preference. The subprotocols may be selected from the IANA WebSocket Subprotocol Name Registry or may be a custom name jointly understood by the client and the server.


Sec-WebSocket-Version
Request header
Specifies the WebSocket protocol version the client wishes to use, so the server can confirm whether or not that version is supported on its end.
httpSec-WebSocket-Version: version


version

The WebSocket protocol version the client wishes to use when communicating with the server. This number should be the most recent version possible listed in the IANA WebSocket Version Number Registry. The most recent final version of the WebSocket protocol is version 13.


Response header
If the server can't communicate using the specified version of the WebSocket protocol, it will respond with an error (such as 426 Upgrade Required) that includes in its headers a Sec-WebSocket-Version header with a comma-separated list of the supported protocol versions. If the server does support the requested protocol version, no Sec-WebSocket-Version header is included in the response.
httpSec-WebSocket-Version: supportedVersions


supportedVersions

A comma-delineated list of the WebSocket protocol versions supported by the server.

Response-only headersThe response from the server may include these.
Sec-WebSocket-Accept
Included in the response message from the server during the opening handshake process when the server is willing to initiate a WebSocket connection. It will appear no more than once in the response headers.
httpSec-WebSocket-Accept: hash


hash

If a Sec-WebSocket-Key header was provided, the value of this header is computed by taking the value of the key, concatenating the string "258EAFA5-E914-47DA-95CA-C5AB0DC85B11" to it, taking the SHA-1 hash of that concatenated string, resulting in a 20-byte value. That value is then base64 encoded to obtain the value of this property.

SpecificationsSpecificationThe WebSocket Protocol Hypertext Transfer Protocol (HTTP/1.1): Message Syntax and Routing Hypertext Transfer Protocol Version 2 (HTTP/2) See also
WebSocket API
Evolution of HTTP
Glossary terms:

HTTP
HTTP/2
QUIC


Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 14, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nProtocol upgrade mechanismThe HTTP/1.1 protocol provides a special mechanism that can be used to upgrade an already established connection to a different protocol, using the Upgrade header field.
This mechanism is optional; it cannot be used to insist on a protocol change. Implementations can choose not to take advantage of an upgrade even if they support the new protocol, and in practice, this mechanism is used mostly to bootstrap a WebSockets connection.
Note also that HTTP/2 explicitly disallows the use of this mechanism; it is specific to HTTP/1.1.Upgrading HTTP/1.1 ConnectionsThe Upgrade header field is used by clients to invite the server to switch to one of the listed protocols, in descending preference order.
Because Upgrade is a hop-by-hop header, it also needs to be listed in the Connection header field. This means that a typical request that includes Upgrade would look something like:
httpGET /index.html HTTP/1.1
Host: www.example.com
Connection: upgrade
Upgrade: example/1, foo/2

Other headers may be required depending on the requested protocol; for example, WebSocket upgrades allow additional headers to configure details about the WebSocket connection as well as to offer a degree of security in opening the connection. See Upgrading to a WebSocket connection for more details.
If the server decides to upgrade the connection, it sends back a 101 Switching Protocols response status with an Upgrade header that specifies the protocol(s) being switched to. If it does not (or cannot) upgrade the connection, it ignores the Upgrade header and sends back a regular response (for example, a 200 OK).
Right after sending the 101 status code, the server can begin speaking the new protocol, performing any additional protocol-specific handshakes as necessary. Effectively, the connection becomes a two-way pipe as soon as the upgraded response is complete, and the request that initiated the upgrade can be completed over the new protocol.Common uses for this mechanismHere we look at the most common use cases for the Upgrade header.Upgrading to a WebSocket connectionBy far, the most common use case for upgrading an HTTP connection is to use WebSockets, which are always implemented by upgrading an HTTP or HTTPS connection. Keep in mind that if you're opening a new connection using the WebSocket API, or any library that does WebSockets, most or all of this is done for you. For example, opening a WebSocket connection is a single method:
jswebSocket = new WebSocket("ws://destination.server.ext", "optionalProtocol");

The WebSocket() constructor does all the work of creating an initial HTTP/1.1 connection then handling the handshaking and upgrade process for you.

Note:
You can also use the "wss://" URL scheme to open a secure WebSocket connection.

If you need to create a WebSocket connection from scratch, you'll have to handle the handshaking process yourself. After creating the initial HTTP/1.1 session, you need to request the upgrade by adding to a standard request the Upgrade and Connection headers, as follows:
httpConnection: Upgrade
Upgrade: websocket
WebSocket-specific headersThe following headers are involved in the WebSocket upgrade process. Other than the Upgrade and Connection headers, the rest are generally optional or handled for you by the browser and server when they're talking to each other.
Sec-WebSocket-Extensions
Specifies one or more protocol-level WebSocket extensions to ask the server to use. Using more than one Sec-WebSocket-Extension header in a request is permitted; the result is the same as if you included all of the listed extensions in one such header.
httpSec-WebSocket-Extensions: extensions


extensions

A comma-separated list of extensions to request (or agree to support). These should be selected from the IANA WebSocket Extension Name Registry. Extensions which take parameters do so by using semicolon delineation.


For example:
httpSec-WebSocket-Extensions: superspeed, colormode; depth=16

Sec-WebSocket-Key
Provides information to the server which is needed in order to confirm that the client is entitled to request an upgrade to WebSocket. This header can be used when insecure (HTTP) clients wish to upgrade, in order to offer some degree of protection against abuse. The value of the key is computed using an algorithm defined in the WebSocket specification, so this does not provide security. Instead, it helps to prevent non-WebSocket clients from inadvertently, or through misuse, requesting a WebSocket connection. In essence, then, this key confirms that "Yes, I really mean to open a WebSocket connection."
This header is automatically added by clients that choose to use it; it cannot be added using the fetch() or XMLHttpRequest.setRequestHeader() methods.
httpSec-WebSocket-Key: key


key

The key for this request to upgrade. The client adds this if it wishes to do so, and the server will include in the response a key of its own, which the client will validate before delivering the upgrade response to you.


The server's response's Sec-WebSocket-Accept header will have a value computed based upon the specified key.
Sec-WebSocket-Protocol
The Sec-WebSocket-Protocol header specifies one or more WebSocket protocols that you wish to use, in order of preference. The first one that is supported by the server will be selected and returned by the server in a Sec-WebSocket-Protocol header included in the response. You can use this more than once in the header, as well; the result is the same as if you used a comma-delineated list of subprotocol identifiers in a single header.
httpSec-WebSocket-Protocol: subprotocols


subprotocols

A comma-separated list of subprotocol names, in the order of preference. The subprotocols may be selected from the IANA WebSocket Subprotocol Name Registry or may be a custom name jointly understood by the client and the server.


Sec-WebSocket-Version
Request header
Specifies the WebSocket protocol version the client wishes to use, so the server can confirm whether or not that version is supported on its end.
httpSec-WebSocket-Version: version


version

The WebSocket protocol version the client wishes to use when communicating with the server. This number should be the most recent version possible listed in the IANA WebSocket Version Number Registry. The most recent final version of the WebSocket protocol is version 13.


Response header
If the server can't communicate using the specified version of the WebSocket protocol, it will respond with an error (such as 426 Upgrade Required) that includes in its headers a Sec-WebSocket-Version header with a comma-separated list of the supported protocol versions. If the server does support the requested protocol version, no Sec-WebSocket-Version header is included in the response.
httpSec-WebSocket-Version: supportedVersions


supportedVersions

A comma-delineated list of the WebSocket protocol versions supported by the server.

Response-only headersThe response from the server may include these.
Sec-WebSocket-Accept
Included in the response message from the server during the opening handshake process when the server is willing to initiate a WebSocket connection. It will appear no more than once in the response headers.
httpSec-WebSocket-Accept: hash


hash

If a Sec-WebSocket-Key header was provided, the value of this header is computed by taking the value of the key, concatenating the string "258EAFA5-E914-47DA-95CA-C5AB0DC85B11" to it, taking the SHA-1 hash of that concatenated string, resulting in a 20-byte value. That value is then base64 encoded to obtain the value of this property.

SpecificationsSpecificationThe WebSocket Protocol Hypertext Transfer Protocol (HTTP/1.1): Message Syntax and Routing Hypertext Transfer Protocol Version 2 (HTTP/2) See also
WebSocket API
Evolution of HTTP
Glossary terms:

HTTP
HTTP/2
QUIC


Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 14, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nProxy servers and tunnelingWhen navigating through different networks of the Internet, proxy servers and HTTP tunnels are facilitating access to content on the World Wide Web. A proxy can be on the user's local computer, or anywhere between the user's computer and a destination server on the Internet. This page outlines some basics about proxies and introduces a few configuration options.
There are two types of proxies: forward proxies (or tunnel, or gateway) and reverse proxies (used to control and protect access to a server for load-balancing, authentication, decryption or caching).Forward proxiesA forward proxy, or gateway, or just "proxy" provides proxy services to a client or a group of clients. There are likely hundreds of thousands of open forward proxies on the Internet. They store and forward Internet services (like the DNS, or web pages) to reduce and control the bandwidth used by the group.
Forward proxies can also be anonymous and allow users to hide their IP address while browsing the Web or using other Internet services. For example, Tor routes internet traffic through multiple proxies for anonymity.Reverse proxiesAs the name implies, a reverse proxy does the opposite of what a forward proxy does: A forward proxy acts on behalf of clients (or requesting hosts). Forward proxies can hide the identities of clients whereas reverse proxies can hide the identities of servers. Reverse proxies have several use cases, a few are:

Load balancing: distribute the load to several web servers,
Cache static content: offload the web servers by caching static content like pictures,
Compression: compress and optimize content to speed up load time.
Forwarding client information through proxiesProxies can make requests appear as if they originated from the proxy's IP address. This can be useful if a proxy is used to provide client anonymity, but in other cases information from the original request is lost. The IP address of the original client is often used for debugging, statistics, or generating location-dependent content. A common way to disclose this information is by using the following HTTP headers:
The standardized header:

Forwarded

Contains information from the client-facing side of proxy servers that is altered or lost when a proxy is involved in the path of the request.


Or the de-facto standard versions:

X-Forwarded-For 
Non-standard


Identifies the originating IP addresses of a client connecting to a web server through an HTTP proxy or a load balancer.

X-Forwarded-Host 
Non-standard


Identifies the original host requested that a client used to connect to your proxy or load balancer.

X-Forwarded-Proto 
Non-standard


identifies the protocol (HTTP or HTTPS) that a client used to connect to your proxy or load balancer.


To provide information about the proxy itself (not about the client connecting to it), the Via header can be used.

Via

Added by proxies, both forward and reverse proxies, and can appear in the request headers and the response headers.

HTTP tunnelingTunneling transmits private network data and protocol information through public network by encapsulating the data. HTTP tunneling is using a protocol of higher level (HTTP) to transport a lower level protocol (TCP).
The HTTP protocol specifies a request method called CONNECT. It starts two-way communications with the requested resource and can be used to open a tunnel. This is how a client behind an HTTP proxy can access websites using TLS (i.e., HTTPS, port 443). Note, however, that not all proxy servers support the CONNECT method or limit it to port 443 only.
See also the HTTP tunnel article on Wikipedia.Proxy Auto-Configuration (PAC)A Proxy Auto-Configuration (PAC) file is a JavaScript function that determines whether web browser requests (HTTP, HTTPS, and FTP) go directly to the destination or are forwarded to a web proxy server. The JavaScript function contained in the PAC file defines the function:
The auto-config file should be saved to a file with a .pac filename extension: proxy.pac.
And the MIME type set to application/x-ns-proxy-autoconfig.
The file consists of a function called FindProxyForURL. The example below will work in an environment where the internal DNS server is set up so that it can only resolve internal host names, and the goal is to use a proxy only for hosts that aren't resolvable:
jsfunction FindProxyForURL(url, host) {
  if (isResolvable(host)) {
    return "DIRECT";
  }
  return "PROXY proxy.mydomain.com:8080";
}
See also
Proxy Auto-Configuration (PAC) file
CONNECT method
Proxy server\n\nProxy servers and tunnelingWhen navigating through different networks of the Internet, proxy servers and HTTP tunnels are facilitating access to content on the World Wide Web. A proxy can be on the user's local computer, or anywhere between the user's computer and a destination server on the Internet. This page outlines some basics about proxies and introduces a few configuration options.
There are two types of proxies: forward proxies (or tunnel, or gateway) and reverse proxies (used to control and protect access to a server for load-balancing, authentication, decryption or caching).Forward proxiesA forward proxy, or gateway, or just "proxy" provides proxy services to a client or a group of clients. There are likely hundreds of thousands of open forward proxies on the Internet. They store and forward Internet services (like the DNS, or web pages) to reduce and control the bandwidth used by the group.
Forward proxies can also be anonymous and allow users to hide their IP address while browsing the Web or using other Internet services. For example, Tor routes internet traffic through multiple proxies for anonymity.Reverse proxiesAs the name implies, a reverse proxy does the opposite of what a forward proxy does: A forward proxy acts on behalf of clients (or requesting hosts). Forward proxies can hide the identities of clients whereas reverse proxies can hide the identities of servers. Reverse proxies have several use cases, a few are:

Load balancing: distribute the load to several web servers,
Cache static content: offload the web servers by caching static content like pictures,
Compression: compress and optimize content to speed up load time.
Forwarding client information through proxiesProxies can make requests appear as if they originated from the proxy's IP address. This can be useful if a proxy is used to provide client anonymity, but in other cases information from the original request is lost. The IP address of the original client is often used for debugging, statistics, or generating location-dependent content. A common way to disclose this information is by using the following HTTP headers:
The standardized header:

Forwarded

Contains information from the client-facing side of proxy servers that is altered or lost when a proxy is involved in the path of the request.


Or the de-facto standard versions:

X-Forwarded-For 
Non-standard


Identifies the originating IP addresses of a client connecting to a web server through an HTTP proxy or a load balancer.

X-Forwarded-Host 
Non-standard


Identifies the original host requested that a client used to connect to your proxy or load balancer.

X-Forwarded-Proto 
Non-standard


identifies the protocol (HTTP or HTTPS) that a client used to connect to your proxy or load balancer.


To provide information about the proxy itself (not about the client connecting to it), the Via header can be used.

Via

Added by proxies, both forward and reverse proxies, and can appear in the request headers and the response headers.

HTTP tunnelingTunneling transmits private network data and protocol information through public network by encapsulating the data. HTTP tunneling is using a protocol of higher level (HTTP) to transport a lower level protocol (TCP).
The HTTP protocol specifies a request method called CONNECT. It starts two-way communications with the requested resource and can be used to open a tunnel. This is how a client behind an HTTP proxy can access websites using TLS (i.e., HTTPS, port 443). Note, however, that not all proxy servers support the CONNECT method or limit it to port 443 only.
See also the HTTP tunnel article on Wikipedia.Proxy Auto-Configuration (PAC)A Proxy Auto-Configuration (PAC) file is a JavaScript function that determines whether web browser requests (HTTP, HTTPS, and FTP) go directly to the destination or are forwarded to a web proxy server. The JavaScript function contained in the PAC file defines the function:
The auto-config file should be saved to a file with a .pac filename extension: proxy.pac.
And the MIME type set to application/x-ns-proxy-autoconfig.
The file consists of a function called FindProxyForURL. The example below will work in an environment where the internal DNS server is set up so that it can only resolve internal host names, and the goal is to use a proxy only for hosts that aren't resolvable:
jsfunction FindProxyForURL(url, host) {
  if (isResolvable(host)) {
    return "DIRECT";
  }
  return "PROXY proxy.mydomain.com:8080";
}
See also
Proxy Auto-Configuration (PAC) file
CONNECT method
Proxy server
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Apr 3, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nProxy servers and tunnelingWhen navigating through different networks of the Internet, proxy servers and HTTP tunnels are facilitating access to content on the World Wide Web. A proxy can be on the user's local computer, or anywhere between the user's computer and a destination server on the Internet. This page outlines some basics about proxies and introduces a few configuration options.
There are two types of proxies: forward proxies (or tunnel, or gateway) and reverse proxies (used to control and protect access to a server for load-balancing, authentication, decryption or caching).Forward proxiesA forward proxy, or gateway, or just "proxy" provides proxy services to a client or a group of clients. There are likely hundreds of thousands of open forward proxies on the Internet. They store and forward Internet services (like the DNS, or web pages) to reduce and control the bandwidth used by the group.
Forward proxies can also be anonymous and allow users to hide their IP address while browsing the Web or using other Internet services. For example, Tor routes internet traffic through multiple proxies for anonymity.Reverse proxiesAs the name implies, a reverse proxy does the opposite of what a forward proxy does: A forward proxy acts on behalf of clients (or requesting hosts). Forward proxies can hide the identities of clients whereas reverse proxies can hide the identities of servers. Reverse proxies have several use cases, a few are:

Load balancing: distribute the load to several web servers,
Cache static content: offload the web servers by caching static content like pictures,
Compression: compress and optimize content to speed up load time.
Forwarding client information through proxiesProxies can make requests appear as if they originated from the proxy's IP address. This can be useful if a proxy is used to provide client anonymity, but in other cases information from the original request is lost. The IP address of the original client is often used for debugging, statistics, or generating location-dependent content. A common way to disclose this information is by using the following HTTP headers:
The standardized header:

Forwarded

Contains information from the client-facing side of proxy servers that is altered or lost when a proxy is involved in the path of the request.


Or the de-facto standard versions:

X-Forwarded-For 
Non-standard


Identifies the originating IP addresses of a client connecting to a web server through an HTTP proxy or a load balancer.

X-Forwarded-Host 
Non-standard


Identifies the original host requested that a client used to connect to your proxy or load balancer.

X-Forwarded-Proto 
Non-standard


identifies the protocol (HTTP or HTTPS) that a client used to connect to your proxy or load balancer.


To provide information about the proxy itself (not about the client connecting to it), the Via header can be used.

Via

Added by proxies, both forward and reverse proxies, and can appear in the request headers and the response headers.

HTTP tunnelingTunneling transmits private network data and protocol information through public network by encapsulating the data. HTTP tunneling is using a protocol of higher level (HTTP) to transport a lower level protocol (TCP).
The HTTP protocol specifies a request method called CONNECT. It starts two-way communications with the requested resource and can be used to open a tunnel. This is how a client behind an HTTP proxy can access websites using TLS (i.e., HTTPS, port 443). Note, however, that not all proxy servers support the CONNECT method or limit it to port 443 only.
See also the HTTP tunnel article on Wikipedia.Proxy Auto-Configuration (PAC)A Proxy Auto-Configuration (PAC) file is a JavaScript function that determines whether web browser requests (HTTP, HTTPS, and FTP) go directly to the destination or are forwarded to a web proxy server. The JavaScript function contained in the PAC file defines the function:
The auto-config file should be saved to a file with a .pac filename extension: proxy.pac.
And the MIME type set to application/x-ns-proxy-autoconfig.
The file consists of a function called FindProxyForURL. The example below will work in an environment where the internal DNS server is set up so that it can only resolve internal host names, and the goal is to use a proxy only for hosts that aren't resolvable:
jsfunction FindProxyForURL(url, host) {
  if (isResolvable(host)) {
    return "DIRECT";
  }
  return "PROXY proxy.mydomain.com:8080";
}
See also
Proxy Auto-Configuration (PAC) file
CONNECT method
Proxy server
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Apr 3, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nHTTP Client hintsClient hints are a set of HTTP request header fields that a server can proactively request from a client to get information about the device, network, user, and user-agent-specific preferences.
The server can determine which resources to send, based on the information that the client chooses to provide.
The set of "hint" headers are listed in the topic HTTP Headers and summarized below.OverviewA server must announce that it supports client hints, using the Accept-CH header to specify the hints that it is interested in receiving.
When a client that supports client hints receives the Accept-CH header it can choose to append some or all of the listed client hint headers in its subsequent requests.
For example, following Accept-CH in a response below, the client could append Width, Downlink and Sec-CH-UA headers to all subsequent requests.
httpAccept-CH: Width, Downlink, Sec-CH-UA

This approach is efficient in that the server only requests the information that it is able to usefully handle.
It is also relatively "privacy-preserving", in that it is up to the client to decide what information it can safely share.
There is a small set of low entropy client hint headers that may be sent by a client even if not requested.

Note:
Client hints can also be specified in HTML using the <meta> element with the http-equiv attribute.
html<meta http-equiv="Accept-CH" content="Width, Downlink, Sec-CH-UA" />

Caching and Client HintsClient hints that determine which resources are sent in responses should generally also be included in the affected response's Vary header.
This ensures that a different resource is cached for every different value of the hint header.
httpVary: Accept, Width, ECT

You may prefer to omit specifying Vary or use some other strategy for client hint headers where the value changes a lot, as this effectively makes the resource uncacheable. (A new cache entry is created for every unique value.)
This applies in particular to network client hints like Downlink and RTT.
For more information see HTTP Caching > Vary.Hint life-timeA server specifies the client hint headers that it is interested in getting in the Accept-CH response header.
The user agent appends the requested client hint headers, or at least the subset that it wants to share with that server, to all subsequent requests in the current browsing session.
In other words, the request for a specific set of hints does not expire until the browser is shut down.
A server can replace the set of client hints it is interested in receiving by resending the Accept-CH response header with a new list.
For example, to stop requesting any hints it would send Accept-CH with an empty list.

Note:
The client hints set for a particular origin can also be cleared by sending a Clear-Site-Data: "clientHints" response header for a URL inside that origin.
Low entropy hintsClient hints are broadly divided into high and low entropy hints.
The low entropy hints are those that don't give away much information that might be used to create a fingerprinting for a user.
They may be sent by default on every client request, irrespective of the server Accept-CH response header, depending on the permission policy.
Low entropy hints are:

Save-Data,
Sec-CH-UA,
Sec-CH-UA-Mobile, and
Sec-CH-UA-Platform.
High entropy hintsThe high entropy hints are those that have the potential to give away more information that can be used for user fingerprinting, and therefore are gated in such a way that the user agent can make a decision whether to provide them.
The decision might be based on user preferences, a permission request, or the permission policy.
All client hints that are not low entropy hints are considered high entropy hints.Critical client hintsA critical client hint is one where applying the response may significantly change the rendered page, potentially in a way that is jarring or will affect usability, and therefore which must be applied before the content is rendered.
For example, Sec-CH-Prefers-Reduced-Motion is commonly treated as a critical hint, because it might markedly affect the behavior of animations, and because a user who chooses this preference needs it to be set.
A server can use the Critical-CH response header along with Accept-CH to specify that an accepted client hint is also a critical client hint (a header in Critical-CH must also appear in Accept-CH).
User agents receiving a response with Critical-CH must check if the indicated critical headers were sent in the original request. If not, then the user agent will retry the request rather than render the page.
This approach ensures that client preferences set using critical client hints are always used, even if not included in the first request, or if the server configuration changes.
For example, in this case, the server tells a client via Accept-CH that it accepts Sec-CH-Prefers-Reduced-Motion, and Critical-CH is used to specify that Sec-CH-Prefers-Reduced-Motion is considered a critical client hint:
httpHTTP/1.1 200 OK
Content-Type: text/html
Accept-CH: Sec-CH-Prefers-Reduced-Motion
Vary: Sec-CH-Prefers-Reduced-Motion
Critical-CH: Sec-CH-Prefers-Reduced-Motion


Note:
We've also specified Sec-CH-Prefers-Reduced-Motion in the Vary header to indicate to the browser that the served content will differ based on this header value, even if the URL stays the same, so the browser shouldn't just use an existing cached response and instead should cache this response separately. Each header listed in the Critical-CH header should also be present in the Accept-CH and Vary headers.

As Sec-CH-Prefers-Reduced-Motion is a critical hint that was not in the original request, the client automatically retries the request — this time telling the server via Sec-CH-Prefers-Reduced-Motion that it has a user preference for reduced-motion animations.
httpGET / HTTP/1.1
Host: example.com
Sec-CH-Prefers-Reduced-Motion: "reduce"
Hint typesUser agent client hintsUser agent (UA) client hint headers allow a server to vary responses based on the user agent (browser), operating system, and device.
For a list of Sec-CH-UA-* headers, see User agent client hints headers.
Client hints are available to web page JavaScript via the User Agent Client Hints API.

Note:
Servers currently get most of the same information by parsing the User-Agent header.
For historical reasons this header contains a lot of largely irrelevant information, and information that might be used to identify a particular user.
UA client hints provide a more efficient and privacy preserving way of getting the desired information.
They are eventually expected to replace this older approach.


Note:
User-agent client hints are not available inside fenced frames because they rely on permissions policy delegation, which could be used to leak data.
User preference media features client hintsUser Preference Media Features Client Hints allow a server to vary responses based on a user agent's preferences for CSS media features such as color scheme or reduced motion.
Headers include: Sec-CH-Prefers-Reduced-Motion, Sec-CH-Prefers-Color-Scheme.Device client hintsDevice client hints allow a server to vary responses based on device characteristics including available memory and screen properties.
Headers include: Device-Memory, Width, Viewport-Width.Network client hintsNetwork client hints allow a server to vary responses based on the user's choice, network bandwidth, and latency.
Headers include: Save-Data, Downlink, ECT, RTT.See also
Client Hints headers
Vary HTTP Header
Client Hints Infrastructure
User Agent Client Hints API
Improving user privacy and developer experience with User-Agent Client Hints (developer.chrome.com)\n\nHTTP Client hintsClient hints are a set of HTTP request header fields that a server can proactively request from a client to get information about the device, network, user, and user-agent-specific preferences.
The server can determine which resources to send, based on the information that the client chooses to provide.
The set of "hint" headers are listed in the topic HTTP Headers and summarized below.OverviewA server must announce that it supports client hints, using the Accept-CH header to specify the hints that it is interested in receiving.
When a client that supports client hints receives the Accept-CH header it can choose to append some or all of the listed client hint headers in its subsequent requests.
For example, following Accept-CH in a response below, the client could append Width, Downlink and Sec-CH-UA headers to all subsequent requests.
httpAccept-CH: Width, Downlink, Sec-CH-UA

This approach is efficient in that the server only requests the information that it is able to usefully handle.
It is also relatively "privacy-preserving", in that it is up to the client to decide what information it can safely share.
There is a small set of low entropy client hint headers that may be sent by a client even if not requested.

Note:
Client hints can also be specified in HTML using the <meta> element with the http-equiv attribute.
html<meta http-equiv="Accept-CH" content="Width, Downlink, Sec-CH-UA" />

Caching and Client HintsClient hints that determine which resources are sent in responses should generally also be included in the affected response's Vary header.
This ensures that a different resource is cached for every different value of the hint header.
httpVary: Accept, Width, ECT

You may prefer to omit specifying Vary or use some other strategy for client hint headers where the value changes a lot, as this effectively makes the resource uncacheable. (A new cache entry is created for every unique value.)
This applies in particular to network client hints like Downlink and RTT.
For more information see HTTP Caching > Vary.Hint life-timeA server specifies the client hint headers that it is interested in getting in the Accept-CH response header.
The user agent appends the requested client hint headers, or at least the subset that it wants to share with that server, to all subsequent requests in the current browsing session.
In other words, the request for a specific set of hints does not expire until the browser is shut down.
A server can replace the set of client hints it is interested in receiving by resending the Accept-CH response header with a new list.
For example, to stop requesting any hints it would send Accept-CH with an empty list.

Note:
The client hints set for a particular origin can also be cleared by sending a Clear-Site-Data: "clientHints" response header for a URL inside that origin.
Low entropy hintsClient hints are broadly divided into high and low entropy hints.
The low entropy hints are those that don't give away much information that might be used to create a fingerprinting for a user.
They may be sent by default on every client request, irrespective of the server Accept-CH response header, depending on the permission policy.
Low entropy hints are:

Save-Data,
Sec-CH-UA,
Sec-CH-UA-Mobile, and
Sec-CH-UA-Platform.
High entropy hintsThe high entropy hints are those that have the potential to give away more information that can be used for user fingerprinting, and therefore are gated in such a way that the user agent can make a decision whether to provide them.
The decision might be based on user preferences, a permission request, or the permission policy.
All client hints that are not low entropy hints are considered high entropy hints.Critical client hintsA critical client hint is one where applying the response may significantly change the rendered page, potentially in a way that is jarring or will affect usability, and therefore which must be applied before the content is rendered.
For example, Sec-CH-Prefers-Reduced-Motion is commonly treated as a critical hint, because it might markedly affect the behavior of animations, and because a user who chooses this preference needs it to be set.
A server can use the Critical-CH response header along with Accept-CH to specify that an accepted client hint is also a critical client hint (a header in Critical-CH must also appear in Accept-CH).
User agents receiving a response with Critical-CH must check if the indicated critical headers were sent in the original request. If not, then the user agent will retry the request rather than render the page.
This approach ensures that client preferences set using critical client hints are always used, even if not included in the first request, or if the server configuration changes.
For example, in this case, the server tells a client via Accept-CH that it accepts Sec-CH-Prefers-Reduced-Motion, and Critical-CH is used to specify that Sec-CH-Prefers-Reduced-Motion is considered a critical client hint:
httpHTTP/1.1 200 OK
Content-Type: text/html
Accept-CH: Sec-CH-Prefers-Reduced-Motion
Vary: Sec-CH-Prefers-Reduced-Motion
Critical-CH: Sec-CH-Prefers-Reduced-Motion


Note:
We've also specified Sec-CH-Prefers-Reduced-Motion in the Vary header to indicate to the browser that the served content will differ based on this header value, even if the URL stays the same, so the browser shouldn't just use an existing cached response and instead should cache this response separately. Each header listed in the Critical-CH header should also be present in the Accept-CH and Vary headers.

As Sec-CH-Prefers-Reduced-Motion is a critical hint that was not in the original request, the client automatically retries the request — this time telling the server via Sec-CH-Prefers-Reduced-Motion that it has a user preference for reduced-motion animations.
httpGET / HTTP/1.1
Host: example.com
Sec-CH-Prefers-Reduced-Motion: "reduce"
Hint typesUser agent client hintsUser agent (UA) client hint headers allow a server to vary responses based on the user agent (browser), operating system, and device.
For a list of Sec-CH-UA-* headers, see User agent client hints headers.
Client hints are available to web page JavaScript via the User Agent Client Hints API.

Note:
Servers currently get most of the same information by parsing the User-Agent header.
For historical reasons this header contains a lot of largely irrelevant information, and information that might be used to identify a particular user.
UA client hints provide a more efficient and privacy preserving way of getting the desired information.
They are eventually expected to replace this older approach.


Note:
User-agent client hints are not available inside fenced frames because they rely on permissions policy delegation, which could be used to leak data.
User preference media features client hintsUser Preference Media Features Client Hints allow a server to vary responses based on a user agent's preferences for CSS media features such as color scheme or reduced motion.
Headers include: Sec-CH-Prefers-Reduced-Motion, Sec-CH-Prefers-Color-Scheme.Device client hintsDevice client hints allow a server to vary responses based on device characteristics including available memory and screen properties.
Headers include: Device-Memory, Width, Viewport-Width.Network client hintsNetwork client hints allow a server to vary responses based on the user's choice, network bandwidth, and latency.
Headers include: Save-Data, Downlink, ECT, RTT.See also
Client Hints headers
Vary HTTP Header
Client Hints Infrastructure
User Agent Client Hints API
Improving user privacy and developer experience with User-Agent Client Hints (developer.chrome.com)
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Apr 10, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nHTTP Client hintsClient hints are a set of HTTP request header fields that a server can proactively request from a client to get information about the device, network, user, and user-agent-specific preferences.
The server can determine which resources to send, based on the information that the client chooses to provide.
The set of "hint" headers are listed in the topic HTTP Headers and summarized below.OverviewA server must announce that it supports client hints, using the Accept-CH header to specify the hints that it is interested in receiving.
When a client that supports client hints receives the Accept-CH header it can choose to append some or all of the listed client hint headers in its subsequent requests.
For example, following Accept-CH in a response below, the client could append Width, Downlink and Sec-CH-UA headers to all subsequent requests.
httpAccept-CH: Width, Downlink, Sec-CH-UA

This approach is efficient in that the server only requests the information that it is able to usefully handle.
It is also relatively "privacy-preserving", in that it is up to the client to decide what information it can safely share.
There is a small set of low entropy client hint headers that may be sent by a client even if not requested.

Note:
Client hints can also be specified in HTML using the <meta> element with the http-equiv attribute.
html<meta http-equiv="Accept-CH" content="Width, Downlink, Sec-CH-UA" />

Caching and Client HintsClient hints that determine which resources are sent in responses should generally also be included in the affected response's Vary header.
This ensures that a different resource is cached for every different value of the hint header.
httpVary: Accept, Width, ECT

You may prefer to omit specifying Vary or use some other strategy for client hint headers where the value changes a lot, as this effectively makes the resource uncacheable. (A new cache entry is created for every unique value.)
This applies in particular to network client hints like Downlink and RTT.
For more information see HTTP Caching > Vary.Hint life-timeA server specifies the client hint headers that it is interested in getting in the Accept-CH response header.
The user agent appends the requested client hint headers, or at least the subset that it wants to share with that server, to all subsequent requests in the current browsing session.
In other words, the request for a specific set of hints does not expire until the browser is shut down.
A server can replace the set of client hints it is interested in receiving by resending the Accept-CH response header with a new list.
For example, to stop requesting any hints it would send Accept-CH with an empty list.

Note:
The client hints set for a particular origin can also be cleared by sending a Clear-Site-Data: "clientHints" response header for a URL inside that origin.
Low entropy hintsClient hints are broadly divided into high and low entropy hints.
The low entropy hints are those that don't give away much information that might be used to create a fingerprinting for a user.
They may be sent by default on every client request, irrespective of the server Accept-CH response header, depending on the permission policy.
Low entropy hints are:

Save-Data,
Sec-CH-UA,
Sec-CH-UA-Mobile, and
Sec-CH-UA-Platform.
High entropy hintsThe high entropy hints are those that have the potential to give away more information that can be used for user fingerprinting, and therefore are gated in such a way that the user agent can make a decision whether to provide them.
The decision might be based on user preferences, a permission request, or the permission policy.
All client hints that are not low entropy hints are considered high entropy hints.Critical client hintsA critical client hint is one where applying the response may significantly change the rendered page, potentially in a way that is jarring or will affect usability, and therefore which must be applied before the content is rendered.
For example, Sec-CH-Prefers-Reduced-Motion is commonly treated as a critical hint, because it might markedly affect the behavior of animations, and because a user who chooses this preference needs it to be set.
A server can use the Critical-CH response header along with Accept-CH to specify that an accepted client hint is also a critical client hint (a header in Critical-CH must also appear in Accept-CH).
User agents receiving a response with Critical-CH must check if the indicated critical headers were sent in the original request. If not, then the user agent will retry the request rather than render the page.
This approach ensures that client preferences set using critical client hints are always used, even if not included in the first request, or if the server configuration changes.
For example, in this case, the server tells a client via Accept-CH that it accepts Sec-CH-Prefers-Reduced-Motion, and Critical-CH is used to specify that Sec-CH-Prefers-Reduced-Motion is considered a critical client hint:
httpHTTP/1.1 200 OK
Content-Type: text/html
Accept-CH: Sec-CH-Prefers-Reduced-Motion
Vary: Sec-CH-Prefers-Reduced-Motion
Critical-CH: Sec-CH-Prefers-Reduced-Motion


Note:
We've also specified Sec-CH-Prefers-Reduced-Motion in the Vary header to indicate to the browser that the served content will differ based on this header value, even if the URL stays the same, so the browser shouldn't just use an existing cached response and instead should cache this response separately. Each header listed in the Critical-CH header should also be present in the Accept-CH and Vary headers.

As Sec-CH-Prefers-Reduced-Motion is a critical hint that was not in the original request, the client automatically retries the request — this time telling the server via Sec-CH-Prefers-Reduced-Motion that it has a user preference for reduced-motion animations.
httpGET / HTTP/1.1
Host: example.com
Sec-CH-Prefers-Reduced-Motion: "reduce"
Hint typesUser agent client hintsUser agent (UA) client hint headers allow a server to vary responses based on the user agent (browser), operating system, and device.
For a list of Sec-CH-UA-* headers, see User agent client hints headers.
Client hints are available to web page JavaScript via the User Agent Client Hints API.

Note:
Servers currently get most of the same information by parsing the User-Agent header.
For historical reasons this header contains a lot of largely irrelevant information, and information that might be used to identify a particular user.
UA client hints provide a more efficient and privacy preserving way of getting the desired information.
They are eventually expected to replace this older approach.


Note:
User-agent client hints are not available inside fenced frames because they rely on permissions policy delegation, which could be used to leak data.
User preference media features client hintsUser Preference Media Features Client Hints allow a server to vary responses based on a user agent's preferences for CSS media features such as color scheme or reduced motion.
Headers include: Sec-CH-Prefers-Reduced-Motion, Sec-CH-Prefers-Color-Scheme.Device client hintsDevice client hints allow a server to vary responses based on device characteristics including available memory and screen properties.
Headers include: Device-Memory, Width, Viewport-Width.Network client hintsNetwork client hints allow a server to vary responses based on the user's choice, network bandwidth, and latency.
Headers include: Save-Data, Downlink, ECT, RTT.See also
Client Hints headers
Vary HTTP Header
Client Hints Infrastructure
User Agent Client Hints API
Improving user privacy and developer experience with User-Agent Client Hints (developer.chrome.com)
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Apr 10, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nPractical security implementation guidesUsers frequently input sensitive data on websites, such as names, addresses, passwords, and banking details. As a web developer, it's crucial to protect this information from bad actors who use a wide range of exploits to steal such information and use it for personal gain. The focus of web security is to help you protect your website against these exploits and secure your users' sensitive data.
This page lists guides that summarize some best practices for implementing security features on websites. While these guides do not cover all possible security scenarios and cannot guarantee complete security of your website, following the information and best practices in these guides will make your sites significantly more secure.HTTP security fundamentalsThe guides in this section summarize best practices for implementing HTTP headers correctly to mitigate security issues, and are directly related to the HTTP Observatory tool.
Observatory performs security audits on a website and provides a grade and score along with recommendations for fixing the security issues it finds. These guides explain how to resolve issues surfaced by the HTTP Observatory tests: the tool links to the relevant guide for each issue, helping guide you towards an effective resolution. Interestingly, Mozilla's internal developer teams use this guidance when implementing websites to ensure that security best practices are applied.
The guides in the table below are listed in the order that we recommend implementing the security features they describe. This order is based on a combination of each feature's security impact and the ease of its implementation from both operational and developmental perspectives. The table provides information about each feature's impact, difficulty of implementation, whether or not it is required, and a brief description.



Guide
Impact
Difficulty
Required
Description




TLS configuration
Medium
Medium
Yes
Use the most secure Transport Layer Security (TLS) configuration available for your user base.


TLS: Resource loading
Maximum
Low
Yes
Load both passive and active resources via HTTPS.


TLS: HTTP redirection
Maximum
Low
Yes
Websites must redirect to HTTPS; API endpoints should disable HTTP entirely.


TLS: HSTS implementation
High
Low
Yes
Notify user agents to connect to sites only over HTTPS, even if the original scheme chosen was HTTP, by using HTTP Strict transport security (HSTS).


Clickjacking prevention
High
Low
Yes
Control how your site may be framed within an <iframe> to prevent clickjacking.


CSRF prevention
High
Unknown
Varies
Protect against Cross-site request forgery (CSRF) using SameSite cookies and anti-CSRF tokens.


Secure cookie configuration
High
Medium
Yes
Set all cookies as restrictively as possible.


CORP implementation
High
Medium
Yes
Protect against speculative side-channel attacks by using Cross-Origin Resource Policy (CORP).


MIME type verification
Low
Low
No
Verify that all your websites are setting the proper MIME types for all resources.


CSP implementation
High
High
Yes
Provide fine-grained control over the code that can be loaded on a site and what it is allowed to do with a Content Security Policy (CSP), thereby mitigating Cross-site scripting (XSS) vulnerabilities.


CORS configuration
High
Low
Yes
Define the non-same origins that are allowed to access the content of pages and have resources loaded from them by using Cross-Origin Resource Sharing (CORS).


Referrer policy configuration
Low
Low
Yes
Improve privacy for users and prevent leaking of internal URLs via the Referer header.


robots.txt configuration
Low
Low
No
Tell robots (such as search engine indexers) how to behave by instructing them not to crawl certain paths on the website.


SRI implementation
Low
Low
No
Verify that fetched resources (for example, from a CDN) are delivered without unexpected manipulation by using Subresource Integrity (SRI).


User information security
How to turn off form autocompletion

Form fields support autocompletion; that is, their values can be remembered and automatically filled out next time a user visits your site. For certain types of data, you may wish to disable this feature; this article explains how.

See also
Open Web Application Security Project (OWASP): Cheatsheet series
OWASP: Attacks\n\nPractical security implementation guidesUsers frequently input sensitive data on websites, such as names, addresses, passwords, and banking details. As a web developer, it's crucial to protect this information from bad actors who use a wide range of exploits to steal such information and use it for personal gain. The focus of web security is to help you protect your website against these exploits and secure your users' sensitive data.
This page lists guides that summarize some best practices for implementing security features on websites. While these guides do not cover all possible security scenarios and cannot guarantee complete security of your website, following the information and best practices in these guides will make your sites significantly more secure.HTTP security fundamentalsThe guides in this section summarize best practices for implementing HTTP headers correctly to mitigate security issues, and are directly related to the HTTP Observatory tool.
Observatory performs security audits on a website and provides a grade and score along with recommendations for fixing the security issues it finds. These guides explain how to resolve issues surfaced by the HTTP Observatory tests: the tool links to the relevant guide for each issue, helping guide you towards an effective resolution. Interestingly, Mozilla's internal developer teams use this guidance when implementing websites to ensure that security best practices are applied.
The guides in the table below are listed in the order that we recommend implementing the security features they describe. This order is based on a combination of each feature's security impact and the ease of its implementation from both operational and developmental perspectives. The table provides information about each feature's impact, difficulty of implementation, whether or not it is required, and a brief description.



Guide
Impact
Difficulty
Required
Description




TLS configuration
Medium
Medium
Yes
Use the most secure Transport Layer Security (TLS) configuration available for your user base.


TLS: Resource loading
Maximum
Low
Yes
Load both passive and active resources via HTTPS.


TLS: HTTP redirection
Maximum
Low
Yes
Websites must redirect to HTTPS; API endpoints should disable HTTP entirely.


TLS: HSTS implementation
High
Low
Yes
Notify user agents to connect to sites only over HTTPS, even if the original scheme chosen was HTTP, by using HTTP Strict transport security (HSTS).


Clickjacking prevention
High
Low
Yes
Control how your site may be framed within an <iframe> to prevent clickjacking.


CSRF prevention
High
Unknown
Varies
Protect against Cross-site request forgery (CSRF) using SameSite cookies and anti-CSRF tokens.


Secure cookie configuration
High
Medium
Yes
Set all cookies as restrictively as possible.


CORP implementation
High
Medium
Yes
Protect against speculative side-channel attacks by using Cross-Origin Resource Policy (CORP).


MIME type verification
Low
Low
No
Verify that all your websites are setting the proper MIME types for all resources.


CSP implementation
High
High
Yes
Provide fine-grained control over the code that can be loaded on a site and what it is allowed to do with a Content Security Policy (CSP), thereby mitigating Cross-site scripting (XSS) vulnerabilities.


CORS configuration
High
Low
Yes
Define the non-same origins that are allowed to access the content of pages and have resources loaded from them by using Cross-Origin Resource Sharing (CORS).


Referrer policy configuration
Low
Low
Yes
Improve privacy for users and prevent leaking of internal URLs via the Referer header.


robots.txt configuration
Low
Low
No
Tell robots (such as search engine indexers) how to behave by instructing them not to crawl certain paths on the website.


SRI implementation
Low
Low
No
Verify that fetched resources (for example, from a CDN) are delivered without unexpected manipulation by using Subresource Integrity (SRI).


User information security
How to turn off form autocompletion

Form fields support autocompletion; that is, their values can be remembered and automatically filled out next time a user visits your site. For certain types of data, you may wish to disable this feature; this article explains how.

See also
Open Web Application Security Project (OWASP): Cheatsheet series
OWASP: Attacks
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Dec 21, 2024 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nPractical security implementation guidesUsers frequently input sensitive data on websites, such as names, addresses, passwords, and banking details. As a web developer, it's crucial to protect this information from bad actors who use a wide range of exploits to steal such information and use it for personal gain. The focus of web security is to help you protect your website against these exploits and secure your users' sensitive data.
This page lists guides that summarize some best practices for implementing security features on websites. While these guides do not cover all possible security scenarios and cannot guarantee complete security of your website, following the information and best practices in these guides will make your sites significantly more secure.HTTP security fundamentalsThe guides in this section summarize best practices for implementing HTTP headers correctly to mitigate security issues, and are directly related to the HTTP Observatory tool.
Observatory performs security audits on a website and provides a grade and score along with recommendations for fixing the security issues it finds. These guides explain how to resolve issues surfaced by the HTTP Observatory tests: the tool links to the relevant guide for each issue, helping guide you towards an effective resolution. Interestingly, Mozilla's internal developer teams use this guidance when implementing websites to ensure that security best practices are applied.
The guides in the table below are listed in the order that we recommend implementing the security features they describe. This order is based on a combination of each feature's security impact and the ease of its implementation from both operational and developmental perspectives. The table provides information about each feature's impact, difficulty of implementation, whether or not it is required, and a brief description.



Guide
Impact
Difficulty
Required
Description




TLS configuration
Medium
Medium
Yes
Use the most secure Transport Layer Security (TLS) configuration available for your user base.


TLS: Resource loading
Maximum
Low
Yes
Load both passive and active resources via HTTPS.


TLS: HTTP redirection
Maximum
Low
Yes
Websites must redirect to HTTPS; API endpoints should disable HTTP entirely.


TLS: HSTS implementation
High
Low
Yes
Notify user agents to connect to sites only over HTTPS, even if the original scheme chosen was HTTP, by using HTTP Strict transport security (HSTS).


Clickjacking prevention
High
Low
Yes
Control how your site may be framed within an <iframe> to prevent clickjacking.


CSRF prevention
High
Unknown
Varies
Protect against Cross-site request forgery (CSRF) using SameSite cookies and anti-CSRF tokens.


Secure cookie configuration
High
Medium
Yes
Set all cookies as restrictively as possible.


CORP implementation
High
Medium
Yes
Protect against speculative side-channel attacks by using Cross-Origin Resource Policy (CORP).


MIME type verification
Low
Low
No
Verify that all your websites are setting the proper MIME types for all resources.


CSP implementation
High
High
Yes
Provide fine-grained control over the code that can be loaded on a site and what it is allowed to do with a Content Security Policy (CSP), thereby mitigating Cross-site scripting (XSS) vulnerabilities.


CORS configuration
High
Low
Yes
Define the non-same origins that are allowed to access the content of pages and have resources loaded from them by using Cross-Origin Resource Sharing (CORS).


Referrer policy configuration
Low
Low
Yes
Improve privacy for users and prevent leaking of internal URLs via the Referer header.


robots.txt configuration
Low
Low
No
Tell robots (such as search engine indexers) how to behave by instructing them not to crawl certain paths on the website.


SRI implementation
Low
Low
No
Verify that fetched resources (for example, from a CDN) are delivered without unexpected manipulation by using Subresource Integrity (SRI).


User information security
How to turn off form autocompletion

Form fields support autocompletion; that is, their values can be remembered and automatically filled out next time a user visits your site. For certain types of data, you may wish to disable this feature; this article explains how.

See also
Open Web Application Security Project (OWASP): Cheatsheet series
OWASP: Attacks
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Dec 21, 2024 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nPermissions PolicyExperimental: This is an experimental technologyCheck the Browser compatibility table carefully before using this in production.
Permissions Policy provides mechanisms for web developers to explicitly declare what functionality can and cannot be used on a website. You define a set of "policies" that restrict what APIs the site's code can access or modify the browser's default behavior for certain features. This allows you to enforce best practices, even as the codebase evolves — as well as more safely compose third-party content.
Permissions Policy is similar to Content Security Policy but controls features instead of security behavior.
Examples of what you can do with Permissions Policy:

Change the default behavior of autoplay on mobile and third-party videos.
Restrict a site from using sensitive devices like the camera, microphone, or speakers.
Allow iframes to use the Fullscreen API.
Stop items from being scripted if they are not visible in the viewport, to improve performance.


Note:
Permissions Policy used to be called Feature Policy. The name has changed, and so has the HTTP header syntax, so bear this in mind if you have used Feature Policy in the past, and check the browser support tables. The <iframe allow=" ... "> syntax has stayed the same.
Concepts and usageThe web provides functionality and APIs that may have privacy or security risks if abused. In such cases, you may wish to strictly limit how functionality is used on a website. In each case, there should be an intuitive or non-breaking way for web developers to detect and handle cases where a feature is disabled.
Some approaches include:

"Permission denied" is returned for JavaScript APIs that require user permission grants.
JavaScript APIs that provide access to features return false values or throw an error.
APIs are not even exposed, as though they don't exist.
Options that control the feature behavior have different default values.


Note:
Newly-introduced features may have an explicit API to signal the state. Existing features that later integrate with Permissions Policy will typically use existing mechanisms.

Permissions Policy allows you to control which origins can use which features, both on the top-level page and in embedded <iframe>s. The aim is to enforce best practices for good user experiences and provide granular control over sensitive or powerful features (meaning features that a user is required to give express permission for usage of, before related code can be executed).
Permissions Policy provides two ways to specify policies:

The Permissions-Policy HTTP header, to control feature usage in received responses and any embedded content within the page (which includes <iframe>s).
The <iframe> allow attribute, to control feature usage only in specific <iframe>s.

These are separate but related — see Inheritance of policies for embedded content for details.

Note:
Scripts can programmatically query information about the permission policy via the FeaturePolicy object located at either Document.featurePolicy or HTMLIFrameElement.featurePolicy.

To control each feature, you write a policy that consists of:

A directive that identifies the name of the feature to control. See the list of the different available directives.
An allowlist, which is a list of origins that the feature should be controlled in. You can enable a feature for all or specific origins, or block its usage in all origins.

See below for multiple examples.Relationship with the Permissions APIPermissions Policy and the Permissions API are closely-related, but different. The features that have their permissions controlled by both these technologies overlap.

Permissions Policy allows a server to set whether a feature can be used in a particular document (or embedded <frame>s within it). These are referred to as policy-controlled features — see the list of Permissions Policy directives.
The Permissions API gates access to features based on user-granted permissions. These features are recorded in the Permissions Registry.

The identifying string used for each feature is kept consistent across both, for example, geolocation for the Geolocation API. Most of the API features in the Permissions Registry also have a corresponding Permissions Policy directive. One exception is the Notifications API.
Generally when a Permissions Policy blocks the use of a powerful feature, the user won't even be asked for permission to use it, and the Permissions API query() method will return a state value of denied.
See also Permissions > Relationship to the Permissions Policy specification.AllowlistsAn allowlist is a list of origins that takes one or more of the following values contained in parentheses, separated by spaces:

*: The feature will be allowed in this document, and all nested browsing contexts (<iframe>s) regardless of their origin.
() (empty allowlist): The feature is disabled in top-level and nested browsing contexts. The equivalent for <iframe> allow attribute is 'none'.
self: The feature will be allowed in this document, and in all nested browsing contexts (<iframe>s) in the same origin only. The feature is not allowed in cross-origin documents in nested browsing contexts. self can be considered shorthand for https://your-site.example.com. The equivalent for <iframe> allow attribute is 'self'.
'src': The feature will be allowed in this <iframe>, as long as the document loaded into it comes from the same origin as the URL in its src attribute. This value is only used in the <iframe> allow attribute, and is the default allowlist value in <iframe>s.
"<origin>": The feature is allowed for specific origins (for example, "https://a.example.com"). Origins should be separated by spaces. Note that origins in <iframe> allow attributes are not quoted.

The values * and () may only be used on their own, while self and src may be used in combination with one or more origins.

Note:
Directives have a default allowlist, which is always one of *, self, or none for the Permissions-Policy HTTP header, and governs the default behavior if they are not explicitly listed in a policy. These are specified on the individual directive reference pages. For <iframe> allow attributes, the default behavior is always src.

Where supported, you can include wildcards in Permissions Policy origins. This means that instead of having to explicitly specify several different subdomains in an allowlist, you can specify them all in a single origin with a wildcard.
So instead of
http("https://example.com" "https://a.example.com" "https://b.example.com" "https://c.example.com")

You can specify
http("https://example.com" "https://*.example.com")


Note: "https://*.example.com" does not match "https://example.com".

allowlist examples:

*
()
(self)
(src)
("https://a.example.com")
("https://a.example.com" "https://b.example.com")
(self "https://a.example.com" "https://b.example.com")
(src "https://a.example.com" "https://b.example.com")
("https://*.example.com")
Permissions-Policy header syntaxThe general syntax looks like this:
httpPermissions-Policy: <directive>=<allowlist>

So for example to block all access to geolocation, you would do this:
httpPermissions-Policy: geolocation=()

Or to allow access to a subset of origins, you'd do this:
httpPermissions-Policy: geolocation=(self "https://a.example.com" "https://b.example.com")

Several features can be controlled at the same time by sending the header with a comma-separated list of policies, or by sending a separate header for each policy.
For example, the following are equivalent:
httpPermissions-Policy: picture-in-picture=(), geolocation=(self "https://example.com"), camera=*;

Permissions-Policy: picture-in-picture=()
Permissions-Policy: geolocation=(self "https://example.com")
Permissions-Policy: camera=*
Embedded frame syntaxFor an <iframe> to have a feature enabled its allowed origin must also be in the allowlist for the parent page. Because of this inheritance behavior, it is a good idea to specify the widest acceptable support for a feature in the HTTP header, and then specify the subset of support you need in each <iframe>.
The general syntax looks like this:
html<iframe src="<origin>" allow="<directive> <allowlist>"></iframe>

So for example to block all access to geolocation, you would do this:
html<iframe src="https://example.com" allow="geolocation 'none'"></iframe>

To apply a policy to the current origin and others, you'd do this:
html<iframe
  src="https://example.com"
  allow="geolocation 'self' https://a.example.com https://b.example.com"></iframe>

This is important: By default, if an <iframe> navigates to another origin, the policy is not applied to the origin that the <iframe> navigates to. By listing the origin that the <iframe> navigates to in the allow attribute, the Permissions Policy that was applied to the original <iframe> will be applied to the origin the <iframe> navigates to.
Several features can be controlled at the same time by including a semi-colon-separated list of policy directives inside the allow attribute.
html<iframe
  src="https://example.com"
  allow="geolocation 'self' https://a.example.com https://b.example.com; fullscreen 'none'"></iframe>

It is worth giving the src value a special mention. We mentioned above that using this allowlist value will mean that the associated feature will be allowed in this <iframe>, as long as the document loaded into it comes from the same origin as the URL in its src attribute. This value is the default allowlist value for features listed in allow, so the following are equivalent:
html<iframe src="https://example.com" allow="geolocation 'src'">
  <iframe src="https://example.com" allow="geolocation"></iframe
></iframe>


Note:
As you'll have noticed, the syntax for <iframe> policies is a bit different to the syntax for Permissions-Policy headers. The former still uses the same syntax as the older Feature Policy specification, which was superseded by Permissions Policy.
Fenced frames and permissions policy<fencedframe>s interact with permissions policies in the same way as <iframe>s, but in a much more restricted capacity. Only specific features designed to be used in <fencedframe>s can be enabled via permissions policies set on them; other policy-controlled features are not available in this context.
See Permissions policies available to fenced frames for more details.Inheritance of policies for embedded contentScripts inherit the policy of their browsing context, regardless of their origin. That means that top-level scripts inherit the policy from the main document.
All <iframe>s inherit the policy of their parent page. If the <iframe> has an allow attribute and the parent page has a Permissions-Policy, the policies of the parent page and the allow attribute are combined, using the most restrictive subset. For an <iframe> to have a feature enabled, the origin must be in the allowlist for both the parent page and the allow attribute.
Disabling a feature in a policy is a one-way toggle. If a feature has been disabled for a child frame by its parent frame, the child cannot re-enable it, and neither can any of the child's descendants.ExamplesCombining HTTP header and <iframe> policiesFor example, let's say that we wanted to enable geolocation usage on our own origin, and in embedded content coming from our trusted ad network. We could set up the page-wide Permissions Policy like this:
httpPermissions-Policy: geolocation=(self "https://trusted-ad-network.com")

Over in our ad <iframe>s, we could set access to the https://trusted-ad-network.com origin like this:
html<iframe src="https://trusted-ad-network.com" allow="geolocation"></iframe>

If a different origin ended up getting loaded into <iframe>, it would not have access to geolocation:
html<iframe src="https://rogue-origin-example.com" allow="geolocation"></iframe>
SpecificationsSpecificationPermissions Policy # permissions-policy-http-header-fieldBrowser compatibilitySee also
Permissions-Policy HTTP header
allow attribute on iframes
Controlling browser features with Permissions Policy: use guide that also contains several demo links.
Permissions/Feature policies on chromestatus.com
Privacy, permissions, and information security\n\nPermissions PolicyExperimental: This is an experimental technologyCheck the Browser compatibility table carefully before using this in production.
Permissions Policy provides mechanisms for web developers to explicitly declare what functionality can and cannot be used on a website. You define a set of "policies" that restrict what APIs the site's code can access or modify the browser's default behavior for certain features. This allows you to enforce best practices, even as the codebase evolves — as well as more safely compose third-party content.
Permissions Policy is similar to Content Security Policy but controls features instead of security behavior.
Examples of what you can do with Permissions Policy:

Change the default behavior of autoplay on mobile and third-party videos.
Restrict a site from using sensitive devices like the camera, microphone, or speakers.
Allow iframes to use the Fullscreen API.
Stop items from being scripted if they are not visible in the viewport, to improve performance.


Note:
Permissions Policy used to be called Feature Policy. The name has changed, and so has the HTTP header syntax, so bear this in mind if you have used Feature Policy in the past, and check the browser support tables. The <iframe allow=" ... "> syntax has stayed the same.
Concepts and usageThe web provides functionality and APIs that may have privacy or security risks if abused. In such cases, you may wish to strictly limit how functionality is used on a website. In each case, there should be an intuitive or non-breaking way for web developers to detect and handle cases where a feature is disabled.
Some approaches include:

"Permission denied" is returned for JavaScript APIs that require user permission grants.
JavaScript APIs that provide access to features return false values or throw an error.
APIs are not even exposed, as though they don't exist.
Options that control the feature behavior have different default values.


Note:
Newly-introduced features may have an explicit API to signal the state. Existing features that later integrate with Permissions Policy will typically use existing mechanisms.

Permissions Policy allows you to control which origins can use which features, both on the top-level page and in embedded <iframe>s. The aim is to enforce best practices for good user experiences and provide granular control over sensitive or powerful features (meaning features that a user is required to give express permission for usage of, before related code can be executed).
Permissions Policy provides two ways to specify policies:

The Permissions-Policy HTTP header, to control feature usage in received responses and any embedded content within the page (which includes <iframe>s).
The <iframe> allow attribute, to control feature usage only in specific <iframe>s.

These are separate but related — see Inheritance of policies for embedded content for details.

Note:
Scripts can programmatically query information about the permission policy via the FeaturePolicy object located at either Document.featurePolicy or HTMLIFrameElement.featurePolicy.

To control each feature, you write a policy that consists of:

A directive that identifies the name of the feature to control. See the list of the different available directives.
An allowlist, which is a list of origins that the feature should be controlled in. You can enable a feature for all or specific origins, or block its usage in all origins.

See below for multiple examples.Relationship with the Permissions APIPermissions Policy and the Permissions API are closely-related, but different. The features that have their permissions controlled by both these technologies overlap.

Permissions Policy allows a server to set whether a feature can be used in a particular document (or embedded <frame>s within it). These are referred to as policy-controlled features — see the list of Permissions Policy directives.
The Permissions API gates access to features based on user-granted permissions. These features are recorded in the Permissions Registry.

The identifying string used for each feature is kept consistent across both, for example, geolocation for the Geolocation API. Most of the API features in the Permissions Registry also have a corresponding Permissions Policy directive. One exception is the Notifications API.
Generally when a Permissions Policy blocks the use of a powerful feature, the user won't even be asked for permission to use it, and the Permissions API query() method will return a state value of denied.
See also Permissions > Relationship to the Permissions Policy specification.AllowlistsAn allowlist is a list of origins that takes one or more of the following values contained in parentheses, separated by spaces:

*: The feature will be allowed in this document, and all nested browsing contexts (<iframe>s) regardless of their origin.
() (empty allowlist): The feature is disabled in top-level and nested browsing contexts. The equivalent for <iframe> allow attribute is 'none'.
self: The feature will be allowed in this document, and in all nested browsing contexts (<iframe>s) in the same origin only. The feature is not allowed in cross-origin documents in nested browsing contexts. self can be considered shorthand for https://your-site.example.com. The equivalent for <iframe> allow attribute is 'self'.
'src': The feature will be allowed in this <iframe>, as long as the document loaded into it comes from the same origin as the URL in its src attribute. This value is only used in the <iframe> allow attribute, and is the default allowlist value in <iframe>s.
"<origin>": The feature is allowed for specific origins (for example, "https://a.example.com"). Origins should be separated by spaces. Note that origins in <iframe> allow attributes are not quoted.

The values * and () may only be used on their own, while self and src may be used in combination with one or more origins.

Note:
Directives have a default allowlist, which is always one of *, self, or none for the Permissions-Policy HTTP header, and governs the default behavior if they are not explicitly listed in a policy. These are specified on the individual directive reference pages. For <iframe> allow attributes, the default behavior is always src.

Where supported, you can include wildcards in Permissions Policy origins. This means that instead of having to explicitly specify several different subdomains in an allowlist, you can specify them all in a single origin with a wildcard.
So instead of
http("https://example.com" "https://a.example.com" "https://b.example.com" "https://c.example.com")

You can specify
http("https://example.com" "https://*.example.com")


Note: "https://*.example.com" does not match "https://example.com".

allowlist examples:

*
()
(self)
(src)
("https://a.example.com")
("https://a.example.com" "https://b.example.com")
(self "https://a.example.com" "https://b.example.com")
(src "https://a.example.com" "https://b.example.com")
("https://*.example.com")
Permissions-Policy header syntaxThe general syntax looks like this:
httpPermissions-Policy: <directive>=<allowlist>

So for example to block all access to geolocation, you would do this:
httpPermissions-Policy: geolocation=()

Or to allow access to a subset of origins, you'd do this:
httpPermissions-Policy: geolocation=(self "https://a.example.com" "https://b.example.com")

Several features can be controlled at the same time by sending the header with a comma-separated list of policies, or by sending a separate header for each policy.
For example, the following are equivalent:
httpPermissions-Policy: picture-in-picture=(), geolocation=(self "https://example.com"), camera=*;

Permissions-Policy: picture-in-picture=()
Permissions-Policy: geolocation=(self "https://example.com")
Permissions-Policy: camera=*
Embedded frame syntaxFor an <iframe> to have a feature enabled its allowed origin must also be in the allowlist for the parent page. Because of this inheritance behavior, it is a good idea to specify the widest acceptable support for a feature in the HTTP header, and then specify the subset of support you need in each <iframe>.
The general syntax looks like this:
html<iframe src="<origin>" allow="<directive> <allowlist>"></iframe>

So for example to block all access to geolocation, you would do this:
html<iframe src="https://example.com" allow="geolocation 'none'"></iframe>

To apply a policy to the current origin and others, you'd do this:
html<iframe
  src="https://example.com"
  allow="geolocation 'self' https://a.example.com https://b.example.com"></iframe>

This is important: By default, if an <iframe> navigates to another origin, the policy is not applied to the origin that the <iframe> navigates to. By listing the origin that the <iframe> navigates to in the allow attribute, the Permissions Policy that was applied to the original <iframe> will be applied to the origin the <iframe> navigates to.
Several features can be controlled at the same time by including a semi-colon-separated list of policy directives inside the allow attribute.
html<iframe
  src="https://example.com"
  allow="geolocation 'self' https://a.example.com https://b.example.com; fullscreen 'none'"></iframe>

It is worth giving the src value a special mention. We mentioned above that using this allowlist value will mean that the associated feature will be allowed in this <iframe>, as long as the document loaded into it comes from the same origin as the URL in its src attribute. This value is the default allowlist value for features listed in allow, so the following are equivalent:
html<iframe src="https://example.com" allow="geolocation 'src'">
  <iframe src="https://example.com" allow="geolocation"></iframe
></iframe>


Note:
As you'll have noticed, the syntax for <iframe> policies is a bit different to the syntax for Permissions-Policy headers. The former still uses the same syntax as the older Feature Policy specification, which was superseded by Permissions Policy.
Fenced frames and permissions policy<fencedframe>s interact with permissions policies in the same way as <iframe>s, but in a much more restricted capacity. Only specific features designed to be used in <fencedframe>s can be enabled via permissions policies set on them; other policy-controlled features are not available in this context.
See Permissions policies available to fenced frames for more details.Inheritance of policies for embedded contentScripts inherit the policy of their browsing context, regardless of their origin. That means that top-level scripts inherit the policy from the main document.
All <iframe>s inherit the policy of their parent page. If the <iframe> has an allow attribute and the parent page has a Permissions-Policy, the policies of the parent page and the allow attribute are combined, using the most restrictive subset. For an <iframe> to have a feature enabled, the origin must be in the allowlist for both the parent page and the allow attribute.
Disabling a feature in a policy is a one-way toggle. If a feature has been disabled for a child frame by its parent frame, the child cannot re-enable it, and neither can any of the child's descendants.ExamplesCombining HTTP header and <iframe> policiesFor example, let's say that we wanted to enable geolocation usage on our own origin, and in embedded content coming from our trusted ad network. We could set up the page-wide Permissions Policy like this:
httpPermissions-Policy: geolocation=(self "https://trusted-ad-network.com")

Over in our ad <iframe>s, we could set access to the https://trusted-ad-network.com origin like this:
html<iframe src="https://trusted-ad-network.com" allow="geolocation"></iframe>

If a different origin ended up getting loaded into <iframe>, it would not have access to geolocation:
html<iframe src="https://rogue-origin-example.com" allow="geolocation"></iframe>
SpecificationsSpecificationPermissions Policy # permissions-policy-http-header-fieldBrowser compatibilitySee also
Permissions-Policy HTTP header
allow attribute on iframes
Controlling browser features with Permissions Policy: use guide that also contains several demo links.
Permissions/Feature policies on chromestatus.com
Privacy, permissions, and information security
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Apr 10, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nPermissions PolicyExperimental: This is an experimental technologyCheck the Browser compatibility table carefully before using this in production.
Permissions Policy provides mechanisms for web developers to explicitly declare what functionality can and cannot be used on a website. You define a set of "policies" that restrict what APIs the site's code can access or modify the browser's default behavior for certain features. This allows you to enforce best practices, even as the codebase evolves — as well as more safely compose third-party content.
Permissions Policy is similar to Content Security Policy but controls features instead of security behavior.
Examples of what you can do with Permissions Policy:

Change the default behavior of autoplay on mobile and third-party videos.
Restrict a site from using sensitive devices like the camera, microphone, or speakers.
Allow iframes to use the Fullscreen API.
Stop items from being scripted if they are not visible in the viewport, to improve performance.


Note:
Permissions Policy used to be called Feature Policy. The name has changed, and so has the HTTP header syntax, so bear this in mind if you have used Feature Policy in the past, and check the browser support tables. The <iframe allow=" ... "> syntax has stayed the same.
Concepts and usageThe web provides functionality and APIs that may have privacy or security risks if abused. In such cases, you may wish to strictly limit how functionality is used on a website. In each case, there should be an intuitive or non-breaking way for web developers to detect and handle cases where a feature is disabled.
Some approaches include:

"Permission denied" is returned for JavaScript APIs that require user permission grants.
JavaScript APIs that provide access to features return false values or throw an error.
APIs are not even exposed, as though they don't exist.
Options that control the feature behavior have different default values.


Note:
Newly-introduced features may have an explicit API to signal the state. Existing features that later integrate with Permissions Policy will typically use existing mechanisms.

Permissions Policy allows you to control which origins can use which features, both on the top-level page and in embedded <iframe>s. The aim is to enforce best practices for good user experiences and provide granular control over sensitive or powerful features (meaning features that a user is required to give express permission for usage of, before related code can be executed).
Permissions Policy provides two ways to specify policies:

The Permissions-Policy HTTP header, to control feature usage in received responses and any embedded content within the page (which includes <iframe>s).
The <iframe> allow attribute, to control feature usage only in specific <iframe>s.

These are separate but related — see Inheritance of policies for embedded content for details.

Note:
Scripts can programmatically query information about the permission policy via the FeaturePolicy object located at either Document.featurePolicy or HTMLIFrameElement.featurePolicy.

To control each feature, you write a policy that consists of:

A directive that identifies the name of the feature to control. See the list of the different available directives.
An allowlist, which is a list of origins that the feature should be controlled in. You can enable a feature for all or specific origins, or block its usage in all origins.

See below for multiple examples.Relationship with the Permissions APIPermissions Policy and the Permissions API are closely-related, but different. The features that have their permissions controlled by both these technologies overlap.

Permissions Policy allows a server to set whether a feature can be used in a particular document (or embedded <frame>s within it). These are referred to as policy-controlled features — see the list of Permissions Policy directives.
The Permissions API gates access to features based on user-granted permissions. These features are recorded in the Permissions Registry.

The identifying string used for each feature is kept consistent across both, for example, geolocation for the Geolocation API. Most of the API features in the Permissions Registry also have a corresponding Permissions Policy directive. One exception is the Notifications API.
Generally when a Permissions Policy blocks the use of a powerful feature, the user won't even be asked for permission to use it, and the Permissions API query() method will return a state value of denied.
See also Permissions > Relationship to the Permissions Policy specification.AllowlistsAn allowlist is a list of origins that takes one or more of the following values contained in parentheses, separated by spaces:

*: The feature will be allowed in this document, and all nested browsing contexts (<iframe>s) regardless of their origin.
() (empty allowlist): The feature is disabled in top-level and nested browsing contexts. The equivalent for <iframe> allow attribute is 'none'.
self: The feature will be allowed in this document, and in all nested browsing contexts (<iframe>s) in the same origin only. The feature is not allowed in cross-origin documents in nested browsing contexts. self can be considered shorthand for https://your-site.example.com. The equivalent for <iframe> allow attribute is 'self'.
'src': The feature will be allowed in this <iframe>, as long as the document loaded into it comes from the same origin as the URL in its src attribute. This value is only used in the <iframe> allow attribute, and is the default allowlist value in <iframe>s.
"<origin>": The feature is allowed for specific origins (for example, "https://a.example.com"). Origins should be separated by spaces. Note that origins in <iframe> allow attributes are not quoted.

The values * and () may only be used on their own, while self and src may be used in combination with one or more origins.

Note:
Directives have a default allowlist, which is always one of *, self, or none for the Permissions-Policy HTTP header, and governs the default behavior if they are not explicitly listed in a policy. These are specified on the individual directive reference pages. For <iframe> allow attributes, the default behavior is always src.

Where supported, you can include wildcards in Permissions Policy origins. This means that instead of having to explicitly specify several different subdomains in an allowlist, you can specify them all in a single origin with a wildcard.
So instead of
http("https://example.com" "https://a.example.com" "https://b.example.com" "https://c.example.com")

You can specify
http("https://example.com" "https://*.example.com")


Note: "https://*.example.com" does not match "https://example.com".

allowlist examples:

*
()
(self)
(src)
("https://a.example.com")
("https://a.example.com" "https://b.example.com")
(self "https://a.example.com" "https://b.example.com")
(src "https://a.example.com" "https://b.example.com")
("https://*.example.com")
Permissions-Policy header syntaxThe general syntax looks like this:
httpPermissions-Policy: <directive>=<allowlist>

So for example to block all access to geolocation, you would do this:
httpPermissions-Policy: geolocation=()

Or to allow access to a subset of origins, you'd do this:
httpPermissions-Policy: geolocation=(self "https://a.example.com" "https://b.example.com")

Several features can be controlled at the same time by sending the header with a comma-separated list of policies, or by sending a separate header for each policy.
For example, the following are equivalent:
httpPermissions-Policy: picture-in-picture=(), geolocation=(self "https://example.com"), camera=*;

Permissions-Policy: picture-in-picture=()
Permissions-Policy: geolocation=(self "https://example.com")
Permissions-Policy: camera=*
Embedded frame syntaxFor an <iframe> to have a feature enabled its allowed origin must also be in the allowlist for the parent page. Because of this inheritance behavior, it is a good idea to specify the widest acceptable support for a feature in the HTTP header, and then specify the subset of support you need in each <iframe>.
The general syntax looks like this:
html<iframe src="<origin>" allow="<directive> <allowlist>"></iframe>

So for example to block all access to geolocation, you would do this:
html<iframe src="https://example.com" allow="geolocation 'none'"></iframe>

To apply a policy to the current origin and others, you'd do this:
html<iframe
  src="https://example.com"
  allow="geolocation 'self' https://a.example.com https://b.example.com"></iframe>

This is important: By default, if an <iframe> navigates to another origin, the policy is not applied to the origin that the <iframe> navigates to. By listing the origin that the <iframe> navigates to in the allow attribute, the Permissions Policy that was applied to the original <iframe> will be applied to the origin the <iframe> navigates to.
Several features can be controlled at the same time by including a semi-colon-separated list of policy directives inside the allow attribute.
html<iframe
  src="https://example.com"
  allow="geolocation 'self' https://a.example.com https://b.example.com; fullscreen 'none'"></iframe>

It is worth giving the src value a special mention. We mentioned above that using this allowlist value will mean that the associated feature will be allowed in this <iframe>, as long as the document loaded into it comes from the same origin as the URL in its src attribute. This value is the default allowlist value for features listed in allow, so the following are equivalent:
html<iframe src="https://example.com" allow="geolocation 'src'">
  <iframe src="https://example.com" allow="geolocation"></iframe
></iframe>


Note:
As you'll have noticed, the syntax for <iframe> policies is a bit different to the syntax for Permissions-Policy headers. The former still uses the same syntax as the older Feature Policy specification, which was superseded by Permissions Policy.
Fenced frames and permissions policy<fencedframe>s interact with permissions policies in the same way as <iframe>s, but in a much more restricted capacity. Only specific features designed to be used in <fencedframe>s can be enabled via permissions policies set on them; other policy-controlled features are not available in this context.
See Permissions policies available to fenced frames for more details.Inheritance of policies for embedded contentScripts inherit the policy of their browsing context, regardless of their origin. That means that top-level scripts inherit the policy from the main document.
All <iframe>s inherit the policy of their parent page. If the <iframe> has an allow attribute and the parent page has a Permissions-Policy, the policies of the parent page and the allow attribute are combined, using the most restrictive subset. For an <iframe> to have a feature enabled, the origin must be in the allowlist for both the parent page and the allow attribute.
Disabling a feature in a policy is a one-way toggle. If a feature has been disabled for a child frame by its parent frame, the child cannot re-enable it, and neither can any of the child's descendants.ExamplesCombining HTTP header and <iframe> policiesFor example, let's say that we wanted to enable geolocation usage on our own origin, and in embedded content coming from our trusted ad network. We could set up the page-wide Permissions Policy like this:
httpPermissions-Policy: geolocation=(self "https://trusted-ad-network.com")

Over in our ad <iframe>s, we could set access to the https://trusted-ad-network.com origin like this:
html<iframe src="https://trusted-ad-network.com" allow="geolocation"></iframe>

If a different origin ended up getting loaded into <iframe>, it would not have access to geolocation:
html<iframe src="https://rogue-origin-example.com" allow="geolocation"></iframe>
SpecificationsSpecificationPermissions Policy # permissions-policy-http-header-fieldBrowser compatibilitySee also
Permissions-Policy HTTP header
allow attribute on iframes
Controlling browser features with Permissions Policy: use guide that also contains several demo links.
Permissions/Feature policies on chromestatus.com
Privacy, permissions, and information security
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Apr 10, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nContent Security Policy (CSP)Content Security Policy (CSP) is a feature that helps to prevent or minimize the risk of certain types of security threats. It consists of a series of instructions from a website to a browser, which instruct the browser to place restrictions on the things that the code comprising the site is allowed to do.
The primary use case for CSP is to control which resources, in particular JavaScript resources, a document is allowed to load. This is mainly used as a defense against cross-site scripting (XSS) attacks, in which an attacker is able to inject malicious code into the victim's site.
A CSP can have other purposes as well, including defending against clickjacking and helping to ensure that a site's pages will be loaded over HTTPS.
In this guide we'll start by describing how a CSP is delivered to a browser and what it looks like at a high level.
Then we'll describe how it can be used to control which resources are loaded to protect against XSS, and then other use cases such as clickjacking protection and upgrading insecure requests. Note that there's no dependency between the different use cases: if you want to add clickjacking protection but not XSS mitigation, you can just add the directives for that use case.
Finally we'll describe strategies for deploying a CSP and tools that can help to make this process easier.CSP overviewA CSP should be delivered to the browser in the Content-Security-Policy response header. It should be set on all responses to all requests, not just the main document.
You can also specify it using the http-equiv attribute of your document's <meta> element, and this is a useful option for some use cases, such as a client-side-rendered single page app which has only static resources, because you can then avoid relying on any server infrastructure. However, this option does not support all CSP features.
The policy is specified as a series of directives, separated by semi-colons. Each directive controls a different aspect of the security policy. Each directive has a name, followed by a space, followed by a value. Different directives can have different syntaxes.
For example, consider the following CSP:
httpContent-Security-Policy: default-src 'self'; img-src 'self' example.com

It sets two directives:

the default-src directive is set to 'self'
the img-src directive is set to 'self' example.com.


The first directive, default-src, tells the browser to load only resources that are same-origin with the document, unless other more specific directives set a different policy for other resource types. The second, img-src, tells the browser to load images that are same-origin or that are served from example.com.
In the next section, we'll look at the tools available to control resource loads, which is the main function of a CSP.Controlling resource loadingA CSP can be used to control the resources that a document is allowed to load. This is primarily used for protection against cross-site scripting (XSS) attacks.
In this section we'll first see how controlling resource loads can help protect against XSS, then at the tools CSP provides to control what resources are loaded. Finally we'll describe one particular recommended strategy, which is called a "Strict CSP".XSS and resource loadingA cross-site scripting (XSS) attack is one in which an attacker is able to execute their code in the context of the target website. This code is then able to do anything that the website's own code could do, including, for example:

access or modify the content of the site's loaded pages
access or modify content in local storage
make HTTP requests with the user's credentials, enabling them to impersonate the user or access sensitive data

An XSS attack is possible when a website accepts some input which might have been crafted by an attacker (for example, URL parameters, or a comment on a blog post) and then includes it in the page without sanitizing it: that is, without ensuring that it can't be executed as JavaScript.
Websites should protect themselves against XSS by sanitizing this input before including it in the page. A CSP provides a complementary protection, which can protect the website even if sanitization fails.
If sanitization does fail, there are various forms the injected malicious code can take in the document, including:


A <script> tag that links to a malicious source:
html<script src="https://evil.example.com/hacker.js"></script>



A <script> tag that includes inline JavaScript:
html<script>
  console.log("You've been hacked!");
</script>



An inline event handler:
html<img onmouseover="console.log(`You've been hacked!`)" />



A javascript: URL:
html<iframe src="javascript:console.log(`You've been hacked!`)"></iframe>



A string argument to an unsafe API like eval():
jseval("console.log(`You've been hacked!`)");



A CSP can provide protection against all of these. With a CSP, you can:

define the permitted sources for JavaScript files and other resources, effectively blocking loads from https://evil.example.com
disable inline script tags
allow only script tags which have the correct nonce or hash set
disable inline event handlers
disable javascript: URLs
disable dangerous APIs like eval()

In the next section we'll go over the tools CSP provides to do these things.

Note:
Setting a CSP is not an alternative to sanitizing input. Websites should sanitize input and set a CSP, providing defense in depth against XSS.
Fetch directivesFetch directives are used to specify a particular category of resource that a document is allowed to load — such as JavaScript, CSS stylesheets, images, fonts, and so on.
There are different fetch directives for different types of resource. For example:

script-src sets allowed sources for JavaScript.
style-src sets allowed sources for CSS stylesheets.
img-src sets allowed sources for images.

One special fetch directive is default-src, which sets a fallback policy for all resources whose directives are not explicitly listed.
For the complete set of fetch directives, see the reference documentation.
Each fetch directive is specified as either the single keyword 'none' or one or more source expressions, separated by spaces. When more than one source expression is listed: if any of the methods allow the resource, then the resource is allowed.
For example, the CSP below sets two fetch directives:

default-src is given the single source expression 'self'
img-src is given two source expressions: 'self' and example.com


The effect of this is that:

images must be either same-origin with the document, or loaded from example.com
all other resources must be same-origin with the document.

In the next few sections we'll describe some of the ways you can use source expressions to control resource loads. Note that although we're describing them separately, these expressions can in general be combined: for example, a single fetch directive may include nonces as well as hostnames.
Blocking resources
To block a resource type entirely, use the 'none' keyword. For example, the following directive blocks all <object> and <embed> resources:
httpContent-Security-Policy: object-src 'none'

Note that 'none' cannot be combined with any other method in a particular directive: in practice, if any other source expressions are given alongside 'none', then they are ignored.
Nonces
A nonce is the recommended approach for restricting the loading of <script> and <style> resources.
With a nonce, the server generates a random value for every HTTP response, and includes it in a script-src and/or a style-src directive:
httpContent-Security-Policy:
  script-src 'nonce-416d1177-4d12-4e3b-b7c9-f6c409789fb8'

The server then includes this value as the value of the nonce attribute of all the <script> and/or <style> tags that they intend to include in the document.
The browser compares the two values, and loads the resource only if they match. The idea is that even if an attacker can insert some JavaScript into the page, they won't know which nonce the server is going to use, so the browser will refuse to run the script.
For this approach to work, it must not be possible for an attacker to guess the nonce.
In practice this means that the nonce must be different for every HTTP response, and must not be predictable.
This in turn means that the server cannot serve static HTML, because it must insert a new nonce each time. Typically the server would use a templating engine to insert the nonce.
Here's a snippet of Express code to demonstrate:
jsfunction content(nonce) {
  return `
    <script nonce="${nonce}" src="/main.js"></script>
    <script nonce="${nonce}">console.log("hello!");</script>
    <h1>Hello world</h1> 
    `;
}

app.get("/", (req, res) => {
  const nonce = crypto.randomUUID();
  res.setHeader("Content-Security-Policy", `script-src 'nonce-${nonce}'`);
  res.send(content(nonce));
});

On every request, the server generates a new nonce, inserts it into the CSP and into the <script> tags in the returned document. Note that the server:

generates a new nonce for every request
can use nonces with both external and inline scripts
uses the same nonce for all <script> tags in the document

It's important that the server uses some kind of templating to insert nonces, and does not just insert them into all <script> tags: otherwise, the server might inadvertently insert nonces into scripts that were injected by an attacker.
Note that nonces can only be used for elements that have a nonce attribute: that is, only <script> and <style> elements.
Hashes
Fetch directives can also use a hash of the script to guarantee its integrity. With this method, the server:

calculates a hash of the script contents using a hash function (one of SHA-256, SHA-384, or SHA-512)
creates a Base64 encoding of the result
appends a prefix identifying the hash algorithm used (one of sha256-, sha384-, or sha512-).

It then adds the result to the directive:
httpContent-Security-Policy: script-src 'sha256-cd9827ad...'

When the browser receives the document, it hashes the script, compares the result with the value from the header, and loads the script only if they match.
External scripts must also include the integrity attribute for this method to work.
Here's a snippet of Express code, to demonstrate:
jsconst hash1 = "sha256-ex2O7MWOzfczthhKm6azheryNVoERSFrPrdvxRtP8DI=";
const hash2 = "sha256-H/eahVJiG1zBXPQyXX0V6oaxkfiBdmanvfG9eZWSuEc=";

const csp = `script-src '${hash1}' '${hash2}'`;
const content = `
  <script src="./main.js" integrity="${hash2}"></script>
  <script>console.log("hello!");</script>
    <h1>Hello world</h1> 
    `;

app.get("/", (req, res) => {
  res.setHeader("Content-Security-Policy", csp);
  res.send(content);
});

Note that:

We have a separate hash for every script in the document.
For the external script "main.js", we also include the integrity attribute, and give it the same value.
Unlike the example using nonces, both the CSP and the content can be static, because the hashes stay the same. This makes hash-based policies more suitable for static pages or websites that rely on client-side rendering.

Scheme-based policies
Fetch directives can list a scheme, like https:, to allow resources that are served using that scheme. This, for example, allows a policy to require HTTPS for all resource loads:
httpContent-Security-Policy: default-src https:

Location-based policies
Fetch directives can control resource loads based on where the resource is located.
The keyword 'self' allows resources which are same-origin with the document itself:
httpContent-Security-Policy: img-src 'self'

You can also specify one or more hostnames, potentially including wildcards, and only resources served from those hosts will be allowed. This might be used, for example, to allow content to be served from a trusted CDN.
httpContent-Security-Policy: img-src *.example.org

You can specify multiple locations. The following directive allows only images that are same-origin with the current document, or are served from a subdomain of "example.org", or are served from "example.com":
httpContent-Security-Policy: img-src 'self' *.example.org  example.com

Inline JavaScript
If a CSP contains either a default-src or a script-src directive, then inline JavaScript will not be allowed to execute unless extra measures are taken to enable it. This includes:


JavaScript included inside a <script> element in the page:
html<script>
  console.log("Hello from an inline script");
</script>



JavaScript in an inline event handler attribute:
html<img src="x" onerror="console.log('Hello from an inline event handler')" />



JavaScript in a javascript: URL:
html<a href="javascript:console.log('Hello from a javascript: URL')"></a>



The unsafe-inline keyword can be used to override this restriction. For example, the following directive requires all resources to be same-origin, but allows inline JavaScript:
httpContent-Security-Policy: default-src 'self' 'unsafe-inline'


Warning:
Developers should avoid 'unsafe-inline', because it defeats much of the purpose of having a CSP. Inline JavaScript is one of the most common XSS vectors, and one of the most basic goals of a CSP is to prevent its uncontrolled use.

Inline <script> elements are allowed if they are protected by a nonce or a hash, as described above.
If a directive contains nonce or hash expressions, then the unsafe-inline keyword is ignored by browsers.
eval() and similar APIs
Like inline JavaScript, if a CSP contains either a default-src or a script-src directive, then eval() and similar APIs will not be allowed to execute. This includes, among other APIs:


eval() itself:
jseval('console.log("hello from eval()")');



The Function() constructor:
jsconst sum = new Function("a", "b", "return a + b");



The string argument to setTimeout() and setInterval():
jssetTimeout("console.log('hello from setTimeout')", 1);



The unsafe-eval keyword can be used to override this behavior, and as with unsafe-inline, and for the same reasons: developers should avoid unsafe-eval. Sometimes it can be difficult to remove usages of eval(): in these situations, the Trusted Types API can make it safer, by ensuring that the input meets a defined policy.
Unlike unsafe-inline, the unsafe-eval keyword does still work in a directive that contains nonce or hash expressions.Strict CSPTo control script loading as a mitigation against XSS, recommended practice is to use nonce- or hash- based fetch directives. This is called a strict CSP. This type of CSP has two main advantages over a location-based CSP (usually called an allowlist CSP):

Allowlist CSPs are hard to get right and often policies inadvertently whitelist unsafe domains, and hence don't provide effective protection against XSS (see CSP Is Dead, Long Live CSP! On the Insecurity of Whitelists and the Future of Content Security Policy).
Allowlist CSPs can be very large and hard to maintain, in particular when using scripts that are outside of your control. According to How I learned to stop worrying and love the Content Security Policy, just to integrate Google Analytics, a developer is asked to add 187 Google domains to the allowlist.

A nonce-based strict CSP looks like this:
httpContent-Security-Policy:
  script-src 'nonce-{RANDOM}';
  object-src 'none';
  base-uri 'none';

In this CSP, we:

use nonces to control which JavaScript resources are allowed to load
block all object embeds
block all uses of the <base> element to set a base URI.

A hash-based strict CSP is the same, except it uses hashes instead of nonces:
httpContent-Security-Policy:
  script-src 'sha256-{HASHED_SCRIPT}';
  object-src 'none';
  base-uri 'none';

Nonce-based directives are easier to maintain if you can generate responses, including the content itself, dynamically. Otherwise, you need to use hash-based directives. The problem with hash-based directives is that you need to recalculate and reapply the hash if any change is made to the script contents.
The strict-dynamic keyword
As presented above, the strict CSP is difficult to implement when you use scripts which are not under your control. If a third-party script loads any additional scripts, or uses any inline scripts, then this will fail, because the third-party script won't pass the nonce or hash through.
The strict-dynamic keyword is provided to help with this problem. It is a keyword that can be included in a fetch directive, and it has the effect that if a script has a nonce or a hash attached to it, then that script will be allowed to load further scripts which do not themselves have nonces or hashes. That is, the trust placed in a script by a nonce or hash is passed on to scripts that the original script loads (and scripts that they load, and so on).
For example, consider a document like this:
html<html>
  <head>
    <script
      src="./main.js"
      integrity="sha256-gEh1+8U9S1vkEuQSmmUMTZjyNSu5tIoECP4UXIEjMTk="></script>
  </head>
  <body>
    <h1>Example page!</h1>
  </body>
</html>

It includes a script "main.js", which creates and adds another script, "main2.js":
jsconsole.log("hello");

const scriptElement = document.createElement("script");
scriptElement.src = `main2.js`;

document.head.appendChild(scriptElement);

We serve our document with a CSP like this:
httpContent-Security-Policy:
  script-src 'sha256-gEh1+8U9S1vkEuQSmmUMTZjyNSu5tIoECP4UXIEjMTk='

The "main.js" script will be allowed to load, because its hash matches the value in the CSP. But its attempt to load "main2.js" will fail.
If we add 'strict-dynamic' to the CSP, then "main.js" will be allowed to load "main2.js":
httpContent-Security-Policy:
  script-src 'sha256-gEh1+8U9S1vkEuQSmmUMTZjyNSu5tIoECP4UXIEjMTk='
  strict-dynamic

The 'strict-dynamic' keyword makes it much easier to create and maintain nonce- or hash-based CSPs, especially when a website uses third-party scripts. It does make your CSP less secure, though, because if the scripts you include create <script> elements based on potential sources of XSS, then the CSP will not protect them.
Refactoring inline JavaScript and eval()
We've seen above that inline JavaScript is disallowed by default in a CSP. With nonces or hashes, a developer can use inline <script> tags, but you'll still need to refactor code to remove other disallowed patterns, including inline event handlers, javascript: URLs, and uses of eval(). For example, inline event handlers should usually be replaced with calls to addEventListener():
html<p onclick="console.log('Hello from an inline event handler')">click me</p>

html<!-- served with the following CSP:
 `script-src 'sha256-AjYfua7yQhrSlg807yyeaggxQ7rP9Lu0Odz7MZv8cL0='`
 -->
<p id="hello">click me</p>
<script>
  const hello = document.querySelector("#hello");
  hello.addEventListener("click", () => {
    console.log("Hello from an inline script");
  });
</script>
Clickjacking protectionThe frame-ancestors directive can be used to control which documents, if any, are allowed to embed this document in a nested browsing context such as an <iframe>. This is an effective protection against clickjacking attacks, because these attacks depend on embedding the target site in a site controlled by the attacker.
The syntax of frame-ancestors is a subset of the fetch directive syntax: you can provide the single keyword value 'none' or one or more source expressions. However, the only source expressions you can use are schemes, hostnames, or the 'self' keyword value.
Unless you need your site to be embeddable, you should set frame-ancestors to 'none':
httpContent-Security-Policy: frame-ancestors 'none'

This directive is a more flexible replacement for the X-Frame-Options header.Upgrading insecure requestsWeb developers are strongly encouraged to serve all their content over HTTPS. In the process of upgrading a site to HTTPS, a site sometimes serves the main document over HTTPS but serves its resources over HTTP, for example, using markup like this:
html<script src="http://example.org/my-cat.js"></script>

This is called mixed content, and the presence of insecure resources greatly weakens the protection afforded by HTTPS. Under the mixed content algorithm that browsers implement, if a document is served over HTTPS, insecure resources are categorized into "upgradable content" and "blockable content". Upgradable content is upgraded to HTTPS, and blockable content is blocked, potentially breaking the page.
The ultimate solution to mixed content is for developers to load all resources over HTTPS. However, even if a site is actually able to serve all content over HTTPS, it can still be very difficult (or even effectively impossible, where archived content is concerned) for a developer to rewrite all the URLs the site uses to load resources.
The upgrade-insecure-requests directive is intended to solve this problem. This directive doesn't have any value: to set it, just include the directive name:
httpContent-Security-Policy: upgrade-insecure-requests

If this directive is set on a document, then the browser will automatically upgrade to HTTPS any HTTP URLs in the following cases:

requests to load resources (such as images, scripts, or fonts)
navigation requests (such as link targets) which are same-origin with the document
navigation requests in nested browsing contexts, such as iframes
form submissions

However, top-level navigation requests whose target is a different origin will not be upgraded.
For example, suppose the document at https://example.org is served with a CSP containing the upgrade-insecure-requests directive, and the document contains markup like this:
html<script src="http://example.org/my-cat.js"></script>
<script src="http://not-example.org/another-cat.js"></script>

The browser will automatically upgrade both of these requests to HTTPS.
Suppose the document also contains this:
html<a href="http://example.org/more-cats">See some more cats!</a>
<a href="http://not-example.org/even-more-cats">More cats, on another site!</a>

The browser will upgrade the first link to HTTPS, but not the second, as it is navigating to a different origin.
This directive is not a substitute for the Strict-Transport-Security header (also known as HSTS), because it does not upgrade external links to a site. Sites should include this directive and the Strict-Transport-Security header.Testing your policyTo ease deployment, CSP can be deployed in report-only mode.
The policy is not enforced, but any violations are sent to the reporting endpoint specified in the policy. Additionally, a report-only header can be used to test a future revision to a policy without actually deploying it.
You can use the Content-Security-Policy-Report-Only HTTP header to specify your policy, like this:
httpContent-Security-Policy-Report-Only: policy

If both a Content-Security-Policy-Report-Only header and a Content-Security-Policy header are present in the same response, both policies are honored.
The policy specified in Content-Security-Policy headers is enforced while the Content-Security-Policy-Report-Only policy generates reports but is not enforced.
Note that unlike a normal content security policy, a report-only policy cannot be delivered in a <meta> element.Violation reportingThe recommended method for reporting CSP violations is to use the Reporting API, declaring endpoints in Reporting-Endpoints and specifying one of them as the CSP reporting target using the Content-Security-Policy header's report-to directive.

Warning:
You can also use the CSP report-uri directive to specify a target URL for CSP violation reports.
This sends a slightly different JSON report format via a POST operation with a Content-Type of application/csp-report.
This approach is deprecated, but you should declare both until report-to is supported in all browsers.
For more information about the approach see the report-uri topic.

A server can inform clients where to send reports using the Reporting-Endpoints HTTP response header.
This header defines one or more endpoint URLs as a comma-separated list.
For example, to define a reporting endpoint named csp-endpoint which accepts reports at https://example.com/csp-reports, the server's response header could look like this:
httpReporting-Endpoints: csp-endpoint="https://example.com/csp-reports"

If you want to have multiple endpoints that handle different types of reports, you would specify them like this:
httpReporting-Endpoints: csp-endpoint="https://example.com/csp-reports",
                     hpkp-endpoint="https://example.com/hpkp-reports"

You can then use the Content-Security-Policy header's report-to directive to specify that a particular defined endpoint should be used for reporting.
For example, to send CSP violation reports to https://example.com/csp-reports for the default-src, you might send response headers that look like the following:
httpReporting-Endpoints: csp-endpoint="https://example.com/csp-reports"
Content-Security-Policy: default-src 'self'; report-to csp-endpoint

When a CSP violation occurs, the browser sends the report as a JSON object to the specified endpoint via an HTTP POST operation, with a Content-Type of application/reports+json.
The report is a serialized form of the Report object containing a type property with a value of "csp-violation", and a body that is the serialized form of a CSPViolationReportBody object.
A typical object might look like this:
json{
  "age": 53531,
  "body": {
    "blockedURL": "inline",
    "columnNumber": 39,
    "disposition": "enforce",
    "documentURL": "https://example.com/csp-report",
    "effectiveDirective": "script-src-elem",
    "lineNumber": 121,
    "originalPolicy": "default-src 'self'; report-to csp-endpoint-name",
    "referrer": "https://www.google.com/",
    "sample": "console.log(\"lo\")",
    "sourceFile": "https://example.com/csp-report",
    "statusCode": 200
  },
  "type": "csp-violation",
  "url": "https://example.com/csp-report",
  "user_agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/127.0.0.0 Safari/537.36"
}

You need to set up a server to receive reports with the given JSON format and content type.
The server handling these requests can then store or process the incoming reports in a way that best suits your needs.See also
Mitigate cross-site scripting with a strict Content Security Policy on web.dev (2024)
Content Security Policy: A successful mess between hardening and mitigation
Content Security Policy Cheat Sheet on owasp.org
CSP Evaluator\n\nContent Security Policy (CSP)Content Security Policy (CSP) is a feature that helps to prevent or minimize the risk of certain types of security threats. It consists of a series of instructions from a website to a browser, which instruct the browser to place restrictions on the things that the code comprising the site is allowed to do.
The primary use case for CSP is to control which resources, in particular JavaScript resources, a document is allowed to load. This is mainly used as a defense against cross-site scripting (XSS) attacks, in which an attacker is able to inject malicious code into the victim's site.
A CSP can have other purposes as well, including defending against clickjacking and helping to ensure that a site's pages will be loaded over HTTPS.
In this guide we'll start by describing how a CSP is delivered to a browser and what it looks like at a high level.
Then we'll describe how it can be used to control which resources are loaded to protect against XSS, and then other use cases such as clickjacking protection and upgrading insecure requests. Note that there's no dependency between the different use cases: if you want to add clickjacking protection but not XSS mitigation, you can just add the directives for that use case.
Finally we'll describe strategies for deploying a CSP and tools that can help to make this process easier.CSP overviewA CSP should be delivered to the browser in the Content-Security-Policy response header. It should be set on all responses to all requests, not just the main document.
You can also specify it using the http-equiv attribute of your document's <meta> element, and this is a useful option for some use cases, such as a client-side-rendered single page app which has only static resources, because you can then avoid relying on any server infrastructure. However, this option does not support all CSP features.
The policy is specified as a series of directives, separated by semi-colons. Each directive controls a different aspect of the security policy. Each directive has a name, followed by a space, followed by a value. Different directives can have different syntaxes.
For example, consider the following CSP:
httpContent-Security-Policy: default-src 'self'; img-src 'self' example.com

It sets two directives:

the default-src directive is set to 'self'
the img-src directive is set to 'self' example.com.


The first directive, default-src, tells the browser to load only resources that are same-origin with the document, unless other more specific directives set a different policy for other resource types. The second, img-src, tells the browser to load images that are same-origin or that are served from example.com.
In the next section, we'll look at the tools available to control resource loads, which is the main function of a CSP.Controlling resource loadingA CSP can be used to control the resources that a document is allowed to load. This is primarily used for protection against cross-site scripting (XSS) attacks.
In this section we'll first see how controlling resource loads can help protect against XSS, then at the tools CSP provides to control what resources are loaded. Finally we'll describe one particular recommended strategy, which is called a "Strict CSP".XSS and resource loadingA cross-site scripting (XSS) attack is one in which an attacker is able to execute their code in the context of the target website. This code is then able to do anything that the website's own code could do, including, for example:

access or modify the content of the site's loaded pages
access or modify content in local storage
make HTTP requests with the user's credentials, enabling them to impersonate the user or access sensitive data

An XSS attack is possible when a website accepts some input which might have been crafted by an attacker (for example, URL parameters, or a comment on a blog post) and then includes it in the page without sanitizing it: that is, without ensuring that it can't be executed as JavaScript.
Websites should protect themselves against XSS by sanitizing this input before including it in the page. A CSP provides a complementary protection, which can protect the website even if sanitization fails.
If sanitization does fail, there are various forms the injected malicious code can take in the document, including:


A <script> tag that links to a malicious source:
html<script src="https://evil.example.com/hacker.js"></script>



A <script> tag that includes inline JavaScript:
html<script>
  console.log("You've been hacked!");
</script>



An inline event handler:
html<img onmouseover="console.log(`You've been hacked!`)" />



A javascript: URL:
html<iframe src="javascript:console.log(`You've been hacked!`)"></iframe>



A string argument to an unsafe API like eval():
jseval("console.log(`You've been hacked!`)");



A CSP can provide protection against all of these. With a CSP, you can:

define the permitted sources for JavaScript files and other resources, effectively blocking loads from https://evil.example.com
disable inline script tags
allow only script tags which have the correct nonce or hash set
disable inline event handlers
disable javascript: URLs
disable dangerous APIs like eval()

In the next section we'll go over the tools CSP provides to do these things.

Note:
Setting a CSP is not an alternative to sanitizing input. Websites should sanitize input and set a CSP, providing defense in depth against XSS.
Fetch directivesFetch directives are used to specify a particular category of resource that a document is allowed to load — such as JavaScript, CSS stylesheets, images, fonts, and so on.
There are different fetch directives for different types of resource. For example:

script-src sets allowed sources for JavaScript.
style-src sets allowed sources for CSS stylesheets.
img-src sets allowed sources for images.

One special fetch directive is default-src, which sets a fallback policy for all resources whose directives are not explicitly listed.
For the complete set of fetch directives, see the reference documentation.
Each fetch directive is specified as either the single keyword 'none' or one or more source expressions, separated by spaces. When more than one source expression is listed: if any of the methods allow the resource, then the resource is allowed.
For example, the CSP below sets two fetch directives:

default-src is given the single source expression 'self'
img-src is given two source expressions: 'self' and example.com


The effect of this is that:

images must be either same-origin with the document, or loaded from example.com
all other resources must be same-origin with the document.

In the next few sections we'll describe some of the ways you can use source expressions to control resource loads. Note that although we're describing them separately, these expressions can in general be combined: for example, a single fetch directive may include nonces as well as hostnames.
Blocking resources
To block a resource type entirely, use the 'none' keyword. For example, the following directive blocks all <object> and <embed> resources:
httpContent-Security-Policy: object-src 'none'

Note that 'none' cannot be combined with any other method in a particular directive: in practice, if any other source expressions are given alongside 'none', then they are ignored.
Nonces
A nonce is the recommended approach for restricting the loading of <script> and <style> resources.
With a nonce, the server generates a random value for every HTTP response, and includes it in a script-src and/or a style-src directive:
httpContent-Security-Policy:
  script-src 'nonce-416d1177-4d12-4e3b-b7c9-f6c409789fb8'

The server then includes this value as the value of the nonce attribute of all the <script> and/or <style> tags that they intend to include in the document.
The browser compares the two values, and loads the resource only if they match. The idea is that even if an attacker can insert some JavaScript into the page, they won't know which nonce the server is going to use, so the browser will refuse to run the script.
For this approach to work, it must not be possible for an attacker to guess the nonce.
In practice this means that the nonce must be different for every HTTP response, and must not be predictable.
This in turn means that the server cannot serve static HTML, because it must insert a new nonce each time. Typically the server would use a templating engine to insert the nonce.
Here's a snippet of Express code to demonstrate:
jsfunction content(nonce) {
  return `
    <script nonce="${nonce}" src="/main.js"></script>
    <script nonce="${nonce}">console.log("hello!");</script>
    <h1>Hello world</h1> 
    `;
}

app.get("/", (req, res) => {
  const nonce = crypto.randomUUID();
  res.setHeader("Content-Security-Policy", `script-src 'nonce-${nonce}'`);
  res.send(content(nonce));
});

On every request, the server generates a new nonce, inserts it into the CSP and into the <script> tags in the returned document. Note that the server:

generates a new nonce for every request
can use nonces with both external and inline scripts
uses the same nonce for all <script> tags in the document

It's important that the server uses some kind of templating to insert nonces, and does not just insert them into all <script> tags: otherwise, the server might inadvertently insert nonces into scripts that were injected by an attacker.
Note that nonces can only be used for elements that have a nonce attribute: that is, only <script> and <style> elements.
Hashes
Fetch directives can also use a hash of the script to guarantee its integrity. With this method, the server:

calculates a hash of the script contents using a hash function (one of SHA-256, SHA-384, or SHA-512)
creates a Base64 encoding of the result
appends a prefix identifying the hash algorithm used (one of sha256-, sha384-, or sha512-).

It then adds the result to the directive:
httpContent-Security-Policy: script-src 'sha256-cd9827ad...'

When the browser receives the document, it hashes the script, compares the result with the value from the header, and loads the script only if they match.
External scripts must also include the integrity attribute for this method to work.
Here's a snippet of Express code, to demonstrate:
jsconst hash1 = "sha256-ex2O7MWOzfczthhKm6azheryNVoERSFrPrdvxRtP8DI=";
const hash2 = "sha256-H/eahVJiG1zBXPQyXX0V6oaxkfiBdmanvfG9eZWSuEc=";

const csp = `script-src '${hash1}' '${hash2}'`;
const content = `
  <script src="./main.js" integrity="${hash2}"></script>
  <script>console.log("hello!");</script>
    <h1>Hello world</h1> 
    `;

app.get("/", (req, res) => {
  res.setHeader("Content-Security-Policy", csp);
  res.send(content);
});

Note that:

We have a separate hash for every script in the document.
For the external script "main.js", we also include the integrity attribute, and give it the same value.
Unlike the example using nonces, both the CSP and the content can be static, because the hashes stay the same. This makes hash-based policies more suitable for static pages or websites that rely on client-side rendering.

Scheme-based policies
Fetch directives can list a scheme, like https:, to allow resources that are served using that scheme. This, for example, allows a policy to require HTTPS for all resource loads:
httpContent-Security-Policy: default-src https:

Location-based policies
Fetch directives can control resource loads based on where the resource is located.
The keyword 'self' allows resources which are same-origin with the document itself:
httpContent-Security-Policy: img-src 'self'

You can also specify one or more hostnames, potentially including wildcards, and only resources served from those hosts will be allowed. This might be used, for example, to allow content to be served from a trusted CDN.
httpContent-Security-Policy: img-src *.example.org

You can specify multiple locations. The following directive allows only images that are same-origin with the current document, or are served from a subdomain of "example.org", or are served from "example.com":
httpContent-Security-Policy: img-src 'self' *.example.org  example.com

Inline JavaScript
If a CSP contains either a default-src or a script-src directive, then inline JavaScript will not be allowed to execute unless extra measures are taken to enable it. This includes:


JavaScript included inside a <script> element in the page:
html<script>
  console.log("Hello from an inline script");
</script>



JavaScript in an inline event handler attribute:
html<img src="x" onerror="console.log('Hello from an inline event handler')" />



JavaScript in a javascript: URL:
html<a href="javascript:console.log('Hello from a javascript: URL')"></a>



The unsafe-inline keyword can be used to override this restriction. For example, the following directive requires all resources to be same-origin, but allows inline JavaScript:
httpContent-Security-Policy: default-src 'self' 'unsafe-inline'


Warning:
Developers should avoid 'unsafe-inline', because it defeats much of the purpose of having a CSP. Inline JavaScript is one of the most common XSS vectors, and one of the most basic goals of a CSP is to prevent its uncontrolled use.

Inline <script> elements are allowed if they are protected by a nonce or a hash, as described above.
If a directive contains nonce or hash expressions, then the unsafe-inline keyword is ignored by browsers.
eval() and similar APIs
Like inline JavaScript, if a CSP contains either a default-src or a script-src directive, then eval() and similar APIs will not be allowed to execute. This includes, among other APIs:


eval() itself:
jseval('console.log("hello from eval()")');



The Function() constructor:
jsconst sum = new Function("a", "b", "return a + b");



The string argument to setTimeout() and setInterval():
jssetTimeout("console.log('hello from setTimeout')", 1);



The unsafe-eval keyword can be used to override this behavior, and as with unsafe-inline, and for the same reasons: developers should avoid unsafe-eval. Sometimes it can be difficult to remove usages of eval(): in these situations, the Trusted Types API can make it safer, by ensuring that the input meets a defined policy.
Unlike unsafe-inline, the unsafe-eval keyword does still work in a directive that contains nonce or hash expressions.Strict CSPTo control script loading as a mitigation against XSS, recommended practice is to use nonce- or hash- based fetch directives. This is called a strict CSP. This type of CSP has two main advantages over a location-based CSP (usually called an allowlist CSP):

Allowlist CSPs are hard to get right and often policies inadvertently whitelist unsafe domains, and hence don't provide effective protection against XSS (see CSP Is Dead, Long Live CSP! On the Insecurity of Whitelists and the Future of Content Security Policy).
Allowlist CSPs can be very large and hard to maintain, in particular when using scripts that are outside of your control. According to How I learned to stop worrying and love the Content Security Policy, just to integrate Google Analytics, a developer is asked to add 187 Google domains to the allowlist.

A nonce-based strict CSP looks like this:
httpContent-Security-Policy:
  script-src 'nonce-{RANDOM}';
  object-src 'none';
  base-uri 'none';

In this CSP, we:

use nonces to control which JavaScript resources are allowed to load
block all object embeds
block all uses of the <base> element to set a base URI.

A hash-based strict CSP is the same, except it uses hashes instead of nonces:
httpContent-Security-Policy:
  script-src 'sha256-{HASHED_SCRIPT}';
  object-src 'none';
  base-uri 'none';

Nonce-based directives are easier to maintain if you can generate responses, including the content itself, dynamically. Otherwise, you need to use hash-based directives. The problem with hash-based directives is that you need to recalculate and reapply the hash if any change is made to the script contents.
The strict-dynamic keyword
As presented above, the strict CSP is difficult to implement when you use scripts which are not under your control. If a third-party script loads any additional scripts, or uses any inline scripts, then this will fail, because the third-party script won't pass the nonce or hash through.
The strict-dynamic keyword is provided to help with this problem. It is a keyword that can be included in a fetch directive, and it has the effect that if a script has a nonce or a hash attached to it, then that script will be allowed to load further scripts which do not themselves have nonces or hashes. That is, the trust placed in a script by a nonce or hash is passed on to scripts that the original script loads (and scripts that they load, and so on).
For example, consider a document like this:
html<html>
  <head>
    <script
      src="./main.js"
      integrity="sha256-gEh1+8U9S1vkEuQSmmUMTZjyNSu5tIoECP4UXIEjMTk="></script>
  </head>
  <body>
    <h1>Example page!</h1>
  </body>
</html>

It includes a script "main.js", which creates and adds another script, "main2.js":
jsconsole.log("hello");

const scriptElement = document.createElement("script");
scriptElement.src = `main2.js`;

document.head.appendChild(scriptElement);

We serve our document with a CSP like this:
httpContent-Security-Policy:
  script-src 'sha256-gEh1+8U9S1vkEuQSmmUMTZjyNSu5tIoECP4UXIEjMTk='

The "main.js" script will be allowed to load, because its hash matches the value in the CSP. But its attempt to load "main2.js" will fail.
If we add 'strict-dynamic' to the CSP, then "main.js" will be allowed to load "main2.js":
httpContent-Security-Policy:
  script-src 'sha256-gEh1+8U9S1vkEuQSmmUMTZjyNSu5tIoECP4UXIEjMTk='
  strict-dynamic

The 'strict-dynamic' keyword makes it much easier to create and maintain nonce- or hash-based CSPs, especially when a website uses third-party scripts. It does make your CSP less secure, though, because if the scripts you include create <script> elements based on potential sources of XSS, then the CSP will not protect them.
Refactoring inline JavaScript and eval()
We've seen above that inline JavaScript is disallowed by default in a CSP. With nonces or hashes, a developer can use inline <script> tags, but you'll still need to refactor code to remove other disallowed patterns, including inline event handlers, javascript: URLs, and uses of eval(). For example, inline event handlers should usually be replaced with calls to addEventListener():
html<p onclick="console.log('Hello from an inline event handler')">click me</p>

html<!-- served with the following CSP:
 `script-src 'sha256-AjYfua7yQhrSlg807yyeaggxQ7rP9Lu0Odz7MZv8cL0='`
 -->
<p id="hello">click me</p>
<script>
  const hello = document.querySelector("#hello");
  hello.addEventListener("click", () => {
    console.log("Hello from an inline script");
  });
</script>
Clickjacking protectionThe frame-ancestors directive can be used to control which documents, if any, are allowed to embed this document in a nested browsing context such as an <iframe>. This is an effective protection against clickjacking attacks, because these attacks depend on embedding the target site in a site controlled by the attacker.
The syntax of frame-ancestors is a subset of the fetch directive syntax: you can provide the single keyword value 'none' or one or more source expressions. However, the only source expressions you can use are schemes, hostnames, or the 'self' keyword value.
Unless you need your site to be embeddable, you should set frame-ancestors to 'none':
httpContent-Security-Policy: frame-ancestors 'none'

This directive is a more flexible replacement for the X-Frame-Options header.Upgrading insecure requestsWeb developers are strongly encouraged to serve all their content over HTTPS. In the process of upgrading a site to HTTPS, a site sometimes serves the main document over HTTPS but serves its resources over HTTP, for example, using markup like this:
html<script src="http://example.org/my-cat.js"></script>

This is called mixed content, and the presence of insecure resources greatly weakens the protection afforded by HTTPS. Under the mixed content algorithm that browsers implement, if a document is served over HTTPS, insecure resources are categorized into "upgradable content" and "blockable content". Upgradable content is upgraded to HTTPS, and blockable content is blocked, potentially breaking the page.
The ultimate solution to mixed content is for developers to load all resources over HTTPS. However, even if a site is actually able to serve all content over HTTPS, it can still be very difficult (or even effectively impossible, where archived content is concerned) for a developer to rewrite all the URLs the site uses to load resources.
The upgrade-insecure-requests directive is intended to solve this problem. This directive doesn't have any value: to set it, just include the directive name:
httpContent-Security-Policy: upgrade-insecure-requests

If this directive is set on a document, then the browser will automatically upgrade to HTTPS any HTTP URLs in the following cases:

requests to load resources (such as images, scripts, or fonts)
navigation requests (such as link targets) which are same-origin with the document
navigation requests in nested browsing contexts, such as iframes
form submissions

However, top-level navigation requests whose target is a different origin will not be upgraded.
For example, suppose the document at https://example.org is served with a CSP containing the upgrade-insecure-requests directive, and the document contains markup like this:
html<script src="http://example.org/my-cat.js"></script>
<script src="http://not-example.org/another-cat.js"></script>

The browser will automatically upgrade both of these requests to HTTPS.
Suppose the document also contains this:
html<a href="http://example.org/more-cats">See some more cats!</a>
<a href="http://not-example.org/even-more-cats">More cats, on another site!</a>

The browser will upgrade the first link to HTTPS, but not the second, as it is navigating to a different origin.
This directive is not a substitute for the Strict-Transport-Security header (also known as HSTS), because it does not upgrade external links to a site. Sites should include this directive and the Strict-Transport-Security header.Testing your policyTo ease deployment, CSP can be deployed in report-only mode.
The policy is not enforced, but any violations are sent to the reporting endpoint specified in the policy. Additionally, a report-only header can be used to test a future revision to a policy without actually deploying it.
You can use the Content-Security-Policy-Report-Only HTTP header to specify your policy, like this:
httpContent-Security-Policy-Report-Only: policy

If both a Content-Security-Policy-Report-Only header and a Content-Security-Policy header are present in the same response, both policies are honored.
The policy specified in Content-Security-Policy headers is enforced while the Content-Security-Policy-Report-Only policy generates reports but is not enforced.
Note that unlike a normal content security policy, a report-only policy cannot be delivered in a <meta> element.Violation reportingThe recommended method for reporting CSP violations is to use the Reporting API, declaring endpoints in Reporting-Endpoints and specifying one of them as the CSP reporting target using the Content-Security-Policy header's report-to directive.

Warning:
You can also use the CSP report-uri directive to specify a target URL for CSP violation reports.
This sends a slightly different JSON report format via a POST operation with a Content-Type of application/csp-report.
This approach is deprecated, but you should declare both until report-to is supported in all browsers.
For more information about the approach see the report-uri topic.

A server can inform clients where to send reports using the Reporting-Endpoints HTTP response header.
This header defines one or more endpoint URLs as a comma-separated list.
For example, to define a reporting endpoint named csp-endpoint which accepts reports at https://example.com/csp-reports, the server's response header could look like this:
httpReporting-Endpoints: csp-endpoint="https://example.com/csp-reports"

If you want to have multiple endpoints that handle different types of reports, you would specify them like this:
httpReporting-Endpoints: csp-endpoint="https://example.com/csp-reports",
                     hpkp-endpoint="https://example.com/hpkp-reports"

You can then use the Content-Security-Policy header's report-to directive to specify that a particular defined endpoint should be used for reporting.
For example, to send CSP violation reports to https://example.com/csp-reports for the default-src, you might send response headers that look like the following:
httpReporting-Endpoints: csp-endpoint="https://example.com/csp-reports"
Content-Security-Policy: default-src 'self'; report-to csp-endpoint

When a CSP violation occurs, the browser sends the report as a JSON object to the specified endpoint via an HTTP POST operation, with a Content-Type of application/reports+json.
The report is a serialized form of the Report object containing a type property with a value of "csp-violation", and a body that is the serialized form of a CSPViolationReportBody object.
A typical object might look like this:
json{
  "age": 53531,
  "body": {
    "blockedURL": "inline",
    "columnNumber": 39,
    "disposition": "enforce",
    "documentURL": "https://example.com/csp-report",
    "effectiveDirective": "script-src-elem",
    "lineNumber": 121,
    "originalPolicy": "default-src 'self'; report-to csp-endpoint-name",
    "referrer": "https://www.google.com/",
    "sample": "console.log(\"lo\")",
    "sourceFile": "https://example.com/csp-report",
    "statusCode": 200
  },
  "type": "csp-violation",
  "url": "https://example.com/csp-report",
  "user_agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/127.0.0.0 Safari/537.36"
}

You need to set up a server to receive reports with the given JSON format and content type.
The server handling these requests can then store or process the incoming reports in a way that best suits your needs.See also
Mitigate cross-site scripting with a strict Content Security Policy on web.dev (2024)
Content Security Policy: A successful mess between hardening and mitigation
Content Security Policy Cheat Sheet on owasp.org
CSP Evaluator
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Apr 10, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nContent Security Policy (CSP)Content Security Policy (CSP) is a feature that helps to prevent or minimize the risk of certain types of security threats. It consists of a series of instructions from a website to a browser, which instruct the browser to place restrictions on the things that the code comprising the site is allowed to do.
The primary use case for CSP is to control which resources, in particular JavaScript resources, a document is allowed to load. This is mainly used as a defense against cross-site scripting (XSS) attacks, in which an attacker is able to inject malicious code into the victim's site.
A CSP can have other purposes as well, including defending against clickjacking and helping to ensure that a site's pages will be loaded over HTTPS.
In this guide we'll start by describing how a CSP is delivered to a browser and what it looks like at a high level.
Then we'll describe how it can be used to control which resources are loaded to protect against XSS, and then other use cases such as clickjacking protection and upgrading insecure requests. Note that there's no dependency between the different use cases: if you want to add clickjacking protection but not XSS mitigation, you can just add the directives for that use case.
Finally we'll describe strategies for deploying a CSP and tools that can help to make this process easier.CSP overviewA CSP should be delivered to the browser in the Content-Security-Policy response header. It should be set on all responses to all requests, not just the main document.
You can also specify it using the http-equiv attribute of your document's <meta> element, and this is a useful option for some use cases, such as a client-side-rendered single page app which has only static resources, because you can then avoid relying on any server infrastructure. However, this option does not support all CSP features.
The policy is specified as a series of directives, separated by semi-colons. Each directive controls a different aspect of the security policy. Each directive has a name, followed by a space, followed by a value. Different directives can have different syntaxes.
For example, consider the following CSP:
httpContent-Security-Policy: default-src 'self'; img-src 'self' example.com

It sets two directives:

the default-src directive is set to 'self'
the img-src directive is set to 'self' example.com.


The first directive, default-src, tells the browser to load only resources that are same-origin with the document, unless other more specific directives set a different policy for other resource types. The second, img-src, tells the browser to load images that are same-origin or that are served from example.com.
In the next section, we'll look at the tools available to control resource loads, which is the main function of a CSP.Controlling resource loadingA CSP can be used to control the resources that a document is allowed to load. This is primarily used for protection against cross-site scripting (XSS) attacks.
In this section we'll first see how controlling resource loads can help protect against XSS, then at the tools CSP provides to control what resources are loaded. Finally we'll describe one particular recommended strategy, which is called a "Strict CSP".XSS and resource loadingA cross-site scripting (XSS) attack is one in which an attacker is able to execute their code in the context of the target website. This code is then able to do anything that the website's own code could do, including, for example:

access or modify the content of the site's loaded pages
access or modify content in local storage
make HTTP requests with the user's credentials, enabling them to impersonate the user or access sensitive data

An XSS attack is possible when a website accepts some input which might have been crafted by an attacker (for example, URL parameters, or a comment on a blog post) and then includes it in the page without sanitizing it: that is, without ensuring that it can't be executed as JavaScript.
Websites should protect themselves against XSS by sanitizing this input before including it in the page. A CSP provides a complementary protection, which can protect the website even if sanitization fails.
If sanitization does fail, there are various forms the injected malicious code can take in the document, including:


A <script> tag that links to a malicious source:
html<script src="https://evil.example.com/hacker.js"></script>



A <script> tag that includes inline JavaScript:
html<script>
  console.log("You've been hacked!");
</script>



An inline event handler:
html<img onmouseover="console.log(`You've been hacked!`)" />



A javascript: URL:
html<iframe src="javascript:console.log(`You've been hacked!`)"></iframe>



A string argument to an unsafe API like eval():
jseval("console.log(`You've been hacked!`)");



A CSP can provide protection against all of these. With a CSP, you can:

define the permitted sources for JavaScript files and other resources, effectively blocking loads from https://evil.example.com
disable inline script tags
allow only script tags which have the correct nonce or hash set
disable inline event handlers
disable javascript: URLs
disable dangerous APIs like eval()

In the next section we'll go over the tools CSP provides to do these things.

Note:
Setting a CSP is not an alternative to sanitizing input. Websites should sanitize input and set a CSP, providing defense in depth against XSS.
Fetch directivesFetch directives are used to specify a particular category of resource that a document is allowed to load — such as JavaScript, CSS stylesheets, images, fonts, and so on.
There are different fetch directives for different types of resource. For example:

script-src sets allowed sources for JavaScript.
style-src sets allowed sources for CSS stylesheets.
img-src sets allowed sources for images.

One special fetch directive is default-src, which sets a fallback policy for all resources whose directives are not explicitly listed.
For the complete set of fetch directives, see the reference documentation.
Each fetch directive is specified as either the single keyword 'none' or one or more source expressions, separated by spaces. When more than one source expression is listed: if any of the methods allow the resource, then the resource is allowed.
For example, the CSP below sets two fetch directives:

default-src is given the single source expression 'self'
img-src is given two source expressions: 'self' and example.com


The effect of this is that:

images must be either same-origin with the document, or loaded from example.com
all other resources must be same-origin with the document.

In the next few sections we'll describe some of the ways you can use source expressions to control resource loads. Note that although we're describing them separately, these expressions can in general be combined: for example, a single fetch directive may include nonces as well as hostnames.
Blocking resources
To block a resource type entirely, use the 'none' keyword. For example, the following directive blocks all <object> and <embed> resources:
httpContent-Security-Policy: object-src 'none'

Note that 'none' cannot be combined with any other method in a particular directive: in practice, if any other source expressions are given alongside 'none', then they are ignored.
Nonces
A nonce is the recommended approach for restricting the loading of <script> and <style> resources.
With a nonce, the server generates a random value for every HTTP response, and includes it in a script-src and/or a style-src directive:
httpContent-Security-Policy:
  script-src 'nonce-416d1177-4d12-4e3b-b7c9-f6c409789fb8'

The server then includes this value as the value of the nonce attribute of all the <script> and/or <style> tags that they intend to include in the document.
The browser compares the two values, and loads the resource only if they match. The idea is that even if an attacker can insert some JavaScript into the page, they won't know which nonce the server is going to use, so the browser will refuse to run the script.
For this approach to work, it must not be possible for an attacker to guess the nonce.
In practice this means that the nonce must be different for every HTTP response, and must not be predictable.
This in turn means that the server cannot serve static HTML, because it must insert a new nonce each time. Typically the server would use a templating engine to insert the nonce.
Here's a snippet of Express code to demonstrate:
jsfunction content(nonce) {
  return `
    <script nonce="${nonce}" src="/main.js"></script>
    <script nonce="${nonce}">console.log("hello!");</script>
    <h1>Hello world</h1> 
    `;
}

app.get("/", (req, res) => {
  const nonce = crypto.randomUUID();
  res.setHeader("Content-Security-Policy", `script-src 'nonce-${nonce}'`);
  res.send(content(nonce));
});

On every request, the server generates a new nonce, inserts it into the CSP and into the <script> tags in the returned document. Note that the server:

generates a new nonce for every request
can use nonces with both external and inline scripts
uses the same nonce for all <script> tags in the document

It's important that the server uses some kind of templating to insert nonces, and does not just insert them into all <script> tags: otherwise, the server might inadvertently insert nonces into scripts that were injected by an attacker.
Note that nonces can only be used for elements that have a nonce attribute: that is, only <script> and <style> elements.
Hashes
Fetch directives can also use a hash of the script to guarantee its integrity. With this method, the server:

calculates a hash of the script contents using a hash function (one of SHA-256, SHA-384, or SHA-512)
creates a Base64 encoding of the result
appends a prefix identifying the hash algorithm used (one of sha256-, sha384-, or sha512-).

It then adds the result to the directive:
httpContent-Security-Policy: script-src 'sha256-cd9827ad...'

When the browser receives the document, it hashes the script, compares the result with the value from the header, and loads the script only if they match.
External scripts must also include the integrity attribute for this method to work.
Here's a snippet of Express code, to demonstrate:
jsconst hash1 = "sha256-ex2O7MWOzfczthhKm6azheryNVoERSFrPrdvxRtP8DI=";
const hash2 = "sha256-H/eahVJiG1zBXPQyXX0V6oaxkfiBdmanvfG9eZWSuEc=";

const csp = `script-src '${hash1}' '${hash2}'`;
const content = `
  <script src="./main.js" integrity="${hash2}"></script>
  <script>console.log("hello!");</script>
    <h1>Hello world</h1> 
    `;

app.get("/", (req, res) => {
  res.setHeader("Content-Security-Policy", csp);
  res.send(content);
});

Note that:

We have a separate hash for every script in the document.
For the external script "main.js", we also include the integrity attribute, and give it the same value.
Unlike the example using nonces, both the CSP and the content can be static, because the hashes stay the same. This makes hash-based policies more suitable for static pages or websites that rely on client-side rendering.

Scheme-based policies
Fetch directives can list a scheme, like https:, to allow resources that are served using that scheme. This, for example, allows a policy to require HTTPS for all resource loads:
httpContent-Security-Policy: default-src https:

Location-based policies
Fetch directives can control resource loads based on where the resource is located.
The keyword 'self' allows resources which are same-origin with the document itself:
httpContent-Security-Policy: img-src 'self'

You can also specify one or more hostnames, potentially including wildcards, and only resources served from those hosts will be allowed. This might be used, for example, to allow content to be served from a trusted CDN.
httpContent-Security-Policy: img-src *.example.org

You can specify multiple locations. The following directive allows only images that are same-origin with the current document, or are served from a subdomain of "example.org", or are served from "example.com":
httpContent-Security-Policy: img-src 'self' *.example.org  example.com

Inline JavaScript
If a CSP contains either a default-src or a script-src directive, then inline JavaScript will not be allowed to execute unless extra measures are taken to enable it. This includes:


JavaScript included inside a <script> element in the page:
html<script>
  console.log("Hello from an inline script");
</script>



JavaScript in an inline event handler attribute:
html<img src="x" onerror="console.log('Hello from an inline event handler')" />



JavaScript in a javascript: URL:
html<a href="javascript:console.log('Hello from a javascript: URL')"></a>



The unsafe-inline keyword can be used to override this restriction. For example, the following directive requires all resources to be same-origin, but allows inline JavaScript:
httpContent-Security-Policy: default-src 'self' 'unsafe-inline'


Warning:
Developers should avoid 'unsafe-inline', because it defeats much of the purpose of having a CSP. Inline JavaScript is one of the most common XSS vectors, and one of the most basic goals of a CSP is to prevent its uncontrolled use.

Inline <script> elements are allowed if they are protected by a nonce or a hash, as described above.
If a directive contains nonce or hash expressions, then the unsafe-inline keyword is ignored by browsers.
eval() and similar APIs
Like inline JavaScript, if a CSP contains either a default-src or a script-src directive, then eval() and similar APIs will not be allowed to execute. This includes, among other APIs:


eval() itself:
jseval('console.log("hello from eval()")');



The Function() constructor:
jsconst sum = new Function("a", "b", "return a + b");



The string argument to setTimeout() and setInterval():
jssetTimeout("console.log('hello from setTimeout')", 1);



The unsafe-eval keyword can be used to override this behavior, and as with unsafe-inline, and for the same reasons: developers should avoid unsafe-eval. Sometimes it can be difficult to remove usages of eval(): in these situations, the Trusted Types API can make it safer, by ensuring that the input meets a defined policy.
Unlike unsafe-inline, the unsafe-eval keyword does still work in a directive that contains nonce or hash expressions.Strict CSPTo control script loading as a mitigation against XSS, recommended practice is to use nonce- or hash- based fetch directives. This is called a strict CSP. This type of CSP has two main advantages over a location-based CSP (usually called an allowlist CSP):

Allowlist CSPs are hard to get right and often policies inadvertently whitelist unsafe domains, and hence don't provide effective protection against XSS (see CSP Is Dead, Long Live CSP! On the Insecurity of Whitelists and the Future of Content Security Policy).
Allowlist CSPs can be very large and hard to maintain, in particular when using scripts that are outside of your control. According to How I learned to stop worrying and love the Content Security Policy, just to integrate Google Analytics, a developer is asked to add 187 Google domains to the allowlist.

A nonce-based strict CSP looks like this:
httpContent-Security-Policy:
  script-src 'nonce-{RANDOM}';
  object-src 'none';
  base-uri 'none';

In this CSP, we:

use nonces to control which JavaScript resources are allowed to load
block all object embeds
block all uses of the <base> element to set a base URI.

A hash-based strict CSP is the same, except it uses hashes instead of nonces:
httpContent-Security-Policy:
  script-src 'sha256-{HASHED_SCRIPT}';
  object-src 'none';
  base-uri 'none';

Nonce-based directives are easier to maintain if you can generate responses, including the content itself, dynamically. Otherwise, you need to use hash-based directives. The problem with hash-based directives is that you need to recalculate and reapply the hash if any change is made to the script contents.
The strict-dynamic keyword
As presented above, the strict CSP is difficult to implement when you use scripts which are not under your control. If a third-party script loads any additional scripts, or uses any inline scripts, then this will fail, because the third-party script won't pass the nonce or hash through.
The strict-dynamic keyword is provided to help with this problem. It is a keyword that can be included in a fetch directive, and it has the effect that if a script has a nonce or a hash attached to it, then that script will be allowed to load further scripts which do not themselves have nonces or hashes. That is, the trust placed in a script by a nonce or hash is passed on to scripts that the original script loads (and scripts that they load, and so on).
For example, consider a document like this:
html<html>
  <head>
    <script
      src="./main.js"
      integrity="sha256-gEh1+8U9S1vkEuQSmmUMTZjyNSu5tIoECP4UXIEjMTk="></script>
  </head>
  <body>
    <h1>Example page!</h1>
  </body>
</html>

It includes a script "main.js", which creates and adds another script, "main2.js":
jsconsole.log("hello");

const scriptElement = document.createElement("script");
scriptElement.src = `main2.js`;

document.head.appendChild(scriptElement);

We serve our document with a CSP like this:
httpContent-Security-Policy:
  script-src 'sha256-gEh1+8U9S1vkEuQSmmUMTZjyNSu5tIoECP4UXIEjMTk='

The "main.js" script will be allowed to load, because its hash matches the value in the CSP. But its attempt to load "main2.js" will fail.
If we add 'strict-dynamic' to the CSP, then "main.js" will be allowed to load "main2.js":
httpContent-Security-Policy:
  script-src 'sha256-gEh1+8U9S1vkEuQSmmUMTZjyNSu5tIoECP4UXIEjMTk='
  strict-dynamic

The 'strict-dynamic' keyword makes it much easier to create and maintain nonce- or hash-based CSPs, especially when a website uses third-party scripts. It does make your CSP less secure, though, because if the scripts you include create <script> elements based on potential sources of XSS, then the CSP will not protect them.
Refactoring inline JavaScript and eval()
We've seen above that inline JavaScript is disallowed by default in a CSP. With nonces or hashes, a developer can use inline <script> tags, but you'll still need to refactor code to remove other disallowed patterns, including inline event handlers, javascript: URLs, and uses of eval(). For example, inline event handlers should usually be replaced with calls to addEventListener():
html<p onclick="console.log('Hello from an inline event handler')">click me</p>

html<!-- served with the following CSP:
 `script-src 'sha256-AjYfua7yQhrSlg807yyeaggxQ7rP9Lu0Odz7MZv8cL0='`
 -->
<p id="hello">click me</p>
<script>
  const hello = document.querySelector("#hello");
  hello.addEventListener("click", () => {
    console.log("Hello from an inline script");
  });
</script>
Clickjacking protectionThe frame-ancestors directive can be used to control which documents, if any, are allowed to embed this document in a nested browsing context such as an <iframe>. This is an effective protection against clickjacking attacks, because these attacks depend on embedding the target site in a site controlled by the attacker.
The syntax of frame-ancestors is a subset of the fetch directive syntax: you can provide the single keyword value 'none' or one or more source expressions. However, the only source expressions you can use are schemes, hostnames, or the 'self' keyword value.
Unless you need your site to be embeddable, you should set frame-ancestors to 'none':
httpContent-Security-Policy: frame-ancestors 'none'

This directive is a more flexible replacement for the X-Frame-Options header.Upgrading insecure requestsWeb developers are strongly encouraged to serve all their content over HTTPS. In the process of upgrading a site to HTTPS, a site sometimes serves the main document over HTTPS but serves its resources over HTTP, for example, using markup like this:
html<script src="http://example.org/my-cat.js"></script>

This is called mixed content, and the presence of insecure resources greatly weakens the protection afforded by HTTPS. Under the mixed content algorithm that browsers implement, if a document is served over HTTPS, insecure resources are categorized into "upgradable content" and "blockable content". Upgradable content is upgraded to HTTPS, and blockable content is blocked, potentially breaking the page.
The ultimate solution to mixed content is for developers to load all resources over HTTPS. However, even if a site is actually able to serve all content over HTTPS, it can still be very difficult (or even effectively impossible, where archived content is concerned) for a developer to rewrite all the URLs the site uses to load resources.
The upgrade-insecure-requests directive is intended to solve this problem. This directive doesn't have any value: to set it, just include the directive name:
httpContent-Security-Policy: upgrade-insecure-requests

If this directive is set on a document, then the browser will automatically upgrade to HTTPS any HTTP URLs in the following cases:

requests to load resources (such as images, scripts, or fonts)
navigation requests (such as link targets) which are same-origin with the document
navigation requests in nested browsing contexts, such as iframes
form submissions

However, top-level navigation requests whose target is a different origin will not be upgraded.
For example, suppose the document at https://example.org is served with a CSP containing the upgrade-insecure-requests directive, and the document contains markup like this:
html<script src="http://example.org/my-cat.js"></script>
<script src="http://not-example.org/another-cat.js"></script>

The browser will automatically upgrade both of these requests to HTTPS.
Suppose the document also contains this:
html<a href="http://example.org/more-cats">See some more cats!</a>
<a href="http://not-example.org/even-more-cats">More cats, on another site!</a>

The browser will upgrade the first link to HTTPS, but not the second, as it is navigating to a different origin.
This directive is not a substitute for the Strict-Transport-Security header (also known as HSTS), because it does not upgrade external links to a site. Sites should include this directive and the Strict-Transport-Security header.Testing your policyTo ease deployment, CSP can be deployed in report-only mode.
The policy is not enforced, but any violations are sent to the reporting endpoint specified in the policy. Additionally, a report-only header can be used to test a future revision to a policy without actually deploying it.
You can use the Content-Security-Policy-Report-Only HTTP header to specify your policy, like this:
httpContent-Security-Policy-Report-Only: policy

If both a Content-Security-Policy-Report-Only header and a Content-Security-Policy header are present in the same response, both policies are honored.
The policy specified in Content-Security-Policy headers is enforced while the Content-Security-Policy-Report-Only policy generates reports but is not enforced.
Note that unlike a normal content security policy, a report-only policy cannot be delivered in a <meta> element.Violation reportingThe recommended method for reporting CSP violations is to use the Reporting API, declaring endpoints in Reporting-Endpoints and specifying one of them as the CSP reporting target using the Content-Security-Policy header's report-to directive.

Warning:
You can also use the CSP report-uri directive to specify a target URL for CSP violation reports.
This sends a slightly different JSON report format via a POST operation with a Content-Type of application/csp-report.
This approach is deprecated, but you should declare both until report-to is supported in all browsers.
For more information about the approach see the report-uri topic.

A server can inform clients where to send reports using the Reporting-Endpoints HTTP response header.
This header defines one or more endpoint URLs as a comma-separated list.
For example, to define a reporting endpoint named csp-endpoint which accepts reports at https://example.com/csp-reports, the server's response header could look like this:
httpReporting-Endpoints: csp-endpoint="https://example.com/csp-reports"

If you want to have multiple endpoints that handle different types of reports, you would specify them like this:
httpReporting-Endpoints: csp-endpoint="https://example.com/csp-reports",
                     hpkp-endpoint="https://example.com/hpkp-reports"

You can then use the Content-Security-Policy header's report-to directive to specify that a particular defined endpoint should be used for reporting.
For example, to send CSP violation reports to https://example.com/csp-reports for the default-src, you might send response headers that look like the following:
httpReporting-Endpoints: csp-endpoint="https://example.com/csp-reports"
Content-Security-Policy: default-src 'self'; report-to csp-endpoint

When a CSP violation occurs, the browser sends the report as a JSON object to the specified endpoint via an HTTP POST operation, with a Content-Type of application/reports+json.
The report is a serialized form of the Report object containing a type property with a value of "csp-violation", and a body that is the serialized form of a CSPViolationReportBody object.
A typical object might look like this:
json{
  "age": 53531,
  "body": {
    "blockedURL": "inline",
    "columnNumber": 39,
    "disposition": "enforce",
    "documentURL": "https://example.com/csp-report",
    "effectiveDirective": "script-src-elem",
    "lineNumber": 121,
    "originalPolicy": "default-src 'self'; report-to csp-endpoint-name",
    "referrer": "https://www.google.com/",
    "sample": "console.log(\"lo\")",
    "sourceFile": "https://example.com/csp-report",
    "statusCode": 200
  },
  "type": "csp-violation",
  "url": "https://example.com/csp-report",
  "user_agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/127.0.0.0 Safari/537.36"
}

You need to set up a server to receive reports with the given JSON format and content type.
The server handling these requests can then store or process the incoming reports in a way that best suits your needs.See also
Mitigate cross-site scripting with a strict Content Security Policy on web.dev (2024)
Content Security Policy: A successful mess between hardening and mitigation
Content Security Policy Cheat Sheet on owasp.org
CSP Evaluator
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Apr 10, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nCross-Origin Resource Policy (CORP)Cross-Origin Resource Policy is a policy set by the Cross-Origin-Resource-Policy HTTP header that lets websites and applications opt in to protection against certain requests from other origins (such as those issued with elements like <script> and <img>), to mitigate speculative side-channel attacks, like Spectre, as well as Cross-Site Script Inclusion attacks.
CORP is an additional layer of protection beyond the default same-origin policy. Cross-Origin Resource Policy complements Cross-Origin Read Blocking (CORB), which is a mechanism to prevent some cross-origin reads by default.

Note:
The policy is only effective for no-cors requests, which are issued by default for CORS-safelisted methods/headers.

As this policy is expressed via a response header, the actual request is not prevented—rather, the browser prevents the result from being leaked by stripping the response body.Usage
Note:
Due to a bug in Chrome, setting Cross-Origin-Resource-Policy can break PDF rendering, preventing visitors from being able to read past the first page of some PDFs. Exercise caution using this header in a production environment.

Web applications set a Cross-Origin Resource Policy via the Cross-Origin-Resource-Policy HTTP response header, which accepts one of three values:

same-site

Only requests from the same Site can read the resource.

Warning:
This is less secure than an origin. The algorithm for checking if two origins are same site is defined in the HTML standard and involves checking the registrable domain.


same-origin

Only requests from the same origin (i.e., scheme + host + port) can read the resource.

cross-origin

Requests from any origin (both same-site and cross-site) can read the resource. This is useful when COEP is used (see below).


httpCross-Origin-Resource-Policy: same-site | same-origin | cross-origin

During a cross-origin resource policy check, if the header is set, the browser will deny no-cors requests issued from a different origin/site.Relationship to cross-origin embedder policy (COEP)The Cross-Origin-Embedder-Policy HTTP response header, when used upon a document, can be used to require subresources to either be same-origin with the document, or come with a Cross-Origin-Resource-Policy HTTP response header to indicate they are okay with being embedded. This is why the cross-origin value exists.HistoryThe concept was originally proposed in 2012 (as From-Origin), but resurrected in Q2 of 2018 and implemented in Safari and Chromium.
In early 2018, two side-channel hardware vulnerabilities known as Meltdown and Spectre were disclosed. These vulnerabilities allowed sensitive data disclosure due to a race condition which arose as part of speculative execution functionality, designed to improve performance.
In response, Chromium shipped Cross-Origin Read Blocking, which automatically protects certain resources (of Content-Type HTML, JSON and XML) against cross-origin reads. If the application does not serve a no-sniff directive, Chromium will attempt to guess the Content-Type and apply the protection anyway.
Cross-Origin-Resource-Policy is an opt-in response header which can protect any resource; there is no need for browsers to sniff MIME types.SpecificationsSpecificationFetch # cross-origin-resource-policy-headerBrowser compatibilitySee also
Cross-Origin-Resource-Policy HTTP Header\n\nCross-Origin Resource Policy (CORP)Cross-Origin Resource Policy is a policy set by the Cross-Origin-Resource-Policy HTTP header that lets websites and applications opt in to protection against certain requests from other origins (such as those issued with elements like <script> and <img>), to mitigate speculative side-channel attacks, like Spectre, as well as Cross-Site Script Inclusion attacks.
CORP is an additional layer of protection beyond the default same-origin policy. Cross-Origin Resource Policy complements Cross-Origin Read Blocking (CORB), which is a mechanism to prevent some cross-origin reads by default.

Note:
The policy is only effective for no-cors requests, which are issued by default for CORS-safelisted methods/headers.

As this policy is expressed via a response header, the actual request is not prevented—rather, the browser prevents the result from being leaked by stripping the response body.Usage
Note:
Due to a bug in Chrome, setting Cross-Origin-Resource-Policy can break PDF rendering, preventing visitors from being able to read past the first page of some PDFs. Exercise caution using this header in a production environment.

Web applications set a Cross-Origin Resource Policy via the Cross-Origin-Resource-Policy HTTP response header, which accepts one of three values:

same-site

Only requests from the same Site can read the resource.

Warning:
This is less secure than an origin. The algorithm for checking if two origins are same site is defined in the HTML standard and involves checking the registrable domain.


same-origin

Only requests from the same origin (i.e., scheme + host + port) can read the resource.

cross-origin

Requests from any origin (both same-site and cross-site) can read the resource. This is useful when COEP is used (see below).


httpCross-Origin-Resource-Policy: same-site | same-origin | cross-origin

During a cross-origin resource policy check, if the header is set, the browser will deny no-cors requests issued from a different origin/site.Relationship to cross-origin embedder policy (COEP)The Cross-Origin-Embedder-Policy HTTP response header, when used upon a document, can be used to require subresources to either be same-origin with the document, or come with a Cross-Origin-Resource-Policy HTTP response header to indicate they are okay with being embedded. This is why the cross-origin value exists.HistoryThe concept was originally proposed in 2012 (as From-Origin), but resurrected in Q2 of 2018 and implemented in Safari and Chromium.
In early 2018, two side-channel hardware vulnerabilities known as Meltdown and Spectre were disclosed. These vulnerabilities allowed sensitive data disclosure due to a race condition which arose as part of speculative execution functionality, designed to improve performance.
In response, Chromium shipped Cross-Origin Read Blocking, which automatically protects certain resources (of Content-Type HTML, JSON and XML) against cross-origin reads. If the application does not serve a no-sniff directive, Chromium will attempt to guess the Content-Type and apply the protection anyway.
Cross-Origin-Resource-Policy is an opt-in response header which can protect any resource; there is no need for browsers to sniff MIME types.SpecificationsSpecificationFetch # cross-origin-resource-policy-headerBrowser compatibilitySee also
Cross-Origin-Resource-Policy HTTP Header
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Apr 3, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nCross-Origin Resource Policy (CORP)Cross-Origin Resource Policy is a policy set by the Cross-Origin-Resource-Policy HTTP header that lets websites and applications opt in to protection against certain requests from other origins (such as those issued with elements like <script> and <img>), to mitigate speculative side-channel attacks, like Spectre, as well as Cross-Site Script Inclusion attacks.
CORP is an additional layer of protection beyond the default same-origin policy. Cross-Origin Resource Policy complements Cross-Origin Read Blocking (CORB), which is a mechanism to prevent some cross-origin reads by default.

Note:
The policy is only effective for no-cors requests, which are issued by default for CORS-safelisted methods/headers.

As this policy is expressed via a response header, the actual request is not prevented—rather, the browser prevents the result from being leaked by stripping the response body.Usage
Note:
Due to a bug in Chrome, setting Cross-Origin-Resource-Policy can break PDF rendering, preventing visitors from being able to read past the first page of some PDFs. Exercise caution using this header in a production environment.

Web applications set a Cross-Origin Resource Policy via the Cross-Origin-Resource-Policy HTTP response header, which accepts one of three values:

same-site

Only requests from the same Site can read the resource.

Warning:
This is less secure than an origin. The algorithm for checking if two origins are same site is defined in the HTML standard and involves checking the registrable domain.


same-origin

Only requests from the same origin (i.e., scheme + host + port) can read the resource.

cross-origin

Requests from any origin (both same-site and cross-site) can read the resource. This is useful when COEP is used (see below).


httpCross-Origin-Resource-Policy: same-site | same-origin | cross-origin

During a cross-origin resource policy check, if the header is set, the browser will deny no-cors requests issued from a different origin/site.Relationship to cross-origin embedder policy (COEP)The Cross-Origin-Embedder-Policy HTTP response header, when used upon a document, can be used to require subresources to either be same-origin with the document, or come with a Cross-Origin-Resource-Policy HTTP response header to indicate they are okay with being embedded. This is why the cross-origin value exists.HistoryThe concept was originally proposed in 2012 (as From-Origin), but resurrected in Q2 of 2018 and implemented in Safari and Chromium.
In early 2018, two side-channel hardware vulnerabilities known as Meltdown and Spectre were disclosed. These vulnerabilities allowed sensitive data disclosure due to a race condition which arose as part of speculative execution functionality, designed to improve performance.
In response, Chromium shipped Cross-Origin Read Blocking, which automatically protects certain resources (of Content-Type HTML, JSON and XML) against cross-origin reads. If the application does not serve a no-sniff directive, Chromium will attempt to guess the Content-Type and apply the protection anyway.
Cross-Origin-Resource-Policy is an opt-in response header which can protect any resource; there is no need for browsers to sniff MIME types.SpecificationsSpecificationFetch # cross-origin-resource-policy-headerBrowser compatibilitySee also
Cross-Origin-Resource-Policy HTTP Header
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Apr 3, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nCross-Origin Resource Sharing (CORS)Baseline Widely availableThis feature is well established and works across many devices and browser versions. It’s been available across browsers since July 2015.Learn moreSee full compatibilityReport feedbackCross-Origin Resource Sharing (CORS) is an HTTP-header based mechanism that allows a server to indicate any origins (domain, scheme, or port) other than its own from which a browser should permit loading resources. CORS also relies on a mechanism by which browsers make a "preflight" request to the server hosting the cross-origin resource, in order to check that the server will permit the actual request. In that preflight, the browser sends headers that indicate the HTTP method and headers that will be used in the actual request.
An example of a cross-origin request: the front-end JavaScript code served from https://domain-a.com uses fetch() to make a request for https://domain-b.com/data.json.
For security reasons, browsers restrict cross-origin HTTP requests initiated from scripts. For example, fetch() and XMLHttpRequest follow the same-origin policy. This means that a web application using those APIs can only request resources from the same origin the application was loaded from unless the response from other origins includes the right CORS headers.

The CORS mechanism supports secure cross-origin requests and data transfers between browsers and servers. Browsers use CORS in APIs such as fetch() or XMLHttpRequest to mitigate the risks of cross-origin HTTP requests.What requests use CORS?This cross-origin sharing standard can enable cross-origin HTTP requests for:

Invocations of fetch() or XMLHttpRequest, as discussed above.
Web Fonts (for cross-domain font usage in @font-face within CSS), so that servers can deploy TrueType fonts that can only be loaded cross-origin and used by websites that are permitted to do so.
WebGL textures.
Images/video frames drawn to a canvas using drawImage().
CSS Shapes from images.

This is a general article about Cross-Origin Resource Sharing and includes a discussion of the necessary HTTP headers.Functional overviewThe Cross-Origin Resource Sharing standard works by adding new HTTP headers that let servers describe which origins are permitted to read that information from a web browser. Additionally, for HTTP request methods that can cause side-effects on server data (in particular, HTTP methods other than GET, or POST with certain MIME types), the specification mandates that browsers "preflight" the request, soliciting supported methods from the server with the HTTP OPTIONS request method, and then, upon "approval" from the server, sending the actual request. Servers can also inform clients whether "credentials" (such as Cookies and HTTP Authentication) should be sent with requests.
CORS failures result in errors but for security reasons, specifics about the error are not available to JavaScript. All the code knows is that an error occurred. The only way to determine what specifically went wrong is to look at the browser's console for details.
Subsequent sections discuss scenarios, as well as provide a breakdown of the HTTP headers used.Examples of access control scenariosWe present three scenarios that demonstrate how Cross-Origin Resource Sharing works. All these examples use fetch(), which can make cross-origin requests in any supporting browser.Simple requestsSome requests don't trigger a CORS preflight. Those are called simple requests from the obsolete CORS spec, though the Fetch spec (which now defines CORS) doesn't use that term.
The motivation is that the <form> element from HTML 4.0 (which predates cross-site fetch() and XMLHttpRequest) can submit simple requests to any origin, so anyone writing a server must already be protecting against cross-site request forgery (CSRF). Under this assumption, the server doesn't have to opt-in (by responding to a preflight request) to receive any request that looks like a form submission, since the threat of CSRF is no worse than that of form submission. However, the server still must opt-in using Access-Control-Allow-Origin to share the response with the script.
A simple request is one that meets all the following conditions:


One of the allowed methods:

GET
HEAD
POST



Apart from the headers automatically set by the user agent (for example, Connection, User-Agent, or the forbidden request headers), the only headers which are allowed to be manually set are the CORS-safelisted request-headers, which are:

Accept
Accept-Language
Content-Language
Content-Type (please note the additional requirements below)
Range (only with a single range header value; e.g., bytes=256- or bytes=127-255)



The only type/subtype combinations allowed for the media type specified in the Content-Type header are:

application/x-www-form-urlencoded
multipart/form-data
text/plain



If the request is made using an XMLHttpRequest object, no event listeners are registered on the object returned by the XMLHttpRequest.upload property used in the request; that is, given an XMLHttpRequest instance xhr, no code has called xhr.upload.addEventListener() to add an event listener to monitor the upload.


No ReadableStream object is used in the request.



Note:
WebKit Nightly and Safari Technology Preview place additional restrictions on the values allowed in the Accept, Accept-Language, and Content-Language headers. If any of those headers have "nonstandard" values, WebKit/Safari does not consider the request to be a "simple request". What values WebKit/Safari consider "nonstandard" is not documented, except in the following WebKit bugs:

Require preflight for non-standard CORS-safelisted request headers Accept, Accept-Language, and Content-Language
Allow commas in Accept, Accept-Language, and Content-Language request headers for simple CORS
Switch to a blacklist model for restricted Accept headers in simple CORS requests

No other browsers implement these extra restrictions because they're not part of the spec.

For example, suppose web content at https://foo.example wishes to fetch JSON content from domain https://bar.other. Code of this sort might be used in JavaScript deployed on foo.example:
jsconst fetchPromise = fetch("https://bar.other");

fetchPromise
  .then((response) => response.json())
  .then((data) => {
    console.log(data);
  });

This operation performs a simple exchange between the client and the server, using CORS headers to handle the privileges:

Let's look at what the browser will send to the server in this case:
httpGET /resources/public-data/ HTTP/1.1
Host: bar.other
User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.14; rv:71.0) Gecko/20100101 Firefox/71.0
Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
Accept-Language: en-us,en;q=0.5
Accept-Encoding: gzip,deflate
Connection: keep-alive
Origin: https://foo.example

The request header of note is Origin, which shows that the invocation is coming from https://foo.example.
Now let's see how the server responds:
httpHTTP/1.1 200 OK
Date: Mon, 01 Dec 2008 00:23:53 GMT
Server: Apache/2
Access-Control-Allow-Origin: *
Keep-Alive: timeout=2, max=100
Connection: Keep-Alive
Transfer-Encoding: chunked
Content-Type: application/xml

[…XML Data…]

In response, the server returns a Access-Control-Allow-Origin header with Access-Control-Allow-Origin: *, which means that the resource can be accessed by any origin.
httpAccess-Control-Allow-Origin: *

This pattern of the Origin and Access-Control-Allow-Origin headers is the simplest use of the access control protocol. If the resource owners at https://bar.other wished to restrict access to the resource to requests only from https://foo.example (i.e., no domain other than https://foo.example can access the resource in a cross-origin manner), they would send:
httpAccess-Control-Allow-Origin: https://foo.example


Note:
When responding to a credentialed requests request, the server must specify an origin in the value of the Access-Control-Allow-Origin header, instead of specifying the * wildcard.
Preflighted requestsUnlike simple requests, for "preflighted" requests the browser first sends an HTTP request using the OPTIONS method to the resource on the other origin, in order to determine if the actual request is safe to send. Such cross-origin requests are preflighted since they may have implications for user data.
The following is an example of a request that will be preflighted:
jsconst fetchPromise = fetch("https://bar.other/doc", {
  method: "POST",
  mode: "cors",
  headers: {
    "Content-Type": "text/xml",
    "X-PINGOTHER": "pingpong",
  },
  body: "<person><name>Arun</name></person>",
});

fetchPromise.then((response) => {
  console.log(response.status);
});

The example above creates an XML body to send with the POST request. Also, a non-standard HTTP X-PINGOTHER request header is set. Such headers are not part of HTTP/1.1, but are generally useful to web applications. Since the request uses a Content-Type of text/xml, and since a custom header is set, this request is preflighted.


Note:
As described below, the actual POST request does not include the Access-Control-Request-* headers; they are needed only for the OPTIONS request.

Let's look at the full exchange between client and server. The first exchange is the preflight request/response:
httpOPTIONS /doc HTTP/1.1
Host: bar.other
User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.14; rv:71.0) Gecko/20100101 Firefox/71.0
Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
Accept-Language: en-us,en;q=0.5
Accept-Encoding: gzip,deflate
Connection: keep-alive
Origin: https://foo.example
Access-Control-Request-Method: POST
Access-Control-Request-Headers: content-type,x-pingother

HTTP/1.1 204 No Content
Date: Mon, 01 Dec 2008 01:15:39 GMT
Server: Apache/2
Access-Control-Allow-Origin: https://foo.example
Access-Control-Allow-Methods: POST, GET, OPTIONS
Access-Control-Allow-Headers: X-PINGOTHER, Content-Type
Access-Control-Max-Age: 86400
Vary: Accept-Encoding, Origin
Keep-Alive: timeout=2, max=100
Connection: Keep-Alive

The first block above represents the preflight request with the OPTIONS method. The browser determines that it needs to send this based on the request parameters that the JavaScript code snippet above was using, so that the server can respond whether it is acceptable to send the request with the actual request parameters. OPTIONS is an HTTP/1.1 method that is used to determine further information from servers, and is a safe method, meaning that it can't be used to change the resource. Note that along with the OPTIONS request, two other request headers are sent:
httpAccess-Control-Request-Method: POST
Access-Control-Request-Headers: content-type,x-pingother

The Access-Control-Request-Method header notifies the server as part of a preflight request that when the actual request is sent, it will do so with a POST request method. The Access-Control-Request-Headers header notifies the server that when the actual request is sent, it will do so with X-PINGOTHER and Content-Type custom headers. Now the server has an opportunity to determine whether it can accept a request under these conditions.
The second block above is the response that the server returns, which indicate that the request method (POST) and request headers (X-PINGOTHER) are acceptable. Let's have a closer look at the following lines:
httpAccess-Control-Allow-Origin: https://foo.example
Access-Control-Allow-Methods: POST, GET, OPTIONS
Access-Control-Allow-Headers: X-PINGOTHER, Content-Type
Access-Control-Max-Age: 86400

The server responds with Access-Control-Allow-Origin: https://foo.example, restricting access to the requesting origin domain only. It also responds with Access-Control-Allow-Methods, which says that POST and GET are valid methods to query the resource in question (this header is similar to the Allow response header, but used strictly within the context of access control).
The server also sends Access-Control-Allow-Headers with a value of X-PINGOTHER, Content-Type, confirming that these are permitted headers to be used with the actual request. Like Access-Control-Allow-Methods, Access-Control-Allow-Headers is a comma-separated list of acceptable headers.
Finally, Access-Control-Max-Age gives the value in seconds for how long the response to the preflight request can be cached without sending another preflight request. The default value is 5 seconds. In the present case, the max age is 86400 seconds (= 24 hours). Note that each browser has a maximum internal value that takes precedence when the Access-Control-Max-Age exceeds it.
Once the preflight request is complete, the real request is sent:
httpPOST /doc HTTP/1.1
Host: bar.other
User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.14; rv:71.0) Gecko/20100101 Firefox/71.0
Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
Accept-Language: en-us,en;q=0.5
Accept-Encoding: gzip,deflate
Connection: keep-alive
X-PINGOTHER: pingpong
Content-Type: text/xml; charset=UTF-8
Referer: https://foo.example/examples/preflightInvocation.html
Content-Length: 55
Origin: https://foo.example
Pragma: no-cache
Cache-Control: no-cache

<person><name>Arun</name></person>

HTTP/1.1 200 OK
Date: Mon, 01 Dec 2008 01:15:40 GMT
Server: Apache/2
Access-Control-Allow-Origin: https://foo.example
Vary: Accept-Encoding, Origin
Content-Encoding: gzip
Content-Length: 235
Keep-Alive: timeout=2, max=99
Connection: Keep-Alive
Content-Type: text/plain

[Some XML content]

Preflighted requests and redirects
Not all browsers currently support following redirects after a preflighted request. If a redirect occurs after such a request, some browsers currently will report an error message such as the following:

The request was redirected to https://example.com/foo, which is disallowed for cross-origin requests that require preflight.
Request requires preflight, which is disallowed to follow cross-origin redirects.

The CORS protocol originally required that behavior but was subsequently changed to no longer require it. However, not all browsers have implemented the change, and thus still exhibit the originally required behavior.
Until browsers catch up with the spec, you may be able to work around this limitation by doing one or both of the following:

Change the server-side behavior to avoid the preflight and/or to avoid the redirect
Change the request such that it is a simple request that doesn't cause a preflight

If that's not possible, then another way is to:

Make a simple request (using Response.url for the Fetch API, or XMLHttpRequest.responseURL) to determine what URL the real preflighted request would end up at.
Make another request (the real request) using the URL you obtained from Response.url or XMLHttpRequest.responseURL in the first step.

However, if the request is one that triggers a preflight due to the presence of the Authorization header in the request, you won't be able to work around the limitation using the steps above. And you won't be able to work around it at all unless you have control over the server the request is being made to.Requests with credentials
Note:
When making credentialed requests to a different domain, third-party cookie policies will still apply. The policy is always enforced regardless of any setup on the server and the client as described in this chapter.

The most interesting capability exposed by both fetch() or XMLHttpRequest and CORS is the ability to make "credentialed" requests that are aware of HTTP cookies and HTTP Authentication information. By default, in cross-origin fetch() or XMLHttpRequest calls, browsers will not send credentials.
To ask for a fetch() request to include credentials, set the credentials option to "include".
To ask for an XMLHttpRequest request to include credentials, set the XMLHttpRequest.withCredentials property to true.
In this example, content originally loaded from https://foo.example makes a GET request to a resource on https://bar.other which sets Cookies. Content on foo.example might contain JavaScript like this:
jsconst url = "https://bar.other/resources/credentialed-content/";

const request = new Request(url, { credentials: "include" });

const fetchPromise = fetch(request);
fetchPromise.then((response) => console.log(response));

This code creates a Request object, setting the credentials option to "include" in the constructor, then passes this request into fetch(). Since this is a simple GET request, it is not preflighted but the browser will reject any response that does not have the Access-Control-Allow-Credentials: true header, and not make the response available to the invoking web content.

Here is a sample exchange between client and server:
httpGET /resources/credentialed-content/ HTTP/1.1
Host: bar.other
User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.14; rv:71.0) Gecko/20100101 Firefox/71.0
Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
Accept-Language: en-us,en;q=0.5
Accept-Encoding: gzip,deflate
Connection: keep-alive
Referer: https://foo.example/examples/credential.html
Origin: https://foo.example
Cookie: pageAccess=2

HTTP/1.1 200 OK
Date: Mon, 01 Dec 2008 01:34:52 GMT
Server: Apache/2
Access-Control-Allow-Origin: https://foo.example
Access-Control-Allow-Credentials: true
Cache-Control: no-cache
Pragma: no-cache
Set-Cookie: pageAccess=3; expires=Wed, 31-Dec-2008 01:34:53 GMT
Vary: Accept-Encoding, Origin
Content-Encoding: gzip
Content-Length: 106
Keep-Alive: timeout=2, max=100
Connection: Keep-Alive
Content-Type: text/plain

[text/plain content]

Although the request's Cookie header contains the cookie destined for the content on https://bar.other, if bar.other did not respond with an Access-Control-Allow-Credentials with value true, as demonstrated in this example, the response would be ignored and not made available to the web content.
Preflight requests and credentials
CORS-preflight requests must never include credentials. The response to a preflight request must specify Access-Control-Allow-Credentials: true to indicate that the actual request can be made with credentials.

Note:
Some enterprise authentication services require that TLS client certificates be sent in preflight requests, in contravention of the Fetch specification.
Firefox 87 allows this non-compliant behavior to be enabled by setting the preference: network.cors_preflight.allow_client_cert to true (Firefox bug 1511151). Chromium-based browsers currently always send TLS client certificates in CORS preflight requests (Chrome bug 775438).

Credentialed requests and wildcards
When responding to a credentialed request:

The server must not specify the * wildcard for the Access-Control-Allow-Origin response-header value, but must instead specify an explicit origin; for example: Access-Control-Allow-Origin: https://example.com
The server must not specify the * wildcard for the Access-Control-Allow-Headers response-header value, but must instead specify an explicit list of header names; for example, Access-Control-Allow-Headers: X-PINGOTHER, Content-Type
The server must not specify the * wildcard for the Access-Control-Allow-Methods response-header value, but must instead specify an explicit list of method names; for example, Access-Control-Allow-Methods: POST, GET
The server must not specify the * wildcard for the Access-Control-Expose-Headers response-header value, but must instead specify an explicit list of header names; for example, Access-Control-Expose-Headers: Content-Encoding, Kuma-Revision

If a request includes a credential (most commonly a Cookie header) and the response includes an Access-Control-Allow-Origin: * header (that is, with the wildcard), the browser will block access to the response, and report a CORS error in the devtools console.
But if a request does include a credential (like the Cookie header) and the response includes an actual origin rather than the wildcard (like, for example, Access-Control-Allow-Origin: https://example.com), then the browser will allow access to the response from the specified origin.
Also note that any Set-Cookie response header in a response would not set a cookie if the Access-Control-Allow-Origin value in that response is the * wildcard rather an actual origin.
Third-party cookies
Note that cookies set in CORS responses are subject to normal third-party cookie policies. In the example above, the page is loaded from foo.example but the Cookie header in the response is sent by bar.other, and would thus not be saved if the user's browser is configured to reject all third-party cookies.
Cookie in the request may also be suppressed in normal third-party cookie policies. The enforced cookie policy may therefore nullify the capability described in this chapter, effectively preventing you from making credentialed requests whatsoever.
Cookie policy around the SameSite attribute would apply.The HTTP response headersThis section lists the HTTP response headers that servers return for access control requests as defined by the Cross-Origin Resource Sharing specification. The previous section gives an overview of these in action.Access-Control-Allow-OriginA returned resource may have one Access-Control-Allow-Origin header with the following syntax:
httpAccess-Control-Allow-Origin: <origin> | *

Access-Control-Allow-Origin specifies either a single origin which tells browsers to allow that origin to access the resource; or else — for requests without credentials — the * wildcard tells browsers to allow any origin to access the resource.
For example, to allow code from the origin https://mozilla.org to access the resource, you can specify:
httpAccess-Control-Allow-Origin: https://mozilla.org
Vary: Origin

If the server specifies a single origin (that may dynamically change based on the requesting origin as part of an allowlist) rather than the * wildcard, then the server should also include Origin in the Vary response header to indicate to clients that server responses will differ based on the value of the Origin request header.Access-Control-Expose-HeadersThe Access-Control-Expose-Headers header adds the specified headers to the allowlist that JavaScript (such as Response.headers) in browsers is allowed to access.
httpAccess-Control-Expose-Headers: <header-name>[, <header-name>]*

For example, the following:
httpAccess-Control-Expose-Headers: X-My-Custom-Header, X-Another-Custom-Header

…would allow the X-My-Custom-Header and X-Another-Custom-Header headers to be exposed to the browser.Access-Control-Max-AgeThe Access-Control-Max-Age header indicates how long the results of a preflight request can be cached. For an example of a preflight request, see the above examples.
httpAccess-Control-Max-Age: <delta-seconds>

The delta-seconds parameter indicates the number of seconds the results can be cached.Access-Control-Allow-CredentialsThe Access-Control-Allow-Credentials header indicates whether or not the response to the request can be exposed when the credentials flag is true. When used as part of a response to a preflight request, this indicates whether or not the actual request can be made using credentials. Note that simple GET requests are not preflighted, and so if a request is made for a resource with credentials, if this header is not returned with the resource, the response is ignored by the browser and not returned to web content.
httpAccess-Control-Allow-Credentials: true

Credentialed requests are discussed above.Access-Control-Allow-MethodsThe Access-Control-Allow-Methods header specifies the method or methods allowed when accessing the resource. This is used in response to a preflight request. The conditions under which a request is preflighted are discussed above.
httpAccess-Control-Allow-Methods: <method>[, <method>]*

An example of a preflight request is given above, including an example which sends this header to the browser.Access-Control-Allow-HeadersThe Access-Control-Allow-Headers header is used in response to a preflight request to indicate which HTTP headers can be used when making the actual request. This header is the server side response to the browser's Access-Control-Request-Headers header.
httpAccess-Control-Allow-Headers: <header-name>[, <header-name>]*
The HTTP request headersThis section lists headers that clients may use when issuing HTTP requests in order to make use of the cross-origin sharing feature. Note that these headers are set for you when making invocations to servers. Developers making cross-origin requests do not have to set any cross-origin sharing request headers programmatically.OriginThe Origin header indicates the origin of the cross-origin access request or preflight request.
httpOrigin: <origin>

The origin is a URL indicating the server from which the request is initiated. It does not include any path information, only the server name.

Note:
The origin value can be null.

Note that in any access control request, the Origin header is always sent.Access-Control-Request-MethodThe Access-Control-Request-Method is used when issuing a preflight request to let the server know what HTTP method will be used when the actual request is made.
httpAccess-Control-Request-Method: <method>

Examples of this usage can be found above.Access-Control-Request-HeadersThe Access-Control-Request-Headers header is used when issuing a preflight request to let the server know what HTTP headers will be used when the actual request is made (for example, by passing them as the headers option). This browser-side header will be answered by the complementary server-side header of Access-Control-Allow-Headers.
httpAccess-Control-Request-Headers: <field-name>[,<field-name>]*

Examples of this usage can be found above.SpecificationsSpecificationFetch # http-access-control-allow-originBrowser compatibilitySee also

CORS errors


Enable CORS: I want to add CORS support to my server


Fetch API

XMLHttpRequest

Will it CORS? - an interactive CORS explainer & generator


How to run Chrome browser without CORS


Using CORS with All (Modern) Browsers


Stack Overflow answer with "how to" info for dealing with common problems:

How to avoid the CORS preflight
How to use a CORS proxy to get around "No Access-Control-Allow-Origin header"
How to fix "Access-Control-Allow-Origin header must not be the wildcard"\n\nCross-Origin Resource Sharing (CORS)Baseline Widely availableThis feature is well established and works across many devices and browser versions. It’s been available across browsers since July 2015.Learn moreSee full compatibilityReport feedbackCross-Origin Resource Sharing (CORS) is an HTTP-header based mechanism that allows a server to indicate any origins (domain, scheme, or port) other than its own from which a browser should permit loading resources. CORS also relies on a mechanism by which browsers make a "preflight" request to the server hosting the cross-origin resource, in order to check that the server will permit the actual request. In that preflight, the browser sends headers that indicate the HTTP method and headers that will be used in the actual request.
An example of a cross-origin request: the front-end JavaScript code served from https://domain-a.com uses fetch() to make a request for https://domain-b.com/data.json.
For security reasons, browsers restrict cross-origin HTTP requests initiated from scripts. For example, fetch() and XMLHttpRequest follow the same-origin policy. This means that a web application using those APIs can only request resources from the same origin the application was loaded from unless the response from other origins includes the right CORS headers.

The CORS mechanism supports secure cross-origin requests and data transfers between browsers and servers. Browsers use CORS in APIs such as fetch() or XMLHttpRequest to mitigate the risks of cross-origin HTTP requests.What requests use CORS?This cross-origin sharing standard can enable cross-origin HTTP requests for:

Invocations of fetch() or XMLHttpRequest, as discussed above.
Web Fonts (for cross-domain font usage in @font-face within CSS), so that servers can deploy TrueType fonts that can only be loaded cross-origin and used by websites that are permitted to do so.
WebGL textures.
Images/video frames drawn to a canvas using drawImage().
CSS Shapes from images.

This is a general article about Cross-Origin Resource Sharing and includes a discussion of the necessary HTTP headers.Functional overviewThe Cross-Origin Resource Sharing standard works by adding new HTTP headers that let servers describe which origins are permitted to read that information from a web browser. Additionally, for HTTP request methods that can cause side-effects on server data (in particular, HTTP methods other than GET, or POST with certain MIME types), the specification mandates that browsers "preflight" the request, soliciting supported methods from the server with the HTTP OPTIONS request method, and then, upon "approval" from the server, sending the actual request. Servers can also inform clients whether "credentials" (such as Cookies and HTTP Authentication) should be sent with requests.
CORS failures result in errors but for security reasons, specifics about the error are not available to JavaScript. All the code knows is that an error occurred. The only way to determine what specifically went wrong is to look at the browser's console for details.
Subsequent sections discuss scenarios, as well as provide a breakdown of the HTTP headers used.Examples of access control scenariosWe present three scenarios that demonstrate how Cross-Origin Resource Sharing works. All these examples use fetch(), which can make cross-origin requests in any supporting browser.Simple requestsSome requests don't trigger a CORS preflight. Those are called simple requests from the obsolete CORS spec, though the Fetch spec (which now defines CORS) doesn't use that term.
The motivation is that the <form> element from HTML 4.0 (which predates cross-site fetch() and XMLHttpRequest) can submit simple requests to any origin, so anyone writing a server must already be protecting against cross-site request forgery (CSRF). Under this assumption, the server doesn't have to opt-in (by responding to a preflight request) to receive any request that looks like a form submission, since the threat of CSRF is no worse than that of form submission. However, the server still must opt-in using Access-Control-Allow-Origin to share the response with the script.
A simple request is one that meets all the following conditions:


One of the allowed methods:

GET
HEAD
POST



Apart from the headers automatically set by the user agent (for example, Connection, User-Agent, or the forbidden request headers), the only headers which are allowed to be manually set are the CORS-safelisted request-headers, which are:

Accept
Accept-Language
Content-Language
Content-Type (please note the additional requirements below)
Range (only with a single range header value; e.g., bytes=256- or bytes=127-255)



The only type/subtype combinations allowed for the media type specified in the Content-Type header are:

application/x-www-form-urlencoded
multipart/form-data
text/plain



If the request is made using an XMLHttpRequest object, no event listeners are registered on the object returned by the XMLHttpRequest.upload property used in the request; that is, given an XMLHttpRequest instance xhr, no code has called xhr.upload.addEventListener() to add an event listener to monitor the upload.


No ReadableStream object is used in the request.



Note:
WebKit Nightly and Safari Technology Preview place additional restrictions on the values allowed in the Accept, Accept-Language, and Content-Language headers. If any of those headers have "nonstandard" values, WebKit/Safari does not consider the request to be a "simple request". What values WebKit/Safari consider "nonstandard" is not documented, except in the following WebKit bugs:

Require preflight for non-standard CORS-safelisted request headers Accept, Accept-Language, and Content-Language
Allow commas in Accept, Accept-Language, and Content-Language request headers for simple CORS
Switch to a blacklist model for restricted Accept headers in simple CORS requests

No other browsers implement these extra restrictions because they're not part of the spec.

For example, suppose web content at https://foo.example wishes to fetch JSON content from domain https://bar.other. Code of this sort might be used in JavaScript deployed on foo.example:
jsconst fetchPromise = fetch("https://bar.other");

fetchPromise
  .then((response) => response.json())
  .then((data) => {
    console.log(data);
  });

This operation performs a simple exchange between the client and the server, using CORS headers to handle the privileges:

Let's look at what the browser will send to the server in this case:
httpGET /resources/public-data/ HTTP/1.1
Host: bar.other
User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.14; rv:71.0) Gecko/20100101 Firefox/71.0
Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
Accept-Language: en-us,en;q=0.5
Accept-Encoding: gzip,deflate
Connection: keep-alive
Origin: https://foo.example

The request header of note is Origin, which shows that the invocation is coming from https://foo.example.
Now let's see how the server responds:
httpHTTP/1.1 200 OK
Date: Mon, 01 Dec 2008 00:23:53 GMT
Server: Apache/2
Access-Control-Allow-Origin: *
Keep-Alive: timeout=2, max=100
Connection: Keep-Alive
Transfer-Encoding: chunked
Content-Type: application/xml

[…XML Data…]

In response, the server returns a Access-Control-Allow-Origin header with Access-Control-Allow-Origin: *, which means that the resource can be accessed by any origin.
httpAccess-Control-Allow-Origin: *

This pattern of the Origin and Access-Control-Allow-Origin headers is the simplest use of the access control protocol. If the resource owners at https://bar.other wished to restrict access to the resource to requests only from https://foo.example (i.e., no domain other than https://foo.example can access the resource in a cross-origin manner), they would send:
httpAccess-Control-Allow-Origin: https://foo.example


Note:
When responding to a credentialed requests request, the server must specify an origin in the value of the Access-Control-Allow-Origin header, instead of specifying the * wildcard.
Preflighted requestsUnlike simple requests, for "preflighted" requests the browser first sends an HTTP request using the OPTIONS method to the resource on the other origin, in order to determine if the actual request is safe to send. Such cross-origin requests are preflighted since they may have implications for user data.
The following is an example of a request that will be preflighted:
jsconst fetchPromise = fetch("https://bar.other/doc", {
  method: "POST",
  mode: "cors",
  headers: {
    "Content-Type": "text/xml",
    "X-PINGOTHER": "pingpong",
  },
  body: "<person><name>Arun</name></person>",
});

fetchPromise.then((response) => {
  console.log(response.status);
});

The example above creates an XML body to send with the POST request. Also, a non-standard HTTP X-PINGOTHER request header is set. Such headers are not part of HTTP/1.1, but are generally useful to web applications. Since the request uses a Content-Type of text/xml, and since a custom header is set, this request is preflighted.


Note:
As described below, the actual POST request does not include the Access-Control-Request-* headers; they are needed only for the OPTIONS request.

Let's look at the full exchange between client and server. The first exchange is the preflight request/response:
httpOPTIONS /doc HTTP/1.1
Host: bar.other
User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.14; rv:71.0) Gecko/20100101 Firefox/71.0
Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
Accept-Language: en-us,en;q=0.5
Accept-Encoding: gzip,deflate
Connection: keep-alive
Origin: https://foo.example
Access-Control-Request-Method: POST
Access-Control-Request-Headers: content-type,x-pingother

HTTP/1.1 204 No Content
Date: Mon, 01 Dec 2008 01:15:39 GMT
Server: Apache/2
Access-Control-Allow-Origin: https://foo.example
Access-Control-Allow-Methods: POST, GET, OPTIONS
Access-Control-Allow-Headers: X-PINGOTHER, Content-Type
Access-Control-Max-Age: 86400
Vary: Accept-Encoding, Origin
Keep-Alive: timeout=2, max=100
Connection: Keep-Alive

The first block above represents the preflight request with the OPTIONS method. The browser determines that it needs to send this based on the request parameters that the JavaScript code snippet above was using, so that the server can respond whether it is acceptable to send the request with the actual request parameters. OPTIONS is an HTTP/1.1 method that is used to determine further information from servers, and is a safe method, meaning that it can't be used to change the resource. Note that along with the OPTIONS request, two other request headers are sent:
httpAccess-Control-Request-Method: POST
Access-Control-Request-Headers: content-type,x-pingother

The Access-Control-Request-Method header notifies the server as part of a preflight request that when the actual request is sent, it will do so with a POST request method. The Access-Control-Request-Headers header notifies the server that when the actual request is sent, it will do so with X-PINGOTHER and Content-Type custom headers. Now the server has an opportunity to determine whether it can accept a request under these conditions.
The second block above is the response that the server returns, which indicate that the request method (POST) and request headers (X-PINGOTHER) are acceptable. Let's have a closer look at the following lines:
httpAccess-Control-Allow-Origin: https://foo.example
Access-Control-Allow-Methods: POST, GET, OPTIONS
Access-Control-Allow-Headers: X-PINGOTHER, Content-Type
Access-Control-Max-Age: 86400

The server responds with Access-Control-Allow-Origin: https://foo.example, restricting access to the requesting origin domain only. It also responds with Access-Control-Allow-Methods, which says that POST and GET are valid methods to query the resource in question (this header is similar to the Allow response header, but used strictly within the context of access control).
The server also sends Access-Control-Allow-Headers with a value of X-PINGOTHER, Content-Type, confirming that these are permitted headers to be used with the actual request. Like Access-Control-Allow-Methods, Access-Control-Allow-Headers is a comma-separated list of acceptable headers.
Finally, Access-Control-Max-Age gives the value in seconds for how long the response to the preflight request can be cached without sending another preflight request. The default value is 5 seconds. In the present case, the max age is 86400 seconds (= 24 hours). Note that each browser has a maximum internal value that takes precedence when the Access-Control-Max-Age exceeds it.
Once the preflight request is complete, the real request is sent:
httpPOST /doc HTTP/1.1
Host: bar.other
User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.14; rv:71.0) Gecko/20100101 Firefox/71.0
Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
Accept-Language: en-us,en;q=0.5
Accept-Encoding: gzip,deflate
Connection: keep-alive
X-PINGOTHER: pingpong
Content-Type: text/xml; charset=UTF-8
Referer: https://foo.example/examples/preflightInvocation.html
Content-Length: 55
Origin: https://foo.example
Pragma: no-cache
Cache-Control: no-cache

<person><name>Arun</name></person>

HTTP/1.1 200 OK
Date: Mon, 01 Dec 2008 01:15:40 GMT
Server: Apache/2
Access-Control-Allow-Origin: https://foo.example
Vary: Accept-Encoding, Origin
Content-Encoding: gzip
Content-Length: 235
Keep-Alive: timeout=2, max=99
Connection: Keep-Alive
Content-Type: text/plain

[Some XML content]

Preflighted requests and redirects
Not all browsers currently support following redirects after a preflighted request. If a redirect occurs after such a request, some browsers currently will report an error message such as the following:

The request was redirected to https://example.com/foo, which is disallowed for cross-origin requests that require preflight.
Request requires preflight, which is disallowed to follow cross-origin redirects.

The CORS protocol originally required that behavior but was subsequently changed to no longer require it. However, not all browsers have implemented the change, and thus still exhibit the originally required behavior.
Until browsers catch up with the spec, you may be able to work around this limitation by doing one or both of the following:

Change the server-side behavior to avoid the preflight and/or to avoid the redirect
Change the request such that it is a simple request that doesn't cause a preflight

If that's not possible, then another way is to:

Make a simple request (using Response.url for the Fetch API, or XMLHttpRequest.responseURL) to determine what URL the real preflighted request would end up at.
Make another request (the real request) using the URL you obtained from Response.url or XMLHttpRequest.responseURL in the first step.

However, if the request is one that triggers a preflight due to the presence of the Authorization header in the request, you won't be able to work around the limitation using the steps above. And you won't be able to work around it at all unless you have control over the server the request is being made to.Requests with credentials
Note:
When making credentialed requests to a different domain, third-party cookie policies will still apply. The policy is always enforced regardless of any setup on the server and the client as described in this chapter.

The most interesting capability exposed by both fetch() or XMLHttpRequest and CORS is the ability to make "credentialed" requests that are aware of HTTP cookies and HTTP Authentication information. By default, in cross-origin fetch() or XMLHttpRequest calls, browsers will not send credentials.
To ask for a fetch() request to include credentials, set the credentials option to "include".
To ask for an XMLHttpRequest request to include credentials, set the XMLHttpRequest.withCredentials property to true.
In this example, content originally loaded from https://foo.example makes a GET request to a resource on https://bar.other which sets Cookies. Content on foo.example might contain JavaScript like this:
jsconst url = "https://bar.other/resources/credentialed-content/";

const request = new Request(url, { credentials: "include" });

const fetchPromise = fetch(request);
fetchPromise.then((response) => console.log(response));

This code creates a Request object, setting the credentials option to "include" in the constructor, then passes this request into fetch(). Since this is a simple GET request, it is not preflighted but the browser will reject any response that does not have the Access-Control-Allow-Credentials: true header, and not make the response available to the invoking web content.

Here is a sample exchange between client and server:
httpGET /resources/credentialed-content/ HTTP/1.1
Host: bar.other
User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.14; rv:71.0) Gecko/20100101 Firefox/71.0
Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
Accept-Language: en-us,en;q=0.5
Accept-Encoding: gzip,deflate
Connection: keep-alive
Referer: https://foo.example/examples/credential.html
Origin: https://foo.example
Cookie: pageAccess=2

HTTP/1.1 200 OK
Date: Mon, 01 Dec 2008 01:34:52 GMT
Server: Apache/2
Access-Control-Allow-Origin: https://foo.example
Access-Control-Allow-Credentials: true
Cache-Control: no-cache
Pragma: no-cache
Set-Cookie: pageAccess=3; expires=Wed, 31-Dec-2008 01:34:53 GMT
Vary: Accept-Encoding, Origin
Content-Encoding: gzip
Content-Length: 106
Keep-Alive: timeout=2, max=100
Connection: Keep-Alive
Content-Type: text/plain

[text/plain content]

Although the request's Cookie header contains the cookie destined for the content on https://bar.other, if bar.other did not respond with an Access-Control-Allow-Credentials with value true, as demonstrated in this example, the response would be ignored and not made available to the web content.
Preflight requests and credentials
CORS-preflight requests must never include credentials. The response to a preflight request must specify Access-Control-Allow-Credentials: true to indicate that the actual request can be made with credentials.

Note:
Some enterprise authentication services require that TLS client certificates be sent in preflight requests, in contravention of the Fetch specification.
Firefox 87 allows this non-compliant behavior to be enabled by setting the preference: network.cors_preflight.allow_client_cert to true (Firefox bug 1511151). Chromium-based browsers currently always send TLS client certificates in CORS preflight requests (Chrome bug 775438).

Credentialed requests and wildcards
When responding to a credentialed request:

The server must not specify the * wildcard for the Access-Control-Allow-Origin response-header value, but must instead specify an explicit origin; for example: Access-Control-Allow-Origin: https://example.com
The server must not specify the * wildcard for the Access-Control-Allow-Headers response-header value, but must instead specify an explicit list of header names; for example, Access-Control-Allow-Headers: X-PINGOTHER, Content-Type
The server must not specify the * wildcard for the Access-Control-Allow-Methods response-header value, but must instead specify an explicit list of method names; for example, Access-Control-Allow-Methods: POST, GET
The server must not specify the * wildcard for the Access-Control-Expose-Headers response-header value, but must instead specify an explicit list of header names; for example, Access-Control-Expose-Headers: Content-Encoding, Kuma-Revision

If a request includes a credential (most commonly a Cookie header) and the response includes an Access-Control-Allow-Origin: * header (that is, with the wildcard), the browser will block access to the response, and report a CORS error in the devtools console.
But if a request does include a credential (like the Cookie header) and the response includes an actual origin rather than the wildcard (like, for example, Access-Control-Allow-Origin: https://example.com), then the browser will allow access to the response from the specified origin.
Also note that any Set-Cookie response header in a response would not set a cookie if the Access-Control-Allow-Origin value in that response is the * wildcard rather an actual origin.
Third-party cookies
Note that cookies set in CORS responses are subject to normal third-party cookie policies. In the example above, the page is loaded from foo.example but the Cookie header in the response is sent by bar.other, and would thus not be saved if the user's browser is configured to reject all third-party cookies.
Cookie in the request may also be suppressed in normal third-party cookie policies. The enforced cookie policy may therefore nullify the capability described in this chapter, effectively preventing you from making credentialed requests whatsoever.
Cookie policy around the SameSite attribute would apply.The HTTP response headersThis section lists the HTTP response headers that servers return for access control requests as defined by the Cross-Origin Resource Sharing specification. The previous section gives an overview of these in action.Access-Control-Allow-OriginA returned resource may have one Access-Control-Allow-Origin header with the following syntax:
httpAccess-Control-Allow-Origin: <origin> | *

Access-Control-Allow-Origin specifies either a single origin which tells browsers to allow that origin to access the resource; or else — for requests without credentials — the * wildcard tells browsers to allow any origin to access the resource.
For example, to allow code from the origin https://mozilla.org to access the resource, you can specify:
httpAccess-Control-Allow-Origin: https://mozilla.org
Vary: Origin

If the server specifies a single origin (that may dynamically change based on the requesting origin as part of an allowlist) rather than the * wildcard, then the server should also include Origin in the Vary response header to indicate to clients that server responses will differ based on the value of the Origin request header.Access-Control-Expose-HeadersThe Access-Control-Expose-Headers header adds the specified headers to the allowlist that JavaScript (such as Response.headers) in browsers is allowed to access.
httpAccess-Control-Expose-Headers: <header-name>[, <header-name>]*

For example, the following:
httpAccess-Control-Expose-Headers: X-My-Custom-Header, X-Another-Custom-Header

…would allow the X-My-Custom-Header and X-Another-Custom-Header headers to be exposed to the browser.Access-Control-Max-AgeThe Access-Control-Max-Age header indicates how long the results of a preflight request can be cached. For an example of a preflight request, see the above examples.
httpAccess-Control-Max-Age: <delta-seconds>

The delta-seconds parameter indicates the number of seconds the results can be cached.Access-Control-Allow-CredentialsThe Access-Control-Allow-Credentials header indicates whether or not the response to the request can be exposed when the credentials flag is true. When used as part of a response to a preflight request, this indicates whether or not the actual request can be made using credentials. Note that simple GET requests are not preflighted, and so if a request is made for a resource with credentials, if this header is not returned with the resource, the response is ignored by the browser and not returned to web content.
httpAccess-Control-Allow-Credentials: true

Credentialed requests are discussed above.Access-Control-Allow-MethodsThe Access-Control-Allow-Methods header specifies the method or methods allowed when accessing the resource. This is used in response to a preflight request. The conditions under which a request is preflighted are discussed above.
httpAccess-Control-Allow-Methods: <method>[, <method>]*

An example of a preflight request is given above, including an example which sends this header to the browser.Access-Control-Allow-HeadersThe Access-Control-Allow-Headers header is used in response to a preflight request to indicate which HTTP headers can be used when making the actual request. This header is the server side response to the browser's Access-Control-Request-Headers header.
httpAccess-Control-Allow-Headers: <header-name>[, <header-name>]*
The HTTP request headersThis section lists headers that clients may use when issuing HTTP requests in order to make use of the cross-origin sharing feature. Note that these headers are set for you when making invocations to servers. Developers making cross-origin requests do not have to set any cross-origin sharing request headers programmatically.OriginThe Origin header indicates the origin of the cross-origin access request or preflight request.
httpOrigin: <origin>

The origin is a URL indicating the server from which the request is initiated. It does not include any path information, only the server name.

Note:
The origin value can be null.

Note that in any access control request, the Origin header is always sent.Access-Control-Request-MethodThe Access-Control-Request-Method is used when issuing a preflight request to let the server know what HTTP method will be used when the actual request is made.
httpAccess-Control-Request-Method: <method>

Examples of this usage can be found above.Access-Control-Request-HeadersThe Access-Control-Request-Headers header is used when issuing a preflight request to let the server know what HTTP headers will be used when the actual request is made (for example, by passing them as the headers option). This browser-side header will be answered by the complementary server-side header of Access-Control-Allow-Headers.
httpAccess-Control-Request-Headers: <field-name>[,<field-name>]*

Examples of this usage can be found above.SpecificationsSpecificationFetch # http-access-control-allow-originBrowser compatibilitySee also

CORS errors


Enable CORS: I want to add CORS support to my server


Fetch API

XMLHttpRequest

Will it CORS? - an interactive CORS explainer & generator


How to run Chrome browser without CORS


Using CORS with All (Modern) Browsers


Stack Overflow answer with "how to" info for dealing with common problems:

How to avoid the CORS preflight
How to use a CORS proxy to get around "No Access-Control-Allow-Origin header"
How to fix "Access-Control-Allow-Origin header must not be the wildcard"


Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 14, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nCross-Origin Resource Sharing (CORS)Baseline Widely availableThis feature is well established and works across many devices and browser versions. It’s been available across browsers since July 2015.Learn moreSee full compatibilityReport feedbackCross-Origin Resource Sharing (CORS) is an HTTP-header based mechanism that allows a server to indicate any origins (domain, scheme, or port) other than its own from which a browser should permit loading resources. CORS also relies on a mechanism by which browsers make a "preflight" request to the server hosting the cross-origin resource, in order to check that the server will permit the actual request. In that preflight, the browser sends headers that indicate the HTTP method and headers that will be used in the actual request.
An example of a cross-origin request: the front-end JavaScript code served from https://domain-a.com uses fetch() to make a request for https://domain-b.com/data.json.
For security reasons, browsers restrict cross-origin HTTP requests initiated from scripts. For example, fetch() and XMLHttpRequest follow the same-origin policy. This means that a web application using those APIs can only request resources from the same origin the application was loaded from unless the response from other origins includes the right CORS headers.

The CORS mechanism supports secure cross-origin requests and data transfers between browsers and servers. Browsers use CORS in APIs such as fetch() or XMLHttpRequest to mitigate the risks of cross-origin HTTP requests.What requests use CORS?This cross-origin sharing standard can enable cross-origin HTTP requests for:

Invocations of fetch() or XMLHttpRequest, as discussed above.
Web Fonts (for cross-domain font usage in @font-face within CSS), so that servers can deploy TrueType fonts that can only be loaded cross-origin and used by websites that are permitted to do so.
WebGL textures.
Images/video frames drawn to a canvas using drawImage().
CSS Shapes from images.

This is a general article about Cross-Origin Resource Sharing and includes a discussion of the necessary HTTP headers.Functional overviewThe Cross-Origin Resource Sharing standard works by adding new HTTP headers that let servers describe which origins are permitted to read that information from a web browser. Additionally, for HTTP request methods that can cause side-effects on server data (in particular, HTTP methods other than GET, or POST with certain MIME types), the specification mandates that browsers "preflight" the request, soliciting supported methods from the server with the HTTP OPTIONS request method, and then, upon "approval" from the server, sending the actual request. Servers can also inform clients whether "credentials" (such as Cookies and HTTP Authentication) should be sent with requests.
CORS failures result in errors but for security reasons, specifics about the error are not available to JavaScript. All the code knows is that an error occurred. The only way to determine what specifically went wrong is to look at the browser's console for details.
Subsequent sections discuss scenarios, as well as provide a breakdown of the HTTP headers used.Examples of access control scenariosWe present three scenarios that demonstrate how Cross-Origin Resource Sharing works. All these examples use fetch(), which can make cross-origin requests in any supporting browser.Simple requestsSome requests don't trigger a CORS preflight. Those are called simple requests from the obsolete CORS spec, though the Fetch spec (which now defines CORS) doesn't use that term.
The motivation is that the <form> element from HTML 4.0 (which predates cross-site fetch() and XMLHttpRequest) can submit simple requests to any origin, so anyone writing a server must already be protecting against cross-site request forgery (CSRF). Under this assumption, the server doesn't have to opt-in (by responding to a preflight request) to receive any request that looks like a form submission, since the threat of CSRF is no worse than that of form submission. However, the server still must opt-in using Access-Control-Allow-Origin to share the response with the script.
A simple request is one that meets all the following conditions:


One of the allowed methods:

GET
HEAD
POST



Apart from the headers automatically set by the user agent (for example, Connection, User-Agent, or the forbidden request headers), the only headers which are allowed to be manually set are the CORS-safelisted request-headers, which are:

Accept
Accept-Language
Content-Language
Content-Type (please note the additional requirements below)
Range (only with a single range header value; e.g., bytes=256- or bytes=127-255)



The only type/subtype combinations allowed for the media type specified in the Content-Type header are:

application/x-www-form-urlencoded
multipart/form-data
text/plain



If the request is made using an XMLHttpRequest object, no event listeners are registered on the object returned by the XMLHttpRequest.upload property used in the request; that is, given an XMLHttpRequest instance xhr, no code has called xhr.upload.addEventListener() to add an event listener to monitor the upload.


No ReadableStream object is used in the request.



Note:
WebKit Nightly and Safari Technology Preview place additional restrictions on the values allowed in the Accept, Accept-Language, and Content-Language headers. If any of those headers have "nonstandard" values, WebKit/Safari does not consider the request to be a "simple request". What values WebKit/Safari consider "nonstandard" is not documented, except in the following WebKit bugs:

Require preflight for non-standard CORS-safelisted request headers Accept, Accept-Language, and Content-Language
Allow commas in Accept, Accept-Language, and Content-Language request headers for simple CORS
Switch to a blacklist model for restricted Accept headers in simple CORS requests

No other browsers implement these extra restrictions because they're not part of the spec.

For example, suppose web content at https://foo.example wishes to fetch JSON content from domain https://bar.other. Code of this sort might be used in JavaScript deployed on foo.example:
jsconst fetchPromise = fetch("https://bar.other");

fetchPromise
  .then((response) => response.json())
  .then((data) => {
    console.log(data);
  });

This operation performs a simple exchange between the client and the server, using CORS headers to handle the privileges:

Let's look at what the browser will send to the server in this case:
httpGET /resources/public-data/ HTTP/1.1
Host: bar.other
User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.14; rv:71.0) Gecko/20100101 Firefox/71.0
Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
Accept-Language: en-us,en;q=0.5
Accept-Encoding: gzip,deflate
Connection: keep-alive
Origin: https://foo.example

The request header of note is Origin, which shows that the invocation is coming from https://foo.example.
Now let's see how the server responds:
httpHTTP/1.1 200 OK
Date: Mon, 01 Dec 2008 00:23:53 GMT
Server: Apache/2
Access-Control-Allow-Origin: *
Keep-Alive: timeout=2, max=100
Connection: Keep-Alive
Transfer-Encoding: chunked
Content-Type: application/xml

[…XML Data…]

In response, the server returns a Access-Control-Allow-Origin header with Access-Control-Allow-Origin: *, which means that the resource can be accessed by any origin.
httpAccess-Control-Allow-Origin: *

This pattern of the Origin and Access-Control-Allow-Origin headers is the simplest use of the access control protocol. If the resource owners at https://bar.other wished to restrict access to the resource to requests only from https://foo.example (i.e., no domain other than https://foo.example can access the resource in a cross-origin manner), they would send:
httpAccess-Control-Allow-Origin: https://foo.example


Note:
When responding to a credentialed requests request, the server must specify an origin in the value of the Access-Control-Allow-Origin header, instead of specifying the * wildcard.
Preflighted requestsUnlike simple requests, for "preflighted" requests the browser first sends an HTTP request using the OPTIONS method to the resource on the other origin, in order to determine if the actual request is safe to send. Such cross-origin requests are preflighted since they may have implications for user data.
The following is an example of a request that will be preflighted:
jsconst fetchPromise = fetch("https://bar.other/doc", {
  method: "POST",
  mode: "cors",
  headers: {
    "Content-Type": "text/xml",
    "X-PINGOTHER": "pingpong",
  },
  body: "<person><name>Arun</name></person>",
});

fetchPromise.then((response) => {
  console.log(response.status);
});

The example above creates an XML body to send with the POST request. Also, a non-standard HTTP X-PINGOTHER request header is set. Such headers are not part of HTTP/1.1, but are generally useful to web applications. Since the request uses a Content-Type of text/xml, and since a custom header is set, this request is preflighted.


Note:
As described below, the actual POST request does not include the Access-Control-Request-* headers; they are needed only for the OPTIONS request.

Let's look at the full exchange between client and server. The first exchange is the preflight request/response:
httpOPTIONS /doc HTTP/1.1
Host: bar.other
User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.14; rv:71.0) Gecko/20100101 Firefox/71.0
Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
Accept-Language: en-us,en;q=0.5
Accept-Encoding: gzip,deflate
Connection: keep-alive
Origin: https://foo.example
Access-Control-Request-Method: POST
Access-Control-Request-Headers: content-type,x-pingother

HTTP/1.1 204 No Content
Date: Mon, 01 Dec 2008 01:15:39 GMT
Server: Apache/2
Access-Control-Allow-Origin: https://foo.example
Access-Control-Allow-Methods: POST, GET, OPTIONS
Access-Control-Allow-Headers: X-PINGOTHER, Content-Type
Access-Control-Max-Age: 86400
Vary: Accept-Encoding, Origin
Keep-Alive: timeout=2, max=100
Connection: Keep-Alive

The first block above represents the preflight request with the OPTIONS method. The browser determines that it needs to send this based on the request parameters that the JavaScript code snippet above was using, so that the server can respond whether it is acceptable to send the request with the actual request parameters. OPTIONS is an HTTP/1.1 method that is used to determine further information from servers, and is a safe method, meaning that it can't be used to change the resource. Note that along with the OPTIONS request, two other request headers are sent:
httpAccess-Control-Request-Method: POST
Access-Control-Request-Headers: content-type,x-pingother

The Access-Control-Request-Method header notifies the server as part of a preflight request that when the actual request is sent, it will do so with a POST request method. The Access-Control-Request-Headers header notifies the server that when the actual request is sent, it will do so with X-PINGOTHER and Content-Type custom headers. Now the server has an opportunity to determine whether it can accept a request under these conditions.
The second block above is the response that the server returns, which indicate that the request method (POST) and request headers (X-PINGOTHER) are acceptable. Let's have a closer look at the following lines:
httpAccess-Control-Allow-Origin: https://foo.example
Access-Control-Allow-Methods: POST, GET, OPTIONS
Access-Control-Allow-Headers: X-PINGOTHER, Content-Type
Access-Control-Max-Age: 86400

The server responds with Access-Control-Allow-Origin: https://foo.example, restricting access to the requesting origin domain only. It also responds with Access-Control-Allow-Methods, which says that POST and GET are valid methods to query the resource in question (this header is similar to the Allow response header, but used strictly within the context of access control).
The server also sends Access-Control-Allow-Headers with a value of X-PINGOTHER, Content-Type, confirming that these are permitted headers to be used with the actual request. Like Access-Control-Allow-Methods, Access-Control-Allow-Headers is a comma-separated list of acceptable headers.
Finally, Access-Control-Max-Age gives the value in seconds for how long the response to the preflight request can be cached without sending another preflight request. The default value is 5 seconds. In the present case, the max age is 86400 seconds (= 24 hours). Note that each browser has a maximum internal value that takes precedence when the Access-Control-Max-Age exceeds it.
Once the preflight request is complete, the real request is sent:
httpPOST /doc HTTP/1.1
Host: bar.other
User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.14; rv:71.0) Gecko/20100101 Firefox/71.0
Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
Accept-Language: en-us,en;q=0.5
Accept-Encoding: gzip,deflate
Connection: keep-alive
X-PINGOTHER: pingpong
Content-Type: text/xml; charset=UTF-8
Referer: https://foo.example/examples/preflightInvocation.html
Content-Length: 55
Origin: https://foo.example
Pragma: no-cache
Cache-Control: no-cache

<person><name>Arun</name></person>

HTTP/1.1 200 OK
Date: Mon, 01 Dec 2008 01:15:40 GMT
Server: Apache/2
Access-Control-Allow-Origin: https://foo.example
Vary: Accept-Encoding, Origin
Content-Encoding: gzip
Content-Length: 235
Keep-Alive: timeout=2, max=99
Connection: Keep-Alive
Content-Type: text/plain

[Some XML content]

Preflighted requests and redirects
Not all browsers currently support following redirects after a preflighted request. If a redirect occurs after such a request, some browsers currently will report an error message such as the following:

The request was redirected to https://example.com/foo, which is disallowed for cross-origin requests that require preflight.
Request requires preflight, which is disallowed to follow cross-origin redirects.

The CORS protocol originally required that behavior but was subsequently changed to no longer require it. However, not all browsers have implemented the change, and thus still exhibit the originally required behavior.
Until browsers catch up with the spec, you may be able to work around this limitation by doing one or both of the following:

Change the server-side behavior to avoid the preflight and/or to avoid the redirect
Change the request such that it is a simple request that doesn't cause a preflight

If that's not possible, then another way is to:

Make a simple request (using Response.url for the Fetch API, or XMLHttpRequest.responseURL) to determine what URL the real preflighted request would end up at.
Make another request (the real request) using the URL you obtained from Response.url or XMLHttpRequest.responseURL in the first step.

However, if the request is one that triggers a preflight due to the presence of the Authorization header in the request, you won't be able to work around the limitation using the steps above. And you won't be able to work around it at all unless you have control over the server the request is being made to.Requests with credentials
Note:
When making credentialed requests to a different domain, third-party cookie policies will still apply. The policy is always enforced regardless of any setup on the server and the client as described in this chapter.

The most interesting capability exposed by both fetch() or XMLHttpRequest and CORS is the ability to make "credentialed" requests that are aware of HTTP cookies and HTTP Authentication information. By default, in cross-origin fetch() or XMLHttpRequest calls, browsers will not send credentials.
To ask for a fetch() request to include credentials, set the credentials option to "include".
To ask for an XMLHttpRequest request to include credentials, set the XMLHttpRequest.withCredentials property to true.
In this example, content originally loaded from https://foo.example makes a GET request to a resource on https://bar.other which sets Cookies. Content on foo.example might contain JavaScript like this:
jsconst url = "https://bar.other/resources/credentialed-content/";

const request = new Request(url, { credentials: "include" });

const fetchPromise = fetch(request);
fetchPromise.then((response) => console.log(response));

This code creates a Request object, setting the credentials option to "include" in the constructor, then passes this request into fetch(). Since this is a simple GET request, it is not preflighted but the browser will reject any response that does not have the Access-Control-Allow-Credentials: true header, and not make the response available to the invoking web content.

Here is a sample exchange between client and server:
httpGET /resources/credentialed-content/ HTTP/1.1
Host: bar.other
User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.14; rv:71.0) Gecko/20100101 Firefox/71.0
Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
Accept-Language: en-us,en;q=0.5
Accept-Encoding: gzip,deflate
Connection: keep-alive
Referer: https://foo.example/examples/credential.html
Origin: https://foo.example
Cookie: pageAccess=2

HTTP/1.1 200 OK
Date: Mon, 01 Dec 2008 01:34:52 GMT
Server: Apache/2
Access-Control-Allow-Origin: https://foo.example
Access-Control-Allow-Credentials: true
Cache-Control: no-cache
Pragma: no-cache
Set-Cookie: pageAccess=3; expires=Wed, 31-Dec-2008 01:34:53 GMT
Vary: Accept-Encoding, Origin
Content-Encoding: gzip
Content-Length: 106
Keep-Alive: timeout=2, max=100
Connection: Keep-Alive
Content-Type: text/plain

[text/plain content]

Although the request's Cookie header contains the cookie destined for the content on https://bar.other, if bar.other did not respond with an Access-Control-Allow-Credentials with value true, as demonstrated in this example, the response would be ignored and not made available to the web content.
Preflight requests and credentials
CORS-preflight requests must never include credentials. The response to a preflight request must specify Access-Control-Allow-Credentials: true to indicate that the actual request can be made with credentials.

Note:
Some enterprise authentication services require that TLS client certificates be sent in preflight requests, in contravention of the Fetch specification.
Firefox 87 allows this non-compliant behavior to be enabled by setting the preference: network.cors_preflight.allow_client_cert to true (Firefox bug 1511151). Chromium-based browsers currently always send TLS client certificates in CORS preflight requests (Chrome bug 775438).

Credentialed requests and wildcards
When responding to a credentialed request:

The server must not specify the * wildcard for the Access-Control-Allow-Origin response-header value, but must instead specify an explicit origin; for example: Access-Control-Allow-Origin: https://example.com
The server must not specify the * wildcard for the Access-Control-Allow-Headers response-header value, but must instead specify an explicit list of header names; for example, Access-Control-Allow-Headers: X-PINGOTHER, Content-Type
The server must not specify the * wildcard for the Access-Control-Allow-Methods response-header value, but must instead specify an explicit list of method names; for example, Access-Control-Allow-Methods: POST, GET
The server must not specify the * wildcard for the Access-Control-Expose-Headers response-header value, but must instead specify an explicit list of header names; for example, Access-Control-Expose-Headers: Content-Encoding, Kuma-Revision

If a request includes a credential (most commonly a Cookie header) and the response includes an Access-Control-Allow-Origin: * header (that is, with the wildcard), the browser will block access to the response, and report a CORS error in the devtools console.
But if a request does include a credential (like the Cookie header) and the response includes an actual origin rather than the wildcard (like, for example, Access-Control-Allow-Origin: https://example.com), then the browser will allow access to the response from the specified origin.
Also note that any Set-Cookie response header in a response would not set a cookie if the Access-Control-Allow-Origin value in that response is the * wildcard rather an actual origin.
Third-party cookies
Note that cookies set in CORS responses are subject to normal third-party cookie policies. In the example above, the page is loaded from foo.example but the Cookie header in the response is sent by bar.other, and would thus not be saved if the user's browser is configured to reject all third-party cookies.
Cookie in the request may also be suppressed in normal third-party cookie policies. The enforced cookie policy may therefore nullify the capability described in this chapter, effectively preventing you from making credentialed requests whatsoever.
Cookie policy around the SameSite attribute would apply.The HTTP response headersThis section lists the HTTP response headers that servers return for access control requests as defined by the Cross-Origin Resource Sharing specification. The previous section gives an overview of these in action.Access-Control-Allow-OriginA returned resource may have one Access-Control-Allow-Origin header with the following syntax:
httpAccess-Control-Allow-Origin: <origin> | *

Access-Control-Allow-Origin specifies either a single origin which tells browsers to allow that origin to access the resource; or else — for requests without credentials — the * wildcard tells browsers to allow any origin to access the resource.
For example, to allow code from the origin https://mozilla.org to access the resource, you can specify:
httpAccess-Control-Allow-Origin: https://mozilla.org
Vary: Origin

If the server specifies a single origin (that may dynamically change based on the requesting origin as part of an allowlist) rather than the * wildcard, then the server should also include Origin in the Vary response header to indicate to clients that server responses will differ based on the value of the Origin request header.Access-Control-Expose-HeadersThe Access-Control-Expose-Headers header adds the specified headers to the allowlist that JavaScript (such as Response.headers) in browsers is allowed to access.
httpAccess-Control-Expose-Headers: <header-name>[, <header-name>]*

For example, the following:
httpAccess-Control-Expose-Headers: X-My-Custom-Header, X-Another-Custom-Header

…would allow the X-My-Custom-Header and X-Another-Custom-Header headers to be exposed to the browser.Access-Control-Max-AgeThe Access-Control-Max-Age header indicates how long the results of a preflight request can be cached. For an example of a preflight request, see the above examples.
httpAccess-Control-Max-Age: <delta-seconds>

The delta-seconds parameter indicates the number of seconds the results can be cached.Access-Control-Allow-CredentialsThe Access-Control-Allow-Credentials header indicates whether or not the response to the request can be exposed when the credentials flag is true. When used as part of a response to a preflight request, this indicates whether or not the actual request can be made using credentials. Note that simple GET requests are not preflighted, and so if a request is made for a resource with credentials, if this header is not returned with the resource, the response is ignored by the browser and not returned to web content.
httpAccess-Control-Allow-Credentials: true

Credentialed requests are discussed above.Access-Control-Allow-MethodsThe Access-Control-Allow-Methods header specifies the method or methods allowed when accessing the resource. This is used in response to a preflight request. The conditions under which a request is preflighted are discussed above.
httpAccess-Control-Allow-Methods: <method>[, <method>]*

An example of a preflight request is given above, including an example which sends this header to the browser.Access-Control-Allow-HeadersThe Access-Control-Allow-Headers header is used in response to a preflight request to indicate which HTTP headers can be used when making the actual request. This header is the server side response to the browser's Access-Control-Request-Headers header.
httpAccess-Control-Allow-Headers: <header-name>[, <header-name>]*
The HTTP request headersThis section lists headers that clients may use when issuing HTTP requests in order to make use of the cross-origin sharing feature. Note that these headers are set for you when making invocations to servers. Developers making cross-origin requests do not have to set any cross-origin sharing request headers programmatically.OriginThe Origin header indicates the origin of the cross-origin access request or preflight request.
httpOrigin: <origin>

The origin is a URL indicating the server from which the request is initiated. It does not include any path information, only the server name.

Note:
The origin value can be null.

Note that in any access control request, the Origin header is always sent.Access-Control-Request-MethodThe Access-Control-Request-Method is used when issuing a preflight request to let the server know what HTTP method will be used when the actual request is made.
httpAccess-Control-Request-Method: <method>

Examples of this usage can be found above.Access-Control-Request-HeadersThe Access-Control-Request-Headers header is used when issuing a preflight request to let the server know what HTTP headers will be used when the actual request is made (for example, by passing them as the headers option). This browser-side header will be answered by the complementary server-side header of Access-Control-Allow-Headers.
httpAccess-Control-Request-Headers: <field-name>[,<field-name>]*

Examples of this usage can be found above.SpecificationsSpecificationFetch # http-access-control-allow-originBrowser compatibilitySee also

CORS errors


Enable CORS: I want to add CORS support to my server


Fetch API

XMLHttpRequest

Will it CORS? - an interactive CORS explainer & generator


How to run Chrome browser without CORS


Using CORS with All (Modern) Browsers


Stack Overflow answer with "how to" info for dealing with common problems:

How to avoid the CORS preflight
How to use a CORS proxy to get around "No Access-Control-Allow-Origin header"
How to fix "Access-Control-Allow-Origin header must not be the wildcard"


Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 14, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nCORS errorsCross-Origin Resource Sharing (CORS) is a standard that allows a server to relax the same-origin policy. This is used to explicitly allow some cross-origin requests while rejecting others. For example, if a site offers an embeddable service, it may be necessary to relax certain restrictions. Setting up such a CORS configuration isn't necessarily easy and may present some challenges. In these pages, we'll look into some common CORS error messages and how to resolve them.
If the CORS configuration isn't set up correctly, the browser console will present an error like "Cross-Origin Request Blocked: The Same Origin Policy disallows reading the remote resource at [some site]" indicating that the request was blocked due to violating the CORS security rules. This might not necessarily be a set-up mistake, though. It's possible that the request is in fact intentionally being disallowed by the user's web application and remote external service. However, If the endpoint is meant to be available, some debugging is needed to succeed.Identifying a CORS issueTo understand the underlying issue with the CORS configuration, you need to find out which request is at fault and why. These steps may help you do so:

Navigate to the website or web app in question and open the Developer Tools.
Now try to reproduce the failing transaction and check the console if you are seeing a CORS violation error message. It will probably look like this:


The text of the error message will be something similar to the following:
Cross-Origin Request Blocked: The Same Origin Policy disallows
reading the remote resource at https://some-url-here. (Reason:
additional information here).


Note:
For security reasons, specifics about what went wrong with a CORS request are not available to JavaScript code. All the code knows is that an error occurred. The only way to determine what specifically went wrong is to look at the browser's console for details.
CORS error messagesFirefox's console displays messages in its console when requests fail due to CORS. Part of the error text is a "reason" message that provides added insight into what went wrong. The reason messages are listed below; click the message to open an article explaining the error in more detail and offering possible solutions.

Reason: CORS disabled
Reason: CORS request did not succeed
Reason: CORS header 'Origin' cannot be added
Reason: CORS request external redirect not allowed
Reason: CORS request not http
Reason: CORS header 'Access-Control-Allow-Origin' missing
Reason: CORS header 'Access-Control-Allow-Origin' does not match 'xyz'
Reason: Credential is not supported if the CORS header 'Access-Control-Allow-Origin' is '*'
Reason: Did not find method in CORS header 'Access-Control-Allow-Methods'
Reason: expected 'true' in CORS header 'Access-Control-Allow-Credentials'
Reason: CORS preflight channel did not succeed
Reason: invalid token 'xyz' in CORS header 'Access-Control-Allow-Methods'
Reason: invalid token 'xyz' in CORS header 'Access-Control-Allow-Headers'
Reason: missing token 'xyz' in CORS header 'Access-Control-Allow-Headers' from CORS preflight channel
Reason: Multiple CORS header 'Access-Control-Allow-Origin' not allowed
See also
Glossary: CORS
CORS introduction
Server-side CORS settings
CORS enabled image
CORS settings attributes\n\nCORS errorsCross-Origin Resource Sharing (CORS) is a standard that allows a server to relax the same-origin policy. This is used to explicitly allow some cross-origin requests while rejecting others. For example, if a site offers an embeddable service, it may be necessary to relax certain restrictions. Setting up such a CORS configuration isn't necessarily easy and may present some challenges. In these pages, we'll look into some common CORS error messages and how to resolve them.
If the CORS configuration isn't set up correctly, the browser console will present an error like "Cross-Origin Request Blocked: The Same Origin Policy disallows reading the remote resource at [some site]" indicating that the request was blocked due to violating the CORS security rules. This might not necessarily be a set-up mistake, though. It's possible that the request is in fact intentionally being disallowed by the user's web application and remote external service. However, If the endpoint is meant to be available, some debugging is needed to succeed.Identifying a CORS issueTo understand the underlying issue with the CORS configuration, you need to find out which request is at fault and why. These steps may help you do so:

Navigate to the website or web app in question and open the Developer Tools.
Now try to reproduce the failing transaction and check the console if you are seeing a CORS violation error message. It will probably look like this:


The text of the error message will be something similar to the following:
Cross-Origin Request Blocked: The Same Origin Policy disallows
reading the remote resource at https://some-url-here. (Reason:
additional information here).


Note:
For security reasons, specifics about what went wrong with a CORS request are not available to JavaScript code. All the code knows is that an error occurred. The only way to determine what specifically went wrong is to look at the browser's console for details.
CORS error messagesFirefox's console displays messages in its console when requests fail due to CORS. Part of the error text is a "reason" message that provides added insight into what went wrong. The reason messages are listed below; click the message to open an article explaining the error in more detail and offering possible solutions.

Reason: CORS disabled
Reason: CORS request did not succeed
Reason: CORS header 'Origin' cannot be added
Reason: CORS request external redirect not allowed
Reason: CORS request not http
Reason: CORS header 'Access-Control-Allow-Origin' missing
Reason: CORS header 'Access-Control-Allow-Origin' does not match 'xyz'
Reason: Credential is not supported if the CORS header 'Access-Control-Allow-Origin' is '*'
Reason: Did not find method in CORS header 'Access-Control-Allow-Methods'
Reason: expected 'true' in CORS header 'Access-Control-Allow-Credentials'
Reason: CORS preflight channel did not succeed
Reason: invalid token 'xyz' in CORS header 'Access-Control-Allow-Methods'
Reason: invalid token 'xyz' in CORS header 'Access-Control-Allow-Headers'
Reason: missing token 'xyz' in CORS header 'Access-Control-Allow-Headers' from CORS preflight channel
Reason: Multiple CORS header 'Access-Control-Allow-Origin' not allowed
See also
Glossary: CORS
CORS introduction
Server-side CORS settings
CORS enabled image
CORS settings attributes
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Apr 10, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nCORS errorsCross-Origin Resource Sharing (CORS) is a standard that allows a server to relax the same-origin policy. This is used to explicitly allow some cross-origin requests while rejecting others. For example, if a site offers an embeddable service, it may be necessary to relax certain restrictions. Setting up such a CORS configuration isn't necessarily easy and may present some challenges. In these pages, we'll look into some common CORS error messages and how to resolve them.
If the CORS configuration isn't set up correctly, the browser console will present an error like "Cross-Origin Request Blocked: The Same Origin Policy disallows reading the remote resource at [some site]" indicating that the request was blocked due to violating the CORS security rules. This might not necessarily be a set-up mistake, though. It's possible that the request is in fact intentionally being disallowed by the user's web application and remote external service. However, If the endpoint is meant to be available, some debugging is needed to succeed.Identifying a CORS issueTo understand the underlying issue with the CORS configuration, you need to find out which request is at fault and why. These steps may help you do so:

Navigate to the website or web app in question and open the Developer Tools.
Now try to reproduce the failing transaction and check the console if you are seeing a CORS violation error message. It will probably look like this:


The text of the error message will be something similar to the following:
Cross-Origin Request Blocked: The Same Origin Policy disallows
reading the remote resource at https://some-url-here. (Reason:
additional information here).


Note:
For security reasons, specifics about what went wrong with a CORS request are not available to JavaScript code. All the code knows is that an error occurred. The only way to determine what specifically went wrong is to look at the browser's console for details.
CORS error messagesFirefox's console displays messages in its console when requests fail due to CORS. Part of the error text is a "reason" message that provides added insight into what went wrong. The reason messages are listed below; click the message to open an article explaining the error in more detail and offering possible solutions.

Reason: CORS disabled
Reason: CORS request did not succeed
Reason: CORS header 'Origin' cannot be added
Reason: CORS request external redirect not allowed
Reason: CORS request not http
Reason: CORS header 'Access-Control-Allow-Origin' missing
Reason: CORS header 'Access-Control-Allow-Origin' does not match 'xyz'
Reason: Credential is not supported if the CORS header 'Access-Control-Allow-Origin' is '*'
Reason: Did not find method in CORS header 'Access-Control-Allow-Methods'
Reason: expected 'true' in CORS header 'Access-Control-Allow-Credentials'
Reason: CORS preflight channel did not succeed
Reason: invalid token 'xyz' in CORS header 'Access-Control-Allow-Methods'
Reason: invalid token 'xyz' in CORS header 'Access-Control-Allow-Headers'
Reason: missing token 'xyz' in CORS header 'Access-Control-Allow-Headers' from CORS preflight channel
Reason: Multiple CORS header 'Access-Control-Allow-Origin' not allowed
See also
Glossary: CORS
CORS introduction
Server-side CORS settings
CORS enabled image
CORS settings attributes
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Apr 10, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nReason: CORS disabledReasonReason: CORS disabled
What went wrong?A request that needs to use CORS was attempted, but CORS is disabled in
the user's browser. When this happens, the user needs to turn CORS back on in their
browser.
In Firefox, the preference that disables CORS is content.cors.disable.
Setting this to true disables CORS, so whenever that's the case, CORS
requests will always fail with this error.See also
CORS errors
Glossary: CORS
CORS introduction\n\nReason: CORS disabledReasonReason: CORS disabled
What went wrong?A request that needs to use CORS was attempted, but CORS is disabled in
the user's browser. When this happens, the user needs to turn CORS back on in their
browser.
In Firefox, the preference that disables CORS is content.cors.disable.
Setting this to true disables CORS, so whenever that's the case, CORS
requests will always fail with this error.See also
CORS errors
Glossary: CORS
CORS introduction
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nReason: CORS disabledReasonReason: CORS disabled
What went wrong?A request that needs to use CORS was attempted, but CORS is disabled in
the user's browser. When this happens, the user needs to turn CORS back on in their
browser.
In Firefox, the preference that disables CORS is content.cors.disable.
Setting this to true disables CORS, so whenever that's the case, CORS
requests will always fail with this error.See also
CORS errors
Glossary: CORS
CORS introduction
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nReason: CORS header 'Access-Control-Allow-Origin' does not match 'xyz'ReasonReason: CORS header 'Access-Control-Allow-Origin' does not match 'xyz'
What went wrong?The origin making the request does not match the origin permitted by the Access-Control-Allow-Origin header. This error can also occur if the response includes more than one Access-Control-Allow-Origin header.
If the service your code is accessing uses a CORS request under your control, make
sure it is configured to include your origin in its Access-Control-Allow-Origin header. In addition, confirm that only one such header is
included in responses, and that it includes only a single origin.
For example, in Apache, add a line such as the following to the server's configuration
(within the appropriate <Directory>, <Location>,
<Files>, or <VirtualHost> section). The
configuration is typically found in a .conf file (httpd.conf
and apache.conf are common names for these), or in an
.htaccess file.

Warning:
You must include the HTTPS or HTTP protocol as part of the origin.

apacheconfHeader set Access-Control-Allow-Origin 'origin'

For Nginx, the command to set up this header is:
nginxadd_header 'Access-Control-Allow-Origin' 'origin'
See also
CORS errors
Glossary: CORS
CORS introduction
Enable CORS: I want to add CORS support to my server\n\nReason: CORS header 'Access-Control-Allow-Origin' does not match 'xyz'ReasonReason: CORS header 'Access-Control-Allow-Origin' does not match 'xyz'
What went wrong?The origin making the request does not match the origin permitted by the Access-Control-Allow-Origin header. This error can also occur if the response includes more than one Access-Control-Allow-Origin header.
If the service your code is accessing uses a CORS request under your control, make
sure it is configured to include your origin in its Access-Control-Allow-Origin header. In addition, confirm that only one such header is
included in responses, and that it includes only a single origin.
For example, in Apache, add a line such as the following to the server's configuration
(within the appropriate <Directory>, <Location>,
<Files>, or <VirtualHost> section). The
configuration is typically found in a .conf file (httpd.conf
and apache.conf are common names for these), or in an
.htaccess file.

Warning:
You must include the HTTPS or HTTP protocol as part of the origin.

apacheconfHeader set Access-Control-Allow-Origin 'origin'

For Nginx, the command to set up this header is:
nginxadd_header 'Access-Control-Allow-Origin' 'origin'
See also
CORS errors
Glossary: CORS
CORS introduction
Enable CORS: I want to add CORS support to my server
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nReason: CORS header 'Access-Control-Allow-Origin' does not match 'xyz'ReasonReason: CORS header 'Access-Control-Allow-Origin' does not match 'xyz'
What went wrong?The origin making the request does not match the origin permitted by the Access-Control-Allow-Origin header. This error can also occur if the response includes more than one Access-Control-Allow-Origin header.
If the service your code is accessing uses a CORS request under your control, make
sure it is configured to include your origin in its Access-Control-Allow-Origin header. In addition, confirm that only one such header is
included in responses, and that it includes only a single origin.
For example, in Apache, add a line such as the following to the server's configuration
(within the appropriate <Directory>, <Location>,
<Files>, or <VirtualHost> section). The
configuration is typically found in a .conf file (httpd.conf
and apache.conf are common names for these), or in an
.htaccess file.

Warning:
You must include the HTTPS or HTTP protocol as part of the origin.

apacheconfHeader set Access-Control-Allow-Origin 'origin'

For Nginx, the command to set up this header is:
nginxadd_header 'Access-Control-Allow-Origin' 'origin'
See also
CORS errors
Glossary: CORS
CORS introduction
Enable CORS: I want to add CORS support to my server
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nReason: CORS header 'Access-Control-Allow-Origin' missingReasonReason: CORS header 'Access-Control-Allow-Origin' missing
What went wrong?The response to the CORS request is missing the required
Access-Control-Allow-Origin header, which is used to determine whether
or not the resource can be accessed by content operating within the current origin.
If the server is under your control, add the origin of the requesting site to the set
of domains permitted access by adding it to the Access-Control-Allow-Origin
header's value.
For example, to allow a site at https://example.com to access the resource using CORS,
the header should be:
httpAccess-Control-Allow-Origin: https://example.com

You can also configure a site to allow any site to access it by using the
* wildcard. You should only use this for public APIs. Private APIs should
never use *, and should instead have a specific domain or domains set. In
addition, the wildcard only works for requests made with the
crossorigin attribute set to anonymous, and it prevents
sending credentials like cookies in requests.
httpAccess-Control-Allow-Origin: *


Warning:
Using the wildcard to allow all sites to access a private
API is a bad idea.

To allow any site to make CORS requests without using the *
wildcard (for example, to enable credentials), your server must read the value of the
request's Origin header and use that value to set
Access-Control-Allow-Origin, and must also set a Vary: Origin
header to indicate that some headers are being set dynamically depending on the origin.Examples for common web serversThe exact directive for setting headers depends on your web server.
In the examples below,
In Apache (docs), add a
line such as the following to the server's configuration (within the appropriate
<Directory>, <Location>,
<Files>, or <VirtualHost> section). The
configuration is typically found in a .conf file (httpd.conf
and apache.conf are common names for these), or in an
.htaccess file:
apacheconfHeader set Access-Control-Allow-Origin 'https://example.com'

For Nginx (docs), the command to set up this header is:
nginxadd_header 'Access-Control-Allow-Origin' 'https://example.com' always;
See also
CORS errors
Glossary: CORS
CORS introduction\n\nReason: CORS header 'Access-Control-Allow-Origin' missingReasonReason: CORS header 'Access-Control-Allow-Origin' missing
What went wrong?The response to the CORS request is missing the required
Access-Control-Allow-Origin header, which is used to determine whether
or not the resource can be accessed by content operating within the current origin.
If the server is under your control, add the origin of the requesting site to the set
of domains permitted access by adding it to the Access-Control-Allow-Origin
header's value.
For example, to allow a site at https://example.com to access the resource using CORS,
the header should be:
httpAccess-Control-Allow-Origin: https://example.com

You can also configure a site to allow any site to access it by using the
* wildcard. You should only use this for public APIs. Private APIs should
never use *, and should instead have a specific domain or domains set. In
addition, the wildcard only works for requests made with the
crossorigin attribute set to anonymous, and it prevents
sending credentials like cookies in requests.
httpAccess-Control-Allow-Origin: *


Warning:
Using the wildcard to allow all sites to access a private
API is a bad idea.

To allow any site to make CORS requests without using the *
wildcard (for example, to enable credentials), your server must read the value of the
request's Origin header and use that value to set
Access-Control-Allow-Origin, and must also set a Vary: Origin
header to indicate that some headers are being set dynamically depending on the origin.Examples for common web serversThe exact directive for setting headers depends on your web server.
In the examples below,
In Apache (docs), add a
line such as the following to the server's configuration (within the appropriate
<Directory>, <Location>,
<Files>, or <VirtualHost> section). The
configuration is typically found in a .conf file (httpd.conf
and apache.conf are common names for these), or in an
.htaccess file:
apacheconfHeader set Access-Control-Allow-Origin 'https://example.com'

For Nginx (docs), the command to set up this header is:
nginxadd_header 'Access-Control-Allow-Origin' 'https://example.com' always;
See also
CORS errors
Glossary: CORS
CORS introduction
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Apr 10, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nReason: CORS header 'Access-Control-Allow-Origin' missingReasonReason: CORS header 'Access-Control-Allow-Origin' missing
What went wrong?The response to the CORS request is missing the required
Access-Control-Allow-Origin header, which is used to determine whether
or not the resource can be accessed by content operating within the current origin.
If the server is under your control, add the origin of the requesting site to the set
of domains permitted access by adding it to the Access-Control-Allow-Origin
header's value.
For example, to allow a site at https://example.com to access the resource using CORS,
the header should be:
httpAccess-Control-Allow-Origin: https://example.com

You can also configure a site to allow any site to access it by using the
* wildcard. You should only use this for public APIs. Private APIs should
never use *, and should instead have a specific domain or domains set. In
addition, the wildcard only works for requests made with the
crossorigin attribute set to anonymous, and it prevents
sending credentials like cookies in requests.
httpAccess-Control-Allow-Origin: *


Warning:
Using the wildcard to allow all sites to access a private
API is a bad idea.

To allow any site to make CORS requests without using the *
wildcard (for example, to enable credentials), your server must read the value of the
request's Origin header and use that value to set
Access-Control-Allow-Origin, and must also set a Vary: Origin
header to indicate that some headers are being set dynamically depending on the origin.Examples for common web serversThe exact directive for setting headers depends on your web server.
In the examples below,
In Apache (docs), add a
line such as the following to the server's configuration (within the appropriate
<Directory>, <Location>,
<Files>, or <VirtualHost> section). The
configuration is typically found in a .conf file (httpd.conf
and apache.conf are common names for these), or in an
.htaccess file:
apacheconfHeader set Access-Control-Allow-Origin 'https://example.com'

For Nginx (docs), the command to set up this header is:
nginxadd_header 'Access-Control-Allow-Origin' 'https://example.com' always;
See also
CORS errors
Glossary: CORS
CORS introduction
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Apr 10, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nReason: CORS header 'Origin' cannot be addedReasonReason: CORS header 'Origin' cannot be added
What went wrong?The user agent was unable to add the required Origin
header to the HTTP request. All CORS requests must have an
Origin header.
This can happen if the JavaScript code is running with enhanced privileges allowing it
access to multiple domains' content, for example.See also
CORS errors
Glossary: CORS
CORS introduction\n\nReason: CORS header 'Origin' cannot be addedReasonReason: CORS header 'Origin' cannot be added
What went wrong?The user agent was unable to add the required Origin
header to the HTTP request. All CORS requests must have an
Origin header.
This can happen if the JavaScript code is running with enhanced privileges allowing it
access to multiple domains' content, for example.See also
CORS errors
Glossary: CORS
CORS introduction
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nReason: CORS header 'Origin' cannot be addedReasonReason: CORS header 'Origin' cannot be added
What went wrong?The user agent was unable to add the required Origin
header to the HTTP request. All CORS requests must have an
Origin header.
This can happen if the JavaScript code is running with enhanced privileges allowing it
access to multiple domains' content, for example.See also
CORS errors
Glossary: CORS
CORS introduction
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nReason: CORS preflight channel did not succeedReasonReason: CORS preflight channel did not succeed
What went wrong?The CORS request requires preflight, preflighting could not be
performed. There are a couple of reasons why preflighting might fail:

A cross-site request has previously been performed that already did a preflight, and
doing the preflight again is not permitted. Make sure your code only preflights once
per connection.
The preflight request suffered any kind of networking error that might ordinarily
occur.
See also
CORS errors
Glossary: CORS
CORS introduction\n\nReason: CORS preflight channel did not succeedReasonReason: CORS preflight channel did not succeed
What went wrong?The CORS request requires preflight, preflighting could not be
performed. There are a couple of reasons why preflighting might fail:

A cross-site request has previously been performed that already did a preflight, and
doing the preflight again is not permitted. Make sure your code only preflights once
per connection.
The preflight request suffered any kind of networking error that might ordinarily
occur.
See also
CORS errors
Glossary: CORS
CORS introduction
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nReason: CORS preflight channel did not succeedReasonReason: CORS preflight channel did not succeed
What went wrong?The CORS request requires preflight, preflighting could not be
performed. There are a couple of reasons why preflighting might fail:

A cross-site request has previously been performed that already did a preflight, and
doing the preflight again is not permitted. Make sure your code only preflights once
per connection.
The preflight request suffered any kind of networking error that might ordinarily
occur.
See also
CORS errors
Glossary: CORS
CORS introduction
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nReason: CORS request did not succeedReasonReason: CORS request did not succeed
What went wrong?The HTTP request which makes use of CORS failed because the HTTP connection failed at either the network or protocol level. The error is not directly related to CORS, but is a fundamental network error of some kind.
In many cases, it is caused by a browser plugin (e.g., an ad blocker or privacy protector) blocking the request.
Other possible causes include:

Trying to access an https resource that has an invalid certificate will cause this error.
Trying to access an http resource from a page with an https origin will also cause this error.
From Firefox 68 to Firefox 84, https pages were not permitted to access http://localhost.
This has been changed with Bug 1488740.
The server did not respond to the actual request (even if it responded to the Preflight request).
One scenario might be an HTTP service being developed that panicked without returning any data.
The window is in "Private Browsing" mode (which may have security requirements that could block a CORS request).
See also
CORS errors
Glossary: CORS
CORS introduction\n\nReason: CORS request did not succeedReasonReason: CORS request did not succeed
What went wrong?The HTTP request which makes use of CORS failed because the HTTP connection failed at either the network or protocol level. The error is not directly related to CORS, but is a fundamental network error of some kind.
In many cases, it is caused by a browser plugin (e.g., an ad blocker or privacy protector) blocking the request.
Other possible causes include:

Trying to access an https resource that has an invalid certificate will cause this error.
Trying to access an http resource from a page with an https origin will also cause this error.
From Firefox 68 to Firefox 84, https pages were not permitted to access http://localhost.
This has been changed with Bug 1488740.
The server did not respond to the actual request (even if it responded to the Preflight request).
One scenario might be an HTTP service being developed that panicked without returning any data.
The window is in "Private Browsing" mode (which may have security requirements that could block a CORS request).
See also
CORS errors
Glossary: CORS
CORS introduction
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Apr 3, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nReason: CORS request did not succeedReasonReason: CORS request did not succeed
What went wrong?The HTTP request which makes use of CORS failed because the HTTP connection failed at either the network or protocol level. The error is not directly related to CORS, but is a fundamental network error of some kind.
In many cases, it is caused by a browser plugin (e.g., an ad blocker or privacy protector) blocking the request.
Other possible causes include:

Trying to access an https resource that has an invalid certificate will cause this error.
Trying to access an http resource from a page with an https origin will also cause this error.
From Firefox 68 to Firefox 84, https pages were not permitted to access http://localhost.
This has been changed with Bug 1488740.
The server did not respond to the actual request (even if it responded to the Preflight request).
One scenario might be an HTTP service being developed that panicked without returning any data.
The window is in "Private Browsing" mode (which may have security requirements that could block a CORS request).
See also
CORS errors
Glossary: CORS
CORS introduction
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Apr 3, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nReason: CORS request external redirect not allowedReasonReason: CORS request external redirect not allowed
What went wrong?The CORS request was responded to by the server with an HTTP redirect
to a URL on a different origin than the original request, which is not permitted during
CORS requests.
For example, if the page https://service.tld/fetchdata were requested, and
the HTTP response is "301 Moved Permanently", "307 Temporary Redirect", or "308
Permanent Redirect" with a Location of
https://anotherservice.net/getdata, the CORS request will fail in this
manner.
To fix the problem, update your code to use the new URL as reported by the redirect,
thereby avoiding the redirect.See also
CORS errors
Glossary: CORS
CORS introduction\n\nReason: CORS request external redirect not allowedReasonReason: CORS request external redirect not allowed
What went wrong?The CORS request was responded to by the server with an HTTP redirect
to a URL on a different origin than the original request, which is not permitted during
CORS requests.
For example, if the page https://service.tld/fetchdata were requested, and
the HTTP response is "301 Moved Permanently", "307 Temporary Redirect", or "308
Permanent Redirect" with a Location of
https://anotherservice.net/getdata, the CORS request will fail in this
manner.
To fix the problem, update your code to use the new URL as reported by the redirect,
thereby avoiding the redirect.See also
CORS errors
Glossary: CORS
CORS introduction
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nReason: CORS request external redirect not allowedReasonReason: CORS request external redirect not allowed
What went wrong?The CORS request was responded to by the server with an HTTP redirect
to a URL on a different origin than the original request, which is not permitted during
CORS requests.
For example, if the page https://service.tld/fetchdata were requested, and
the HTTP response is "301 Moved Permanently", "307 Temporary Redirect", or "308
Permanent Redirect" with a Location of
https://anotherservice.net/getdata, the CORS request will fail in this
manner.
To fix the problem, update your code to use the new URL as reported by the redirect,
thereby avoiding the redirect.See also
CORS errors
Glossary: CORS
CORS introduction
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nReason: CORS request not HTTPReasonReason: CORS request not HTTP
What went wrong?CORS requests may only use the HTTP or HTTPS URL scheme, but the URL specified by the request is of a different type.
This often occurs if the URL specifies a local file, using the file:/// scheme.
To fix this problem, make sure you use HTTPS URLs when issuing requests involving CORS, such as fetch(), XMLHttpRequest, Web Fonts (@font-face), and WebGL textures, and XSL stylesheets.Loading a local fileLocal files from the same directory and subdirectories were historically treated as being from the same origin.
This meant that a file and all its resources could be loaded from a local directory or subdirectory during testing, without triggering a CORS error.
Unfortunately this had security implications, as noted in this advisory: CVE-2019-11730.
Many browsers, including Firefox and Chrome, now treat all local files as having opaque origins (by default).
As a result, loading a local file with included local resources will now result in CORS errors.
Developers who need to perform local testing should now set up a local server.
As all files are served from the same scheme and domain (localhost) they all have the same origin, and do not trigger cross-origin errors.

Note:
This change is in line with the URL specification, which leaves the origin behavior for files to the implementation, but recommends that file origins are treated as opaque if in doubt.
See also
CORS errors
CORS introduction
What is a URL?\n\nReason: CORS request not HTTPReasonReason: CORS request not HTTP
What went wrong?CORS requests may only use the HTTP or HTTPS URL scheme, but the URL specified by the request is of a different type.
This often occurs if the URL specifies a local file, using the file:/// scheme.
To fix this problem, make sure you use HTTPS URLs when issuing requests involving CORS, such as fetch(), XMLHttpRequest, Web Fonts (@font-face), and WebGL textures, and XSL stylesheets.Loading a local fileLocal files from the same directory and subdirectories were historically treated as being from the same origin.
This meant that a file and all its resources could be loaded from a local directory or subdirectory during testing, without triggering a CORS error.
Unfortunately this had security implications, as noted in this advisory: CVE-2019-11730.
Many browsers, including Firefox and Chrome, now treat all local files as having opaque origins (by default).
As a result, loading a local file with included local resources will now result in CORS errors.
Developers who need to perform local testing should now set up a local server.
As all files are served from the same scheme and domain (localhost) they all have the same origin, and do not trigger cross-origin errors.

Note:
This change is in line with the URL specification, which leaves the origin behavior for files to the implementation, but recommends that file origins are treated as opaque if in doubt.
See also
CORS errors
CORS introduction
What is a URL?
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nReason: CORS request not HTTPReasonReason: CORS request not HTTP
What went wrong?CORS requests may only use the HTTP or HTTPS URL scheme, but the URL specified by the request is of a different type.
This often occurs if the URL specifies a local file, using the file:/// scheme.
To fix this problem, make sure you use HTTPS URLs when issuing requests involving CORS, such as fetch(), XMLHttpRequest, Web Fonts (@font-face), and WebGL textures, and XSL stylesheets.Loading a local fileLocal files from the same directory and subdirectories were historically treated as being from the same origin.
This meant that a file and all its resources could be loaded from a local directory or subdirectory during testing, without triggering a CORS error.
Unfortunately this had security implications, as noted in this advisory: CVE-2019-11730.
Many browsers, including Firefox and Chrome, now treat all local files as having opaque origins (by default).
As a result, loading a local file with included local resources will now result in CORS errors.
Developers who need to perform local testing should now set up a local server.
As all files are served from the same scheme and domain (localhost) they all have the same origin, and do not trigger cross-origin errors.

Note:
This change is in line with the URL specification, which leaves the origin behavior for files to the implementation, but recommends that file origins are treated as opaque if in doubt.
See also
CORS errors
CORS introduction
What is a URL?
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nReason: Credential is not supported if the CORS header 'Access-Control-Allow-Origin' is '*'ReasonReason: Credential is not supported if the CORS header 'Access-Control-Allow-Origin' is '*'
What went wrong?The CORS request was attempted with the credentials flag set, but the server is configured using the wildcard ("*") as the value of Access-Control-Allow-Origin, which doesn't allow the use of credentials.
To correct this problem on the client side, ensure that the credentials flag's value is false when issuing your CORS request.

If using the Fetch API, make sure Request.credentials is "omit".
If the request is being issued using XMLHttpRequest, make sure you're not setting withCredentials to true.
If using Server-sent events, make sure EventSource.withCredentials is false (it's the default value).

If, instead, you need to adjust the server's behavior, you'll need to change the value of Access-Control-Allow-Origin to grant access to the origin from which the client is loaded.See also
CORS errors
Glossary: CORS
CORS introduction\n\nReason: Credential is not supported if the CORS header 'Access-Control-Allow-Origin' is '*'ReasonReason: Credential is not supported if the CORS header 'Access-Control-Allow-Origin' is '*'
What went wrong?The CORS request was attempted with the credentials flag set, but the server is configured using the wildcard ("*") as the value of Access-Control-Allow-Origin, which doesn't allow the use of credentials.
To correct this problem on the client side, ensure that the credentials flag's value is false when issuing your CORS request.

If using the Fetch API, make sure Request.credentials is "omit".
If the request is being issued using XMLHttpRequest, make sure you're not setting withCredentials to true.
If using Server-sent events, make sure EventSource.withCredentials is false (it's the default value).

If, instead, you need to adjust the server's behavior, you'll need to change the value of Access-Control-Allow-Origin to grant access to the origin from which the client is loaded.See also
CORS errors
Glossary: CORS
CORS introduction
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nReason: Credential is not supported if the CORS header 'Access-Control-Allow-Origin' is '*'ReasonReason: Credential is not supported if the CORS header 'Access-Control-Allow-Origin' is '*'
What went wrong?The CORS request was attempted with the credentials flag set, but the server is configured using the wildcard ("*") as the value of Access-Control-Allow-Origin, which doesn't allow the use of credentials.
To correct this problem on the client side, ensure that the credentials flag's value is false when issuing your CORS request.

If using the Fetch API, make sure Request.credentials is "omit".
If the request is being issued using XMLHttpRequest, make sure you're not setting withCredentials to true.
If using Server-sent events, make sure EventSource.withCredentials is false (it's the default value).

If, instead, you need to adjust the server's behavior, you'll need to change the value of Access-Control-Allow-Origin to grant access to the origin from which the client is loaded.See also
CORS errors
Glossary: CORS
CORS introduction
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nReason: Did not find method in CORS header 'Access-Control-Allow-Methods'ReasonReason: Did not find method in CORS header 'Access-Control-Allow-Methods'
What went wrong?The HTTP method being used by the CORS request is not included in the
list of methods specified by the response's
Access-Control-Allow-Methods header. This header specifies a
comma-delimited list of the HTTP methods which may be used when using CORS to access
the URL specified in the request; if the request is using any other method, this error
occurs.
For example, if the response includes:
httpAccess-Control-Allow-Methods: GET,HEAD,POST

Trying to use a PUT request will fail with this error.
Make sure your code only uses the permitted HTTP methods when accessing the service.

Note:
If the server includes any unrecognized or undefined method names in its Access-Control-Allow-methods header, a different error occurs: Reason: invalid token 'xyz' in CORS header 'Access-Control-Allow-Methods'.
See also
CORS errors
Glossary: CORS
CORS introduction
HTTP request methods\n\nReason: Did not find method in CORS header 'Access-Control-Allow-Methods'ReasonReason: Did not find method in CORS header 'Access-Control-Allow-Methods'
What went wrong?The HTTP method being used by the CORS request is not included in the
list of methods specified by the response's
Access-Control-Allow-Methods header. This header specifies a
comma-delimited list of the HTTP methods which may be used when using CORS to access
the URL specified in the request; if the request is using any other method, this error
occurs.
For example, if the response includes:
httpAccess-Control-Allow-Methods: GET,HEAD,POST

Trying to use a PUT request will fail with this error.
Make sure your code only uses the permitted HTTP methods when accessing the service.

Note:
If the server includes any unrecognized or undefined method names in its Access-Control-Allow-methods header, a different error occurs: Reason: invalid token 'xyz' in CORS header 'Access-Control-Allow-Methods'.
See also
CORS errors
Glossary: CORS
CORS introduction
HTTP request methods
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nReason: Did not find method in CORS header 'Access-Control-Allow-Methods'ReasonReason: Did not find method in CORS header 'Access-Control-Allow-Methods'
What went wrong?The HTTP method being used by the CORS request is not included in the
list of methods specified by the response's
Access-Control-Allow-Methods header. This header specifies a
comma-delimited list of the HTTP methods which may be used when using CORS to access
the URL specified in the request; if the request is using any other method, this error
occurs.
For example, if the response includes:
httpAccess-Control-Allow-Methods: GET,HEAD,POST

Trying to use a PUT request will fail with this error.
Make sure your code only uses the permitted HTTP methods when accessing the service.

Note:
If the server includes any unrecognized or undefined method names in its Access-Control-Allow-methods header, a different error occurs: Reason: invalid token 'xyz' in CORS header 'Access-Control-Allow-Methods'.
See also
CORS errors
Glossary: CORS
CORS introduction
HTTP request methods
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nReason: expected 'true' in CORS header 'Access-Control-Allow-Credentials'ReasonReason: expected 'true' in CORS header 'Access-Control-Allow-Credentials'
What went wrong?The CORS request requires that the server permit the use of
credentials, but the server's Access-Control-Allow-Credentials
header's value isn't set to true to enable their use.
To fix this problem on the client side, revise the code to not request the use of
credentials.

If using the Fetch API, make sure
Request.credentials is "omit".
If the request is being issued using XMLHttpRequest, make sure you're
not setting withCredentials to
true.
If using Server-sent events,
make sure EventSource.withCredentials is false (it's the
default value).

To eliminate this error by changing the server's configuration, adjust the server's
configuration to set the Access-Control-Allow-Credentials header's value to
true.See also
CORS errors
Glossary: CORS
CORS introduction\n\nReason: expected 'true' in CORS header 'Access-Control-Allow-Credentials'ReasonReason: expected 'true' in CORS header 'Access-Control-Allow-Credentials'
What went wrong?The CORS request requires that the server permit the use of
credentials, but the server's Access-Control-Allow-Credentials
header's value isn't set to true to enable their use.
To fix this problem on the client side, revise the code to not request the use of
credentials.

If using the Fetch API, make sure
Request.credentials is "omit".
If the request is being issued using XMLHttpRequest, make sure you're
not setting withCredentials to
true.
If using Server-sent events,
make sure EventSource.withCredentials is false (it's the
default value).

To eliminate this error by changing the server's configuration, adjust the server's
configuration to set the Access-Control-Allow-Credentials header's value to
true.See also
CORS errors
Glossary: CORS
CORS introduction
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nReason: expected 'true' in CORS header 'Access-Control-Allow-Credentials'ReasonReason: expected 'true' in CORS header 'Access-Control-Allow-Credentials'
What went wrong?The CORS request requires that the server permit the use of
credentials, but the server's Access-Control-Allow-Credentials
header's value isn't set to true to enable their use.
To fix this problem on the client side, revise the code to not request the use of
credentials.

If using the Fetch API, make sure
Request.credentials is "omit".
If the request is being issued using XMLHttpRequest, make sure you're
not setting withCredentials to
true.
If using Server-sent events,
make sure EventSource.withCredentials is false (it's the
default value).

To eliminate this error by changing the server's configuration, adjust the server's
configuration to set the Access-Control-Allow-Credentials header's value to
true.See also
CORS errors
Glossary: CORS
CORS introduction
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nReason: invalid token 'xyz' in CORS header 'Access-Control-Allow-Headers'ReasonReason: invalid token 'xyz' in CORS header 'Access-Control-Allow-Headers'
What went wrong?The response to the CORS request that was sent by the server includes
an Access-Control-Allow-Headers header which includes at least one
invalid header name.
The Access-Control-Allow-Headers header is sent by the server in response
to a preflight request; it lets the client know which HTTP headers are permitted in CORS requests.
If the client user agent finds among the comma-delineated values
provided by the header any header name it does not recognize, this error occurs.
This is a problem that most likely can only be fixed on the server side, by modifying
the server's configuration to no longer send the invalid or unknown header name with the
Access-Control-Allow-Headers header. It may also be worth checking to
ensure that the user agent or HTTP library you're using on the client is up-to-date.See also
CORS errors
Glossary: CORS
CORS introduction
HTTP headers\n\nReason: invalid token 'xyz' in CORS header 'Access-Control-Allow-Headers'ReasonReason: invalid token 'xyz' in CORS header 'Access-Control-Allow-Headers'
What went wrong?The response to the CORS request that was sent by the server includes
an Access-Control-Allow-Headers header which includes at least one
invalid header name.
The Access-Control-Allow-Headers header is sent by the server in response
to a preflight request; it lets the client know which HTTP headers are permitted in CORS requests.
If the client user agent finds among the comma-delineated values
provided by the header any header name it does not recognize, this error occurs.
This is a problem that most likely can only be fixed on the server side, by modifying
the server's configuration to no longer send the invalid or unknown header name with the
Access-Control-Allow-Headers header. It may also be worth checking to
ensure that the user agent or HTTP library you're using on the client is up-to-date.See also
CORS errors
Glossary: CORS
CORS introduction
HTTP headers
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nReason: invalid token 'xyz' in CORS header 'Access-Control-Allow-Headers'ReasonReason: invalid token 'xyz' in CORS header 'Access-Control-Allow-Headers'
What went wrong?The response to the CORS request that was sent by the server includes
an Access-Control-Allow-Headers header which includes at least one
invalid header name.
The Access-Control-Allow-Headers header is sent by the server in response
to a preflight request; it lets the client know which HTTP headers are permitted in CORS requests.
If the client user agent finds among the comma-delineated values
provided by the header any header name it does not recognize, this error occurs.
This is a problem that most likely can only be fixed on the server side, by modifying
the server's configuration to no longer send the invalid or unknown header name with the
Access-Control-Allow-Headers header. It may also be worth checking to
ensure that the user agent or HTTP library you're using on the client is up-to-date.See also
CORS errors
Glossary: CORS
CORS introduction
HTTP headers
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nReason: invalid token 'xyz' in CORS header 'Access-Control-Allow-Methods'ReasonReason: invalid token 'xyz' in CORS header 'Access-Control-Allow-Methods'
What went wrong?The response to the CORS request that was sent by the server includes
an Access-Control-Allow-Methods header which includes at least one
invalid method name.
The Access-Control-Allow-Methods header is sent by the server to let the
client know what HTTP request methods it
supports for CORS requests. The header's value is a comma-delineated string of HTTP
method names, such as GET, POST, or
HEAD. If any of the specified values are not recognized by the client
user agent, this error occurs.
This is a problem that most likely can only be fixed on the server side, by modifying
the server's configuration to no longer send the invalid or unknown method name with the
Access-Control-Allow-Methods header. It may also be worth checking to
ensure that the user agent or HTTP library you're using on the client is up-to-date.See also
CORS errors
Glossary: CORS
CORS introduction
HTTP request methods\n\nReason: invalid token 'xyz' in CORS header 'Access-Control-Allow-Methods'ReasonReason: invalid token 'xyz' in CORS header 'Access-Control-Allow-Methods'
What went wrong?The response to the CORS request that was sent by the server includes
an Access-Control-Allow-Methods header which includes at least one
invalid method name.
The Access-Control-Allow-Methods header is sent by the server to let the
client know what HTTP request methods it
supports for CORS requests. The header's value is a comma-delineated string of HTTP
method names, such as GET, POST, or
HEAD. If any of the specified values are not recognized by the client
user agent, this error occurs.
This is a problem that most likely can only be fixed on the server side, by modifying
the server's configuration to no longer send the invalid or unknown method name with the
Access-Control-Allow-Methods header. It may also be worth checking to
ensure that the user agent or HTTP library you're using on the client is up-to-date.See also
CORS errors
Glossary: CORS
CORS introduction
HTTP request methods
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nReason: invalid token 'xyz' in CORS header 'Access-Control-Allow-Methods'ReasonReason: invalid token 'xyz' in CORS header 'Access-Control-Allow-Methods'
What went wrong?The response to the CORS request that was sent by the server includes
an Access-Control-Allow-Methods header which includes at least one
invalid method name.
The Access-Control-Allow-Methods header is sent by the server to let the
client know what HTTP request methods it
supports for CORS requests. The header's value is a comma-delineated string of HTTP
method names, such as GET, POST, or
HEAD. If any of the specified values are not recognized by the client
user agent, this error occurs.
This is a problem that most likely can only be fixed on the server side, by modifying
the server's configuration to no longer send the invalid or unknown method name with the
Access-Control-Allow-Methods header. It may also be worth checking to
ensure that the user agent or HTTP library you're using on the client is up-to-date.See also
CORS errors
Glossary: CORS
CORS introduction
HTTP request methods
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nReason: missing token 'xyz' in CORS header 'Access-Control-Allow-Headers' from CORS preflight channelReasonReason: missing token 'xyz' in CORS header 'Access-Control-Allow-Headers' from CORS preflight channel
What went wrong?The Access-Control-Allow-Headers header is sent by the server to let the client know which headers it supports for CORS requests. The value of Access-Control-Allow-Headers should be a comma-delineated list of header names, such as X-Custom-Information or any of the standard but non-basic header names (which are always allowed).
This error occurs when attempting to preflight a header that is not expressly allowed (that is, it's not included in the list specified by the Access-Control-Allow-Headers header sent by the server). To fix this, the server needs to be updated so that it allows the indicated header, or you need to avoid using that header.See also
CORS errors
Glossary: CORS
CORS introduction
HTTP headers\n\nReason: missing token 'xyz' in CORS header 'Access-Control-Allow-Headers' from CORS preflight channelReasonReason: missing token 'xyz' in CORS header 'Access-Control-Allow-Headers' from CORS preflight channel
What went wrong?The Access-Control-Allow-Headers header is sent by the server to let the client know which headers it supports for CORS requests. The value of Access-Control-Allow-Headers should be a comma-delineated list of header names, such as X-Custom-Information or any of the standard but non-basic header names (which are always allowed).
This error occurs when attempting to preflight a header that is not expressly allowed (that is, it's not included in the list specified by the Access-Control-Allow-Headers header sent by the server). To fix this, the server needs to be updated so that it allows the indicated header, or you need to avoid using that header.See also
CORS errors
Glossary: CORS
CORS introduction
HTTP headers
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nReason: missing token 'xyz' in CORS header 'Access-Control-Allow-Headers' from CORS preflight channelReasonReason: missing token 'xyz' in CORS header 'Access-Control-Allow-Headers' from CORS preflight channel
What went wrong?The Access-Control-Allow-Headers header is sent by the server to let the client know which headers it supports for CORS requests. The value of Access-Control-Allow-Headers should be a comma-delineated list of header names, such as X-Custom-Information or any of the standard but non-basic header names (which are always allowed).
This error occurs when attempting to preflight a header that is not expressly allowed (that is, it's not included in the list specified by the Access-Control-Allow-Headers header sent by the server). To fix this, the server needs to be updated so that it allows the indicated header, or you need to avoid using that header.See also
CORS errors
Glossary: CORS
CORS introduction
HTTP headers
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nReason: Multiple CORS header 'Access-Control-Allow-Origin' not allowedReasonReason: Multiple CORS header 'Access-Control-Allow-Origin' not allowed
What went wrong?More than one Access-Control-Allow-Origin header was sent by the
server. This isn't allowed.
If you have access to the server you can change your implementation to echo back an
origin in the Access-Control-Allow-Origin header. You cannot send back a
list of origins, because browsers only accept a value that is either a single origin or
nullSee also
CORS errors
Glossary: CORS
CORS introduction
Enable CORS: I want to add CORS support to my server\n\nReason: Multiple CORS header 'Access-Control-Allow-Origin' not allowedReasonReason: Multiple CORS header 'Access-Control-Allow-Origin' not allowed
What went wrong?More than one Access-Control-Allow-Origin header was sent by the
server. This isn't allowed.
If you have access to the server you can change your implementation to echo back an
origin in the Access-Control-Allow-Origin header. You cannot send back a
list of origins, because browsers only accept a value that is either a single origin or
nullSee also
CORS errors
Glossary: CORS
CORS introduction
Enable CORS: I want to add CORS support to my server
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nReason: Multiple CORS header 'Access-Control-Allow-Origin' not allowedReasonReason: Multiple CORS header 'Access-Control-Allow-Origin' not allowed
What went wrong?More than one Access-Control-Allow-Origin header was sent by the
server. This isn't allowed.
If you have access to the server you can change your implementation to echo back an
origin in the Access-Control-Allow-Origin header. You cannot send back a
list of origins, because browsers only accept a value that is either a single origin or
nullSee also
CORS errors
Glossary: CORS
CORS introduction
Enable CORS: I want to add CORS support to my server
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nHTTP referenceThis page lists HTTP reference documentation on MDN.
HTTP headersHTTP headers let the client and the server pass additional information with a message in a request or response.
In HTTP/1.X, a header is a case-insensitive name followed by a colon, then optional whitespace which will be ignored, and finally by its value (for example: Allow: POST).
In HTTP/2 and above, headers are displayed in lowercase when viewed in developer tools (accept: */*), and prefixed with a colon for a special group of pseudo-headers (:status: 200).
You can find more information on the syntax in each protocol version in the HTTP messages page.HTTP request methodsHTTP defines a set of request methods to indicate the purpose of the request and what is expected if the request is successful.
Although they can also be nouns, these request methods are sometimes referred to as HTTP verbs.
Each request method has its own semantics, but some characteristics are shared across multiple methods, specifically request methods can be safe, idempotent, or cacheable.HTTP resources and specificationsHTTP was first specified in the early 1990s. Designed with extensibility in mind, it has seen numerous additions over the years; this lead to its specification being scattered through numerous specification documents (in the midst of experimental abandoned extensions). This page lists relevant resources about HTTP.HTTP response status codesHTTP response status codes indicate whether a specific HTTP request has been successfully completed.
Responses are grouped in five classes:
The following subsections are also notable:

CSP directives

The Content-Security-Policy (CSP) response header allows website administrators to specify which resources the user agent is allowed to load for a given page.
This section lists directives that can be used in a CSP header, with individual documentation pages that describe how the directives work and how to use them.

Permissions-Policy directives

The Permissions-Policy response header provides a mechanism to allow or deny the use of browser features in a document or within any <iframe> element in the document.
This section lists directives that can be used in a Permissions-Policy header, with individual documentation pages that describe how the directives work and how to use them.\n\nHTTP referenceThis page lists HTTP reference documentation on MDN.
HTTP headersHTTP headers let the client and the server pass additional information with a message in a request or response.
In HTTP/1.X, a header is a case-insensitive name followed by a colon, then optional whitespace which will be ignored, and finally by its value (for example: Allow: POST).
In HTTP/2 and above, headers are displayed in lowercase when viewed in developer tools (accept: */*), and prefixed with a colon for a special group of pseudo-headers (:status: 200).
You can find more information on the syntax in each protocol version in the HTTP messages page.HTTP request methodsHTTP defines a set of request methods to indicate the purpose of the request and what is expected if the request is successful.
Although they can also be nouns, these request methods are sometimes referred to as HTTP verbs.
Each request method has its own semantics, but some characteristics are shared across multiple methods, specifically request methods can be safe, idempotent, or cacheable.HTTP resources and specificationsHTTP was first specified in the early 1990s. Designed with extensibility in mind, it has seen numerous additions over the years; this lead to its specification being scattered through numerous specification documents (in the midst of experimental abandoned extensions). This page lists relevant resources about HTTP.HTTP response status codesHTTP response status codes indicate whether a specific HTTP request has been successfully completed.
Responses are grouped in five classes:
The following subsections are also notable:

CSP directives

The Content-Security-Policy (CSP) response header allows website administrators to specify which resources the user agent is allowed to load for a given page.
This section lists directives that can be used in a CSP header, with individual documentation pages that describe how the directives work and how to use them.

Permissions-Policy directives

The Permissions-Policy response header provides a mechanism to allow or deny the use of browser features in a document or within any <iframe> element in the document.
This section lists directives that can be used in a Permissions-Policy header, with individual documentation pages that describe how the directives work and how to use them.

Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nHTTP referenceThis page lists HTTP reference documentation on MDN.
HTTP headersHTTP headers let the client and the server pass additional information with a message in a request or response.
In HTTP/1.X, a header is a case-insensitive name followed by a colon, then optional whitespace which will be ignored, and finally by its value (for example: Allow: POST).
In HTTP/2 and above, headers are displayed in lowercase when viewed in developer tools (accept: */*), and prefixed with a colon for a special group of pseudo-headers (:status: 200).
You can find more information on the syntax in each protocol version in the HTTP messages page.HTTP request methodsHTTP defines a set of request methods to indicate the purpose of the request and what is expected if the request is successful.
Although they can also be nouns, these request methods are sometimes referred to as HTTP verbs.
Each request method has its own semantics, but some characteristics are shared across multiple methods, specifically request methods can be safe, idempotent, or cacheable.HTTP resources and specificationsHTTP was first specified in the early 1990s. Designed with extensibility in mind, it has seen numerous additions over the years; this lead to its specification being scattered through numerous specification documents (in the midst of experimental abandoned extensions). This page lists relevant resources about HTTP.HTTP response status codesHTTP response status codes indicate whether a specific HTTP request has been successfully completed.
Responses are grouped in five classes:
The following subsections are also notable:

CSP directives

The Content-Security-Policy (CSP) response header allows website administrators to specify which resources the user agent is allowed to load for a given page.
This section lists directives that can be used in a CSP header, with individual documentation pages that describe how the directives work and how to use them.

Permissions-Policy directives

The Permissions-Policy response header provides a mechanism to allow or deny the use of browser features in a document or within any <iframe> element in the document.
This section lists directives that can be used in a Permissions-Policy header, with individual documentation pages that describe how the directives work and how to use them.

Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nHTTP headersHTTP headers let the client and the server pass additional information with a message in a request or response.
In HTTP/1.X, a header is a case-insensitive name followed by a colon, then optional whitespace which will be ignored, and finally by its value (for example: Allow: POST).
In HTTP/2 and above, headers are displayed in lowercase when viewed in developer tools (accept: */*), and prefixed with a colon for a special group of pseudo-headers (:status: 200).
You can find more information on the syntax in each protocol version in the HTTP messages page.
Custom proprietary headers have historically been used with an X- prefix, but this convention was deprecated in 2012 because of the inconveniences it caused when nonstandard fields became standard in RFC 6648; others are listed in the IANA HTTP Field Name Registry, whose original content was defined in RFC 4229.
The IANA registry lists headers, including information about their status.
Headers can be grouped according to their contexts:

Request headers

Contain more information about the resource to be fetched, or about the client requesting the resource.

Response headers

Hold additional information about the response, like its location or about the server providing it.

Representation headers

Contain information about the body of the resource, like its MIME type, or encoding/compression applied.

Payload headers

Contain representation-independent information about payload data, including content length and the encoding used for transport.


Headers can also be grouped according to how proxies handle them:

End-to-end headers

These headers must be transmitted to the final recipient of the message: the server for a request, or the client for a response. Intermediate proxies must retransmit these headers unmodified and caches must store them.

Hop-by-hop headers

These headers are meaningful only for a single transport-level connection, and must not be retransmitted by proxies or cached. Note that only hop-by-hop headers may be set using the Connection header.

Authentication
WWW-Authenticate

Defines the authentication method that should be used to access a resource.

Authorization

Contains the credentials to authenticate a user-agent with a server.

Proxy-Authenticate

Defines the authentication method that should be used to access a resource behind a proxy server.

Proxy-Authorization

Contains the credentials to authenticate a user agent with a proxy server.

Caching
Age

The time, in seconds, that the object has been in a proxy cache.

Cache-Control

Directives for caching mechanisms in both requests and responses.

Clear-Site-Data

Clears browsing data (e.g., cookies, storage, cache) associated with the requesting website.

Expires

The date/time after which the response is considered stale.

No-Vary-Search 
Experimental


Specifies a set of rules that define how a URL's query parameters will affect cache matching. These rules dictate whether the same URL with different URL parameters should be saved as separate browser cache entries.

Conditionals
Last-Modified

The last modification date of the resource, used to compare several versions of the same resource. It is less accurate than ETag, but easier to calculate in some environments. Conditional requests using If-Modified-Since and If-Unmodified-Since use this value to change the behavior of the request.

ETag

A unique string identifying the version of the resource. Conditional requests using If-Match and If-None-Match use this value to change the behavior of the request.

If-Match

Makes the request conditional, and applies the method only if the stored resource matches one of the given ETags.

If-None-Match

Makes the request conditional, and applies the method only if the stored resource doesn't match any of the given ETags. This is used to update caches (for safe requests), or to prevent uploading a new resource when one already exists.

If-Modified-Since

Makes the request conditional, and expects the resource to be transmitted only if it has been modified after the given date. This is used to transmit data only when the cache is out of date.

If-Unmodified-Since

Makes the request conditional, and expects the resource to be transmitted only if it has not been modified after the given date. This ensures the coherence of a new fragment of a specific range with previous ones, or to implement an optimistic concurrency control system when modifying existing documents.

Vary

Determines how to match request headers to decide whether a cached response can be used rather than requesting a fresh one from the origin server.

Connection management
Connection

Controls whether the network connection stays open after the current transaction finishes.

Keep-Alive

Controls how long a persistent connection should stay open.

Content negotiationFor more details, refer to the Content negotiation article.

Accept

Informs the server about the types of data that can be sent back.

Accept-Encoding

The encoding algorithm, usually a compression algorithm, that can be used on the resource sent back.

Accept-Language

Informs the server about the human language the server is expected to send back. This is a hint and is not necessarily under the full control of the user: the server should always pay attention not to override an explicit user choice (like selecting a language from a dropdown).

Accept-Patch

A request content negotiation response header that advertises which media type the server is able to understand in a PATCH request.

Accept-Post

A request content negotiation response header that advertises which media type the server is able to understand in a POST request.

Controls
Expect

Indicates expectations that need to be fulfilled by the server to properly handle the request.

Max-Forwards

When using TRACE, indicates the maximum number of hops the request can do before being reflected to the sender.

Cookies
Cookie

Contains stored HTTP cookies previously sent by the server with the Set-Cookie header.

Set-Cookie

Send cookies from the server to the user-agent.

CORSFor more information, refer to the CORS documentation.

Access-Control-Allow-Credentials

Indicates whether the response to the request can be exposed when the credentials flag is true.

Access-Control-Allow-Headers

Used in response to a preflight request to indicate which HTTP headers can be used when making the actual request.

Access-Control-Allow-Methods

Specifies the methods allowed when accessing the resource in response to a preflight request.

Access-Control-Allow-Origin

Indicates whether the response can be shared.

Access-Control-Expose-Headers

Indicates which headers can be exposed as part of the response by listing their names.

Access-Control-Max-Age

Indicates how long the results of a preflight request can be cached.

Access-Control-Request-Headers

Used when issuing a preflight request to let the server know which HTTP headers will be used when the actual request is made.

Access-Control-Request-Method

Used when issuing a preflight request to let the server know which HTTP method will be used when the actual request is made.

Origin

Indicates where a fetch originates from.

Timing-Allow-Origin

Specifies origins that are allowed to see values of attributes retrieved via features of the Resource Timing API, which would otherwise be reported as zero due to cross-origin restrictions.

Downloads
Content-Disposition

Indicates if the resource transmitted should be displayed inline (default behavior without the header), or if it should be handled like a download and the browser should present a "Save As" dialog.

Integrity digests
Content-Digest 
Experimental


Provides a digest of the stream of octets framed in an HTTP message (the message content) dependent on Content-Encoding and Content-Range.

Repr-Digest 
Experimental


Provides a digest of the selected representation of the target resource before transmission.
Unlike the Content-Digest, the digest does not consider Content-Encoding or Content-Range.

Want-Content-Digest 
Experimental


States the wish for a Content-Digest header.
It is the Content- analogue of Want-Repr-Digest.

Want-Repr-Digest 
Experimental


States the wish for a Repr-Digest header.
It is the Repr- analogue of Want-Content-Digest.

Message body information
Content-Length

The size of the resource, in decimal number of bytes.

Content-Type

Indicates the media type of the resource.

Content-Encoding

Used to specify the compression algorithm.

Content-Language

Describes the human language(s) intended for the audience, so that it allows a user to differentiate according to the users' own preferred language.

Content-Location

Indicates an alternate location for the returned data.

PreferencesPreferences can be sent by clients in requests to indicate optional behaviors for requests and responses.
The server response may indicate if a preference is applied, in cases where it would otherwise be ambiguous for the client.
Browsers have no native handling for sending preferences via these headers; they are used in custom, implementation-specific clients.

Prefer

Indicates preferences for specific server behaviors during request processing. For example, it can request minimal response content (return=minimal) or asynchronous processing (respond-async). The server processes the request normally if the header is unsupported.

Preference-Applied

Informs the client which preferences specified in the Prefer header were applied by the server. It is a response-only header providing transparency about preference handling.

Proxies
Forwarded

Contains information from the client-facing side of proxy servers that is altered or lost when a proxy is involved in the path of the request.

Via

Added by proxies, both forward and reverse proxies, and can appear in the request headers and the response headers.

Range requestsHTTP range requests allow the client to request a portion of a resource from the server.
Range requests are useful for applications like media players that support random access, data tools that know they need only part of a large file, and download managers that let the user pause and resume a download.

Accept-Ranges

Indicates if the server supports range requests, and if so in which unit the range can be expressed.

Range

Indicates the part of a document that the server should return.

If-Range

Creates a conditional range request that is only fulfilled if the given etag or date matches the remote resource. Used to prevent downloading two ranges from incompatible version of the resource.

Content-Range

Indicates where in a full body message a partial message belongs.

Redirects
Location

Indicates the URL to redirect a page to.

Refresh

Directs the browser to reload the page or redirect to another. Takes the same value as the meta element with http-equiv="refresh".

Request context
From

Contains an Internet email address for a human user who controls the requesting user agent.

Host

Specifies the domain name of the server (for virtual hosting), and (optionally) the TCP port number on which the server is listening.

Referer

The address of the previous web page from which a link to the currently requested page was followed.

Referrer-Policy

Governs which referrer information sent in the Referer header should be included with requests made.

User-Agent

Contains a characteristic string that allows the network protocol peers to identify the application type, operating system, software vendor or software version of the requesting software user agent.

Response context
Allow

Lists the set of HTTP request methods supported by a resource.

Server

Contains information about the software used by the origin server to handle the request.

Security
Cross-Origin-Embedder-Policy (COEP)

Allows a server to declare an embedder policy for a given document.

Cross-Origin-Opener-Policy (COOP)

Prevents other domains from opening/controlling a window.

Cross-Origin-Resource-Policy (CORP)

Prevents other domains from reading the response of the resources to which this header is applied. See also CORP explainer article.

Content-Security-Policy (CSP)

Controls resources the user agent is allowed to load for a given page.

Content-Security-Policy-Report-Only

Allows web developers to experiment with policies by monitoring, but not enforcing, their effects. These violation reports consist of JSON documents sent via an HTTP POST request to the specified URI.

Expect-CT 
Deprecated


Lets sites opt in to reporting and enforcement of Certificate Transparency to detect use of misissued certificates for that site.

Permissions-Policy

Provides a mechanism to allow and deny the use of browser features in a website's own frame, and in <iframe>s that it embeds.

Reporting-Endpoints 
Experimental


Response header that allows website owners to specify one or more endpoints used to receive errors such as CSP violation reports, Cross-Origin-Opener-Policy reports, or other generic violations.

Strict-Transport-Security (HSTS)

Force communication using HTTPS instead of HTTP.

Upgrade-Insecure-Requests

Sends a signal to the server expressing the client's preference for an encrypted and authenticated response, and that it can successfully handle the upgrade-insecure-requests directive.

X-Content-Type-Options

Disables MIME sniffing and forces browser to use the type given in Content-Type.

X-Frame-Options (XFO)

Indicates whether a browser should be allowed to render a page in a <frame>, <iframe>, <embed> or <object>.

X-Permitted-Cross-Domain-Policies

A cross-domain policy file may grant clients, such as Adobe Acrobat or Apache Flex (among others), permission to handle data across domains that would otherwise be restricted due to the Same-Origin Policy.
The X-Permitted-Cross-Domain-Policies header overrides such policy files so that clients still block unwanted requests.

X-Powered-By

May be set by hosting environments or other frameworks and contains information about them while not providing any usefulness to the application or its visitors. Unset this header to avoid exposing potential vulnerabilities.

X-XSS-Protection

Enables cross-site scripting filtering.

Fetch metadata request headersFetch metadata request headers provide information about the context from which the request originated. A server can use them to make decisions about whether a request should be allowed, based on where the request came from and how the resource will be used.

Sec-Fetch-Site

Indicates the relationship between a request initiator's origin and its target's origin. It is a Structured Header whose value is a token with possible values cross-site, same-origin, same-site, and none.

Sec-Fetch-Mode

Indicates the request's mode to a server. It is a Structured Header whose value is a token with possible values cors, navigate, no-cors, same-origin, and websocket.

Sec-Fetch-User

Indicates whether or not a navigation request was triggered by user activation. It is a Structured Header whose value is a boolean so possible values are ?0 for false and ?1 for true.

Sec-Fetch-Dest

Indicates the request's destination. It is a Structured Header whose value is a token with possible values audio, audioworklet, document, embed, empty, font, image, manifest, object, paintworklet, report, script, serviceworker, sharedworker, style, track, video, worker, and xslt.


The following request headers are not strictly "fetch metadata request headers", but similarly provide information about the context of how a resource will be used. A server might use them to modify its caching behavior, or the information that is returned:

Sec-Purpose

Indicates the purpose of the request, when the purpose is something other than immediate use by the user-agent. The header currently has one possible value, prefetch, which indicates that the resource is being fetched preemptively for a possible future navigation.

Service-Worker-Navigation-Preload

A request header sent in preemptive request to fetch() a resource during service worker boot. The value, which is set with NavigationPreloadManager.setHeaderValue(), can be used to inform a server that a different resource should be returned than in a normal fetch() operation.

Server-sent events
Reporting-Endpoints

Response header used to specify server endpoints where the browser should send warning and error reports when using the Reporting API.

Report-To 
Deprecated
 
Non-standard


Response header used to specify server endpoints where the browser should send warning and error reports when using the Reporting API.

Transfer coding
Transfer-Encoding

Specifies the form of encoding used to safely transfer the resource to the user.

TE

Specifies the transfer encodings the user agent is willing to accept.

Trailer

Allows the sender to include additional fields at the end of chunked message.

WebSocketsHeaders used by the WebSockets API in the WebSocket handshake:

Sec-WebSocket-Accept

Response header that indicates that the server is willing to upgrade to a WebSocket connection.

Sec-WebSocket-Extensions

In requests, this header indicates the WebSocket extensions supported by the client in preferred order.
In responses, it indicates the extension selected by the server from the client's preferences.

Sec-WebSocket-Key

Request header containing a key that verifies that the client explicitly intends to open a WebSocket.

Sec-WebSocket-Protocol

In requests, this header indicates the sub-protocols supported by the client in preferred order.
In responses, it indicates the sub-protocol selected by the server from the client's preferences.

Sec-WebSocket-Version

In requests, this header indicates the version of the WebSocket protocol used by the client.
In responses, it is sent only if the requested protocol version is not supported by the server, and lists the versions that the server supports.

Other
Alt-Svc

Used to list alternate ways to reach this service.

Alt-Used

Used to identify the alternative service in use.

Date

Contains the date and time at which the message was originated.

Link

This entity-header field provides a means for serializing one or more links in HTTP headers. It is semantically equivalent to the HTML <link> element.

Retry-After

Indicates how long the user agent should wait before making a follow-up request.

Server-Timing

Communicates one or more metrics and descriptions for the given request-response cycle.

Service-Worker

Included in fetches for a service worker's script resource.
This header helps administrators log service worker script requests for monitoring purposes.

Service-Worker-Allowed

Used to remove the path restriction by including this header in the response of the Service Worker script.

SourceMap

Links to a source map so that debuggers can step through original source code instead of generated or transformed code.

Upgrade

This HTTP/1.1 (only) header can be used to upgrade an already established client/server connection to a different protocol (over the same transport protocol). For example, it can be used by a client to upgrade a connection from HTTP 1.1 to HTTP 2.0, or an HTTP or HTTPS connection into a WebSocket.

Priority

Provides a hint from about the priority of a particular resource request on a particular connection.
The value can be sent in a request to indicate the client priority, or in a response if the server chooses to reprioritize the request.

Experimental headersAttribution reporting headersThe Attribution Reporting API enables developers to measure conversions — for example when a user clicks an ad embedded on one site and then proceeds to purchase the item over on the vendor's site — and then access reports on those conversions. It does this without relying on third-party tracking cookies, instead relying on various headers to register sources and triggers that are matched to indicate a conversion.

Attribution-Reporting-Eligible

Used to indicate that the response corresponding to the current request is eligible to take part in attribution reporting, by registering either an attribution source or trigger.

Attribution-Reporting-Register-Source

Included as part of a response to a request that included an Attribution-Reporting-Eligible header, this is used to register an attribution source.

Attribution-Reporting-Register-Trigger

Included as part of a response to a request that included an Attribution-Reporting-Eligible header, this is used to register an attribution trigger.

Client hintsHTTP Client hints are a set of request headers that provide useful information about the client such as device type and network conditions, and allow servers to optimize what is served for those conditions.
Servers proactively requests the client hint headers they are interested in from the client using Accept-CH. The client may then choose to include the requested headers in subsequent requests.

Accept-CH

Servers can advertise support for Client Hints using the Accept-CH header field or an equivalent HTML <meta> element with http-equiv attribute.

Critical-CH 
Experimental


Servers use Critical-CH along with Accept-CH to specify that accepted client hints are also critical client hints.


The different categories of client hints are listed below.
User agent client hints
The UA client hints are request headers that provide information about the user agent, the platform/architecture it is running on, and user preferences set on the user agent or platform:

Sec-CH-UA 
Experimental


User agent's branding and version.

Sec-CH-UA-Arch 
Experimental


User agent's underlying platform architecture.

Sec-CH-UA-Bitness 
Experimental


User agent's underlying CPU architecture bitness (for example "64" bit).

Sec-CH-UA-Form-Factors 
Experimental


User agent's form-factors, describing how the user interacts with the user-agent.

Sec-CH-UA-Full-Version 
Deprecated


User agent's full version string.

Sec-CH-UA-Full-Version-List 
Experimental


Full version for each brand in the user agent's brand list.

Sec-CH-UA-Mobile 
Experimental


User agent is running on a mobile device or, more generally, prefers a "mobile" user experience.

Sec-CH-UA-Model 
Experimental


User agent's device model.

Sec-CH-UA-Platform 
Experimental


User agent's underlying operation system/platform.

Sec-CH-UA-Platform-Version 
Experimental


User agent's underlying operation system version.

Sec-CH-UA-WoW64 
Experimental


Whether or not the user agent binary is running in 32-bit mode on 64-bit Windows.

Sec-CH-Prefers-Color-Scheme 
Experimental


User's preference of dark or light color scheme.

Sec-CH-Prefers-Reduced-Motion 
Experimental


User's preference to see fewer animations and content layout shifts.

Sec-CH-Prefers-Reduced-Transparency 
Experimental


Request header indicates the user agent's preference for reduced transparency.



Note:
User-agent client hints are not available inside fenced frames because they rely on permissions policy delegation, which could be used to leak data.

Device client hints

Content-DPR 
Deprecated
 
Non-standard


Response header used to confirm the image device to pixel ratio (DPR) in requests where the screen DPR client hint was used to select an image resource.

Device-Memory

Approximate amount of available client RAM memory. This is part of the Device Memory API.

DPR 
Deprecated
 
Non-standard


Request header that provides the client device pixel ratio (the number of physical device pixels for each CSS pixel).

Viewport-Width 
Deprecated
 
Non-standard


Request header provides the client's layout viewport width in CSS pixels.

Width 
Deprecated
 
Non-standard


Request header indicates the desired resource width in physical pixels (the intrinsic size of an image).


Network client hints
Network client hints allow a server to choose what information is sent based on the user choice and network bandwidth and latency.

Downlink 
Experimental


Approximate bandwidth of the client's connection to the server, in Mbps. This is part of the Network Information API.

ECT 
Experimental


The effective connection type ("network profile") that best matches the connection's latency and bandwidth. This is part of the Network Information API.

RTT 
Experimental


Application layer round trip time (RTT) in milliseconds, which includes the server processing time. This is part of the Network Information API.

Save-Data 
Experimental


A string on that indicates the user agent's preference for reduced data usage.

Compression Dictionary TransportCompression Dictionary Transport is a way of using a shared compression dictionary to reduce the transport size of HTTP responses rather than using the standard static dictionary in Brotli compression or Zstandard compression.

Available-Dictionary 
Experimental


A browser can use this request header to indicate the best dictionary it has available for the server to use for compression.

Dictionary-ID 
Experimental


Used when a browser already has a dictionary available for a resource and the server provided an id for the dictionary in the Use-As-Dictionary header.
Requests for resources that can use the dictionary have an Available-Dictionary header and the server-provided dictionary id in the Dictionary-ID header.

Use-As-Dictionary 
Experimental


Lists the matching criteria that the dictionary can be used for in future requests.

Privacy
DNT 
Deprecated
 
Non-standard


Request header that indicates the user's tracking preference (Do Not Track).
Deprecated in favor of Global Privacy Control (GPC), which is communicated to servers using the Sec-GPC header, and accessible to clients via navigator.globalPrivacyControl.

Tk 
Deprecated
 
Non-standard


Response header that indicates the tracking status that applied to the corresponding request. Used in conjunction with DNT.

Sec-GPC 
Non-standard
 
Experimental


Indicates whether the user consents to a website or service selling or sharing their personal information with third parties.

Security
Origin-Agent-Cluster 
Experimental


Response header used to indicate that the associated Document should be placed in an origin-keyed agent cluster.
This isolation allows user agents to allocate implementation-specific resources for agent clusters, such as processes or threads, more efficiently.

Server-sent events
NEL 
Experimental


Defines a mechanism that enables developers to declare a network error reporting policy.

Topics APIThe Topics API provides a mechanism for developers to implement use cases such as interest-based advertising (IBA).
See the Topics API documentation for more information.

Observe-Browsing-Topics 
Experimental
 
Non-standard


Response header used to mark topics of interest inferred from a calling site's URL as observed in the response to a request generated by a feature that enables the Topics API.

Sec-Browsing-Topics 
Experimental
 
Non-standard


Request header that sends the selected topics for the current user along with the associated request, which are used by an ad tech platform to choose a personalized ad to display.

Other
Accept-Signature 
Experimental


A client can send the Accept-Signature header field to indicate intention to take advantage of any available signatures and to indicate what kinds of signatures it supports.

Early-Data 
Experimental


Indicates that the request has been conveyed in TLS early data.

Set-Login 
Experimental


Response header sent by a federated identity provider (IdP) to set its login status, meaning whether any users are logged into the IdP on the current browser or not.
This is stored by the browser and used by the FedCM API.

Signature 
Experimental


The Signature header field conveys a list of signatures for an exchange, each one accompanied by information about how to determine the authority of and refresh that signature.

Signed-Headers 
Experimental


The Signed-Headers header field identifies an ordered list of response header fields to include in a signature.

Speculation-Rules 
Experimental


Provides a list of URLs pointing to text resources containing speculation rule JSON definitions. When the response is an HTML document, these rules will be added to the document's speculation rule set.

Supports-Loading-Mode 
Experimental


Set by a navigation target to opt-in to using various higher-risk loading modes. For example, cross-origin, same-site prerendering requires a Supports-Loading-Mode value of credentialed-prerender.

Non-standard headers
X-Forwarded-For 
Non-standard


Identifies the originating IP addresses of a client connecting to a web server through an HTTP proxy or a load balancer.

X-Forwarded-Host 
Non-standard


Identifies the original host requested that a client used to connect to your proxy or load balancer.

X-Forwarded-Proto 
Non-standard


Identifies the protocol (HTTP or HTTPS) that a client used to connect to your proxy or load balancer.

X-DNS-Prefetch-Control 
Non-standard


Controls DNS prefetching, a feature by which browsers proactively perform domain name resolution on both links that the user may choose to follow as well as URLs for items referenced by the document, including images, CSS, JavaScript, and so forth.

X-Robots-Tag 
Non-standard


The X-Robots-Tag HTTP header is used to indicate how a web page is to be indexed within public search engine results. The header is effectively equivalent to <meta name="robots" content="…">.

Deprecated headers
Pragma 
Deprecated


Implementation-specific header that may have various effects anywhere along the request-response chain. Used for backwards compatibility with HTTP/1.0 caches where the Cache-Control header is not yet present.

Warning 
Deprecated


General warning information about possible problems.

See also
Wikipedia page on List of HTTP headers
IANA registry
HTTP Working Group\n\nHTTP headersHTTP headers let the client and the server pass additional information with a message in a request or response.
In HTTP/1.X, a header is a case-insensitive name followed by a colon, then optional whitespace which will be ignored, and finally by its value (for example: Allow: POST).
In HTTP/2 and above, headers are displayed in lowercase when viewed in developer tools (accept: */*), and prefixed with a colon for a special group of pseudo-headers (:status: 200).
You can find more information on the syntax in each protocol version in the HTTP messages page.
Custom proprietary headers have historically been used with an X- prefix, but this convention was deprecated in 2012 because of the inconveniences it caused when nonstandard fields became standard in RFC 6648; others are listed in the IANA HTTP Field Name Registry, whose original content was defined in RFC 4229.
The IANA registry lists headers, including information about their status.
Headers can be grouped according to their contexts:

Request headers

Contain more information about the resource to be fetched, or about the client requesting the resource.

Response headers

Hold additional information about the response, like its location or about the server providing it.

Representation headers

Contain information about the body of the resource, like its MIME type, or encoding/compression applied.

Payload headers

Contain representation-independent information about payload data, including content length and the encoding used for transport.


Headers can also be grouped according to how proxies handle them:

End-to-end headers

These headers must be transmitted to the final recipient of the message: the server for a request, or the client for a response. Intermediate proxies must retransmit these headers unmodified and caches must store them.

Hop-by-hop headers

These headers are meaningful only for a single transport-level connection, and must not be retransmitted by proxies or cached. Note that only hop-by-hop headers may be set using the Connection header.

Authentication
WWW-Authenticate

Defines the authentication method that should be used to access a resource.

Authorization

Contains the credentials to authenticate a user-agent with a server.

Proxy-Authenticate

Defines the authentication method that should be used to access a resource behind a proxy server.

Proxy-Authorization

Contains the credentials to authenticate a user agent with a proxy server.

Caching
Age

The time, in seconds, that the object has been in a proxy cache.

Cache-Control

Directives for caching mechanisms in both requests and responses.

Clear-Site-Data

Clears browsing data (e.g., cookies, storage, cache) associated with the requesting website.

Expires

The date/time after which the response is considered stale.

No-Vary-Search 
Experimental


Specifies a set of rules that define how a URL's query parameters will affect cache matching. These rules dictate whether the same URL with different URL parameters should be saved as separate browser cache entries.

Conditionals
Last-Modified

The last modification date of the resource, used to compare several versions of the same resource. It is less accurate than ETag, but easier to calculate in some environments. Conditional requests using If-Modified-Since and If-Unmodified-Since use this value to change the behavior of the request.

ETag

A unique string identifying the version of the resource. Conditional requests using If-Match and If-None-Match use this value to change the behavior of the request.

If-Match

Makes the request conditional, and applies the method only if the stored resource matches one of the given ETags.

If-None-Match

Makes the request conditional, and applies the method only if the stored resource doesn't match any of the given ETags. This is used to update caches (for safe requests), or to prevent uploading a new resource when one already exists.

If-Modified-Since

Makes the request conditional, and expects the resource to be transmitted only if it has been modified after the given date. This is used to transmit data only when the cache is out of date.

If-Unmodified-Since

Makes the request conditional, and expects the resource to be transmitted only if it has not been modified after the given date. This ensures the coherence of a new fragment of a specific range with previous ones, or to implement an optimistic concurrency control system when modifying existing documents.

Vary

Determines how to match request headers to decide whether a cached response can be used rather than requesting a fresh one from the origin server.

Connection management
Connection

Controls whether the network connection stays open after the current transaction finishes.

Keep-Alive

Controls how long a persistent connection should stay open.

Content negotiationFor more details, refer to the Content negotiation article.

Accept

Informs the server about the types of data that can be sent back.

Accept-Encoding

The encoding algorithm, usually a compression algorithm, that can be used on the resource sent back.

Accept-Language

Informs the server about the human language the server is expected to send back. This is a hint and is not necessarily under the full control of the user: the server should always pay attention not to override an explicit user choice (like selecting a language from a dropdown).

Accept-Patch

A request content negotiation response header that advertises which media type the server is able to understand in a PATCH request.

Accept-Post

A request content negotiation response header that advertises which media type the server is able to understand in a POST request.

Controls
Expect

Indicates expectations that need to be fulfilled by the server to properly handle the request.

Max-Forwards

When using TRACE, indicates the maximum number of hops the request can do before being reflected to the sender.

Cookies
Cookie

Contains stored HTTP cookies previously sent by the server with the Set-Cookie header.

Set-Cookie

Send cookies from the server to the user-agent.

CORSFor more information, refer to the CORS documentation.

Access-Control-Allow-Credentials

Indicates whether the response to the request can be exposed when the credentials flag is true.

Access-Control-Allow-Headers

Used in response to a preflight request to indicate which HTTP headers can be used when making the actual request.

Access-Control-Allow-Methods

Specifies the methods allowed when accessing the resource in response to a preflight request.

Access-Control-Allow-Origin

Indicates whether the response can be shared.

Access-Control-Expose-Headers

Indicates which headers can be exposed as part of the response by listing their names.

Access-Control-Max-Age

Indicates how long the results of a preflight request can be cached.

Access-Control-Request-Headers

Used when issuing a preflight request to let the server know which HTTP headers will be used when the actual request is made.

Access-Control-Request-Method

Used when issuing a preflight request to let the server know which HTTP method will be used when the actual request is made.

Origin

Indicates where a fetch originates from.

Timing-Allow-Origin

Specifies origins that are allowed to see values of attributes retrieved via features of the Resource Timing API, which would otherwise be reported as zero due to cross-origin restrictions.

Downloads
Content-Disposition

Indicates if the resource transmitted should be displayed inline (default behavior without the header), or if it should be handled like a download and the browser should present a "Save As" dialog.

Integrity digests
Content-Digest 
Experimental


Provides a digest of the stream of octets framed in an HTTP message (the message content) dependent on Content-Encoding and Content-Range.

Repr-Digest 
Experimental


Provides a digest of the selected representation of the target resource before transmission.
Unlike the Content-Digest, the digest does not consider Content-Encoding or Content-Range.

Want-Content-Digest 
Experimental


States the wish for a Content-Digest header.
It is the Content- analogue of Want-Repr-Digest.

Want-Repr-Digest 
Experimental


States the wish for a Repr-Digest header.
It is the Repr- analogue of Want-Content-Digest.

Message body information
Content-Length

The size of the resource, in decimal number of bytes.

Content-Type

Indicates the media type of the resource.

Content-Encoding

Used to specify the compression algorithm.

Content-Language

Describes the human language(s) intended for the audience, so that it allows a user to differentiate according to the users' own preferred language.

Content-Location

Indicates an alternate location for the returned data.

PreferencesPreferences can be sent by clients in requests to indicate optional behaviors for requests and responses.
The server response may indicate if a preference is applied, in cases where it would otherwise be ambiguous for the client.
Browsers have no native handling for sending preferences via these headers; they are used in custom, implementation-specific clients.

Prefer

Indicates preferences for specific server behaviors during request processing. For example, it can request minimal response content (return=minimal) or asynchronous processing (respond-async). The server processes the request normally if the header is unsupported.

Preference-Applied

Informs the client which preferences specified in the Prefer header were applied by the server. It is a response-only header providing transparency about preference handling.

Proxies
Forwarded

Contains information from the client-facing side of proxy servers that is altered or lost when a proxy is involved in the path of the request.

Via

Added by proxies, both forward and reverse proxies, and can appear in the request headers and the response headers.

Range requestsHTTP range requests allow the client to request a portion of a resource from the server.
Range requests are useful for applications like media players that support random access, data tools that know they need only part of a large file, and download managers that let the user pause and resume a download.

Accept-Ranges

Indicates if the server supports range requests, and if so in which unit the range can be expressed.

Range

Indicates the part of a document that the server should return.

If-Range

Creates a conditional range request that is only fulfilled if the given etag or date matches the remote resource. Used to prevent downloading two ranges from incompatible version of the resource.

Content-Range

Indicates where in a full body message a partial message belongs.

Redirects
Location

Indicates the URL to redirect a page to.

Refresh

Directs the browser to reload the page or redirect to another. Takes the same value as the meta element with http-equiv="refresh".

Request context
From

Contains an Internet email address for a human user who controls the requesting user agent.

Host

Specifies the domain name of the server (for virtual hosting), and (optionally) the TCP port number on which the server is listening.

Referer

The address of the previous web page from which a link to the currently requested page was followed.

Referrer-Policy

Governs which referrer information sent in the Referer header should be included with requests made.

User-Agent

Contains a characteristic string that allows the network protocol peers to identify the application type, operating system, software vendor or software version of the requesting software user agent.

Response context
Allow

Lists the set of HTTP request methods supported by a resource.

Server

Contains information about the software used by the origin server to handle the request.

Security
Cross-Origin-Embedder-Policy (COEP)

Allows a server to declare an embedder policy for a given document.

Cross-Origin-Opener-Policy (COOP)

Prevents other domains from opening/controlling a window.

Cross-Origin-Resource-Policy (CORP)

Prevents other domains from reading the response of the resources to which this header is applied. See also CORP explainer article.

Content-Security-Policy (CSP)

Controls resources the user agent is allowed to load for a given page.

Content-Security-Policy-Report-Only

Allows web developers to experiment with policies by monitoring, but not enforcing, their effects. These violation reports consist of JSON documents sent via an HTTP POST request to the specified URI.

Expect-CT 
Deprecated


Lets sites opt in to reporting and enforcement of Certificate Transparency to detect use of misissued certificates for that site.

Permissions-Policy

Provides a mechanism to allow and deny the use of browser features in a website's own frame, and in <iframe>s that it embeds.

Reporting-Endpoints 
Experimental


Response header that allows website owners to specify one or more endpoints used to receive errors such as CSP violation reports, Cross-Origin-Opener-Policy reports, or other generic violations.

Strict-Transport-Security (HSTS)

Force communication using HTTPS instead of HTTP.

Upgrade-Insecure-Requests

Sends a signal to the server expressing the client's preference for an encrypted and authenticated response, and that it can successfully handle the upgrade-insecure-requests directive.

X-Content-Type-Options

Disables MIME sniffing and forces browser to use the type given in Content-Type.

X-Frame-Options (XFO)

Indicates whether a browser should be allowed to render a page in a <frame>, <iframe>, <embed> or <object>.

X-Permitted-Cross-Domain-Policies

A cross-domain policy file may grant clients, such as Adobe Acrobat or Apache Flex (among others), permission to handle data across domains that would otherwise be restricted due to the Same-Origin Policy.
The X-Permitted-Cross-Domain-Policies header overrides such policy files so that clients still block unwanted requests.

X-Powered-By

May be set by hosting environments or other frameworks and contains information about them while not providing any usefulness to the application or its visitors. Unset this header to avoid exposing potential vulnerabilities.

X-XSS-Protection

Enables cross-site scripting filtering.

Fetch metadata request headersFetch metadata request headers provide information about the context from which the request originated. A server can use them to make decisions about whether a request should be allowed, based on where the request came from and how the resource will be used.

Sec-Fetch-Site

Indicates the relationship between a request initiator's origin and its target's origin. It is a Structured Header whose value is a token with possible values cross-site, same-origin, same-site, and none.

Sec-Fetch-Mode

Indicates the request's mode to a server. It is a Structured Header whose value is a token with possible values cors, navigate, no-cors, same-origin, and websocket.

Sec-Fetch-User

Indicates whether or not a navigation request was triggered by user activation. It is a Structured Header whose value is a boolean so possible values are ?0 for false and ?1 for true.

Sec-Fetch-Dest

Indicates the request's destination. It is a Structured Header whose value is a token with possible values audio, audioworklet, document, embed, empty, font, image, manifest, object, paintworklet, report, script, serviceworker, sharedworker, style, track, video, worker, and xslt.


The following request headers are not strictly "fetch metadata request headers", but similarly provide information about the context of how a resource will be used. A server might use them to modify its caching behavior, or the information that is returned:

Sec-Purpose

Indicates the purpose of the request, when the purpose is something other than immediate use by the user-agent. The header currently has one possible value, prefetch, which indicates that the resource is being fetched preemptively for a possible future navigation.

Service-Worker-Navigation-Preload

A request header sent in preemptive request to fetch() a resource during service worker boot. The value, which is set with NavigationPreloadManager.setHeaderValue(), can be used to inform a server that a different resource should be returned than in a normal fetch() operation.

Server-sent events
Reporting-Endpoints

Response header used to specify server endpoints where the browser should send warning and error reports when using the Reporting API.

Report-To 
Deprecated
 
Non-standard


Response header used to specify server endpoints where the browser should send warning and error reports when using the Reporting API.

Transfer coding
Transfer-Encoding

Specifies the form of encoding used to safely transfer the resource to the user.

TE

Specifies the transfer encodings the user agent is willing to accept.

Trailer

Allows the sender to include additional fields at the end of chunked message.

WebSocketsHeaders used by the WebSockets API in the WebSocket handshake:

Sec-WebSocket-Accept

Response header that indicates that the server is willing to upgrade to a WebSocket connection.

Sec-WebSocket-Extensions

In requests, this header indicates the WebSocket extensions supported by the client in preferred order.
In responses, it indicates the extension selected by the server from the client's preferences.

Sec-WebSocket-Key

Request header containing a key that verifies that the client explicitly intends to open a WebSocket.

Sec-WebSocket-Protocol

In requests, this header indicates the sub-protocols supported by the client in preferred order.
In responses, it indicates the sub-protocol selected by the server from the client's preferences.

Sec-WebSocket-Version

In requests, this header indicates the version of the WebSocket protocol used by the client.
In responses, it is sent only if the requested protocol version is not supported by the server, and lists the versions that the server supports.

Other
Alt-Svc

Used to list alternate ways to reach this service.

Alt-Used

Used to identify the alternative service in use.

Date

Contains the date and time at which the message was originated.

Link

This entity-header field provides a means for serializing one or more links in HTTP headers. It is semantically equivalent to the HTML <link> element.

Retry-After

Indicates how long the user agent should wait before making a follow-up request.

Server-Timing

Communicates one or more metrics and descriptions for the given request-response cycle.

Service-Worker

Included in fetches for a service worker's script resource.
This header helps administrators log service worker script requests for monitoring purposes.

Service-Worker-Allowed

Used to remove the path restriction by including this header in the response of the Service Worker script.

SourceMap

Links to a source map so that debuggers can step through original source code instead of generated or transformed code.

Upgrade

This HTTP/1.1 (only) header can be used to upgrade an already established client/server connection to a different protocol (over the same transport protocol). For example, it can be used by a client to upgrade a connection from HTTP 1.1 to HTTP 2.0, or an HTTP or HTTPS connection into a WebSocket.

Priority

Provides a hint from about the priority of a particular resource request on a particular connection.
The value can be sent in a request to indicate the client priority, or in a response if the server chooses to reprioritize the request.

Experimental headersAttribution reporting headersThe Attribution Reporting API enables developers to measure conversions — for example when a user clicks an ad embedded on one site and then proceeds to purchase the item over on the vendor's site — and then access reports on those conversions. It does this without relying on third-party tracking cookies, instead relying on various headers to register sources and triggers that are matched to indicate a conversion.

Attribution-Reporting-Eligible

Used to indicate that the response corresponding to the current request is eligible to take part in attribution reporting, by registering either an attribution source or trigger.

Attribution-Reporting-Register-Source

Included as part of a response to a request that included an Attribution-Reporting-Eligible header, this is used to register an attribution source.

Attribution-Reporting-Register-Trigger

Included as part of a response to a request that included an Attribution-Reporting-Eligible header, this is used to register an attribution trigger.

Client hintsHTTP Client hints are a set of request headers that provide useful information about the client such as device type and network conditions, and allow servers to optimize what is served for those conditions.
Servers proactively requests the client hint headers they are interested in from the client using Accept-CH. The client may then choose to include the requested headers in subsequent requests.

Accept-CH

Servers can advertise support for Client Hints using the Accept-CH header field or an equivalent HTML <meta> element with http-equiv attribute.

Critical-CH 
Experimental


Servers use Critical-CH along with Accept-CH to specify that accepted client hints are also critical client hints.


The different categories of client hints are listed below.
User agent client hints
The UA client hints are request headers that provide information about the user agent, the platform/architecture it is running on, and user preferences set on the user agent or platform:

Sec-CH-UA 
Experimental


User agent's branding and version.

Sec-CH-UA-Arch 
Experimental


User agent's underlying platform architecture.

Sec-CH-UA-Bitness 
Experimental


User agent's underlying CPU architecture bitness (for example "64" bit).

Sec-CH-UA-Form-Factors 
Experimental


User agent's form-factors, describing how the user interacts with the user-agent.

Sec-CH-UA-Full-Version 
Deprecated


User agent's full version string.

Sec-CH-UA-Full-Version-List 
Experimental


Full version for each brand in the user agent's brand list.

Sec-CH-UA-Mobile 
Experimental


User agent is running on a mobile device or, more generally, prefers a "mobile" user experience.

Sec-CH-UA-Model 
Experimental


User agent's device model.

Sec-CH-UA-Platform 
Experimental


User agent's underlying operation system/platform.

Sec-CH-UA-Platform-Version 
Experimental


User agent's underlying operation system version.

Sec-CH-UA-WoW64 
Experimental


Whether or not the user agent binary is running in 32-bit mode on 64-bit Windows.

Sec-CH-Prefers-Color-Scheme 
Experimental


User's preference of dark or light color scheme.

Sec-CH-Prefers-Reduced-Motion 
Experimental


User's preference to see fewer animations and content layout shifts.

Sec-CH-Prefers-Reduced-Transparency 
Experimental


Request header indicates the user agent's preference for reduced transparency.



Note:
User-agent client hints are not available inside fenced frames because they rely on permissions policy delegation, which could be used to leak data.

Device client hints

Content-DPR 
Deprecated
 
Non-standard


Response header used to confirm the image device to pixel ratio (DPR) in requests where the screen DPR client hint was used to select an image resource.

Device-Memory

Approximate amount of available client RAM memory. This is part of the Device Memory API.

DPR 
Deprecated
 
Non-standard


Request header that provides the client device pixel ratio (the number of physical device pixels for each CSS pixel).

Viewport-Width 
Deprecated
 
Non-standard


Request header provides the client's layout viewport width in CSS pixels.

Width 
Deprecated
 
Non-standard


Request header indicates the desired resource width in physical pixels (the intrinsic size of an image).


Network client hints
Network client hints allow a server to choose what information is sent based on the user choice and network bandwidth and latency.

Downlink 
Experimental


Approximate bandwidth of the client's connection to the server, in Mbps. This is part of the Network Information API.

ECT 
Experimental


The effective connection type ("network profile") that best matches the connection's latency and bandwidth. This is part of the Network Information API.

RTT 
Experimental


Application layer round trip time (RTT) in milliseconds, which includes the server processing time. This is part of the Network Information API.

Save-Data 
Experimental


A string on that indicates the user agent's preference for reduced data usage.

Compression Dictionary TransportCompression Dictionary Transport is a way of using a shared compression dictionary to reduce the transport size of HTTP responses rather than using the standard static dictionary in Brotli compression or Zstandard compression.

Available-Dictionary 
Experimental


A browser can use this request header to indicate the best dictionary it has available for the server to use for compression.

Dictionary-ID 
Experimental


Used when a browser already has a dictionary available for a resource and the server provided an id for the dictionary in the Use-As-Dictionary header.
Requests for resources that can use the dictionary have an Available-Dictionary header and the server-provided dictionary id in the Dictionary-ID header.

Use-As-Dictionary 
Experimental


Lists the matching criteria that the dictionary can be used for in future requests.

Privacy
DNT 
Deprecated
 
Non-standard


Request header that indicates the user's tracking preference (Do Not Track).
Deprecated in favor of Global Privacy Control (GPC), which is communicated to servers using the Sec-GPC header, and accessible to clients via navigator.globalPrivacyControl.

Tk 
Deprecated
 
Non-standard


Response header that indicates the tracking status that applied to the corresponding request. Used in conjunction with DNT.

Sec-GPC 
Non-standard
 
Experimental


Indicates whether the user consents to a website or service selling or sharing their personal information with third parties.

Security
Origin-Agent-Cluster 
Experimental


Response header used to indicate that the associated Document should be placed in an origin-keyed agent cluster.
This isolation allows user agents to allocate implementation-specific resources for agent clusters, such as processes or threads, more efficiently.

Server-sent events
NEL 
Experimental


Defines a mechanism that enables developers to declare a network error reporting policy.

Topics APIThe Topics API provides a mechanism for developers to implement use cases such as interest-based advertising (IBA).
See the Topics API documentation for more information.

Observe-Browsing-Topics 
Experimental
 
Non-standard


Response header used to mark topics of interest inferred from a calling site's URL as observed in the response to a request generated by a feature that enables the Topics API.

Sec-Browsing-Topics 
Experimental
 
Non-standard


Request header that sends the selected topics for the current user along with the associated request, which are used by an ad tech platform to choose a personalized ad to display.

Other
Accept-Signature 
Experimental


A client can send the Accept-Signature header field to indicate intention to take advantage of any available signatures and to indicate what kinds of signatures it supports.

Early-Data 
Experimental


Indicates that the request has been conveyed in TLS early data.

Set-Login 
Experimental


Response header sent by a federated identity provider (IdP) to set its login status, meaning whether any users are logged into the IdP on the current browser or not.
This is stored by the browser and used by the FedCM API.

Signature 
Experimental


The Signature header field conveys a list of signatures for an exchange, each one accompanied by information about how to determine the authority of and refresh that signature.

Signed-Headers 
Experimental


The Signed-Headers header field identifies an ordered list of response header fields to include in a signature.

Speculation-Rules 
Experimental


Provides a list of URLs pointing to text resources containing speculation rule JSON definitions. When the response is an HTML document, these rules will be added to the document's speculation rule set.

Supports-Loading-Mode 
Experimental


Set by a navigation target to opt-in to using various higher-risk loading modes. For example, cross-origin, same-site prerendering requires a Supports-Loading-Mode value of credentialed-prerender.

Non-standard headers
X-Forwarded-For 
Non-standard


Identifies the originating IP addresses of a client connecting to a web server through an HTTP proxy or a load balancer.

X-Forwarded-Host 
Non-standard


Identifies the original host requested that a client used to connect to your proxy or load balancer.

X-Forwarded-Proto 
Non-standard


Identifies the protocol (HTTP or HTTPS) that a client used to connect to your proxy or load balancer.

X-DNS-Prefetch-Control 
Non-standard


Controls DNS prefetching, a feature by which browsers proactively perform domain name resolution on both links that the user may choose to follow as well as URLs for items referenced by the document, including images, CSS, JavaScript, and so forth.

X-Robots-Tag 
Non-standard


The X-Robots-Tag HTTP header is used to indicate how a web page is to be indexed within public search engine results. The header is effectively equivalent to <meta name="robots" content="…">.

Deprecated headers
Pragma 
Deprecated


Implementation-specific header that may have various effects anywhere along the request-response chain. Used for backwards compatibility with HTTP/1.0 caches where the Cache-Control header is not yet present.

Warning 
Deprecated


General warning information about possible problems.

See also
Wikipedia page on List of HTTP headers
IANA registry
HTTP Working Group
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Apr 10, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nHTTP headersHTTP headers let the client and the server pass additional information with a message in a request or response.
In HTTP/1.X, a header is a case-insensitive name followed by a colon, then optional whitespace which will be ignored, and finally by its value (for example: Allow: POST).
In HTTP/2 and above, headers are displayed in lowercase when viewed in developer tools (accept: */*), and prefixed with a colon for a special group of pseudo-headers (:status: 200).
You can find more information on the syntax in each protocol version in the HTTP messages page.
Custom proprietary headers have historically been used with an X- prefix, but this convention was deprecated in 2012 because of the inconveniences it caused when nonstandard fields became standard in RFC 6648; others are listed in the IANA HTTP Field Name Registry, whose original content was defined in RFC 4229.
The IANA registry lists headers, including information about their status.
Headers can be grouped according to their contexts:

Request headers

Contain more information about the resource to be fetched, or about the client requesting the resource.

Response headers

Hold additional information about the response, like its location or about the server providing it.

Representation headers

Contain information about the body of the resource, like its MIME type, or encoding/compression applied.

Payload headers

Contain representation-independent information about payload data, including content length and the encoding used for transport.


Headers can also be grouped according to how proxies handle them:

End-to-end headers

These headers must be transmitted to the final recipient of the message: the server for a request, or the client for a response. Intermediate proxies must retransmit these headers unmodified and caches must store them.

Hop-by-hop headers

These headers are meaningful only for a single transport-level connection, and must not be retransmitted by proxies or cached. Note that only hop-by-hop headers may be set using the Connection header.

Authentication
WWW-Authenticate

Defines the authentication method that should be used to access a resource.

Authorization

Contains the credentials to authenticate a user-agent with a server.

Proxy-Authenticate

Defines the authentication method that should be used to access a resource behind a proxy server.

Proxy-Authorization

Contains the credentials to authenticate a user agent with a proxy server.

Caching
Age

The time, in seconds, that the object has been in a proxy cache.

Cache-Control

Directives for caching mechanisms in both requests and responses.

Clear-Site-Data

Clears browsing data (e.g., cookies, storage, cache) associated with the requesting website.

Expires

The date/time after which the response is considered stale.

No-Vary-Search 
Experimental


Specifies a set of rules that define how a URL's query parameters will affect cache matching. These rules dictate whether the same URL with different URL parameters should be saved as separate browser cache entries.

Conditionals
Last-Modified

The last modification date of the resource, used to compare several versions of the same resource. It is less accurate than ETag, but easier to calculate in some environments. Conditional requests using If-Modified-Since and If-Unmodified-Since use this value to change the behavior of the request.

ETag

A unique string identifying the version of the resource. Conditional requests using If-Match and If-None-Match use this value to change the behavior of the request.

If-Match

Makes the request conditional, and applies the method only if the stored resource matches one of the given ETags.

If-None-Match

Makes the request conditional, and applies the method only if the stored resource doesn't match any of the given ETags. This is used to update caches (for safe requests), or to prevent uploading a new resource when one already exists.

If-Modified-Since

Makes the request conditional, and expects the resource to be transmitted only if it has been modified after the given date. This is used to transmit data only when the cache is out of date.

If-Unmodified-Since

Makes the request conditional, and expects the resource to be transmitted only if it has not been modified after the given date. This ensures the coherence of a new fragment of a specific range with previous ones, or to implement an optimistic concurrency control system when modifying existing documents.

Vary

Determines how to match request headers to decide whether a cached response can be used rather than requesting a fresh one from the origin server.

Connection management
Connection

Controls whether the network connection stays open after the current transaction finishes.

Keep-Alive

Controls how long a persistent connection should stay open.

Content negotiationFor more details, refer to the Content negotiation article.

Accept

Informs the server about the types of data that can be sent back.

Accept-Encoding

The encoding algorithm, usually a compression algorithm, that can be used on the resource sent back.

Accept-Language

Informs the server about the human language the server is expected to send back. This is a hint and is not necessarily under the full control of the user: the server should always pay attention not to override an explicit user choice (like selecting a language from a dropdown).

Accept-Patch

A request content negotiation response header that advertises which media type the server is able to understand in a PATCH request.

Accept-Post

A request content negotiation response header that advertises which media type the server is able to understand in a POST request.

Controls
Expect

Indicates expectations that need to be fulfilled by the server to properly handle the request.

Max-Forwards

When using TRACE, indicates the maximum number of hops the request can do before being reflected to the sender.

Cookies
Cookie

Contains stored HTTP cookies previously sent by the server with the Set-Cookie header.

Set-Cookie

Send cookies from the server to the user-agent.

CORSFor more information, refer to the CORS documentation.

Access-Control-Allow-Credentials

Indicates whether the response to the request can be exposed when the credentials flag is true.

Access-Control-Allow-Headers

Used in response to a preflight request to indicate which HTTP headers can be used when making the actual request.

Access-Control-Allow-Methods

Specifies the methods allowed when accessing the resource in response to a preflight request.

Access-Control-Allow-Origin

Indicates whether the response can be shared.

Access-Control-Expose-Headers

Indicates which headers can be exposed as part of the response by listing their names.

Access-Control-Max-Age

Indicates how long the results of a preflight request can be cached.

Access-Control-Request-Headers

Used when issuing a preflight request to let the server know which HTTP headers will be used when the actual request is made.

Access-Control-Request-Method

Used when issuing a preflight request to let the server know which HTTP method will be used when the actual request is made.

Origin

Indicates where a fetch originates from.

Timing-Allow-Origin

Specifies origins that are allowed to see values of attributes retrieved via features of the Resource Timing API, which would otherwise be reported as zero due to cross-origin restrictions.

Downloads
Content-Disposition

Indicates if the resource transmitted should be displayed inline (default behavior without the header), or if it should be handled like a download and the browser should present a "Save As" dialog.

Integrity digests
Content-Digest 
Experimental


Provides a digest of the stream of octets framed in an HTTP message (the message content) dependent on Content-Encoding and Content-Range.

Repr-Digest 
Experimental


Provides a digest of the selected representation of the target resource before transmission.
Unlike the Content-Digest, the digest does not consider Content-Encoding or Content-Range.

Want-Content-Digest 
Experimental


States the wish for a Content-Digest header.
It is the Content- analogue of Want-Repr-Digest.

Want-Repr-Digest 
Experimental


States the wish for a Repr-Digest header.
It is the Repr- analogue of Want-Content-Digest.

Message body information
Content-Length

The size of the resource, in decimal number of bytes.

Content-Type

Indicates the media type of the resource.

Content-Encoding

Used to specify the compression algorithm.

Content-Language

Describes the human language(s) intended for the audience, so that it allows a user to differentiate according to the users' own preferred language.

Content-Location

Indicates an alternate location for the returned data.

PreferencesPreferences can be sent by clients in requests to indicate optional behaviors for requests and responses.
The server response may indicate if a preference is applied, in cases where it would otherwise be ambiguous for the client.
Browsers have no native handling for sending preferences via these headers; they are used in custom, implementation-specific clients.

Prefer

Indicates preferences for specific server behaviors during request processing. For example, it can request minimal response content (return=minimal) or asynchronous processing (respond-async). The server processes the request normally if the header is unsupported.

Preference-Applied

Informs the client which preferences specified in the Prefer header were applied by the server. It is a response-only header providing transparency about preference handling.

Proxies
Forwarded

Contains information from the client-facing side of proxy servers that is altered or lost when a proxy is involved in the path of the request.

Via

Added by proxies, both forward and reverse proxies, and can appear in the request headers and the response headers.

Range requestsHTTP range requests allow the client to request a portion of a resource from the server.
Range requests are useful for applications like media players that support random access, data tools that know they need only part of a large file, and download managers that let the user pause and resume a download.

Accept-Ranges

Indicates if the server supports range requests, and if so in which unit the range can be expressed.

Range

Indicates the part of a document that the server should return.

If-Range

Creates a conditional range request that is only fulfilled if the given etag or date matches the remote resource. Used to prevent downloading two ranges from incompatible version of the resource.

Content-Range

Indicates where in a full body message a partial message belongs.

Redirects
Location

Indicates the URL to redirect a page to.

Refresh

Directs the browser to reload the page or redirect to another. Takes the same value as the meta element with http-equiv="refresh".

Request context
From

Contains an Internet email address for a human user who controls the requesting user agent.

Host

Specifies the domain name of the server (for virtual hosting), and (optionally) the TCP port number on which the server is listening.

Referer

The address of the previous web page from which a link to the currently requested page was followed.

Referrer-Policy

Governs which referrer information sent in the Referer header should be included with requests made.

User-Agent

Contains a characteristic string that allows the network protocol peers to identify the application type, operating system, software vendor or software version of the requesting software user agent.

Response context
Allow

Lists the set of HTTP request methods supported by a resource.

Server

Contains information about the software used by the origin server to handle the request.

Security
Cross-Origin-Embedder-Policy (COEP)

Allows a server to declare an embedder policy for a given document.

Cross-Origin-Opener-Policy (COOP)

Prevents other domains from opening/controlling a window.

Cross-Origin-Resource-Policy (CORP)

Prevents other domains from reading the response of the resources to which this header is applied. See also CORP explainer article.

Content-Security-Policy (CSP)

Controls resources the user agent is allowed to load for a given page.

Content-Security-Policy-Report-Only

Allows web developers to experiment with policies by monitoring, but not enforcing, their effects. These violation reports consist of JSON documents sent via an HTTP POST request to the specified URI.

Expect-CT 
Deprecated


Lets sites opt in to reporting and enforcement of Certificate Transparency to detect use of misissued certificates for that site.

Permissions-Policy

Provides a mechanism to allow and deny the use of browser features in a website's own frame, and in <iframe>s that it embeds.

Reporting-Endpoints 
Experimental


Response header that allows website owners to specify one or more endpoints used to receive errors such as CSP violation reports, Cross-Origin-Opener-Policy reports, or other generic violations.

Strict-Transport-Security (HSTS)

Force communication using HTTPS instead of HTTP.

Upgrade-Insecure-Requests

Sends a signal to the server expressing the client's preference for an encrypted and authenticated response, and that it can successfully handle the upgrade-insecure-requests directive.

X-Content-Type-Options

Disables MIME sniffing and forces browser to use the type given in Content-Type.

X-Frame-Options (XFO)

Indicates whether a browser should be allowed to render a page in a <frame>, <iframe>, <embed> or <object>.

X-Permitted-Cross-Domain-Policies

A cross-domain policy file may grant clients, such as Adobe Acrobat or Apache Flex (among others), permission to handle data across domains that would otherwise be restricted due to the Same-Origin Policy.
The X-Permitted-Cross-Domain-Policies header overrides such policy files so that clients still block unwanted requests.

X-Powered-By

May be set by hosting environments or other frameworks and contains information about them while not providing any usefulness to the application or its visitors. Unset this header to avoid exposing potential vulnerabilities.

X-XSS-Protection

Enables cross-site scripting filtering.

Fetch metadata request headersFetch metadata request headers provide information about the context from which the request originated. A server can use them to make decisions about whether a request should be allowed, based on where the request came from and how the resource will be used.

Sec-Fetch-Site

Indicates the relationship between a request initiator's origin and its target's origin. It is a Structured Header whose value is a token with possible values cross-site, same-origin, same-site, and none.

Sec-Fetch-Mode

Indicates the request's mode to a server. It is a Structured Header whose value is a token with possible values cors, navigate, no-cors, same-origin, and websocket.

Sec-Fetch-User

Indicates whether or not a navigation request was triggered by user activation. It is a Structured Header whose value is a boolean so possible values are ?0 for false and ?1 for true.

Sec-Fetch-Dest

Indicates the request's destination. It is a Structured Header whose value is a token with possible values audio, audioworklet, document, embed, empty, font, image, manifest, object, paintworklet, report, script, serviceworker, sharedworker, style, track, video, worker, and xslt.


The following request headers are not strictly "fetch metadata request headers", but similarly provide information about the context of how a resource will be used. A server might use them to modify its caching behavior, or the information that is returned:

Sec-Purpose

Indicates the purpose of the request, when the purpose is something other than immediate use by the user-agent. The header currently has one possible value, prefetch, which indicates that the resource is being fetched preemptively for a possible future navigation.

Service-Worker-Navigation-Preload

A request header sent in preemptive request to fetch() a resource during service worker boot. The value, which is set with NavigationPreloadManager.setHeaderValue(), can be used to inform a server that a different resource should be returned than in a normal fetch() operation.

Server-sent events
Reporting-Endpoints

Response header used to specify server endpoints where the browser should send warning and error reports when using the Reporting API.

Report-To 
Deprecated
 
Non-standard


Response header used to specify server endpoints where the browser should send warning and error reports when using the Reporting API.

Transfer coding
Transfer-Encoding

Specifies the form of encoding used to safely transfer the resource to the user.

TE

Specifies the transfer encodings the user agent is willing to accept.

Trailer

Allows the sender to include additional fields at the end of chunked message.

WebSocketsHeaders used by the WebSockets API in the WebSocket handshake:

Sec-WebSocket-Accept

Response header that indicates that the server is willing to upgrade to a WebSocket connection.

Sec-WebSocket-Extensions

In requests, this header indicates the WebSocket extensions supported by the client in preferred order.
In responses, it indicates the extension selected by the server from the client's preferences.

Sec-WebSocket-Key

Request header containing a key that verifies that the client explicitly intends to open a WebSocket.

Sec-WebSocket-Protocol

In requests, this header indicates the sub-protocols supported by the client in preferred order.
In responses, it indicates the sub-protocol selected by the server from the client's preferences.

Sec-WebSocket-Version

In requests, this header indicates the version of the WebSocket protocol used by the client.
In responses, it is sent only if the requested protocol version is not supported by the server, and lists the versions that the server supports.

Other
Alt-Svc

Used to list alternate ways to reach this service.

Alt-Used

Used to identify the alternative service in use.

Date

Contains the date and time at which the message was originated.

Link

This entity-header field provides a means for serializing one or more links in HTTP headers. It is semantically equivalent to the HTML <link> element.

Retry-After

Indicates how long the user agent should wait before making a follow-up request.

Server-Timing

Communicates one or more metrics and descriptions for the given request-response cycle.

Service-Worker

Included in fetches for a service worker's script resource.
This header helps administrators log service worker script requests for monitoring purposes.

Service-Worker-Allowed

Used to remove the path restriction by including this header in the response of the Service Worker script.

SourceMap

Links to a source map so that debuggers can step through original source code instead of generated or transformed code.

Upgrade

This HTTP/1.1 (only) header can be used to upgrade an already established client/server connection to a different protocol (over the same transport protocol). For example, it can be used by a client to upgrade a connection from HTTP 1.1 to HTTP 2.0, or an HTTP or HTTPS connection into a WebSocket.

Priority

Provides a hint from about the priority of a particular resource request on a particular connection.
The value can be sent in a request to indicate the client priority, or in a response if the server chooses to reprioritize the request.

Experimental headersAttribution reporting headersThe Attribution Reporting API enables developers to measure conversions — for example when a user clicks an ad embedded on one site and then proceeds to purchase the item over on the vendor's site — and then access reports on those conversions. It does this without relying on third-party tracking cookies, instead relying on various headers to register sources and triggers that are matched to indicate a conversion.

Attribution-Reporting-Eligible

Used to indicate that the response corresponding to the current request is eligible to take part in attribution reporting, by registering either an attribution source or trigger.

Attribution-Reporting-Register-Source

Included as part of a response to a request that included an Attribution-Reporting-Eligible header, this is used to register an attribution source.

Attribution-Reporting-Register-Trigger

Included as part of a response to a request that included an Attribution-Reporting-Eligible header, this is used to register an attribution trigger.

Client hintsHTTP Client hints are a set of request headers that provide useful information about the client such as device type and network conditions, and allow servers to optimize what is served for those conditions.
Servers proactively requests the client hint headers they are interested in from the client using Accept-CH. The client may then choose to include the requested headers in subsequent requests.

Accept-CH

Servers can advertise support for Client Hints using the Accept-CH header field or an equivalent HTML <meta> element with http-equiv attribute.

Critical-CH 
Experimental


Servers use Critical-CH along with Accept-CH to specify that accepted client hints are also critical client hints.


The different categories of client hints are listed below.
User agent client hints
The UA client hints are request headers that provide information about the user agent, the platform/architecture it is running on, and user preferences set on the user agent or platform:

Sec-CH-UA 
Experimental


User agent's branding and version.

Sec-CH-UA-Arch 
Experimental


User agent's underlying platform architecture.

Sec-CH-UA-Bitness 
Experimental


User agent's underlying CPU architecture bitness (for example "64" bit).

Sec-CH-UA-Form-Factors 
Experimental


User agent's form-factors, describing how the user interacts with the user-agent.

Sec-CH-UA-Full-Version 
Deprecated


User agent's full version string.

Sec-CH-UA-Full-Version-List 
Experimental


Full version for each brand in the user agent's brand list.

Sec-CH-UA-Mobile 
Experimental


User agent is running on a mobile device or, more generally, prefers a "mobile" user experience.

Sec-CH-UA-Model 
Experimental


User agent's device model.

Sec-CH-UA-Platform 
Experimental


User agent's underlying operation system/platform.

Sec-CH-UA-Platform-Version 
Experimental


User agent's underlying operation system version.

Sec-CH-UA-WoW64 
Experimental


Whether or not the user agent binary is running in 32-bit mode on 64-bit Windows.

Sec-CH-Prefers-Color-Scheme 
Experimental


User's preference of dark or light color scheme.

Sec-CH-Prefers-Reduced-Motion 
Experimental


User's preference to see fewer animations and content layout shifts.

Sec-CH-Prefers-Reduced-Transparency 
Experimental


Request header indicates the user agent's preference for reduced transparency.



Note:
User-agent client hints are not available inside fenced frames because they rely on permissions policy delegation, which could be used to leak data.

Device client hints

Content-DPR 
Deprecated
 
Non-standard


Response header used to confirm the image device to pixel ratio (DPR) in requests where the screen DPR client hint was used to select an image resource.

Device-Memory

Approximate amount of available client RAM memory. This is part of the Device Memory API.

DPR 
Deprecated
 
Non-standard


Request header that provides the client device pixel ratio (the number of physical device pixels for each CSS pixel).

Viewport-Width 
Deprecated
 
Non-standard


Request header provides the client's layout viewport width in CSS pixels.

Width 
Deprecated
 
Non-standard


Request header indicates the desired resource width in physical pixels (the intrinsic size of an image).


Network client hints
Network client hints allow a server to choose what information is sent based on the user choice and network bandwidth and latency.

Downlink 
Experimental


Approximate bandwidth of the client's connection to the server, in Mbps. This is part of the Network Information API.

ECT 
Experimental


The effective connection type ("network profile") that best matches the connection's latency and bandwidth. This is part of the Network Information API.

RTT 
Experimental


Application layer round trip time (RTT) in milliseconds, which includes the server processing time. This is part of the Network Information API.

Save-Data 
Experimental


A string on that indicates the user agent's preference for reduced data usage.

Compression Dictionary TransportCompression Dictionary Transport is a way of using a shared compression dictionary to reduce the transport size of HTTP responses rather than using the standard static dictionary in Brotli compression or Zstandard compression.

Available-Dictionary 
Experimental


A browser can use this request header to indicate the best dictionary it has available for the server to use for compression.

Dictionary-ID 
Experimental


Used when a browser already has a dictionary available for a resource and the server provided an id for the dictionary in the Use-As-Dictionary header.
Requests for resources that can use the dictionary have an Available-Dictionary header and the server-provided dictionary id in the Dictionary-ID header.

Use-As-Dictionary 
Experimental


Lists the matching criteria that the dictionary can be used for in future requests.

Privacy
DNT 
Deprecated
 
Non-standard


Request header that indicates the user's tracking preference (Do Not Track).
Deprecated in favor of Global Privacy Control (GPC), which is communicated to servers using the Sec-GPC header, and accessible to clients via navigator.globalPrivacyControl.

Tk 
Deprecated
 
Non-standard


Response header that indicates the tracking status that applied to the corresponding request. Used in conjunction with DNT.

Sec-GPC 
Non-standard
 
Experimental


Indicates whether the user consents to a website or service selling or sharing their personal information with third parties.

Security
Origin-Agent-Cluster 
Experimental


Response header used to indicate that the associated Document should be placed in an origin-keyed agent cluster.
This isolation allows user agents to allocate implementation-specific resources for agent clusters, such as processes or threads, more efficiently.

Server-sent events
NEL 
Experimental


Defines a mechanism that enables developers to declare a network error reporting policy.

Topics APIThe Topics API provides a mechanism for developers to implement use cases such as interest-based advertising (IBA).
See the Topics API documentation for more information.

Observe-Browsing-Topics 
Experimental
 
Non-standard


Response header used to mark topics of interest inferred from a calling site's URL as observed in the response to a request generated by a feature that enables the Topics API.

Sec-Browsing-Topics 
Experimental
 
Non-standard


Request header that sends the selected topics for the current user along with the associated request, which are used by an ad tech platform to choose a personalized ad to display.

Other
Accept-Signature 
Experimental


A client can send the Accept-Signature header field to indicate intention to take advantage of any available signatures and to indicate what kinds of signatures it supports.

Early-Data 
Experimental


Indicates that the request has been conveyed in TLS early data.

Set-Login 
Experimental


Response header sent by a federated identity provider (IdP) to set its login status, meaning whether any users are logged into the IdP on the current browser or not.
This is stored by the browser and used by the FedCM API.

Signature 
Experimental


The Signature header field conveys a list of signatures for an exchange, each one accompanied by information about how to determine the authority of and refresh that signature.

Signed-Headers 
Experimental


The Signed-Headers header field identifies an ordered list of response header fields to include in a signature.

Speculation-Rules 
Experimental


Provides a list of URLs pointing to text resources containing speculation rule JSON definitions. When the response is an HTML document, these rules will be added to the document's speculation rule set.

Supports-Loading-Mode 
Experimental


Set by a navigation target to opt-in to using various higher-risk loading modes. For example, cross-origin, same-site prerendering requires a Supports-Loading-Mode value of credentialed-prerender.

Non-standard headers
X-Forwarded-For 
Non-standard


Identifies the originating IP addresses of a client connecting to a web server through an HTTP proxy or a load balancer.

X-Forwarded-Host 
Non-standard


Identifies the original host requested that a client used to connect to your proxy or load balancer.

X-Forwarded-Proto 
Non-standard


Identifies the protocol (HTTP or HTTPS) that a client used to connect to your proxy or load balancer.

X-DNS-Prefetch-Control 
Non-standard


Controls DNS prefetching, a feature by which browsers proactively perform domain name resolution on both links that the user may choose to follow as well as URLs for items referenced by the document, including images, CSS, JavaScript, and so forth.

X-Robots-Tag 
Non-standard


The X-Robots-Tag HTTP header is used to indicate how a web page is to be indexed within public search engine results. The header is effectively equivalent to <meta name="robots" content="…">.

Deprecated headers
Pragma 
Deprecated


Implementation-specific header that may have various effects anywhere along the request-response chain. Used for backwards compatibility with HTTP/1.0 caches where the Cache-Control header is not yet present.

Warning 
Deprecated


General warning information about possible problems.

See also
Wikipedia page on List of HTTP headers
IANA registry
HTTP Working Group
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Apr 10, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nAcceptBaseline Widely availableThis feature is well established and works across many devices and browser versions. It’s been available across browsers since July 2015.Learn moreSee full compatibilityReport feedbackThe HTTP Accept request and response header indicates which content types, expressed as MIME types, the sender is able to understand.
In requests, the server uses content negotiation to select one of the proposals and informs the client of the choice with the Content-Type response header.
In responses, it provides information about which content types the server can understand in messages to the requested resource, so that the content type can be used in subsequent requests to the resource.
Browsers set required values for this header based on the context of the request.
For example, a browser uses different values in a request when fetching a CSS stylesheet, image, video, or a script.

  
    
      Header type
      Request header,
      Response header
    
    
      Forbidden request header
      No
    
    
      
        CORS-safelisted request header
      
      
        Yes*
      
    
  

* Values can't contain CORS-unsafe request header bytes, including "():<>?@[\]{},, Delete 0x7F, and control characters 0x00 to 0x19, except for Tab 0x09.SyntaxhttpAccept: <media-type>/<MIME_subtype>
Accept: <media-type>/*
Accept: */*

// Multiple types, weighted with the quality value syntax
Accept: text/html, application/xhtml+xml, application/xml;q=0.9, image/webp, */*;q=0.8
Directives
<media-type>/<subtype>

A single, precise media type, like text/html.

<media-type>/*

A media type without a subtype.
For example, image/* corresponds to image/png, image/svg, image/gif, and other image types.

*/*

Any media type.

;q= (q-factor weighting)

A value in order of preference expressed using a relative quality value called the weight.

ExamplesUsing default Accept request headersHTTP requests made using command line tools such as curl and wget use */* as the default Accept value:
httpGET / HTTP/1.1
Host: example.com
User-Agent: curl/8.7.1
Accept: */*

Browser navigation typically has the following Accept request header value:
httpGET /en-US/ HTTP/2
Host: developer.mozilla.org
Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
…

After receiving the document, the default Accept values in requests for images on the developer.mozilla.org example look like this:
httpAccept: image/avif,image/webp,image/png,image/svg+xml,image/*;q=0.8,*/*;q=0.5
Configuring Accept request headers for JSON responsesSystems that involve API interaction commonly request application/json responses.
Here's an example of a GET request where the client specifically requests a JSON response:
httpGET /users/123 HTTP/1.1
Host: example.com
Authorization: Bearer abcd123
Accept: application/json
SpecificationsSpecificationHTTP Semantics # field.acceptBrowser compatibilitySee also
HTTP content negotiation
List of default Accept values
CORS safelist request header restrictions
A header with the result of the content negotiation: Content-Type
Other similar headers: TE, Accept-Encoding, Accept-Language\n\nAcceptBaseline Widely availableThis feature is well established and works across many devices and browser versions. It’s been available across browsers since July 2015.Learn moreSee full compatibilityReport feedbackThe HTTP Accept request and response header indicates which content types, expressed as MIME types, the sender is able to understand.
In requests, the server uses content negotiation to select one of the proposals and informs the client of the choice with the Content-Type response header.
In responses, it provides information about which content types the server can understand in messages to the requested resource, so that the content type can be used in subsequent requests to the resource.
Browsers set required values for this header based on the context of the request.
For example, a browser uses different values in a request when fetching a CSS stylesheet, image, video, or a script.

  
    
      Header type
      Request header,
      Response header
    
    
      Forbidden request header
      No
    
    
      
        CORS-safelisted request header
      
      
        Yes*
      
    
  

* Values can't contain CORS-unsafe request header bytes, including "():<>?@[\]{},, Delete 0x7F, and control characters 0x00 to 0x19, except for Tab 0x09.SyntaxhttpAccept: <media-type>/<MIME_subtype>
Accept: <media-type>/*
Accept: */*

// Multiple types, weighted with the quality value syntax
Accept: text/html, application/xhtml+xml, application/xml;q=0.9, image/webp, */*;q=0.8
Directives
<media-type>/<subtype>

A single, precise media type, like text/html.

<media-type>/*

A media type without a subtype.
For example, image/* corresponds to image/png, image/svg, image/gif, and other image types.

*/*

Any media type.

;q= (q-factor weighting)

A value in order of preference expressed using a relative quality value called the weight.

ExamplesUsing default Accept request headersHTTP requests made using command line tools such as curl and wget use */* as the default Accept value:
httpGET / HTTP/1.1
Host: example.com
User-Agent: curl/8.7.1
Accept: */*

Browser navigation typically has the following Accept request header value:
httpGET /en-US/ HTTP/2
Host: developer.mozilla.org
Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
…

After receiving the document, the default Accept values in requests for images on the developer.mozilla.org example look like this:
httpAccept: image/avif,image/webp,image/png,image/svg+xml,image/*;q=0.8,*/*;q=0.5
Configuring Accept request headers for JSON responsesSystems that involve API interaction commonly request application/json responses.
Here's an example of a GET request where the client specifically requests a JSON response:
httpGET /users/123 HTTP/1.1
Host: example.com
Authorization: Bearer abcd123
Accept: application/json
SpecificationsSpecificationHTTP Semantics # field.acceptBrowser compatibilitySee also
HTTP content negotiation
List of default Accept values
CORS safelist request header restrictions
A header with the result of the content negotiation: Content-Type
Other similar headers: TE, Accept-Encoding, Accept-Language
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nAcceptBaseline Widely availableThis feature is well established and works across many devices and browser versions. It’s been available across browsers since July 2015.Learn moreSee full compatibilityReport feedbackThe HTTP Accept request and response header indicates which content types, expressed as MIME types, the sender is able to understand.
In requests, the server uses content negotiation to select one of the proposals and informs the client of the choice with the Content-Type response header.
In responses, it provides information about which content types the server can understand in messages to the requested resource, so that the content type can be used in subsequent requests to the resource.
Browsers set required values for this header based on the context of the request.
For example, a browser uses different values in a request when fetching a CSS stylesheet, image, video, or a script.

  
    
      Header type
      Request header,
      Response header
    
    
      Forbidden request header
      No
    
    
      
        CORS-safelisted request header
      
      
        Yes*
      
    
  

* Values can't contain CORS-unsafe request header bytes, including "():<>?@[\]{},, Delete 0x7F, and control characters 0x00 to 0x19, except for Tab 0x09.SyntaxhttpAccept: <media-type>/<MIME_subtype>
Accept: <media-type>/*
Accept: */*

// Multiple types, weighted with the quality value syntax
Accept: text/html, application/xhtml+xml, application/xml;q=0.9, image/webp, */*;q=0.8
Directives
<media-type>/<subtype>

A single, precise media type, like text/html.

<media-type>/*

A media type without a subtype.
For example, image/* corresponds to image/png, image/svg, image/gif, and other image types.

*/*

Any media type.

;q= (q-factor weighting)

A value in order of preference expressed using a relative quality value called the weight.

ExamplesUsing default Accept request headersHTTP requests made using command line tools such as curl and wget use */* as the default Accept value:
httpGET / HTTP/1.1
Host: example.com
User-Agent: curl/8.7.1
Accept: */*

Browser navigation typically has the following Accept request header value:
httpGET /en-US/ HTTP/2
Host: developer.mozilla.org
Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
…

After receiving the document, the default Accept values in requests for images on the developer.mozilla.org example look like this:
httpAccept: image/avif,image/webp,image/png,image/svg+xml,image/*;q=0.8,*/*;q=0.5
Configuring Accept request headers for JSON responsesSystems that involve API interaction commonly request application/json responses.
Here's an example of a GET request where the client specifically requests a JSON response:
httpGET /users/123 HTTP/1.1
Host: example.com
Authorization: Bearer abcd123
Accept: application/json
SpecificationsSpecificationHTTP Semantics # field.acceptBrowser compatibilitySee also
HTTP content negotiation
List of default Accept values
CORS safelist request header restrictions
A header with the result of the content negotiation: Content-Type
Other similar headers: TE, Accept-Encoding, Accept-Language
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nAccept-CHSecure context: This feature is available only in secure contexts (HTTPS), in some or all supporting browsers.
The HTTP Accept-CH response header may be set by a server to specify which client hint headers should be included by the client in subsequent requests.
To ensure client hints are sent reliably, the Accept-CH header should be persisted for all secure requests.

  
    
      Header type
      Response header
    
    
      Forbidden request header
      No
    
    
      
        CORS-safelisted response header
      
      No
    
  
SyntaxhttpAccept-CH: <client-hints-headers>

// Client hint headers in a comma-separated list
Accept-CH: <ch-header-one>, <ch-header-two>
ExamplesClient hint response headersThe following response headers indicate that the server accepts Viewport-Width and Width device client hints in subsequent requests.
The Vary header indicates which values were used to vary the response based on the accepted client hints.
httpAccept-CH: Viewport-Width, Width
Vary: Viewport-Width, Width
SpecificationsSpecificationHTTP Client Hints # section-3.1Browser compatibilitySee also
Vary\n\nAccept-CHSecure context: This feature is available only in secure contexts (HTTPS), in some or all supporting browsers.
The HTTP Accept-CH response header may be set by a server to specify which client hint headers should be included by the client in subsequent requests.
To ensure client hints are sent reliably, the Accept-CH header should be persisted for all secure requests.

  
    
      Header type
      Response header
    
    
      Forbidden request header
      No
    
    
      
        CORS-safelisted response header
      
      No
    
  
SyntaxhttpAccept-CH: <client-hints-headers>

// Client hint headers in a comma-separated list
Accept-CH: <ch-header-one>, <ch-header-two>
ExamplesClient hint response headersThe following response headers indicate that the server accepts Viewport-Width and Width device client hints in subsequent requests.
The Vary header indicates which values were used to vary the response based on the accepted client hints.
httpAccept-CH: Viewport-Width, Width
Vary: Viewport-Width, Width
SpecificationsSpecificationHTTP Client Hints # section-3.1Browser compatibilitySee also
Vary
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nAccept-CHSecure context: This feature is available only in secure contexts (HTTPS), in some or all supporting browsers.
The HTTP Accept-CH response header may be set by a server to specify which client hint headers should be included by the client in subsequent requests.
To ensure client hints are sent reliably, the Accept-CH header should be persisted for all secure requests.

  
    
      Header type
      Response header
    
    
      Forbidden request header
      No
    
    
      
        CORS-safelisted response header
      
      No
    
  
SyntaxhttpAccept-CH: <client-hints-headers>

// Client hint headers in a comma-separated list
Accept-CH: <ch-header-one>, <ch-header-two>
ExamplesClient hint response headersThe following response headers indicate that the server accepts Viewport-Width and Width device client hints in subsequent requests.
The Vary header indicates which values were used to vary the response based on the accepted client hints.
httpAccept-CH: Viewport-Width, Width
Vary: Viewport-Width, Width
SpecificationsSpecificationHTTP Client Hints # section-3.1Browser compatibilitySee also
Vary
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nAccept-EncodingBaseline Widely available *This feature is well established and works across many devices and browser versions. It’s been available across browsers since July 2015.* Some parts of this feature may have varying levels of support.Learn moreSee full compatibilityReport feedbackThe HTTP Accept-Encoding request and response header indicates the content encoding (usually a compression algorithm) that the sender can understand.
In requests, the server uses content negotiation to select one of the encoding proposals from the client and informs the client of that choice with the Content-Encoding response header.
In responses, it provides information about which content encodings the server can understand in messages to the requested resource, so that the encoding can be used in subsequent requests to the resource.
For example, Accept-Encoding is included in a 415 Unsupported Media Type response if a request to a resource (e.g., PUT) used an unsupported encoding.
Even if both the client and the server support the same compression algorithms, the server may choose not to compress the body of a response if the identity value is also acceptable.
This happens in two common cases:

The data is already compressed, meaning a second round of compression will not reduce the transmitted data size, and may actually increase the size of the content in some cases.
This is true for pre-compressed image formats (JPEG, for instance).
The server is overloaded and cannot allocate computing resources to perform the compression. For example, Microsoft recommends not to compress if a server uses more than 80% of its computational power.

As long as the identity;q=0 or *;q=0 directives do not explicitly forbid the identity value that means no encoding, the server must never return a 406 Not Acceptable error.

Note:
IANA maintains a list of official content encodings.
The bzip and bzip2 encodings are non-standard, but may be used in some cases, particularly for legacy support.


  
    
      Header type
      Request header, Response header
    
    
      Forbidden request header
      Yes
    
  
SyntaxhttpAccept-Encoding: gzip
Accept-Encoding: compress
Accept-Encoding: deflate
Accept-Encoding: br
Accept-Encoding: zstd
Accept-Encoding: dcb
Accept-Encoding: dcz
Accept-Encoding: identity
Accept-Encoding: *

// Multiple algorithms, weighted with the quality value syntax:
Accept-Encoding: deflate, gzip;q=1.0, *;q=0.5
Directives
gzip

A compression format that uses the Lempel-Ziv coding (LZ77) with a 32-bit CRC.

compress

A compression format that uses the Lempel-Ziv-Welch (LZW) algorithm.

deflate

A compression format that uses the zlib structure with the deflate compression algorithm.

br

A compression format that uses the Brotli algorithm.

zstd

A compression format that uses the Zstandard algorithm.

dcb 
Experimental


A format that uses the Dictionary-Compressed Brotli algorithm. See Compression Dictionary Transport.

dcz 
Experimental


A format that uses the Dictionary-Compressed Zstandard algorithm. See Compression Dictionary Transport.

identity

Indicates the identity function (that is, without modification or compression). This value is always considered as acceptable, even if omitted.

* (wildcard)

Matches any content encoding not already listed in the header. This is the default value if the header is not present. This directive does not suggest that any algorithm is supported but indicates that no preference is expressed.

;q= (qvalues weighting)

Any value is placed in an order of preference expressed using a relative quality value called weight.

ExamplesDefault Accept-Encoding valuesBrowser navigation typically has the following Accept-Encoding request header value:
httpGET /en-US/ HTTP/2
Host: developer.mozilla.org
Accept-Encoding: gzip, deflate, br, zstd
Weighted Accept-Encoding valuesThe following header shows Accept-Encoding preferences using a quality value between 0 (lowest priority) and 1 (highest-priority).
Brotli compression is weighted at 1.0, making br the client's first choice, followed by gzip at 0.8 priority, and then any other content encoding at 0.1:
httpAccept-Encoding: br;q=1.0, gzip;q=0.8, *;q=0.1
SpecificationsSpecificationHTTP Semantics # field.accept-encodingBrowser compatibilitySee also
415 Unsupported Media Type
HTTP content negotiation
A header with the result of the content negotiation: Content-Encoding
Other similar headers: TE, Accept, Accept-Language
Brotli compression
GZip compression
Zstandard compression
Compression Dictionary Transport guide\n\nAccept-EncodingBaseline Widely available *This feature is well established and works across many devices and browser versions. It’s been available across browsers since July 2015.* Some parts of this feature may have varying levels of support.Learn moreSee full compatibilityReport feedbackThe HTTP Accept-Encoding request and response header indicates the content encoding (usually a compression algorithm) that the sender can understand.
In requests, the server uses content negotiation to select one of the encoding proposals from the client and informs the client of that choice with the Content-Encoding response header.
In responses, it provides information about which content encodings the server can understand in messages to the requested resource, so that the encoding can be used in subsequent requests to the resource.
For example, Accept-Encoding is included in a 415 Unsupported Media Type response if a request to a resource (e.g., PUT) used an unsupported encoding.
Even if both the client and the server support the same compression algorithms, the server may choose not to compress the body of a response if the identity value is also acceptable.
This happens in two common cases:

The data is already compressed, meaning a second round of compression will not reduce the transmitted data size, and may actually increase the size of the content in some cases.
This is true for pre-compressed image formats (JPEG, for instance).
The server is overloaded and cannot allocate computing resources to perform the compression. For example, Microsoft recommends not to compress if a server uses more than 80% of its computational power.

As long as the identity;q=0 or *;q=0 directives do not explicitly forbid the identity value that means no encoding, the server must never return a 406 Not Acceptable error.

Note:
IANA maintains a list of official content encodings.
The bzip and bzip2 encodings are non-standard, but may be used in some cases, particularly for legacy support.


  
    
      Header type
      Request header, Response header
    
    
      Forbidden request header
      Yes
    
  
SyntaxhttpAccept-Encoding: gzip
Accept-Encoding: compress
Accept-Encoding: deflate
Accept-Encoding: br
Accept-Encoding: zstd
Accept-Encoding: dcb
Accept-Encoding: dcz
Accept-Encoding: identity
Accept-Encoding: *

// Multiple algorithms, weighted with the quality value syntax:
Accept-Encoding: deflate, gzip;q=1.0, *;q=0.5
Directives
gzip

A compression format that uses the Lempel-Ziv coding (LZ77) with a 32-bit CRC.

compress

A compression format that uses the Lempel-Ziv-Welch (LZW) algorithm.

deflate

A compression format that uses the zlib structure with the deflate compression algorithm.

br

A compression format that uses the Brotli algorithm.

zstd

A compression format that uses the Zstandard algorithm.

dcb 
Experimental


A format that uses the Dictionary-Compressed Brotli algorithm. See Compression Dictionary Transport.

dcz 
Experimental


A format that uses the Dictionary-Compressed Zstandard algorithm. See Compression Dictionary Transport.

identity

Indicates the identity function (that is, without modification or compression). This value is always considered as acceptable, even if omitted.

* (wildcard)

Matches any content encoding not already listed in the header. This is the default value if the header is not present. This directive does not suggest that any algorithm is supported but indicates that no preference is expressed.

;q= (qvalues weighting)

Any value is placed in an order of preference expressed using a relative quality value called weight.

ExamplesDefault Accept-Encoding valuesBrowser navigation typically has the following Accept-Encoding request header value:
httpGET /en-US/ HTTP/2
Host: developer.mozilla.org
Accept-Encoding: gzip, deflate, br, zstd
Weighted Accept-Encoding valuesThe following header shows Accept-Encoding preferences using a quality value between 0 (lowest priority) and 1 (highest-priority).
Brotli compression is weighted at 1.0, making br the client's first choice, followed by gzip at 0.8 priority, and then any other content encoding at 0.1:
httpAccept-Encoding: br;q=1.0, gzip;q=0.8, *;q=0.1
SpecificationsSpecificationHTTP Semantics # field.accept-encodingBrowser compatibilitySee also
415 Unsupported Media Type
HTTP content negotiation
A header with the result of the content negotiation: Content-Encoding
Other similar headers: TE, Accept, Accept-Language
Brotli compression
GZip compression
Zstandard compression
Compression Dictionary Transport guide
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Apr 3, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nAccept-EncodingBaseline Widely available *This feature is well established and works across many devices and browser versions. It’s been available across browsers since July 2015.* Some parts of this feature may have varying levels of support.Learn moreSee full compatibilityReport feedbackThe HTTP Accept-Encoding request and response header indicates the content encoding (usually a compression algorithm) that the sender can understand.
In requests, the server uses content negotiation to select one of the encoding proposals from the client and informs the client of that choice with the Content-Encoding response header.
In responses, it provides information about which content encodings the server can understand in messages to the requested resource, so that the encoding can be used in subsequent requests to the resource.
For example, Accept-Encoding is included in a 415 Unsupported Media Type response if a request to a resource (e.g., PUT) used an unsupported encoding.
Even if both the client and the server support the same compression algorithms, the server may choose not to compress the body of a response if the identity value is also acceptable.
This happens in two common cases:

The data is already compressed, meaning a second round of compression will not reduce the transmitted data size, and may actually increase the size of the content in some cases.
This is true for pre-compressed image formats (JPEG, for instance).
The server is overloaded and cannot allocate computing resources to perform the compression. For example, Microsoft recommends not to compress if a server uses more than 80% of its computational power.

As long as the identity;q=0 or *;q=0 directives do not explicitly forbid the identity value that means no encoding, the server must never return a 406 Not Acceptable error.

Note:
IANA maintains a list of official content encodings.
The bzip and bzip2 encodings are non-standard, but may be used in some cases, particularly for legacy support.


  
    
      Header type
      Request header, Response header
    
    
      Forbidden request header
      Yes
    
  
SyntaxhttpAccept-Encoding: gzip
Accept-Encoding: compress
Accept-Encoding: deflate
Accept-Encoding: br
Accept-Encoding: zstd
Accept-Encoding: dcb
Accept-Encoding: dcz
Accept-Encoding: identity
Accept-Encoding: *

// Multiple algorithms, weighted with the quality value syntax:
Accept-Encoding: deflate, gzip;q=1.0, *;q=0.5
Directives
gzip

A compression format that uses the Lempel-Ziv coding (LZ77) with a 32-bit CRC.

compress

A compression format that uses the Lempel-Ziv-Welch (LZW) algorithm.

deflate

A compression format that uses the zlib structure with the deflate compression algorithm.

br

A compression format that uses the Brotli algorithm.

zstd

A compression format that uses the Zstandard algorithm.

dcb 
Experimental


A format that uses the Dictionary-Compressed Brotli algorithm. See Compression Dictionary Transport.

dcz 
Experimental


A format that uses the Dictionary-Compressed Zstandard algorithm. See Compression Dictionary Transport.

identity

Indicates the identity function (that is, without modification or compression). This value is always considered as acceptable, even if omitted.

* (wildcard)

Matches any content encoding not already listed in the header. This is the default value if the header is not present. This directive does not suggest that any algorithm is supported but indicates that no preference is expressed.

;q= (qvalues weighting)

Any value is placed in an order of preference expressed using a relative quality value called weight.

ExamplesDefault Accept-Encoding valuesBrowser navigation typically has the following Accept-Encoding request header value:
httpGET /en-US/ HTTP/2
Host: developer.mozilla.org
Accept-Encoding: gzip, deflate, br, zstd
Weighted Accept-Encoding valuesThe following header shows Accept-Encoding preferences using a quality value between 0 (lowest priority) and 1 (highest-priority).
Brotli compression is weighted at 1.0, making br the client's first choice, followed by gzip at 0.8 priority, and then any other content encoding at 0.1:
httpAccept-Encoding: br;q=1.0, gzip;q=0.8, *;q=0.1
SpecificationsSpecificationHTTP Semantics # field.accept-encodingBrowser compatibilitySee also
415 Unsupported Media Type
HTTP content negotiation
A header with the result of the content negotiation: Content-Encoding
Other similar headers: TE, Accept, Accept-Language
Brotli compression
GZip compression
Zstandard compression
Compression Dictionary Transport guide
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Apr 3, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nAccept-LanguageBaseline Widely availableThis feature is well established and works across many devices and browser versions. It’s been available across browsers since July 2015.Learn moreSee full compatibilityReport feedbackThe HTTP Accept-Language request header indicates the natural language and locale that the client prefers.
The server uses content negotiation to select one of the proposals and informs the client of the choice with the Content-Language response header.
Browsers set required values for this header according to their active user interface language.
Users can also configure additional preferred languages through browser settings.
The Accept-Language header generally lists the same locales as the navigator.languages property, with decreasing q values (quality values). Some browsers, like Chrome and Safari, add language-only fallback tags in Accept-Language. For example, en-US,en;q=0.9,zh-CN;q=0.8,zh;q=0.7 when navigator.languages is ["en-US", "zh-CN"]. For privacy purposes (reducing fingerprinting), both Accept-Language and navigator.languages may not include the full list of user preferences. For example, in Safari (always) and Chrome's incognito mode, only one language is listed.
This header serves as a hint when the server cannot determine the target content language otherwise (for example, use a specific URL that depends on an explicit user decision).
The server should never override an explicit user language choice. The content of Accept-Language is often out of a user's control (when traveling, for instance).
A user may also want to visit a page in a language different from the user interface language.
The server may send back a 406 Not Acceptable error code when unable to serve content in a matching language, but this is rarely implemented.
Servers often ignore the Accept-Language header in such cases and send a successful response with the most appropriate resource instead for a better user experience.

  
    
      Header type
      Request header
    
    
      Forbidden request header
      No
    
    
      
        CORS-safelisted request header
      
      
        Yes*
      
    
  

* Values can only be 0-9, A-Z, a-z, space, or the characters *,-.;=.SyntaxhttpAccept-Language: <language>
Accept-Language: *

// Multiple types, weighted with the quality value syntax:
Accept-Language: fr-CH, fr;q=0.9, en;q=0.8, de;q=0.7, *;q=0.5
Directives
<language>

A language tag (which is sometimes referred to as a "locale identifier").
This consists of a 2-3 letter base language tag that indicates a language, optionally followed by additional subtags separated by -.
The most common extra information is the country or region variant (like en-US or fr-CA) or the type of alphabet to use (like sr-Latn).
Other variants, like the type of orthography (de-DE-1996), are usually not used in the context of this header.

* (wildcard)

Any language not matched by any other language present in the Accept-Language field.

;q= (q-factor weighting)

Any value placed in an order of preference expressed using a relative quality value called weight.
The quality value defaults to 1.

ExamplesUsing Accept-Language headersThe following request has a preference for German using the de base language:
httpAccept-Language: de
Using quality values in Accept-LanguageThe following request indicates a stronger preference for Danish, but accepts British English and other types of English at a lower priority:
httpAccept-Language: da, en-gb;q=0.8, en;q=0.7
SpecificationsSpecificationHTTP Semantics # field.accept-languageBrowser compatibilitySee also
HTTP content negotiation
A header with the result of the content negotiation: Content-Language
Other similar headers: TE, Accept-Encoding, Accept\n\nAccept-LanguageBaseline Widely availableThis feature is well established and works across many devices and browser versions. It’s been available across browsers since July 2015.Learn moreSee full compatibilityReport feedbackThe HTTP Accept-Language request header indicates the natural language and locale that the client prefers.
The server uses content negotiation to select one of the proposals and informs the client of the choice with the Content-Language response header.
Browsers set required values for this header according to their active user interface language.
Users can also configure additional preferred languages through browser settings.
The Accept-Language header generally lists the same locales as the navigator.languages property, with decreasing q values (quality values). Some browsers, like Chrome and Safari, add language-only fallback tags in Accept-Language. For example, en-US,en;q=0.9,zh-CN;q=0.8,zh;q=0.7 when navigator.languages is ["en-US", "zh-CN"]. For privacy purposes (reducing fingerprinting), both Accept-Language and navigator.languages may not include the full list of user preferences. For example, in Safari (always) and Chrome's incognito mode, only one language is listed.
This header serves as a hint when the server cannot determine the target content language otherwise (for example, use a specific URL that depends on an explicit user decision).
The server should never override an explicit user language choice. The content of Accept-Language is often out of a user's control (when traveling, for instance).
A user may also want to visit a page in a language different from the user interface language.
The server may send back a 406 Not Acceptable error code when unable to serve content in a matching language, but this is rarely implemented.
Servers often ignore the Accept-Language header in such cases and send a successful response with the most appropriate resource instead for a better user experience.

  
    
      Header type
      Request header
    
    
      Forbidden request header
      No
    
    
      
        CORS-safelisted request header
      
      
        Yes*
      
    
  

* Values can only be 0-9, A-Z, a-z, space, or the characters *,-.;=.SyntaxhttpAccept-Language: <language>
Accept-Language: *

// Multiple types, weighted with the quality value syntax:
Accept-Language: fr-CH, fr;q=0.9, en;q=0.8, de;q=0.7, *;q=0.5
Directives
<language>

A language tag (which is sometimes referred to as a "locale identifier").
This consists of a 2-3 letter base language tag that indicates a language, optionally followed by additional subtags separated by -.
The most common extra information is the country or region variant (like en-US or fr-CA) or the type of alphabet to use (like sr-Latn).
Other variants, like the type of orthography (de-DE-1996), are usually not used in the context of this header.

* (wildcard)

Any language not matched by any other language present in the Accept-Language field.

;q= (q-factor weighting)

Any value placed in an order of preference expressed using a relative quality value called weight.
The quality value defaults to 1.

ExamplesUsing Accept-Language headersThe following request has a preference for German using the de base language:
httpAccept-Language: de
Using quality values in Accept-LanguageThe following request indicates a stronger preference for Danish, but accepts British English and other types of English at a lower priority:
httpAccept-Language: da, en-gb;q=0.8, en;q=0.7
SpecificationsSpecificationHTTP Semantics # field.accept-languageBrowser compatibilitySee also
HTTP content negotiation
A header with the result of the content negotiation: Content-Language
Other similar headers: TE, Accept-Encoding, Accept
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nAccept-LanguageBaseline Widely availableThis feature is well established and works across many devices and browser versions. It’s been available across browsers since July 2015.Learn moreSee full compatibilityReport feedbackThe HTTP Accept-Language request header indicates the natural language and locale that the client prefers.
The server uses content negotiation to select one of the proposals and informs the client of the choice with the Content-Language response header.
Browsers set required values for this header according to their active user interface language.
Users can also configure additional preferred languages through browser settings.
The Accept-Language header generally lists the same locales as the navigator.languages property, with decreasing q values (quality values). Some browsers, like Chrome and Safari, add language-only fallback tags in Accept-Language. For example, en-US,en;q=0.9,zh-CN;q=0.8,zh;q=0.7 when navigator.languages is ["en-US", "zh-CN"]. For privacy purposes (reducing fingerprinting), both Accept-Language and navigator.languages may not include the full list of user preferences. For example, in Safari (always) and Chrome's incognito mode, only one language is listed.
This header serves as a hint when the server cannot determine the target content language otherwise (for example, use a specific URL that depends on an explicit user decision).
The server should never override an explicit user language choice. The content of Accept-Language is often out of a user's control (when traveling, for instance).
A user may also want to visit a page in a language different from the user interface language.
The server may send back a 406 Not Acceptable error code when unable to serve content in a matching language, but this is rarely implemented.
Servers often ignore the Accept-Language header in such cases and send a successful response with the most appropriate resource instead for a better user experience.

  
    
      Header type
      Request header
    
    
      Forbidden request header
      No
    
    
      
        CORS-safelisted request header
      
      
        Yes*
      
    
  

* Values can only be 0-9, A-Z, a-z, space, or the characters *,-.;=.SyntaxhttpAccept-Language: <language>
Accept-Language: *

// Multiple types, weighted with the quality value syntax:
Accept-Language: fr-CH, fr;q=0.9, en;q=0.8, de;q=0.7, *;q=0.5
Directives
<language>

A language tag (which is sometimes referred to as a "locale identifier").
This consists of a 2-3 letter base language tag that indicates a language, optionally followed by additional subtags separated by -.
The most common extra information is the country or region variant (like en-US or fr-CA) or the type of alphabet to use (like sr-Latn).
Other variants, like the type of orthography (de-DE-1996), are usually not used in the context of this header.

* (wildcard)

Any language not matched by any other language present in the Accept-Language field.

;q= (q-factor weighting)

Any value placed in an order of preference expressed using a relative quality value called weight.
The quality value defaults to 1.

ExamplesUsing Accept-Language headersThe following request has a preference for German using the de base language:
httpAccept-Language: de
Using quality values in Accept-LanguageThe following request indicates a stronger preference for Danish, but accepts British English and other types of English at a lower priority:
httpAccept-Language: da, en-gb;q=0.8, en;q=0.7
SpecificationsSpecificationHTTP Semantics # field.accept-languageBrowser compatibilitySee also
HTTP content negotiation
A header with the result of the content negotiation: Content-Language
Other similar headers: TE, Accept-Encoding, Accept
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nAccept-PatchThe HTTP Accept-Patch response header advertises which media types the server is able to understand in a PATCH request.
For example, a server receiving a PATCH request with an unsupported media type could reply with 415 Unsupported Media Type and an Accept-Patch header referencing one or more supported media types.
The header should appear in OPTIONS requests to a resource that supports the PATCH method.
An Accept-Patch header in a response to any request method implicitly means that a PATCH is allowed on the target resource in the request.

Note:
IANA maintains a list of official content encodings.
The bzip and bzip2 encodings are non-standard but may be used in some cases, particularly for legacy support.


  
    
      Header type
      Response header
    
    
      Forbidden request header
      Yes
    
  
SyntaxhttpAccept-Patch: <media-type>/<subtype>
Accept-Patch: <media-type>/*
Accept-Patch: */*

// Comma-separated list of media types
Accept-Patch: <media-type>/<subtype>, <media-type>/<subtype>
Directives
<media-type>/<subtype>

A single, precise media type, like text/html.

<media-type>/*

A media type without a subtype.
For example, image/* corresponds to image/png, image/svg, image/gif, and other image types.

*/*

Any media type.

ExampleshttpAccept-Patch: application/json
Accept-Patch: application/json, text/plain
Accept-Patch: text/plain;charset=utf-8
SpecificationsSpecificationRFC 5789 # section-3.1Browser compatibilityBrowser compatibility is not relevant for this header.
The server sends the header, and the specification doesn't define client behavior.See also
Accept-Post
415 Unsupported Media Type
PATCH request method\n\nAccept-PatchThe HTTP Accept-Patch response header advertises which media types the server is able to understand in a PATCH request.
For example, a server receiving a PATCH request with an unsupported media type could reply with 415 Unsupported Media Type and an Accept-Patch header referencing one or more supported media types.
The header should appear in OPTIONS requests to a resource that supports the PATCH method.
An Accept-Patch header in a response to any request method implicitly means that a PATCH is allowed on the target resource in the request.

Note:
IANA maintains a list of official content encodings.
The bzip and bzip2 encodings are non-standard but may be used in some cases, particularly for legacy support.


  
    
      Header type
      Response header
    
    
      Forbidden request header
      Yes
    
  
SyntaxhttpAccept-Patch: <media-type>/<subtype>
Accept-Patch: <media-type>/*
Accept-Patch: */*

// Comma-separated list of media types
Accept-Patch: <media-type>/<subtype>, <media-type>/<subtype>
Directives
<media-type>/<subtype>

A single, precise media type, like text/html.

<media-type>/*

A media type without a subtype.
For example, image/* corresponds to image/png, image/svg, image/gif, and other image types.

*/*

Any media type.

ExampleshttpAccept-Patch: application/json
Accept-Patch: application/json, text/plain
Accept-Patch: text/plain;charset=utf-8
SpecificationsSpecificationRFC 5789 # section-3.1Browser compatibilityBrowser compatibility is not relevant for this header.
The server sends the header, and the specification doesn't define client behavior.See also
Accept-Post
415 Unsupported Media Type
PATCH request method
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nAccept-PatchThe HTTP Accept-Patch response header advertises which media types the server is able to understand in a PATCH request.
For example, a server receiving a PATCH request with an unsupported media type could reply with 415 Unsupported Media Type and an Accept-Patch header referencing one or more supported media types.
The header should appear in OPTIONS requests to a resource that supports the PATCH method.
An Accept-Patch header in a response to any request method implicitly means that a PATCH is allowed on the target resource in the request.

Note:
IANA maintains a list of official content encodings.
The bzip and bzip2 encodings are non-standard but may be used in some cases, particularly for legacy support.


  
    
      Header type
      Response header
    
    
      Forbidden request header
      Yes
    
  
SyntaxhttpAccept-Patch: <media-type>/<subtype>
Accept-Patch: <media-type>/*
Accept-Patch: */*

// Comma-separated list of media types
Accept-Patch: <media-type>/<subtype>, <media-type>/<subtype>
Directives
<media-type>/<subtype>

A single, precise media type, like text/html.

<media-type>/*

A media type without a subtype.
For example, image/* corresponds to image/png, image/svg, image/gif, and other image types.

*/*

Any media type.

ExampleshttpAccept-Patch: application/json
Accept-Patch: application/json, text/plain
Accept-Patch: text/plain;charset=utf-8
SpecificationsSpecificationRFC 5789 # section-3.1Browser compatibilityBrowser compatibility is not relevant for this header.
The server sends the header, and the specification doesn't define client behavior.See also
Accept-Post
415 Unsupported Media Type
PATCH request method
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nAccept-PostThe HTTP Accept-Post response header advertises which media types are accepted by the server in a POST request.
For example, a server receiving a POST request with an unsupported media type could reply with 415 Unsupported Media Type and an Accept-Post header referencing one or more supported media types.
The header should appear in OPTIONS requests to a resource that supports the POST method.
An Accept-Post header in a response to any request method implicitly means that a POST is allowed on the target resource in the request.

Note:
IANA maintains a list of official content encodings.
The bzip and bzip2 encodings are non-standard but may be used in some cases, particularly for legacy support.


  
    
      Header type
      Response header
    
    
      Forbidden request header
      Yes
    
  
SyntaxhttpAccept-Post: <media-type>/<subtype>
Accept-Post: <media-type>/*
Accept-Post: */*

// Comma-separated list of media types
Accept-Post: <media-type>/<subtype>, <media-type>/<subtype>


Note:
The Accept-Post header specifies a media range in the same way as Accept, except that it has no notion of preference via q (quality values) arguments.
This is because Accept-Post is a response header while Accept is a request header.
Directives
<media-type>/<subtype>

A single, precise media type, like text/html.

<media-type>/*

A media type without a subtype.
For example, image/* corresponds to image/png, image/svg, image/gif, and other image types.

*/*

Any media type.

ExampleshttpAccept-Post: application/json, text/plain
Accept-Post: image/webp
Accept-Post: */*
SpecificationsSpecificationLinked Data Platform # header-accept-postBrowser compatibilityBrowser compatibility is not relevant for this header.
The header is sent by the server and the specification does not define client behavior.See also
Accept-Patch
POST request method\n\nAccept-PostThe HTTP Accept-Post response header advertises which media types are accepted by the server in a POST request.
For example, a server receiving a POST request with an unsupported media type could reply with 415 Unsupported Media Type and an Accept-Post header referencing one or more supported media types.
The header should appear in OPTIONS requests to a resource that supports the POST method.
An Accept-Post header in a response to any request method implicitly means that a POST is allowed on the target resource in the request.

Note:
IANA maintains a list of official content encodings.
The bzip and bzip2 encodings are non-standard but may be used in some cases, particularly for legacy support.


  
    
      Header type
      Response header
    
    
      Forbidden request header
      Yes
    
  
SyntaxhttpAccept-Post: <media-type>/<subtype>
Accept-Post: <media-type>/*
Accept-Post: */*

// Comma-separated list of media types
Accept-Post: <media-type>/<subtype>, <media-type>/<subtype>


Note:
The Accept-Post header specifies a media range in the same way as Accept, except that it has no notion of preference via q (quality values) arguments.
This is because Accept-Post is a response header while Accept is a request header.
Directives
<media-type>/<subtype>

A single, precise media type, like text/html.

<media-type>/*

A media type without a subtype.
For example, image/* corresponds to image/png, image/svg, image/gif, and other image types.

*/*

Any media type.

ExampleshttpAccept-Post: application/json, text/plain
Accept-Post: image/webp
Accept-Post: */*
SpecificationsSpecificationLinked Data Platform # header-accept-postBrowser compatibilityBrowser compatibility is not relevant for this header.
The header is sent by the server and the specification does not define client behavior.See also
Accept-Patch
POST request method
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nAccept-PostThe HTTP Accept-Post response header advertises which media types are accepted by the server in a POST request.
For example, a server receiving a POST request with an unsupported media type could reply with 415 Unsupported Media Type and an Accept-Post header referencing one or more supported media types.
The header should appear in OPTIONS requests to a resource that supports the POST method.
An Accept-Post header in a response to any request method implicitly means that a POST is allowed on the target resource in the request.

Note:
IANA maintains a list of official content encodings.
The bzip and bzip2 encodings are non-standard but may be used in some cases, particularly for legacy support.


  
    
      Header type
      Response header
    
    
      Forbidden request header
      Yes
    
  
SyntaxhttpAccept-Post: <media-type>/<subtype>
Accept-Post: <media-type>/*
Accept-Post: */*

// Comma-separated list of media types
Accept-Post: <media-type>/<subtype>, <media-type>/<subtype>


Note:
The Accept-Post header specifies a media range in the same way as Accept, except that it has no notion of preference via q (quality values) arguments.
This is because Accept-Post is a response header while Accept is a request header.
Directives
<media-type>/<subtype>

A single, precise media type, like text/html.

<media-type>/*

A media type without a subtype.
For example, image/* corresponds to image/png, image/svg, image/gif, and other image types.

*/*

Any media type.

ExampleshttpAccept-Post: application/json, text/plain
Accept-Post: image/webp
Accept-Post: */*
SpecificationsSpecificationLinked Data Platform # header-accept-postBrowser compatibilityBrowser compatibility is not relevant for this header.
The header is sent by the server and the specification does not define client behavior.See also
Accept-Patch
POST request method
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nAccept-RangesBaseline Widely availableThis feature is well established and works across many devices and browser versions. It’s been available across browsers since July 2015.Learn moreSee full compatibilityReport feedbackThe HTTP Accept-Ranges response header is used by the server to advertise its support for range requests, allowing clients to request part or several parts of a resource.
The value of this header indicates the unit that can be used to define a range.
For example, a response with an Accept-Ranges header indicates that the server is capable of resuming an interrupted download instead of a client restarting the transfer in full.

  
    
      Header type
      Response header
    
    
      Forbidden request header
      No
    
  
SyntaxhttpAccept-Ranges: <range-unit>
Accept-Ranges: none
Directives
<range-unit>

The range unit that the server supports, although bytes is the only range unit formally defined by RFC 7233.
Range units are registered in the HTTP Range Unit Registry.

none

No range unit is supported.
This is equivalent to omitting the header and is, therefore, rarely used.
This value was used in legacy browsers to disable or remove the pause buttons in the download manager if servers had no support for range requests.

ExampleshttpAccept-Ranges: bytes
SpecificationsSpecificationHTTP Semantics # field.accept-rangesBrowser compatibilitySee also
HTTP range requests guide
HTTP conditional requests guide
Range, If-Range request headers
IANA HTTP Range Unit Registry\n\nAccept-RangesBaseline Widely availableThis feature is well established and works across many devices and browser versions. It’s been available across browsers since July 2015.Learn moreSee full compatibilityReport feedbackThe HTTP Accept-Ranges response header is used by the server to advertise its support for range requests, allowing clients to request part or several parts of a resource.
The value of this header indicates the unit that can be used to define a range.
For example, a response with an Accept-Ranges header indicates that the server is capable of resuming an interrupted download instead of a client restarting the transfer in full.

  
    
      Header type
      Response header
    
    
      Forbidden request header
      No
    
  
SyntaxhttpAccept-Ranges: <range-unit>
Accept-Ranges: none
Directives
<range-unit>

The range unit that the server supports, although bytes is the only range unit formally defined by RFC 7233.
Range units are registered in the HTTP Range Unit Registry.

none

No range unit is supported.
This is equivalent to omitting the header and is, therefore, rarely used.
This value was used in legacy browsers to disable or remove the pause buttons in the download manager if servers had no support for range requests.

ExampleshttpAccept-Ranges: bytes
SpecificationsSpecificationHTTP Semantics # field.accept-rangesBrowser compatibilitySee also
HTTP range requests guide
HTTP conditional requests guide
Range, If-Range request headers
IANA HTTP Range Unit Registry
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nAccept-RangesBaseline Widely availableThis feature is well established and works across many devices and browser versions. It’s been available across browsers since July 2015.Learn moreSee full compatibilityReport feedbackThe HTTP Accept-Ranges response header is used by the server to advertise its support for range requests, allowing clients to request part or several parts of a resource.
The value of this header indicates the unit that can be used to define a range.
For example, a response with an Accept-Ranges header indicates that the server is capable of resuming an interrupted download instead of a client restarting the transfer in full.

  
    
      Header type
      Response header
    
    
      Forbidden request header
      No
    
  
SyntaxhttpAccept-Ranges: <range-unit>
Accept-Ranges: none
Directives
<range-unit>

The range unit that the server supports, although bytes is the only range unit formally defined by RFC 7233.
Range units are registered in the HTTP Range Unit Registry.

none

No range unit is supported.
This is equivalent to omitting the header and is, therefore, rarely used.
This value was used in legacy browsers to disable or remove the pause buttons in the download manager if servers had no support for range requests.

ExampleshttpAccept-Ranges: bytes
SpecificationsSpecificationHTTP Semantics # field.accept-rangesBrowser compatibilitySee also
HTTP range requests guide
HTTP conditional requests guide
Range, If-Range request headers
IANA HTTP Range Unit Registry
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nAccess-Control-Allow-CredentialsBaseline Widely availableThis feature is well established and works across many devices and browser versions. It’s been available across browsers since July 2015.Learn moreSee full compatibilityReport feedbackThe HTTP Access-Control-Allow-Credentials response header tells browsers whether the server allows credentials to be included in cross-origin HTTP requests.
Credentials include cookies, Transport Layer Security (TLS) client certificates, or authentication headers containing a username and password.
By default, these credentials are not sent in cross-origin requests, and doing so can make a site vulnerable to Cross-Site Request Forgery (CSRF) attacks.
A client can ask for credentials to be included in cross-site requests in several ways:

Using fetch(), by setting the credentials option to "include".
Using XMLHttpRequest, by setting the XMLHttpRequest.withCredentials property to true.
Using EventSource(), by setting the EventSource.withCredentials property to true.

When credentials are included:

For preflighted requests: The preflight request does not include credentials.
If the server's response to the preflight request sets the Access-Control-Allow-Credentials header to true, then the real request will include credentials; otherwise, the browser reports a network error.
For non-preflighted requests: The request will include credentials, and if the server's response does not set the Access-Control-Allow-Credentials header to true, the browser reports a network error.


  
    
      Header type
      Response header
    
    
      Forbidden request header
      No
    
  
SyntaxhttpAccess-Control-Allow-Credentials: true
Directives
true

The server allows credentials to be included in cross-origin HTTP requests.
This is the only valid value for this header and is case-sensitive.
If you don't need credentials, omit this header entirely rather than setting its value to false.

ExamplesAllow credentials:
httpAccess-Control-Allow-Credentials: true

Using fetch() with credentials:
jsfetch(url, {
  credentials: "include",
});

Using XMLHttpRequest with credentials:
jsconst xhr = new XMLHttpRequest();
xhr.open("GET", "http://example.com/", true);
xhr.withCredentials = true;
xhr.send(null);
SpecificationsSpecificationFetch # http-access-control-allow-credentialsBrowser compatibilitySee also
XMLHttpRequest.withCredentials
Request()\n\nAccess-Control-Allow-CredentialsBaseline Widely availableThis feature is well established and works across many devices and browser versions. It’s been available across browsers since July 2015.Learn moreSee full compatibilityReport feedbackThe HTTP Access-Control-Allow-Credentials response header tells browsers whether the server allows credentials to be included in cross-origin HTTP requests.
Credentials include cookies, Transport Layer Security (TLS) client certificates, or authentication headers containing a username and password.
By default, these credentials are not sent in cross-origin requests, and doing so can make a site vulnerable to Cross-Site Request Forgery (CSRF) attacks.
A client can ask for credentials to be included in cross-site requests in several ways:

Using fetch(), by setting the credentials option to "include".
Using XMLHttpRequest, by setting the XMLHttpRequest.withCredentials property to true.
Using EventSource(), by setting the EventSource.withCredentials property to true.

When credentials are included:

For preflighted requests: The preflight request does not include credentials.
If the server's response to the preflight request sets the Access-Control-Allow-Credentials header to true, then the real request will include credentials; otherwise, the browser reports a network error.
For non-preflighted requests: The request will include credentials, and if the server's response does not set the Access-Control-Allow-Credentials header to true, the browser reports a network error.


  
    
      Header type
      Response header
    
    
      Forbidden request header
      No
    
  
SyntaxhttpAccess-Control-Allow-Credentials: true
Directives
true

The server allows credentials to be included in cross-origin HTTP requests.
This is the only valid value for this header and is case-sensitive.
If you don't need credentials, omit this header entirely rather than setting its value to false.

ExamplesAllow credentials:
httpAccess-Control-Allow-Credentials: true

Using fetch() with credentials:
jsfetch(url, {
  credentials: "include",
});

Using XMLHttpRequest with credentials:
jsconst xhr = new XMLHttpRequest();
xhr.open("GET", "http://example.com/", true);
xhr.withCredentials = true;
xhr.send(null);
SpecificationsSpecificationFetch # http-access-control-allow-credentialsBrowser compatibilitySee also
XMLHttpRequest.withCredentials
Request()
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nAccess-Control-Allow-CredentialsBaseline Widely availableThis feature is well established and works across many devices and browser versions. It’s been available across browsers since July 2015.Learn moreSee full compatibilityReport feedbackThe HTTP Access-Control-Allow-Credentials response header tells browsers whether the server allows credentials to be included in cross-origin HTTP requests.
Credentials include cookies, Transport Layer Security (TLS) client certificates, or authentication headers containing a username and password.
By default, these credentials are not sent in cross-origin requests, and doing so can make a site vulnerable to Cross-Site Request Forgery (CSRF) attacks.
A client can ask for credentials to be included in cross-site requests in several ways:

Using fetch(), by setting the credentials option to "include".
Using XMLHttpRequest, by setting the XMLHttpRequest.withCredentials property to true.
Using EventSource(), by setting the EventSource.withCredentials property to true.

When credentials are included:

For preflighted requests: The preflight request does not include credentials.
If the server's response to the preflight request sets the Access-Control-Allow-Credentials header to true, then the real request will include credentials; otherwise, the browser reports a network error.
For non-preflighted requests: The request will include credentials, and if the server's response does not set the Access-Control-Allow-Credentials header to true, the browser reports a network error.


  
    
      Header type
      Response header
    
    
      Forbidden request header
      No
    
  
SyntaxhttpAccess-Control-Allow-Credentials: true
Directives
true

The server allows credentials to be included in cross-origin HTTP requests.
This is the only valid value for this header and is case-sensitive.
If you don't need credentials, omit this header entirely rather than setting its value to false.

ExamplesAllow credentials:
httpAccess-Control-Allow-Credentials: true

Using fetch() with credentials:
jsfetch(url, {
  credentials: "include",
});

Using XMLHttpRequest with credentials:
jsconst xhr = new XMLHttpRequest();
xhr.open("GET", "http://example.com/", true);
xhr.withCredentials = true;
xhr.send(null);
SpecificationsSpecificationFetch # http-access-control-allow-credentialsBrowser compatibilitySee also
XMLHttpRequest.withCredentials
Request()
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nAccess-Control-Allow-HeadersBaseline Widely available *This feature is well established and works across many devices and browser versions. It’s been available across browsers since July 2015.* Some parts of this feature may have varying levels of support.Learn moreSee full compatibilityReport feedbackThe HTTP Access-Control-Allow-Headers response header is used in response to a preflight request to indicate the HTTP headers that can be used during the actual request.
This header is required if the preflight request contains Access-Control-Request-Headers.

Note:
The CORS-safelisted request headers are always allowed and usually aren't listed in Access-Control-Allow-Headers unless there is a need to circumvent the additional safelist restrictions.


  
    
      Header type
      Response header
    
    
      Forbidden request header
      No
    
  
SyntaxhttpAccess-Control-Allow-Headers: <header-name>
Access-Control-Allow-Headers: <header-name>, <header-name>
Access-Control-Allow-Headers: *
Directives
<header-name>

The name of a supported request header. The header may list any number of headers, separated by commas.

* (wildcard)

Any header.
The value * only counts as a special wildcard value for requests without credentials (requests without HTTP cookies or HTTP authentication information).
In requests with credentials, it is treated as the literal header name * without special semantics.
The Authorization header can't be wildcarded and always needs to be listed explicitly.

ExamplesImplementing a custom headerBelow is an example of an Access-Control-Allow-Headers header.
It indicates that a custom header named X-Custom-Header is supported by CORS requests to the server, in addition to the CORS-safelisted request headers.
httpAccess-Control-Allow-Headers: X-Custom-Header
Supporting multiple headersThis example shows Access-Control-Allow-Headers when it specifies support for multiple headers.
httpAccess-Control-Allow-Headers: X-Custom-Header, Upgrade-Insecure-Requests
Bypassing additional restrictions on CORS-safelisted headersAlthough CORS-safelisted request headers are always allowed and don't usually need to be listed in Access-Control-Allow-Headers, listing them anyway will circumvent the additional restrictions that apply.
httpAccess-Control-Allow-Headers: Accept
Handling preflight requestsLet's look at an example of a preflight request involving Access-Control-Allow-Headers.
Request
First, the preflight request is an OPTIONS request that includes some combination of the three preflight request headers: Access-Control-Request-Method, Access-Control-Request-Headers, and Origin.
The preflight request below tells the server that we want to send a CORS GET request with the headers listed in Access-Control-Request-Headers (Content-Type and X-Requested-With).
httpOPTIONS /resource/foo
Access-Control-Request-Method: GET
Access-Control-Request-Headers: content-type,x-requested-with
Origin: https://foo.bar.org

Response
If the CORS request indicated by the preflight request is authorized, the server will respond to the preflight request with a message that indicates the allowed origin, methods, and headers. Below, we see that Access-Control-Allow-Headers includes the headers that were requested.
httpHTTP/1.1 200 OK
Content-Length: 0
Connection: keep-alive
Access-Control-Allow-Origin: https://foo.bar.org
Access-Control-Allow-Methods: POST, GET, OPTIONS, DELETE
Access-Control-Allow-Headers: Content-Type, x-requested-with
Access-Control-Max-Age: 86400

If the requested method isn't supported, the server will respond with an error.SpecificationsSpecificationFetch # http-access-control-allow-headersBrowser compatibilitySee also
Access-Control-Allow-Origin
Access-Control-Expose-Headers
Access-Control-Allow-Methods
Access-Control-Request-Headers\n\nAccess-Control-Allow-HeadersBaseline Widely available *This feature is well established and works across many devices and browser versions. It’s been available across browsers since July 2015.* Some parts of this feature may have varying levels of support.Learn moreSee full compatibilityReport feedbackThe HTTP Access-Control-Allow-Headers response header is used in response to a preflight request to indicate the HTTP headers that can be used during the actual request.
This header is required if the preflight request contains Access-Control-Request-Headers.

Note:
The CORS-safelisted request headers are always allowed and usually aren't listed in Access-Control-Allow-Headers unless there is a need to circumvent the additional safelist restrictions.


  
    
      Header type
      Response header
    
    
      Forbidden request header
      No
    
  
SyntaxhttpAccess-Control-Allow-Headers: <header-name>
Access-Control-Allow-Headers: <header-name>, <header-name>
Access-Control-Allow-Headers: *
Directives
<header-name>

The name of a supported request header. The header may list any number of headers, separated by commas.

* (wildcard)

Any header.
The value * only counts as a special wildcard value for requests without credentials (requests without HTTP cookies or HTTP authentication information).
In requests with credentials, it is treated as the literal header name * without special semantics.
The Authorization header can't be wildcarded and always needs to be listed explicitly.

ExamplesImplementing a custom headerBelow is an example of an Access-Control-Allow-Headers header.
It indicates that a custom header named X-Custom-Header is supported by CORS requests to the server, in addition to the CORS-safelisted request headers.
httpAccess-Control-Allow-Headers: X-Custom-Header
Supporting multiple headersThis example shows Access-Control-Allow-Headers when it specifies support for multiple headers.
httpAccess-Control-Allow-Headers: X-Custom-Header, Upgrade-Insecure-Requests
Bypassing additional restrictions on CORS-safelisted headersAlthough CORS-safelisted request headers are always allowed and don't usually need to be listed in Access-Control-Allow-Headers, listing them anyway will circumvent the additional restrictions that apply.
httpAccess-Control-Allow-Headers: Accept
Handling preflight requestsLet's look at an example of a preflight request involving Access-Control-Allow-Headers.
Request
First, the preflight request is an OPTIONS request that includes some combination of the three preflight request headers: Access-Control-Request-Method, Access-Control-Request-Headers, and Origin.
The preflight request below tells the server that we want to send a CORS GET request with the headers listed in Access-Control-Request-Headers (Content-Type and X-Requested-With).
httpOPTIONS /resource/foo
Access-Control-Request-Method: GET
Access-Control-Request-Headers: content-type,x-requested-with
Origin: https://foo.bar.org

Response
If the CORS request indicated by the preflight request is authorized, the server will respond to the preflight request with a message that indicates the allowed origin, methods, and headers. Below, we see that Access-Control-Allow-Headers includes the headers that were requested.
httpHTTP/1.1 200 OK
Content-Length: 0
Connection: keep-alive
Access-Control-Allow-Origin: https://foo.bar.org
Access-Control-Allow-Methods: POST, GET, OPTIONS, DELETE
Access-Control-Allow-Headers: Content-Type, x-requested-with
Access-Control-Max-Age: 86400

If the requested method isn't supported, the server will respond with an error.SpecificationsSpecificationFetch # http-access-control-allow-headersBrowser compatibilitySee also
Access-Control-Allow-Origin
Access-Control-Expose-Headers
Access-Control-Allow-Methods
Access-Control-Request-Headers
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nAccess-Control-Allow-HeadersBaseline Widely available *This feature is well established and works across many devices and browser versions. It’s been available across browsers since July 2015.* Some parts of this feature may have varying levels of support.Learn moreSee full compatibilityReport feedbackThe HTTP Access-Control-Allow-Headers response header is used in response to a preflight request to indicate the HTTP headers that can be used during the actual request.
This header is required if the preflight request contains Access-Control-Request-Headers.

Note:
The CORS-safelisted request headers are always allowed and usually aren't listed in Access-Control-Allow-Headers unless there is a need to circumvent the additional safelist restrictions.


  
    
      Header type
      Response header
    
    
      Forbidden request header
      No
    
  
SyntaxhttpAccess-Control-Allow-Headers: <header-name>
Access-Control-Allow-Headers: <header-name>, <header-name>
Access-Control-Allow-Headers: *
Directives
<header-name>

The name of a supported request header. The header may list any number of headers, separated by commas.

* (wildcard)

Any header.
The value * only counts as a special wildcard value for requests without credentials (requests without HTTP cookies or HTTP authentication information).
In requests with credentials, it is treated as the literal header name * without special semantics.
The Authorization header can't be wildcarded and always needs to be listed explicitly.

ExamplesImplementing a custom headerBelow is an example of an Access-Control-Allow-Headers header.
It indicates that a custom header named X-Custom-Header is supported by CORS requests to the server, in addition to the CORS-safelisted request headers.
httpAccess-Control-Allow-Headers: X-Custom-Header
Supporting multiple headersThis example shows Access-Control-Allow-Headers when it specifies support for multiple headers.
httpAccess-Control-Allow-Headers: X-Custom-Header, Upgrade-Insecure-Requests
Bypassing additional restrictions on CORS-safelisted headersAlthough CORS-safelisted request headers are always allowed and don't usually need to be listed in Access-Control-Allow-Headers, listing them anyway will circumvent the additional restrictions that apply.
httpAccess-Control-Allow-Headers: Accept
Handling preflight requestsLet's look at an example of a preflight request involving Access-Control-Allow-Headers.
Request
First, the preflight request is an OPTIONS request that includes some combination of the three preflight request headers: Access-Control-Request-Method, Access-Control-Request-Headers, and Origin.
The preflight request below tells the server that we want to send a CORS GET request with the headers listed in Access-Control-Request-Headers (Content-Type and X-Requested-With).
httpOPTIONS /resource/foo
Access-Control-Request-Method: GET
Access-Control-Request-Headers: content-type,x-requested-with
Origin: https://foo.bar.org

Response
If the CORS request indicated by the preflight request is authorized, the server will respond to the preflight request with a message that indicates the allowed origin, methods, and headers. Below, we see that Access-Control-Allow-Headers includes the headers that were requested.
httpHTTP/1.1 200 OK
Content-Length: 0
Connection: keep-alive
Access-Control-Allow-Origin: https://foo.bar.org
Access-Control-Allow-Methods: POST, GET, OPTIONS, DELETE
Access-Control-Allow-Headers: Content-Type, x-requested-with
Access-Control-Max-Age: 86400

If the requested method isn't supported, the server will respond with an error.SpecificationsSpecificationFetch # http-access-control-allow-headersBrowser compatibilitySee also
Access-Control-Allow-Origin
Access-Control-Expose-Headers
Access-Control-Allow-Methods
Access-Control-Request-Headers
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nAccess-Control-Allow-MethodsBaseline Widely availableThis feature is well established and works across many devices and browser versions. It’s been available across browsers since July 2015.Learn moreSee full compatibilityReport feedbackThe HTTP Access-Control-Allow-Methods response header specifies one or more HTTP request methods allowed when accessing a resource in response to a preflight request.

  
    
      Header type
      Response header
    
    
      Forbidden request header
      No
    
  
SyntaxhttpAccess-Control-Allow-Methods: <method>, <method>, …
Access-Control-Allow-Methods: *
Directives
<method>

A comma-separated list of the allowed request methods. GET, HEAD, and POST are always allowed, regardless of whether they are specified in this header, as they are defined as CORS-safelisted methods.

* (wildcard)

All HTTP methods.
It has this meaning only for requests without credentials (requests without HTTP cookies or HTTP authentication information). In requests with credentials, it is
treated as the literal method name * without special semantics.

ExampleshttpAccess-Control-Allow-Methods: PUT, DELETE
Access-Control-Allow-Methods: *
SpecificationsSpecificationFetch # http-access-control-allow-methodsBrowser compatibilitySee also
Access-Control-Allow-Origin
Access-Control-Expose-Headers
Access-Control-Allow-Headers
Access-Control-Request-Method
HTTP request methods\n\nAccess-Control-Allow-MethodsBaseline Widely availableThis feature is well established and works across many devices and browser versions. It’s been available across browsers since July 2015.Learn moreSee full compatibilityReport feedbackThe HTTP Access-Control-Allow-Methods response header specifies one or more HTTP request methods allowed when accessing a resource in response to a preflight request.

  
    
      Header type
      Response header
    
    
      Forbidden request header
      No
    
  
SyntaxhttpAccess-Control-Allow-Methods: <method>, <method>, …
Access-Control-Allow-Methods: *
Directives
<method>

A comma-separated list of the allowed request methods. GET, HEAD, and POST are always allowed, regardless of whether they are specified in this header, as they are defined as CORS-safelisted methods.

* (wildcard)

All HTTP methods.
It has this meaning only for requests without credentials (requests without HTTP cookies or HTTP authentication information). In requests with credentials, it is
treated as the literal method name * without special semantics.

ExampleshttpAccess-Control-Allow-Methods: PUT, DELETE
Access-Control-Allow-Methods: *
SpecificationsSpecificationFetch # http-access-control-allow-methodsBrowser compatibilitySee also
Access-Control-Allow-Origin
Access-Control-Expose-Headers
Access-Control-Allow-Headers
Access-Control-Request-Method
HTTP request methods
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nAccess-Control-Allow-MethodsBaseline Widely availableThis feature is well established and works across many devices and browser versions. It’s been available across browsers since July 2015.Learn moreSee full compatibilityReport feedbackThe HTTP Access-Control-Allow-Methods response header specifies one or more HTTP request methods allowed when accessing a resource in response to a preflight request.

  
    
      Header type
      Response header
    
    
      Forbidden request header
      No
    
  
SyntaxhttpAccess-Control-Allow-Methods: <method>, <method>, …
Access-Control-Allow-Methods: *
Directives
<method>

A comma-separated list of the allowed request methods. GET, HEAD, and POST are always allowed, regardless of whether they are specified in this header, as they are defined as CORS-safelisted methods.

* (wildcard)

All HTTP methods.
It has this meaning only for requests without credentials (requests without HTTP cookies or HTTP authentication information). In requests with credentials, it is
treated as the literal method name * without special semantics.

ExampleshttpAccess-Control-Allow-Methods: PUT, DELETE
Access-Control-Allow-Methods: *
SpecificationsSpecificationFetch # http-access-control-allow-methodsBrowser compatibilitySee also
Access-Control-Allow-Origin
Access-Control-Expose-Headers
Access-Control-Allow-Headers
Access-Control-Request-Method
HTTP request methods
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nAccess-Control-Allow-OriginBaseline Widely availableThis feature is well established and works across many devices and browser versions. It’s been available across browsers since July 2015.Learn moreSee full compatibilityReport feedbackThe HTTP Access-Control-Allow-Origin response header indicates whether the response can be shared with requesting code from the given origin.

  
    
      Header type
      Response header
    
    
      Forbidden request header
      No
    
  
SyntaxhttpAccess-Control-Allow-Origin: *
Access-Control-Allow-Origin: <origin>
Access-Control-Allow-Origin: null
Directives
* (wildcard)

The requesting code from any origin is allowed to access the resource.
For requests without credentials, the literal value * can be specified as a wildcard.
Attempting to use the wildcard with credentials results in an error.

<origin>

Specifies a single origin. If the server supports clients from multiple origins, it must return the origin for the specific client making the request.

null

Specifies the origin "null".

Note:
The value null should not be used. It may seem safe to return Access-Control-Allow-Origin: "null"; however, the origin of resources that use a non-hierarchical scheme (such as data: or file:) and sandboxed documents is serialized as null.
Many browsers will grant such documents access to a response with an Access-Control-Allow-Origin: null header, and any origin can create a hostile document with a null origin.
Therefore, the null value for the Access-Control-Allow-Origin header should be avoided.


ExamplesA response that tells the browser to allow code from any origin to access a resource will include the following:
httpAccess-Control-Allow-Origin: *

A response that tells the browser to allow requesting code from the origin https://developer.mozilla.org to access a resource will include the following:
httpAccess-Control-Allow-Origin: https://developer.mozilla.org

Limiting the possible Access-Control-Allow-Origin values to a set of allowed origins requires code on the server side to check the value of the Origin request header, compare that to a list of allowed origins, and then if the Origin value is in the list, set the Access-Control-Allow-Origin value to the same value as the Origin value.CORS and cachingSuppose the server sends a response with an Access-Control-Allow-Origin value with an explicit origin (rather than the * wildcard). In that case, the response should also include a Vary response header with the value Origin — to indicate to browsers that server responses can differ based on the value of the Origin request header.
httpAccess-Control-Allow-Origin: https://developer.mozilla.org
Vary: Origin
SpecificationsSpecificationFetch # http-access-control-allow-originBrowser compatibilitySee also
Origin
Vary
Cross-Origin Resource Sharing (CORS)
Cross-Origin-Resource-Policy\n\nAccess-Control-Allow-OriginBaseline Widely availableThis feature is well established and works across many devices and browser versions. It’s been available across browsers since July 2015.Learn moreSee full compatibilityReport feedbackThe HTTP Access-Control-Allow-Origin response header indicates whether the response can be shared with requesting code from the given origin.

  
    
      Header type
      Response header
    
    
      Forbidden request header
      No
    
  
SyntaxhttpAccess-Control-Allow-Origin: *
Access-Control-Allow-Origin: <origin>
Access-Control-Allow-Origin: null
Directives
* (wildcard)

The requesting code from any origin is allowed to access the resource.
For requests without credentials, the literal value * can be specified as a wildcard.
Attempting to use the wildcard with credentials results in an error.

<origin>

Specifies a single origin. If the server supports clients from multiple origins, it must return the origin for the specific client making the request.

null

Specifies the origin "null".

Note:
The value null should not be used. It may seem safe to return Access-Control-Allow-Origin: "null"; however, the origin of resources that use a non-hierarchical scheme (such as data: or file:) and sandboxed documents is serialized as null.
Many browsers will grant such documents access to a response with an Access-Control-Allow-Origin: null header, and any origin can create a hostile document with a null origin.
Therefore, the null value for the Access-Control-Allow-Origin header should be avoided.


ExamplesA response that tells the browser to allow code from any origin to access a resource will include the following:
httpAccess-Control-Allow-Origin: *

A response that tells the browser to allow requesting code from the origin https://developer.mozilla.org to access a resource will include the following:
httpAccess-Control-Allow-Origin: https://developer.mozilla.org

Limiting the possible Access-Control-Allow-Origin values to a set of allowed origins requires code on the server side to check the value of the Origin request header, compare that to a list of allowed origins, and then if the Origin value is in the list, set the Access-Control-Allow-Origin value to the same value as the Origin value.CORS and cachingSuppose the server sends a response with an Access-Control-Allow-Origin value with an explicit origin (rather than the * wildcard). In that case, the response should also include a Vary response header with the value Origin — to indicate to browsers that server responses can differ based on the value of the Origin request header.
httpAccess-Control-Allow-Origin: https://developer.mozilla.org
Vary: Origin
SpecificationsSpecificationFetch # http-access-control-allow-originBrowser compatibilitySee also
Origin
Vary
Cross-Origin Resource Sharing (CORS)
Cross-Origin-Resource-Policy
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nAccess-Control-Allow-OriginBaseline Widely availableThis feature is well established and works across many devices and browser versions. It’s been available across browsers since July 2015.Learn moreSee full compatibilityReport feedbackThe HTTP Access-Control-Allow-Origin response header indicates whether the response can be shared with requesting code from the given origin.

  
    
      Header type
      Response header
    
    
      Forbidden request header
      No
    
  
SyntaxhttpAccess-Control-Allow-Origin: *
Access-Control-Allow-Origin: <origin>
Access-Control-Allow-Origin: null
Directives
* (wildcard)

The requesting code from any origin is allowed to access the resource.
For requests without credentials, the literal value * can be specified as a wildcard.
Attempting to use the wildcard with credentials results in an error.

<origin>

Specifies a single origin. If the server supports clients from multiple origins, it must return the origin for the specific client making the request.

null

Specifies the origin "null".

Note:
The value null should not be used. It may seem safe to return Access-Control-Allow-Origin: "null"; however, the origin of resources that use a non-hierarchical scheme (such as data: or file:) and sandboxed documents is serialized as null.
Many browsers will grant such documents access to a response with an Access-Control-Allow-Origin: null header, and any origin can create a hostile document with a null origin.
Therefore, the null value for the Access-Control-Allow-Origin header should be avoided.


ExamplesA response that tells the browser to allow code from any origin to access a resource will include the following:
httpAccess-Control-Allow-Origin: *

A response that tells the browser to allow requesting code from the origin https://developer.mozilla.org to access a resource will include the following:
httpAccess-Control-Allow-Origin: https://developer.mozilla.org

Limiting the possible Access-Control-Allow-Origin values to a set of allowed origins requires code on the server side to check the value of the Origin request header, compare that to a list of allowed origins, and then if the Origin value is in the list, set the Access-Control-Allow-Origin value to the same value as the Origin value.CORS and cachingSuppose the server sends a response with an Access-Control-Allow-Origin value with an explicit origin (rather than the * wildcard). In that case, the response should also include a Vary response header with the value Origin — to indicate to browsers that server responses can differ based on the value of the Origin request header.
httpAccess-Control-Allow-Origin: https://developer.mozilla.org
Vary: Origin
SpecificationsSpecificationFetch # http-access-control-allow-originBrowser compatibilitySee also
Origin
Vary
Cross-Origin Resource Sharing (CORS)
Cross-Origin-Resource-Policy
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nAccess-Control-Expose-HeadersBaseline Widely availableThis feature is well established and works across many devices and browser versions. It’s been available across browsers since July 2015.Learn moreSee full compatibilityReport feedbackThe HTTP Access-Control-Expose-Headers response header allows a server to indicate which response headers should be made available to scripts running in the browser in response to a cross-origin request.
Only the CORS-safelisted response headers are exposed by default. For clients to be able to access other headers, the server must list them using the Access-Control-Expose-Headers header.

  
    
      Header type
      Response header
    
    
      Forbidden request header
      No
    
  
SyntaxhttpAccess-Control-Expose-Headers: [<header-name>[, <header-name>]*]
Access-Control-Expose-Headers: *
Directives
<header-name>

A list of zero or more comma-separated header names that clients are allowed to access from a response.
These are in addition to the CORS-safelisted response headers.

* (wildcard)

Any header.
The value * only counts as a special wildcard value for requests without credentials (requests without HTTP cookies or HTTP authentication information).
In requests with credentials, it is treated as the literal header name *.

ExamplesThe CORS-safelisted response headers are: Cache-Control, Content-Language, Content-Length, Content-Type, Expires, Last-Modified, Pragma. To expose a non-CORS-safelisted response header, you can specify:
httpAccess-Control-Expose-Headers: Content-Encoding

To additionally expose a custom header, like Kuma-Revision, you can specify multiple headers separated by a comma:
httpAccess-Control-Expose-Headers: Content-Encoding, Kuma-Revision

For requests without credentials, a server can also respond with a wildcard value:
httpAccess-Control-Expose-Headers: *

A server can also respond with the * value for requests with credentials, but in this case it would refer to a header named *.SpecificationsSpecificationFetch # http-access-control-expose-headersBrowser compatibilitySee also
Access-Control-Allow-Headers
Access-Control-Allow-Origin\n\nAccess-Control-Expose-HeadersBaseline Widely availableThis feature is well established and works across many devices and browser versions. It’s been available across browsers since July 2015.Learn moreSee full compatibilityReport feedbackThe HTTP Access-Control-Expose-Headers response header allows a server to indicate which response headers should be made available to scripts running in the browser in response to a cross-origin request.
Only the CORS-safelisted response headers are exposed by default. For clients to be able to access other headers, the server must list them using the Access-Control-Expose-Headers header.

  
    
      Header type
      Response header
    
    
      Forbidden request header
      No
    
  
SyntaxhttpAccess-Control-Expose-Headers: [<header-name>[, <header-name>]*]
Access-Control-Expose-Headers: *
Directives
<header-name>

A list of zero or more comma-separated header names that clients are allowed to access from a response.
These are in addition to the CORS-safelisted response headers.

* (wildcard)

Any header.
The value * only counts as a special wildcard value for requests without credentials (requests without HTTP cookies or HTTP authentication information).
In requests with credentials, it is treated as the literal header name *.

ExamplesThe CORS-safelisted response headers are: Cache-Control, Content-Language, Content-Length, Content-Type, Expires, Last-Modified, Pragma. To expose a non-CORS-safelisted response header, you can specify:
httpAccess-Control-Expose-Headers: Content-Encoding

To additionally expose a custom header, like Kuma-Revision, you can specify multiple headers separated by a comma:
httpAccess-Control-Expose-Headers: Content-Encoding, Kuma-Revision

For requests without credentials, a server can also respond with a wildcard value:
httpAccess-Control-Expose-Headers: *

A server can also respond with the * value for requests with credentials, but in this case it would refer to a header named *.SpecificationsSpecificationFetch # http-access-control-expose-headersBrowser compatibilitySee also
Access-Control-Allow-Headers
Access-Control-Allow-Origin
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nAccess-Control-Expose-HeadersBaseline Widely availableThis feature is well established and works across many devices and browser versions. It’s been available across browsers since July 2015.Learn moreSee full compatibilityReport feedbackThe HTTP Access-Control-Expose-Headers response header allows a server to indicate which response headers should be made available to scripts running in the browser in response to a cross-origin request.
Only the CORS-safelisted response headers are exposed by default. For clients to be able to access other headers, the server must list them using the Access-Control-Expose-Headers header.

  
    
      Header type
      Response header
    
    
      Forbidden request header
      No
    
  
SyntaxhttpAccess-Control-Expose-Headers: [<header-name>[, <header-name>]*]
Access-Control-Expose-Headers: *
Directives
<header-name>

A list of zero or more comma-separated header names that clients are allowed to access from a response.
These are in addition to the CORS-safelisted response headers.

* (wildcard)

Any header.
The value * only counts as a special wildcard value for requests without credentials (requests without HTTP cookies or HTTP authentication information).
In requests with credentials, it is treated as the literal header name *.

ExamplesThe CORS-safelisted response headers are: Cache-Control, Content-Language, Content-Length, Content-Type, Expires, Last-Modified, Pragma. To expose a non-CORS-safelisted response header, you can specify:
httpAccess-Control-Expose-Headers: Content-Encoding

To additionally expose a custom header, like Kuma-Revision, you can specify multiple headers separated by a comma:
httpAccess-Control-Expose-Headers: Content-Encoding, Kuma-Revision

For requests without credentials, a server can also respond with a wildcard value:
httpAccess-Control-Expose-Headers: *

A server can also respond with the * value for requests with credentials, but in this case it would refer to a header named *.SpecificationsSpecificationFetch # http-access-control-expose-headersBrowser compatibilitySee also
Access-Control-Allow-Headers
Access-Control-Allow-Origin
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nAccess-Control-Max-AgeBaseline Widely availableThis feature is well established and works across many devices and browser versions. It’s been available across browsers since July 2015.Learn moreSee full compatibilityReport feedbackThe HTTP Access-Control-Max-Age response header indicates how long the results of a preflight request (that is, the information contained in the Access-Control-Allow-Methods and Access-Control-Allow-Headers headers) can be cached.

  
    
      Header type
      Response header
    
    
      Forbidden request header
      No
    
  
SyntaxhttpAccess-Control-Max-Age: <delta-seconds>
Directives
<delta-seconds>

Maximum number of seconds for which the results can be cached as an unsigned non-negative integer.
Firefox caps this at 24 hours (86400 seconds).
Chromium (prior to v76) caps at 10 minutes (600 seconds).
Chromium (starting in v76) caps at 2 hours (7200 seconds).
The default value is 5 seconds.

ExamplesCache results of a preflight request for 10 minutes:
httpAccess-Control-Max-Age: 600
SpecificationsSpecificationFetch # http-access-control-max-ageBrowser compatibilitySee also
Access-Control-Allow-Headers
Access-Control-Allow-Methods\n\nAccess-Control-Max-AgeBaseline Widely availableThis feature is well established and works across many devices and browser versions. It’s been available across browsers since July 2015.Learn moreSee full compatibilityReport feedbackThe HTTP Access-Control-Max-Age response header indicates how long the results of a preflight request (that is, the information contained in the Access-Control-Allow-Methods and Access-Control-Allow-Headers headers) can be cached.

  
    
      Header type
      Response header
    
    
      Forbidden request header
      No
    
  
SyntaxhttpAccess-Control-Max-Age: <delta-seconds>
Directives
<delta-seconds>

Maximum number of seconds for which the results can be cached as an unsigned non-negative integer.
Firefox caps this at 24 hours (86400 seconds).
Chromium (prior to v76) caps at 10 minutes (600 seconds).
Chromium (starting in v76) caps at 2 hours (7200 seconds).
The default value is 5 seconds.

ExamplesCache results of a preflight request for 10 minutes:
httpAccess-Control-Max-Age: 600
SpecificationsSpecificationFetch # http-access-control-max-ageBrowser compatibilitySee also
Access-Control-Allow-Headers
Access-Control-Allow-Methods
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nAccess-Control-Max-AgeBaseline Widely availableThis feature is well established and works across many devices and browser versions. It’s been available across browsers since July 2015.Learn moreSee full compatibilityReport feedbackThe HTTP Access-Control-Max-Age response header indicates how long the results of a preflight request (that is, the information contained in the Access-Control-Allow-Methods and Access-Control-Allow-Headers headers) can be cached.

  
    
      Header type
      Response header
    
    
      Forbidden request header
      No
    
  
SyntaxhttpAccess-Control-Max-Age: <delta-seconds>
Directives
<delta-seconds>

Maximum number of seconds for which the results can be cached as an unsigned non-negative integer.
Firefox caps this at 24 hours (86400 seconds).
Chromium (prior to v76) caps at 10 minutes (600 seconds).
Chromium (starting in v76) caps at 2 hours (7200 seconds).
The default value is 5 seconds.

ExamplesCache results of a preflight request for 10 minutes:
httpAccess-Control-Max-Age: 600
SpecificationsSpecificationFetch # http-access-control-max-ageBrowser compatibilitySee also
Access-Control-Allow-Headers
Access-Control-Allow-Methods
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nAccess-Control-Request-HeadersBaseline Widely availableThis feature is well established and works across many devices and browser versions. It’s been available across browsers since July 2015.Learn moreSee full compatibilityReport feedbackThe HTTP Access-Control-Request-Headers request header is used by browsers when issuing a preflight request to let the server know which HTTP headers the client might send when the actual request is made (such as with fetch() or XMLHttpRequest.setRequestHeader()). The complementary server-side header of Access-Control-Allow-Headers will answer this browser-side header.

  
    
      Header type
      Request header
    
    
      Forbidden request header
      Yes
    
  
SyntaxhttpAccess-Control-Request-Headers: <header-name>,<header-name>,…
Directives
<header-name>

A sorted list of unique, comma-separated, lowercase HTTP headers that are included in the request.

ExampleshttpAccess-Control-Request-Headers: content-type,x-pingother
SpecificationsSpecificationFetch # http-access-control-request-headersBrowser compatibilitySee also
Access-Control-Request-Method\n\nAccess-Control-Request-HeadersBaseline Widely availableThis feature is well established and works across many devices and browser versions. It’s been available across browsers since July 2015.Learn moreSee full compatibilityReport feedbackThe HTTP Access-Control-Request-Headers request header is used by browsers when issuing a preflight request to let the server know which HTTP headers the client might send when the actual request is made (such as with fetch() or XMLHttpRequest.setRequestHeader()). The complementary server-side header of Access-Control-Allow-Headers will answer this browser-side header.

  
    
      Header type
      Request header
    
    
      Forbidden request header
      Yes
    
  
SyntaxhttpAccess-Control-Request-Headers: <header-name>,<header-name>,…
Directives
<header-name>

A sorted list of unique, comma-separated, lowercase HTTP headers that are included in the request.

ExampleshttpAccess-Control-Request-Headers: content-type,x-pingother
SpecificationsSpecificationFetch # http-access-control-request-headersBrowser compatibilitySee also
Access-Control-Request-Method
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nAccess-Control-Request-HeadersBaseline Widely availableThis feature is well established and works across many devices and browser versions. It’s been available across browsers since July 2015.Learn moreSee full compatibilityReport feedbackThe HTTP Access-Control-Request-Headers request header is used by browsers when issuing a preflight request to let the server know which HTTP headers the client might send when the actual request is made (such as with fetch() or XMLHttpRequest.setRequestHeader()). The complementary server-side header of Access-Control-Allow-Headers will answer this browser-side header.

  
    
      Header type
      Request header
    
    
      Forbidden request header
      Yes
    
  
SyntaxhttpAccess-Control-Request-Headers: <header-name>,<header-name>,…
Directives
<header-name>

A sorted list of unique, comma-separated, lowercase HTTP headers that are included in the request.

ExampleshttpAccess-Control-Request-Headers: content-type,x-pingother
SpecificationsSpecificationFetch # http-access-control-request-headersBrowser compatibilitySee also
Access-Control-Request-Method
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nAccess-Control-Request-MethodBaseline Widely availableThis feature is well established and works across many devices and browser versions. It’s been available across browsers since July 2015.Learn moreSee full compatibilityReport feedbackThe HTTP Access-Control-Request-Method request header is used by browsers when issuing a preflight request to let the server know which HTTP method will be used when the actual request is made.
This header is necessary because the preflight request is always an OPTIONS and doesn't use the same method as the actual request.

  
    
      Header type
      Request header
    
    
      Forbidden request header
      Yes
    
  
SyntaxhttpAccess-Control-Request-Method: <method>
Directives
<method>

An HTTP request method; for example, GET, POST, or DELETE.

ExampleshttpAccess-Control-Request-Method: POST
SpecificationsSpecificationFetch # http-access-control-request-methodBrowser compatibilitySee also
Access-Control-Request-Headers\n\nAccess-Control-Request-MethodBaseline Widely availableThis feature is well established and works across many devices and browser versions. It’s been available across browsers since July 2015.Learn moreSee full compatibilityReport feedbackThe HTTP Access-Control-Request-Method request header is used by browsers when issuing a preflight request to let the server know which HTTP method will be used when the actual request is made.
This header is necessary because the preflight request is always an OPTIONS and doesn't use the same method as the actual request.

  
    
      Header type
      Request header
    
    
      Forbidden request header
      Yes
    
  
SyntaxhttpAccess-Control-Request-Method: <method>
Directives
<method>

An HTTP request method; for example, GET, POST, or DELETE.

ExampleshttpAccess-Control-Request-Method: POST
SpecificationsSpecificationFetch # http-access-control-request-methodBrowser compatibilitySee also
Access-Control-Request-Headers
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nAccess-Control-Request-MethodBaseline Widely availableThis feature is well established and works across many devices and browser versions. It’s been available across browsers since July 2015.Learn moreSee full compatibilityReport feedbackThe HTTP Access-Control-Request-Method request header is used by browsers when issuing a preflight request to let the server know which HTTP method will be used when the actual request is made.
This header is necessary because the preflight request is always an OPTIONS and doesn't use the same method as the actual request.

  
    
      Header type
      Request header
    
    
      Forbidden request header
      Yes
    
  
SyntaxhttpAccess-Control-Request-Method: <method>
Directives
<method>

An HTTP request method; for example, GET, POST, or DELETE.

ExampleshttpAccess-Control-Request-Method: POST
SpecificationsSpecificationFetch # http-access-control-request-methodBrowser compatibilitySee also
Access-Control-Request-Headers
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nAgeBaseline Widely availableThis feature is well established and works across many devices and browser versions. It’s been available across browsers since July 2015.Learn moreSee full compatibilityReport feedbackThe HTTP Age response header indicates the time in seconds for which an object was in a proxy cache.
The header value is usually close to zero.
If the value is 0, the object was probably fetched from the origin server; otherwise, the value is usually calculated as a difference between the proxy's current date and the Date general header included in the HTTP response.

  
    
      Header type
      Response header
    
    
      Forbidden request header
      No
    
  
SyntaxhttpAge: <delta-seconds>
Directives
<delta-seconds>

A non-negative integer that represents the time in seconds for which the object was in a proxy cache.

ExampleshttpAge: 24
SpecificationsSpecificationHTTP Caching # field.ageBrowser compatibilitySee also
Cache-Control
Expires\n\nAgeBaseline Widely availableThis feature is well established and works across many devices and browser versions. It’s been available across browsers since July 2015.Learn moreSee full compatibilityReport feedbackThe HTTP Age response header indicates the time in seconds for which an object was in a proxy cache.
The header value is usually close to zero.
If the value is 0, the object was probably fetched from the origin server; otherwise, the value is usually calculated as a difference between the proxy's current date and the Date general header included in the HTTP response.

  
    
      Header type
      Response header
    
    
      Forbidden request header
      No
    
  
SyntaxhttpAge: <delta-seconds>
Directives
<delta-seconds>

A non-negative integer that represents the time in seconds for which the object was in a proxy cache.

ExampleshttpAge: 24
SpecificationsSpecificationHTTP Caching # field.ageBrowser compatibilitySee also
Cache-Control
Expires
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nAgeBaseline Widely availableThis feature is well established and works across many devices and browser versions. It’s been available across browsers since July 2015.Learn moreSee full compatibilityReport feedbackThe HTTP Age response header indicates the time in seconds for which an object was in a proxy cache.
The header value is usually close to zero.
If the value is 0, the object was probably fetched from the origin server; otherwise, the value is usually calculated as a difference between the proxy's current date and the Date general header included in the HTTP response.

  
    
      Header type
      Response header
    
    
      Forbidden request header
      No
    
  
SyntaxhttpAge: <delta-seconds>
Directives
<delta-seconds>

A non-negative integer that represents the time in seconds for which the object was in a proxy cache.

ExampleshttpAge: 24
SpecificationsSpecificationHTTP Caching # field.ageBrowser compatibilitySee also
Cache-Control
Expires
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nAllowThe HTTP Allow response header lists the set of request methods supported by a resource.
This header must be sent if the server responds with a 405 Method Not Allowed status code to indicate which request methods can be used instead.
An empty Allow value indicates that the resource allows no request methods, which might occur temporarily for a given resource.

  
    
      Header type
      Response header
    
    
      Forbidden request header
      No
    
  
SyntaxhttpAllow: <http-methods>
Directives
<http-methods>

A comma-separated list of allowed request methods supported by a resource.

ExampleshttpAllow: GET, POST, HEAD
SpecificationsSpecificationHTTP Semantics # field.allowSee also
405 Method Not Allowed status code
Server
OPTIONS\n\nAllowThe HTTP Allow response header lists the set of request methods supported by a resource.
This header must be sent if the server responds with a 405 Method Not Allowed status code to indicate which request methods can be used instead.
An empty Allow value indicates that the resource allows no request methods, which might occur temporarily for a given resource.

  
    
      Header type
      Response header
    
    
      Forbidden request header
      No
    
  
SyntaxhttpAllow: <http-methods>
Directives
<http-methods>

A comma-separated list of allowed request methods supported by a resource.

ExampleshttpAllow: GET, POST, HEAD
SpecificationsSpecificationHTTP Semantics # field.allowSee also
405 Method Not Allowed status code
Server
OPTIONS
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nAllowThe HTTP Allow response header lists the set of request methods supported by a resource.
This header must be sent if the server responds with a 405 Method Not Allowed status code to indicate which request methods can be used instead.
An empty Allow value indicates that the resource allows no request methods, which might occur temporarily for a given resource.

  
    
      Header type
      Response header
    
    
      Forbidden request header
      No
    
  
SyntaxhttpAllow: <http-methods>
Directives
<http-methods>

A comma-separated list of allowed request methods supported by a resource.

ExampleshttpAllow: GET, POST, HEAD
SpecificationsSpecificationHTTP Semantics # field.allowSee also
405 Method Not Allowed status code
Server
OPTIONS
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nAlt-SvcThe HTTP Alt-Svc response header lets a server indicate that another network location (the "alternative service") can be treated as authoritative for that origin when making future requests.
Doing so allows new protocol versions to be advertised without affecting in-flight requests and can also help servers manage traffic. Using an alternative service is not visible to the end user; it does not change the URL or the origin of the request and does not introduce additional round trips.

  
    
      Header type
      Response header
    
    
      Forbidden request header
      No
    
  
SyntaxhttpAlt-Svc: clear
Alt-Svc: <protocol-id>=<alt-authority>; ma=<max-age>
Alt-Svc: <protocol-id>=<alt-authority>; ma=<max-age>; persist=1


clear

All alternative services of the origin are invalidated.

<protocol-id>

The Application-Layer Protocol Negotiation (ALPN) protocol identifier. Examples include h2 for HTTP/2 and h3-25 for draft 25 of the HTTP/3 protocol.

<alt-authority>

A quoted string specifying the alternative authority, consisting of an optional host override, a colon, and a mandatory port number.

ma=<max-age> Optional

The number of seconds for which the alternative service is considered fresh.
If omitted, it defaults to 24 hours.
Alternative service entries can be cached for up to <max-age> seconds, minus the age of the response (from the Age header).
Once the cached entry expires, the client can no longer use this alternative service for new connections.

persist=1 Optional

Entries are not deleted by network configuration changes.
Cached alternative service entries are usually cleared on such changes.


Multiple entries can be specified in a single Alt-Svc header using comma as separator.
In that case, early entries are considered more preferable.ExamplehttpAlt-Svc: h2=":443"; ma=2592000;
Alt-Svc: h2=":443"; ma=2592000; persist=1
Alt-Svc: h2="alt.example.com:443", h2=":443"
Alt-Svc: h3-25=":443"; ma=3600, h2=":443"; ma=3600
SpecificationsSpecificationHTTP Alternative Services # alt-svcBrowser compatibilitySee also
Alternative Services by HTTP Working Group chair, Mark Nottingham (2016)\n\nAlt-SvcThe HTTP Alt-Svc response header lets a server indicate that another network location (the "alternative service") can be treated as authoritative for that origin when making future requests.
Doing so allows new protocol versions to be advertised without affecting in-flight requests and can also help servers manage traffic. Using an alternative service is not visible to the end user; it does not change the URL or the origin of the request and does not introduce additional round trips.

  
    
      Header type
      Response header
    
    
      Forbidden request header
      No
    
  
SyntaxhttpAlt-Svc: clear
Alt-Svc: <protocol-id>=<alt-authority>; ma=<max-age>
Alt-Svc: <protocol-id>=<alt-authority>; ma=<max-age>; persist=1


clear

All alternative services of the origin are invalidated.

<protocol-id>

The Application-Layer Protocol Negotiation (ALPN) protocol identifier. Examples include h2 for HTTP/2 and h3-25 for draft 25 of the HTTP/3 protocol.

<alt-authority>

A quoted string specifying the alternative authority, consisting of an optional host override, a colon, and a mandatory port number.

ma=<max-age> Optional

The number of seconds for which the alternative service is considered fresh.
If omitted, it defaults to 24 hours.
Alternative service entries can be cached for up to <max-age> seconds, minus the age of the response (from the Age header).
Once the cached entry expires, the client can no longer use this alternative service for new connections.

persist=1 Optional

Entries are not deleted by network configuration changes.
Cached alternative service entries are usually cleared on such changes.


Multiple entries can be specified in a single Alt-Svc header using comma as separator.
In that case, early entries are considered more preferable.ExamplehttpAlt-Svc: h2=":443"; ma=2592000;
Alt-Svc: h2=":443"; ma=2592000; persist=1
Alt-Svc: h2="alt.example.com:443", h2=":443"
Alt-Svc: h3-25=":443"; ma=3600, h2=":443"; ma=3600
SpecificationsSpecificationHTTP Alternative Services # alt-svcBrowser compatibilitySee also
Alternative Services by HTTP Working Group chair, Mark Nottingham (2016)
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nAlt-SvcThe HTTP Alt-Svc response header lets a server indicate that another network location (the "alternative service") can be treated as authoritative for that origin when making future requests.
Doing so allows new protocol versions to be advertised without affecting in-flight requests and can also help servers manage traffic. Using an alternative service is not visible to the end user; it does not change the URL or the origin of the request and does not introduce additional round trips.

  
    
      Header type
      Response header
    
    
      Forbidden request header
      No
    
  
SyntaxhttpAlt-Svc: clear
Alt-Svc: <protocol-id>=<alt-authority>; ma=<max-age>
Alt-Svc: <protocol-id>=<alt-authority>; ma=<max-age>; persist=1


clear

All alternative services of the origin are invalidated.

<protocol-id>

The Application-Layer Protocol Negotiation (ALPN) protocol identifier. Examples include h2 for HTTP/2 and h3-25 for draft 25 of the HTTP/3 protocol.

<alt-authority>

A quoted string specifying the alternative authority, consisting of an optional host override, a colon, and a mandatory port number.

ma=<max-age> Optional

The number of seconds for which the alternative service is considered fresh.
If omitted, it defaults to 24 hours.
Alternative service entries can be cached for up to <max-age> seconds, minus the age of the response (from the Age header).
Once the cached entry expires, the client can no longer use this alternative service for new connections.

persist=1 Optional

Entries are not deleted by network configuration changes.
Cached alternative service entries are usually cleared on such changes.


Multiple entries can be specified in a single Alt-Svc header using comma as separator.
In that case, early entries are considered more preferable.ExamplehttpAlt-Svc: h2=":443"; ma=2592000;
Alt-Svc: h2=":443"; ma=2592000; persist=1
Alt-Svc: h2="alt.example.com:443", h2=":443"
Alt-Svc: h3-25=":443"; ma=3600, h2=":443"; ma=3600
SpecificationsSpecificationHTTP Alternative Services # alt-svcBrowser compatibilitySee also
Alternative Services by HTTP Working Group chair, Mark Nottingham (2016)
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nAlt-UsedThe HTTP Alt-Used request header is used to identify the alternative service in use, just as the Host HTTP header field identifies the host and port of the origin.
The is intended to allow alternative services to detect loops, differentiate traffic for purposes of load balancing, and generally to ensure that it is possible to identify the intended destination of traffic, since introducing this information after a protocol is in use has proven to be problematic.
When a client uses an alternative service for a request, it can indicate this to the server using the Alt-Used HTTP header.

  
    
      Header type
      Request header
    
    
      Forbidden request header
      No
    
  
SyntaxhttpAlt-Used: <host>:<port>
Directives
<host>

The domain name of the server.

<port> Optional

The TCP port number on which the server is listening.

ExampleshttpAlt-Used: alternate.example.net
SpecificationsSpecificationHTTP Alternative Services See also
Alt-Svc
Host\n\nAlt-UsedThe HTTP Alt-Used request header is used to identify the alternative service in use, just as the Host HTTP header field identifies the host and port of the origin.
The is intended to allow alternative services to detect loops, differentiate traffic for purposes of load balancing, and generally to ensure that it is possible to identify the intended destination of traffic, since introducing this information after a protocol is in use has proven to be problematic.
When a client uses an alternative service for a request, it can indicate this to the server using the Alt-Used HTTP header.

  
    
      Header type
      Request header
    
    
      Forbidden request header
      No
    
  
SyntaxhttpAlt-Used: <host>:<port>
Directives
<host>

The domain name of the server.

<port> Optional

The TCP port number on which the server is listening.

ExampleshttpAlt-Used: alternate.example.net
SpecificationsSpecificationHTTP Alternative Services See also
Alt-Svc
Host
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nAlt-UsedThe HTTP Alt-Used request header is used to identify the alternative service in use, just as the Host HTTP header field identifies the host and port of the origin.
The is intended to allow alternative services to detect loops, differentiate traffic for purposes of load balancing, and generally to ensure that it is possible to identify the intended destination of traffic, since introducing this information after a protocol is in use has proven to be problematic.
When a client uses an alternative service for a request, it can indicate this to the server using the Alt-Used HTTP header.

  
    
      Header type
      Request header
    
    
      Forbidden request header
      No
    
  
SyntaxhttpAlt-Used: <host>:<port>
Directives
<host>

The domain name of the server.

<port> Optional

The TCP port number on which the server is listening.

ExampleshttpAlt-Used: alternate.example.net
SpecificationsSpecificationHTTP Alternative Services See also
Alt-Svc
Host
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nAttribution-Reporting-EligibleLimited availabilityThis feature is not Baseline because it does not work in some of the most widely-used browsers.Learn moreSee full compatibilityReport feedbackExperimental: This is an experimental technologyCheck the Browser compatibility table carefully before using this in production.
The HTTP Attribution-Reporting-Eligible request header indicates that the corresponding response is eligible to register an attribution source or trigger.
This header is never set manually and is instead sent by the browser in response to various HTML element or JavaScript request settings. Depending on the allowed registrations specified in the Attribution-Reporting-Eligible value, the server is expected to respond with either an Attribution-Reporting-Register-Source or Attribution-Reporting-Register-Trigger header to complete the registration of an attribution source or trigger, respectively.
See the Attribution Reporting API for more details.

  
    
      Header type
      Request header
    
    
      Forbidden request header
      No
    
  
SyntaxhttpAttribution-Reporting-Eligible: <allowed-registrations>
Directives
<allowed-registrations>

A structured-header dictionary representing the registrations allowed in the corresponding response. Possible keys are:

event-source

An event-based attribution source can be registered.

navigation-source

A navigation-based attribution source can be registered.

trigger

An attribution trigger can be registered.




Every response in a redirect chain can register at most one source or one trigger.ExampleshttpAttribution-Reporting-Eligible: trigger
SpecificationsSpecificationAttribution Reporting # attribution-reporting-eligibleBrowser compatibilitySee also
Attribution-Reporting-Register-Source
Attribution-Reporting-Register-Trigger
Attribution Reporting API\n\nAttribution-Reporting-EligibleLimited availabilityThis feature is not Baseline because it does not work in some of the most widely-used browsers.Learn moreSee full compatibilityReport feedbackExperimental: This is an experimental technologyCheck the Browser compatibility table carefully before using this in production.
The HTTP Attribution-Reporting-Eligible request header indicates that the corresponding response is eligible to register an attribution source or trigger.
This header is never set manually and is instead sent by the browser in response to various HTML element or JavaScript request settings. Depending on the allowed registrations specified in the Attribution-Reporting-Eligible value, the server is expected to respond with either an Attribution-Reporting-Register-Source or Attribution-Reporting-Register-Trigger header to complete the registration of an attribution source or trigger, respectively.
See the Attribution Reporting API for more details.

  
    
      Header type
      Request header
    
    
      Forbidden request header
      No
    
  
SyntaxhttpAttribution-Reporting-Eligible: <allowed-registrations>
Directives
<allowed-registrations>

A structured-header dictionary representing the registrations allowed in the corresponding response. Possible keys are:

event-source

An event-based attribution source can be registered.

navigation-source

A navigation-based attribution source can be registered.

trigger

An attribution trigger can be registered.




Every response in a redirect chain can register at most one source or one trigger.ExampleshttpAttribution-Reporting-Eligible: trigger
SpecificationsSpecificationAttribution Reporting # attribution-reporting-eligibleBrowser compatibilitySee also
Attribution-Reporting-Register-Source
Attribution-Reporting-Register-Trigger
Attribution Reporting API
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nAttribution-Reporting-EligibleLimited availabilityThis feature is not Baseline because it does not work in some of the most widely-used browsers.Learn moreSee full compatibilityReport feedbackExperimental: This is an experimental technologyCheck the Browser compatibility table carefully before using this in production.
The HTTP Attribution-Reporting-Eligible request header indicates that the corresponding response is eligible to register an attribution source or trigger.
This header is never set manually and is instead sent by the browser in response to various HTML element or JavaScript request settings. Depending on the allowed registrations specified in the Attribution-Reporting-Eligible value, the server is expected to respond with either an Attribution-Reporting-Register-Source or Attribution-Reporting-Register-Trigger header to complete the registration of an attribution source or trigger, respectively.
See the Attribution Reporting API for more details.

  
    
      Header type
      Request header
    
    
      Forbidden request header
      No
    
  
SyntaxhttpAttribution-Reporting-Eligible: <allowed-registrations>
Directives
<allowed-registrations>

A structured-header dictionary representing the registrations allowed in the corresponding response. Possible keys are:

event-source

An event-based attribution source can be registered.

navigation-source

A navigation-based attribution source can be registered.

trigger

An attribution trigger can be registered.




Every response in a redirect chain can register at most one source or one trigger.ExampleshttpAttribution-Reporting-Eligible: trigger
SpecificationsSpecificationAttribution Reporting # attribution-reporting-eligibleBrowser compatibilitySee also
Attribution-Reporting-Register-Source
Attribution-Reporting-Register-Trigger
Attribution Reporting API
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nAttribution-Reporting-Register-SourceLimited availabilityThis feature is not Baseline because it does not work in some of the most widely-used browsers.Learn moreSee full compatibilityReport feedbackExperimental: This is an experimental technologyCheck the Browser compatibility table carefully before using this in production.
The HTTP Attribution-Reporting-Register-Source response header registers a page feature as an attribution source. This header is included as part of a response to a request that contains the Attribution-Reporting-Eligible header. It provides the information that the browser should store when a user interacts with the attribution source. The information you include in this header also determines the types of reports the browser can generate.
See the Attribution Reporting API for more details.

Note:
If the calling site does not have the Attribution Reporting API included in a successful privacy sandbox enrollment process, the Attribution-Reporting-Register-Source header is ignored and attribution sources are not registered.


  
    
      Header type
      Response header
    
    
      Forbidden request header
      No
    
    
      
        CORS-safelisted response header
      
      No
    
  
SyntaxhttpAttribution-Reporting-Register-Source: <json-string>
Directives
<json-string>

A JSON string providing the information that the browser should store when the attribution source is interacted with. Available fields are as follows:

"source_event_id" Optional

A string representing an ID for the attribution source, which can be used to map it to other information when the attribution source is interacted with, or aggregate information at the reporting endpoint. The string must consist solely of a base-10-formatted 64-bit unsigned integer.

"destination"

A single string or an array of 1–3 strings. These strings must contain a complete URL corresponding to the site (scheme + eTLD+1) on which a trigger is expected to occur. These are used to match the attribution trigger to the source when a trigger is interacted with.

"aggregation_keys" Optional

An object containing user-provided keys representing different data points to aggregate report values under.

"aggregatable_report_window" Optional

A string representing a time in seconds after which trigger data will no longer be included in generated aggregatable reports (this is called a report window). If not set, this defaults to the "expiry" value.

"debug_key" Optional

A base-10-formatted 64-bit unsigned integer representing a debug key. Set this if you want to generate a debug report alongside the associated attribution report.

"debug_reporting" Optional

A boolean value. If a debug_key is set, set this to true to specify that the generated debug report should be a verbose debug report.

"event_level_epsilon" Optional

A number equal to or greater than 0, which controls the amount of noise added to reports. Lower values of epsilon result in more noise and therefore provide greater privacy protection. The maximum and default values will vary across implementations; Chrome for example has a maximum and default value of 14.

"event_report_window" Optional

A string representing a time in seconds, after which subsequent triggers won't be attributable to this source for the purpose of producing event-level reports (this is called a report window). If not set, the event report window falls back to the "expiry" value.

Note:
If "event_report_window" is specified, "event_report_windows" cannot be specified, otherwise the source registration will fail.


"event_report_windows" Optional

An object representing a series of report windows, starting at "start_time", with reports for this source being delivered after each specified end time in "end_times". This can be used to vary the time of report delivery across multiple reports. If not set, the event report window falls back to the "expiry" value. Properties are as follows:

"start_time" Optional: A non-negative number specifying the start time for the reporting windows. If not specified, it defaults to 0.
"end_times": An array of positive numbers specifying end times for subsequent report windows. The values must be increasing, and greater than "start_time".

Note:
If "event_report_windows" is specified, "event_report_window" cannot be specified, otherwise the source registration will fail.




"expiry" Optional

A string representing an expiry time in seconds for the attribution source, after which it will no longer be active (i.e., subsequent triggers won't be attributable to this source). The maximum allowable expiry time is 2592000 seconds (30 days), which is also the default value if "expiry" is not explicitly set.

"filter_data" Optional

An object defining custom data that can be used to filter which conversions generate reports. See Filters for more details.

"max_event_level_reports" Optional

A number between 0 and 20, inclusive, which specifies the total number of event-level reports this source can generate. After this maximum is reached, the source is no longer capable of producing any new data. If not specified, "max_event_level_reports" defaults to 3 for navigation-based sources and 1 for event-based (image- or script-based) sources.

"priority" Optional

A string representing a priority value for the attribution source. By default, conversions are attributed to the most recent matching source. For both event-level and summary reports you set a higher priority number to prioritize specific sources. For example, a value of 2 takes priority over the default value of 1. See Report priorities and limits for more information.

"trigger_data" Optional

An array of 32-bit unsigned integers representing data that describes the different trigger events that could match this source. For example, "user added item to shopping cart" or "user signed up to mailing list" could be actions happening at the trigger site that could match this source and indicate a conversion of some kind that the advertiser is trying to measure. These must be matched against "trigger_data" specified in triggers for event-level attribution to take place. If omitted, "trigger_data" defaults to [0, 1, 2, 3, 4, 5, 6, 7] for navigation-based sources and [0, 1] for event-based (image- or script-based) sources.

Note:
The values used to represent each event, and the number of elements in the array, are completely arbitrary and defined by you as the developer. The array may contain values that are not used, but values must be present in the array to be attributed to the source by the browser when a trigger is registered.


"trigger_data_matching" Optional

A string that specifies how the "trigger_data" from the trigger is matched against the source's "trigger_data". Possible values are:

"exact": The "trigger_data" from the trigger must exactly match a value contained in the source's "trigger_data"; if there is no such match, no event-level attribution takes place.
"modulus": In this case, the following calculation is performed — d % allowedValues.size — where d is the "trigger_data" from the trigger, and allowedValues is the sequence of values in the source's "trigger_data" array. If the result of this calculation matches a value in the source's "trigger_data" array, the match is a success. In such a case, the value will always match, unless allowedValues is empty.

"modulus" mode exists primarily for backwards compatibility with the API's behavior before "exact" was introduced, and as such, you'd be unlikely to use it. It is still useful in particular cases that require a very specific kind of compression resulting in smaller registration headers. This can be required when using complex filtering logic that needs to set different trigger data based on the source type according to the maximum number of source "trigger_data" items.

Note:
If "modulus" is used, the source's "trigger_data" must form a contiguous sequence of integers starting at 0. If the trigger data does not form such a sequence, an error occurs.

If not specified, "trigger_data_matching" defaults to "modulus". Again, the reason for this is backwards compatibility: omitting the "trigger_data_matching" field needs to result in the same behavior observed before this field was introduced.



ExamplesRegistering a source for an event-level reportA Node.js server might set the Attribution-Reporting-Register-Source response header as follows to make a browser generate an event-level report when a trigger is matched to a source:
jsres.set(
  "Attribution-Reporting-Register-Source",
  JSON.stringify({
    source_event_id: "412444888111012",
    destination: "https://shop.example",
    trigger_data: [0, 1, 2, 3, 4],
    trigger_data_matching: "exact",
    expiry: "604800",
    priority: "100",
    debug_key: "122939999",
    event_report_window: "86400",
  }),
);
Registering a source for a summary reportTo make the browser generate a summary report when a trigger is matched to a source, you need to include some extra fields, in addition to those required for event-level report generation.
jsres.set(
  "Attribution-Reporting-Register-Source",
  JSON.stringify({
    source_event_id: "412444888111012",
    destination: "https://shop.example",
    trigger_data: [0, 1, 2, 3, 4],
    trigger_data_matching: "exact",
    expiry: "604800",
    priority: "100",
    debug_key: "122939999",
    event_report_window: "86400",

    aggregation_keys: {
      campaignCounts: "0x159",
      geoValue: "0x5",
    },
    aggregatable_report_window: "86400",
  }),
);
SpecificationsSpecificationAttribution Reporting # parse-source-registration-jsonBrowser compatibilitySee also
Attribution-Reporting-Eligible
Attribution-Reporting-Register-Trigger
Attribution Reporting API\n\nAttribution-Reporting-Register-SourceLimited availabilityThis feature is not Baseline because it does not work in some of the most widely-used browsers.Learn moreSee full compatibilityReport feedbackExperimental: This is an experimental technologyCheck the Browser compatibility table carefully before using this in production.
The HTTP Attribution-Reporting-Register-Source response header registers a page feature as an attribution source. This header is included as part of a response to a request that contains the Attribution-Reporting-Eligible header. It provides the information that the browser should store when a user interacts with the attribution source. The information you include in this header also determines the types of reports the browser can generate.
See the Attribution Reporting API for more details.

Note:
If the calling site does not have the Attribution Reporting API included in a successful privacy sandbox enrollment process, the Attribution-Reporting-Register-Source header is ignored and attribution sources are not registered.


  
    
      Header type
      Response header
    
    
      Forbidden request header
      No
    
    
      
        CORS-safelisted response header
      
      No
    
  
SyntaxhttpAttribution-Reporting-Register-Source: <json-string>
Directives
<json-string>

A JSON string providing the information that the browser should store when the attribution source is interacted with. Available fields are as follows:

"source_event_id" Optional

A string representing an ID for the attribution source, which can be used to map it to other information when the attribution source is interacted with, or aggregate information at the reporting endpoint. The string must consist solely of a base-10-formatted 64-bit unsigned integer.

"destination"

A single string or an array of 1–3 strings. These strings must contain a complete URL corresponding to the site (scheme + eTLD+1) on which a trigger is expected to occur. These are used to match the attribution trigger to the source when a trigger is interacted with.

"aggregation_keys" Optional

An object containing user-provided keys representing different data points to aggregate report values under.

"aggregatable_report_window" Optional

A string representing a time in seconds after which trigger data will no longer be included in generated aggregatable reports (this is called a report window). If not set, this defaults to the "expiry" value.

"debug_key" Optional

A base-10-formatted 64-bit unsigned integer representing a debug key. Set this if you want to generate a debug report alongside the associated attribution report.

"debug_reporting" Optional

A boolean value. If a debug_key is set, set this to true to specify that the generated debug report should be a verbose debug report.

"event_level_epsilon" Optional

A number equal to or greater than 0, which controls the amount of noise added to reports. Lower values of epsilon result in more noise and therefore provide greater privacy protection. The maximum and default values will vary across implementations; Chrome for example has a maximum and default value of 14.

"event_report_window" Optional

A string representing a time in seconds, after which subsequent triggers won't be attributable to this source for the purpose of producing event-level reports (this is called a report window). If not set, the event report window falls back to the "expiry" value.

Note:
If "event_report_window" is specified, "event_report_windows" cannot be specified, otherwise the source registration will fail.


"event_report_windows" Optional

An object representing a series of report windows, starting at "start_time", with reports for this source being delivered after each specified end time in "end_times". This can be used to vary the time of report delivery across multiple reports. If not set, the event report window falls back to the "expiry" value. Properties are as follows:

"start_time" Optional: A non-negative number specifying the start time for the reporting windows. If not specified, it defaults to 0.
"end_times": An array of positive numbers specifying end times for subsequent report windows. The values must be increasing, and greater than "start_time".

Note:
If "event_report_windows" is specified, "event_report_window" cannot be specified, otherwise the source registration will fail.




"expiry" Optional

A string representing an expiry time in seconds for the attribution source, after which it will no longer be active (i.e., subsequent triggers won't be attributable to this source). The maximum allowable expiry time is 2592000 seconds (30 days), which is also the default value if "expiry" is not explicitly set.

"filter_data" Optional

An object defining custom data that can be used to filter which conversions generate reports. See Filters for more details.

"max_event_level_reports" Optional

A number between 0 and 20, inclusive, which specifies the total number of event-level reports this source can generate. After this maximum is reached, the source is no longer capable of producing any new data. If not specified, "max_event_level_reports" defaults to 3 for navigation-based sources and 1 for event-based (image- or script-based) sources.

"priority" Optional

A string representing a priority value for the attribution source. By default, conversions are attributed to the most recent matching source. For both event-level and summary reports you set a higher priority number to prioritize specific sources. For example, a value of 2 takes priority over the default value of 1. See Report priorities and limits for more information.

"trigger_data" Optional

An array of 32-bit unsigned integers representing data that describes the different trigger events that could match this source. For example, "user added item to shopping cart" or "user signed up to mailing list" could be actions happening at the trigger site that could match this source and indicate a conversion of some kind that the advertiser is trying to measure. These must be matched against "trigger_data" specified in triggers for event-level attribution to take place. If omitted, "trigger_data" defaults to [0, 1, 2, 3, 4, 5, 6, 7] for navigation-based sources and [0, 1] for event-based (image- or script-based) sources.

Note:
The values used to represent each event, and the number of elements in the array, are completely arbitrary and defined by you as the developer. The array may contain values that are not used, but values must be present in the array to be attributed to the source by the browser when a trigger is registered.


"trigger_data_matching" Optional

A string that specifies how the "trigger_data" from the trigger is matched against the source's "trigger_data". Possible values are:

"exact": The "trigger_data" from the trigger must exactly match a value contained in the source's "trigger_data"; if there is no such match, no event-level attribution takes place.
"modulus": In this case, the following calculation is performed — d % allowedValues.size — where d is the "trigger_data" from the trigger, and allowedValues is the sequence of values in the source's "trigger_data" array. If the result of this calculation matches a value in the source's "trigger_data" array, the match is a success. In such a case, the value will always match, unless allowedValues is empty.

"modulus" mode exists primarily for backwards compatibility with the API's behavior before "exact" was introduced, and as such, you'd be unlikely to use it. It is still useful in particular cases that require a very specific kind of compression resulting in smaller registration headers. This can be required when using complex filtering logic that needs to set different trigger data based on the source type according to the maximum number of source "trigger_data" items.

Note:
If "modulus" is used, the source's "trigger_data" must form a contiguous sequence of integers starting at 0. If the trigger data does not form such a sequence, an error occurs.

If not specified, "trigger_data_matching" defaults to "modulus". Again, the reason for this is backwards compatibility: omitting the "trigger_data_matching" field needs to result in the same behavior observed before this field was introduced.



ExamplesRegistering a source for an event-level reportA Node.js server might set the Attribution-Reporting-Register-Source response header as follows to make a browser generate an event-level report when a trigger is matched to a source:
jsres.set(
  "Attribution-Reporting-Register-Source",
  JSON.stringify({
    source_event_id: "412444888111012",
    destination: "https://shop.example",
    trigger_data: [0, 1, 2, 3, 4],
    trigger_data_matching: "exact",
    expiry: "604800",
    priority: "100",
    debug_key: "122939999",
    event_report_window: "86400",
  }),
);
Registering a source for a summary reportTo make the browser generate a summary report when a trigger is matched to a source, you need to include some extra fields, in addition to those required for event-level report generation.
jsres.set(
  "Attribution-Reporting-Register-Source",
  JSON.stringify({
    source_event_id: "412444888111012",
    destination: "https://shop.example",
    trigger_data: [0, 1, 2, 3, 4],
    trigger_data_matching: "exact",
    expiry: "604800",
    priority: "100",
    debug_key: "122939999",
    event_report_window: "86400",

    aggregation_keys: {
      campaignCounts: "0x159",
      geoValue: "0x5",
    },
    aggregatable_report_window: "86400",
  }),
);
SpecificationsSpecificationAttribution Reporting # parse-source-registration-jsonBrowser compatibilitySee also
Attribution-Reporting-Eligible
Attribution-Reporting-Register-Trigger
Attribution Reporting API
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Apr 3, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nAttribution-Reporting-Register-SourceLimited availabilityThis feature is not Baseline because it does not work in some of the most widely-used browsers.Learn moreSee full compatibilityReport feedbackExperimental: This is an experimental technologyCheck the Browser compatibility table carefully before using this in production.
The HTTP Attribution-Reporting-Register-Source response header registers a page feature as an attribution source. This header is included as part of a response to a request that contains the Attribution-Reporting-Eligible header. It provides the information that the browser should store when a user interacts with the attribution source. The information you include in this header also determines the types of reports the browser can generate.
See the Attribution Reporting API for more details.

Note:
If the calling site does not have the Attribution Reporting API included in a successful privacy sandbox enrollment process, the Attribution-Reporting-Register-Source header is ignored and attribution sources are not registered.


  
    
      Header type
      Response header
    
    
      Forbidden request header
      No
    
    
      
        CORS-safelisted response header
      
      No
    
  
SyntaxhttpAttribution-Reporting-Register-Source: <json-string>
Directives
<json-string>

A JSON string providing the information that the browser should store when the attribution source is interacted with. Available fields are as follows:

"source_event_id" Optional

A string representing an ID for the attribution source, which can be used to map it to other information when the attribution source is interacted with, or aggregate information at the reporting endpoint. The string must consist solely of a base-10-formatted 64-bit unsigned integer.

"destination"

A single string or an array of 1–3 strings. These strings must contain a complete URL corresponding to the site (scheme + eTLD+1) on which a trigger is expected to occur. These are used to match the attribution trigger to the source when a trigger is interacted with.

"aggregation_keys" Optional

An object containing user-provided keys representing different data points to aggregate report values under.

"aggregatable_report_window" Optional

A string representing a time in seconds after which trigger data will no longer be included in generated aggregatable reports (this is called a report window). If not set, this defaults to the "expiry" value.

"debug_key" Optional

A base-10-formatted 64-bit unsigned integer representing a debug key. Set this if you want to generate a debug report alongside the associated attribution report.

"debug_reporting" Optional

A boolean value. If a debug_key is set, set this to true to specify that the generated debug report should be a verbose debug report.

"event_level_epsilon" Optional

A number equal to or greater than 0, which controls the amount of noise added to reports. Lower values of epsilon result in more noise and therefore provide greater privacy protection. The maximum and default values will vary across implementations; Chrome for example has a maximum and default value of 14.

"event_report_window" Optional

A string representing a time in seconds, after which subsequent triggers won't be attributable to this source for the purpose of producing event-level reports (this is called a report window). If not set, the event report window falls back to the "expiry" value.

Note:
If "event_report_window" is specified, "event_report_windows" cannot be specified, otherwise the source registration will fail.


"event_report_windows" Optional

An object representing a series of report windows, starting at "start_time", with reports for this source being delivered after each specified end time in "end_times". This can be used to vary the time of report delivery across multiple reports. If not set, the event report window falls back to the "expiry" value. Properties are as follows:

"start_time" Optional: A non-negative number specifying the start time for the reporting windows. If not specified, it defaults to 0.
"end_times": An array of positive numbers specifying end times for subsequent report windows. The values must be increasing, and greater than "start_time".

Note:
If "event_report_windows" is specified, "event_report_window" cannot be specified, otherwise the source registration will fail.




"expiry" Optional

A string representing an expiry time in seconds for the attribution source, after which it will no longer be active (i.e., subsequent triggers won't be attributable to this source). The maximum allowable expiry time is 2592000 seconds (30 days), which is also the default value if "expiry" is not explicitly set.

"filter_data" Optional

An object defining custom data that can be used to filter which conversions generate reports. See Filters for more details.

"max_event_level_reports" Optional

A number between 0 and 20, inclusive, which specifies the total number of event-level reports this source can generate. After this maximum is reached, the source is no longer capable of producing any new data. If not specified, "max_event_level_reports" defaults to 3 for navigation-based sources and 1 for event-based (image- or script-based) sources.

"priority" Optional

A string representing a priority value for the attribution source. By default, conversions are attributed to the most recent matching source. For both event-level and summary reports you set a higher priority number to prioritize specific sources. For example, a value of 2 takes priority over the default value of 1. See Report priorities and limits for more information.

"trigger_data" Optional

An array of 32-bit unsigned integers representing data that describes the different trigger events that could match this source. For example, "user added item to shopping cart" or "user signed up to mailing list" could be actions happening at the trigger site that could match this source and indicate a conversion of some kind that the advertiser is trying to measure. These must be matched against "trigger_data" specified in triggers for event-level attribution to take place. If omitted, "trigger_data" defaults to [0, 1, 2, 3, 4, 5, 6, 7] for navigation-based sources and [0, 1] for event-based (image- or script-based) sources.

Note:
The values used to represent each event, and the number of elements in the array, are completely arbitrary and defined by you as the developer. The array may contain values that are not used, but values must be present in the array to be attributed to the source by the browser when a trigger is registered.


"trigger_data_matching" Optional

A string that specifies how the "trigger_data" from the trigger is matched against the source's "trigger_data". Possible values are:

"exact": The "trigger_data" from the trigger must exactly match a value contained in the source's "trigger_data"; if there is no such match, no event-level attribution takes place.
"modulus": In this case, the following calculation is performed — d % allowedValues.size — where d is the "trigger_data" from the trigger, and allowedValues is the sequence of values in the source's "trigger_data" array. If the result of this calculation matches a value in the source's "trigger_data" array, the match is a success. In such a case, the value will always match, unless allowedValues is empty.

"modulus" mode exists primarily for backwards compatibility with the API's behavior before "exact" was introduced, and as such, you'd be unlikely to use it. It is still useful in particular cases that require a very specific kind of compression resulting in smaller registration headers. This can be required when using complex filtering logic that needs to set different trigger data based on the source type according to the maximum number of source "trigger_data" items.

Note:
If "modulus" is used, the source's "trigger_data" must form a contiguous sequence of integers starting at 0. If the trigger data does not form such a sequence, an error occurs.

If not specified, "trigger_data_matching" defaults to "modulus". Again, the reason for this is backwards compatibility: omitting the "trigger_data_matching" field needs to result in the same behavior observed before this field was introduced.



ExamplesRegistering a source for an event-level reportA Node.js server might set the Attribution-Reporting-Register-Source response header as follows to make a browser generate an event-level report when a trigger is matched to a source:
jsres.set(
  "Attribution-Reporting-Register-Source",
  JSON.stringify({
    source_event_id: "412444888111012",
    destination: "https://shop.example",
    trigger_data: [0, 1, 2, 3, 4],
    trigger_data_matching: "exact",
    expiry: "604800",
    priority: "100",
    debug_key: "122939999",
    event_report_window: "86400",
  }),
);
Registering a source for a summary reportTo make the browser generate a summary report when a trigger is matched to a source, you need to include some extra fields, in addition to those required for event-level report generation.
jsres.set(
  "Attribution-Reporting-Register-Source",
  JSON.stringify({
    source_event_id: "412444888111012",
    destination: "https://shop.example",
    trigger_data: [0, 1, 2, 3, 4],
    trigger_data_matching: "exact",
    expiry: "604800",
    priority: "100",
    debug_key: "122939999",
    event_report_window: "86400",

    aggregation_keys: {
      campaignCounts: "0x159",
      geoValue: "0x5",
    },
    aggregatable_report_window: "86400",
  }),
);
SpecificationsSpecificationAttribution Reporting # parse-source-registration-jsonBrowser compatibilitySee also
Attribution-Reporting-Eligible
Attribution-Reporting-Register-Trigger
Attribution Reporting API
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Apr 3, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nAttribution-Reporting-Register-TriggerLimited availabilityThis feature is not Baseline because it does not work in some of the most widely-used browsers.Learn moreSee full compatibilityReport feedbackExperimental: This is an experimental technologyCheck the Browser compatibility table carefully before using this in production.
The HTTP Attribution-Reporting-Register-Trigger response header registers a page feature as an attribution trigger. This header is included as part of a response to a request that contains the Attribution-Reporting-Eligible header.
See the Attribution Reporting API for more details.

Note:
If the calling site does not have the Attribution Reporting API included in a successful privacy sandbox enrollment process, the Attribution-Reporting-Register-Trigger header is ignored and attribution triggers are not registered.


  
    
      Header type
      Response header
    
    
      Forbidden request header
      No
    
    
      
        CORS-safelisted response header
      
      No
    
  
SyntaxhttpAttribution-Reporting-Register-Trigger: <json-string>
Directives
<json-string>

A JSON string providing data that can be included in generated reports, such as the ID of the trigger, and priority and deduplication values. Available fields are as follows:

"aggregatable_trigger_data"

An array of objects, each one defining an aggregation key to apply to different source keys. Each object contains the following properties:

"key_piece"

A hexadecimal value representing a key.

"source_keys"

An array containing one or more key values for the data.



"aggregatable_values"

An object containing properties representing a value for each data point defined in "aggregatable_trigger_data". In each case, the property name is equal to the name defined in "source_keys", and the property value is whatever arbitrary value you require.

"debug_key" Optional

A number representing a debug key. Set this if you want to generate a debug report alongside the associated attribution report.

"debug_reporting" Optional

A boolean value. If a debug_key is set, set this to true to specify that the generated debug report should be a verbose debug report.

"filters" Optional

An object containing custom data that can be used to filter which triggers generate reports. See Filters for more details.

"event_trigger_data"

An object representing data about the trigger. Available sub-fields are as follows:

"trigger_data"

A string representing data that describes the trigger, which is typically used to indicate events such as "user added item to shopping cart" or "user signed up to mailing list". This value will be included in the generated event-level report, if any, although it will be subject to modification based on the attributed source's "trigger_data_matching" field.

Note:
The values used to represent each event, and the number of elements in the array, are completely arbitrary and defined by you as the developer. The array may contain values that are not used, but values must be present in the array to be attributed to the source by the browser when a trigger is registered.


"priority" Optional

A string representing a priority value for the attribution trigger. By default, triggers are attributed to the most recent matching source. For both event-level and summary reports you set a higher priority number to make the trigger match older sources. For example, a value of 2 takes priority over the default value of 1. See Report priorities and limits for more information.

"deduplication_key" Optional

A string representing a unique key that can be used to prevent attributions from being duplicated — for example if a user were to add the same item to a shopping cart multiple times. See Prevent duplication in reports for more information.

"filters" Optional

An object containing filters that perform selective filtering to set "trigger_data", "priority", and "deduplication_key" based on the filter_data set in a corresponding Attribution-Reporting-Register-Source header. See Filters for more information.





ExamplesRegistering a trigger for an event-level reportA Node.js server might set the Attribution-Reporting-Register-Trigger response header as follows to register a trigger intended to match an event-level report attribution source:
jsres.set(
  "Attribution-Reporting-Register-Trigger",
  JSON.stringify({
    event_trigger_data: [
      {
        trigger_data: "4",
        priority: "1000000000000",
        deduplication_key: "2345698765",
      },
    ],
    debug_key: "1115698977",
  }),
);
Registering a trigger for a summary reportWhen registering a trigger intended to match with a summary report attribution source, you need to include the following fields:
jsres.set(
  "Attribution-Reporting-Register-Trigger",
  JSON.stringify({
    aggregatable_trigger_data: [
      {
        key_piece: "0x400",
        source_keys: ["campaignCounts"],
      },
      {
        key_piece: "0xA80",
        source_keys: ["geoValue", "nonMatchingKeyIdsAreIgnored"],
      },
    ],
    aggregatable_values: {
      campaignCounts: 32768,
      geoValue: 1664,
    },
    debug_key: "1115698977",
  }),
);
SpecificationsSpecificationAttribution Reporting # create-an-attribution-triggerBrowser compatibilitySee also
Attribution-Reporting-Eligible
Attribution-Reporting-Register-Source
Attribution Reporting API\n\nAttribution-Reporting-Register-TriggerLimited availabilityThis feature is not Baseline because it does not work in some of the most widely-used browsers.Learn moreSee full compatibilityReport feedbackExperimental: This is an experimental technologyCheck the Browser compatibility table carefully before using this in production.
The HTTP Attribution-Reporting-Register-Trigger response header registers a page feature as an attribution trigger. This header is included as part of a response to a request that contains the Attribution-Reporting-Eligible header.
See the Attribution Reporting API for more details.

Note:
If the calling site does not have the Attribution Reporting API included in a successful privacy sandbox enrollment process, the Attribution-Reporting-Register-Trigger header is ignored and attribution triggers are not registered.


  
    
      Header type
      Response header
    
    
      Forbidden request header
      No
    
    
      
        CORS-safelisted response header
      
      No
    
  
SyntaxhttpAttribution-Reporting-Register-Trigger: <json-string>
Directives
<json-string>

A JSON string providing data that can be included in generated reports, such as the ID of the trigger, and priority and deduplication values. Available fields are as follows:

"aggregatable_trigger_data"

An array of objects, each one defining an aggregation key to apply to different source keys. Each object contains the following properties:

"key_piece"

A hexadecimal value representing a key.

"source_keys"

An array containing one or more key values for the data.



"aggregatable_values"

An object containing properties representing a value for each data point defined in "aggregatable_trigger_data". In each case, the property name is equal to the name defined in "source_keys", and the property value is whatever arbitrary value you require.

"debug_key" Optional

A number representing a debug key. Set this if you want to generate a debug report alongside the associated attribution report.

"debug_reporting" Optional

A boolean value. If a debug_key is set, set this to true to specify that the generated debug report should be a verbose debug report.

"filters" Optional

An object containing custom data that can be used to filter which triggers generate reports. See Filters for more details.

"event_trigger_data"

An object representing data about the trigger. Available sub-fields are as follows:

"trigger_data"

A string representing data that describes the trigger, which is typically used to indicate events such as "user added item to shopping cart" or "user signed up to mailing list". This value will be included in the generated event-level report, if any, although it will be subject to modification based on the attributed source's "trigger_data_matching" field.

Note:
The values used to represent each event, and the number of elements in the array, are completely arbitrary and defined by you as the developer. The array may contain values that are not used, but values must be present in the array to be attributed to the source by the browser when a trigger is registered.


"priority" Optional

A string representing a priority value for the attribution trigger. By default, triggers are attributed to the most recent matching source. For both event-level and summary reports you set a higher priority number to make the trigger match older sources. For example, a value of 2 takes priority over the default value of 1. See Report priorities and limits for more information.

"deduplication_key" Optional

A string representing a unique key that can be used to prevent attributions from being duplicated — for example if a user were to add the same item to a shopping cart multiple times. See Prevent duplication in reports for more information.

"filters" Optional

An object containing filters that perform selective filtering to set "trigger_data", "priority", and "deduplication_key" based on the filter_data set in a corresponding Attribution-Reporting-Register-Source header. See Filters for more information.





ExamplesRegistering a trigger for an event-level reportA Node.js server might set the Attribution-Reporting-Register-Trigger response header as follows to register a trigger intended to match an event-level report attribution source:
jsres.set(
  "Attribution-Reporting-Register-Trigger",
  JSON.stringify({
    event_trigger_data: [
      {
        trigger_data: "4",
        priority: "1000000000000",
        deduplication_key: "2345698765",
      },
    ],
    debug_key: "1115698977",
  }),
);
Registering a trigger for a summary reportWhen registering a trigger intended to match with a summary report attribution source, you need to include the following fields:
jsres.set(
  "Attribution-Reporting-Register-Trigger",
  JSON.stringify({
    aggregatable_trigger_data: [
      {
        key_piece: "0x400",
        source_keys: ["campaignCounts"],
      },
      {
        key_piece: "0xA80",
        source_keys: ["geoValue", "nonMatchingKeyIdsAreIgnored"],
      },
    ],
    aggregatable_values: {
      campaignCounts: 32768,
      geoValue: 1664,
    },
    debug_key: "1115698977",
  }),
);
SpecificationsSpecificationAttribution Reporting # create-an-attribution-triggerBrowser compatibilitySee also
Attribution-Reporting-Eligible
Attribution-Reporting-Register-Source
Attribution Reporting API
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Apr 4, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nAttribution-Reporting-Register-TriggerLimited availabilityThis feature is not Baseline because it does not work in some of the most widely-used browsers.Learn moreSee full compatibilityReport feedbackExperimental: This is an experimental technologyCheck the Browser compatibility table carefully before using this in production.
The HTTP Attribution-Reporting-Register-Trigger response header registers a page feature as an attribution trigger. This header is included as part of a response to a request that contains the Attribution-Reporting-Eligible header.
See the Attribution Reporting API for more details.

Note:
If the calling site does not have the Attribution Reporting API included in a successful privacy sandbox enrollment process, the Attribution-Reporting-Register-Trigger header is ignored and attribution triggers are not registered.


  
    
      Header type
      Response header
    
    
      Forbidden request header
      No
    
    
      
        CORS-safelisted response header
      
      No
    
  
SyntaxhttpAttribution-Reporting-Register-Trigger: <json-string>
Directives
<json-string>

A JSON string providing data that can be included in generated reports, such as the ID of the trigger, and priority and deduplication values. Available fields are as follows:

"aggregatable_trigger_data"

An array of objects, each one defining an aggregation key to apply to different source keys. Each object contains the following properties:

"key_piece"

A hexadecimal value representing a key.

"source_keys"

An array containing one or more key values for the data.



"aggregatable_values"

An object containing properties representing a value for each data point defined in "aggregatable_trigger_data". In each case, the property name is equal to the name defined in "source_keys", and the property value is whatever arbitrary value you require.

"debug_key" Optional

A number representing a debug key. Set this if you want to generate a debug report alongside the associated attribution report.

"debug_reporting" Optional

A boolean value. If a debug_key is set, set this to true to specify that the generated debug report should be a verbose debug report.

"filters" Optional

An object containing custom data that can be used to filter which triggers generate reports. See Filters for more details.

"event_trigger_data"

An object representing data about the trigger. Available sub-fields are as follows:

"trigger_data"

A string representing data that describes the trigger, which is typically used to indicate events such as "user added item to shopping cart" or "user signed up to mailing list". This value will be included in the generated event-level report, if any, although it will be subject to modification based on the attributed source's "trigger_data_matching" field.

Note:
The values used to represent each event, and the number of elements in the array, are completely arbitrary and defined by you as the developer. The array may contain values that are not used, but values must be present in the array to be attributed to the source by the browser when a trigger is registered.


"priority" Optional

A string representing a priority value for the attribution trigger. By default, triggers are attributed to the most recent matching source. For both event-level and summary reports you set a higher priority number to make the trigger match older sources. For example, a value of 2 takes priority over the default value of 1. See Report priorities and limits for more information.

"deduplication_key" Optional

A string representing a unique key that can be used to prevent attributions from being duplicated — for example if a user were to add the same item to a shopping cart multiple times. See Prevent duplication in reports for more information.

"filters" Optional

An object containing filters that perform selective filtering to set "trigger_data", "priority", and "deduplication_key" based on the filter_data set in a corresponding Attribution-Reporting-Register-Source header. See Filters for more information.





ExamplesRegistering a trigger for an event-level reportA Node.js server might set the Attribution-Reporting-Register-Trigger response header as follows to register a trigger intended to match an event-level report attribution source:
jsres.set(
  "Attribution-Reporting-Register-Trigger",
  JSON.stringify({
    event_trigger_data: [
      {
        trigger_data: "4",
        priority: "1000000000000",
        deduplication_key: "2345698765",
      },
    ],
    debug_key: "1115698977",
  }),
);
Registering a trigger for a summary reportWhen registering a trigger intended to match with a summary report attribution source, you need to include the following fields:
jsres.set(
  "Attribution-Reporting-Register-Trigger",
  JSON.stringify({
    aggregatable_trigger_data: [
      {
        key_piece: "0x400",
        source_keys: ["campaignCounts"],
      },
      {
        key_piece: "0xA80",
        source_keys: ["geoValue", "nonMatchingKeyIdsAreIgnored"],
      },
    ],
    aggregatable_values: {
      campaignCounts: 32768,
      geoValue: 1664,
    },
    debug_key: "1115698977",
  }),
);
SpecificationsSpecificationAttribution Reporting # create-an-attribution-triggerBrowser compatibilitySee also
Attribution-Reporting-Eligible
Attribution-Reporting-Register-Source
Attribution Reporting API
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Apr 4, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nAuthorizationBaseline Widely available *This feature is well established and works across many devices and browser versions. It’s been available across browsers since July 2015.* Some parts of this feature may have varying levels of support.Learn moreSee full compatibilityReport feedbackThe HTTP Authorization request header can be used to provide credentials that authenticate a user agent with a server, allowing access to protected resources.
The Authorization header is usually, but not always, sent after the user agent first attempts to request a protected resource without credentials.
The server responds with a 401 Unauthorized message that includes at least one WWW-Authenticate header.
This header indicates the authentication schemes that can be used to access the resource and any additional information needed by the client to use them.
The user-agent should select the most secure authentication scheme that it supports from those offered, prompt the user for their credentials, and then re-request the resource with the encoded credentials in the Authorization header.
This header is stripped from cross-origin redirects.

Note:
This header is part of the General HTTP authentication framework.
It can be used with a number of authentication schemes.


  
    
      Header type
      Request header
    
    
      Forbidden request header
      No
    
  
SyntaxhttpAuthorization: <auth-scheme> <authorization-parameters>

// Basic authentication
Authorization: Basic <credentials>

// Digest authentication
Authorization: Digest username=<username>,
    realm="<realm>",
    uri="<url>",
    algorithm=<algorithm>,
    nonce="<nonce>",
    nc=<nc>,
    cnonce="<cnonce>",
    qop=<qop>,
    response="<response>",
    opaque="<opaque>"
Directives
<auth-scheme>

The Authentication scheme that defines how the credentials are encoded.
Some of the more common types are (case-insensitive): Basic, Digest, Negotiate and AWS4-HMAC-SHA256.

Note:
For more information/options see HTTP Authentication > Authentication schemes



Other than <auth-scheme>, the remaining directives are specific to each authentication scheme.
Generally, you will need to check the relevant specifications for these (keys for a small subset of schemes are listed below).Basic authentication
<credentials>

The credentials, encoded according to the specified scheme.

Note:
For information about the encoding algorithm, see the examples: below, in WWW-Authenticate, in HTTP Authentication, and in the relevant specifications.


Digest authentication
<response>

A string of the hex digits that proves that the user knows a password.
The algorithm encodes the username and password, realm, cnonce, qop, nc, and so on.
It is described in detail in the specification.

username

A quoted string containing user's name for the specified realm in either plain text or the hash code in hexadecimal notation.
If the name contains characters that aren't allowed in the field, then username* can be used instead (not "as well").

username*

The user's name formatted using an extended notation defined in RFC5987.
This should be used only if the name can't be encoded in username and if userhash is set "false".

uri

The Effective Request URI. See the specification for more information.

realm

Realm of the requested username/password (again, should match the value in the corresponding WWW-Authenticate response for the resource being requested).

opaque

The value in the corresponding WWW-Authenticate response for the resource being requested.

algorithm

The algorithm used to calculate the digest. Must be a supported algorithm from the WWW-Authenticate response for the resource being requested.

qop

A token indicating the quality of protection applied to the message.
Must match the one value in the set specified in the WWW-Authenticate response for the resource being requested.

"auth": Authentication
"auth-int": Authentication with integrity protection


cnonce

An quoted ASCII-only string value provided by the client.
This is used by both the client and server to provide mutual authentication, provide some message integrity protection, and avoid "chosen plaintext
attacks".
See the specification for additional information.

nc

Nonce count. The hexadecimal count of requests in which the client has sent the current cnonce value (including the current request).
The server can use duplicate nc values to recognize replay requests.

userhash Optional

"true" if the username has been hashed. "false" by default.

ExamplesBasic authenticationFor Basic authentication, the credentials are constructed by first combining the username and the password with a colon (e.g., aladdin:opensesame), and then by encoding the resulting string in base64 (e.g., YWxhZGRpbjpvcGVuc2VzYW1l).
httpAuthorization: Basic YWxhZGRpbjpvcGVuc2VzYW1l


Warning: Base64-encoding can easily be reversed to obtain the original name and password, so Basic authentication offers no cryptographic security.
HTTPS is always recommended when using authentication, but is even more so when using Basic authentication.

See also HTTP authentication for examples on how to configure Apache or Nginx servers to password protect your site with HTTP basic authentication.SpecificationsSpecificationHTTP Semantics # field.authorizationBrowser compatibilitySee also
HTTP authentication
WWW-Authenticate
Proxy-Authorization
Proxy-Authenticate
401, 403, 407\n\nAuthorizationBaseline Widely available *This feature is well established and works across many devices and browser versions. It’s been available across browsers since July 2015.* Some parts of this feature may have varying levels of support.Learn moreSee full compatibilityReport feedbackThe HTTP Authorization request header can be used to provide credentials that authenticate a user agent with a server, allowing access to protected resources.
The Authorization header is usually, but not always, sent after the user agent first attempts to request a protected resource without credentials.
The server responds with a 401 Unauthorized message that includes at least one WWW-Authenticate header.
This header indicates the authentication schemes that can be used to access the resource and any additional information needed by the client to use them.
The user-agent should select the most secure authentication scheme that it supports from those offered, prompt the user for their credentials, and then re-request the resource with the encoded credentials in the Authorization header.
This header is stripped from cross-origin redirects.

Note:
This header is part of the General HTTP authentication framework.
It can be used with a number of authentication schemes.


  
    
      Header type
      Request header
    
    
      Forbidden request header
      No
    
  
SyntaxhttpAuthorization: <auth-scheme> <authorization-parameters>

// Basic authentication
Authorization: Basic <credentials>

// Digest authentication
Authorization: Digest username=<username>,
    realm="<realm>",
    uri="<url>",
    algorithm=<algorithm>,
    nonce="<nonce>",
    nc=<nc>,
    cnonce="<cnonce>",
    qop=<qop>,
    response="<response>",
    opaque="<opaque>"
Directives
<auth-scheme>

The Authentication scheme that defines how the credentials are encoded.
Some of the more common types are (case-insensitive): Basic, Digest, Negotiate and AWS4-HMAC-SHA256.

Note:
For more information/options see HTTP Authentication > Authentication schemes



Other than <auth-scheme>, the remaining directives are specific to each authentication scheme.
Generally, you will need to check the relevant specifications for these (keys for a small subset of schemes are listed below).Basic authentication
<credentials>

The credentials, encoded according to the specified scheme.

Note:
For information about the encoding algorithm, see the examples: below, in WWW-Authenticate, in HTTP Authentication, and in the relevant specifications.


Digest authentication
<response>

A string of the hex digits that proves that the user knows a password.
The algorithm encodes the username and password, realm, cnonce, qop, nc, and so on.
It is described in detail in the specification.

username

A quoted string containing user's name for the specified realm in either plain text or the hash code in hexadecimal notation.
If the name contains characters that aren't allowed in the field, then username* can be used instead (not "as well").

username*

The user's name formatted using an extended notation defined in RFC5987.
This should be used only if the name can't be encoded in username and if userhash is set "false".

uri

The Effective Request URI. See the specification for more information.

realm

Realm of the requested username/password (again, should match the value in the corresponding WWW-Authenticate response for the resource being requested).

opaque

The value in the corresponding WWW-Authenticate response for the resource being requested.

algorithm

The algorithm used to calculate the digest. Must be a supported algorithm from the WWW-Authenticate response for the resource being requested.

qop

A token indicating the quality of protection applied to the message.
Must match the one value in the set specified in the WWW-Authenticate response for the resource being requested.

"auth": Authentication
"auth-int": Authentication with integrity protection


cnonce

An quoted ASCII-only string value provided by the client.
This is used by both the client and server to provide mutual authentication, provide some message integrity protection, and avoid "chosen plaintext
attacks".
See the specification for additional information.

nc

Nonce count. The hexadecimal count of requests in which the client has sent the current cnonce value (including the current request).
The server can use duplicate nc values to recognize replay requests.

userhash Optional

"true" if the username has been hashed. "false" by default.

ExamplesBasic authenticationFor Basic authentication, the credentials are constructed by first combining the username and the password with a colon (e.g., aladdin:opensesame), and then by encoding the resulting string in base64 (e.g., YWxhZGRpbjpvcGVuc2VzYW1l).
httpAuthorization: Basic YWxhZGRpbjpvcGVuc2VzYW1l


Warning: Base64-encoding can easily be reversed to obtain the original name and password, so Basic authentication offers no cryptographic security.
HTTPS is always recommended when using authentication, but is even more so when using Basic authentication.

See also HTTP authentication for examples on how to configure Apache or Nginx servers to password protect your site with HTTP basic authentication.SpecificationsSpecificationHTTP Semantics # field.authorizationBrowser compatibilitySee also
HTTP authentication
WWW-Authenticate
Proxy-Authorization
Proxy-Authenticate
401, 403, 407
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nAuthorizationBaseline Widely available *This feature is well established and works across many devices and browser versions. It’s been available across browsers since July 2015.* Some parts of this feature may have varying levels of support.Learn moreSee full compatibilityReport feedbackThe HTTP Authorization request header can be used to provide credentials that authenticate a user agent with a server, allowing access to protected resources.
The Authorization header is usually, but not always, sent after the user agent first attempts to request a protected resource without credentials.
The server responds with a 401 Unauthorized message that includes at least one WWW-Authenticate header.
This header indicates the authentication schemes that can be used to access the resource and any additional information needed by the client to use them.
The user-agent should select the most secure authentication scheme that it supports from those offered, prompt the user for their credentials, and then re-request the resource with the encoded credentials in the Authorization header.
This header is stripped from cross-origin redirects.

Note:
This header is part of the General HTTP authentication framework.
It can be used with a number of authentication schemes.


  
    
      Header type
      Request header
    
    
      Forbidden request header
      No
    
  
SyntaxhttpAuthorization: <auth-scheme> <authorization-parameters>

// Basic authentication
Authorization: Basic <credentials>

// Digest authentication
Authorization: Digest username=<username>,
    realm="<realm>",
    uri="<url>",
    algorithm=<algorithm>,
    nonce="<nonce>",
    nc=<nc>,
    cnonce="<cnonce>",
    qop=<qop>,
    response="<response>",
    opaque="<opaque>"
Directives
<auth-scheme>

The Authentication scheme that defines how the credentials are encoded.
Some of the more common types are (case-insensitive): Basic, Digest, Negotiate and AWS4-HMAC-SHA256.

Note:
For more information/options see HTTP Authentication > Authentication schemes



Other than <auth-scheme>, the remaining directives are specific to each authentication scheme.
Generally, you will need to check the relevant specifications for these (keys for a small subset of schemes are listed below).Basic authentication
<credentials>

The credentials, encoded according to the specified scheme.

Note:
For information about the encoding algorithm, see the examples: below, in WWW-Authenticate, in HTTP Authentication, and in the relevant specifications.


Digest authentication
<response>

A string of the hex digits that proves that the user knows a password.
The algorithm encodes the username and password, realm, cnonce, qop, nc, and so on.
It is described in detail in the specification.

username

A quoted string containing user's name for the specified realm in either plain text or the hash code in hexadecimal notation.
If the name contains characters that aren't allowed in the field, then username* can be used instead (not "as well").

username*

The user's name formatted using an extended notation defined in RFC5987.
This should be used only if the name can't be encoded in username and if userhash is set "false".

uri

The Effective Request URI. See the specification for more information.

realm

Realm of the requested username/password (again, should match the value in the corresponding WWW-Authenticate response for the resource being requested).

opaque

The value in the corresponding WWW-Authenticate response for the resource being requested.

algorithm

The algorithm used to calculate the digest. Must be a supported algorithm from the WWW-Authenticate response for the resource being requested.

qop

A token indicating the quality of protection applied to the message.
Must match the one value in the set specified in the WWW-Authenticate response for the resource being requested.

"auth": Authentication
"auth-int": Authentication with integrity protection


cnonce

An quoted ASCII-only string value provided by the client.
This is used by both the client and server to provide mutual authentication, provide some message integrity protection, and avoid "chosen plaintext
attacks".
See the specification for additional information.

nc

Nonce count. The hexadecimal count of requests in which the client has sent the current cnonce value (including the current request).
The server can use duplicate nc values to recognize replay requests.

userhash Optional

"true" if the username has been hashed. "false" by default.

ExamplesBasic authenticationFor Basic authentication, the credentials are constructed by first combining the username and the password with a colon (e.g., aladdin:opensesame), and then by encoding the resulting string in base64 (e.g., YWxhZGRpbjpvcGVuc2VzYW1l).
httpAuthorization: Basic YWxhZGRpbjpvcGVuc2VzYW1l


Warning: Base64-encoding can easily be reversed to obtain the original name and password, so Basic authentication offers no cryptographic security.
HTTPS is always recommended when using authentication, but is even more so when using Basic authentication.

See also HTTP authentication for examples on how to configure Apache or Nginx servers to password protect your site with HTTP basic authentication.SpecificationsSpecificationHTTP Semantics # field.authorizationBrowser compatibilitySee also
HTTP authentication
WWW-Authenticate
Proxy-Authorization
Proxy-Authenticate
401, 403, 407
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nAvailable-DictionaryLimited availabilityThis feature is not Baseline because it does not work in some of the most widely-used browsers.Learn moreSee full compatibilityReport feedbackExperimental: This is an experimental technologyCheck the Browser compatibility table carefully before using this in production.
The HTTP Available-Dictionary request header allows the browser to specify the best matching dictionary it has to allow the server to use Compression Dictionary Transport for a resource request.
See the Compression Dictionary Transport guide for more information.SyntaxClients can send an Available-Dictionary header when they support dcb or dcz encodings. The header is a colon-surrounded base-64 encoded SHA-256 hash of the dictionary contents.
httpAvailable-Dictionary: :<base64-hash>:
Directives
<base64-hash>

A base-64 encoded SHA-256 hash of the dictionary contents.

ExampleshttpAccept-Encoding: gzip, br, zstd, dcb, dcz
Available-Dictionary: :pZGm1Av0IEBKARczz7exkNYsZb8LzaMrV7J32a2fFG4=:
SpecificationsSpecificationCompression Dictionary Transport # name-available-dictionaryBrowser compatibilitySee also
Compression Dictionary Transport guide
Use-As-Dictionary
Dictionary-ID\n\nAvailable-DictionaryLimited availabilityThis feature is not Baseline because it does not work in some of the most widely-used browsers.Learn moreSee full compatibilityReport feedbackExperimental: This is an experimental technologyCheck the Browser compatibility table carefully before using this in production.
The HTTP Available-Dictionary request header allows the browser to specify the best matching dictionary it has to allow the server to use Compression Dictionary Transport for a resource request.
See the Compression Dictionary Transport guide for more information.SyntaxClients can send an Available-Dictionary header when they support dcb or dcz encodings. The header is a colon-surrounded base-64 encoded SHA-256 hash of the dictionary contents.
httpAvailable-Dictionary: :<base64-hash>:
Directives
<base64-hash>

A base-64 encoded SHA-256 hash of the dictionary contents.

ExampleshttpAccept-Encoding: gzip, br, zstd, dcb, dcz
Available-Dictionary: :pZGm1Av0IEBKARczz7exkNYsZb8LzaMrV7J32a2fFG4=:
SpecificationsSpecificationCompression Dictionary Transport # name-available-dictionaryBrowser compatibilitySee also
Compression Dictionary Transport guide
Use-As-Dictionary
Dictionary-ID
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Apr 3, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nAvailable-DictionaryLimited availabilityThis feature is not Baseline because it does not work in some of the most widely-used browsers.Learn moreSee full compatibilityReport feedbackExperimental: This is an experimental technologyCheck the Browser compatibility table carefully before using this in production.
The HTTP Available-Dictionary request header allows the browser to specify the best matching dictionary it has to allow the server to use Compression Dictionary Transport for a resource request.
See the Compression Dictionary Transport guide for more information.SyntaxClients can send an Available-Dictionary header when they support dcb or dcz encodings. The header is a colon-surrounded base-64 encoded SHA-256 hash of the dictionary contents.
httpAvailable-Dictionary: :<base64-hash>:
Directives
<base64-hash>

A base-64 encoded SHA-256 hash of the dictionary contents.

ExampleshttpAccept-Encoding: gzip, br, zstd, dcb, dcz
Available-Dictionary: :pZGm1Av0IEBKARczz7exkNYsZb8LzaMrV7J32a2fFG4=:
SpecificationsSpecificationCompression Dictionary Transport # name-available-dictionaryBrowser compatibilitySee also
Compression Dictionary Transport guide
Use-As-Dictionary
Dictionary-ID
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Apr 3, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nCache-ControlBaseline Widely availableThis feature is well established and works across many devices and browser versions. It’s been available across browsers since July 2015.Learn moreSee full compatibilityReport feedbackThe HTTP Cache-Control header holds directives (instructions) in both requests and responses that control caching in browsers and shared caches (e.g., Proxies, CDNs).

  
    
      Header type
      
        Request header,
        Response header
      
    
    
      Forbidden request header
      No
    
    
      
        CORS-safelisted response header
      
      Yes
    
  
SyntaxCache directives follow these rules:

Caching directives are case-insensitive. However, lowercase is recommended because some implementations do not recognize uppercase directives.
Multiple directives are permitted and must be comma-separated (e.g., Cache-control: max-age=180, public).
Some directives have an optional argument. When an argument is provided, it is separated from the directive name by an equals symbol (=). Typically, arguments for the directives are integers and are therefore not enclosed in quote characters (e.g., Cache-control: max-age=12).
Cache directivesThe following table lists the standard Cache-Control directives:



Request
Response




max-age
max-age


max-stale
-


min-fresh
-


-
s-maxage


no-cache
no-cache


no-store
no-store


no-transform
no-transform


only-if-cached
-


-
must-revalidate


-
proxy-revalidate


-
must-understand


-
private


-
public


-
immutable


-
stale-while-revalidate


stale-if-error
stale-if-error



Note: Check the compatibility table for their support; user agents that don't recognize them should ignore them.VocabularyThis section defines the terms used in this document, some of which are from the specification.

(HTTP) cache

Implementation that holds requests and responses for reusing in subsequent requests. It can be either a shared cache or a private cache.

Shared cache

Cache that exists between the origin server and clients (e.g., Proxy, CDN). It stores a single response and reuses it with multiple users — so developers should avoid storing personalized contents to be cached in the shared cache.

Private cache

Cache that exists in the client. It is also called local cache or browser cache. It can store and reuse personalized content for a single user.

Store response

Store a response in caches when the response is cacheable. However, the cached response is not always reused as-is. (Usually, "cache" means storing a response.)

Reuse response

Reuse cached responses for subsequent requests.

Revalidate response

Ask the origin server whether or not the stored response is still fresh. Usually, the revalidation is done through a conditional request.

Fresh response

Indicates that the response is fresh. This usually means the response can be reused for subsequent requests, depending on request directives.

Stale response

Indicates that the response is a stale response. This usually means the response can't be reused as-is. Cache storage isn't required to remove stale responses immediately because revalidation could change the response from being stale to being fresh again.

Age

The time since a response was generated. It is a criterion for whether a response is fresh or stale.

DirectivesThis section lists directives that affect caching — both response directives and request directives.Response Directivesmax-age
The max-age=N response directive indicates that the response remains fresh until N seconds after the response is generated.
httpCache-Control: max-age=604800

Indicates that caches can store this response and reuse it for subsequent requests while it's fresh.
Note that max-age is not the elapsed time since the response was received; it is the elapsed time since the response was generated on the origin server.
So if the other cache(s) — on the network route taken by the response — store the response for 100 seconds (indicated using the Age response header field), the browser cache would deduct 100 seconds from its freshness lifetime.
If the max-age value is negative (for example, -1) or isn't an integer (for example, 3599.99), then the caching behavior is unspecified. Caches are encouraged to treat the value as if it were 0 (this is noted in the Calculating Freshness Lifetime section of the HTTP specification).
httpCache-Control: max-age=604800
Age: 100

s-maxage
The s-maxage response directive indicates how long the response remains fresh in a shared cache.
The s-maxage directive is ignored by private caches, and overrides the value specified by the max-age directive or the Expires header for shared caches, if they are present.
httpCache-Control: s-maxage=604800

no-cache
The no-cache response directive indicates that the response can be stored in caches, but the response must be validated with the origin server before each reuse, even when the cache is disconnected from the origin server.
httpCache-Control: no-cache

If you want caches to always check for content updates while reusing stored content, no-cache is the directive to use. It does this by requiring caches to revalidate each request with the origin server.
Note that no-cache does not mean "don't cache". no-cache allows caches to store a response but requires them to revalidate it before reuse. If the sense of "don't cache" that you want is actually "don't store", then no-store is the directive to use.
must-revalidate
The must-revalidate response directive indicates that the response can be stored in caches and can be reused while fresh. If the response becomes stale, it must be validated with the origin server before reuse.
Typically, must-revalidate is used with max-age.
httpCache-Control: max-age=604800, must-revalidate

HTTP allows caches to reuse stale responses when they are disconnected from the origin server. must-revalidate is a way to prevent this from happening - either the stored response is revalidated with the origin server or a 504 (Gateway Timeout) response is generated.
proxy-revalidate
The proxy-revalidate response directive is the equivalent of must-revalidate, but specifically for shared caches only.
no-store
The no-store response directive indicates that any caches of any kind (private or shared) should not store this response.
httpCache-Control: no-store

private
The private response directive indicates that the response can be stored only in a private cache (e.g., local caches in browsers).
httpCache-Control: private

You should add the private directive for user-personalized content, especially for responses received after login and for sessions managed via cookies.
If you forget to add private to a response with personalized content, then that response can be stored in a shared cache and end up being reused for multiple users, which can cause personal information to leak.
public
The public response directive indicates that the response can be stored in a shared cache. Responses for requests with Authorization header fields must not be stored in a shared cache; however, the public directive will cause such responses to be stored in a shared cache.
httpCache-Control: public

In general, when pages are under Basic Auth or Digest Auth, the browser sends requests with the Authorization header. This means that the response is access-controlled for restricted users (who have accounts), and it's fundamentally not shared-cacheable, even if it has max-age.
You can use the public directive to unlock that restriction.
httpCache-Control: public, max-age=604800

Note that s-maxage or must-revalidate also unlock that restriction.
If a request doesn't have an Authorization header, or you are already using s-maxage or must-revalidate in the response, then you don't need to use public.
must-understand
The must-understand response directive indicates that a cache should store the response only if it understands the requirements for caching based on status code.
must-understand should be coupled with no-store for fallback behavior.
httpCache-Control: must-understand, no-store

If a cache doesn't support must-understand, it will be ignored. If no-store is also present, the response isn't stored.
If a cache supports must-understand, it stores the response with an understanding of cache requirements based on its status code.
no-transform
Some intermediaries transform content for various reasons. For example, some convert images to reduce transfer size. In some cases, this is undesirable for the content provider.
no-transform indicates that any intermediary (regardless of whether it implements a cache) shouldn't transform the response contents.
immutable
The immutable response directive indicates that the response will not be updated while it's fresh.
httpCache-Control: public, max-age=604800, immutable

A modern best practice for static resources is to include version/hashes in their URLs, while never modifying the resources — but instead, when necessary, updating the resources with newer versions that have new version-numbers/hashes, so that their URLs are different. That's called the cache-busting pattern.
html<script src="https://example.com/react.0.0.0.js"></script>

When a user reloads the browser, the browser will send conditional requests for validating to the origin server. But it's not necessary to revalidate those kinds of static resources even when a user reloads the browser, because they're never modified.
immutable tells a cache that the response is immutable while it's fresh and avoids those kinds of unnecessary conditional requests to the server.
When you use a cache-busting pattern for resources and apply them to a long max-age, you can also add immutable to avoid revalidation.
stale-while-revalidate
The stale-while-revalidate response directive indicates that the cache could reuse a stale response while it revalidates it to a cache.
httpCache-Control: max-age=604800, stale-while-revalidate=86400

In the example above, the response is fresh for 7 days (604800s).
After 7 days it becomes stale, but the cache is allowed to reuse it for any requests that are made in the following day (86400s), provided that they revalidate the response in the background.
Revalidation will make the cache be fresh again, so it appears to clients that it was always fresh during that period — effectively hiding the latency penalty of revalidation from them.
If no request happened during that period, the cache became stale and the next request will revalidate normally.
stale-if-error
The stale-if-error response directive indicates that the cache can reuse a stale response when an upstream server generates an error, or when the error is generated locally. Here, an error is considered any response with a status code of 500, 502, 503, or 504.
httpCache-Control: max-age=604800, stale-if-error=86400

In the example above, the response is fresh for 7 days (604800s). Afterwards, it becomes stale, but can be used for an extra 1 day (86400s) when an error is encountered.
After the stale-if-error period passes, the client will receive any error generated.Request Directivesno-cache
The no-cache request directive asks caches to validate the response with the origin server before reuse.
httpCache-Control: no-cache

no-cache allows clients to request the most up-to-date response even if the cache has a fresh response.
Browsers usually add no-cache to requests when users are force reloading a page.
no-store
The no-store request directive allows a client to request that caches refrain from storing the request and corresponding response — even if the origin server's response could be stored.
httpCache-Control: no-store

max-age
The max-age=N request directive indicates that the client allows a stored response that is generated on the origin server within N seconds — where N may be any non-negative integer (including 0).
httpCache-Control: max-age=10800

In the case above, if the response with Cache-Control: max-age=10800 was generated more than 3 hours ago (calculated from max-age and the Age header), the cache couldn't reuse that response.
Many browsers use this directive for reloading, as explained below.
httpCache-Control: max-age=0

max-age=0 is a workaround for no-cache, because many old (HTTP/1.0) cache implementations don't support no-cache. Recently browsers are still using max-age=0 in "reloading" — for backward compatibility — and alternatively using no-cache to cause a "force reloading".
If the max-age value is negative (for example, -1) or isn't an integer (for example, 3599.99), then the caching behavior is unspecified. Caches are encouraged to treat the value as if it were 0.
max-stale
The max-stale=N request directive indicates that the client allows a stored response that is stale within N seconds.
If no N value is specified, the client will accept a stale response of any age.
httpCache-Control: max-stale=3600

For example, a request with the header above indicates that the browser will accept a stale response from the cache that has expired within the last hour.
Clients can use this header when the origin server is down or too slow and can accept cached responses from caches even if they are a bit old.
Note that the major browsers do not support requests with max-stale.
min-fresh
The min-fresh=N request directive indicates that the client allows a stored response that is fresh for at least N seconds.
httpCache-Control: min-fresh=600

In the case above, if the response with Cache-Control: max-age=3600 was stored in caches 51 minutes ago, the cache couldn't reuse that response.
Clients can use this header when the user requires the response to not only be fresh, but also requires that it won't be updated for a period of time.
Note that the major browsers do not support requests with min-fresh.
no-transform
Same meaning that no-transform has for a response, but for a request instead.
only-if-cached
The client indicates that an already-cached response should be returned. If a cache has a stored response, even a stale one, it will be returned. If no cached response is available, a 504 Gateway Timeout response will be returned.Use CasesPreventing storingIf you don't want a response stored in caches, use the no-store directive.
httpCache-Control: no-store

Note that no-cache means "it can be stored but don't reuse before validating" — so it's not for preventing a response from being stored.
httpCache-Control: no-cache

In theory, if directives are conflicted, the most restrictive directive should be honored. So the example below is basically meaningless because private, no-cache, max-age=0 and must-revalidate conflict with no-store.
http# conflicted
Cache-Control: private, no-cache, no-store, max-age=0, must-revalidate

# equivalent to
Cache-Control: no-store
Caching static assets with "cache busting"When you build static assets with versioning/hashing mechanisms, adding a version/hash to the filename or query string is a good way to manage caching.
For example:
html<!-- index.html -->
<script src="/assets/react.min.js"></script>
<img src="/assets/hero.png" width="900" height="400" />

The React library version will change when you update the library, and hero.png will also change when you edit the picture. So those are hard to store in a cache with max-age.
In such a case, you could address the caching needs by using a specific, numbered version of the library, and including the hash of the picture in its URL.
html<!-- index.html -->
<script src="/assets/react.0.0.0min.js"></script>
<img src="/assets/hero.png?hash=deadbeef" width="900" height="400" />

You can add a long max-age value and immutable because the content will never change.
http# /assets/*
Cache-Control: max-age=31536000, immutable

When you update the library or edit the picture, new content should have a new URL, and caches aren't reused. That is called the "cache busting" pattern.
Use a no-cache to make sure that the HTML response itself is not cached. no-cache could cause revalidation, and the client will correctly receive a new version of the HTML response and static assets.
http# /index.html
Cache-Control: no-cache

Note: If index.html is controlled under Basic Authentication or Digest Authentication, files under /assets are not stored in the shared cache. If /assets/ files are suitable for storing in a shared cache, you also need one of public, s-maxage or must-revalidate.Up-to-date contents alwaysFor content that's generated dynamically, or that's static but updated often, you want a user to always receive the most up-to-date version.
If you don't add a Cache-Control header because the response is not intended to be cached, that could cause an unexpected result. Cache storage is allowed to cache it heuristically — so if you have any requirements on caching, you should always indicate them explicitly, in the Cache-Control header.
Adding no-cache to the response causes revalidation to the server, so you can serve a fresh response every time — or if the client already has a new one, just respond 304 Not Modified.
httpCache-Control: no-cache

Most HTTP/1.0 caches don't support no-cache directives, so historically max-age=0 was used as a workaround. But only max-age=0 could cause a stale response to be reused when caches disconnected from the origin server. must-revalidate addresses that. That's why the example below is equivalent to no-cache.
httpCache-Control: max-age=0, must-revalidate

But for now, you can simply use no-cache instead.Clearing an already-stored cacheThere are no cache directives for clearing already-stored responses from caches on intermediate servers.
Imagine that clients/caches store a fresh response for a path, with no request flight to the server. There is nothing a server could do to that path.
Clear-Site-Data: cache can be used to clear every stored response for a site in the browser cache, so use this with care.
Note that this will not affected shared or intermediate caches.SpecificationsSpecificationHTTP Caching # field.cache-controlHTTP Immutable Responses # the-immutable-cache-control-extensionBrowser compatibilitySee also
HTTP caching
Caching Tutorial for Web Authors and Webmasters
Caching best practices & max-age gotchas
Cache-Control for Civilians
RFC 9111 – HTTP Caching
RFC 5861 – HTTP Cache-Control Extensions for Stale Content
RFC 8246 – HTTP Immutable Responses\n\nCache-ControlBaseline Widely availableThis feature is well established and works across many devices and browser versions. It’s been available across browsers since July 2015.Learn moreSee full compatibilityReport feedbackThe HTTP Cache-Control header holds directives (instructions) in both requests and responses that control caching in browsers and shared caches (e.g., Proxies, CDNs).

  
    
      Header type
      
        Request header,
        Response header
      
    
    
      Forbidden request header
      No
    
    
      
        CORS-safelisted response header
      
      Yes
    
  
SyntaxCache directives follow these rules:

Caching directives are case-insensitive. However, lowercase is recommended because some implementations do not recognize uppercase directives.
Multiple directives are permitted and must be comma-separated (e.g., Cache-control: max-age=180, public).
Some directives have an optional argument. When an argument is provided, it is separated from the directive name by an equals symbol (=). Typically, arguments for the directives are integers and are therefore not enclosed in quote characters (e.g., Cache-control: max-age=12).
Cache directivesThe following table lists the standard Cache-Control directives:



Request
Response




max-age
max-age


max-stale
-


min-fresh
-


-
s-maxage


no-cache
no-cache


no-store
no-store


no-transform
no-transform


only-if-cached
-


-
must-revalidate


-
proxy-revalidate


-
must-understand


-
private


-
public


-
immutable


-
stale-while-revalidate


stale-if-error
stale-if-error



Note: Check the compatibility table for their support; user agents that don't recognize them should ignore them.VocabularyThis section defines the terms used in this document, some of which are from the specification.

(HTTP) cache

Implementation that holds requests and responses for reusing in subsequent requests. It can be either a shared cache or a private cache.

Shared cache

Cache that exists between the origin server and clients (e.g., Proxy, CDN). It stores a single response and reuses it with multiple users — so developers should avoid storing personalized contents to be cached in the shared cache.

Private cache

Cache that exists in the client. It is also called local cache or browser cache. It can store and reuse personalized content for a single user.

Store response

Store a response in caches when the response is cacheable. However, the cached response is not always reused as-is. (Usually, "cache" means storing a response.)

Reuse response

Reuse cached responses for subsequent requests.

Revalidate response

Ask the origin server whether or not the stored response is still fresh. Usually, the revalidation is done through a conditional request.

Fresh response

Indicates that the response is fresh. This usually means the response can be reused for subsequent requests, depending on request directives.

Stale response

Indicates that the response is a stale response. This usually means the response can't be reused as-is. Cache storage isn't required to remove stale responses immediately because revalidation could change the response from being stale to being fresh again.

Age

The time since a response was generated. It is a criterion for whether a response is fresh or stale.

DirectivesThis section lists directives that affect caching — both response directives and request directives.Response Directivesmax-age
The max-age=N response directive indicates that the response remains fresh until N seconds after the response is generated.
httpCache-Control: max-age=604800

Indicates that caches can store this response and reuse it for subsequent requests while it's fresh.
Note that max-age is not the elapsed time since the response was received; it is the elapsed time since the response was generated on the origin server.
So if the other cache(s) — on the network route taken by the response — store the response for 100 seconds (indicated using the Age response header field), the browser cache would deduct 100 seconds from its freshness lifetime.
If the max-age value is negative (for example, -1) or isn't an integer (for example, 3599.99), then the caching behavior is unspecified. Caches are encouraged to treat the value as if it were 0 (this is noted in the Calculating Freshness Lifetime section of the HTTP specification).
httpCache-Control: max-age=604800
Age: 100

s-maxage
The s-maxage response directive indicates how long the response remains fresh in a shared cache.
The s-maxage directive is ignored by private caches, and overrides the value specified by the max-age directive or the Expires header for shared caches, if they are present.
httpCache-Control: s-maxage=604800

no-cache
The no-cache response directive indicates that the response can be stored in caches, but the response must be validated with the origin server before each reuse, even when the cache is disconnected from the origin server.
httpCache-Control: no-cache

If you want caches to always check for content updates while reusing stored content, no-cache is the directive to use. It does this by requiring caches to revalidate each request with the origin server.
Note that no-cache does not mean "don't cache". no-cache allows caches to store a response but requires them to revalidate it before reuse. If the sense of "don't cache" that you want is actually "don't store", then no-store is the directive to use.
must-revalidate
The must-revalidate response directive indicates that the response can be stored in caches and can be reused while fresh. If the response becomes stale, it must be validated with the origin server before reuse.
Typically, must-revalidate is used with max-age.
httpCache-Control: max-age=604800, must-revalidate

HTTP allows caches to reuse stale responses when they are disconnected from the origin server. must-revalidate is a way to prevent this from happening - either the stored response is revalidated with the origin server or a 504 (Gateway Timeout) response is generated.
proxy-revalidate
The proxy-revalidate response directive is the equivalent of must-revalidate, but specifically for shared caches only.
no-store
The no-store response directive indicates that any caches of any kind (private or shared) should not store this response.
httpCache-Control: no-store

private
The private response directive indicates that the response can be stored only in a private cache (e.g., local caches in browsers).
httpCache-Control: private

You should add the private directive for user-personalized content, especially for responses received after login and for sessions managed via cookies.
If you forget to add private to a response with personalized content, then that response can be stored in a shared cache and end up being reused for multiple users, which can cause personal information to leak.
public
The public response directive indicates that the response can be stored in a shared cache. Responses for requests with Authorization header fields must not be stored in a shared cache; however, the public directive will cause such responses to be stored in a shared cache.
httpCache-Control: public

In general, when pages are under Basic Auth or Digest Auth, the browser sends requests with the Authorization header. This means that the response is access-controlled for restricted users (who have accounts), and it's fundamentally not shared-cacheable, even if it has max-age.
You can use the public directive to unlock that restriction.
httpCache-Control: public, max-age=604800

Note that s-maxage or must-revalidate also unlock that restriction.
If a request doesn't have an Authorization header, or you are already using s-maxage or must-revalidate in the response, then you don't need to use public.
must-understand
The must-understand response directive indicates that a cache should store the response only if it understands the requirements for caching based on status code.
must-understand should be coupled with no-store for fallback behavior.
httpCache-Control: must-understand, no-store

If a cache doesn't support must-understand, it will be ignored. If no-store is also present, the response isn't stored.
If a cache supports must-understand, it stores the response with an understanding of cache requirements based on its status code.
no-transform
Some intermediaries transform content for various reasons. For example, some convert images to reduce transfer size. In some cases, this is undesirable for the content provider.
no-transform indicates that any intermediary (regardless of whether it implements a cache) shouldn't transform the response contents.
immutable
The immutable response directive indicates that the response will not be updated while it's fresh.
httpCache-Control: public, max-age=604800, immutable

A modern best practice for static resources is to include version/hashes in their URLs, while never modifying the resources — but instead, when necessary, updating the resources with newer versions that have new version-numbers/hashes, so that their URLs are different. That's called the cache-busting pattern.
html<script src="https://example.com/react.0.0.0.js"></script>

When a user reloads the browser, the browser will send conditional requests for validating to the origin server. But it's not necessary to revalidate those kinds of static resources even when a user reloads the browser, because they're never modified.
immutable tells a cache that the response is immutable while it's fresh and avoids those kinds of unnecessary conditional requests to the server.
When you use a cache-busting pattern for resources and apply them to a long max-age, you can also add immutable to avoid revalidation.
stale-while-revalidate
The stale-while-revalidate response directive indicates that the cache could reuse a stale response while it revalidates it to a cache.
httpCache-Control: max-age=604800, stale-while-revalidate=86400

In the example above, the response is fresh for 7 days (604800s).
After 7 days it becomes stale, but the cache is allowed to reuse it for any requests that are made in the following day (86400s), provided that they revalidate the response in the background.
Revalidation will make the cache be fresh again, so it appears to clients that it was always fresh during that period — effectively hiding the latency penalty of revalidation from them.
If no request happened during that period, the cache became stale and the next request will revalidate normally.
stale-if-error
The stale-if-error response directive indicates that the cache can reuse a stale response when an upstream server generates an error, or when the error is generated locally. Here, an error is considered any response with a status code of 500, 502, 503, or 504.
httpCache-Control: max-age=604800, stale-if-error=86400

In the example above, the response is fresh for 7 days (604800s). Afterwards, it becomes stale, but can be used for an extra 1 day (86400s) when an error is encountered.
After the stale-if-error period passes, the client will receive any error generated.Request Directivesno-cache
The no-cache request directive asks caches to validate the response with the origin server before reuse.
httpCache-Control: no-cache

no-cache allows clients to request the most up-to-date response even if the cache has a fresh response.
Browsers usually add no-cache to requests when users are force reloading a page.
no-store
The no-store request directive allows a client to request that caches refrain from storing the request and corresponding response — even if the origin server's response could be stored.
httpCache-Control: no-store

max-age
The max-age=N request directive indicates that the client allows a stored response that is generated on the origin server within N seconds — where N may be any non-negative integer (including 0).
httpCache-Control: max-age=10800

In the case above, if the response with Cache-Control: max-age=10800 was generated more than 3 hours ago (calculated from max-age and the Age header), the cache couldn't reuse that response.
Many browsers use this directive for reloading, as explained below.
httpCache-Control: max-age=0

max-age=0 is a workaround for no-cache, because many old (HTTP/1.0) cache implementations don't support no-cache. Recently browsers are still using max-age=0 in "reloading" — for backward compatibility — and alternatively using no-cache to cause a "force reloading".
If the max-age value is negative (for example, -1) or isn't an integer (for example, 3599.99), then the caching behavior is unspecified. Caches are encouraged to treat the value as if it were 0.
max-stale
The max-stale=N request directive indicates that the client allows a stored response that is stale within N seconds.
If no N value is specified, the client will accept a stale response of any age.
httpCache-Control: max-stale=3600

For example, a request with the header above indicates that the browser will accept a stale response from the cache that has expired within the last hour.
Clients can use this header when the origin server is down or too slow and can accept cached responses from caches even if they are a bit old.
Note that the major browsers do not support requests with max-stale.
min-fresh
The min-fresh=N request directive indicates that the client allows a stored response that is fresh for at least N seconds.
httpCache-Control: min-fresh=600

In the case above, if the response with Cache-Control: max-age=3600 was stored in caches 51 minutes ago, the cache couldn't reuse that response.
Clients can use this header when the user requires the response to not only be fresh, but also requires that it won't be updated for a period of time.
Note that the major browsers do not support requests with min-fresh.
no-transform
Same meaning that no-transform has for a response, but for a request instead.
only-if-cached
The client indicates that an already-cached response should be returned. If a cache has a stored response, even a stale one, it will be returned. If no cached response is available, a 504 Gateway Timeout response will be returned.Use CasesPreventing storingIf you don't want a response stored in caches, use the no-store directive.
httpCache-Control: no-store

Note that no-cache means "it can be stored but don't reuse before validating" — so it's not for preventing a response from being stored.
httpCache-Control: no-cache

In theory, if directives are conflicted, the most restrictive directive should be honored. So the example below is basically meaningless because private, no-cache, max-age=0 and must-revalidate conflict with no-store.
http# conflicted
Cache-Control: private, no-cache, no-store, max-age=0, must-revalidate

# equivalent to
Cache-Control: no-store
Caching static assets with "cache busting"When you build static assets with versioning/hashing mechanisms, adding a version/hash to the filename or query string is a good way to manage caching.
For example:
html<!-- index.html -->
<script src="/assets/react.min.js"></script>
<img src="/assets/hero.png" width="900" height="400" />

The React library version will change when you update the library, and hero.png will also change when you edit the picture. So those are hard to store in a cache with max-age.
In such a case, you could address the caching needs by using a specific, numbered version of the library, and including the hash of the picture in its URL.
html<!-- index.html -->
<script src="/assets/react.0.0.0min.js"></script>
<img src="/assets/hero.png?hash=deadbeef" width="900" height="400" />

You can add a long max-age value and immutable because the content will never change.
http# /assets/*
Cache-Control: max-age=31536000, immutable

When you update the library or edit the picture, new content should have a new URL, and caches aren't reused. That is called the "cache busting" pattern.
Use a no-cache to make sure that the HTML response itself is not cached. no-cache could cause revalidation, and the client will correctly receive a new version of the HTML response and static assets.
http# /index.html
Cache-Control: no-cache

Note: If index.html is controlled under Basic Authentication or Digest Authentication, files under /assets are not stored in the shared cache. If /assets/ files are suitable for storing in a shared cache, you also need one of public, s-maxage or must-revalidate.Up-to-date contents alwaysFor content that's generated dynamically, or that's static but updated often, you want a user to always receive the most up-to-date version.
If you don't add a Cache-Control header because the response is not intended to be cached, that could cause an unexpected result. Cache storage is allowed to cache it heuristically — so if you have any requirements on caching, you should always indicate them explicitly, in the Cache-Control header.
Adding no-cache to the response causes revalidation to the server, so you can serve a fresh response every time — or if the client already has a new one, just respond 304 Not Modified.
httpCache-Control: no-cache

Most HTTP/1.0 caches don't support no-cache directives, so historically max-age=0 was used as a workaround. But only max-age=0 could cause a stale response to be reused when caches disconnected from the origin server. must-revalidate addresses that. That's why the example below is equivalent to no-cache.
httpCache-Control: max-age=0, must-revalidate

But for now, you can simply use no-cache instead.Clearing an already-stored cacheThere are no cache directives for clearing already-stored responses from caches on intermediate servers.
Imagine that clients/caches store a fresh response for a path, with no request flight to the server. There is nothing a server could do to that path.
Clear-Site-Data: cache can be used to clear every stored response for a site in the browser cache, so use this with care.
Note that this will not affected shared or intermediate caches.SpecificationsSpecificationHTTP Caching # field.cache-controlHTTP Immutable Responses # the-immutable-cache-control-extensionBrowser compatibilitySee also
HTTP caching
Caching Tutorial for Web Authors and Webmasters
Caching best practices & max-age gotchas
Cache-Control for Civilians
RFC 9111 – HTTP Caching
RFC 5861 – HTTP Cache-Control Extensions for Stale Content
RFC 8246 – HTTP Immutable Responses
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Apr 3, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nCache-ControlBaseline Widely availableThis feature is well established and works across many devices and browser versions. It’s been available across browsers since July 2015.Learn moreSee full compatibilityReport feedbackThe HTTP Cache-Control header holds directives (instructions) in both requests and responses that control caching in browsers and shared caches (e.g., Proxies, CDNs).

  
    
      Header type
      
        Request header,
        Response header
      
    
    
      Forbidden request header
      No
    
    
      
        CORS-safelisted response header
      
      Yes
    
  
SyntaxCache directives follow these rules:

Caching directives are case-insensitive. However, lowercase is recommended because some implementations do not recognize uppercase directives.
Multiple directives are permitted and must be comma-separated (e.g., Cache-control: max-age=180, public).
Some directives have an optional argument. When an argument is provided, it is separated from the directive name by an equals symbol (=). Typically, arguments for the directives are integers and are therefore not enclosed in quote characters (e.g., Cache-control: max-age=12).
Cache directivesThe following table lists the standard Cache-Control directives:



Request
Response




max-age
max-age


max-stale
-


min-fresh
-


-
s-maxage


no-cache
no-cache


no-store
no-store


no-transform
no-transform


only-if-cached
-


-
must-revalidate


-
proxy-revalidate


-
must-understand


-
private


-
public


-
immutable


-
stale-while-revalidate


stale-if-error
stale-if-error



Note: Check the compatibility table for their support; user agents that don't recognize them should ignore them.VocabularyThis section defines the terms used in this document, some of which are from the specification.

(HTTP) cache

Implementation that holds requests and responses for reusing in subsequent requests. It can be either a shared cache or a private cache.

Shared cache

Cache that exists between the origin server and clients (e.g., Proxy, CDN). It stores a single response and reuses it with multiple users — so developers should avoid storing personalized contents to be cached in the shared cache.

Private cache

Cache that exists in the client. It is also called local cache or browser cache. It can store and reuse personalized content for a single user.

Store response

Store a response in caches when the response is cacheable. However, the cached response is not always reused as-is. (Usually, "cache" means storing a response.)

Reuse response

Reuse cached responses for subsequent requests.

Revalidate response

Ask the origin server whether or not the stored response is still fresh. Usually, the revalidation is done through a conditional request.

Fresh response

Indicates that the response is fresh. This usually means the response can be reused for subsequent requests, depending on request directives.

Stale response

Indicates that the response is a stale response. This usually means the response can't be reused as-is. Cache storage isn't required to remove stale responses immediately because revalidation could change the response from being stale to being fresh again.

Age

The time since a response was generated. It is a criterion for whether a response is fresh or stale.

DirectivesThis section lists directives that affect caching — both response directives and request directives.Response Directivesmax-age
The max-age=N response directive indicates that the response remains fresh until N seconds after the response is generated.
httpCache-Control: max-age=604800

Indicates that caches can store this response and reuse it for subsequent requests while it's fresh.
Note that max-age is not the elapsed time since the response was received; it is the elapsed time since the response was generated on the origin server.
So if the other cache(s) — on the network route taken by the response — store the response for 100 seconds (indicated using the Age response header field), the browser cache would deduct 100 seconds from its freshness lifetime.
If the max-age value is negative (for example, -1) or isn't an integer (for example, 3599.99), then the caching behavior is unspecified. Caches are encouraged to treat the value as if it were 0 (this is noted in the Calculating Freshness Lifetime section of the HTTP specification).
httpCache-Control: max-age=604800
Age: 100

s-maxage
The s-maxage response directive indicates how long the response remains fresh in a shared cache.
The s-maxage directive is ignored by private caches, and overrides the value specified by the max-age directive or the Expires header for shared caches, if they are present.
httpCache-Control: s-maxage=604800

no-cache
The no-cache response directive indicates that the response can be stored in caches, but the response must be validated with the origin server before each reuse, even when the cache is disconnected from the origin server.
httpCache-Control: no-cache

If you want caches to always check for content updates while reusing stored content, no-cache is the directive to use. It does this by requiring caches to revalidate each request with the origin server.
Note that no-cache does not mean "don't cache". no-cache allows caches to store a response but requires them to revalidate it before reuse. If the sense of "don't cache" that you want is actually "don't store", then no-store is the directive to use.
must-revalidate
The must-revalidate response directive indicates that the response can be stored in caches and can be reused while fresh. If the response becomes stale, it must be validated with the origin server before reuse.
Typically, must-revalidate is used with max-age.
httpCache-Control: max-age=604800, must-revalidate

HTTP allows caches to reuse stale responses when they are disconnected from the origin server. must-revalidate is a way to prevent this from happening - either the stored response is revalidated with the origin server or a 504 (Gateway Timeout) response is generated.
proxy-revalidate
The proxy-revalidate response directive is the equivalent of must-revalidate, but specifically for shared caches only.
no-store
The no-store response directive indicates that any caches of any kind (private or shared) should not store this response.
httpCache-Control: no-store

private
The private response directive indicates that the response can be stored only in a private cache (e.g., local caches in browsers).
httpCache-Control: private

You should add the private directive for user-personalized content, especially for responses received after login and for sessions managed via cookies.
If you forget to add private to a response with personalized content, then that response can be stored in a shared cache and end up being reused for multiple users, which can cause personal information to leak.
public
The public response directive indicates that the response can be stored in a shared cache. Responses for requests with Authorization header fields must not be stored in a shared cache; however, the public directive will cause such responses to be stored in a shared cache.
httpCache-Control: public

In general, when pages are under Basic Auth or Digest Auth, the browser sends requests with the Authorization header. This means that the response is access-controlled for restricted users (who have accounts), and it's fundamentally not shared-cacheable, even if it has max-age.
You can use the public directive to unlock that restriction.
httpCache-Control: public, max-age=604800

Note that s-maxage or must-revalidate also unlock that restriction.
If a request doesn't have an Authorization header, or you are already using s-maxage or must-revalidate in the response, then you don't need to use public.
must-understand
The must-understand response directive indicates that a cache should store the response only if it understands the requirements for caching based on status code.
must-understand should be coupled with no-store for fallback behavior.
httpCache-Control: must-understand, no-store

If a cache doesn't support must-understand, it will be ignored. If no-store is also present, the response isn't stored.
If a cache supports must-understand, it stores the response with an understanding of cache requirements based on its status code.
no-transform
Some intermediaries transform content for various reasons. For example, some convert images to reduce transfer size. In some cases, this is undesirable for the content provider.
no-transform indicates that any intermediary (regardless of whether it implements a cache) shouldn't transform the response contents.
immutable
The immutable response directive indicates that the response will not be updated while it's fresh.
httpCache-Control: public, max-age=604800, immutable

A modern best practice for static resources is to include version/hashes in their URLs, while never modifying the resources — but instead, when necessary, updating the resources with newer versions that have new version-numbers/hashes, so that their URLs are different. That's called the cache-busting pattern.
html<script src="https://example.com/react.0.0.0.js"></script>

When a user reloads the browser, the browser will send conditional requests for validating to the origin server. But it's not necessary to revalidate those kinds of static resources even when a user reloads the browser, because they're never modified.
immutable tells a cache that the response is immutable while it's fresh and avoids those kinds of unnecessary conditional requests to the server.
When you use a cache-busting pattern for resources and apply them to a long max-age, you can also add immutable to avoid revalidation.
stale-while-revalidate
The stale-while-revalidate response directive indicates that the cache could reuse a stale response while it revalidates it to a cache.
httpCache-Control: max-age=604800, stale-while-revalidate=86400

In the example above, the response is fresh for 7 days (604800s).
After 7 days it becomes stale, but the cache is allowed to reuse it for any requests that are made in the following day (86400s), provided that they revalidate the response in the background.
Revalidation will make the cache be fresh again, so it appears to clients that it was always fresh during that period — effectively hiding the latency penalty of revalidation from them.
If no request happened during that period, the cache became stale and the next request will revalidate normally.
stale-if-error
The stale-if-error response directive indicates that the cache can reuse a stale response when an upstream server generates an error, or when the error is generated locally. Here, an error is considered any response with a status code of 500, 502, 503, or 504.
httpCache-Control: max-age=604800, stale-if-error=86400

In the example above, the response is fresh for 7 days (604800s). Afterwards, it becomes stale, but can be used for an extra 1 day (86400s) when an error is encountered.
After the stale-if-error period passes, the client will receive any error generated.Request Directivesno-cache
The no-cache request directive asks caches to validate the response with the origin server before reuse.
httpCache-Control: no-cache

no-cache allows clients to request the most up-to-date response even if the cache has a fresh response.
Browsers usually add no-cache to requests when users are force reloading a page.
no-store
The no-store request directive allows a client to request that caches refrain from storing the request and corresponding response — even if the origin server's response could be stored.
httpCache-Control: no-store

max-age
The max-age=N request directive indicates that the client allows a stored response that is generated on the origin server within N seconds — where N may be any non-negative integer (including 0).
httpCache-Control: max-age=10800

In the case above, if the response with Cache-Control: max-age=10800 was generated more than 3 hours ago (calculated from max-age and the Age header), the cache couldn't reuse that response.
Many browsers use this directive for reloading, as explained below.
httpCache-Control: max-age=0

max-age=0 is a workaround for no-cache, because many old (HTTP/1.0) cache implementations don't support no-cache. Recently browsers are still using max-age=0 in "reloading" — for backward compatibility — and alternatively using no-cache to cause a "force reloading".
If the max-age value is negative (for example, -1) or isn't an integer (for example, 3599.99), then the caching behavior is unspecified. Caches are encouraged to treat the value as if it were 0.
max-stale
The max-stale=N request directive indicates that the client allows a stored response that is stale within N seconds.
If no N value is specified, the client will accept a stale response of any age.
httpCache-Control: max-stale=3600

For example, a request with the header above indicates that the browser will accept a stale response from the cache that has expired within the last hour.
Clients can use this header when the origin server is down or too slow and can accept cached responses from caches even if they are a bit old.
Note that the major browsers do not support requests with max-stale.
min-fresh
The min-fresh=N request directive indicates that the client allows a stored response that is fresh for at least N seconds.
httpCache-Control: min-fresh=600

In the case above, if the response with Cache-Control: max-age=3600 was stored in caches 51 minutes ago, the cache couldn't reuse that response.
Clients can use this header when the user requires the response to not only be fresh, but also requires that it won't be updated for a period of time.
Note that the major browsers do not support requests with min-fresh.
no-transform
Same meaning that no-transform has for a response, but for a request instead.
only-if-cached
The client indicates that an already-cached response should be returned. If a cache has a stored response, even a stale one, it will be returned. If no cached response is available, a 504 Gateway Timeout response will be returned.Use CasesPreventing storingIf you don't want a response stored in caches, use the no-store directive.
httpCache-Control: no-store

Note that no-cache means "it can be stored but don't reuse before validating" — so it's not for preventing a response from being stored.
httpCache-Control: no-cache

In theory, if directives are conflicted, the most restrictive directive should be honored. So the example below is basically meaningless because private, no-cache, max-age=0 and must-revalidate conflict with no-store.
http# conflicted
Cache-Control: private, no-cache, no-store, max-age=0, must-revalidate

# equivalent to
Cache-Control: no-store
Caching static assets with "cache busting"When you build static assets with versioning/hashing mechanisms, adding a version/hash to the filename or query string is a good way to manage caching.
For example:
html<!-- index.html -->
<script src="/assets/react.min.js"></script>
<img src="/assets/hero.png" width="900" height="400" />

The React library version will change when you update the library, and hero.png will also change when you edit the picture. So those are hard to store in a cache with max-age.
In such a case, you could address the caching needs by using a specific, numbered version of the library, and including the hash of the picture in its URL.
html<!-- index.html -->
<script src="/assets/react.0.0.0min.js"></script>
<img src="/assets/hero.png?hash=deadbeef" width="900" height="400" />

You can add a long max-age value and immutable because the content will never change.
http# /assets/*
Cache-Control: max-age=31536000, immutable

When you update the library or edit the picture, new content should have a new URL, and caches aren't reused. That is called the "cache busting" pattern.
Use a no-cache to make sure that the HTML response itself is not cached. no-cache could cause revalidation, and the client will correctly receive a new version of the HTML response and static assets.
http# /index.html
Cache-Control: no-cache

Note: If index.html is controlled under Basic Authentication or Digest Authentication, files under /assets are not stored in the shared cache. If /assets/ files are suitable for storing in a shared cache, you also need one of public, s-maxage or must-revalidate.Up-to-date contents alwaysFor content that's generated dynamically, or that's static but updated often, you want a user to always receive the most up-to-date version.
If you don't add a Cache-Control header because the response is not intended to be cached, that could cause an unexpected result. Cache storage is allowed to cache it heuristically — so if you have any requirements on caching, you should always indicate them explicitly, in the Cache-Control header.
Adding no-cache to the response causes revalidation to the server, so you can serve a fresh response every time — or if the client already has a new one, just respond 304 Not Modified.
httpCache-Control: no-cache

Most HTTP/1.0 caches don't support no-cache directives, so historically max-age=0 was used as a workaround. But only max-age=0 could cause a stale response to be reused when caches disconnected from the origin server. must-revalidate addresses that. That's why the example below is equivalent to no-cache.
httpCache-Control: max-age=0, must-revalidate

But for now, you can simply use no-cache instead.Clearing an already-stored cacheThere are no cache directives for clearing already-stored responses from caches on intermediate servers.
Imagine that clients/caches store a fresh response for a path, with no request flight to the server. There is nothing a server could do to that path.
Clear-Site-Data: cache can be used to clear every stored response for a site in the browser cache, so use this with care.
Note that this will not affected shared or intermediate caches.SpecificationsSpecificationHTTP Caching # field.cache-controlHTTP Immutable Responses # the-immutable-cache-control-extensionBrowser compatibilitySee also
HTTP caching
Caching Tutorial for Web Authors and Webmasters
Caching best practices & max-age gotchas
Cache-Control for Civilians
RFC 9111 – HTTP Caching
RFC 5861 – HTTP Cache-Control Extensions for Stale Content
RFC 8246 – HTTP Immutable Responses
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Apr 3, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nClear-Site-DataBaseline 2023 *Newly availableSince September 2023, this feature works across the latest devices and browser versions. This feature might not work in older devices or browsers.* Some parts of this feature may have varying levels of support.Learn moreSee full compatibilityReport feedbackSecure context: This feature is available only in secure contexts (HTTPS), in some or all supporting browsers.
The HTTP Clear-Site-Data response header sends a signal to the client that it should remove all browsing data of certain types (cookies, storage, cache) associated with the requesting website.
It allows web developers to have more control over the data stored by browsers for their origins.

  
    
      Header type
      Response header
    
    
      Forbidden request header
      No
    
  
Syntaxhttp// Single directive
Clear-Site-Data: "cache"

// Multiple directives (comma separated)
Clear-Site-Data: "cache", "cookies"

// Wild card
Clear-Site-Data: "*"
Directives
Note:
All directives must comply with the quoted-string grammar. A directive that does not include the double quotes is invalid.


"cache"

The server signals that the client should remove locally cached data (the browser cache, see HTTP caching) for the origin of the response URL. Depending on the browser, this might also clear out things like pre-rendered pages, script caches, WebGL shader caches, or address bar suggestions.

"clientHints" 
Experimental


Indicates that the server will remove all client hints (requested via Accept-CH) stored for the origin of the response URL.

Note:
In browsers that support the "clientHints" data type, client hints are also cleared when the "cache", "cookies", or "*" types are specified. "clientHints" is therefore only needed when none of those other types are specified.


"cookies"

The server signals that the client should remove all cookies for the origin of the response URL. HTTP authentication credentials are also cleared out. This affects the entire registered domain, including subdomains. So https://example.com as well as https://stage.example.com, will have cookies cleared.

"storage"

The server signals that the client should remove all DOM storage for the origin of the response URL. This includes storage mechanisms such as:

localStorage (executes localStorage.clear),
sessionStorage (executes sessionStorage.clear),
IndexedDB (for each database execute IDBFactory.deleteDatabase),
Service worker registrations (for each service worker registration, execute ServiceWorkerRegistration.unregister),
Web SQL databases (deprecated),
FileSystem API data,
Plugin data (Flash via NPP_ClearSiteData).


"executionContexts" 
Experimental


The server signals that the client should reload all browsing contexts for the origin of the response (Location.reload).

"*" (wildcard)

The server signals that the client should clear all types of data for the origin of the response. If more data types are added in future versions of this header, they will also be covered by it.

ExamplesSign out of a websiteIf a user signs out of your website or service, you might want to remove locally stored data. To do this, add the Clear-Site-Data header to the page that confirms the logging out from the site has been accomplished successfully (https://example.com/logout, for example):
httpClear-Site-Data: "cache", "cookies", "storage", "executionContexts"
Clearing cookiesIf this header is delivered with the response at https://example.com/clear-cookies, all cookies on the same domain https://example.com and any subdomains (like https://stage.example.com, etc.), will be cleared out.
httpClear-Site-Data: "cookies"
SpecificationsSpecificationClear Site Data # headerBrowser compatibilitySee also
Cache-Control\n\nClear-Site-DataBaseline 2023 *Newly availableSince September 2023, this feature works across the latest devices and browser versions. This feature might not work in older devices or browsers.* Some parts of this feature may have varying levels of support.Learn moreSee full compatibilityReport feedbackSecure context: This feature is available only in secure contexts (HTTPS), in some or all supporting browsers.
The HTTP Clear-Site-Data response header sends a signal to the client that it should remove all browsing data of certain types (cookies, storage, cache) associated with the requesting website.
It allows web developers to have more control over the data stored by browsers for their origins.

  
    
      Header type
      Response header
    
    
      Forbidden request header
      No
    
  
Syntaxhttp// Single directive
Clear-Site-Data: "cache"

// Multiple directives (comma separated)
Clear-Site-Data: "cache", "cookies"

// Wild card
Clear-Site-Data: "*"
Directives
Note:
All directives must comply with the quoted-string grammar. A directive that does not include the double quotes is invalid.


"cache"

The server signals that the client should remove locally cached data (the browser cache, see HTTP caching) for the origin of the response URL. Depending on the browser, this might also clear out things like pre-rendered pages, script caches, WebGL shader caches, or address bar suggestions.

"clientHints" 
Experimental


Indicates that the server will remove all client hints (requested via Accept-CH) stored for the origin of the response URL.

Note:
In browsers that support the "clientHints" data type, client hints are also cleared when the "cache", "cookies", or "*" types are specified. "clientHints" is therefore only needed when none of those other types are specified.


"cookies"

The server signals that the client should remove all cookies for the origin of the response URL. HTTP authentication credentials are also cleared out. This affects the entire registered domain, including subdomains. So https://example.com as well as https://stage.example.com, will have cookies cleared.

"storage"

The server signals that the client should remove all DOM storage for the origin of the response URL. This includes storage mechanisms such as:

localStorage (executes localStorage.clear),
sessionStorage (executes sessionStorage.clear),
IndexedDB (for each database execute IDBFactory.deleteDatabase),
Service worker registrations (for each service worker registration, execute ServiceWorkerRegistration.unregister),
Web SQL databases (deprecated),
FileSystem API data,
Plugin data (Flash via NPP_ClearSiteData).


"executionContexts" 
Experimental


The server signals that the client should reload all browsing contexts for the origin of the response (Location.reload).

"*" (wildcard)

The server signals that the client should clear all types of data for the origin of the response. If more data types are added in future versions of this header, they will also be covered by it.

ExamplesSign out of a websiteIf a user signs out of your website or service, you might want to remove locally stored data. To do this, add the Clear-Site-Data header to the page that confirms the logging out from the site has been accomplished successfully (https://example.com/logout, for example):
httpClear-Site-Data: "cache", "cookies", "storage", "executionContexts"
Clearing cookiesIf this header is delivered with the response at https://example.com/clear-cookies, all cookies on the same domain https://example.com and any subdomains (like https://stage.example.com, etc.), will be cleared out.
httpClear-Site-Data: "cookies"
SpecificationsSpecificationClear Site Data # headerBrowser compatibilitySee also
Cache-Control
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nClear-Site-DataBaseline 2023 *Newly availableSince September 2023, this feature works across the latest devices and browser versions. This feature might not work in older devices or browsers.* Some parts of this feature may have varying levels of support.Learn moreSee full compatibilityReport feedbackSecure context: This feature is available only in secure contexts (HTTPS), in some or all supporting browsers.
The HTTP Clear-Site-Data response header sends a signal to the client that it should remove all browsing data of certain types (cookies, storage, cache) associated with the requesting website.
It allows web developers to have more control over the data stored by browsers for their origins.

  
    
      Header type
      Response header
    
    
      Forbidden request header
      No
    
  
Syntaxhttp// Single directive
Clear-Site-Data: "cache"

// Multiple directives (comma separated)
Clear-Site-Data: "cache", "cookies"

// Wild card
Clear-Site-Data: "*"
Directives
Note:
All directives must comply with the quoted-string grammar. A directive that does not include the double quotes is invalid.


"cache"

The server signals that the client should remove locally cached data (the browser cache, see HTTP caching) for the origin of the response URL. Depending on the browser, this might also clear out things like pre-rendered pages, script caches, WebGL shader caches, or address bar suggestions.

"clientHints" 
Experimental


Indicates that the server will remove all client hints (requested via Accept-CH) stored for the origin of the response URL.

Note:
In browsers that support the "clientHints" data type, client hints are also cleared when the "cache", "cookies", or "*" types are specified. "clientHints" is therefore only needed when none of those other types are specified.


"cookies"

The server signals that the client should remove all cookies for the origin of the response URL. HTTP authentication credentials are also cleared out. This affects the entire registered domain, including subdomains. So https://example.com as well as https://stage.example.com, will have cookies cleared.

"storage"

The server signals that the client should remove all DOM storage for the origin of the response URL. This includes storage mechanisms such as:

localStorage (executes localStorage.clear),
sessionStorage (executes sessionStorage.clear),
IndexedDB (for each database execute IDBFactory.deleteDatabase),
Service worker registrations (for each service worker registration, execute ServiceWorkerRegistration.unregister),
Web SQL databases (deprecated),
FileSystem API data,
Plugin data (Flash via NPP_ClearSiteData).


"executionContexts" 
Experimental


The server signals that the client should reload all browsing contexts for the origin of the response (Location.reload).

"*" (wildcard)

The server signals that the client should clear all types of data for the origin of the response. If more data types are added in future versions of this header, they will also be covered by it.

ExamplesSign out of a websiteIf a user signs out of your website or service, you might want to remove locally stored data. To do this, add the Clear-Site-Data header to the page that confirms the logging out from the site has been accomplished successfully (https://example.com/logout, for example):
httpClear-Site-Data: "cache", "cookies", "storage", "executionContexts"
Clearing cookiesIf this header is delivered with the response at https://example.com/clear-cookies, all cookies on the same domain https://example.com and any subdomains (like https://stage.example.com, etc.), will be cleared out.
httpClear-Site-Data: "cookies"
SpecificationsSpecificationClear Site Data # headerBrowser compatibilitySee also
Cache-Control
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nConnectionBaseline Widely availableThis feature is well established and works across many devices and browser versions. It’s been available across browsers since July 2015.Learn moreSee full compatibilityReport feedbackThe HTTP Connection header controls whether the network connection stays open after the current transaction finishes.
If the value sent is keep-alive, the connection is persistent and not closed, allowing subsequent requests to the same server on the same connection.

Warning:
Connection-specific header fields such as
Connection and Keep-Alive are prohibited
in HTTP/2 and
HTTP/3. Chrome and
Firefox ignore them in HTTP/2 responses, but Safari conforms to the HTTP/2
spec requirements and does not load any response that contains them.

All hop-by-hop headers, including the standard hop-by-hop headers (Keep-Alive,
Transfer-Encoding, TE, Connection,
Trailer, Upgrade,
Proxy-Authorization, and Proxy-Authenticate) must be listed in the Connection
header, so that the first proxy knows it has to consume them and not forward them
further.
The default value of Connection changed between HTTP/1.0 and HTTP/1.1.
Therefore, to ensure backwards compatibility, browsers often send Connection: keep-alive explicitly, even though it's the default in HTTP/1.1.

  
    
      Header type
      
        Request header,
        Response header
      
    
    
      Forbidden request header
      Yes
    
  
SyntaxhttpConnection: keep-alive
Connection: close
Directives
close

Indicates that either the client or the server would like to close the connection.
This is the default on HTTP/1.0 requests.

any comma-separated list of HTTP headers (usually keep-alive only)

Indicates that the client would like to keep the connection open. Keeping a connection open
is the default on HTTP/1.1 requests. The list of headers are the
name of the header to be removed by the first non-transparent proxy or cache
in-between: these headers define the connection between the emitter and the first
entity, not the destination node.

SpecificationsSpecificationHTTP Semantics # field.connectionBrowser compatibilitySee also
Connection management in HTTP/1.x
Protocol upgrade mechanism\n\nConnectionBaseline Widely availableThis feature is well established and works across many devices and browser versions. It’s been available across browsers since July 2015.Learn moreSee full compatibilityReport feedbackThe HTTP Connection header controls whether the network connection stays open after the current transaction finishes.
If the value sent is keep-alive, the connection is persistent and not closed, allowing subsequent requests to the same server on the same connection.

Warning:
Connection-specific header fields such as
Connection and Keep-Alive are prohibited
in HTTP/2 and
HTTP/3. Chrome and
Firefox ignore them in HTTP/2 responses, but Safari conforms to the HTTP/2
spec requirements and does not load any response that contains them.

All hop-by-hop headers, including the standard hop-by-hop headers (Keep-Alive,
Transfer-Encoding, TE, Connection,
Trailer, Upgrade,
Proxy-Authorization, and Proxy-Authenticate) must be listed in the Connection
header, so that the first proxy knows it has to consume them and not forward them
further.
The default value of Connection changed between HTTP/1.0 and HTTP/1.1.
Therefore, to ensure backwards compatibility, browsers often send Connection: keep-alive explicitly, even though it's the default in HTTP/1.1.

  
    
      Header type
      
        Request header,
        Response header
      
    
    
      Forbidden request header
      Yes
    
  
SyntaxhttpConnection: keep-alive
Connection: close
Directives
close

Indicates that either the client or the server would like to close the connection.
This is the default on HTTP/1.0 requests.

any comma-separated list of HTTP headers (usually keep-alive only)

Indicates that the client would like to keep the connection open. Keeping a connection open
is the default on HTTP/1.1 requests. The list of headers are the
name of the header to be removed by the first non-transparent proxy or cache
in-between: these headers define the connection between the emitter and the first
entity, not the destination node.

SpecificationsSpecificationHTTP Semantics # field.connectionBrowser compatibilitySee also
Connection management in HTTP/1.x
Protocol upgrade mechanism
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nConnectionBaseline Widely availableThis feature is well established and works across many devices and browser versions. It’s been available across browsers since July 2015.Learn moreSee full compatibilityReport feedbackThe HTTP Connection header controls whether the network connection stays open after the current transaction finishes.
If the value sent is keep-alive, the connection is persistent and not closed, allowing subsequent requests to the same server on the same connection.

Warning:
Connection-specific header fields such as
Connection and Keep-Alive are prohibited
in HTTP/2 and
HTTP/3. Chrome and
Firefox ignore them in HTTP/2 responses, but Safari conforms to the HTTP/2
spec requirements and does not load any response that contains them.

All hop-by-hop headers, including the standard hop-by-hop headers (Keep-Alive,
Transfer-Encoding, TE, Connection,
Trailer, Upgrade,
Proxy-Authorization, and Proxy-Authenticate) must be listed in the Connection
header, so that the first proxy knows it has to consume them and not forward them
further.
The default value of Connection changed between HTTP/1.0 and HTTP/1.1.
Therefore, to ensure backwards compatibility, browsers often send Connection: keep-alive explicitly, even though it's the default in HTTP/1.1.

  
    
      Header type
      
        Request header,
        Response header
      
    
    
      Forbidden request header
      Yes
    
  
SyntaxhttpConnection: keep-alive
Connection: close
Directives
close

Indicates that either the client or the server would like to close the connection.
This is the default on HTTP/1.0 requests.

any comma-separated list of HTTP headers (usually keep-alive only)

Indicates that the client would like to keep the connection open. Keeping a connection open
is the default on HTTP/1.1 requests. The list of headers are the
name of the header to be removed by the first non-transparent proxy or cache
in-between: these headers define the connection between the emitter and the first
entity, not the destination node.

SpecificationsSpecificationHTTP Semantics # field.connectionBrowser compatibilitySee also
Connection management in HTTP/1.x
Protocol upgrade mechanism
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nContent-DigestThe HTTP Content-Digest request and response header provides a digest calculated using a hashing algorithm applied to the message content.
A recipient can use the Content-Digest to validate the HTTP message content for integrity purposes.
The Want-Content-Digest field lets a sender request a Content-Digest along with their hashing algorithm preferences.
A content digest will differ based on Content-Encoding and Content-Range, but not Transfer-Encoding.
In certain cases, a Repr-Digest can be used to validate the integrity of partial or multipart messages against the full representation.
For example, in range requests, a Repr-Digest will always have the same value if only the requested byte ranges differ, whereas the content digest will be different for each part.
For this reason, a Content-Digest is identical to a Repr-Digest when a representation is sent in a single message.

  
    
      Header type
      Request header, Response header, Representation header
    
    
      Forbidden request header
      No
    
  
SyntaxhttpContent-Digest: <digest-algorithm>=<digest-value>

// Multiple digest algorithms
Content-Digest: <digest-algorithm>=<digest-value>,<digest-algorithm>=<digest-value>, …
Directives
<digest-algorithm>

The algorithm used to create a digest of the message content.
Only two registered digest algorithms are considered secure: sha-512 and sha-256.
The insecure (legacy) registered digest algorithms are: md5, sha (SHA-1), unixsum, unixcksum, adler (ADLER32) and crc32c.

<digest-value>

The digest in bytes of the message content using the <digest-algorithm>.
The choice of digest algorithm also determines the encoding to use: sha-512 and sha-256 use base64 encoding, while some legacy digest algorithms such as unixsum use a decimal integer.
In contrast to earlier drafts of the specification, the standard base64-encoded digest bytes are wrapped in colons (:, ASCII 0x3A) as part of the dictionary syntax.

DescriptionA Digest header was defined in previous specifications, but it proved problematic as the scope of what the digest applied to was not clear.
Specifically, it was difficult to distinguish whether a digest applied to the entire resource representation or to the specific content of a HTTP message.
As such, two separate headers were specified (Content-Digest and Repr-Digest) to convey HTTP message content digests and resource representation digests, respectively.ExamplesUser-agent request for a SHA-256 Content-DigestIn the following example, a user-agent requests a digest of the message content with a preference for SHA-256, followed by SHA-1 at a lower preference:
httpGET /items/123 HTTP/1.1
Host: example.com
Want-Content-Digest: sha-256=10, sha=3

The server responds with a Content-Digest of the message content using the SHA-256 algorithm:
httpHTTP/1.1 200 OK
Content-Type: application/json
Content-Digest: sha-256=:RK/0qy18MlBSVnWgjwz6lZEWjP/lF5HF9bvEF8FabDg=:

{"hello": "world"}
Identical Content-Digest and Repr-Digest valuesA user-agent requests a resource without a Want-Content-Digest field:
httpGET /items/123 HTTP/1.1
Host: example.com

The server is configured to send unsolicited digest headers in responses.
The Repr-Digest and Content-Digest fields have matching values because they are using the same algorithm, and in this case the whole resource is sent in one message:
httpHTTP/1.1 200 OK
Content-Type: application/json
Content-Length: 19
Content-Digest: sha-256=:RK/0qy18MlBSVnWgjwz6lZEWjP/lF5HF9bvEF8FabDg=:
Repr-Digest: sha-256=:RK/0qy18MlBSVnWgjwz6lZEWjP/lF5HF9bvEF8FabDg=:

{"hello": "world"}
Diverging Content-Digest and Repr-Digest valuesIf the same request is repeated as the previous example, but uses a HEAD method instead of a GET, the Repr-Digest and Content-Digest fields will be different:
httpGET /items/123 HTTP/1.1
Host: example.com

The Repr-Digest value will be the same as before, but there is no message body, so a different Content-Digest would be sent by the server:
httpHTTP/1.1 200 OK
Content-Type: application/json
Content-Digest: sha-256=:47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=:
Repr-Digest: sha-256=:RK/0qy18MlBSVnWgjwz6lZEWjP/lF5HF9bvEF8FabDg=:
User-agent sending a Content-Digest in requestsIn the following example, a user-agent sends a digest of the message content using SHA-512.
It sends both a Content-Digest and a Repr-Digest, which differ from each other because of the Content-Encoding:
httpPOST /bank_transfer HTTP/1.1
Host: example.com
Content-Encoding: zstd
Content-Digest: sha-512=:ABC…=:
Repr-Digest: sha-512=:DEF…=:

{
 "recipient": "Alex",
 "amount": 900000000
}

The server may calculate a digest of the content it has received and compare the result with the Content-Digest or Repr-Digest headers to validate the message integrity.
In requests like the example above, the Repr-Digest is more useful to the server as this is calculated over the decoded representation and would be more consistent in different scenarios.SpecificationsSpecificationDigest Fields # section-2Browser compatibilityThis header has no specification-defined browser integration ("browser compatibility" does not apply).
Developers can set and get HTTP headers using fetch() in order to provide application-specific implementation behavior.See also
Want-Content-Digest header to request a content digest
Repr-Digest, Want-Repr-Digest representation digest headers
ETag
Digital Signatures for APIs SDK guide uses Content-Digests for digital signatures in HTTP calls (developer.ebay.com)\n\nContent-DigestThe HTTP Content-Digest request and response header provides a digest calculated using a hashing algorithm applied to the message content.
A recipient can use the Content-Digest to validate the HTTP message content for integrity purposes.
The Want-Content-Digest field lets a sender request a Content-Digest along with their hashing algorithm preferences.
A content digest will differ based on Content-Encoding and Content-Range, but not Transfer-Encoding.
In certain cases, a Repr-Digest can be used to validate the integrity of partial or multipart messages against the full representation.
For example, in range requests, a Repr-Digest will always have the same value if only the requested byte ranges differ, whereas the content digest will be different for each part.
For this reason, a Content-Digest is identical to a Repr-Digest when a representation is sent in a single message.

  
    
      Header type
      Request header, Response header, Representation header
    
    
      Forbidden request header
      No
    
  
SyntaxhttpContent-Digest: <digest-algorithm>=<digest-value>

// Multiple digest algorithms
Content-Digest: <digest-algorithm>=<digest-value>,<digest-algorithm>=<digest-value>, …
Directives
<digest-algorithm>

The algorithm used to create a digest of the message content.
Only two registered digest algorithms are considered secure: sha-512 and sha-256.
The insecure (legacy) registered digest algorithms are: md5, sha (SHA-1), unixsum, unixcksum, adler (ADLER32) and crc32c.

<digest-value>

The digest in bytes of the message content using the <digest-algorithm>.
The choice of digest algorithm also determines the encoding to use: sha-512 and sha-256 use base64 encoding, while some legacy digest algorithms such as unixsum use a decimal integer.
In contrast to earlier drafts of the specification, the standard base64-encoded digest bytes are wrapped in colons (:, ASCII 0x3A) as part of the dictionary syntax.

DescriptionA Digest header was defined in previous specifications, but it proved problematic as the scope of what the digest applied to was not clear.
Specifically, it was difficult to distinguish whether a digest applied to the entire resource representation or to the specific content of a HTTP message.
As such, two separate headers were specified (Content-Digest and Repr-Digest) to convey HTTP message content digests and resource representation digests, respectively.ExamplesUser-agent request for a SHA-256 Content-DigestIn the following example, a user-agent requests a digest of the message content with a preference for SHA-256, followed by SHA-1 at a lower preference:
httpGET /items/123 HTTP/1.1
Host: example.com
Want-Content-Digest: sha-256=10, sha=3

The server responds with a Content-Digest of the message content using the SHA-256 algorithm:
httpHTTP/1.1 200 OK
Content-Type: application/json
Content-Digest: sha-256=:RK/0qy18MlBSVnWgjwz6lZEWjP/lF5HF9bvEF8FabDg=:

{"hello": "world"}
Identical Content-Digest and Repr-Digest valuesA user-agent requests a resource without a Want-Content-Digest field:
httpGET /items/123 HTTP/1.1
Host: example.com

The server is configured to send unsolicited digest headers in responses.
The Repr-Digest and Content-Digest fields have matching values because they are using the same algorithm, and in this case the whole resource is sent in one message:
httpHTTP/1.1 200 OK
Content-Type: application/json
Content-Length: 19
Content-Digest: sha-256=:RK/0qy18MlBSVnWgjwz6lZEWjP/lF5HF9bvEF8FabDg=:
Repr-Digest: sha-256=:RK/0qy18MlBSVnWgjwz6lZEWjP/lF5HF9bvEF8FabDg=:

{"hello": "world"}
Diverging Content-Digest and Repr-Digest valuesIf the same request is repeated as the previous example, but uses a HEAD method instead of a GET, the Repr-Digest and Content-Digest fields will be different:
httpGET /items/123 HTTP/1.1
Host: example.com

The Repr-Digest value will be the same as before, but there is no message body, so a different Content-Digest would be sent by the server:
httpHTTP/1.1 200 OK
Content-Type: application/json
Content-Digest: sha-256=:47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=:
Repr-Digest: sha-256=:RK/0qy18MlBSVnWgjwz6lZEWjP/lF5HF9bvEF8FabDg=:
User-agent sending a Content-Digest in requestsIn the following example, a user-agent sends a digest of the message content using SHA-512.
It sends both a Content-Digest and a Repr-Digest, which differ from each other because of the Content-Encoding:
httpPOST /bank_transfer HTTP/1.1
Host: example.com
Content-Encoding: zstd
Content-Digest: sha-512=:ABC…=:
Repr-Digest: sha-512=:DEF…=:

{
 "recipient": "Alex",
 "amount": 900000000
}

The server may calculate a digest of the content it has received and compare the result with the Content-Digest or Repr-Digest headers to validate the message integrity.
In requests like the example above, the Repr-Digest is more useful to the server as this is calculated over the decoded representation and would be more consistent in different scenarios.SpecificationsSpecificationDigest Fields # section-2Browser compatibilityThis header has no specification-defined browser integration ("browser compatibility" does not apply).
Developers can set and get HTTP headers using fetch() in order to provide application-specific implementation behavior.See also
Want-Content-Digest header to request a content digest
Repr-Digest, Want-Repr-Digest representation digest headers
ETag
Digital Signatures for APIs SDK guide uses Content-Digests for digital signatures in HTTP calls (developer.ebay.com)
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 30, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nContent-DigestThe HTTP Content-Digest request and response header provides a digest calculated using a hashing algorithm applied to the message content.
A recipient can use the Content-Digest to validate the HTTP message content for integrity purposes.
The Want-Content-Digest field lets a sender request a Content-Digest along with their hashing algorithm preferences.
A content digest will differ based on Content-Encoding and Content-Range, but not Transfer-Encoding.
In certain cases, a Repr-Digest can be used to validate the integrity of partial or multipart messages against the full representation.
For example, in range requests, a Repr-Digest will always have the same value if only the requested byte ranges differ, whereas the content digest will be different for each part.
For this reason, a Content-Digest is identical to a Repr-Digest when a representation is sent in a single message.

  
    
      Header type
      Request header, Response header, Representation header
    
    
      Forbidden request header
      No
    
  
SyntaxhttpContent-Digest: <digest-algorithm>=<digest-value>

// Multiple digest algorithms
Content-Digest: <digest-algorithm>=<digest-value>,<digest-algorithm>=<digest-value>, …
Directives
<digest-algorithm>

The algorithm used to create a digest of the message content.
Only two registered digest algorithms are considered secure: sha-512 and sha-256.
The insecure (legacy) registered digest algorithms are: md5, sha (SHA-1), unixsum, unixcksum, adler (ADLER32) and crc32c.

<digest-value>

The digest in bytes of the message content using the <digest-algorithm>.
The choice of digest algorithm also determines the encoding to use: sha-512 and sha-256 use base64 encoding, while some legacy digest algorithms such as unixsum use a decimal integer.
In contrast to earlier drafts of the specification, the standard base64-encoded digest bytes are wrapped in colons (:, ASCII 0x3A) as part of the dictionary syntax.

DescriptionA Digest header was defined in previous specifications, but it proved problematic as the scope of what the digest applied to was not clear.
Specifically, it was difficult to distinguish whether a digest applied to the entire resource representation or to the specific content of a HTTP message.
As such, two separate headers were specified (Content-Digest and Repr-Digest) to convey HTTP message content digests and resource representation digests, respectively.ExamplesUser-agent request for a SHA-256 Content-DigestIn the following example, a user-agent requests a digest of the message content with a preference for SHA-256, followed by SHA-1 at a lower preference:
httpGET /items/123 HTTP/1.1
Host: example.com
Want-Content-Digest: sha-256=10, sha=3

The server responds with a Content-Digest of the message content using the SHA-256 algorithm:
httpHTTP/1.1 200 OK
Content-Type: application/json
Content-Digest: sha-256=:RK/0qy18MlBSVnWgjwz6lZEWjP/lF5HF9bvEF8FabDg=:

{"hello": "world"}
Identical Content-Digest and Repr-Digest valuesA user-agent requests a resource without a Want-Content-Digest field:
httpGET /items/123 HTTP/1.1
Host: example.com

The server is configured to send unsolicited digest headers in responses.
The Repr-Digest and Content-Digest fields have matching values because they are using the same algorithm, and in this case the whole resource is sent in one message:
httpHTTP/1.1 200 OK
Content-Type: application/json
Content-Length: 19
Content-Digest: sha-256=:RK/0qy18MlBSVnWgjwz6lZEWjP/lF5HF9bvEF8FabDg=:
Repr-Digest: sha-256=:RK/0qy18MlBSVnWgjwz6lZEWjP/lF5HF9bvEF8FabDg=:

{"hello": "world"}
Diverging Content-Digest and Repr-Digest valuesIf the same request is repeated as the previous example, but uses a HEAD method instead of a GET, the Repr-Digest and Content-Digest fields will be different:
httpGET /items/123 HTTP/1.1
Host: example.com

The Repr-Digest value will be the same as before, but there is no message body, so a different Content-Digest would be sent by the server:
httpHTTP/1.1 200 OK
Content-Type: application/json
Content-Digest: sha-256=:47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=:
Repr-Digest: sha-256=:RK/0qy18MlBSVnWgjwz6lZEWjP/lF5HF9bvEF8FabDg=:
User-agent sending a Content-Digest in requestsIn the following example, a user-agent sends a digest of the message content using SHA-512.
It sends both a Content-Digest and a Repr-Digest, which differ from each other because of the Content-Encoding:
httpPOST /bank_transfer HTTP/1.1
Host: example.com
Content-Encoding: zstd
Content-Digest: sha-512=:ABC…=:
Repr-Digest: sha-512=:DEF…=:

{
 "recipient": "Alex",
 "amount": 900000000
}

The server may calculate a digest of the content it has received and compare the result with the Content-Digest or Repr-Digest headers to validate the message integrity.
In requests like the example above, the Repr-Digest is more useful to the server as this is calculated over the decoded representation and would be more consistent in different scenarios.SpecificationsSpecificationDigest Fields # section-2Browser compatibilityThis header has no specification-defined browser integration ("browser compatibility" does not apply).
Developers can set and get HTTP headers using fetch() in order to provide application-specific implementation behavior.See also
Want-Content-Digest header to request a content digest
Repr-Digest, Want-Repr-Digest representation digest headers
ETag
Digital Signatures for APIs SDK guide uses Content-Digests for digital signatures in HTTP calls (developer.ebay.com)
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 30, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nContent-DispositionBaseline Widely availableThis feature is well established and works across many devices and browser versions. It’s been available across browsers since July 2015.Learn moreSee full compatibilityReport feedbackThe HTTP Content-Disposition header indicates whether content should be displayed inline in the browser as a web page or part of a web page or downloaded as an attachment locally.
In a multipart body, the header must be used on each subpart to provide information about its corresponding field. The subpart is delimited by the boundary defined in the Content-Type header. When used on the body itself, Content-Disposition has no effect.
The Content-Disposition header is defined in the larger context of MIME messages for email, but only a subset of the possible parameters apply to HTTP forms and POST requests. Only the value form-data, as well as the optional directive name and filename, can be used in the HTTP context.

  
    
      Header type
      
        Response header (for the main body),Request header,
        Response header (for a subpart of a multipart body)
      
    
    
      Forbidden request header
      No
    
  
SyntaxAs a response header for the main bodyThe first parameter in the HTTP context is either inline (default value, indicating it can be displayed inside the Web page, or as the Web page) or attachment (indicating it should be downloaded; most browsers presenting a 'Save as' dialog, prefilled with the value of the filename parameters if present).
httpContent-Disposition: inline
Content-Disposition: attachment
Content-Disposition: attachment; filename="file name.jpg"
Content-Disposition: attachment; filename*=UTF-8''file%20name.jpg

The quotes around the file name are optional, but are necessary if you use special characters in the file name, such as spaces.
The parameters filename and filename* differ only in that filename* uses the encoding defined in RFC 5987, section 3.2.
When both filename and filename* are present in a single header field value, filename* is preferred over filename when both are understood. It's recommended to include both for maximum compatibility, and you can convert filename* to filename by substituting non-ASCII characters with ASCII equivalents (such as converting é to e).
You may want to avoid percent escape sequences in filename, because they are handled inconsistently across browsers. (Firefox and Chrome decode them, while Safari does not.)
Browsers may apply transformations to conform to the file system requirements, such as converting path separators (/ and \) to underscores (_).

Note:
Chrome, and Firefox 82 and later, prioritize the HTML <a> element's download attribute over the Content-Disposition: inline parameter (for same-origin URLs). Earlier Firefox versions prioritize the header and will display the content inline.
As a header for a multipart bodyA multipart/form-data body requires a Content-Disposition header to provide information about each subpart of the form (e.g., for every form field and any files that are part of field data). The first directive is always form-data, and the header must also include a name parameter to identify the relevant field. Additional directives are case-insensitive and have arguments that use quoted-string syntax after the = sign. Multiple parameters are separated by a semicolon (;).
httpContent-Disposition: form-data; name="fieldName"
Content-Disposition: form-data; name="fieldName"; filename="filename.jpg"

Directives

name

Is followed by a string containing the name of the HTML field in the form that the content of this subpart refers to. When dealing with multiple files in the same field (for example, the multiple attribute of an <input type="file"> element), there can be several subparts with the same name.
A name with a value of '_charset_' indicates that the part is not an HTML field, but the default charset to use for parts without explicit charset information.

filename

Is followed by a string containing the original name of the file transmitted. This parameter provides mostly indicative information. The suggestions in RFC2183 apply:

Prefer ASCII characters if possible (the client may percent-encode it, as long as the server implementation decodes it).
Any path information should be stripped, such as by replacing / with _.
When writing to disk, it should not overwrite an existing file.
Avoid creating special files with security implications, such as creating a file on the command search path.
Satisfy other file system requirements, such as restricted characters and length limits.



Note that the request header does not have the filename* parameter and does not allow RFC 5987 encoding.ExamplesTriggering download prompt for a resourceThe following response triggers the "Save As" dialog in a browser:
http200 OK
Content-Type: text/html; charset=utf-8
Content-Disposition: attachment; filename="cool.html"
Content-Length: 21

<HTML>Save me!</HTML>

The HTML file will be downloaded rather than displayed in the browser.
Most browsers will prompt users to save it with the cool.html file name by default (as specified in the filename directive).HTML posting multipart/form-data content typeThe following example shows an HTML form sent using multipart/form-data using the Content-Disposition header.
In practice, the boundary value delimiter123 would be a browser-generated string like ----8721656041911415653955004498:
httpPOST /test.html HTTP/1.1
Host: example.org
Content-Type: multipart/form-data;boundary="delimiter123"

--delimiter123
Content-Disposition: form-data; name="field1"

value1
--delimiter123
Content-Disposition: form-data; name="field2"; filename="example.txt"

value2
--delimiter123--
SpecificationsSpecificationUse of the Content-Disposition Header Field in the Hypertext Transfer Protocol (HTTP) # header.field.definitionReturning Values from Forms: multipart/form-data # section-4.2Browser compatibilitySee also
HTML Forms
The Content-Type defining the boundary of the multipart body.
The FormData interface used to prepare form data for use in the fetch() or XMLHttpRequest APIs.\n\nContent-DispositionBaseline Widely availableThis feature is well established and works across many devices and browser versions. It’s been available across browsers since July 2015.Learn moreSee full compatibilityReport feedbackThe HTTP Content-Disposition header indicates whether content should be displayed inline in the browser as a web page or part of a web page or downloaded as an attachment locally.
In a multipart body, the header must be used on each subpart to provide information about its corresponding field. The subpart is delimited by the boundary defined in the Content-Type header. When used on the body itself, Content-Disposition has no effect.
The Content-Disposition header is defined in the larger context of MIME messages for email, but only a subset of the possible parameters apply to HTTP forms and POST requests. Only the value form-data, as well as the optional directive name and filename, can be used in the HTTP context.

  
    
      Header type
      
        Response header (for the main body),Request header,
        Response header (for a subpart of a multipart body)
      
    
    
      Forbidden request header
      No
    
  
SyntaxAs a response header for the main bodyThe first parameter in the HTTP context is either inline (default value, indicating it can be displayed inside the Web page, or as the Web page) or attachment (indicating it should be downloaded; most browsers presenting a 'Save as' dialog, prefilled with the value of the filename parameters if present).
httpContent-Disposition: inline
Content-Disposition: attachment
Content-Disposition: attachment; filename="file name.jpg"
Content-Disposition: attachment; filename*=UTF-8''file%20name.jpg

The quotes around the file name are optional, but are necessary if you use special characters in the file name, such as spaces.
The parameters filename and filename* differ only in that filename* uses the encoding defined in RFC 5987, section 3.2.
When both filename and filename* are present in a single header field value, filename* is preferred over filename when both are understood. It's recommended to include both for maximum compatibility, and you can convert filename* to filename by substituting non-ASCII characters with ASCII equivalents (such as converting é to e).
You may want to avoid percent escape sequences in filename, because they are handled inconsistently across browsers. (Firefox and Chrome decode them, while Safari does not.)
Browsers may apply transformations to conform to the file system requirements, such as converting path separators (/ and \) to underscores (_).

Note:
Chrome, and Firefox 82 and later, prioritize the HTML <a> element's download attribute over the Content-Disposition: inline parameter (for same-origin URLs). Earlier Firefox versions prioritize the header and will display the content inline.
As a header for a multipart bodyA multipart/form-data body requires a Content-Disposition header to provide information about each subpart of the form (e.g., for every form field and any files that are part of field data). The first directive is always form-data, and the header must also include a name parameter to identify the relevant field. Additional directives are case-insensitive and have arguments that use quoted-string syntax after the = sign. Multiple parameters are separated by a semicolon (;).
httpContent-Disposition: form-data; name="fieldName"
Content-Disposition: form-data; name="fieldName"; filename="filename.jpg"

Directives

name

Is followed by a string containing the name of the HTML field in the form that the content of this subpart refers to. When dealing with multiple files in the same field (for example, the multiple attribute of an <input type="file"> element), there can be several subparts with the same name.
A name with a value of '_charset_' indicates that the part is not an HTML field, but the default charset to use for parts without explicit charset information.

filename

Is followed by a string containing the original name of the file transmitted. This parameter provides mostly indicative information. The suggestions in RFC2183 apply:

Prefer ASCII characters if possible (the client may percent-encode it, as long as the server implementation decodes it).
Any path information should be stripped, such as by replacing / with _.
When writing to disk, it should not overwrite an existing file.
Avoid creating special files with security implications, such as creating a file on the command search path.
Satisfy other file system requirements, such as restricted characters and length limits.



Note that the request header does not have the filename* parameter and does not allow RFC 5987 encoding.ExamplesTriggering download prompt for a resourceThe following response triggers the "Save As" dialog in a browser:
http200 OK
Content-Type: text/html; charset=utf-8
Content-Disposition: attachment; filename="cool.html"
Content-Length: 21

<HTML>Save me!</HTML>

The HTML file will be downloaded rather than displayed in the browser.
Most browsers will prompt users to save it with the cool.html file name by default (as specified in the filename directive).HTML posting multipart/form-data content typeThe following example shows an HTML form sent using multipart/form-data using the Content-Disposition header.
In practice, the boundary value delimiter123 would be a browser-generated string like ----8721656041911415653955004498:
httpPOST /test.html HTTP/1.1
Host: example.org
Content-Type: multipart/form-data;boundary="delimiter123"

--delimiter123
Content-Disposition: form-data; name="field1"

value1
--delimiter123
Content-Disposition: form-data; name="field2"; filename="example.txt"

value2
--delimiter123--
SpecificationsSpecificationUse of the Content-Disposition Header Field in the Hypertext Transfer Protocol (HTTP) # header.field.definitionReturning Values from Forms: multipart/form-data # section-4.2Browser compatibilitySee also
HTML Forms
The Content-Type defining the boundary of the multipart body.
The FormData interface used to prepare form data for use in the fetch() or XMLHttpRequest APIs.
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Apr 10, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nContent-DispositionBaseline Widely availableThis feature is well established and works across many devices and browser versions. It’s been available across browsers since July 2015.Learn moreSee full compatibilityReport feedbackThe HTTP Content-Disposition header indicates whether content should be displayed inline in the browser as a web page or part of a web page or downloaded as an attachment locally.
In a multipart body, the header must be used on each subpart to provide information about its corresponding field. The subpart is delimited by the boundary defined in the Content-Type header. When used on the body itself, Content-Disposition has no effect.
The Content-Disposition header is defined in the larger context of MIME messages for email, but only a subset of the possible parameters apply to HTTP forms and POST requests. Only the value form-data, as well as the optional directive name and filename, can be used in the HTTP context.

  
    
      Header type
      
        Response header (for the main body),Request header,
        Response header (for a subpart of a multipart body)
      
    
    
      Forbidden request header
      No
    
  
SyntaxAs a response header for the main bodyThe first parameter in the HTTP context is either inline (default value, indicating it can be displayed inside the Web page, or as the Web page) or attachment (indicating it should be downloaded; most browsers presenting a 'Save as' dialog, prefilled with the value of the filename parameters if present).
httpContent-Disposition: inline
Content-Disposition: attachment
Content-Disposition: attachment; filename="file name.jpg"
Content-Disposition: attachment; filename*=UTF-8''file%20name.jpg

The quotes around the file name are optional, but are necessary if you use special characters in the file name, such as spaces.
The parameters filename and filename* differ only in that filename* uses the encoding defined in RFC 5987, section 3.2.
When both filename and filename* are present in a single header field value, filename* is preferred over filename when both are understood. It's recommended to include both for maximum compatibility, and you can convert filename* to filename by substituting non-ASCII characters with ASCII equivalents (such as converting é to e).
You may want to avoid percent escape sequences in filename, because they are handled inconsistently across browsers. (Firefox and Chrome decode them, while Safari does not.)
Browsers may apply transformations to conform to the file system requirements, such as converting path separators (/ and \) to underscores (_).

Note:
Chrome, and Firefox 82 and later, prioritize the HTML <a> element's download attribute over the Content-Disposition: inline parameter (for same-origin URLs). Earlier Firefox versions prioritize the header and will display the content inline.
As a header for a multipart bodyA multipart/form-data body requires a Content-Disposition header to provide information about each subpart of the form (e.g., for every form field and any files that are part of field data). The first directive is always form-data, and the header must also include a name parameter to identify the relevant field. Additional directives are case-insensitive and have arguments that use quoted-string syntax after the = sign. Multiple parameters are separated by a semicolon (;).
httpContent-Disposition: form-data; name="fieldName"
Content-Disposition: form-data; name="fieldName"; filename="filename.jpg"

Directives

name

Is followed by a string containing the name of the HTML field in the form that the content of this subpart refers to. When dealing with multiple files in the same field (for example, the multiple attribute of an <input type="file"> element), there can be several subparts with the same name.
A name with a value of '_charset_' indicates that the part is not an HTML field, but the default charset to use for parts without explicit charset information.

filename

Is followed by a string containing the original name of the file transmitted. This parameter provides mostly indicative information. The suggestions in RFC2183 apply:

Prefer ASCII characters if possible (the client may percent-encode it, as long as the server implementation decodes it).
Any path information should be stripped, such as by replacing / with _.
When writing to disk, it should not overwrite an existing file.
Avoid creating special files with security implications, such as creating a file on the command search path.
Satisfy other file system requirements, such as restricted characters and length limits.



Note that the request header does not have the filename* parameter and does not allow RFC 5987 encoding.ExamplesTriggering download prompt for a resourceThe following response triggers the "Save As" dialog in a browser:
http200 OK
Content-Type: text/html; charset=utf-8
Content-Disposition: attachment; filename="cool.html"
Content-Length: 21

<HTML>Save me!</HTML>

The HTML file will be downloaded rather than displayed in the browser.
Most browsers will prompt users to save it with the cool.html file name by default (as specified in the filename directive).HTML posting multipart/form-data content typeThe following example shows an HTML form sent using multipart/form-data using the Content-Disposition header.
In practice, the boundary value delimiter123 would be a browser-generated string like ----8721656041911415653955004498:
httpPOST /test.html HTTP/1.1
Host: example.org
Content-Type: multipart/form-data;boundary="delimiter123"

--delimiter123
Content-Disposition: form-data; name="field1"

value1
--delimiter123
Content-Disposition: form-data; name="field2"; filename="example.txt"

value2
--delimiter123--
SpecificationsSpecificationUse of the Content-Disposition Header Field in the Hypertext Transfer Protocol (HTTP) # header.field.definitionReturning Values from Forms: multipart/form-data # section-4.2Browser compatibilitySee also
HTML Forms
The Content-Type defining the boundary of the multipart body.
The FormData interface used to prepare form data for use in the fetch() or XMLHttpRequest APIs.
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Apr 10, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nContent-DPRDeprecated: This feature is no longer recommended. Though some browsers might still support it, it may have already been removed from the relevant web standards, may be in the process of being dropped, or may only be kept for compatibility purposes. Avoid using it, and update existing code if possible; see the compatibility table at the bottom of this page to guide your decision. Be aware that this feature may cease to work at any time.
Secure context: This feature is available only in secure contexts (HTTPS), in some or all supporting browsers.
Non-standard: This feature is non-standard and is not on a standards track. Do not use it on production sites facing the Web: it will not work for every user. There may also be large incompatibilities between implementations and the behavior may change in the future.
The HTTP Content-DPR response header is used to confirm the image device to pixel ratio (DPR) in requests where the screen DPR client hint was used to select an image resource.

Note:
The Content-DPR header was removed from the client hints specification in draft-ietf-httpbis-client-hints-07.
The Responsive Image Client Hints specification proposes to replace this header by specifying intrinsic resolution/dimensions in EXIF metadata.

If the DPR client hint is used to select an image, the server must specify Content-DPR in the response.
If the value in Content-DPR is different from the DPR value in the request (i.e., image DPR is not the same as screen DPR), the client must use the Content-DPR for determining intrinsic image size and scaling the image.
If the Content-DPR header appears more than once in a message, the last occurrence is used.

  
    
      Header type
      
        Response header,
        Client hint
      
    
    
      Forbidden request header
      No
    
    
      
        CORS-safelisted response header
      
      No
    
  
SyntaxhttpContent-DPR: <number>
Directives
<number>

The image device pixel ratio, calculated according to the following formula:
Content-DPR = Selected image resource size / (Width / DPR)

ExamplesSee the DPR header example.Browser compatibilitySee also
Device client hints

Device-Memory
DPR
Viewport-Width
Width


Accept-CH
HTTP Caching: Vary and Vary
Improving user privacy and developer experience with User-Agent Client Hints on developer.chrome.com (2020)\n\nContent-DPRDeprecated: This feature is no longer recommended. Though some browsers might still support it, it may have already been removed from the relevant web standards, may be in the process of being dropped, or may only be kept for compatibility purposes. Avoid using it, and update existing code if possible; see the compatibility table at the bottom of this page to guide your decision. Be aware that this feature may cease to work at any time.
Secure context: This feature is available only in secure contexts (HTTPS), in some or all supporting browsers.
Non-standard: This feature is non-standard and is not on a standards track. Do not use it on production sites facing the Web: it will not work for every user. There may also be large incompatibilities between implementations and the behavior may change in the future.
The HTTP Content-DPR response header is used to confirm the image device to pixel ratio (DPR) in requests where the screen DPR client hint was used to select an image resource.

Note:
The Content-DPR header was removed from the client hints specification in draft-ietf-httpbis-client-hints-07.
The Responsive Image Client Hints specification proposes to replace this header by specifying intrinsic resolution/dimensions in EXIF metadata.

If the DPR client hint is used to select an image, the server must specify Content-DPR in the response.
If the value in Content-DPR is different from the DPR value in the request (i.e., image DPR is not the same as screen DPR), the client must use the Content-DPR for determining intrinsic image size and scaling the image.
If the Content-DPR header appears more than once in a message, the last occurrence is used.

  
    
      Header type
      
        Response header,
        Client hint
      
    
    
      Forbidden request header
      No
    
    
      
        CORS-safelisted response header
      
      No
    
  
SyntaxhttpContent-DPR: <number>
Directives
<number>

The image device pixel ratio, calculated according to the following formula:
Content-DPR = Selected image resource size / (Width / DPR)

ExamplesSee the DPR header example.Browser compatibilitySee also
Device client hints

Device-Memory
DPR
Viewport-Width
Width


Accept-CH
HTTP Caching: Vary and Vary
Improving user privacy and developer experience with User-Agent Client Hints on developer.chrome.com (2020)
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nContent-DPRDeprecated: This feature is no longer recommended. Though some browsers might still support it, it may have already been removed from the relevant web standards, may be in the process of being dropped, or may only be kept for compatibility purposes. Avoid using it, and update existing code if possible; see the compatibility table at the bottom of this page to guide your decision. Be aware that this feature may cease to work at any time.
Secure context: This feature is available only in secure contexts (HTTPS), in some or all supporting browsers.
Non-standard: This feature is non-standard and is not on a standards track. Do not use it on production sites facing the Web: it will not work for every user. There may also be large incompatibilities between implementations and the behavior may change in the future.
The HTTP Content-DPR response header is used to confirm the image device to pixel ratio (DPR) in requests where the screen DPR client hint was used to select an image resource.

Note:
The Content-DPR header was removed from the client hints specification in draft-ietf-httpbis-client-hints-07.
The Responsive Image Client Hints specification proposes to replace this header by specifying intrinsic resolution/dimensions in EXIF metadata.

If the DPR client hint is used to select an image, the server must specify Content-DPR in the response.
If the value in Content-DPR is different from the DPR value in the request (i.e., image DPR is not the same as screen DPR), the client must use the Content-DPR for determining intrinsic image size and scaling the image.
If the Content-DPR header appears more than once in a message, the last occurrence is used.

  
    
      Header type
      
        Response header,
        Client hint
      
    
    
      Forbidden request header
      No
    
    
      
        CORS-safelisted response header
      
      No
    
  
SyntaxhttpContent-DPR: <number>
Directives
<number>

The image device pixel ratio, calculated according to the following formula:
Content-DPR = Selected image resource size / (Width / DPR)

ExamplesSee the DPR header example.Browser compatibilitySee also
Device client hints

Device-Memory
DPR
Viewport-Width
Width


Accept-CH
HTTP Caching: Vary and Vary
Improving user privacy and developer experience with User-Agent Client Hints on developer.chrome.com (2020)
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nContent-EncodingBaseline Widely available *This feature is well established and works across many devices and browser versions. It’s been available across browsers since July 2015.* Some parts of this feature may have varying levels of support.Learn moreSee full compatibilityReport feedbackThe HTTP Content-Encoding representation header lists the encodings and the order in which they have been applied to a resource.
This lets the recipient know how to decode the data in order to obtain the original content format described in the Content-Type header.
Content encoding is mainly used to compress content without losing information about the original media type.
Servers should compress data as much as possible, and should use content encoding where appropriate.
Compressing already compressed media types, such as .zip or .jpeg, is usually not appropriate because it can increase the file size.
If the original media is already encoded (e.g., as a .zip file), this information is not included in the Content-Encoding header.
When the Content-Encoding header is present, other metadata (e.g., Content-Length) refer to the encoded form of the data, not the original resource, unless explicitly stated.
Content encoding differs to Transfer-Encoding in that Transfer-Encoding handles how HTTP messages themselves are delivered across the network on a hop-by-hop basis.

  
    
      Header type
      Representation header
    
    
      Forbidden request header
      No
    
  
SyntaxhttpContent-Encoding: gzip
Content-Encoding: compress
Content-Encoding: deflate
Content-Encoding: br
Content-Encoding: zstd
Content-Encoding: dcb
Content-Encoding: dcz

// Multiple, in the order in which they were applied
Content-Encoding: deflate, gzip
Directives
gzip

A format using the Lempel-Ziv coding (LZ77), with a 32-bit CRC.
This is the original format of the UNIX gzip program.
The HTTP/1.1 standard also recommends that the servers supporting this content-encoding should recognize x-gzip as an alias, for compatibility purposes.

compress

A format using the Lempel-Ziv-Welch (LZW) algorithm.
The value name was taken from the UNIX compress program, which implemented this algorithm.
Like the compress program, which has disappeared from most UNIX distributions, this content-encoding is not used by many browsers today, partly because of a patent issue (it expired in 2003).

deflate

Using the zlib structure (defined in RFC 1950) with the deflate compression algorithm (defined in RFC 1951).

br

A format using the Brotli algorithm structure (defined in RFC 7932).

zstd

A format using the Zstandard algorithm structure (defined in RFC 8878).

dcb 
Experimental


A format that uses the Dictionary-Compressed Brotli algorithm. See Compression Dictionary Transport.

dcz 
Experimental


A format that uses the Dictionary-Compressed Zstandard algorithm. See Compression Dictionary Transport.

ExamplesCompressing with gzipOn the client side, you can advertise a list of compression schemes that will be sent along in an HTTP request. The Accept-Encoding header is used for negotiating content encoding.
httpAccept-Encoding: gzip, deflate

The server responds with the scheme used, indicated by the Content-Encoding response header.
httpContent-Encoding: gzip

Whether a server uses compression methods requested by the client depends on server configuration and capabilities.SpecificationsSpecificationHTTP Semantics # field.content-encodingBrowser compatibilitySee also
Accept-Encoding
Transfer-Encoding
Brotli compression
GZip compression
Zstandard compression
Compression Dictionary Transport guide\n\nContent-EncodingBaseline Widely available *This feature is well established and works across many devices and browser versions. It’s been available across browsers since July 2015.* Some parts of this feature may have varying levels of support.Learn moreSee full compatibilityReport feedbackThe HTTP Content-Encoding representation header lists the encodings and the order in which they have been applied to a resource.
This lets the recipient know how to decode the data in order to obtain the original content format described in the Content-Type header.
Content encoding is mainly used to compress content without losing information about the original media type.
Servers should compress data as much as possible, and should use content encoding where appropriate.
Compressing already compressed media types, such as .zip or .jpeg, is usually not appropriate because it can increase the file size.
If the original media is already encoded (e.g., as a .zip file), this information is not included in the Content-Encoding header.
When the Content-Encoding header is present, other metadata (e.g., Content-Length) refer to the encoded form of the data, not the original resource, unless explicitly stated.
Content encoding differs to Transfer-Encoding in that Transfer-Encoding handles how HTTP messages themselves are delivered across the network on a hop-by-hop basis.

  
    
      Header type
      Representation header
    
    
      Forbidden request header
      No
    
  
SyntaxhttpContent-Encoding: gzip
Content-Encoding: compress
Content-Encoding: deflate
Content-Encoding: br
Content-Encoding: zstd
Content-Encoding: dcb
Content-Encoding: dcz

// Multiple, in the order in which they were applied
Content-Encoding: deflate, gzip
Directives
gzip

A format using the Lempel-Ziv coding (LZ77), with a 32-bit CRC.
This is the original format of the UNIX gzip program.
The HTTP/1.1 standard also recommends that the servers supporting this content-encoding should recognize x-gzip as an alias, for compatibility purposes.

compress

A format using the Lempel-Ziv-Welch (LZW) algorithm.
The value name was taken from the UNIX compress program, which implemented this algorithm.
Like the compress program, which has disappeared from most UNIX distributions, this content-encoding is not used by many browsers today, partly because of a patent issue (it expired in 2003).

deflate

Using the zlib structure (defined in RFC 1950) with the deflate compression algorithm (defined in RFC 1951).

br

A format using the Brotli algorithm structure (defined in RFC 7932).

zstd

A format using the Zstandard algorithm structure (defined in RFC 8878).

dcb 
Experimental


A format that uses the Dictionary-Compressed Brotli algorithm. See Compression Dictionary Transport.

dcz 
Experimental


A format that uses the Dictionary-Compressed Zstandard algorithm. See Compression Dictionary Transport.

ExamplesCompressing with gzipOn the client side, you can advertise a list of compression schemes that will be sent along in an HTTP request. The Accept-Encoding header is used for negotiating content encoding.
httpAccept-Encoding: gzip, deflate

The server responds with the scheme used, indicated by the Content-Encoding response header.
httpContent-Encoding: gzip

Whether a server uses compression methods requested by the client depends on server configuration and capabilities.SpecificationsSpecificationHTTP Semantics # field.content-encodingBrowser compatibilitySee also
Accept-Encoding
Transfer-Encoding
Brotli compression
GZip compression
Zstandard compression
Compression Dictionary Transport guide
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Apr 3, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nContent-EncodingBaseline Widely available *This feature is well established and works across many devices and browser versions. It’s been available across browsers since July 2015.* Some parts of this feature may have varying levels of support.Learn moreSee full compatibilityReport feedbackThe HTTP Content-Encoding representation header lists the encodings and the order in which they have been applied to a resource.
This lets the recipient know how to decode the data in order to obtain the original content format described in the Content-Type header.
Content encoding is mainly used to compress content without losing information about the original media type.
Servers should compress data as much as possible, and should use content encoding where appropriate.
Compressing already compressed media types, such as .zip or .jpeg, is usually not appropriate because it can increase the file size.
If the original media is already encoded (e.g., as a .zip file), this information is not included in the Content-Encoding header.
When the Content-Encoding header is present, other metadata (e.g., Content-Length) refer to the encoded form of the data, not the original resource, unless explicitly stated.
Content encoding differs to Transfer-Encoding in that Transfer-Encoding handles how HTTP messages themselves are delivered across the network on a hop-by-hop basis.

  
    
      Header type
      Representation header
    
    
      Forbidden request header
      No
    
  
SyntaxhttpContent-Encoding: gzip
Content-Encoding: compress
Content-Encoding: deflate
Content-Encoding: br
Content-Encoding: zstd
Content-Encoding: dcb
Content-Encoding: dcz

// Multiple, in the order in which they were applied
Content-Encoding: deflate, gzip
Directives
gzip

A format using the Lempel-Ziv coding (LZ77), with a 32-bit CRC.
This is the original format of the UNIX gzip program.
The HTTP/1.1 standard also recommends that the servers supporting this content-encoding should recognize x-gzip as an alias, for compatibility purposes.

compress

A format using the Lempel-Ziv-Welch (LZW) algorithm.
The value name was taken from the UNIX compress program, which implemented this algorithm.
Like the compress program, which has disappeared from most UNIX distributions, this content-encoding is not used by many browsers today, partly because of a patent issue (it expired in 2003).

deflate

Using the zlib structure (defined in RFC 1950) with the deflate compression algorithm (defined in RFC 1951).

br

A format using the Brotli algorithm structure (defined in RFC 7932).

zstd

A format using the Zstandard algorithm structure (defined in RFC 8878).

dcb 
Experimental


A format that uses the Dictionary-Compressed Brotli algorithm. See Compression Dictionary Transport.

dcz 
Experimental


A format that uses the Dictionary-Compressed Zstandard algorithm. See Compression Dictionary Transport.

ExamplesCompressing with gzipOn the client side, you can advertise a list of compression schemes that will be sent along in an HTTP request. The Accept-Encoding header is used for negotiating content encoding.
httpAccept-Encoding: gzip, deflate

The server responds with the scheme used, indicated by the Content-Encoding response header.
httpContent-Encoding: gzip

Whether a server uses compression methods requested by the client depends on server configuration and capabilities.SpecificationsSpecificationHTTP Semantics # field.content-encodingBrowser compatibilitySee also
Accept-Encoding
Transfer-Encoding
Brotli compression
GZip compression
Zstandard compression
Compression Dictionary Transport guide
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Apr 3, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nContent-LanguageBaseline Widely availableThis feature is well established and works across many devices and browser versions. It’s been available across browsers since July 2015.Learn moreSee full compatibilityReport feedbackThe HTTP Content-Language representation header is used to describe the language(s) intended for the audience, so users can differentiate it according to their own preferred language.
For example, Content-Language: de-DE indicates that the document is intended for German language speakers. The document may be written in English, not German, as part of a language course for German speakers. To indicate the language the document is written in, use the lang attribute instead.
If no Content-Language is specified, the default is that the content is intended for all language audiences. Multiple language tags are also possible, as well as applying the Content-Language header to various media types and not only to textual documents.

  
    
      Header type
      Representation header
    
    
      Forbidden request header
      No
    
    
      
        CORS-safelisted response header
      
      Yes
    
    
      
        CORS-safelisted request header
      
      
        Yes*
      
    
  

* Values can only be 0-9, A-Z, a-z, a space, or the characters *,-.;=.SyntaxhttpContent-Language: de-DE
Content-Language: en-US
Content-Language: de-DE, en-CA
Directives
language-tag

Multiple language tags are separated by a comma. Each language tag is a sequence of one or more case-insensitive subtags, each separated by a hyphen character (-). In most cases, a language tag consists of a primary language subtag that identifies a broad family of related languages (e.g., en = English) and is optionally followed by a series of subtags that refine or narrow that language's range (e.g., en-CA = the variety of English as communicated in Canada).



Note:
Language tags are formally defined in BCP 47, which rely on the ISO 639 standard (quite often the ISO 639-1 code list) for language codes to be used.
ExamplesIndicating the language a document is written inThe global lang attribute is used on HTML elements to indicate the language of an entire HTML document or parts of it.
html<html lang="de">
  …
</html>

Do not use this meta element to state the document language, as shown below:
html<meta http-equiv="content-language" content="de" />
Indicating a target audience for a resourceThe Content-Language header is used to specify the page's intended audience and can indicate that this is more than one language.
httpContent-Language: de, en
SpecificationsSpecificationHTTP Semantics # field.content-languageBrowser compatibilitySee also
Accept-Language
HTTP headers, meta elements and language information
HTML lang attribute\n\nContent-LanguageBaseline Widely availableThis feature is well established and works across many devices and browser versions. It’s been available across browsers since July 2015.Learn moreSee full compatibilityReport feedbackThe HTTP Content-Language representation header is used to describe the language(s) intended for the audience, so users can differentiate it according to their own preferred language.
For example, Content-Language: de-DE indicates that the document is intended for German language speakers. The document may be written in English, not German, as part of a language course for German speakers. To indicate the language the document is written in, use the lang attribute instead.
If no Content-Language is specified, the default is that the content is intended for all language audiences. Multiple language tags are also possible, as well as applying the Content-Language header to various media types and not only to textual documents.

  
    
      Header type
      Representation header
    
    
      Forbidden request header
      No
    
    
      
        CORS-safelisted response header
      
      Yes
    
    
      
        CORS-safelisted request header
      
      
        Yes*
      
    
  

* Values can only be 0-9, A-Z, a-z, a space, or the characters *,-.;=.SyntaxhttpContent-Language: de-DE
Content-Language: en-US
Content-Language: de-DE, en-CA
Directives
language-tag

Multiple language tags are separated by a comma. Each language tag is a sequence of one or more case-insensitive subtags, each separated by a hyphen character (-). In most cases, a language tag consists of a primary language subtag that identifies a broad family of related languages (e.g., en = English) and is optionally followed by a series of subtags that refine or narrow that language's range (e.g., en-CA = the variety of English as communicated in Canada).



Note:
Language tags are formally defined in BCP 47, which rely on the ISO 639 standard (quite often the ISO 639-1 code list) for language codes to be used.
ExamplesIndicating the language a document is written inThe global lang attribute is used on HTML elements to indicate the language of an entire HTML document or parts of it.
html<html lang="de">
  …
</html>

Do not use this meta element to state the document language, as shown below:
html<meta http-equiv="content-language" content="de" />
Indicating a target audience for a resourceThe Content-Language header is used to specify the page's intended audience and can indicate that this is more than one language.
httpContent-Language: de, en
SpecificationsSpecificationHTTP Semantics # field.content-languageBrowser compatibilitySee also
Accept-Language
HTTP headers, meta elements and language information
HTML lang attribute
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Apr 10, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nContent-LanguageBaseline Widely availableThis feature is well established and works across many devices and browser versions. It’s been available across browsers since July 2015.Learn moreSee full compatibilityReport feedbackThe HTTP Content-Language representation header is used to describe the language(s) intended for the audience, so users can differentiate it according to their own preferred language.
For example, Content-Language: de-DE indicates that the document is intended for German language speakers. The document may be written in English, not German, as part of a language course for German speakers. To indicate the language the document is written in, use the lang attribute instead.
If no Content-Language is specified, the default is that the content is intended for all language audiences. Multiple language tags are also possible, as well as applying the Content-Language header to various media types and not only to textual documents.

  
    
      Header type
      Representation header
    
    
      Forbidden request header
      No
    
    
      
        CORS-safelisted response header
      
      Yes
    
    
      
        CORS-safelisted request header
      
      
        Yes*
      
    
  

* Values can only be 0-9, A-Z, a-z, a space, or the characters *,-.;=.SyntaxhttpContent-Language: de-DE
Content-Language: en-US
Content-Language: de-DE, en-CA
Directives
language-tag

Multiple language tags are separated by a comma. Each language tag is a sequence of one or more case-insensitive subtags, each separated by a hyphen character (-). In most cases, a language tag consists of a primary language subtag that identifies a broad family of related languages (e.g., en = English) and is optionally followed by a series of subtags that refine or narrow that language's range (e.g., en-CA = the variety of English as communicated in Canada).



Note:
Language tags are formally defined in BCP 47, which rely on the ISO 639 standard (quite often the ISO 639-1 code list) for language codes to be used.
ExamplesIndicating the language a document is written inThe global lang attribute is used on HTML elements to indicate the language of an entire HTML document or parts of it.
html<html lang="de">
  …
</html>

Do not use this meta element to state the document language, as shown below:
html<meta http-equiv="content-language" content="de" />
Indicating a target audience for a resourceThe Content-Language header is used to specify the page's intended audience and can indicate that this is more than one language.
httpContent-Language: de, en
SpecificationsSpecificationHTTP Semantics # field.content-languageBrowser compatibilitySee also
Accept-Language
HTTP headers, meta elements and language information
HTML lang attribute
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Apr 10, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nContent-LengthBaseline Widely availableThis feature is well established and works across many devices and browser versions. It’s been available across browsers since July 2015.Learn moreSee full compatibilityReport feedbackThe HTTP Content-Length header indicates the size, in bytes, of the message body sent to the recipient.

  
    
      Header type
      
        Request header,
        Response header,
        Content header
      
    
    
      Forbidden request header
      Yes
    
    
      
        CORS-safelisted response header
      
      Yes
    
  
SyntaxhttpContent-Length: <length>
Directives
<length>

The length in octets.

SpecificationsSpecificationHTTP Semantics # field.content-lengthBrowser compatibilitySee also
Transfer-Encoding\n\nContent-LengthBaseline Widely availableThis feature is well established and works across many devices and browser versions. It’s been available across browsers since July 2015.Learn moreSee full compatibilityReport feedbackThe HTTP Content-Length header indicates the size, in bytes, of the message body sent to the recipient.

  
    
      Header type
      
        Request header,
        Response header,
        Content header
      
    
    
      Forbidden request header
      Yes
    
    
      
        CORS-safelisted response header
      
      Yes
    
  
SyntaxhttpContent-Length: <length>
Directives
<length>

The length in octets.

SpecificationsSpecificationHTTP Semantics # field.content-lengthBrowser compatibilitySee also
Transfer-Encoding
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nContent-LengthBaseline Widely availableThis feature is well established and works across many devices and browser versions. It’s been available across browsers since July 2015.Learn moreSee full compatibilityReport feedbackThe HTTP Content-Length header indicates the size, in bytes, of the message body sent to the recipient.

  
    
      Header type
      
        Request header,
        Response header,
        Content header
      
    
    
      Forbidden request header
      Yes
    
    
      
        CORS-safelisted response header
      
      Yes
    
  
SyntaxhttpContent-Length: <length>
Directives
<length>

The length in octets.

SpecificationsSpecificationHTTP Semantics # field.content-lengthBrowser compatibilitySee also
Transfer-Encoding
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nContent-LocationBaseline Widely availableThis feature is well established and works across many devices and browser versions. It’s been available across browsers since July 2015.Learn moreSee full compatibilityReport feedbackThe HTTP Content-Location representation header indicates an alternate location for the returned data.
It's main use is to indicate the URL of a resource transmitted as the result of content negotiation.
The Content-Location header is different from the Location header.
Content-Location indicates the direct URL to access the resource when content negotiation has happened, allowing the client to bypass future content negotiation for this resource.
Location, on the other hand, indicates either the target of a 3XX redirection or the URL of a newly created resource in a 201 Created response.

  
    
      Header type
      Representation header
    
    
      Forbidden request header
      No
    
  
SyntaxhttpContent-Location: <url>
Directives
<url>

A URL that can be absolute or relative to the request URL.

ExamplesRequesting data from a server in different formatsLet's say a site's API can return data in JSON, XML, or
CSV formats. If the URL for a particular document
is at https://example.com/documents/foo, the site could return different
URLs for Content-Location depending on the request's
Accept header:



Request header
Response header




Accept: application/json, text/json
Content-Location: /documents/foo.json


Accept: application/xml, text/xml
Content-Location: /documents/foo.xml


Accept: text/plain, text/*
Content-Location: /documents/foo.txt



These URLs are examples — the site could serve the different filetypes with any URL
patterns it wishes, such as a query string parameter: /documents/foo?format=json,
/documents/foo?format=xml, and so on.
Then the client could remember that the JSON version is available at that particular
URL, skipping content negotiation the next time it requests that document.
The server could also consider other content negotiation headers, such
as Accept-Language.Indicating the URL of a transaction's resultSay you have a
<form> for sending
money to another user of a site.
html<form action="/send-payment" method="post">
  <p>
    <label>
      Who do you want to send the money to?
      <input type="text" name="recipient" />
    </label>
  </p>

  <p>
    <label>
      How much?
      <input type="number" name="amount" />
    </label>
  </p>

  <button type="submit">Send Money</button>
</form>

When the form is submitted, the site generates a receipt for the transaction. The
server could use Content-Location to indicate that receipt's URL for future
access.
httpHTTP/1.1 200 OK
Content-Type: text/html; charset=utf-8
Content-Location: /my-receipts/38

<!doctype html>
(Lots of HTML…)

<p>You sent $38.00 to ExampleUser.</p>

(Lots more HTML…)
SpecificationsSpecificationHTTP Semantics # field.content-locationBrowser compatibilitySee also
Location\n\nContent-LocationBaseline Widely availableThis feature is well established and works across many devices and browser versions. It’s been available across browsers since July 2015.Learn moreSee full compatibilityReport feedbackThe HTTP Content-Location representation header indicates an alternate location for the returned data.
It's main use is to indicate the URL of a resource transmitted as the result of content negotiation.
The Content-Location header is different from the Location header.
Content-Location indicates the direct URL to access the resource when content negotiation has happened, allowing the client to bypass future content negotiation for this resource.
Location, on the other hand, indicates either the target of a 3XX redirection or the URL of a newly created resource in a 201 Created response.

  
    
      Header type
      Representation header
    
    
      Forbidden request header
      No
    
  
SyntaxhttpContent-Location: <url>
Directives
<url>

A URL that can be absolute or relative to the request URL.

ExamplesRequesting data from a server in different formatsLet's say a site's API can return data in JSON, XML, or
CSV formats. If the URL for a particular document
is at https://example.com/documents/foo, the site could return different
URLs for Content-Location depending on the request's
Accept header:



Request header
Response header




Accept: application/json, text/json
Content-Location: /documents/foo.json


Accept: application/xml, text/xml
Content-Location: /documents/foo.xml


Accept: text/plain, text/*
Content-Location: /documents/foo.txt



These URLs are examples — the site could serve the different filetypes with any URL
patterns it wishes, such as a query string parameter: /documents/foo?format=json,
/documents/foo?format=xml, and so on.
Then the client could remember that the JSON version is available at that particular
URL, skipping content negotiation the next time it requests that document.
The server could also consider other content negotiation headers, such
as Accept-Language.Indicating the URL of a transaction's resultSay you have a
<form> for sending
money to another user of a site.
html<form action="/send-payment" method="post">
  <p>
    <label>
      Who do you want to send the money to?
      <input type="text" name="recipient" />
    </label>
  </p>

  <p>
    <label>
      How much?
      <input type="number" name="amount" />
    </label>
  </p>

  <button type="submit">Send Money</button>
</form>

When the form is submitted, the site generates a receipt for the transaction. The
server could use Content-Location to indicate that receipt's URL for future
access.
httpHTTP/1.1 200 OK
Content-Type: text/html; charset=utf-8
Content-Location: /my-receipts/38

<!doctype html>
(Lots of HTML…)

<p>You sent $38.00 to ExampleUser.</p>

(Lots more HTML…)
SpecificationsSpecificationHTTP Semantics # field.content-locationBrowser compatibilitySee also
Location
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Apr 10, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nContent-LocationBaseline Widely availableThis feature is well established and works across many devices and browser versions. It’s been available across browsers since July 2015.Learn moreSee full compatibilityReport feedbackThe HTTP Content-Location representation header indicates an alternate location for the returned data.
It's main use is to indicate the URL of a resource transmitted as the result of content negotiation.
The Content-Location header is different from the Location header.
Content-Location indicates the direct URL to access the resource when content negotiation has happened, allowing the client to bypass future content negotiation for this resource.
Location, on the other hand, indicates either the target of a 3XX redirection or the URL of a newly created resource in a 201 Created response.

  
    
      Header type
      Representation header
    
    
      Forbidden request header
      No
    
  
SyntaxhttpContent-Location: <url>
Directives
<url>

A URL that can be absolute or relative to the request URL.

ExamplesRequesting data from a server in different formatsLet's say a site's API can return data in JSON, XML, or
CSV formats. If the URL for a particular document
is at https://example.com/documents/foo, the site could return different
URLs for Content-Location depending on the request's
Accept header:



Request header
Response header




Accept: application/json, text/json
Content-Location: /documents/foo.json


Accept: application/xml, text/xml
Content-Location: /documents/foo.xml


Accept: text/plain, text/*
Content-Location: /documents/foo.txt



These URLs are examples — the site could serve the different filetypes with any URL
patterns it wishes, such as a query string parameter: /documents/foo?format=json,
/documents/foo?format=xml, and so on.
Then the client could remember that the JSON version is available at that particular
URL, skipping content negotiation the next time it requests that document.
The server could also consider other content negotiation headers, such
as Accept-Language.Indicating the URL of a transaction's resultSay you have a
<form> for sending
money to another user of a site.
html<form action="/send-payment" method="post">
  <p>
    <label>
      Who do you want to send the money to?
      <input type="text" name="recipient" />
    </label>
  </p>

  <p>
    <label>
      How much?
      <input type="number" name="amount" />
    </label>
  </p>

  <button type="submit">Send Money</button>
</form>

When the form is submitted, the site generates a receipt for the transaction. The
server could use Content-Location to indicate that receipt's URL for future
access.
httpHTTP/1.1 200 OK
Content-Type: text/html; charset=utf-8
Content-Location: /my-receipts/38

<!doctype html>
(Lots of HTML…)

<p>You sent $38.00 to ExampleUser.</p>

(Lots more HTML…)
SpecificationsSpecificationHTTP Semantics # field.content-locationBrowser compatibilitySee also
Location
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Apr 10, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nContent-RangeBaseline Widely availableThis feature is well established and works across many devices and browser versions. It’s been available across browsers since July 2015.Learn moreSee full compatibilityReport feedbackThe HTTP Content-Range response header is used in range requests to indicate where the content of a response body belongs in relation to a complete resource.
It should only be included in 206 Partial Content or 416 Range Not Satisfiable responses.

  
    
      Header type
      
        Response header,
        Content header
      
    
    
      Forbidden request header
      No
    
    
      
        CORS-safelisted request header
      
      No
    
  
SyntaxhttpContent-Range: <unit> <range>/<size>
Content-Range: <unit> <range>/*
Content-Range: <unit> */<size>
Directives
<unit>

The unit for specifying ranges.
Currently, only bytes is supported.

<range>

A range with the format <range-start>-<range-end>, where <range-start> and <range-end> are integers for the start and end position (zero-indexed & inclusive) of the range in the given <unit>, respectively.
* is used in a 416 Range Not Satisfiable response to indicate that the value is not a range.

<size>

The total length of the document (or * if unknown).

ExamplesPartial content responseThis 206 Partial Content response shows a partial response, with the Content-Range indicating that it contains the first 1024 bytes of a 146515 byte file.
httpHTTP/2 206
content-type: image/jpeg
content-length: 1024
content-range: bytes 0-1023/146515
…

(binary content)
Range not satisfiableIf the server cannot satisfy the requested range request, it should respond with a 416 Range Not Satisfiable status, and the Content-Range should specify * for the range along with the total size of the resource.
httpHTTP/2 416

Content-Range: bytes */67589
SpecificationsSpecificationHTTP Semantics # field.content-rangeBrowser compatibilitySee also
HTTP range requests guide
If-Range, Range headers
Content-Type
206 Partial Content, 416 Range Not Satisfiable status codes\n\nContent-RangeBaseline Widely availableThis feature is well established and works across many devices and browser versions. It’s been available across browsers since July 2015.Learn moreSee full compatibilityReport feedbackThe HTTP Content-Range response header is used in range requests to indicate where the content of a response body belongs in relation to a complete resource.
It should only be included in 206 Partial Content or 416 Range Not Satisfiable responses.

  
    
      Header type
      
        Response header,
        Content header
      
    
    
      Forbidden request header
      No
    
    
      
        CORS-safelisted request header
      
      No
    
  
SyntaxhttpContent-Range: <unit> <range>/<size>
Content-Range: <unit> <range>/*
Content-Range: <unit> */<size>
Directives
<unit>

The unit for specifying ranges.
Currently, only bytes is supported.

<range>

A range with the format <range-start>-<range-end>, where <range-start> and <range-end> are integers for the start and end position (zero-indexed & inclusive) of the range in the given <unit>, respectively.
* is used in a 416 Range Not Satisfiable response to indicate that the value is not a range.

<size>

The total length of the document (or * if unknown).

ExamplesPartial content responseThis 206 Partial Content response shows a partial response, with the Content-Range indicating that it contains the first 1024 bytes of a 146515 byte file.
httpHTTP/2 206
content-type: image/jpeg
content-length: 1024
content-range: bytes 0-1023/146515
…

(binary content)
Range not satisfiableIf the server cannot satisfy the requested range request, it should respond with a 416 Range Not Satisfiable status, and the Content-Range should specify * for the range along with the total size of the resource.
httpHTTP/2 416

Content-Range: bytes */67589
SpecificationsSpecificationHTTP Semantics # field.content-rangeBrowser compatibilitySee also
HTTP range requests guide
If-Range, Range headers
Content-Type
206 Partial Content, 416 Range Not Satisfiable status codes
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nContent-RangeBaseline Widely availableThis feature is well established and works across many devices and browser versions. It’s been available across browsers since July 2015.Learn moreSee full compatibilityReport feedbackThe HTTP Content-Range response header is used in range requests to indicate where the content of a response body belongs in relation to a complete resource.
It should only be included in 206 Partial Content or 416 Range Not Satisfiable responses.

  
    
      Header type
      
        Response header,
        Content header
      
    
    
      Forbidden request header
      No
    
    
      
        CORS-safelisted request header
      
      No
    
  
SyntaxhttpContent-Range: <unit> <range>/<size>
Content-Range: <unit> <range>/*
Content-Range: <unit> */<size>
Directives
<unit>

The unit for specifying ranges.
Currently, only bytes is supported.

<range>

A range with the format <range-start>-<range-end>, where <range-start> and <range-end> are integers for the start and end position (zero-indexed & inclusive) of the range in the given <unit>, respectively.
* is used in a 416 Range Not Satisfiable response to indicate that the value is not a range.

<size>

The total length of the document (or * if unknown).

ExamplesPartial content responseThis 206 Partial Content response shows a partial response, with the Content-Range indicating that it contains the first 1024 bytes of a 146515 byte file.
httpHTTP/2 206
content-type: image/jpeg
content-length: 1024
content-range: bytes 0-1023/146515
…

(binary content)
Range not satisfiableIf the server cannot satisfy the requested range request, it should respond with a 416 Range Not Satisfiable status, and the Content-Range should specify * for the range along with the total size of the resource.
httpHTTP/2 416

Content-Range: bytes */67589
SpecificationsSpecificationHTTP Semantics # field.content-rangeBrowser compatibilitySee also
HTTP range requests guide
If-Range, Range headers
Content-Type
206 Partial Content, 416 Range Not Satisfiable status codes
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nContent-Security-Policy (CSP)Baseline Widely available *This feature is well established and works across many devices and browser versions. It’s been available across browsers since August 2016.* Some parts of this feature may have varying levels of support.Learn moreSee full compatibilityReport feedbackThe HTTP Content-Security-Policy response header allows website administrators to control resources the user agent is allowed to load for a given page. With a few exceptions, policies mostly involve specifying server origins and script endpoints.
This helps guard against cross-site scripting attacks.
See the Content Security Policy (CSP) guide for details about how a CSP is delivered to the browser, what it looks like, along with use cases and deployment strategies.

  
    
      Header type
      Response header
    
    
      Forbidden request header
      no
    
  
SyntaxhttpContent-Security-Policy: <policy-directive>; <policy-directive>

where <policy-directive> consists of:
<directive> <value> with no internal punctuation.DirectivesFetch directivesFetch directives control the locations from which certain resource types may be loaded.

child-src

Defines the valid sources for web workers and nested browsing contexts loaded using elements such as
<frame> and <iframe>.
Fallback for frame-src and worker-src.

connect-src

Restricts the URLs which can be loaded using script interfaces.

default-src

Serves as a fallback for the other fetch directives.
Fallback for all other fetch directives.

fenced-frame-src 
Experimental


Specifies valid sources for nested browsing contexts loaded into <fencedframe> elements.

font-src

Specifies valid sources for fonts loaded using @font-face.

frame-src

Specifies valid sources for nested browsing contexts loaded into elements such as
<frame> and <iframe>.

img-src

Specifies valid sources of images and favicons.

manifest-src

Specifies valid sources of application manifest files.

media-src

Specifies valid sources for loading media using the <audio>,
<video> and <track> elements.

object-src

Specifies valid sources for the <object> and <embed> elements.

prefetch-src 
Deprecated
 
Non-standard


Specifies valid sources to be prefetched or prerendered.

script-src

Specifies valid sources for JavaScript and WebAssembly resources.
Fallback for script-src-elem and script-src-attr.

script-src-elem

Specifies valid sources for JavaScript <script> elements.

script-src-attr

Specifies valid sources for JavaScript inline event handlers.

style-src

Specifies valid sources for stylesheets.
Fallback for style-src-elem and style-src-attr.

style-src-elem

Specifies valid sources for stylesheets <style> elements and
<link> elements with rel="stylesheet".

style-src-attr

Specifies valid sources for inline styles applied to individual DOM elements.

worker-src

Specifies valid sources for Worker, SharedWorker, or
ServiceWorker scripts.


All fetch directives may be specified the single value 'none', indicating that the specific resource type should be completely blocked, or as one or more source expression values, indicating valid sources for that resource type. See Fetch directive syntax for more details.
Fallbacks
Some fetch directives function as fallbacks for other more granular directives. This means that if the more granular directive is not specified, then the fallback is used to provide a policy for that resource type.

default-src is a fallback for all other fetch directives.
script-src is a fallback for script-src-attr and script-src-elem.
style-src is a fallback for style-src-attr and style-src-elem.
child-src is a fallback for frame-src and worker-src.

For example:

If img-src is omitted but default-src is included, then the policy defined by default-src will be applied to images.
If script-src-elem is omitted but script-src is included, then the policy defined by script-src will be applied to <script> elements.
If script-src-elem and script-src are both omitted, but default-src is included, then the policy defined by default-src will be applied to <script> elements.
Document directivesDocument directives govern the properties of a document or worker environment to which a policy
applies.

base-uri

Restricts the URLs which can be used in a document's <base>
element.

sandbox

Enables a sandbox for the requested resource similar to the
<iframe> sandbox attribute.

Navigation directivesNavigation directives govern to which locations a user can navigate or submit a form,
for example.

form-action

Restricts the URLs which can be used as the target of a form submissions from a
given context.

frame-ancestors

Specifies valid parents that may embed a page using <frame>,
<iframe>, <object>, or <embed>.

Reporting directivesReporting directives control the destination URL for CSP violation reports in Content-Security-Policy and Content-Security-Policy-Report-Only.

report-to

Provides the browser with a token identifying the reporting endpoint or group of endpoints to send CSP violation information to.
The endpoints that the token represents are provided through other HTTP headers, such as Reporting-Endpoints and Report-To 
Deprecated
.

Warning:
This directive is intended to replace report-uri; in browsers that support report-to, the report-uri directive is ignored.
However until report-to is broadly supported you should specify both headers as shown (where endpoint_name is the name of a separately provided endpoint):
httpContent-Security-Policy: …; report-uri https://endpoint.example.com; report-to endpoint_name



Other directives
require-trusted-types-for

Enforces Trusted Types at the DOM XSS injection sinks.

trusted-types

Used to specify an allowlist of Trusted Types policies.
Trusted Types allows applications to lock down DOM XSS injection sinks to only accept non-spoofable, typed values in place of strings.

upgrade-insecure-requests

Instructs user agents to treat all of a site's insecure URLs (those served over
HTTP) as though they have been replaced with secure URLs (those served over HTTPS).
This directive is intended for websites with large numbers of insecure legacy URLs
that need to be rewritten.

Deprecated directives
block-all-mixed-content 
Deprecated


Prevents loading any assets using HTTP when the page is loaded using HTTPS.

report-uri 
Deprecated


Provides the browser with a URL where CSP violation reports should be sent.
This has been superseded by the report-to directive.

Fetch directive syntaxAll fetch directives may be specified as one of the following:

the single value 'none', indicating that the specific resource type should be completely blocked
one or more source expression values, indicating valid sources for that resource type.

Each source expression takes one of the forms listed below. Note that not all forms are applicable to all fetch directives: see the documentation for each fetch directive to find out which forms are applicable to it.
The <host-source> and <scheme-source> formats must be unquoted, and all other formats must be enclosed in single quotes.'nonce-<nonce_value>'This value consists of the string nonce- followed by a base64-encoded string. This string is a random value that the server generates for every HTTP response. For example:
'nonce-416d1177-4d12-4e3b-b7c9-f6c409789fb8'

The server can then include the same value as the value of the nonce attribute of any <script> or <style> resources that they intend to load from the document.
The browser compares the value from the CSP directive against the value in the element attribute, and loads the resource only if they match.
If a directive contains a nonce and unsafe-inline, then the browser ignores unsafe-inline.
See Nonces in the CSP guide for more usage information.

Note:
Nonce source expressions are only applicable to <script> and <style> elements.
'<hash_algorithm>-<hash_value>'This value consists of a string identifying a hash algorithm, followed by -, followed by a base64-encoded string representing the hash value.

The hash algorithm identifier must be one of sha256, sha384, or sha512.
The hash value is the base64-encoded hash of a <script> or <style> resource, calculated using one of the following hash functions: SHA-256, SHA-384, or SHA-512.

For example:
'sha256-cd9827ad...'

When the browser receives the document, it hashes the contents of any <script> and <style> elements, compares the result with any hashes in the CSP directive, and loads the resource only if there is a match.
If the element loads an external resource (for example, using the src attribute), then the element must also have the integrity attribute set.
If a directive contains a hash and unsafe-inline, then the browser ignores unsafe-inline.
See Hashes in the CSP guide for more usage information.

Note:
Hash source expressions are only applicable to <script> and <style> elements.
<host-source>The URL or IP address of a host that is a valid source for the resource.
The scheme, port number, and path are optional.
If the scheme is omitted, the scheme of the document's origin is used.
When matching schemes, secure upgrades are allowed. For example:

http://example.com will also permit resources from https://example.com
ws://example.org will also permit resources from wss://example.org.

Wildcards ('*') can be used for subdomains, host address, and port number, indicating that all legal values of each are valid. For example:

http://*.example.com permits resources from any subdomain of example.com, over HTTP or HTTPS.

Paths that end in / match any path they are a prefix of. For example:

example.com/api/ will permit resources from example.com/api/users/new.

Paths that do not end in / are matched exactly. For example:

https://example.com/file.js permits resources from https://example.com/file.js but not https://example.com/file.js/file2.js.
<scheme-source>A scheme, such as https:. The colon is required.
Secure upgrades are allowed, so:

http: will also permit resources loaded using HTTPS
ws: will also permit resources loaded using WSS.
'self'Resources of the given type may only be loaded from the same origin as the document.
Secure upgrades are allowed. For example:

If the document is served from http://example.com, then a CSP of 'self' will also permit resources from https://example.com.
If the document is served from ws://example.org, then a CSP of 'self' will also permit resources from wss://example.org.
'unsafe-eval'By default, if a CSP contains a default-src or a script-src directive, then JavaScript functions which evaluate their arguments as JavaScript are disabled. This includes eval(), the code argument to setTimeout(), or the Function() constructor.
The unsafe-eval keyword can be used to undo this protection, allowing dynamic evaluation of strings as JavaScript.

Warning:
Developers should avoid 'unsafe-eval', because it defeats much of the purpose of having a CSP.

See eval() and similar APIs in the CSP guide for more usage information.'wasm-unsafe-eval'By default, if a CSP contains a default-src or a script-src directive, then a page won't be allowed to compile WebAssembly using functions like WebAssembly.compileStreaming().
The wasm-unsafe-eval keyword can be used to undo this protection. This is a much safer alternative to 'unsafe-eval', since it does not enable general evaluation of JavaScript.'unsafe-inline'By default, if a CSP contains a default-src or a script-src directive, then inline JavaScript is not allowed to execute. This includes:

inline <script> tags
inline event handler attributes
javascript: URLs.

Similarly, if a CSP contains default-src or a style-src directive, then inline CSS will not be loaded, including:

inline <style> tags
style attributes.

The unsafe-inline keyword can be used to undo this protection, allowing all these forms to be loaded.

Warning:
Developers should avoid 'unsafe-inline', because it defeats much of the purpose of having a CSP.

See Inline JavaScript in the CSP guide for more usage information.'unsafe-hashes'By default, if a CSP contains a default-src or a script-src directive, then inline event handler attributes like onclick and inline style attributes are not allowed to execute.
The 'unsafe-hashes' expression allows the browser to use hash expressions for inline event handlers and style attributes. For example, a CSP might contain a directive like this:
httpscript-src 'unsafe-hashes' 'sha256-cd9827ad...'

If the hash value matches the hash of an inline event handler attribute value or of a style attribute value, then the code will be allowed to execute.

Warning:
The 'unsafe-hashes' value is unsafe.
In particular, it enables an attack in which the content of the inline event handler attribute is injected into the document as an inline <script> element. Suppose the inline event handler is:
html<button onclick="transferAllMyMoney()">Transfer all my money</button>

If an attacker can inject an inline <script> element containing this code, the CSP will allow it to execute automatically.
However, 'unsafe-hashes' is much safer than 'unsafe-inline'.
'inline-speculation-rules'By default, if a CSP contains a default-src or a script-src directive, then inline JavaScript is not allowed to execute. The 'inline-speculation-rules' allows the browser to load inline <script> elements that have a type attribute of speculationrules.
See the Speculation Rules API for more information.'strict-dynamic'The 'strict-dynamic' keyword makes the trust conferred on a script by a nonce or a hash extend to scripts that this script dynamically loads, for example by creating new <script> tags using Document.createElement() and then inserting them into the document using Node.appendChild().
If this keyword is present in a directive, then the following source expression values are all ignored:

<host-source>
<scheme-source>
'self'
'unsafe-inline'

See The strict-dynamic keyword in the CSP guide for more usage information.'report-sample'If this expression is included in a directive controlling scripts or styles, and the directive causes the browser to block any inline scripts, inline styles, or event handler attributes, then the violation report that the browser generates will contain a sample property containing the first 40 characters of the blocked resource.CSP in workersWorkers are in general not governed
by the content security policy of the document (or parent worker) that created them. To
specify a content security policy for the worker, set a
Content-Security-Policy response header for the request which requested the
worker script itself.
The exception to this is if the worker script's origin is a globally unique identifier
(for example, if its URL has a scheme of data or blob). In this case, the worker does
inherit the content security policy of the document or worker that created it.Multiple content security policiesThe CSP mechanism allows multiple policies being specified for a resource, including
via the Content-Security-Policy header, the
Content-Security-Policy-Report-Only header and a
<meta> element.
You can use the Content-Security-Policy header more than once, as in the
example below. Pay special attention to the connect-src directive here. Even
though the second policy would allow the connection, the first policy contains
connect-src 'none'. Adding additional policies can only further
restrict the capabilities of the protected resource, which means that there will
be no connection allowed and, as the strictest policy, connect-src 'none'
is enforced.
httpContent-Security-Policy: default-src 'self' http://example.com;
                          connect-src 'none';
Content-Security-Policy: connect-src http://example.com/;
                          script-src http://example.com/
ExamplesDisable unsafe inline code and only allow HTTPS resourcesThis HTTP header sets the default policy to only allow resource loading (images, fonts, scripts, etc.) over HTTPS.
Because the unsafe-inline and unsafe-eval directives are not set, inline scripts will be blocked.
httpContent-Security-Policy: default-src https:

The same restrictions can be applied using the HTML <meta> element.
html<meta http-equiv="Content-Security-Policy" content="default-src https:" />
Allow inline code and HTTPS resources, but disable pluginsThis policy could be used on a pre-existing site that uses too much inline code to fix, to ensure resources are loaded only over HTTPS and disable plugins:
httpContent-Security-Policy: default-src https: 'unsafe-eval' 'unsafe-inline'; object-src 'none'
Report but don't enforce violations when testingThis example sets the same restrictions as the previous example, but using the Content-Security-Policy-Report-Only header and the report-to directive.
This approach is used during testing to report violations but not block code from executing.
Endpoints (URLs) to send reports to are defined using the Reporting-Endpoints HTTP response header.
httpReporting-Endpoints: csp-endpoint="https://example.com/csp-reports"

A particular endpoint is then selected as the report target in the CSP policy using the report-to directive.
httpContent-Security-Policy-Report-Only: default-src https:; report-uri /csp-violation-report-url/; report-to csp-endpoint

Note that the report-uri 
Deprecated
 directive is also specified above because report-to is not yet broadly supported by browsers.
See Content Security Policy (CSP) implementation for more examples.SpecificationsSpecificationContent Security Policy Level 3 # csp-headerBrowser compatibilitySee also
Content-Security-Policy-Report-Only
Learn about: Content Security Policy
Content Security in WebExtensions
Adopting a strict policy
CSP Evaluator - Evaluate your
Content Security Policy\n\nContent-Security-Policy (CSP)Baseline Widely available *This feature is well established and works across many devices and browser versions. It’s been available across browsers since August 2016.* Some parts of this feature may have varying levels of support.Learn moreSee full compatibilityReport feedbackThe HTTP Content-Security-Policy response header allows website administrators to control resources the user agent is allowed to load for a given page. With a few exceptions, policies mostly involve specifying server origins and script endpoints.
This helps guard against cross-site scripting attacks.
See the Content Security Policy (CSP) guide for details about how a CSP is delivered to the browser, what it looks like, along with use cases and deployment strategies.

  
    
      Header type
      Response header
    
    
      Forbidden request header
      no
    
  
SyntaxhttpContent-Security-Policy: <policy-directive>; <policy-directive>

where <policy-directive> consists of:
<directive> <value> with no internal punctuation.DirectivesFetch directivesFetch directives control the locations from which certain resource types may be loaded.

child-src

Defines the valid sources for web workers and nested browsing contexts loaded using elements such as
<frame> and <iframe>.
Fallback for frame-src and worker-src.

connect-src

Restricts the URLs which can be loaded using script interfaces.

default-src

Serves as a fallback for the other fetch directives.
Fallback for all other fetch directives.

fenced-frame-src 
Experimental


Specifies valid sources for nested browsing contexts loaded into <fencedframe> elements.

font-src

Specifies valid sources for fonts loaded using @font-face.

frame-src

Specifies valid sources for nested browsing contexts loaded into elements such as
<frame> and <iframe>.

img-src

Specifies valid sources of images and favicons.

manifest-src

Specifies valid sources of application manifest files.

media-src

Specifies valid sources for loading media using the <audio>,
<video> and <track> elements.

object-src

Specifies valid sources for the <object> and <embed> elements.

prefetch-src 
Deprecated
 
Non-standard


Specifies valid sources to be prefetched or prerendered.

script-src

Specifies valid sources for JavaScript and WebAssembly resources.
Fallback for script-src-elem and script-src-attr.

script-src-elem

Specifies valid sources for JavaScript <script> elements.

script-src-attr

Specifies valid sources for JavaScript inline event handlers.

style-src

Specifies valid sources for stylesheets.
Fallback for style-src-elem and style-src-attr.

style-src-elem

Specifies valid sources for stylesheets <style> elements and
<link> elements with rel="stylesheet".

style-src-attr

Specifies valid sources for inline styles applied to individual DOM elements.

worker-src

Specifies valid sources for Worker, SharedWorker, or
ServiceWorker scripts.


All fetch directives may be specified the single value 'none', indicating that the specific resource type should be completely blocked, or as one or more source expression values, indicating valid sources for that resource type. See Fetch directive syntax for more details.
Fallbacks
Some fetch directives function as fallbacks for other more granular directives. This means that if the more granular directive is not specified, then the fallback is used to provide a policy for that resource type.

default-src is a fallback for all other fetch directives.
script-src is a fallback for script-src-attr and script-src-elem.
style-src is a fallback for style-src-attr and style-src-elem.
child-src is a fallback for frame-src and worker-src.

For example:

If img-src is omitted but default-src is included, then the policy defined by default-src will be applied to images.
If script-src-elem is omitted but script-src is included, then the policy defined by script-src will be applied to <script> elements.
If script-src-elem and script-src are both omitted, but default-src is included, then the policy defined by default-src will be applied to <script> elements.
Document directivesDocument directives govern the properties of a document or worker environment to which a policy
applies.

base-uri

Restricts the URLs which can be used in a document's <base>
element.

sandbox

Enables a sandbox for the requested resource similar to the
<iframe> sandbox attribute.

Navigation directivesNavigation directives govern to which locations a user can navigate or submit a form,
for example.

form-action

Restricts the URLs which can be used as the target of a form submissions from a
given context.

frame-ancestors

Specifies valid parents that may embed a page using <frame>,
<iframe>, <object>, or <embed>.

Reporting directivesReporting directives control the destination URL for CSP violation reports in Content-Security-Policy and Content-Security-Policy-Report-Only.

report-to

Provides the browser with a token identifying the reporting endpoint or group of endpoints to send CSP violation information to.
The endpoints that the token represents are provided through other HTTP headers, such as Reporting-Endpoints and Report-To 
Deprecated
.

Warning:
This directive is intended to replace report-uri; in browsers that support report-to, the report-uri directive is ignored.
However until report-to is broadly supported you should specify both headers as shown (where endpoint_name is the name of a separately provided endpoint):
httpContent-Security-Policy: …; report-uri https://endpoint.example.com; report-to endpoint_name



Other directives
require-trusted-types-for

Enforces Trusted Types at the DOM XSS injection sinks.

trusted-types

Used to specify an allowlist of Trusted Types policies.
Trusted Types allows applications to lock down DOM XSS injection sinks to only accept non-spoofable, typed values in place of strings.

upgrade-insecure-requests

Instructs user agents to treat all of a site's insecure URLs (those served over
HTTP) as though they have been replaced with secure URLs (those served over HTTPS).
This directive is intended for websites with large numbers of insecure legacy URLs
that need to be rewritten.

Deprecated directives
block-all-mixed-content 
Deprecated


Prevents loading any assets using HTTP when the page is loaded using HTTPS.

report-uri 
Deprecated


Provides the browser with a URL where CSP violation reports should be sent.
This has been superseded by the report-to directive.

Fetch directive syntaxAll fetch directives may be specified as one of the following:

the single value 'none', indicating that the specific resource type should be completely blocked
one or more source expression values, indicating valid sources for that resource type.

Each source expression takes one of the forms listed below. Note that not all forms are applicable to all fetch directives: see the documentation for each fetch directive to find out which forms are applicable to it.
The <host-source> and <scheme-source> formats must be unquoted, and all other formats must be enclosed in single quotes.'nonce-<nonce_value>'This value consists of the string nonce- followed by a base64-encoded string. This string is a random value that the server generates for every HTTP response. For example:
'nonce-416d1177-4d12-4e3b-b7c9-f6c409789fb8'

The server can then include the same value as the value of the nonce attribute of any <script> or <style> resources that they intend to load from the document.
The browser compares the value from the CSP directive against the value in the element attribute, and loads the resource only if they match.
If a directive contains a nonce and unsafe-inline, then the browser ignores unsafe-inline.
See Nonces in the CSP guide for more usage information.

Note:
Nonce source expressions are only applicable to <script> and <style> elements.
'<hash_algorithm>-<hash_value>'This value consists of a string identifying a hash algorithm, followed by -, followed by a base64-encoded string representing the hash value.

The hash algorithm identifier must be one of sha256, sha384, or sha512.
The hash value is the base64-encoded hash of a <script> or <style> resource, calculated using one of the following hash functions: SHA-256, SHA-384, or SHA-512.

For example:
'sha256-cd9827ad...'

When the browser receives the document, it hashes the contents of any <script> and <style> elements, compares the result with any hashes in the CSP directive, and loads the resource only if there is a match.
If the element loads an external resource (for example, using the src attribute), then the element must also have the integrity attribute set.
If a directive contains a hash and unsafe-inline, then the browser ignores unsafe-inline.
See Hashes in the CSP guide for more usage information.

Note:
Hash source expressions are only applicable to <script> and <style> elements.
<host-source>The URL or IP address of a host that is a valid source for the resource.
The scheme, port number, and path are optional.
If the scheme is omitted, the scheme of the document's origin is used.
When matching schemes, secure upgrades are allowed. For example:

http://example.com will also permit resources from https://example.com
ws://example.org will also permit resources from wss://example.org.

Wildcards ('*') can be used for subdomains, host address, and port number, indicating that all legal values of each are valid. For example:

http://*.example.com permits resources from any subdomain of example.com, over HTTP or HTTPS.

Paths that end in / match any path they are a prefix of. For example:

example.com/api/ will permit resources from example.com/api/users/new.

Paths that do not end in / are matched exactly. For example:

https://example.com/file.js permits resources from https://example.com/file.js but not https://example.com/file.js/file2.js.
<scheme-source>A scheme, such as https:. The colon is required.
Secure upgrades are allowed, so:

http: will also permit resources loaded using HTTPS
ws: will also permit resources loaded using WSS.
'self'Resources of the given type may only be loaded from the same origin as the document.
Secure upgrades are allowed. For example:

If the document is served from http://example.com, then a CSP of 'self' will also permit resources from https://example.com.
If the document is served from ws://example.org, then a CSP of 'self' will also permit resources from wss://example.org.
'unsafe-eval'By default, if a CSP contains a default-src or a script-src directive, then JavaScript functions which evaluate their arguments as JavaScript are disabled. This includes eval(), the code argument to setTimeout(), or the Function() constructor.
The unsafe-eval keyword can be used to undo this protection, allowing dynamic evaluation of strings as JavaScript.

Warning:
Developers should avoid 'unsafe-eval', because it defeats much of the purpose of having a CSP.

See eval() and similar APIs in the CSP guide for more usage information.'wasm-unsafe-eval'By default, if a CSP contains a default-src or a script-src directive, then a page won't be allowed to compile WebAssembly using functions like WebAssembly.compileStreaming().
The wasm-unsafe-eval keyword can be used to undo this protection. This is a much safer alternative to 'unsafe-eval', since it does not enable general evaluation of JavaScript.'unsafe-inline'By default, if a CSP contains a default-src or a script-src directive, then inline JavaScript is not allowed to execute. This includes:

inline <script> tags
inline event handler attributes
javascript: URLs.

Similarly, if a CSP contains default-src or a style-src directive, then inline CSS will not be loaded, including:

inline <style> tags
style attributes.

The unsafe-inline keyword can be used to undo this protection, allowing all these forms to be loaded.

Warning:
Developers should avoid 'unsafe-inline', because it defeats much of the purpose of having a CSP.

See Inline JavaScript in the CSP guide for more usage information.'unsafe-hashes'By default, if a CSP contains a default-src or a script-src directive, then inline event handler attributes like onclick and inline style attributes are not allowed to execute.
The 'unsafe-hashes' expression allows the browser to use hash expressions for inline event handlers and style attributes. For example, a CSP might contain a directive like this:
httpscript-src 'unsafe-hashes' 'sha256-cd9827ad...'

If the hash value matches the hash of an inline event handler attribute value or of a style attribute value, then the code will be allowed to execute.

Warning:
The 'unsafe-hashes' value is unsafe.
In particular, it enables an attack in which the content of the inline event handler attribute is injected into the document as an inline <script> element. Suppose the inline event handler is:
html<button onclick="transferAllMyMoney()">Transfer all my money</button>

If an attacker can inject an inline <script> element containing this code, the CSP will allow it to execute automatically.
However, 'unsafe-hashes' is much safer than 'unsafe-inline'.
'inline-speculation-rules'By default, if a CSP contains a default-src or a script-src directive, then inline JavaScript is not allowed to execute. The 'inline-speculation-rules' allows the browser to load inline <script> elements that have a type attribute of speculationrules.
See the Speculation Rules API for more information.'strict-dynamic'The 'strict-dynamic' keyword makes the trust conferred on a script by a nonce or a hash extend to scripts that this script dynamically loads, for example by creating new <script> tags using Document.createElement() and then inserting them into the document using Node.appendChild().
If this keyword is present in a directive, then the following source expression values are all ignored:

<host-source>
<scheme-source>
'self'
'unsafe-inline'

See The strict-dynamic keyword in the CSP guide for more usage information.'report-sample'If this expression is included in a directive controlling scripts or styles, and the directive causes the browser to block any inline scripts, inline styles, or event handler attributes, then the violation report that the browser generates will contain a sample property containing the first 40 characters of the blocked resource.CSP in workersWorkers are in general not governed
by the content security policy of the document (or parent worker) that created them. To
specify a content security policy for the worker, set a
Content-Security-Policy response header for the request which requested the
worker script itself.
The exception to this is if the worker script's origin is a globally unique identifier
(for example, if its URL has a scheme of data or blob). In this case, the worker does
inherit the content security policy of the document or worker that created it.Multiple content security policiesThe CSP mechanism allows multiple policies being specified for a resource, including
via the Content-Security-Policy header, the
Content-Security-Policy-Report-Only header and a
<meta> element.
You can use the Content-Security-Policy header more than once, as in the
example below. Pay special attention to the connect-src directive here. Even
though the second policy would allow the connection, the first policy contains
connect-src 'none'. Adding additional policies can only further
restrict the capabilities of the protected resource, which means that there will
be no connection allowed and, as the strictest policy, connect-src 'none'
is enforced.
httpContent-Security-Policy: default-src 'self' http://example.com;
                          connect-src 'none';
Content-Security-Policy: connect-src http://example.com/;
                          script-src http://example.com/
ExamplesDisable unsafe inline code and only allow HTTPS resourcesThis HTTP header sets the default policy to only allow resource loading (images, fonts, scripts, etc.) over HTTPS.
Because the unsafe-inline and unsafe-eval directives are not set, inline scripts will be blocked.
httpContent-Security-Policy: default-src https:

The same restrictions can be applied using the HTML <meta> element.
html<meta http-equiv="Content-Security-Policy" content="default-src https:" />
Allow inline code and HTTPS resources, but disable pluginsThis policy could be used on a pre-existing site that uses too much inline code to fix, to ensure resources are loaded only over HTTPS and disable plugins:
httpContent-Security-Policy: default-src https: 'unsafe-eval' 'unsafe-inline'; object-src 'none'
Report but don't enforce violations when testingThis example sets the same restrictions as the previous example, but using the Content-Security-Policy-Report-Only header and the report-to directive.
This approach is used during testing to report violations but not block code from executing.
Endpoints (URLs) to send reports to are defined using the Reporting-Endpoints HTTP response header.
httpReporting-Endpoints: csp-endpoint="https://example.com/csp-reports"

A particular endpoint is then selected as the report target in the CSP policy using the report-to directive.
httpContent-Security-Policy-Report-Only: default-src https:; report-uri /csp-violation-report-url/; report-to csp-endpoint

Note that the report-uri 
Deprecated
 directive is also specified above because report-to is not yet broadly supported by browsers.
See Content Security Policy (CSP) implementation for more examples.SpecificationsSpecificationContent Security Policy Level 3 # csp-headerBrowser compatibilitySee also
Content-Security-Policy-Report-Only
Learn about: Content Security Policy
Content Security in WebExtensions
Adopting a strict policy
CSP Evaluator - Evaluate your
Content Security Policy
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Apr 10, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nContent-Security-Policy (CSP)Baseline Widely available *This feature is well established and works across many devices and browser versions. It’s been available across browsers since August 2016.* Some parts of this feature may have varying levels of support.Learn moreSee full compatibilityReport feedbackThe HTTP Content-Security-Policy response header allows website administrators to control resources the user agent is allowed to load for a given page. With a few exceptions, policies mostly involve specifying server origins and script endpoints.
This helps guard against cross-site scripting attacks.
See the Content Security Policy (CSP) guide for details about how a CSP is delivered to the browser, what it looks like, along with use cases and deployment strategies.

  
    
      Header type
      Response header
    
    
      Forbidden request header
      no
    
  
SyntaxhttpContent-Security-Policy: <policy-directive>; <policy-directive>

where <policy-directive> consists of:
<directive> <value> with no internal punctuation.DirectivesFetch directivesFetch directives control the locations from which certain resource types may be loaded.

child-src

Defines the valid sources for web workers and nested browsing contexts loaded using elements such as
<frame> and <iframe>.
Fallback for frame-src and worker-src.

connect-src

Restricts the URLs which can be loaded using script interfaces.

default-src

Serves as a fallback for the other fetch directives.
Fallback for all other fetch directives.

fenced-frame-src 
Experimental


Specifies valid sources for nested browsing contexts loaded into <fencedframe> elements.

font-src

Specifies valid sources for fonts loaded using @font-face.

frame-src

Specifies valid sources for nested browsing contexts loaded into elements such as
<frame> and <iframe>.

img-src

Specifies valid sources of images and favicons.

manifest-src

Specifies valid sources of application manifest files.

media-src

Specifies valid sources for loading media using the <audio>,
<video> and <track> elements.

object-src

Specifies valid sources for the <object> and <embed> elements.

prefetch-src 
Deprecated
 
Non-standard


Specifies valid sources to be prefetched or prerendered.

script-src

Specifies valid sources for JavaScript and WebAssembly resources.
Fallback for script-src-elem and script-src-attr.

script-src-elem

Specifies valid sources for JavaScript <script> elements.

script-src-attr

Specifies valid sources for JavaScript inline event handlers.

style-src

Specifies valid sources for stylesheets.
Fallback for style-src-elem and style-src-attr.

style-src-elem

Specifies valid sources for stylesheets <style> elements and
<link> elements with rel="stylesheet".

style-src-attr

Specifies valid sources for inline styles applied to individual DOM elements.

worker-src

Specifies valid sources for Worker, SharedWorker, or
ServiceWorker scripts.


All fetch directives may be specified the single value 'none', indicating that the specific resource type should be completely blocked, or as one or more source expression values, indicating valid sources for that resource type. See Fetch directive syntax for more details.
Fallbacks
Some fetch directives function as fallbacks for other more granular directives. This means that if the more granular directive is not specified, then the fallback is used to provide a policy for that resource type.

default-src is a fallback for all other fetch directives.
script-src is a fallback for script-src-attr and script-src-elem.
style-src is a fallback for style-src-attr and style-src-elem.
child-src is a fallback for frame-src and worker-src.

For example:

If img-src is omitted but default-src is included, then the policy defined by default-src will be applied to images.
If script-src-elem is omitted but script-src is included, then the policy defined by script-src will be applied to <script> elements.
If script-src-elem and script-src are both omitted, but default-src is included, then the policy defined by default-src will be applied to <script> elements.
Document directivesDocument directives govern the properties of a document or worker environment to which a policy
applies.

base-uri

Restricts the URLs which can be used in a document's <base>
element.

sandbox

Enables a sandbox for the requested resource similar to the
<iframe> sandbox attribute.

Navigation directivesNavigation directives govern to which locations a user can navigate or submit a form,
for example.

form-action

Restricts the URLs which can be used as the target of a form submissions from a
given context.

frame-ancestors

Specifies valid parents that may embed a page using <frame>,
<iframe>, <object>, or <embed>.

Reporting directivesReporting directives control the destination URL for CSP violation reports in Content-Security-Policy and Content-Security-Policy-Report-Only.

report-to

Provides the browser with a token identifying the reporting endpoint or group of endpoints to send CSP violation information to.
The endpoints that the token represents are provided through other HTTP headers, such as Reporting-Endpoints and Report-To 
Deprecated
.

Warning:
This directive is intended to replace report-uri; in browsers that support report-to, the report-uri directive is ignored.
However until report-to is broadly supported you should specify both headers as shown (where endpoint_name is the name of a separately provided endpoint):
httpContent-Security-Policy: …; report-uri https://endpoint.example.com; report-to endpoint_name



Other directives
require-trusted-types-for

Enforces Trusted Types at the DOM XSS injection sinks.

trusted-types

Used to specify an allowlist of Trusted Types policies.
Trusted Types allows applications to lock down DOM XSS injection sinks to only accept non-spoofable, typed values in place of strings.

upgrade-insecure-requests

Instructs user agents to treat all of a site's insecure URLs (those served over
HTTP) as though they have been replaced with secure URLs (those served over HTTPS).
This directive is intended for websites with large numbers of insecure legacy URLs
that need to be rewritten.

Deprecated directives
block-all-mixed-content 
Deprecated


Prevents loading any assets using HTTP when the page is loaded using HTTPS.

report-uri 
Deprecated


Provides the browser with a URL where CSP violation reports should be sent.
This has been superseded by the report-to directive.

Fetch directive syntaxAll fetch directives may be specified as one of the following:

the single value 'none', indicating that the specific resource type should be completely blocked
one or more source expression values, indicating valid sources for that resource type.

Each source expression takes one of the forms listed below. Note that not all forms are applicable to all fetch directives: see the documentation for each fetch directive to find out which forms are applicable to it.
The <host-source> and <scheme-source> formats must be unquoted, and all other formats must be enclosed in single quotes.'nonce-<nonce_value>'This value consists of the string nonce- followed by a base64-encoded string. This string is a random value that the server generates for every HTTP response. For example:
'nonce-416d1177-4d12-4e3b-b7c9-f6c409789fb8'

The server can then include the same value as the value of the nonce attribute of any <script> or <style> resources that they intend to load from the document.
The browser compares the value from the CSP directive against the value in the element attribute, and loads the resource only if they match.
If a directive contains a nonce and unsafe-inline, then the browser ignores unsafe-inline.
See Nonces in the CSP guide for more usage information.

Note:
Nonce source expressions are only applicable to <script> and <style> elements.
'<hash_algorithm>-<hash_value>'This value consists of a string identifying a hash algorithm, followed by -, followed by a base64-encoded string representing the hash value.

The hash algorithm identifier must be one of sha256, sha384, or sha512.
The hash value is the base64-encoded hash of a <script> or <style> resource, calculated using one of the following hash functions: SHA-256, SHA-384, or SHA-512.

For example:
'sha256-cd9827ad...'

When the browser receives the document, it hashes the contents of any <script> and <style> elements, compares the result with any hashes in the CSP directive, and loads the resource only if there is a match.
If the element loads an external resource (for example, using the src attribute), then the element must also have the integrity attribute set.
If a directive contains a hash and unsafe-inline, then the browser ignores unsafe-inline.
See Hashes in the CSP guide for more usage information.

Note:
Hash source expressions are only applicable to <script> and <style> elements.
<host-source>The URL or IP address of a host that is a valid source for the resource.
The scheme, port number, and path are optional.
If the scheme is omitted, the scheme of the document's origin is used.
When matching schemes, secure upgrades are allowed. For example:

http://example.com will also permit resources from https://example.com
ws://example.org will also permit resources from wss://example.org.

Wildcards ('*') can be used for subdomains, host address, and port number, indicating that all legal values of each are valid. For example:

http://*.example.com permits resources from any subdomain of example.com, over HTTP or HTTPS.

Paths that end in / match any path they are a prefix of. For example:

example.com/api/ will permit resources from example.com/api/users/new.

Paths that do not end in / are matched exactly. For example:

https://example.com/file.js permits resources from https://example.com/file.js but not https://example.com/file.js/file2.js.
<scheme-source>A scheme, such as https:. The colon is required.
Secure upgrades are allowed, so:

http: will also permit resources loaded using HTTPS
ws: will also permit resources loaded using WSS.
'self'Resources of the given type may only be loaded from the same origin as the document.
Secure upgrades are allowed. For example:

If the document is served from http://example.com, then a CSP of 'self' will also permit resources from https://example.com.
If the document is served from ws://example.org, then a CSP of 'self' will also permit resources from wss://example.org.
'unsafe-eval'By default, if a CSP contains a default-src or a script-src directive, then JavaScript functions which evaluate their arguments as JavaScript are disabled. This includes eval(), the code argument to setTimeout(), or the Function() constructor.
The unsafe-eval keyword can be used to undo this protection, allowing dynamic evaluation of strings as JavaScript.

Warning:
Developers should avoid 'unsafe-eval', because it defeats much of the purpose of having a CSP.

See eval() and similar APIs in the CSP guide for more usage information.'wasm-unsafe-eval'By default, if a CSP contains a default-src or a script-src directive, then a page won't be allowed to compile WebAssembly using functions like WebAssembly.compileStreaming().
The wasm-unsafe-eval keyword can be used to undo this protection. This is a much safer alternative to 'unsafe-eval', since it does not enable general evaluation of JavaScript.'unsafe-inline'By default, if a CSP contains a default-src or a script-src directive, then inline JavaScript is not allowed to execute. This includes:

inline <script> tags
inline event handler attributes
javascript: URLs.

Similarly, if a CSP contains default-src or a style-src directive, then inline CSS will not be loaded, including:

inline <style> tags
style attributes.

The unsafe-inline keyword can be used to undo this protection, allowing all these forms to be loaded.

Warning:
Developers should avoid 'unsafe-inline', because it defeats much of the purpose of having a CSP.

See Inline JavaScript in the CSP guide for more usage information.'unsafe-hashes'By default, if a CSP contains a default-src or a script-src directive, then inline event handler attributes like onclick and inline style attributes are not allowed to execute.
The 'unsafe-hashes' expression allows the browser to use hash expressions for inline event handlers and style attributes. For example, a CSP might contain a directive like this:
httpscript-src 'unsafe-hashes' 'sha256-cd9827ad...'

If the hash value matches the hash of an inline event handler attribute value or of a style attribute value, then the code will be allowed to execute.

Warning:
The 'unsafe-hashes' value is unsafe.
In particular, it enables an attack in which the content of the inline event handler attribute is injected into the document as an inline <script> element. Suppose the inline event handler is:
html<button onclick="transferAllMyMoney()">Transfer all my money</button>

If an attacker can inject an inline <script> element containing this code, the CSP will allow it to execute automatically.
However, 'unsafe-hashes' is much safer than 'unsafe-inline'.
'inline-speculation-rules'By default, if a CSP contains a default-src or a script-src directive, then inline JavaScript is not allowed to execute. The 'inline-speculation-rules' allows the browser to load inline <script> elements that have a type attribute of speculationrules.
See the Speculation Rules API for more information.'strict-dynamic'The 'strict-dynamic' keyword makes the trust conferred on a script by a nonce or a hash extend to scripts that this script dynamically loads, for example by creating new <script> tags using Document.createElement() and then inserting them into the document using Node.appendChild().
If this keyword is present in a directive, then the following source expression values are all ignored:

<host-source>
<scheme-source>
'self'
'unsafe-inline'

See The strict-dynamic keyword in the CSP guide for more usage information.'report-sample'If this expression is included in a directive controlling scripts or styles, and the directive causes the browser to block any inline scripts, inline styles, or event handler attributes, then the violation report that the browser generates will contain a sample property containing the first 40 characters of the blocked resource.CSP in workersWorkers are in general not governed
by the content security policy of the document (or parent worker) that created them. To
specify a content security policy for the worker, set a
Content-Security-Policy response header for the request which requested the
worker script itself.
The exception to this is if the worker script's origin is a globally unique identifier
(for example, if its URL has a scheme of data or blob). In this case, the worker does
inherit the content security policy of the document or worker that created it.Multiple content security policiesThe CSP mechanism allows multiple policies being specified for a resource, including
via the Content-Security-Policy header, the
Content-Security-Policy-Report-Only header and a
<meta> element.
You can use the Content-Security-Policy header more than once, as in the
example below. Pay special attention to the connect-src directive here. Even
though the second policy would allow the connection, the first policy contains
connect-src 'none'. Adding additional policies can only further
restrict the capabilities of the protected resource, which means that there will
be no connection allowed and, as the strictest policy, connect-src 'none'
is enforced.
httpContent-Security-Policy: default-src 'self' http://example.com;
                          connect-src 'none';
Content-Security-Policy: connect-src http://example.com/;
                          script-src http://example.com/
ExamplesDisable unsafe inline code and only allow HTTPS resourcesThis HTTP header sets the default policy to only allow resource loading (images, fonts, scripts, etc.) over HTTPS.
Because the unsafe-inline and unsafe-eval directives are not set, inline scripts will be blocked.
httpContent-Security-Policy: default-src https:

The same restrictions can be applied using the HTML <meta> element.
html<meta http-equiv="Content-Security-Policy" content="default-src https:" />
Allow inline code and HTTPS resources, but disable pluginsThis policy could be used on a pre-existing site that uses too much inline code to fix, to ensure resources are loaded only over HTTPS and disable plugins:
httpContent-Security-Policy: default-src https: 'unsafe-eval' 'unsafe-inline'; object-src 'none'
Report but don't enforce violations when testingThis example sets the same restrictions as the previous example, but using the Content-Security-Policy-Report-Only header and the report-to directive.
This approach is used during testing to report violations but not block code from executing.
Endpoints (URLs) to send reports to are defined using the Reporting-Endpoints HTTP response header.
httpReporting-Endpoints: csp-endpoint="https://example.com/csp-reports"

A particular endpoint is then selected as the report target in the CSP policy using the report-to directive.
httpContent-Security-Policy-Report-Only: default-src https:; report-uri /csp-violation-report-url/; report-to csp-endpoint

Note that the report-uri 
Deprecated
 directive is also specified above because report-to is not yet broadly supported by browsers.
See Content Security Policy (CSP) implementation for more examples.SpecificationsSpecificationContent Security Policy Level 3 # csp-headerBrowser compatibilitySee also
Content-Security-Policy-Report-Only
Learn about: Content Security Policy
Content Security in WebExtensions
Adopting a strict policy
CSP Evaluator - Evaluate your
Content Security Policy
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Apr 10, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nContent-Security-Policy-Report-OnlyBaseline Widely availableThis feature is well established and works across many devices and browser versions. It’s been available across browsers since August 2016.Learn moreSee full compatibilityReport feedbackThe HTTP Content-Security-Policy-Report-Only response header helps to monitor Content Security Policy (CSP) violations and their effects without enforcing the security policies.
This header allows you to test or repair violations before a specific Content-Security-Policy is applied and enforced.
The CSP report-to directive must be specified for reports to be sent: if not, the operation won't have any effect.
Violation reports are sent using the Reporting API to endpoints defined in a Reporting-Endpoints HTTP response header and selected using the CSP report-to directive.
For more information, see our Content Security Policy (CSP) guide.

Note:
The header can also be used with the deprecated report-uri directive (this is being replaced by report-to).
The usage and resulting report syntax is slightly different; see the report-uri topic for more details.


  
    
      Header type
      Response header
    
    
      Forbidden request header
      No
    
    
      
        This header is not supported inside a <meta> element.
      
    
  
SyntaxhttpContent-Security-Policy-Report-Only: <policy-directive>; …; <policy-directive>; report-to <endpoint-name>
DirectivesThe Content-Security-Policy-Report-Only header supports all Content-Security-Policy directives except sandbox, which is ignored.

Note:
The CSP report-to directive should be used with this header or it will have no effect.
ExamplesUsing Content-Security-Policy-Report-Only to send CSP reportsTo use the report-to directive, you first need to define a corresponding endpoint using the Reporting-Endpoints response header.
In the example below, we define a single endpoint named csp-endpoint.
httpReporting-Endpoints: csp-endpoint="https://example.com/csp-reports"

We can then define the destination of the report using report-to and report-uri, as shown below.
Note that this particular report would be triggered if the page loaded resources insecurely, or from inline code.
httpContent-Security-Policy-Report-Only: default-src https:;
  report-uri /csp-report-url/;
  report-to csp-endpoint;


Note:
The report-to directive is preferred over the deprecated report-uri, but we declare both because report-to does not yet have full cross-browser support.
SpecificationsSpecificationContent Security Policy Level 3 # cspro-headerBrowser compatibilitySee also
Content-Security-Policy
CSP report-to directive
CSP report-uri directive 
Deprecated\n\nContent-Security-Policy-Report-OnlyBaseline Widely availableThis feature is well established and works across many devices and browser versions. It’s been available across browsers since August 2016.Learn moreSee full compatibilityReport feedbackThe HTTP Content-Security-Policy-Report-Only response header helps to monitor Content Security Policy (CSP) violations and their effects without enforcing the security policies.
This header allows you to test or repair violations before a specific Content-Security-Policy is applied and enforced.
The CSP report-to directive must be specified for reports to be sent: if not, the operation won't have any effect.
Violation reports are sent using the Reporting API to endpoints defined in a Reporting-Endpoints HTTP response header and selected using the CSP report-to directive.
For more information, see our Content Security Policy (CSP) guide.

Note:
The header can also be used with the deprecated report-uri directive (this is being replaced by report-to).
The usage and resulting report syntax is slightly different; see the report-uri topic for more details.


  
    
      Header type
      Response header
    
    
      Forbidden request header
      No
    
    
      
        This header is not supported inside a <meta> element.
      
    
  
SyntaxhttpContent-Security-Policy-Report-Only: <policy-directive>; …; <policy-directive>; report-to <endpoint-name>
DirectivesThe Content-Security-Policy-Report-Only header supports all Content-Security-Policy directives except sandbox, which is ignored.

Note:
The CSP report-to directive should be used with this header or it will have no effect.
ExamplesUsing Content-Security-Policy-Report-Only to send CSP reportsTo use the report-to directive, you first need to define a corresponding endpoint using the Reporting-Endpoints response header.
In the example below, we define a single endpoint named csp-endpoint.
httpReporting-Endpoints: csp-endpoint="https://example.com/csp-reports"

We can then define the destination of the report using report-to and report-uri, as shown below.
Note that this particular report would be triggered if the page loaded resources insecurely, or from inline code.
httpContent-Security-Policy-Report-Only: default-src https:;
  report-uri /csp-report-url/;
  report-to csp-endpoint;


Note:
The report-to directive is preferred over the deprecated report-uri, but we declare both because report-to does not yet have full cross-browser support.
SpecificationsSpecificationContent Security Policy Level 3 # cspro-headerBrowser compatibilitySee also
Content-Security-Policy
CSP report-to directive
CSP report-uri directive 
Deprecated

Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nContent-Security-Policy-Report-OnlyBaseline Widely availableThis feature is well established and works across many devices and browser versions. It’s been available across browsers since August 2016.Learn moreSee full compatibilityReport feedbackThe HTTP Content-Security-Policy-Report-Only response header helps to monitor Content Security Policy (CSP) violations and their effects without enforcing the security policies.
This header allows you to test or repair violations before a specific Content-Security-Policy is applied and enforced.
The CSP report-to directive must be specified for reports to be sent: if not, the operation won't have any effect.
Violation reports are sent using the Reporting API to endpoints defined in a Reporting-Endpoints HTTP response header and selected using the CSP report-to directive.
For more information, see our Content Security Policy (CSP) guide.

Note:
The header can also be used with the deprecated report-uri directive (this is being replaced by report-to).
The usage and resulting report syntax is slightly different; see the report-uri topic for more details.


  
    
      Header type
      Response header
    
    
      Forbidden request header
      No
    
    
      
        This header is not supported inside a <meta> element.
      
    
  
SyntaxhttpContent-Security-Policy-Report-Only: <policy-directive>; …; <policy-directive>; report-to <endpoint-name>
DirectivesThe Content-Security-Policy-Report-Only header supports all Content-Security-Policy directives except sandbox, which is ignored.

Note:
The CSP report-to directive should be used with this header or it will have no effect.
ExamplesUsing Content-Security-Policy-Report-Only to send CSP reportsTo use the report-to directive, you first need to define a corresponding endpoint using the Reporting-Endpoints response header.
In the example below, we define a single endpoint named csp-endpoint.
httpReporting-Endpoints: csp-endpoint="https://example.com/csp-reports"

We can then define the destination of the report using report-to and report-uri, as shown below.
Note that this particular report would be triggered if the page loaded resources insecurely, or from inline code.
httpContent-Security-Policy-Report-Only: default-src https:;
  report-uri /csp-report-url/;
  report-to csp-endpoint;


Note:
The report-to directive is preferred over the deprecated report-uri, but we declare both because report-to does not yet have full cross-browser support.
SpecificationsSpecificationContent Security Policy Level 3 # cspro-headerBrowser compatibilitySee also
Content-Security-Policy
CSP report-to directive
CSP report-uri directive 
Deprecated

Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nContent-TypeBaseline Widely availableThis feature is well established and works across many devices and browser versions. It’s been available across browsers since July 2015.Learn moreSee full compatibilityReport feedbackThe HTTP Content-Type representation header is used to indicate the original media type of a resource before any content encoding is applied.
In responses, the Content-Type header informs the client about the media type of the returned data.
In requests such as POST or PUT, the client uses the Content-Type header to specify the type of content being sent to the server.
If a server implementation or configuration is strict about content type handling, a 415 client error response may be returned.
The Content-Type header differs from Content-Encoding in that Content-Encoding helps the recipient understand how to decode data to its original form.

Note:
This value may be ignored if browsers perform MIME sniffing (or content sniffing) on responses.
To prevent browsers from using MIME sniffing, set the X-Content-Type-Options header value to nosniff.
See MIME type verification for more details.


  
    
      Header type
      Representation header
    
    
      Forbidden request header
      No
    
    
      
        CORS-safelisted response header
      
      Yes
    
    
      
        CORS-safelisted request header
      
      
        Yes*
      
    
  

* Values can't contain a CORS-unsafe request header byte: "():<>?@[\]{},, Delete 0x7F, and control characters 0x00 to 0x19 except for Tab 0x09.
It also needs to have a media type of its parsed value (ignoring parameters) of either application/x-www-form-urlencoded, multipart/form-data, or text/plain.SyntaxContent-Type: <media-type>

For example:
httpContent-Type: text/html; charset=utf-8
Content-Type: multipart/form-data; boundary=ExampleBoundaryString
Directives
<media-type>

The media type of the resource or data.
May contain the following parameters:

charset: Indicates the character encoding standard used.
The value is case insensitive but lowercase is preferred.
boundary: For multipart entities, the boundary parameter is required.
It is used to demarcate the boundaries of the multiple parts of the message.
The value consists of 1 to 70 characters (not ending with white space) known to be robust in the context of different systems (e.g., email gateways).
Often, the header boundary is prepended by two dashes in the request body, and the final boundary has two dashes appended at the end.


ExamplesServing assets with correct content typeIn the following two example responses, JavaScript and CSS assets are served using text/javascript for JavaScript and text/css for CSS.
The correct content type for these resources helps the browser handle them more securely and with better performance.
See Properly configuring server MIME types for more information.
httpHTTP/1.1 200
content-encoding: br
content-type: text/javascript; charset=utf-8
vary: Accept-Encoding
date: Fri, 21 Jun 2024 14:02:25 GMT
content-length: 2978

const videoPlayer=document.getElementById...

httpHTTP/3 200
server: nginx
date: Wed, 24 Jul 2024 16:53:02 GMT
content-type: text/css
vary: Accept-Encoding
content-encoding: br

.super-container{clear:both;max-width:100%}...
Content-Type in multipart formsIn a POST request resulting from an HTML form submission, the Content-Type of the request is specified by the enctype attribute on the <form> element.
html<form action="/foo" method="post" enctype="multipart/form-data">
  <input type="text" name="description" value="Description input value" />
  <input type="file" name="myFile" />
  <button type="submit">Submit</button>
</form>

The request looks something like the following example with some headers omitted for brevity.
In the request, a boundary of ExampleBoundaryString is used for illustration, but in practice, a browser would create a string more like this ---------------------------1003363413119651595289485765.
httpPOST /foo HTTP/1.1
Content-Length: 68137
Content-Type: multipart/form-data; boundary=ExampleBoundaryString

--ExampleBoundaryString
Content-Disposition: form-data; name="description"

Description input value
--ExampleBoundaryString
Content-Disposition: form-data; name="myFile"; filename="foo.txt"
Content-Type: text/plain

[content of the file foo.txt chosen by the user]
--ExampleBoundaryString--
Content-Type in URL-encoded form submissionWhen forms don't involve file uploads and are using simpler fields, URL-encoded forms may be more convenient where the form data is included in the request body:
html<form action="/submit" method="post">
  <label for="comment">Comment:</label>
  <input type="text" id="comment" name="comment" value="Hello!" />
  <button type="submit">Submit</button>
</form>

httpPOST /submit HTTP/1.1
Host: example.com
Content-Type: application/x-www-form-urlencoded
Content-Length: 15

comment=Hello!
Content-Type in a REST API using JSONMany REST APIs use application/json as a content type which is convenient for machine-to-machine communication or programmatic interaction.
The following example shows a 201 Created response showing the result of a successful request:
httpHTTP/1.1 201 Created
Content-Type: application/json

{
  "message": "New user created",
  "user": {
    "id": 123,
    "firstName": "Paul",
    "lastName": "Klee",
    "email": "p.klee@example.com"
  }
}
SpecificationsSpecificationHTTP Semantics # status.206HTTP Semantics # field.content-typeBrowser compatibilitySee also
Accept, Accept-Encoding, Accept-Language headers
Vary
Content-Encoding
Content-Disposition
206 Partial Content
X-Content-Type-Options\n\nContent-TypeBaseline Widely availableThis feature is well established and works across many devices and browser versions. It’s been available across browsers since July 2015.Learn moreSee full compatibilityReport feedbackThe HTTP Content-Type representation header is used to indicate the original media type of a resource before any content encoding is applied.
In responses, the Content-Type header informs the client about the media type of the returned data.
In requests such as POST or PUT, the client uses the Content-Type header to specify the type of content being sent to the server.
If a server implementation or configuration is strict about content type handling, a 415 client error response may be returned.
The Content-Type header differs from Content-Encoding in that Content-Encoding helps the recipient understand how to decode data to its original form.

Note:
This value may be ignored if browsers perform MIME sniffing (or content sniffing) on responses.
To prevent browsers from using MIME sniffing, set the X-Content-Type-Options header value to nosniff.
See MIME type verification for more details.


  
    
      Header type
      Representation header
    
    
      Forbidden request header
      No
    
    
      
        CORS-safelisted response header
      
      Yes
    
    
      
        CORS-safelisted request header
      
      
        Yes*
      
    
  

* Values can't contain a CORS-unsafe request header byte: "():<>?@[\]{},, Delete 0x7F, and control characters 0x00 to 0x19 except for Tab 0x09.
It also needs to have a media type of its parsed value (ignoring parameters) of either application/x-www-form-urlencoded, multipart/form-data, or text/plain.SyntaxContent-Type: <media-type>

For example:
httpContent-Type: text/html; charset=utf-8
Content-Type: multipart/form-data; boundary=ExampleBoundaryString
Directives
<media-type>

The media type of the resource or data.
May contain the following parameters:

charset: Indicates the character encoding standard used.
The value is case insensitive but lowercase is preferred.
boundary: For multipart entities, the boundary parameter is required.
It is used to demarcate the boundaries of the multiple parts of the message.
The value consists of 1 to 70 characters (not ending with white space) known to be robust in the context of different systems (e.g., email gateways).
Often, the header boundary is prepended by two dashes in the request body, and the final boundary has two dashes appended at the end.


ExamplesServing assets with correct content typeIn the following two example responses, JavaScript and CSS assets are served using text/javascript for JavaScript and text/css for CSS.
The correct content type for these resources helps the browser handle them more securely and with better performance.
See Properly configuring server MIME types for more information.
httpHTTP/1.1 200
content-encoding: br
content-type: text/javascript; charset=utf-8
vary: Accept-Encoding
date: Fri, 21 Jun 2024 14:02:25 GMT
content-length: 2978

const videoPlayer=document.getElementById...

httpHTTP/3 200
server: nginx
date: Wed, 24 Jul 2024 16:53:02 GMT
content-type: text/css
vary: Accept-Encoding
content-encoding: br

.super-container{clear:both;max-width:100%}...
Content-Type in multipart formsIn a POST request resulting from an HTML form submission, the Content-Type of the request is specified by the enctype attribute on the <form> element.
html<form action="/foo" method="post" enctype="multipart/form-data">
  <input type="text" name="description" value="Description input value" />
  <input type="file" name="myFile" />
  <button type="submit">Submit</button>
</form>

The request looks something like the following example with some headers omitted for brevity.
In the request, a boundary of ExampleBoundaryString is used for illustration, but in practice, a browser would create a string more like this ---------------------------1003363413119651595289485765.
httpPOST /foo HTTP/1.1
Content-Length: 68137
Content-Type: multipart/form-data; boundary=ExampleBoundaryString

--ExampleBoundaryString
Content-Disposition: form-data; name="description"

Description input value
--ExampleBoundaryString
Content-Disposition: form-data; name="myFile"; filename="foo.txt"
Content-Type: text/plain

[content of the file foo.txt chosen by the user]
--ExampleBoundaryString--
Content-Type in URL-encoded form submissionWhen forms don't involve file uploads and are using simpler fields, URL-encoded forms may be more convenient where the form data is included in the request body:
html<form action="/submit" method="post">
  <label for="comment">Comment:</label>
  <input type="text" id="comment" name="comment" value="Hello!" />
  <button type="submit">Submit</button>
</form>

httpPOST /submit HTTP/1.1
Host: example.com
Content-Type: application/x-www-form-urlencoded
Content-Length: 15

comment=Hello!
Content-Type in a REST API using JSONMany REST APIs use application/json as a content type which is convenient for machine-to-machine communication or programmatic interaction.
The following example shows a 201 Created response showing the result of a successful request:
httpHTTP/1.1 201 Created
Content-Type: application/json

{
  "message": "New user created",
  "user": {
    "id": 123,
    "firstName": "Paul",
    "lastName": "Klee",
    "email": "p.klee@example.com"
  }
}
SpecificationsSpecificationHTTP Semantics # status.206HTTP Semantics # field.content-typeBrowser compatibilitySee also
Accept, Accept-Encoding, Accept-Language headers
Vary
Content-Encoding
Content-Disposition
206 Partial Content
X-Content-Type-Options
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nContent-TypeBaseline Widely availableThis feature is well established and works across many devices and browser versions. It’s been available across browsers since July 2015.Learn moreSee full compatibilityReport feedbackThe HTTP Content-Type representation header is used to indicate the original media type of a resource before any content encoding is applied.
In responses, the Content-Type header informs the client about the media type of the returned data.
In requests such as POST or PUT, the client uses the Content-Type header to specify the type of content being sent to the server.
If a server implementation or configuration is strict about content type handling, a 415 client error response may be returned.
The Content-Type header differs from Content-Encoding in that Content-Encoding helps the recipient understand how to decode data to its original form.

Note:
This value may be ignored if browsers perform MIME sniffing (or content sniffing) on responses.
To prevent browsers from using MIME sniffing, set the X-Content-Type-Options header value to nosniff.
See MIME type verification for more details.


  
    
      Header type
      Representation header
    
    
      Forbidden request header
      No
    
    
      
        CORS-safelisted response header
      
      Yes
    
    
      
        CORS-safelisted request header
      
      
        Yes*
      
    
  

* Values can't contain a CORS-unsafe request header byte: "():<>?@[\]{},, Delete 0x7F, and control characters 0x00 to 0x19 except for Tab 0x09.
It also needs to have a media type of its parsed value (ignoring parameters) of either application/x-www-form-urlencoded, multipart/form-data, or text/plain.SyntaxContent-Type: <media-type>

For example:
httpContent-Type: text/html; charset=utf-8
Content-Type: multipart/form-data; boundary=ExampleBoundaryString
Directives
<media-type>

The media type of the resource or data.
May contain the following parameters:

charset: Indicates the character encoding standard used.
The value is case insensitive but lowercase is preferred.
boundary: For multipart entities, the boundary parameter is required.
It is used to demarcate the boundaries of the multiple parts of the message.
The value consists of 1 to 70 characters (not ending with white space) known to be robust in the context of different systems (e.g., email gateways).
Often, the header boundary is prepended by two dashes in the request body, and the final boundary has two dashes appended at the end.


ExamplesServing assets with correct content typeIn the following two example responses, JavaScript and CSS assets are served using text/javascript for JavaScript and text/css for CSS.
The correct content type for these resources helps the browser handle them more securely and with better performance.
See Properly configuring server MIME types for more information.
httpHTTP/1.1 200
content-encoding: br
content-type: text/javascript; charset=utf-8
vary: Accept-Encoding
date: Fri, 21 Jun 2024 14:02:25 GMT
content-length: 2978

const videoPlayer=document.getElementById...

httpHTTP/3 200
server: nginx
date: Wed, 24 Jul 2024 16:53:02 GMT
content-type: text/css
vary: Accept-Encoding
content-encoding: br

.super-container{clear:both;max-width:100%}...
Content-Type in multipart formsIn a POST request resulting from an HTML form submission, the Content-Type of the request is specified by the enctype attribute on the <form> element.
html<form action="/foo" method="post" enctype="multipart/form-data">
  <input type="text" name="description" value="Description input value" />
  <input type="file" name="myFile" />
  <button type="submit">Submit</button>
</form>

The request looks something like the following example with some headers omitted for brevity.
In the request, a boundary of ExampleBoundaryString is used for illustration, but in practice, a browser would create a string more like this ---------------------------1003363413119651595289485765.
httpPOST /foo HTTP/1.1
Content-Length: 68137
Content-Type: multipart/form-data; boundary=ExampleBoundaryString

--ExampleBoundaryString
Content-Disposition: form-data; name="description"

Description input value
--ExampleBoundaryString
Content-Disposition: form-data; name="myFile"; filename="foo.txt"
Content-Type: text/plain

[content of the file foo.txt chosen by the user]
--ExampleBoundaryString--
Content-Type in URL-encoded form submissionWhen forms don't involve file uploads and are using simpler fields, URL-encoded forms may be more convenient where the form data is included in the request body:
html<form action="/submit" method="post">
  <label for="comment">Comment:</label>
  <input type="text" id="comment" name="comment" value="Hello!" />
  <button type="submit">Submit</button>
</form>

httpPOST /submit HTTP/1.1
Host: example.com
Content-Type: application/x-www-form-urlencoded
Content-Length: 15

comment=Hello!
Content-Type in a REST API using JSONMany REST APIs use application/json as a content type which is convenient for machine-to-machine communication or programmatic interaction.
The following example shows a 201 Created response showing the result of a successful request:
httpHTTP/1.1 201 Created
Content-Type: application/json

{
  "message": "New user created",
  "user": {
    "id": 123,
    "firstName": "Paul",
    "lastName": "Klee",
    "email": "p.klee@example.com"
  }
}
SpecificationsSpecificationHTTP Semantics # status.206HTTP Semantics # field.content-typeBrowser compatibilitySee also
Accept, Accept-Encoding, Accept-Language headers
Vary
Content-Encoding
Content-Disposition
206 Partial Content
X-Content-Type-Options
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nCookieBaseline Widely availableThis feature is well established and works across many devices and browser versions. It’s been available across browsers since July 2015.Learn moreSee full compatibilityReport feedbackThe HTTP Cookie request header contains stored HTTP cookies associated with the server (i.e., previously sent by the server with the Set-Cookie header or set in JavaScript using Document.cookie).
The Cookie header is optional and may be omitted if, for example, the browser's privacy settings block cookies.

  
    
      Header type
      Request header
    
    
      Forbidden request header
      Yes
    
  
SyntaxhttpCookie: <cookie-list>
Cookie: name=value
Cookie: name=value; name2=value2; name3=value3
Directives
<cookie-list>

A list of name-value pairs in the form of <cookie-name>=<cookie-value>.
Pairs in the list are separated by a semicolon and a space.

ExampleshttpCookie: PHPSESSID=298zf09hf012fh2; csrftoken=u32t4o3tb3gg43; _gat=1
SpecificationsSpecificationHTTP State Management Mechanism # cookieBrowser compatibilitySee also
413 Content Too Large
Set-Cookie
Document.cookie\n\nCookieBaseline Widely availableThis feature is well established and works across many devices and browser versions. It’s been available across browsers since July 2015.Learn moreSee full compatibilityReport feedbackThe HTTP Cookie request header contains stored HTTP cookies associated with the server (i.e., previously sent by the server with the Set-Cookie header or set in JavaScript using Document.cookie).
The Cookie header is optional and may be omitted if, for example, the browser's privacy settings block cookies.

  
    
      Header type
      Request header
    
    
      Forbidden request header
      Yes
    
  
SyntaxhttpCookie: <cookie-list>
Cookie: name=value
Cookie: name=value; name2=value2; name3=value3
Directives
<cookie-list>

A list of name-value pairs in the form of <cookie-name>=<cookie-value>.
Pairs in the list are separated by a semicolon and a space.

ExampleshttpCookie: PHPSESSID=298zf09hf012fh2; csrftoken=u32t4o3tb3gg43; _gat=1
SpecificationsSpecificationHTTP State Management Mechanism # cookieBrowser compatibilitySee also
413 Content Too Large
Set-Cookie
Document.cookie
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nCookieBaseline Widely availableThis feature is well established and works across many devices and browser versions. It’s been available across browsers since July 2015.Learn moreSee full compatibilityReport feedbackThe HTTP Cookie request header contains stored HTTP cookies associated with the server (i.e., previously sent by the server with the Set-Cookie header or set in JavaScript using Document.cookie).
The Cookie header is optional and may be omitted if, for example, the browser's privacy settings block cookies.

  
    
      Header type
      Request header
    
    
      Forbidden request header
      Yes
    
  
SyntaxhttpCookie: <cookie-list>
Cookie: name=value
Cookie: name=value; name2=value2; name3=value3
Directives
<cookie-list>

A list of name-value pairs in the form of <cookie-name>=<cookie-value>.
Pairs in the list are separated by a semicolon and a space.

ExampleshttpCookie: PHPSESSID=298zf09hf012fh2; csrftoken=u32t4o3tb3gg43; _gat=1
SpecificationsSpecificationHTTP State Management Mechanism # cookieBrowser compatibilitySee also
413 Content Too Large
Set-Cookie
Document.cookie
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nCritical-CHExperimental: This is an experimental technologyCheck the Browser compatibility table carefully before using this in production.
Secure context: This feature is available only in secure contexts (HTTPS), in some or all supporting browsers.
The HTTP Critical-CH response header is used along with Accept-CH to identify the accepted client hints that are critical.
User agents receiving a response with Critical-CH must check if the indicated critical headers were sent in the original request. If not, the user agent will retry the request along with the critical headers rather than render the page. This approach ensures that client preferences set using critical client hints are always used, even if not included in the first request, or following server configuration changes.
Each header listed in the Critical-CH header should also be present in the Accept-CH and Vary headers.

  
    
      Header type
      
        Response header
      
    
    
      Forbidden request header
      No
    
  
SyntaxhttpCritical-CH: <ch-list>
Directives
<ch-list>

A list of one or more comma-delimited client hint headers that the server considers to be critical client hints.

ExamplesThe client makes an initial request to the server:
httpGET / HTTP/1.1
Host: example.com

The server responds, indicating via Accept-CH that it accepts Sec-CH-Prefers-Reduced-Motion. In this example, Critical-CH is also used to specify that Sec-CH-Prefers-Reduced-Motion is considered a critical client hint.
httpHTTP/1.1 200 OK
Content-Type: text/html
Accept-CH: Sec-CH-Prefers-Reduced-Motion
Vary: Sec-CH-Prefers-Reduced-Motion
Critical-CH: Sec-CH-Prefers-Reduced-Motion


Note:
We've specified Sec-CH-Prefers-Reduced-Motion in the Vary header to indicate that responses should be separately cached based on the value of this header (even if the URL stays the same).
Each header listed in the Critical-CH header should also be present in the Accept-CH and Vary headers.

The client automatically retries the request (due to Critical-CH being specified above), telling the server via Sec-CH-Prefers-Reduced-Motion that it has a user preference for reduced-motion animations:
httpGET / HTTP/1.1
Host: example.com
Sec-CH-Prefers-Reduced-Motion: "reduce"

The client will include the header in subsequent requests in the current session unless the Accept-CH changes in responses to indicate that it is no longer supported by the server.SpecificationsSpecificationClient Hint Reliability # name-the-critical-ch-response-heBrowser compatibilitySee also
Client hints
User-Agent Client Hints API
Improving user privacy and developer experience with User-Agent Client Hints (developer.chrome.com)
Accept-CH
HTTP Caching: Vary and Vary
PerformanceNavigationTiming.criticalCHRestart\n\nCritical-CHExperimental: This is an experimental technologyCheck the Browser compatibility table carefully before using this in production.
Secure context: This feature is available only in secure contexts (HTTPS), in some or all supporting browsers.
The HTTP Critical-CH response header is used along with Accept-CH to identify the accepted client hints that are critical.
User agents receiving a response with Critical-CH must check if the indicated critical headers were sent in the original request. If not, the user agent will retry the request along with the critical headers rather than render the page. This approach ensures that client preferences set using critical client hints are always used, even if not included in the first request, or following server configuration changes.
Each header listed in the Critical-CH header should also be present in the Accept-CH and Vary headers.

  
    
      Header type
      
        Response header
      
    
    
      Forbidden request header
      No
    
  
SyntaxhttpCritical-CH: <ch-list>
Directives
<ch-list>

A list of one or more comma-delimited client hint headers that the server considers to be critical client hints.

ExamplesThe client makes an initial request to the server:
httpGET / HTTP/1.1
Host: example.com

The server responds, indicating via Accept-CH that it accepts Sec-CH-Prefers-Reduced-Motion. In this example, Critical-CH is also used to specify that Sec-CH-Prefers-Reduced-Motion is considered a critical client hint.
httpHTTP/1.1 200 OK
Content-Type: text/html
Accept-CH: Sec-CH-Prefers-Reduced-Motion
Vary: Sec-CH-Prefers-Reduced-Motion
Critical-CH: Sec-CH-Prefers-Reduced-Motion


Note:
We've specified Sec-CH-Prefers-Reduced-Motion in the Vary header to indicate that responses should be separately cached based on the value of this header (even if the URL stays the same).
Each header listed in the Critical-CH header should also be present in the Accept-CH and Vary headers.

The client automatically retries the request (due to Critical-CH being specified above), telling the server via Sec-CH-Prefers-Reduced-Motion that it has a user preference for reduced-motion animations:
httpGET / HTTP/1.1
Host: example.com
Sec-CH-Prefers-Reduced-Motion: "reduce"

The client will include the header in subsequent requests in the current session unless the Accept-CH changes in responses to indicate that it is no longer supported by the server.SpecificationsSpecificationClient Hint Reliability # name-the-critical-ch-response-heBrowser compatibilitySee also
Client hints
User-Agent Client Hints API
Improving user privacy and developer experience with User-Agent Client Hints (developer.chrome.com)
Accept-CH
HTTP Caching: Vary and Vary
PerformanceNavigationTiming.criticalCHRestart
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nCritical-CHExperimental: This is an experimental technologyCheck the Browser compatibility table carefully before using this in production.
Secure context: This feature is available only in secure contexts (HTTPS), in some or all supporting browsers.
The HTTP Critical-CH response header is used along with Accept-CH to identify the accepted client hints that are critical.
User agents receiving a response with Critical-CH must check if the indicated critical headers were sent in the original request. If not, the user agent will retry the request along with the critical headers rather than render the page. This approach ensures that client preferences set using critical client hints are always used, even if not included in the first request, or following server configuration changes.
Each header listed in the Critical-CH header should also be present in the Accept-CH and Vary headers.

  
    
      Header type
      
        Response header
      
    
    
      Forbidden request header
      No
    
  
SyntaxhttpCritical-CH: <ch-list>
Directives
<ch-list>

A list of one or more comma-delimited client hint headers that the server considers to be critical client hints.

ExamplesThe client makes an initial request to the server:
httpGET / HTTP/1.1
Host: example.com

The server responds, indicating via Accept-CH that it accepts Sec-CH-Prefers-Reduced-Motion. In this example, Critical-CH is also used to specify that Sec-CH-Prefers-Reduced-Motion is considered a critical client hint.
httpHTTP/1.1 200 OK
Content-Type: text/html
Accept-CH: Sec-CH-Prefers-Reduced-Motion
Vary: Sec-CH-Prefers-Reduced-Motion
Critical-CH: Sec-CH-Prefers-Reduced-Motion


Note:
We've specified Sec-CH-Prefers-Reduced-Motion in the Vary header to indicate that responses should be separately cached based on the value of this header (even if the URL stays the same).
Each header listed in the Critical-CH header should also be present in the Accept-CH and Vary headers.

The client automatically retries the request (due to Critical-CH being specified above), telling the server via Sec-CH-Prefers-Reduced-Motion that it has a user preference for reduced-motion animations:
httpGET / HTTP/1.1
Host: example.com
Sec-CH-Prefers-Reduced-Motion: "reduce"

The client will include the header in subsequent requests in the current session unless the Accept-CH changes in responses to indicate that it is no longer supported by the server.SpecificationsSpecificationClient Hint Reliability # name-the-critical-ch-response-heBrowser compatibilitySee also
Client hints
User-Agent Client Hints API
Improving user privacy and developer experience with User-Agent Client Hints (developer.chrome.com)
Accept-CH
HTTP Caching: Vary and Vary
PerformanceNavigationTiming.criticalCHRestart
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nCross-Origin-Embedder-PolicyThe HTTP Cross-Origin-Embedder-Policy (COEP) response header configures the current document's policy for loading and embedding cross-origin resources.
The policy for whether a particular resource is embeddable cross-site may be defined for that resource using the Cross-Origin-Resource-Policy (CORP) header for a no-cors fetch, or using CORS.
If neither of these policies are set, then by default, resources can be loaded or embedded into a document as though they had a CORP value of cross-site.
The Cross-Origin-Embedder-Policy allows you to require that CORP or CORS headers be set in order to load cross-site resources into the current document.
You can also set the policy to keep the default behaviour, or to allow the resources to be loaded, but strip any credentials that might otherwise be sent.
The policy applies to loaded resources, and resources in <iframe>s and nested frames.

Note:
The Cross-Origin-Embedder-Policy doesn't override or affect the embedding behaviour for a resource for which CORP or CORS has been set.
If CORP restricts a resource to being embedded only same-origin, it won't be loaded cross-origin into a resource irrespective of the COEP value.


  
    
      Header type
      Response header
    
    
      Forbidden response header name
      No
    
  
SyntaxhttpCross-Origin-Embedder-Policy: unsafe-none | require-corp | credentialless
Directives
unsafe-none

Allows the document to load cross-origin resources without giving explicit permission through the CORS protocol or the Cross-Origin-Resource-Policy header.
This is the default value.

require-corp

A document can only load resources from the same origin, or resources explicitly marked as loadable from another origin.
Cross-origin resource loading will be blocked by COEP unless:

The resource is requested in no-cors mode and the response includes a Cross-Origin-Resource-Policy header that allows it to be loaded into the document origin.
The resource is requested in cors mode and the resource supports and is permitted by CORS.
This can be done, for example, in HTML using the crossorigin attribute, or in JavaScript by making a request with {mode="cors"}.


credentialless

A document can load cross-origin resources that are requested in no-cors mode without an explicit permission via the Cross-Origin-Resource-Policy header.
In this case requests are sent without credentials: cookies are omitted in the request, and ignored in the response.
The cross-origin loading behaviour for other request modes is the same as for require-corp.
For example, a cross-origin resource requested in cors mode must support (and be permitted by) CORS.

ExamplesFeatures that depend on cross-origin isolationCertain features, such as access to SharedArrayBuffer objects or using Performance.now() with unthrottled timers, are only available if your document is cross-origin isolated.
To use these features in a document, you will need to set the COEP header with a value of require-corp or credentialless, and the Cross-Origin-Opener-Policy header to same-origin.
In addition the feature must not be blocked by Permissions-Policy: cross-origin-isolated.
httpCross-Origin-Opener-Policy: same-origin
Cross-Origin-Embedder-Policy: require-corp

You can use the Window.crossOriginIsolated and WorkerGlobalScope.crossOriginIsolated properties to check if the features are restricted in window and worker contexts, respectively:
jsconst myWorker = new Worker("worker.js");

if (crossOriginIsolated) {
  const buffer = new SharedArrayBuffer(16);
  myWorker.postMessage(buffer);
} else {
  const buffer = new ArrayBuffer(16);
  myWorker.postMessage(buffer);
}
Avoiding COEP blockage with CORSIf you enable COEP using require-corp and want to embed a cross origin resource that supports CORS, you will need to explicitly specify that it is requested in cors mode.
For example, to fetch an image declared in HTML from a third-party site that supports CORS, you can use the crossorigin attribute so that it is requested in cors mode:
html<img src="https://thirdparty.com/img.png" crossorigin />

You can similarly use the HTMLScriptElement.crossOrigin attribute or fetch with { mode: 'cors' } to request a file in CORS mode using JavaScript.
If CORS is not supported for some images, a COEP value of credentialless can be used as an alternative to load the image without any explicit opt-in from the cross-origin server, at the cost of requesting it without cookies.SpecificationsSpecificationHTML # coepBrowser compatibilitySee also
Cross-Origin-Opener-Policy
Window.crossOriginIsolated and WorkerGlobalScope.crossOriginIsolated
Cross Origin Opener Policy in Why you need "cross-origin isolated" for powerful features on web.dev (2020)
COOP and COEP explained: Artur Janc, Charlie Reis, Anne van Kesteren (2020)\n\nCross-Origin-Embedder-PolicyThe HTTP Cross-Origin-Embedder-Policy (COEP) response header configures the current document's policy for loading and embedding cross-origin resources.
The policy for whether a particular resource is embeddable cross-site may be defined for that resource using the Cross-Origin-Resource-Policy (CORP) header for a no-cors fetch, or using CORS.
If neither of these policies are set, then by default, resources can be loaded or embedded into a document as though they had a CORP value of cross-site.
The Cross-Origin-Embedder-Policy allows you to require that CORP or CORS headers be set in order to load cross-site resources into the current document.
You can also set the policy to keep the default behaviour, or to allow the resources to be loaded, but strip any credentials that might otherwise be sent.
The policy applies to loaded resources, and resources in <iframe>s and nested frames.

Note:
The Cross-Origin-Embedder-Policy doesn't override or affect the embedding behaviour for a resource for which CORP or CORS has been set.
If CORP restricts a resource to being embedded only same-origin, it won't be loaded cross-origin into a resource irrespective of the COEP value.


  
    
      Header type
      Response header
    
    
      Forbidden response header name
      No
    
  
SyntaxhttpCross-Origin-Embedder-Policy: unsafe-none | require-corp | credentialless
Directives
unsafe-none

Allows the document to load cross-origin resources without giving explicit permission through the CORS protocol or the Cross-Origin-Resource-Policy header.
This is the default value.

require-corp

A document can only load resources from the same origin, or resources explicitly marked as loadable from another origin.
Cross-origin resource loading will be blocked by COEP unless:

The resource is requested in no-cors mode and the response includes a Cross-Origin-Resource-Policy header that allows it to be loaded into the document origin.
The resource is requested in cors mode and the resource supports and is permitted by CORS.
This can be done, for example, in HTML using the crossorigin attribute, or in JavaScript by making a request with {mode="cors"}.


credentialless

A document can load cross-origin resources that are requested in no-cors mode without an explicit permission via the Cross-Origin-Resource-Policy header.
In this case requests are sent without credentials: cookies are omitted in the request, and ignored in the response.
The cross-origin loading behaviour for other request modes is the same as for require-corp.
For example, a cross-origin resource requested in cors mode must support (and be permitted by) CORS.

ExamplesFeatures that depend on cross-origin isolationCertain features, such as access to SharedArrayBuffer objects or using Performance.now() with unthrottled timers, are only available if your document is cross-origin isolated.
To use these features in a document, you will need to set the COEP header with a value of require-corp or credentialless, and the Cross-Origin-Opener-Policy header to same-origin.
In addition the feature must not be blocked by Permissions-Policy: cross-origin-isolated.
httpCross-Origin-Opener-Policy: same-origin
Cross-Origin-Embedder-Policy: require-corp

You can use the Window.crossOriginIsolated and WorkerGlobalScope.crossOriginIsolated properties to check if the features are restricted in window and worker contexts, respectively:
jsconst myWorker = new Worker("worker.js");

if (crossOriginIsolated) {
  const buffer = new SharedArrayBuffer(16);
  myWorker.postMessage(buffer);
} else {
  const buffer = new ArrayBuffer(16);
  myWorker.postMessage(buffer);
}
Avoiding COEP blockage with CORSIf you enable COEP using require-corp and want to embed a cross origin resource that supports CORS, you will need to explicitly specify that it is requested in cors mode.
For example, to fetch an image declared in HTML from a third-party site that supports CORS, you can use the crossorigin attribute so that it is requested in cors mode:
html<img src="https://thirdparty.com/img.png" crossorigin />

You can similarly use the HTMLScriptElement.crossOrigin attribute or fetch with { mode: 'cors' } to request a file in CORS mode using JavaScript.
If CORS is not supported for some images, a COEP value of credentialless can be used as an alternative to load the image without any explicit opt-in from the cross-origin server, at the cost of requesting it without cookies.SpecificationsSpecificationHTML # coepBrowser compatibilitySee also
Cross-Origin-Opener-Policy
Window.crossOriginIsolated and WorkerGlobalScope.crossOriginIsolated
Cross Origin Opener Policy in Why you need "cross-origin isolated" for powerful features on web.dev (2020)
COOP and COEP explained: Artur Janc, Charlie Reis, Anne van Kesteren (2020)
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Apr 10, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nCross-Origin-Embedder-PolicyThe HTTP Cross-Origin-Embedder-Policy (COEP) response header configures the current document's policy for loading and embedding cross-origin resources.
The policy for whether a particular resource is embeddable cross-site may be defined for that resource using the Cross-Origin-Resource-Policy (CORP) header for a no-cors fetch, or using CORS.
If neither of these policies are set, then by default, resources can be loaded or embedded into a document as though they had a CORP value of cross-site.
The Cross-Origin-Embedder-Policy allows you to require that CORP or CORS headers be set in order to load cross-site resources into the current document.
You can also set the policy to keep the default behaviour, or to allow the resources to be loaded, but strip any credentials that might otherwise be sent.
The policy applies to loaded resources, and resources in <iframe>s and nested frames.

Note:
The Cross-Origin-Embedder-Policy doesn't override or affect the embedding behaviour for a resource for which CORP or CORS has been set.
If CORP restricts a resource to being embedded only same-origin, it won't be loaded cross-origin into a resource irrespective of the COEP value.


  
    
      Header type
      Response header
    
    
      Forbidden response header name
      No
    
  
SyntaxhttpCross-Origin-Embedder-Policy: unsafe-none | require-corp | credentialless
Directives
unsafe-none

Allows the document to load cross-origin resources without giving explicit permission through the CORS protocol or the Cross-Origin-Resource-Policy header.
This is the default value.

require-corp

A document can only load resources from the same origin, or resources explicitly marked as loadable from another origin.
Cross-origin resource loading will be blocked by COEP unless:

The resource is requested in no-cors mode and the response includes a Cross-Origin-Resource-Policy header that allows it to be loaded into the document origin.
The resource is requested in cors mode and the resource supports and is permitted by CORS.
This can be done, for example, in HTML using the crossorigin attribute, or in JavaScript by making a request with {mode="cors"}.


credentialless

A document can load cross-origin resources that are requested in no-cors mode without an explicit permission via the Cross-Origin-Resource-Policy header.
In this case requests are sent without credentials: cookies are omitted in the request, and ignored in the response.
The cross-origin loading behaviour for other request modes is the same as for require-corp.
For example, a cross-origin resource requested in cors mode must support (and be permitted by) CORS.

ExamplesFeatures that depend on cross-origin isolationCertain features, such as access to SharedArrayBuffer objects or using Performance.now() with unthrottled timers, are only available if your document is cross-origin isolated.
To use these features in a document, you will need to set the COEP header with a value of require-corp or credentialless, and the Cross-Origin-Opener-Policy header to same-origin.
In addition the feature must not be blocked by Permissions-Policy: cross-origin-isolated.
httpCross-Origin-Opener-Policy: same-origin
Cross-Origin-Embedder-Policy: require-corp

You can use the Window.crossOriginIsolated and WorkerGlobalScope.crossOriginIsolated properties to check if the features are restricted in window and worker contexts, respectively:
jsconst myWorker = new Worker("worker.js");

if (crossOriginIsolated) {
  const buffer = new SharedArrayBuffer(16);
  myWorker.postMessage(buffer);
} else {
  const buffer = new ArrayBuffer(16);
  myWorker.postMessage(buffer);
}
Avoiding COEP blockage with CORSIf you enable COEP using require-corp and want to embed a cross origin resource that supports CORS, you will need to explicitly specify that it is requested in cors mode.
For example, to fetch an image declared in HTML from a third-party site that supports CORS, you can use the crossorigin attribute so that it is requested in cors mode:
html<img src="https://thirdparty.com/img.png" crossorigin />

You can similarly use the HTMLScriptElement.crossOrigin attribute or fetch with { mode: 'cors' } to request a file in CORS mode using JavaScript.
If CORS is not supported for some images, a COEP value of credentialless can be used as an alternative to load the image without any explicit opt-in from the cross-origin server, at the cost of requesting it without cookies.SpecificationsSpecificationHTML # coepBrowser compatibilitySee also
Cross-Origin-Opener-Policy
Window.crossOriginIsolated and WorkerGlobalScope.crossOriginIsolated
Cross Origin Opener Policy in Why you need "cross-origin isolated" for powerful features on web.dev (2020)
COOP and COEP explained: Artur Janc, Charlie Reis, Anne van Kesteren (2020)
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Apr 10, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nCross-Origin-Opener-PolicyThe HTTP Cross-Origin-Opener-Policy (COOP) response header allows a website to control whether a new top-level document, opened using Window.open() or by navigating to a new page, is opened in the same browsing context group (BCG) or in a new browsing context group.
When opened in a new BCG, any references between the new document and its opener are severed, and the new document may be process-isolated from its opener.
This ensures that potential attackers can't open your documents with Window.open() and then use the returned value to access its global object, and thereby prevents a set of cross-origin attacks referred to as XS-Leaks.
It also means that any object opened by your document in a new BCG can't access it using window.opener.
This allows you to have more control over references to a window than rel=noopener, which affects outgoing navigations but not documents opened with Window.open().
The behaviour depends on the policies of both the new document and its opener, and whether the new document is opened following a navigation or using Window.open().

  
    
      Header type
      Response header
    
    
      Forbidden request header
      No
    
  
SyntaxhttpCross-Origin-Opener-Policy: unsafe-none
Cross-Origin-Opener-Policy: same-origin-allow-popups
Cross-Origin-Opener-Policy: same-origin
Cross-Origin-Opener-Policy: noopener-allow-popups
Directives
unsafe-none

The document permits sharing its browsing context group with any other document, and may therefore be unsafe.
It is used to opt-out a document from using COOP for process isolation.
This is the default value.
On navigations, documents with unsafe-none will always open and be opened into a new BCG — unless the other document also has unsafe-none (or no COOP directive value).
Using Window.open(), documents with unsafe-none will always open documents with any other value into a new BCG.
However documents with unsafe-none can be opened in the same BCG if the opener has the directive same-origin-allow-popups, noopener-allow-popups, or unsafe-none.
A document with same-origin will always open a document with unsafe-none in a new BCG.

same-origin

The document permits loading into BCGs that use COOP and contain only same-origin documents.
This is used to provide cross-origin isolation for a BCG.
Documents with same-origin will only open and be opened in the same BCG if both documents are same-origin and have the same-origin directive.

same-origin-allow-popups

This is similar to same-origin directive, except that it allows the opening of documents using Window.open() in the same BCG if they have a COOP value of unsafe-none.
The directive is used to relax the same-origin restriction for integrations where a document needs the benefits of cross-origin isolation but also needs to open and retain a reference to trusted cross-origin documents.
For example, when using a cross-origin service for OAuth or payments.
A document with this directive can open a document in the same BCG using Window.open() if it has a COOP value of unsafe-none.
In this case it does not matter if the opened document is cross-site or same-site.
Otherwise documents with same-origin-allow-popups will only open and be opened in the same BCG if both documents are same-origin and have the same-origin-allow-popups directive.

noopener-allow-popups

Documents with this directive are always opened into a new BCG, except when opened by navigating from a document that also has noopener-allow-popups.
It is used to support cases where there is a need to process-isolate same-origin documents.
This severs the connections between the new document and its opener, isolating the browsing context for the current document regardless of the opener document's origin.
This ensures that the opener can't run scripts in opened documents and vice versa — even if they are same-origin.
On navigations, a document with this directive will always open other documents in a new BCG unless they are same-origin and have the directive noopener-allow-popups.
Using Window.open(), a document with this directive will open documents in a new BCG unless they have unsafe-none, and in this case it does not matter if they are same-site or cross-site.

DescriptionGenerally you should set your policies such that only same-origin and trusted cross-origin resources that need to be able to script each other should be allowed to be opened in the same browser context group.
Other resources should be cross-origin isolated in their own group.
The following sections show whether documents will be opened in the same BCG or a new BCG following a navigation or opening a window programmatically.

Note:
The specification uses the term "popup" to refer to any document opened using Window.open(), whether it is a popup, tab, window, or other context.
NavigationsWhen navigating between documents, the new document is opened in the same BCG if the two documents have "matching coop policies", and otherwise into a new BCG.
The policies match if either both documents have the policy unsafe-none, or if the policies are the same and the documents are same-origin.
The table below shows how this rule affects whether documents are opened in the same or a new BCG for the different directive values.




Opener (↓) / Opened (→)
unsafe-none
same-origin-allow-popups
same-origin
noopener-allow-popups




unsafe-none
Same
New
New
New


same-origin-allow-popups
New
Same if same-origin
New
New


same-origin
New
New
Same if same-origin
New


noopener-allow-popups
New
New
New
Same if same-origin


Opening with Window.open()When opening a document using Window.open(), the new document is opened in a new BCG according to the following rules, which are evaluated in order:

If the new document has COOP set to noopener-allow-popups => open the new document in a new BCG
If the new document has COOP set to unsafe-none and the opener document has COOP set to either same-origin-allow-popups or noopener-allow-popups => open the new document in the same BCG
If the new document and the opening document have matching COOP policies => open the new document in the same BCG
Otherwise, open the new document in a new BCG

The table below shows how these rules affect whether documents are opened in the same or a new BCG for the different directive values.




Opener (↓) / Opened (→)
unsafe-none
same-origin-allow-popups
same-origin
noopener-allow-popups




unsafe-none
Same
New
New
New


same-origin-allow-popups
Same
Same if same-origin
New
New


same-origin
New
New
Same if same-origin
New


noopener-allow-popups
Same
New
New
New


ExamplesFeatures that depend on cross-origin isolationCertain features, such as access to SharedArrayBuffer objects or using Performance.now() with unthrottled timers, are only available if your document is cross-origin isolated.
To use these features in a document, you will need to set the COOP header to same-origin and the Cross-Origin-Embedder-Policy header to require-corp (or credentialless).
In addition the feature must not be blocked by Permissions-Policy: cross-origin-isolated.
httpCross-Origin-Opener-Policy: same-origin
Cross-Origin-Embedder-Policy: require-corp

You can use the Window.crossOriginIsolated and WorkerGlobalScope.crossOriginIsolated properties to check if a document is cross-origin isolated, and hence whether or not the features are restricted:
jsconst myWorker = new Worker("worker.js");

if (crossOriginIsolated) {
  const buffer = new SharedArrayBuffer(16);
  myWorker.postMessage(buffer);
} else {
  const buffer = new ArrayBuffer(16);
  myWorker.postMessage(buffer);
}
Severing the opener relationshipConsider a hypothetical origin example.com that has two very different applications on the same origin:

A chat application at /chat that enables any user to contact any other user and send them messages.
A password management application at /passwords that contains all of the user's passwords, across different services.

The administrators of the "passwords" application would very much like to ensure that it can't be directly scripted by the "chat" app, which by its nature has a larger XSS surface.
The "right way" to isolate these applications would be to host them on different origins, but in some cases that's not possible, and those two applications have to be on a single origin for historical, business, or branding reasons.
The Cross-Origin-Opener-Policy: noopener-allow-popups header can be used to ensure that a document can't be scripted by a document that opens it.
If example.com/passwords is served with noopener-allow-popups the WindowProxy returned by Window.open() will indicate that the windows is closed (Window.closed is true), so the opener can't script the passwords app:
jsconst handle = window.open("example.com/passwords", "passwordTab");
if (windowProxy.closed) {
  // The new window is closed so it can't be scripted.
}

Note that this alone is not considered a sufficient security measure.
The site would also need to do the following:

Use Fetch Metadata to block same-origin requests to the more-sensitive app that are not navigation requests.
Ensure their authentication cookies are all HttpOnly.
Ensure root-level Service-Workers are not installed by the less-sensitive app.
Ensure that postMessage or BroadcastChannel on the more-sensitive app don't expose any sensitive information the any other same-origin app.
Ensure their login page is served on a separate origin, due to password manager autofill being applied based on origin.
Understand that the browser may still allocate the more-sensitive app in the same process as the less-sensitive one, making it vulnerable to Spectre-like attacks.
SpecificationsSpecificationHTML # the-coop-headersBrowser compatibilitySee also
Cross-Origin-Embedder-Policy\n\nCross-Origin-Opener-PolicyThe HTTP Cross-Origin-Opener-Policy (COOP) response header allows a website to control whether a new top-level document, opened using Window.open() or by navigating to a new page, is opened in the same browsing context group (BCG) or in a new browsing context group.
When opened in a new BCG, any references between the new document and its opener are severed, and the new document may be process-isolated from its opener.
This ensures that potential attackers can't open your documents with Window.open() and then use the returned value to access its global object, and thereby prevents a set of cross-origin attacks referred to as XS-Leaks.
It also means that any object opened by your document in a new BCG can't access it using window.opener.
This allows you to have more control over references to a window than rel=noopener, which affects outgoing navigations but not documents opened with Window.open().
The behaviour depends on the policies of both the new document and its opener, and whether the new document is opened following a navigation or using Window.open().

  
    
      Header type
      Response header
    
    
      Forbidden request header
      No
    
  
SyntaxhttpCross-Origin-Opener-Policy: unsafe-none
Cross-Origin-Opener-Policy: same-origin-allow-popups
Cross-Origin-Opener-Policy: same-origin
Cross-Origin-Opener-Policy: noopener-allow-popups
Directives
unsafe-none

The document permits sharing its browsing context group with any other document, and may therefore be unsafe.
It is used to opt-out a document from using COOP for process isolation.
This is the default value.
On navigations, documents with unsafe-none will always open and be opened into a new BCG — unless the other document also has unsafe-none (or no COOP directive value).
Using Window.open(), documents with unsafe-none will always open documents with any other value into a new BCG.
However documents with unsafe-none can be opened in the same BCG if the opener has the directive same-origin-allow-popups, noopener-allow-popups, or unsafe-none.
A document with same-origin will always open a document with unsafe-none in a new BCG.

same-origin

The document permits loading into BCGs that use COOP and contain only same-origin documents.
This is used to provide cross-origin isolation for a BCG.
Documents with same-origin will only open and be opened in the same BCG if both documents are same-origin and have the same-origin directive.

same-origin-allow-popups

This is similar to same-origin directive, except that it allows the opening of documents using Window.open() in the same BCG if they have a COOP value of unsafe-none.
The directive is used to relax the same-origin restriction for integrations where a document needs the benefits of cross-origin isolation but also needs to open and retain a reference to trusted cross-origin documents.
For example, when using a cross-origin service for OAuth or payments.
A document with this directive can open a document in the same BCG using Window.open() if it has a COOP value of unsafe-none.
In this case it does not matter if the opened document is cross-site or same-site.
Otherwise documents with same-origin-allow-popups will only open and be opened in the same BCG if both documents are same-origin and have the same-origin-allow-popups directive.

noopener-allow-popups

Documents with this directive are always opened into a new BCG, except when opened by navigating from a document that also has noopener-allow-popups.
It is used to support cases where there is a need to process-isolate same-origin documents.
This severs the connections between the new document and its opener, isolating the browsing context for the current document regardless of the opener document's origin.
This ensures that the opener can't run scripts in opened documents and vice versa — even if they are same-origin.
On navigations, a document with this directive will always open other documents in a new BCG unless they are same-origin and have the directive noopener-allow-popups.
Using Window.open(), a document with this directive will open documents in a new BCG unless they have unsafe-none, and in this case it does not matter if they are same-site or cross-site.

DescriptionGenerally you should set your policies such that only same-origin and trusted cross-origin resources that need to be able to script each other should be allowed to be opened in the same browser context group.
Other resources should be cross-origin isolated in their own group.
The following sections show whether documents will be opened in the same BCG or a new BCG following a navigation or opening a window programmatically.

Note:
The specification uses the term "popup" to refer to any document opened using Window.open(), whether it is a popup, tab, window, or other context.
NavigationsWhen navigating between documents, the new document is opened in the same BCG if the two documents have "matching coop policies", and otherwise into a new BCG.
The policies match if either both documents have the policy unsafe-none, or if the policies are the same and the documents are same-origin.
The table below shows how this rule affects whether documents are opened in the same or a new BCG for the different directive values.




Opener (↓) / Opened (→)
unsafe-none
same-origin-allow-popups
same-origin
noopener-allow-popups




unsafe-none
Same
New
New
New


same-origin-allow-popups
New
Same if same-origin
New
New


same-origin
New
New
Same if same-origin
New


noopener-allow-popups
New
New
New
Same if same-origin


Opening with Window.open()When opening a document using Window.open(), the new document is opened in a new BCG according to the following rules, which are evaluated in order:

If the new document has COOP set to noopener-allow-popups => open the new document in a new BCG
If the new document has COOP set to unsafe-none and the opener document has COOP set to either same-origin-allow-popups or noopener-allow-popups => open the new document in the same BCG
If the new document and the opening document have matching COOP policies => open the new document in the same BCG
Otherwise, open the new document in a new BCG

The table below shows how these rules affect whether documents are opened in the same or a new BCG for the different directive values.




Opener (↓) / Opened (→)
unsafe-none
same-origin-allow-popups
same-origin
noopener-allow-popups




unsafe-none
Same
New
New
New


same-origin-allow-popups
Same
Same if same-origin
New
New


same-origin
New
New
Same if same-origin
New


noopener-allow-popups
Same
New
New
New


ExamplesFeatures that depend on cross-origin isolationCertain features, such as access to SharedArrayBuffer objects or using Performance.now() with unthrottled timers, are only available if your document is cross-origin isolated.
To use these features in a document, you will need to set the COOP header to same-origin and the Cross-Origin-Embedder-Policy header to require-corp (or credentialless).
In addition the feature must not be blocked by Permissions-Policy: cross-origin-isolated.
httpCross-Origin-Opener-Policy: same-origin
Cross-Origin-Embedder-Policy: require-corp

You can use the Window.crossOriginIsolated and WorkerGlobalScope.crossOriginIsolated properties to check if a document is cross-origin isolated, and hence whether or not the features are restricted:
jsconst myWorker = new Worker("worker.js");

if (crossOriginIsolated) {
  const buffer = new SharedArrayBuffer(16);
  myWorker.postMessage(buffer);
} else {
  const buffer = new ArrayBuffer(16);
  myWorker.postMessage(buffer);
}
Severing the opener relationshipConsider a hypothetical origin example.com that has two very different applications on the same origin:

A chat application at /chat that enables any user to contact any other user and send them messages.
A password management application at /passwords that contains all of the user's passwords, across different services.

The administrators of the "passwords" application would very much like to ensure that it can't be directly scripted by the "chat" app, which by its nature has a larger XSS surface.
The "right way" to isolate these applications would be to host them on different origins, but in some cases that's not possible, and those two applications have to be on a single origin for historical, business, or branding reasons.
The Cross-Origin-Opener-Policy: noopener-allow-popups header can be used to ensure that a document can't be scripted by a document that opens it.
If example.com/passwords is served with noopener-allow-popups the WindowProxy returned by Window.open() will indicate that the windows is closed (Window.closed is true), so the opener can't script the passwords app:
jsconst handle = window.open("example.com/passwords", "passwordTab");
if (windowProxy.closed) {
  // The new window is closed so it can't be scripted.
}

Note that this alone is not considered a sufficient security measure.
The site would also need to do the following:

Use Fetch Metadata to block same-origin requests to the more-sensitive app that are not navigation requests.
Ensure their authentication cookies are all HttpOnly.
Ensure root-level Service-Workers are not installed by the less-sensitive app.
Ensure that postMessage or BroadcastChannel on the more-sensitive app don't expose any sensitive information the any other same-origin app.
Ensure their login page is served on a separate origin, due to password manager autofill being applied based on origin.
Understand that the browser may still allocate the more-sensitive app in the same process as the less-sensitive one, making it vulnerable to Spectre-like attacks.
SpecificationsSpecificationHTML # the-coop-headersBrowser compatibilitySee also
Cross-Origin-Embedder-Policy
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Apr 10, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nCross-Origin-Opener-PolicyThe HTTP Cross-Origin-Opener-Policy (COOP) response header allows a website to control whether a new top-level document, opened using Window.open() or by navigating to a new page, is opened in the same browsing context group (BCG) or in a new browsing context group.
When opened in a new BCG, any references between the new document and its opener are severed, and the new document may be process-isolated from its opener.
This ensures that potential attackers can't open your documents with Window.open() and then use the returned value to access its global object, and thereby prevents a set of cross-origin attacks referred to as XS-Leaks.
It also means that any object opened by your document in a new BCG can't access it using window.opener.
This allows you to have more control over references to a window than rel=noopener, which affects outgoing navigations but not documents opened with Window.open().
The behaviour depends on the policies of both the new document and its opener, and whether the new document is opened following a navigation or using Window.open().

  
    
      Header type
      Response header
    
    
      Forbidden request header
      No
    
  
SyntaxhttpCross-Origin-Opener-Policy: unsafe-none
Cross-Origin-Opener-Policy: same-origin-allow-popups
Cross-Origin-Opener-Policy: same-origin
Cross-Origin-Opener-Policy: noopener-allow-popups
Directives
unsafe-none

The document permits sharing its browsing context group with any other document, and may therefore be unsafe.
It is used to opt-out a document from using COOP for process isolation.
This is the default value.
On navigations, documents with unsafe-none will always open and be opened into a new BCG — unless the other document also has unsafe-none (or no COOP directive value).
Using Window.open(), documents with unsafe-none will always open documents with any other value into a new BCG.
However documents with unsafe-none can be opened in the same BCG if the opener has the directive same-origin-allow-popups, noopener-allow-popups, or unsafe-none.
A document with same-origin will always open a document with unsafe-none in a new BCG.

same-origin

The document permits loading into BCGs that use COOP and contain only same-origin documents.
This is used to provide cross-origin isolation for a BCG.
Documents with same-origin will only open and be opened in the same BCG if both documents are same-origin and have the same-origin directive.

same-origin-allow-popups

This is similar to same-origin directive, except that it allows the opening of documents using Window.open() in the same BCG if they have a COOP value of unsafe-none.
The directive is used to relax the same-origin restriction for integrations where a document needs the benefits of cross-origin isolation but also needs to open and retain a reference to trusted cross-origin documents.
For example, when using a cross-origin service for OAuth or payments.
A document with this directive can open a document in the same BCG using Window.open() if it has a COOP value of unsafe-none.
In this case it does not matter if the opened document is cross-site or same-site.
Otherwise documents with same-origin-allow-popups will only open and be opened in the same BCG if both documents are same-origin and have the same-origin-allow-popups directive.

noopener-allow-popups

Documents with this directive are always opened into a new BCG, except when opened by navigating from a document that also has noopener-allow-popups.
It is used to support cases where there is a need to process-isolate same-origin documents.
This severs the connections between the new document and its opener, isolating the browsing context for the current document regardless of the opener document's origin.
This ensures that the opener can't run scripts in opened documents and vice versa — even if they are same-origin.
On navigations, a document with this directive will always open other documents in a new BCG unless they are same-origin and have the directive noopener-allow-popups.
Using Window.open(), a document with this directive will open documents in a new BCG unless they have unsafe-none, and in this case it does not matter if they are same-site or cross-site.

DescriptionGenerally you should set your policies such that only same-origin and trusted cross-origin resources that need to be able to script each other should be allowed to be opened in the same browser context group.
Other resources should be cross-origin isolated in their own group.
The following sections show whether documents will be opened in the same BCG or a new BCG following a navigation or opening a window programmatically.

Note:
The specification uses the term "popup" to refer to any document opened using Window.open(), whether it is a popup, tab, window, or other context.
NavigationsWhen navigating between documents, the new document is opened in the same BCG if the two documents have "matching coop policies", and otherwise into a new BCG.
The policies match if either both documents have the policy unsafe-none, or if the policies are the same and the documents are same-origin.
The table below shows how this rule affects whether documents are opened in the same or a new BCG for the different directive values.




Opener (↓) / Opened (→)
unsafe-none
same-origin-allow-popups
same-origin
noopener-allow-popups




unsafe-none
Same
New
New
New


same-origin-allow-popups
New
Same if same-origin
New
New


same-origin
New
New
Same if same-origin
New


noopener-allow-popups
New
New
New
Same if same-origin


Opening with Window.open()When opening a document using Window.open(), the new document is opened in a new BCG according to the following rules, which are evaluated in order:

If the new document has COOP set to noopener-allow-popups => open the new document in a new BCG
If the new document has COOP set to unsafe-none and the opener document has COOP set to either same-origin-allow-popups or noopener-allow-popups => open the new document in the same BCG
If the new document and the opening document have matching COOP policies => open the new document in the same BCG
Otherwise, open the new document in a new BCG

The table below shows how these rules affect whether documents are opened in the same or a new BCG for the different directive values.




Opener (↓) / Opened (→)
unsafe-none
same-origin-allow-popups
same-origin
noopener-allow-popups




unsafe-none
Same
New
New
New


same-origin-allow-popups
Same
Same if same-origin
New
New


same-origin
New
New
Same if same-origin
New


noopener-allow-popups
Same
New
New
New


ExamplesFeatures that depend on cross-origin isolationCertain features, such as access to SharedArrayBuffer objects or using Performance.now() with unthrottled timers, are only available if your document is cross-origin isolated.
To use these features in a document, you will need to set the COOP header to same-origin and the Cross-Origin-Embedder-Policy header to require-corp (or credentialless).
In addition the feature must not be blocked by Permissions-Policy: cross-origin-isolated.
httpCross-Origin-Opener-Policy: same-origin
Cross-Origin-Embedder-Policy: require-corp

You can use the Window.crossOriginIsolated and WorkerGlobalScope.crossOriginIsolated properties to check if a document is cross-origin isolated, and hence whether or not the features are restricted:
jsconst myWorker = new Worker("worker.js");

if (crossOriginIsolated) {
  const buffer = new SharedArrayBuffer(16);
  myWorker.postMessage(buffer);
} else {
  const buffer = new ArrayBuffer(16);
  myWorker.postMessage(buffer);
}
Severing the opener relationshipConsider a hypothetical origin example.com that has two very different applications on the same origin:

A chat application at /chat that enables any user to contact any other user and send them messages.
A password management application at /passwords that contains all of the user's passwords, across different services.

The administrators of the "passwords" application would very much like to ensure that it can't be directly scripted by the "chat" app, which by its nature has a larger XSS surface.
The "right way" to isolate these applications would be to host them on different origins, but in some cases that's not possible, and those two applications have to be on a single origin for historical, business, or branding reasons.
The Cross-Origin-Opener-Policy: noopener-allow-popups header can be used to ensure that a document can't be scripted by a document that opens it.
If example.com/passwords is served with noopener-allow-popups the WindowProxy returned by Window.open() will indicate that the windows is closed (Window.closed is true), so the opener can't script the passwords app:
jsconst handle = window.open("example.com/passwords", "passwordTab");
if (windowProxy.closed) {
  // The new window is closed so it can't be scripted.
}

Note that this alone is not considered a sufficient security measure.
The site would also need to do the following:

Use Fetch Metadata to block same-origin requests to the more-sensitive app that are not navigation requests.
Ensure their authentication cookies are all HttpOnly.
Ensure root-level Service-Workers are not installed by the less-sensitive app.
Ensure that postMessage or BroadcastChannel on the more-sensitive app don't expose any sensitive information the any other same-origin app.
Ensure their login page is served on a separate origin, due to password manager autofill being applied based on origin.
Understand that the browser may still allocate the more-sensitive app in the same process as the less-sensitive one, making it vulnerable to Spectre-like attacks.
SpecificationsSpecificationHTML # the-coop-headersBrowser compatibilitySee also
Cross-Origin-Embedder-Policy
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Apr 10, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nCross-Origin-Resource-PolicyThe HTTP Cross-Origin-Resource-Policy response header (CORP) indicates that the browser should block no-cors cross-origin or cross-site requests to the given resource.
It specifies resource owner's policy for what sites/origins should be allowed to load this resource.

  
    
      Header type
      Response header
    
    
      Forbidden request header
      No
    
  
SyntaxhttpCross-Origin-Resource-Policy: same-site | same-origin | cross-origin
Directives
same-site

Resources can only be loaded from the same site.

same-origin

Resources can only be loaded from the same origin.

cross-origin

Resources can be loaded by any other origin/website.

ExamplesFor more examples, see https://resourcepolicy.fyi/.Disallowing cross-origin no-cors requestsThe Cross-Origin-Resource-Policy header below will cause compatible user agents to disallow cross-origin no-cors requests:
httpCross-Origin-Resource-Policy: same-origin
SpecificationsSpecificationFetch # cross-origin-resource-policy-headerBrowser compatibilitySee also
Cross-Origin Resource Policy (CORP) explainer
Consider deploying Cross-Origin Resource Policy
Cross-Origin-Embedder-Policy
Access-Control-Allow-Origin\n\nCross-Origin-Resource-PolicyThe HTTP Cross-Origin-Resource-Policy response header (CORP) indicates that the browser should block no-cors cross-origin or cross-site requests to the given resource.
It specifies resource owner's policy for what sites/origins should be allowed to load this resource.

  
    
      Header type
      Response header
    
    
      Forbidden request header
      No
    
  
SyntaxhttpCross-Origin-Resource-Policy: same-site | same-origin | cross-origin
Directives
same-site

Resources can only be loaded from the same site.

same-origin

Resources can only be loaded from the same origin.

cross-origin

Resources can be loaded by any other origin/website.

ExamplesFor more examples, see https://resourcepolicy.fyi/.Disallowing cross-origin no-cors requestsThe Cross-Origin-Resource-Policy header below will cause compatible user agents to disallow cross-origin no-cors requests:
httpCross-Origin-Resource-Policy: same-origin
SpecificationsSpecificationFetch # cross-origin-resource-policy-headerBrowser compatibilitySee also
Cross-Origin Resource Policy (CORP) explainer
Consider deploying Cross-Origin Resource Policy
Cross-Origin-Embedder-Policy
Access-Control-Allow-Origin
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nCross-Origin-Resource-PolicyThe HTTP Cross-Origin-Resource-Policy response header (CORP) indicates that the browser should block no-cors cross-origin or cross-site requests to the given resource.
It specifies resource owner's policy for what sites/origins should be allowed to load this resource.

  
    
      Header type
      Response header
    
    
      Forbidden request header
      No
    
  
SyntaxhttpCross-Origin-Resource-Policy: same-site | same-origin | cross-origin
Directives
same-site

Resources can only be loaded from the same site.

same-origin

Resources can only be loaded from the same origin.

cross-origin

Resources can be loaded by any other origin/website.

ExamplesFor more examples, see https://resourcepolicy.fyi/.Disallowing cross-origin no-cors requestsThe Cross-Origin-Resource-Policy header below will cause compatible user agents to disallow cross-origin no-cors requests:
httpCross-Origin-Resource-Policy: same-origin
SpecificationsSpecificationFetch # cross-origin-resource-policy-headerBrowser compatibilitySee also
Cross-Origin Resource Policy (CORP) explainer
Consider deploying Cross-Origin Resource Policy
Cross-Origin-Embedder-Policy
Access-Control-Allow-Origin
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nDateBaseline Widely availableThis feature is well established and works across many devices and browser versions. It’s been available across browsers since July 2015.Learn moreSee full compatibilityReport feedbackThe HTTP Date request and response header contains the date and time at which the message originated.

  
    
      Header type
      
        Request header,
        Response header
      
    
    
      Forbidden request header
      Yes
    
  
SyntaxhttpDate: <day-name>, <day> <month> <year> <hour>:<minute>:<second> GMT
Directives
<day-name>

One of Mon, Tue, Wed, Thu, Fri, Sat, or Sun (case-sensitive).

<day>

2 digit day number, e.g., "04" or "23".

<month>

One of Jan, Feb, Mar, Apr, May, Jun, Jul, Aug, Sep, Oct, Nov, Dec (case sensitive).

<year>

4 digit year number, e.g., "1990" or "2016".

<hour>

2 digit hour number, e.g., "09" or "23".

<minute>

2 digit minute number, e.g., "04" or "59".

<second>

2 digit second number, e.g., "04" or "59".

GMT

Greenwich Mean Time. HTTP dates are always expressed in GMT, never in local time.

ExamplesResponse with a Date headerThe following HTTP message is a successful 200 status, with a Date header showing the time the message originated.
Other headers are omitted for brevity:
httpHTTP/1.1 200
Content-Type: text/html
Date: Tue, 29 Oct 2024 16:56:32 GMT

<html lang="en-US" …
Attempting to set the field value in JavaScriptThe Date header is a Forbidden request header, so this code cannot set the message Date field:
jsfetch("https://httpbin.org/get", {
  headers: {
    Date: new Date().toUTCString(),
  },
});
SpecificationsSpecificationHTTP Semantics # field.dateBrowser compatibilitySee also
Age\n\nDateBaseline Widely availableThis feature is well established and works across many devices and browser versions. It’s been available across browsers since July 2015.Learn moreSee full compatibilityReport feedbackThe HTTP Date request and response header contains the date and time at which the message originated.

  
    
      Header type
      
        Request header,
        Response header
      
    
    
      Forbidden request header
      Yes
    
  
SyntaxhttpDate: <day-name>, <day> <month> <year> <hour>:<minute>:<second> GMT
Directives
<day-name>

One of Mon, Tue, Wed, Thu, Fri, Sat, or Sun (case-sensitive).

<day>

2 digit day number, e.g., "04" or "23".

<month>

One of Jan, Feb, Mar, Apr, May, Jun, Jul, Aug, Sep, Oct, Nov, Dec (case sensitive).

<year>

4 digit year number, e.g., "1990" or "2016".

<hour>

2 digit hour number, e.g., "09" or "23".

<minute>

2 digit minute number, e.g., "04" or "59".

<second>

2 digit second number, e.g., "04" or "59".

GMT

Greenwich Mean Time. HTTP dates are always expressed in GMT, never in local time.

ExamplesResponse with a Date headerThe following HTTP message is a successful 200 status, with a Date header showing the time the message originated.
Other headers are omitted for brevity:
httpHTTP/1.1 200
Content-Type: text/html
Date: Tue, 29 Oct 2024 16:56:32 GMT

<html lang="en-US" …
Attempting to set the field value in JavaScriptThe Date header is a Forbidden request header, so this code cannot set the message Date field:
jsfetch("https://httpbin.org/get", {
  headers: {
    Date: new Date().toUTCString(),
  },
});
SpecificationsSpecificationHTTP Semantics # field.dateBrowser compatibilitySee also
Age
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nDateBaseline Widely availableThis feature is well established and works across many devices and browser versions. It’s been available across browsers since July 2015.Learn moreSee full compatibilityReport feedbackThe HTTP Date request and response header contains the date and time at which the message originated.

  
    
      Header type
      
        Request header,
        Response header
      
    
    
      Forbidden request header
      Yes
    
  
SyntaxhttpDate: <day-name>, <day> <month> <year> <hour>:<minute>:<second> GMT
Directives
<day-name>

One of Mon, Tue, Wed, Thu, Fri, Sat, or Sun (case-sensitive).

<day>

2 digit day number, e.g., "04" or "23".

<month>

One of Jan, Feb, Mar, Apr, May, Jun, Jul, Aug, Sep, Oct, Nov, Dec (case sensitive).

<year>

4 digit year number, e.g., "1990" or "2016".

<hour>

2 digit hour number, e.g., "09" or "23".

<minute>

2 digit minute number, e.g., "04" or "59".

<second>

2 digit second number, e.g., "04" or "59".

GMT

Greenwich Mean Time. HTTP dates are always expressed in GMT, never in local time.

ExamplesResponse with a Date headerThe following HTTP message is a successful 200 status, with a Date header showing the time the message originated.
Other headers are omitted for brevity:
httpHTTP/1.1 200
Content-Type: text/html
Date: Tue, 29 Oct 2024 16:56:32 GMT

<html lang="en-US" …
Attempting to set the field value in JavaScriptThe Date header is a Forbidden request header, so this code cannot set the message Date field:
jsfetch("https://httpbin.org/get", {
  headers: {
    Date: new Date().toUTCString(),
  },
});
SpecificationsSpecificationHTTP Semantics # field.dateBrowser compatibilitySee also
Age
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nDevice-MemoryLimited availabilityThis feature is not Baseline because it does not work in some of the most widely-used browsers.Learn moreSee full compatibilityReport feedbackSecure context: This feature is available only in secure contexts (HTTPS), in some or all supporting browsers.
The HTTP Device-Memory request header is used in device client hints to indicate the approximate amount of available RAM on the client device, in gigabytes.
The header is part of the Device Memory API.
Client hints are accessible only on secure origins.
A server has to opt in to receive the Device-Memory header from the client, by first sending the Accept-CH response header.
Servers that opt in to the Device-Memory client hint will typically also specify it in the Vary header to inform caches that the server may send different responses based on the header value in a request.

  
    
      Header type
      
        Request header,
        Client hint
      
    
    
      Forbidden request header
      No
    
  
SyntaxhttpDevice-Memory: <number>
Directives
<number>

The approximate amount of device RAM. Possible values are: 0.25, 0.5, 1, 2, 4, 8.
The amount of device RAM can be used as a fingerprinting variable, so values for the header are intentionally coarse to reduce the potential for its misuse.

ExamplesThe server first needs to opt in to receive Device-Memory header by sending the Accept-CH response header containing Device-Memory:
httpAccept-CH: Device-Memory

Then on subsequent requests the client might send Device-Memory header back:
httpDevice-Memory: 1
SpecificationsSpecificationDevice Memory # iana-device-memoryBrowser compatibilitySee also
Improving user privacy and developer experience with User-Agent Client Hints (developer.chrome.com)
Device Memory API
Navigator.deviceMemory
WorkerNavigator.deviceMemory
Device client hints

Content-DPR
DPR
Viewport-Width
Width


Accept-CH
HTTP Caching: Vary and Vary\n\nDevice-MemoryLimited availabilityThis feature is not Baseline because it does not work in some of the most widely-used browsers.Learn moreSee full compatibilityReport feedbackSecure context: This feature is available only in secure contexts (HTTPS), in some or all supporting browsers.
The HTTP Device-Memory request header is used in device client hints to indicate the approximate amount of available RAM on the client device, in gigabytes.
The header is part of the Device Memory API.
Client hints are accessible only on secure origins.
A server has to opt in to receive the Device-Memory header from the client, by first sending the Accept-CH response header.
Servers that opt in to the Device-Memory client hint will typically also specify it in the Vary header to inform caches that the server may send different responses based on the header value in a request.

  
    
      Header type
      
        Request header,
        Client hint
      
    
    
      Forbidden request header
      No
    
  
SyntaxhttpDevice-Memory: <number>
Directives
<number>

The approximate amount of device RAM. Possible values are: 0.25, 0.5, 1, 2, 4, 8.
The amount of device RAM can be used as a fingerprinting variable, so values for the header are intentionally coarse to reduce the potential for its misuse.

ExamplesThe server first needs to opt in to receive Device-Memory header by sending the Accept-CH response header containing Device-Memory:
httpAccept-CH: Device-Memory

Then on subsequent requests the client might send Device-Memory header back:
httpDevice-Memory: 1
SpecificationsSpecificationDevice Memory # iana-device-memoryBrowser compatibilitySee also
Improving user privacy and developer experience with User-Agent Client Hints (developer.chrome.com)
Device Memory API
Navigator.deviceMemory
WorkerNavigator.deviceMemory
Device client hints

Content-DPR
DPR
Viewport-Width
Width


Accept-CH
HTTP Caching: Vary and Vary
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nDevice-MemoryLimited availabilityThis feature is not Baseline because it does not work in some of the most widely-used browsers.Learn moreSee full compatibilityReport feedbackSecure context: This feature is available only in secure contexts (HTTPS), in some or all supporting browsers.
The HTTP Device-Memory request header is used in device client hints to indicate the approximate amount of available RAM on the client device, in gigabytes.
The header is part of the Device Memory API.
Client hints are accessible only on secure origins.
A server has to opt in to receive the Device-Memory header from the client, by first sending the Accept-CH response header.
Servers that opt in to the Device-Memory client hint will typically also specify it in the Vary header to inform caches that the server may send different responses based on the header value in a request.

  
    
      Header type
      
        Request header,
        Client hint
      
    
    
      Forbidden request header
      No
    
  
SyntaxhttpDevice-Memory: <number>
Directives
<number>

The approximate amount of device RAM. Possible values are: 0.25, 0.5, 1, 2, 4, 8.
The amount of device RAM can be used as a fingerprinting variable, so values for the header are intentionally coarse to reduce the potential for its misuse.

ExamplesThe server first needs to opt in to receive Device-Memory header by sending the Accept-CH response header containing Device-Memory:
httpAccept-CH: Device-Memory

Then on subsequent requests the client might send Device-Memory header back:
httpDevice-Memory: 1
SpecificationsSpecificationDevice Memory # iana-device-memoryBrowser compatibilitySee also
Improving user privacy and developer experience with User-Agent Client Hints (developer.chrome.com)
Device Memory API
Navigator.deviceMemory
WorkerNavigator.deviceMemory
Device client hints

Content-DPR
DPR
Viewport-Width
Width


Accept-CH
HTTP Caching: Vary and Vary
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nDictionary-IDLimited availabilityThis feature is not Baseline because it does not work in some of the most widely-used browsers.Learn moreSee full compatibilityReport feedbackExperimental: This is an experimental technologyCheck the Browser compatibility table carefully before using this in production.
The HTTP Dictionary-ID request header references a dictionary that can be used in Compression Dictionary Transport to compress the server's response.
A server can indicate that a resource can be used as a dictionary by sending the Use-As-Dictionary header with the response. The server may include an id directive in the Use-As-Dictionary header, thus assigning an ID value to the dictionary. If the server does this, then when the browser requests a resource that can be compressed using the dictionary, the resource request must include the Dictionary-ID header, and its value must match the ID that was given in Use-As-Dictionary.
This allows the server to identify and find a dictionary that is referenced by some arbitrary key, rather than having to use the dictionary hash as a key (if that approach is used, the server will have to hash every response that includes the Use-As-Dictionary header just in case the resource might eventually be used as a dictionary).
Note that while the server can identify and locate the dictionary from its Dictionary-ID, it must still check the hash from the Available-Dictionary header to confirm that it is a correct match.
See the Compression Dictionary Transport guide for more information.SyntaxhttpDictionary-ID: "<string-identifier>"
Directives
<string-identifier>

A string representing the dictionary's server-assigned ID.

ExamplesFor example, suppose the server has sent a Use-As-Dictionary header containing an id="dictionary-12345" directive:
httpUse-As-Dictionary: match="/js/app.*.js", id="dictionary-12345"

When the client requests a matching resource, it will include this id value in a Dictionary-ID header:
httpAccept-Encoding: gzip, br, zstd, dcb, dcz
Available-Dictionary: :pZGm1Av0IEBKARczz7exkNYsZb8LzaMrV7J32a2fFG4=:
Dictionary-ID: "dictionary-12345"
SpecificationsSpecificationCompression Dictionary Transport # name-dictionary-idBrowser compatibilitySee also
Compression Dictionary Transport guide
Available-Dictionary
Use-As-Dictionary\n\nDictionary-IDLimited availabilityThis feature is not Baseline because it does not work in some of the most widely-used browsers.Learn moreSee full compatibilityReport feedbackExperimental: This is an experimental technologyCheck the Browser compatibility table carefully before using this in production.
The HTTP Dictionary-ID request header references a dictionary that can be used in Compression Dictionary Transport to compress the server's response.
A server can indicate that a resource can be used as a dictionary by sending the Use-As-Dictionary header with the response. The server may include an id directive in the Use-As-Dictionary header, thus assigning an ID value to the dictionary. If the server does this, then when the browser requests a resource that can be compressed using the dictionary, the resource request must include the Dictionary-ID header, and its value must match the ID that was given in Use-As-Dictionary.
This allows the server to identify and find a dictionary that is referenced by some arbitrary key, rather than having to use the dictionary hash as a key (if that approach is used, the server will have to hash every response that includes the Use-As-Dictionary header just in case the resource might eventually be used as a dictionary).
Note that while the server can identify and locate the dictionary from its Dictionary-ID, it must still check the hash from the Available-Dictionary header to confirm that it is a correct match.
See the Compression Dictionary Transport guide for more information.SyntaxhttpDictionary-ID: "<string-identifier>"
Directives
<string-identifier>

A string representing the dictionary's server-assigned ID.

ExamplesFor example, suppose the server has sent a Use-As-Dictionary header containing an id="dictionary-12345" directive:
httpUse-As-Dictionary: match="/js/app.*.js", id="dictionary-12345"

When the client requests a matching resource, it will include this id value in a Dictionary-ID header:
httpAccept-Encoding: gzip, br, zstd, dcb, dcz
Available-Dictionary: :pZGm1Av0IEBKARczz7exkNYsZb8LzaMrV7J32a2fFG4=:
Dictionary-ID: "dictionary-12345"
SpecificationsSpecificationCompression Dictionary Transport # name-dictionary-idBrowser compatibilitySee also
Compression Dictionary Transport guide
Available-Dictionary
Use-As-Dictionary
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Apr 9, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nDictionary-IDLimited availabilityThis feature is not Baseline because it does not work in some of the most widely-used browsers.Learn moreSee full compatibilityReport feedbackExperimental: This is an experimental technologyCheck the Browser compatibility table carefully before using this in production.
The HTTP Dictionary-ID request header references a dictionary that can be used in Compression Dictionary Transport to compress the server's response.
A server can indicate that a resource can be used as a dictionary by sending the Use-As-Dictionary header with the response. The server may include an id directive in the Use-As-Dictionary header, thus assigning an ID value to the dictionary. If the server does this, then when the browser requests a resource that can be compressed using the dictionary, the resource request must include the Dictionary-ID header, and its value must match the ID that was given in Use-As-Dictionary.
This allows the server to identify and find a dictionary that is referenced by some arbitrary key, rather than having to use the dictionary hash as a key (if that approach is used, the server will have to hash every response that includes the Use-As-Dictionary header just in case the resource might eventually be used as a dictionary).
Note that while the server can identify and locate the dictionary from its Dictionary-ID, it must still check the hash from the Available-Dictionary header to confirm that it is a correct match.
See the Compression Dictionary Transport guide for more information.SyntaxhttpDictionary-ID: "<string-identifier>"
Directives
<string-identifier>

A string representing the dictionary's server-assigned ID.

ExamplesFor example, suppose the server has sent a Use-As-Dictionary header containing an id="dictionary-12345" directive:
httpUse-As-Dictionary: match="/js/app.*.js", id="dictionary-12345"

When the client requests a matching resource, it will include this id value in a Dictionary-ID header:
httpAccept-Encoding: gzip, br, zstd, dcb, dcz
Available-Dictionary: :pZGm1Av0IEBKARczz7exkNYsZb8LzaMrV7J32a2fFG4=:
Dictionary-ID: "dictionary-12345"
SpecificationsSpecificationCompression Dictionary Transport # name-dictionary-idBrowser compatibilitySee also
Compression Dictionary Transport guide
Available-Dictionary
Use-As-Dictionary
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Apr 9, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nDNTDeprecated: This feature is no longer recommended. Though some browsers might still support it, it may have already been removed from the relevant web standards, may be in the process of being dropped, or may only be kept for compatibility purposes. Avoid using it, and update existing code if possible; see the compatibility table at the bottom of this page to guide your decision. Be aware that this feature may cease to work at any time.
Non-standard: This feature is non-standard and is not on a standards track. Do not use it on production sites facing the Web: it will not work for every user. There may also be large incompatibilities between implementations and the behavior may change in the future.

Note:
The DNT (Do Not Track) specification has been discontinued. See Navigator.doNotTrack for more information.

The HTTP DNT (Do Not Track) request header indicates the user's tracking preference.
It lets users indicate whether they would prefer privacy rather than personalized content.
DNT is deprecated in favor of Global Privacy Control, which is communicated to servers using the Sec-GPC header, and accessible to clients from navigator.globalPrivacyControl.

  
    
      Header type
      Request header
    
    
      Forbidden request header
      Yes
    
  
SyntaxhttpDNT: 0
DNT: 1
DNT: null
Directives
0

The user prefers to allow tracking on the target site.

1

The user prefers not to be tracked on the target site.

null

The user has not specified a preference about tracking.

ExamplesReading Do Not Track status from JavaScriptThe user's DNT preference can also be read from JavaScript using the
Navigator.doNotTrack property:
jsnavigator.doNotTrack; // "0", "1" or null
SpecificationsPart of the discontinued Tracking Preference Expression (DNT) specification.Browser compatibilitySee also
Navigator.doNotTrack
Tk header
Do Not Track on Wikipedia
What Does the "Track" in "Do Not Track" Mean? – EFF
DNT on Electronic Frontier Foundation
DNT browser settings help:

Firefox
Chrome


GPC - Global Privacy Control

Enabling GPC in Firefox\n\nDNTDeprecated: This feature is no longer recommended. Though some browsers might still support it, it may have already been removed from the relevant web standards, may be in the process of being dropped, or may only be kept for compatibility purposes. Avoid using it, and update existing code if possible; see the compatibility table at the bottom of this page to guide your decision. Be aware that this feature may cease to work at any time.
Non-standard: This feature is non-standard and is not on a standards track. Do not use it on production sites facing the Web: it will not work for every user. There may also be large incompatibilities between implementations and the behavior may change in the future.

Note:
The DNT (Do Not Track) specification has been discontinued. See Navigator.doNotTrack for more information.

The HTTP DNT (Do Not Track) request header indicates the user's tracking preference.
It lets users indicate whether they would prefer privacy rather than personalized content.
DNT is deprecated in favor of Global Privacy Control, which is communicated to servers using the Sec-GPC header, and accessible to clients from navigator.globalPrivacyControl.

  
    
      Header type
      Request header
    
    
      Forbidden request header
      Yes
    
  
SyntaxhttpDNT: 0
DNT: 1
DNT: null
Directives
0

The user prefers to allow tracking on the target site.

1

The user prefers not to be tracked on the target site.

null

The user has not specified a preference about tracking.

ExamplesReading Do Not Track status from JavaScriptThe user's DNT preference can also be read from JavaScript using the
Navigator.doNotTrack property:
jsnavigator.doNotTrack; // "0", "1" or null
SpecificationsPart of the discontinued Tracking Preference Expression (DNT) specification.Browser compatibilitySee also
Navigator.doNotTrack
Tk header
Do Not Track on Wikipedia
What Does the "Track" in "Do Not Track" Mean? – EFF
DNT on Electronic Frontier Foundation
DNT browser settings help:

Firefox
Chrome


GPC - Global Privacy Control

Enabling GPC in Firefox


Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nDNTDeprecated: This feature is no longer recommended. Though some browsers might still support it, it may have already been removed from the relevant web standards, may be in the process of being dropped, or may only be kept for compatibility purposes. Avoid using it, and update existing code if possible; see the compatibility table at the bottom of this page to guide your decision. Be aware that this feature may cease to work at any time.
Non-standard: This feature is non-standard and is not on a standards track. Do not use it on production sites facing the Web: it will not work for every user. There may also be large incompatibilities between implementations and the behavior may change in the future.

Note:
The DNT (Do Not Track) specification has been discontinued. See Navigator.doNotTrack for more information.

The HTTP DNT (Do Not Track) request header indicates the user's tracking preference.
It lets users indicate whether they would prefer privacy rather than personalized content.
DNT is deprecated in favor of Global Privacy Control, which is communicated to servers using the Sec-GPC header, and accessible to clients from navigator.globalPrivacyControl.

  
    
      Header type
      Request header
    
    
      Forbidden request header
      Yes
    
  
SyntaxhttpDNT: 0
DNT: 1
DNT: null
Directives
0

The user prefers to allow tracking on the target site.

1

The user prefers not to be tracked on the target site.

null

The user has not specified a preference about tracking.

ExamplesReading Do Not Track status from JavaScriptThe user's DNT preference can also be read from JavaScript using the
Navigator.doNotTrack property:
jsnavigator.doNotTrack; // "0", "1" or null
SpecificationsPart of the discontinued Tracking Preference Expression (DNT) specification.Browser compatibilitySee also
Navigator.doNotTrack
Tk header
Do Not Track on Wikipedia
What Does the "Track" in "Do Not Track" Mean? – EFF
DNT on Electronic Frontier Foundation
DNT browser settings help:

Firefox
Chrome


GPC - Global Privacy Control

Enabling GPC in Firefox


Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nDownlinkLimited availabilityThis feature is not Baseline because it does not work in some of the most widely-used browsers.Learn moreSee full compatibilityReport feedback 
Experimental: This is an experimental technologyCheck the Browser compatibility table carefully before using this in production.
The HTTP Downlink request header is used in Client Hints to provide the approximate bandwidth in Mbps of the client's connection to the server.
The hint allows a server to choose what information is sent based on the network bandwidth.
For example, a server might choose to send smaller versions of images and other resources on low bandwidth networks.

Note:
The Vary header is used in responses to indicate that a different resource is sent for every different value of the header (see HTTP Caching Vary).
Even if Downlink is used to configure what resources are sent, consider omitting it in the Vary header — it is likely to change often, which effectively makes the resource uncacheable.


  
    
      Header type
      
        Request header,
        Client hint
      
    
    
      Forbidden request header
      No
    
  
SyntaxhttpDownlink: <number>
Directives
<number>

The downlink rate in Mbps, rounded to the nearest 25 kilobits.
The downlink rate may be used as a fingerprinting variable, so values for the header are intentionally coarse to reduce the potential for its misuse.

ExamplesA server first needs to opt in to receive the Downlink header by sending the Accept-CH response header containing Downlink.
httpAccept-CH: Downlink

Then on subsequent requests the client might send a Downlink header back:
httpDownlink: 1.7
SpecificationsSpecificationNetwork Information API # downlink-request-header-fieldBrowser compatibilitySee also
Improving user privacy and developer experience with User-Agent Client Hints (developer.chrome.com)
Network client hints

RTT
ECT
Save-Data


Accept-CH
HTTP Caching: Vary and Vary
NetworkInformation.effectiveType\n\nDownlinkLimited availabilityThis feature is not Baseline because it does not work in some of the most widely-used browsers.Learn moreSee full compatibilityReport feedback 
Experimental: This is an experimental technologyCheck the Browser compatibility table carefully before using this in production.
The HTTP Downlink request header is used in Client Hints to provide the approximate bandwidth in Mbps of the client's connection to the server.
The hint allows a server to choose what information is sent based on the network bandwidth.
For example, a server might choose to send smaller versions of images and other resources on low bandwidth networks.

Note:
The Vary header is used in responses to indicate that a different resource is sent for every different value of the header (see HTTP Caching Vary).
Even if Downlink is used to configure what resources are sent, consider omitting it in the Vary header — it is likely to change often, which effectively makes the resource uncacheable.


  
    
      Header type
      
        Request header,
        Client hint
      
    
    
      Forbidden request header
      No
    
  
SyntaxhttpDownlink: <number>
Directives
<number>

The downlink rate in Mbps, rounded to the nearest 25 kilobits.
The downlink rate may be used as a fingerprinting variable, so values for the header are intentionally coarse to reduce the potential for its misuse.

ExamplesA server first needs to opt in to receive the Downlink header by sending the Accept-CH response header containing Downlink.
httpAccept-CH: Downlink

Then on subsequent requests the client might send a Downlink header back:
httpDownlink: 1.7
SpecificationsSpecificationNetwork Information API # downlink-request-header-fieldBrowser compatibilitySee also
Improving user privacy and developer experience with User-Agent Client Hints (developer.chrome.com)
Network client hints

RTT
ECT
Save-Data


Accept-CH
HTTP Caching: Vary and Vary
NetworkInformation.effectiveType
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nDownlinkLimited availabilityThis feature is not Baseline because it does not work in some of the most widely-used browsers.Learn moreSee full compatibilityReport feedback 
Experimental: This is an experimental technologyCheck the Browser compatibility table carefully before using this in production.
The HTTP Downlink request header is used in Client Hints to provide the approximate bandwidth in Mbps of the client's connection to the server.
The hint allows a server to choose what information is sent based on the network bandwidth.
For example, a server might choose to send smaller versions of images and other resources on low bandwidth networks.

Note:
The Vary header is used in responses to indicate that a different resource is sent for every different value of the header (see HTTP Caching Vary).
Even if Downlink is used to configure what resources are sent, consider omitting it in the Vary header — it is likely to change often, which effectively makes the resource uncacheable.


  
    
      Header type
      
        Request header,
        Client hint
      
    
    
      Forbidden request header
      No
    
  
SyntaxhttpDownlink: <number>
Directives
<number>

The downlink rate in Mbps, rounded to the nearest 25 kilobits.
The downlink rate may be used as a fingerprinting variable, so values for the header are intentionally coarse to reduce the potential for its misuse.

ExamplesA server first needs to opt in to receive the Downlink header by sending the Accept-CH response header containing Downlink.
httpAccept-CH: Downlink

Then on subsequent requests the client might send a Downlink header back:
httpDownlink: 1.7
SpecificationsSpecificationNetwork Information API # downlink-request-header-fieldBrowser compatibilitySee also
Improving user privacy and developer experience with User-Agent Client Hints (developer.chrome.com)
Network client hints

RTT
ECT
Save-Data


Accept-CH
HTTP Caching: Vary and Vary
NetworkInformation.effectiveType
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nDPRDeprecated: This feature is no longer recommended. Though some browsers might still support it, it may have already been removed from the relevant web standards, may be in the process of being dropped, or may only be kept for compatibility purposes. Avoid using it, and update existing code if possible; see the compatibility table at the bottom of this page to guide your decision. Be aware that this feature may cease to work at any time.
Secure context: This feature is available only in secure contexts (HTTPS), in some or all supporting browsers.
Non-standard: This feature is non-standard and is not on a standards track. Do not use it on production sites facing the Web: it will not work for every user. There may also be large incompatibilities between implementations and the behavior may change in the future.

Warning:
The DPR header was removed from the client hints specification in draft-ietf-httpbis-client-hints-07.
The proposed replacement is Sec-CH-DPR (Responsive Image Client Hints).

The HTTP DPR request header provides device client hints about the client device pixel ratio (DPR).
This ratio is the number of physical device pixels corresponding to every CSS pixel.
The hint is useful when selecting image sources that best correspond to a screen's pixel density.
This is similar to the role played by x descriptors in the <img> srcset attribute to allow user agents to select a preferred image.
If a server uses the DPR hint to choose which resource is sent in a response, the response must include the Content-DPR header.
The client must use the value in Content-DPR for layout if it differs from the value in the request's DPR header.
If the DPR header appears more than once in a message the last occurrence is used.
Servers that opt in to the DPR client hint will typically also specify it in the Vary header to inform caches that the server may send different responses based on the header value in a request.

  
    
      Header type
      
        Request header,
        Client hint
      
    
    
      Forbidden request header
      No
    
  
SyntaxhttpDPR: <number>
Directives
<number>

The client device pixel ratio.

ExamplesA server must first opt in to receive the DPR header by sending the response header Accept-CH containing the directive DPR.
httpAccept-CH: DPR

Then on subsequent requests the client might send DPR header to the server:
httpDPR: 2.0

If a request with the DPR header (as shown above) is for an image resource, then the server response must include the Content-DPR header:
httpContent-DPR: 2.0
Browser compatibilitySee also
Device client hints

Content-DPR
Device-Memory
Viewport-Width
Width


Accept-CH
HTTP Caching: Vary and Vary
Improving user privacy and developer experience with User-Agent Client Hints (developer.chrome.com)\n\nDPRDeprecated: This feature is no longer recommended. Though some browsers might still support it, it may have already been removed from the relevant web standards, may be in the process of being dropped, or may only be kept for compatibility purposes. Avoid using it, and update existing code if possible; see the compatibility table at the bottom of this page to guide your decision. Be aware that this feature may cease to work at any time.
Secure context: This feature is available only in secure contexts (HTTPS), in some or all supporting browsers.
Non-standard: This feature is non-standard and is not on a standards track. Do not use it on production sites facing the Web: it will not work for every user. There may also be large incompatibilities between implementations and the behavior may change in the future.

Warning:
The DPR header was removed from the client hints specification in draft-ietf-httpbis-client-hints-07.
The proposed replacement is Sec-CH-DPR (Responsive Image Client Hints).

The HTTP DPR request header provides device client hints about the client device pixel ratio (DPR).
This ratio is the number of physical device pixels corresponding to every CSS pixel.
The hint is useful when selecting image sources that best correspond to a screen's pixel density.
This is similar to the role played by x descriptors in the <img> srcset attribute to allow user agents to select a preferred image.
If a server uses the DPR hint to choose which resource is sent in a response, the response must include the Content-DPR header.
The client must use the value in Content-DPR for layout if it differs from the value in the request's DPR header.
If the DPR header appears more than once in a message the last occurrence is used.
Servers that opt in to the DPR client hint will typically also specify it in the Vary header to inform caches that the server may send different responses based on the header value in a request.

  
    
      Header type
      
        Request header,
        Client hint
      
    
    
      Forbidden request header
      No
    
  
SyntaxhttpDPR: <number>
Directives
<number>

The client device pixel ratio.

ExamplesA server must first opt in to receive the DPR header by sending the response header Accept-CH containing the directive DPR.
httpAccept-CH: DPR

Then on subsequent requests the client might send DPR header to the server:
httpDPR: 2.0

If a request with the DPR header (as shown above) is for an image resource, then the server response must include the Content-DPR header:
httpContent-DPR: 2.0
Browser compatibilitySee also
Device client hints

Content-DPR
Device-Memory
Viewport-Width
Width


Accept-CH
HTTP Caching: Vary and Vary
Improving user privacy and developer experience with User-Agent Client Hints (developer.chrome.com)
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Apr 10, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nDPRDeprecated: This feature is no longer recommended. Though some browsers might still support it, it may have already been removed from the relevant web standards, may be in the process of being dropped, or may only be kept for compatibility purposes. Avoid using it, and update existing code if possible; see the compatibility table at the bottom of this page to guide your decision. Be aware that this feature may cease to work at any time.
Secure context: This feature is available only in secure contexts (HTTPS), in some or all supporting browsers.
Non-standard: This feature is non-standard and is not on a standards track. Do not use it on production sites facing the Web: it will not work for every user. There may also be large incompatibilities between implementations and the behavior may change in the future.

Warning:
The DPR header was removed from the client hints specification in draft-ietf-httpbis-client-hints-07.
The proposed replacement is Sec-CH-DPR (Responsive Image Client Hints).

The HTTP DPR request header provides device client hints about the client device pixel ratio (DPR).
This ratio is the number of physical device pixels corresponding to every CSS pixel.
The hint is useful when selecting image sources that best correspond to a screen's pixel density.
This is similar to the role played by x descriptors in the <img> srcset attribute to allow user agents to select a preferred image.
If a server uses the DPR hint to choose which resource is sent in a response, the response must include the Content-DPR header.
The client must use the value in Content-DPR for layout if it differs from the value in the request's DPR header.
If the DPR header appears more than once in a message the last occurrence is used.
Servers that opt in to the DPR client hint will typically also specify it in the Vary header to inform caches that the server may send different responses based on the header value in a request.

  
    
      Header type
      
        Request header,
        Client hint
      
    
    
      Forbidden request header
      No
    
  
SyntaxhttpDPR: <number>
Directives
<number>

The client device pixel ratio.

ExamplesA server must first opt in to receive the DPR header by sending the response header Accept-CH containing the directive DPR.
httpAccept-CH: DPR

Then on subsequent requests the client might send DPR header to the server:
httpDPR: 2.0

If a request with the DPR header (as shown above) is for an image resource, then the server response must include the Content-DPR header:
httpContent-DPR: 2.0
Browser compatibilitySee also
Device client hints

Content-DPR
Device-Memory
Viewport-Width
Width


Accept-CH
HTTP Caching: Vary and Vary
Improving user privacy and developer experience with User-Agent Client Hints (developer.chrome.com)
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Apr 10, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nEarly-DataLimited availabilityThis feature is not Baseline because it does not work in some of the most widely-used browsers.Learn moreSee full compatibilityReport feedbackExperimental: This is an experimental technologyCheck the Browser compatibility table carefully before using this in production.
The HTTP Early-Data request header is set by an intermediary to indicate that the request has been conveyed in TLS early data, and also indicates that the intermediary understands the 425 Too Early status code.
If a client has interacted with a server recently, early data (also known as zero round-trip time (0-RTT) data) allows the client to send data to a server in the first round trip of a connection, without waiting for the TLS handshake to complete.
This reduces latency for repeat connections between a client and server, but has security implications, as early data is susceptible to replay attacks.
The Early-Data header is not set by the originator of the request (i.e., a browser).

  
    
      Header type
      Request header
    
    
      Forbidden request header
      No
    
  
SyntaxhttpEarly-Data: 1
ExamplesA GET request with an Early-Data headerA client that wants to use early data can send HTTP requests immediately after sending the TLS ClientHello.
Sending a request in early data implies that the client is willing to retry a request in response to a 425 Too Early status code, so the Early-Data header is not included:
httpGET /resource HTTP/1.1
Host: example.com

An intermediary that forwards a request prior to the completion of the TLS handshake with its client sends it with the Early-Data header set to 1:
httpGET /resource HTTP/1.1
Host: example.com
Early-Data: 1
SpecificationsSpecificationUsing Early Data in HTTP # headerBrowser compatibilitySee also
425 Too Early
Replay Attacks on 0-RTT\n\nEarly-DataLimited availabilityThis feature is not Baseline because it does not work in some of the most widely-used browsers.Learn moreSee full compatibilityReport feedbackExperimental: This is an experimental technologyCheck the Browser compatibility table carefully before using this in production.
The HTTP Early-Data request header is set by an intermediary to indicate that the request has been conveyed in TLS early data, and also indicates that the intermediary understands the 425 Too Early status code.
If a client has interacted with a server recently, early data (also known as zero round-trip time (0-RTT) data) allows the client to send data to a server in the first round trip of a connection, without waiting for the TLS handshake to complete.
This reduces latency for repeat connections between a client and server, but has security implications, as early data is susceptible to replay attacks.
The Early-Data header is not set by the originator of the request (i.e., a browser).

  
    
      Header type
      Request header
    
    
      Forbidden request header
      No
    
  
SyntaxhttpEarly-Data: 1
ExamplesA GET request with an Early-Data headerA client that wants to use early data can send HTTP requests immediately after sending the TLS ClientHello.
Sending a request in early data implies that the client is willing to retry a request in response to a 425 Too Early status code, so the Early-Data header is not included:
httpGET /resource HTTP/1.1
Host: example.com

An intermediary that forwards a request prior to the completion of the TLS handshake with its client sends it with the Early-Data header set to 1:
httpGET /resource HTTP/1.1
Host: example.com
Early-Data: 1
SpecificationsSpecificationUsing Early Data in HTTP # headerBrowser compatibilitySee also
425 Too Early
Replay Attacks on 0-RTT
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nEarly-DataLimited availabilityThis feature is not Baseline because it does not work in some of the most widely-used browsers.Learn moreSee full compatibilityReport feedbackExperimental: This is an experimental technologyCheck the Browser compatibility table carefully before using this in production.
The HTTP Early-Data request header is set by an intermediary to indicate that the request has been conveyed in TLS early data, and also indicates that the intermediary understands the 425 Too Early status code.
If a client has interacted with a server recently, early data (also known as zero round-trip time (0-RTT) data) allows the client to send data to a server in the first round trip of a connection, without waiting for the TLS handshake to complete.
This reduces latency for repeat connections between a client and server, but has security implications, as early data is susceptible to replay attacks.
The Early-Data header is not set by the originator of the request (i.e., a browser).

  
    
      Header type
      Request header
    
    
      Forbidden request header
      No
    
  
SyntaxhttpEarly-Data: 1
ExamplesA GET request with an Early-Data headerA client that wants to use early data can send HTTP requests immediately after sending the TLS ClientHello.
Sending a request in early data implies that the client is willing to retry a request in response to a 425 Too Early status code, so the Early-Data header is not included:
httpGET /resource HTTP/1.1
Host: example.com

An intermediary that forwards a request prior to the completion of the TLS handshake with its client sends it with the Early-Data header set to 1:
httpGET /resource HTTP/1.1
Host: example.com
Early-Data: 1
SpecificationsSpecificationUsing Early Data in HTTP # headerBrowser compatibilitySee also
425 Too Early
Replay Attacks on 0-RTT
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nECTLimited availabilityThis feature is not Baseline because it does not work in some of the most widely-used browsers.Learn moreSee full compatibilityReport feedback 
Experimental: This is an experimental technologyCheck the Browser compatibility table carefully before using this in production.
The HTTP ECT request header is used in Client Hints to indicate the effective connection type: slow-2g, 2g, 3g, or 4g.
The value represents the "network profile" that best matches the connection's latency and bandwidth, rather than the actual mechanisms used for transferring the data.
For example, 2g might be used to represent a slow Wi-Fi connection with high latency and low bandwidth, while 4g might represent a fast fibre-based broadband network.
The hint allows a server to choose what information is sent based on the broad characteristics of the network. For example, a server might choose to send smaller versions of images and other resources on less capable connections. The value might also be used as a starting point for determining what information is sent, which is further refined using information in RTT and Downlink hints.

Note:
A server that specifies ECT in Accept-CH may also specify it in Vary to indicate that responses should be cached for different ECT values.


  
    
      Header type
      
        Request header,
        Client hint
      
    
    
      Forbidden request header
      No
    
  
SyntaxhttpECT: <value>
Directives
<value>

A value indicating effective connection type. Can be one of: slow-2g, 2g, 3g, or 4g.

ExamplesA server first needs to opt in to receive the ECT header by sending the Accept-CH response header containing ECT.
httpAccept-CH: ECT

Then on subsequent requests the client might send an ECT header back:
httpECT: 2g
SpecificationsSpecificationNetwork Information API # ect-request-header-fieldBrowser compatibilitySee also

Improving user privacy and developer experience with User-Agent Client Hints (developer.chrome.com)


Network client hints

Downlink
RTT
Save-Data


Accept-CH

HTTP Caching > Vary and Vary

NetworkInformation.effectiveType\n\nECTLimited availabilityThis feature is not Baseline because it does not work in some of the most widely-used browsers.Learn moreSee full compatibilityReport feedback 
Experimental: This is an experimental technologyCheck the Browser compatibility table carefully before using this in production.
The HTTP ECT request header is used in Client Hints to indicate the effective connection type: slow-2g, 2g, 3g, or 4g.
The value represents the "network profile" that best matches the connection's latency and bandwidth, rather than the actual mechanisms used for transferring the data.
For example, 2g might be used to represent a slow Wi-Fi connection with high latency and low bandwidth, while 4g might represent a fast fibre-based broadband network.
The hint allows a server to choose what information is sent based on the broad characteristics of the network. For example, a server might choose to send smaller versions of images and other resources on less capable connections. The value might also be used as a starting point for determining what information is sent, which is further refined using information in RTT and Downlink hints.

Note:
A server that specifies ECT in Accept-CH may also specify it in Vary to indicate that responses should be cached for different ECT values.


  
    
      Header type
      
        Request header,
        Client hint
      
    
    
      Forbidden request header
      No
    
  
SyntaxhttpECT: <value>
Directives
<value>

A value indicating effective connection type. Can be one of: slow-2g, 2g, 3g, or 4g.

ExamplesA server first needs to opt in to receive the ECT header by sending the Accept-CH response header containing ECT.
httpAccept-CH: ECT

Then on subsequent requests the client might send an ECT header back:
httpECT: 2g
SpecificationsSpecificationNetwork Information API # ect-request-header-fieldBrowser compatibilitySee also

Improving user privacy and developer experience with User-Agent Client Hints (developer.chrome.com)


Network client hints

Downlink
RTT
Save-Data


Accept-CH

HTTP Caching > Vary and Vary

NetworkInformation.effectiveType
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nECTLimited availabilityThis feature is not Baseline because it does not work in some of the most widely-used browsers.Learn moreSee full compatibilityReport feedback 
Experimental: This is an experimental technologyCheck the Browser compatibility table carefully before using this in production.
The HTTP ECT request header is used in Client Hints to indicate the effective connection type: slow-2g, 2g, 3g, or 4g.
The value represents the "network profile" that best matches the connection's latency and bandwidth, rather than the actual mechanisms used for transferring the data.
For example, 2g might be used to represent a slow Wi-Fi connection with high latency and low bandwidth, while 4g might represent a fast fibre-based broadband network.
The hint allows a server to choose what information is sent based on the broad characteristics of the network. For example, a server might choose to send smaller versions of images and other resources on less capable connections. The value might also be used as a starting point for determining what information is sent, which is further refined using information in RTT and Downlink hints.

Note:
A server that specifies ECT in Accept-CH may also specify it in Vary to indicate that responses should be cached for different ECT values.


  
    
      Header type
      
        Request header,
        Client hint
      
    
    
      Forbidden request header
      No
    
  
SyntaxhttpECT: <value>
Directives
<value>

A value indicating effective connection type. Can be one of: slow-2g, 2g, 3g, or 4g.

ExamplesA server first needs to opt in to receive the ECT header by sending the Accept-CH response header containing ECT.
httpAccept-CH: ECT

Then on subsequent requests the client might send an ECT header back:
httpECT: 2g
SpecificationsSpecificationNetwork Information API # ect-request-header-fieldBrowser compatibilitySee also

Improving user privacy and developer experience with User-Agent Client Hints (developer.chrome.com)


Network client hints

Downlink
RTT
Save-Data


Accept-CH

HTTP Caching > Vary and Vary

NetworkInformation.effectiveType
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nETagBaseline Widely availableThis feature is well established and works across many devices and browser versions. It’s been available across browsers since July 2015.Learn moreSee full compatibilityReport feedbackThe HTTP ETag (entity tag) response header is an identifier for a specific version of a resource.
It lets caches be more efficient and save bandwidth, as a web server does not need to resend a full response if the content has not changed.
Additionally, ETags help to prevent simultaneous updates of a resource from overwriting each other ("mid-air collisions").
If the resource at a given URL changes, a new Etag value must be generated.
A comparison of them can determine whether two representations of a resource are the same.

  
    
      Header type
      Response header, Representation header
    
    
      Forbidden request header
      No
    
  
SyntaxhttpETag: W/"<etag_value>"
ETag: "<etag_value>"
Directives
W/ Optional

W/ (case-sensitive) indicates that a weak validator is used.
Weak ETags are easy to generate, but are far less useful for comparisons.
Strong validators are ideal for comparisons but can be very difficult to generate efficiently.
Weak ETag values of two representations of the same resources might be semantically equivalent, but not byte-for-byte identical.
This means weak ETags prevent caching when byte range requests are used, but strong ETags mean range requests can still be cached.

<etag_value>

Entity tag that uniquely represents the requested resource. It is a string of ASCII characters placed between double quotes, like "675af34563dc-tr34".
The method by which ETag values are generated is not specified.
Typically, the ETag value is a hash of the content, a hash of the last modification timestamp, or just a revision number.
For example, a wiki engine can use a hexadecimal hash of the documentation article content.

ExampleshttpETag: "33a64df551425fcc55e4d42a148795d9f25f89d4"
ETag: W/"0815"
Avoiding mid-air collisionsWith the help of the ETag and the If-Match headers, you can detect mid-air edit collisions (conflicts).
For example, when editing a wiki, the current wiki content may be hashed and put into an Etag header in the response:
httpETag: "33a64df551425fcc55e4d42a148795d9f25f89d4"

When saving changes to a wiki page (posting data), the POST request
will contain the If-Match header containing the ETag
values to check freshness against.
httpIf-Match: "33a64df551425fcc55e4d42a148795d9f25f89d4"

If the hashes don't match, it means that the document has been edited in-between and a
412 Precondition Failed error is thrown.Caching of unchanged resourcesAnother typical use of the ETag header is to cache resources that are unchanged.
If a user visits a given URL again (that has an ETag set), and it is stale (too old to be considered usable), the client will send the value of its ETag along in an If-None-Match header field:
httpIf-None-Match: "33a64df551425fcc55e4d42a148795d9f25f89d4"

The server compares the client's ETag (sent with If-None-Match) with the ETag for its current version of the resource, and if both values match (that is, the resource has not changed), the server sends back a 304 Not Modified status, without a body, which tells the client that the cached version of the response is still good to use (fresh).SpecificationsSpecificationHTTP Semantics # field.etagBrowser compatibilitySee also
If-Match, If-None-Match headers
304 Not Modified, 412 Precondition Failed response status codes
W3C Note: Editing the Web – Detecting the Lost Update Problem Using Unreserved Checkout\n\nETagBaseline Widely availableThis feature is well established and works across many devices and browser versions. It’s been available across browsers since July 2015.Learn moreSee full compatibilityReport feedbackThe HTTP ETag (entity tag) response header is an identifier for a specific version of a resource.
It lets caches be more efficient and save bandwidth, as a web server does not need to resend a full response if the content has not changed.
Additionally, ETags help to prevent simultaneous updates of a resource from overwriting each other ("mid-air collisions").
If the resource at a given URL changes, a new Etag value must be generated.
A comparison of them can determine whether two representations of a resource are the same.

  
    
      Header type
      Response header, Representation header
    
    
      Forbidden request header
      No
    
  
SyntaxhttpETag: W/"<etag_value>"
ETag: "<etag_value>"
Directives
W/ Optional

W/ (case-sensitive) indicates that a weak validator is used.
Weak ETags are easy to generate, but are far less useful for comparisons.
Strong validators are ideal for comparisons but can be very difficult to generate efficiently.
Weak ETag values of two representations of the same resources might be semantically equivalent, but not byte-for-byte identical.
This means weak ETags prevent caching when byte range requests are used, but strong ETags mean range requests can still be cached.

<etag_value>

Entity tag that uniquely represents the requested resource. It is a string of ASCII characters placed between double quotes, like "675af34563dc-tr34".
The method by which ETag values are generated is not specified.
Typically, the ETag value is a hash of the content, a hash of the last modification timestamp, or just a revision number.
For example, a wiki engine can use a hexadecimal hash of the documentation article content.

ExampleshttpETag: "33a64df551425fcc55e4d42a148795d9f25f89d4"
ETag: W/"0815"
Avoiding mid-air collisionsWith the help of the ETag and the If-Match headers, you can detect mid-air edit collisions (conflicts).
For example, when editing a wiki, the current wiki content may be hashed and put into an Etag header in the response:
httpETag: "33a64df551425fcc55e4d42a148795d9f25f89d4"

When saving changes to a wiki page (posting data), the POST request
will contain the If-Match header containing the ETag
values to check freshness against.
httpIf-Match: "33a64df551425fcc55e4d42a148795d9f25f89d4"

If the hashes don't match, it means that the document has been edited in-between and a
412 Precondition Failed error is thrown.Caching of unchanged resourcesAnother typical use of the ETag header is to cache resources that are unchanged.
If a user visits a given URL again (that has an ETag set), and it is stale (too old to be considered usable), the client will send the value of its ETag along in an If-None-Match header field:
httpIf-None-Match: "33a64df551425fcc55e4d42a148795d9f25f89d4"

The server compares the client's ETag (sent with If-None-Match) with the ETag for its current version of the resource, and if both values match (that is, the resource has not changed), the server sends back a 304 Not Modified status, without a body, which tells the client that the cached version of the response is still good to use (fresh).SpecificationsSpecificationHTTP Semantics # field.etagBrowser compatibilitySee also
If-Match, If-None-Match headers
304 Not Modified, 412 Precondition Failed response status codes
W3C Note: Editing the Web – Detecting the Lost Update Problem Using Unreserved Checkout
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nETagBaseline Widely availableThis feature is well established and works across many devices and browser versions. It’s been available across browsers since July 2015.Learn moreSee full compatibilityReport feedbackThe HTTP ETag (entity tag) response header is an identifier for a specific version of a resource.
It lets caches be more efficient and save bandwidth, as a web server does not need to resend a full response if the content has not changed.
Additionally, ETags help to prevent simultaneous updates of a resource from overwriting each other ("mid-air collisions").
If the resource at a given URL changes, a new Etag value must be generated.
A comparison of them can determine whether two representations of a resource are the same.

  
    
      Header type
      Response header, Representation header
    
    
      Forbidden request header
      No
    
  
SyntaxhttpETag: W/"<etag_value>"
ETag: "<etag_value>"
Directives
W/ Optional

W/ (case-sensitive) indicates that a weak validator is used.
Weak ETags are easy to generate, but are far less useful for comparisons.
Strong validators are ideal for comparisons but can be very difficult to generate efficiently.
Weak ETag values of two representations of the same resources might be semantically equivalent, but not byte-for-byte identical.
This means weak ETags prevent caching when byte range requests are used, but strong ETags mean range requests can still be cached.

<etag_value>

Entity tag that uniquely represents the requested resource. It is a string of ASCII characters placed between double quotes, like "675af34563dc-tr34".
The method by which ETag values are generated is not specified.
Typically, the ETag value is a hash of the content, a hash of the last modification timestamp, or just a revision number.
For example, a wiki engine can use a hexadecimal hash of the documentation article content.

ExampleshttpETag: "33a64df551425fcc55e4d42a148795d9f25f89d4"
ETag: W/"0815"
Avoiding mid-air collisionsWith the help of the ETag and the If-Match headers, you can detect mid-air edit collisions (conflicts).
For example, when editing a wiki, the current wiki content may be hashed and put into an Etag header in the response:
httpETag: "33a64df551425fcc55e4d42a148795d9f25f89d4"

When saving changes to a wiki page (posting data), the POST request
will contain the If-Match header containing the ETag
values to check freshness against.
httpIf-Match: "33a64df551425fcc55e4d42a148795d9f25f89d4"

If the hashes don't match, it means that the document has been edited in-between and a
412 Precondition Failed error is thrown.Caching of unchanged resourcesAnother typical use of the ETag header is to cache resources that are unchanged.
If a user visits a given URL again (that has an ETag set), and it is stale (too old to be considered usable), the client will send the value of its ETag along in an If-None-Match header field:
httpIf-None-Match: "33a64df551425fcc55e4d42a148795d9f25f89d4"

The server compares the client's ETag (sent with If-None-Match) with the ETag for its current version of the resource, and if both values match (that is, the resource has not changed), the server sends back a 304 Not Modified status, without a body, which tells the client that the cached version of the response is still good to use (fresh).SpecificationsSpecificationHTTP Semantics # field.etagBrowser compatibilitySee also
If-Match, If-None-Match headers
304 Not Modified, 412 Precondition Failed response status codes
W3C Note: Editing the Web – Detecting the Lost Update Problem Using Unreserved Checkout
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nExpectThe HTTP Expect request header indicates that there are expectations that need to be met by the server in order to handle the complete request successfully.
When a request has an Expect: 100-continue header, a server sends a 100 Continue response to indicate that the server is ready or capable of receiving the rest of the request content.
Waiting for a 100 response can be helpful if a client anticipates that an error is likely, for example, when sending state-changing operations without previously verified authentication credentials.
A 417 Expectation Failed response is returned if the server cannot meet the expectation, or any other status otherwise (e.g., a 4XX status for a client error, or a 2XX status if the request can be resolved successfully without further processing).
None of the more common browsers send the Expect header, but some clients (command-line tools) do so by default.

  
    
      Header type
      Request header
    
    
      Forbidden request header
      Yes
    
  
SyntaxhttpExpect: 100-continue
DirectivesThere is only one defined expectation:

100-continue

Informs recipients that the client is about to send a (presumably large) message body in this request and wishes to receive a 100 Continue interim response.

ExamplesLarge message bodyA client sends a request with Expect header and waits for the server to respond before sending the message body.
httpPUT /somewhere/fun HTTP/1.1
Host: origin.example.com
Content-Type: video/h264
Content-Length: 1234567890987
Expect: 100-continue

The server checks the headers and generates the response, where a 100 Continue instructs the client to send the message body:
httpHTTP/1.1 100 Continue

The client completes the request by sending the actual data:
http[Video data as content for PUT request]
SpecificationsSpecificationHTTP Semantics # field.expectSee also
417 Expectation Failed
100 Continue\n\nExpectThe HTTP Expect request header indicates that there are expectations that need to be met by the server in order to handle the complete request successfully.
When a request has an Expect: 100-continue header, a server sends a 100 Continue response to indicate that the server is ready or capable of receiving the rest of the request content.
Waiting for a 100 response can be helpful if a client anticipates that an error is likely, for example, when sending state-changing operations without previously verified authentication credentials.
A 417 Expectation Failed response is returned if the server cannot meet the expectation, or any other status otherwise (e.g., a 4XX status for a client error, or a 2XX status if the request can be resolved successfully without further processing).
None of the more common browsers send the Expect header, but some clients (command-line tools) do so by default.

  
    
      Header type
      Request header
    
    
      Forbidden request header
      Yes
    
  
SyntaxhttpExpect: 100-continue
DirectivesThere is only one defined expectation:

100-continue

Informs recipients that the client is about to send a (presumably large) message body in this request and wishes to receive a 100 Continue interim response.

ExamplesLarge message bodyA client sends a request with Expect header and waits for the server to respond before sending the message body.
httpPUT /somewhere/fun HTTP/1.1
Host: origin.example.com
Content-Type: video/h264
Content-Length: 1234567890987
Expect: 100-continue

The server checks the headers and generates the response, where a 100 Continue instructs the client to send the message body:
httpHTTP/1.1 100 Continue

The client completes the request by sending the actual data:
http[Video data as content for PUT request]
SpecificationsSpecificationHTTP Semantics # field.expectSee also
417 Expectation Failed
100 Continue
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nExpectThe HTTP Expect request header indicates that there are expectations that need to be met by the server in order to handle the complete request successfully.
When a request has an Expect: 100-continue header, a server sends a 100 Continue response to indicate that the server is ready or capable of receiving the rest of the request content.
Waiting for a 100 response can be helpful if a client anticipates that an error is likely, for example, when sending state-changing operations without previously verified authentication credentials.
A 417 Expectation Failed response is returned if the server cannot meet the expectation, or any other status otherwise (e.g., a 4XX status for a client error, or a 2XX status if the request can be resolved successfully without further processing).
None of the more common browsers send the Expect header, but some clients (command-line tools) do so by default.

  
    
      Header type
      Request header
    
    
      Forbidden request header
      Yes
    
  
SyntaxhttpExpect: 100-continue
DirectivesThere is only one defined expectation:

100-continue

Informs recipients that the client is about to send a (presumably large) message body in this request and wishes to receive a 100 Continue interim response.

ExamplesLarge message bodyA client sends a request with Expect header and waits for the server to respond before sending the message body.
httpPUT /somewhere/fun HTTP/1.1
Host: origin.example.com
Content-Type: video/h264
Content-Length: 1234567890987
Expect: 100-continue

The server checks the headers and generates the response, where a 100 Continue instructs the client to send the message body:
httpHTTP/1.1 100 Continue

The client completes the request by sending the actual data:
http[Video data as content for PUT request]
SpecificationsSpecificationHTTP Semantics # field.expectSee also
417 Expectation Failed
100 Continue
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nExpect-CTDeprecated: This feature is no longer recommended. Though some browsers might still support it, it may have already been removed from the relevant web standards, may be in the process of being dropped, or may only be kept for compatibility purposes. Avoid using it, and update existing code if possible; see the compatibility table at the bottom of this page to guide your decision. Be aware that this feature may cease to work at any time.
The Expect-CT response header lets sites opt in to reporting and/or enforcement of Certificate Transparency requirements.
Certificate Transparency (CT) aims to prevent the use of misissued certificates for that site from going unnoticed.
Only Google Chrome and other Chromium-based browsers implemented Expect-CT, and Chromium has deprecated the header from version 107, because Chromium now enforces CT by default.
See the Chrome Platform Status update.
CT requirements can be satisfied via any one of the following mechanisms:

X.509v3 certificate extension to allow embedding of signed certificate timestamps issued by individual logs. Most TLS certificates issued by publicly-trusted CAs and used online contain embedded CT.
A TLS extension of type signed_certificate_timestamp sent during the handshake
Supporting OCSP stapling (that is, the status_request TLS extension) and providing a SignedCertificateTimestampList


Note:
When a site enables the Expect-CT header, they are requesting that the browser check that any certificate for that site appears in public CT logs.


Note:
Browsers ignore the Expect-CT header over HTTP; the header only has effect on HTTPS connections.


Note:
The Expect-CT is mostly obsolete since June 2021.
Since May 2018, all new TLS certificates are expected to support SCTs by default.
Certificates issued before March 2018 were allowed to have a lifetime of 39 months, so they had expired in June 2021.
Chromium plans to deprecate Expect-CT header and to eventually remove it.


  
    
      Header type
      Response header
    
    
      Forbidden request header
      Yes
    
  
SyntaxhttpExpect-CT: report-uri="<uri>",
           enforce,
           max-age=<age>
Directives
max-age

The number of seconds after reception of the Expect-CT header field during which the user agent should regard the host of the received message as a known Expect-CT host.
If a cache receives a value greater than it can represent, or if any of its subsequent calculations overflows, the cache will consider this value to be either 2,147,483,648 (2^31) or the greatest positive integer it can represent.

report-uri="<uri>" Optional

The URI where the user agent should report Expect-CT failures.
When present with the enforce directive, the configuration is referred to as an "enforce-and-report" configuration, signalling to the user agent both that compliance to the Certificate Transparency policy should be enforced and that violations should be reported.

enforce Optional

Signals to the user agent that compliance with the Certificate Transparency policy should be enforced (rather than only reporting compliance) and that the user agent should refuse future connections that violate its Certificate Transparency policy.
When both the enforce directive and the report-uri directive are present, the configuration is referred to as an "enforce-and-report" configuration, signalling to the user agent both that compliance to the Certificate Transparency policy should be enforced and that violations should be reported.

ExampleThe following example specifies enforcement of Certificate Transparency for 24 hours and reports violations to foo.example.com.
httpExpect-CT: max-age=86400, enforce, report-uri="https://foo.example.com/report"
NotesRoot CAs manually added to the trust store override and suppress Expect-CT reports/enforcement.
Browsers will not remember an Expect-CT policy, unless the site has 'proven' it can serve a certificate satisfying the certificate transparency requirements. Browsers implement their own trust model regarding which CT logs are considered trusted for the certificate to have been logged to.
Builds of Chrome are designed to stop enforcing the Expect-CT policy 10 weeks after the installation's build date.SpecificationsSpecificationExpect-CT Extension for HTTP # section-2.1Browser compatibilitySee also
Secure Contexts
Glossary terms:

Transport Layer Security (TLS)
Secure Sockets Layer (SSL)
HTTPS\n\nExpect-CTDeprecated: This feature is no longer recommended. Though some browsers might still support it, it may have already been removed from the relevant web standards, may be in the process of being dropped, or may only be kept for compatibility purposes. Avoid using it, and update existing code if possible; see the compatibility table at the bottom of this page to guide your decision. Be aware that this feature may cease to work at any time.
The Expect-CT response header lets sites opt in to reporting and/or enforcement of Certificate Transparency requirements.
Certificate Transparency (CT) aims to prevent the use of misissued certificates for that site from going unnoticed.
Only Google Chrome and other Chromium-based browsers implemented Expect-CT, and Chromium has deprecated the header from version 107, because Chromium now enforces CT by default.
See the Chrome Platform Status update.
CT requirements can be satisfied via any one of the following mechanisms:

X.509v3 certificate extension to allow embedding of signed certificate timestamps issued by individual logs. Most TLS certificates issued by publicly-trusted CAs and used online contain embedded CT.
A TLS extension of type signed_certificate_timestamp sent during the handshake
Supporting OCSP stapling (that is, the status_request TLS extension) and providing a SignedCertificateTimestampList


Note:
When a site enables the Expect-CT header, they are requesting that the browser check that any certificate for that site appears in public CT logs.


Note:
Browsers ignore the Expect-CT header over HTTP; the header only has effect on HTTPS connections.


Note:
The Expect-CT is mostly obsolete since June 2021.
Since May 2018, all new TLS certificates are expected to support SCTs by default.
Certificates issued before March 2018 were allowed to have a lifetime of 39 months, so they had expired in June 2021.
Chromium plans to deprecate Expect-CT header and to eventually remove it.


  
    
      Header type
      Response header
    
    
      Forbidden request header
      Yes
    
  
SyntaxhttpExpect-CT: report-uri="<uri>",
           enforce,
           max-age=<age>
Directives
max-age

The number of seconds after reception of the Expect-CT header field during which the user agent should regard the host of the received message as a known Expect-CT host.
If a cache receives a value greater than it can represent, or if any of its subsequent calculations overflows, the cache will consider this value to be either 2,147,483,648 (2^31) or the greatest positive integer it can represent.

report-uri="<uri>" Optional

The URI where the user agent should report Expect-CT failures.
When present with the enforce directive, the configuration is referred to as an "enforce-and-report" configuration, signalling to the user agent both that compliance to the Certificate Transparency policy should be enforced and that violations should be reported.

enforce Optional

Signals to the user agent that compliance with the Certificate Transparency policy should be enforced (rather than only reporting compliance) and that the user agent should refuse future connections that violate its Certificate Transparency policy.
When both the enforce directive and the report-uri directive are present, the configuration is referred to as an "enforce-and-report" configuration, signalling to the user agent both that compliance to the Certificate Transparency policy should be enforced and that violations should be reported.

ExampleThe following example specifies enforcement of Certificate Transparency for 24 hours and reports violations to foo.example.com.
httpExpect-CT: max-age=86400, enforce, report-uri="https://foo.example.com/report"
NotesRoot CAs manually added to the trust store override and suppress Expect-CT reports/enforcement.
Browsers will not remember an Expect-CT policy, unless the site has 'proven' it can serve a certificate satisfying the certificate transparency requirements. Browsers implement their own trust model regarding which CT logs are considered trusted for the certificate to have been logged to.
Builds of Chrome are designed to stop enforcing the Expect-CT policy 10 weeks after the installation's build date.SpecificationsSpecificationExpect-CT Extension for HTTP # section-2.1Browser compatibilitySee also
Secure Contexts
Glossary terms:

Transport Layer Security (TLS)
Secure Sockets Layer (SSL)
HTTPS


Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nExpect-CTDeprecated: This feature is no longer recommended. Though some browsers might still support it, it may have already been removed from the relevant web standards, may be in the process of being dropped, or may only be kept for compatibility purposes. Avoid using it, and update existing code if possible; see the compatibility table at the bottom of this page to guide your decision. Be aware that this feature may cease to work at any time.
The Expect-CT response header lets sites opt in to reporting and/or enforcement of Certificate Transparency requirements.
Certificate Transparency (CT) aims to prevent the use of misissued certificates for that site from going unnoticed.
Only Google Chrome and other Chromium-based browsers implemented Expect-CT, and Chromium has deprecated the header from version 107, because Chromium now enforces CT by default.
See the Chrome Platform Status update.
CT requirements can be satisfied via any one of the following mechanisms:

X.509v3 certificate extension to allow embedding of signed certificate timestamps issued by individual logs. Most TLS certificates issued by publicly-trusted CAs and used online contain embedded CT.
A TLS extension of type signed_certificate_timestamp sent during the handshake
Supporting OCSP stapling (that is, the status_request TLS extension) and providing a SignedCertificateTimestampList


Note:
When a site enables the Expect-CT header, they are requesting that the browser check that any certificate for that site appears in public CT logs.


Note:
Browsers ignore the Expect-CT header over HTTP; the header only has effect on HTTPS connections.


Note:
The Expect-CT is mostly obsolete since June 2021.
Since May 2018, all new TLS certificates are expected to support SCTs by default.
Certificates issued before March 2018 were allowed to have a lifetime of 39 months, so they had expired in June 2021.
Chromium plans to deprecate Expect-CT header and to eventually remove it.


  
    
      Header type
      Response header
    
    
      Forbidden request header
      Yes
    
  
SyntaxhttpExpect-CT: report-uri="<uri>",
           enforce,
           max-age=<age>
Directives
max-age

The number of seconds after reception of the Expect-CT header field during which the user agent should regard the host of the received message as a known Expect-CT host.
If a cache receives a value greater than it can represent, or if any of its subsequent calculations overflows, the cache will consider this value to be either 2,147,483,648 (2^31) or the greatest positive integer it can represent.

report-uri="<uri>" Optional

The URI where the user agent should report Expect-CT failures.
When present with the enforce directive, the configuration is referred to as an "enforce-and-report" configuration, signalling to the user agent both that compliance to the Certificate Transparency policy should be enforced and that violations should be reported.

enforce Optional

Signals to the user agent that compliance with the Certificate Transparency policy should be enforced (rather than only reporting compliance) and that the user agent should refuse future connections that violate its Certificate Transparency policy.
When both the enforce directive and the report-uri directive are present, the configuration is referred to as an "enforce-and-report" configuration, signalling to the user agent both that compliance to the Certificate Transparency policy should be enforced and that violations should be reported.

ExampleThe following example specifies enforcement of Certificate Transparency for 24 hours and reports violations to foo.example.com.
httpExpect-CT: max-age=86400, enforce, report-uri="https://foo.example.com/report"
NotesRoot CAs manually added to the trust store override and suppress Expect-CT reports/enforcement.
Browsers will not remember an Expect-CT policy, unless the site has 'proven' it can serve a certificate satisfying the certificate transparency requirements. Browsers implement their own trust model regarding which CT logs are considered trusted for the certificate to have been logged to.
Builds of Chrome are designed to stop enforcing the Expect-CT policy 10 weeks after the installation's build date.SpecificationsSpecificationExpect-CT Extension for HTTP # section-2.1Browser compatibilitySee also
Secure Contexts
Glossary terms:

Transport Layer Security (TLS)
Secure Sockets Layer (SSL)
HTTPS


Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nExpiresBaseline Widely availableThis feature is well established and works across many devices and browser versions. It’s been available across browsers since July 2015.Learn moreSee full compatibilityReport feedbackThe HTTP Expires response header contains the date/time after which the response is considered expired in the context of HTTP caching.
The value 0 is used to represent a date in the past, indicating the resource has already expired.

Note:
If there is a Cache-Control header with the max-age or s-maxage directive in the response, the Expires header is ignored.


  
    
      Header type
      Response header
    
    
      Forbidden request header
      No
    
    
      
        CORS-safelisted response header
      
      Yes
    
  
SyntaxhttpExpires: <day-name>, <day> <month> <year> <hour>:<minute>:<second> GMT
Directives
<day-name>

One of Mon, Tue, Wed, Thu, Fri, Sat, or Sun (case-sensitive).

<day>

2 digit day number, e.g., "04" or "23".

<month>

One of Jan, Feb, Mar, Apr, May, Jun, Jul, Aug, Sep, Oct, Nov, Dec (case sensitive).

<year>

4 digit year number, e.g., "1990" or "2016".

<hour>

2 digit hour number, e.g., "09" or "23".

<minute>

2 digit minute number, e.g., "04" or "59".

<second>

2 digit second number, e.g., "04" or "59".

GMT

Greenwich Mean Time. HTTP dates are always expressed in GMT, never in local time.

ExampleshttpExpires: Wed, 21 Oct 2015 07:28:00 GMT
SpecificationsSpecificationHTTP Caching # field.expiresBrowser compatibilitySee also
HTTP caching guide
Cache-Control
Age\n\nExpiresBaseline Widely availableThis feature is well established and works across many devices and browser versions. It’s been available across browsers since July 2015.Learn moreSee full compatibilityReport feedbackThe HTTP Expires response header contains the date/time after which the response is considered expired in the context of HTTP caching.
The value 0 is used to represent a date in the past, indicating the resource has already expired.

Note:
If there is a Cache-Control header with the max-age or s-maxage directive in the response, the Expires header is ignored.


  
    
      Header type
      Response header
    
    
      Forbidden request header
      No
    
    
      
        CORS-safelisted response header
      
      Yes
    
  
SyntaxhttpExpires: <day-name>, <day> <month> <year> <hour>:<minute>:<second> GMT
Directives
<day-name>

One of Mon, Tue, Wed, Thu, Fri, Sat, or Sun (case-sensitive).

<day>

2 digit day number, e.g., "04" or "23".

<month>

One of Jan, Feb, Mar, Apr, May, Jun, Jul, Aug, Sep, Oct, Nov, Dec (case sensitive).

<year>

4 digit year number, e.g., "1990" or "2016".

<hour>

2 digit hour number, e.g., "09" or "23".

<minute>

2 digit minute number, e.g., "04" or "59".

<second>

2 digit second number, e.g., "04" or "59".

GMT

Greenwich Mean Time. HTTP dates are always expressed in GMT, never in local time.

ExampleshttpExpires: Wed, 21 Oct 2015 07:28:00 GMT
SpecificationsSpecificationHTTP Caching # field.expiresBrowser compatibilitySee also
HTTP caching guide
Cache-Control
Age
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nExpiresBaseline Widely availableThis feature is well established and works across many devices and browser versions. It’s been available across browsers since July 2015.Learn moreSee full compatibilityReport feedbackThe HTTP Expires response header contains the date/time after which the response is considered expired in the context of HTTP caching.
The value 0 is used to represent a date in the past, indicating the resource has already expired.

Note:
If there is a Cache-Control header with the max-age or s-maxage directive in the response, the Expires header is ignored.


  
    
      Header type
      Response header
    
    
      Forbidden request header
      No
    
    
      
        CORS-safelisted response header
      
      Yes
    
  
SyntaxhttpExpires: <day-name>, <day> <month> <year> <hour>:<minute>:<second> GMT
Directives
<day-name>

One of Mon, Tue, Wed, Thu, Fri, Sat, or Sun (case-sensitive).

<day>

2 digit day number, e.g., "04" or "23".

<month>

One of Jan, Feb, Mar, Apr, May, Jun, Jul, Aug, Sep, Oct, Nov, Dec (case sensitive).

<year>

4 digit year number, e.g., "1990" or "2016".

<hour>

2 digit hour number, e.g., "09" or "23".

<minute>

2 digit minute number, e.g., "04" or "59".

<second>

2 digit second number, e.g., "04" or "59".

GMT

Greenwich Mean Time. HTTP dates are always expressed in GMT, never in local time.

ExampleshttpExpires: Wed, 21 Oct 2015 07:28:00 GMT
SpecificationsSpecificationHTTP Caching # field.expiresBrowser compatibilitySee also
HTTP caching guide
Cache-Control
Age
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nForwardedThe HTTP Forwarded request header contains information that may be added by reverse proxy servers (load balancers, CDNs, etc.) that would otherwise be altered or lost when proxy servers are involved in the path of the request.
For example, if a client is connecting to a web server through an HTTP proxy (or load balancer), server logs will only contain the IP address, host address, and protocol of the proxy; this header can be used to identify the IP address, host, and protocol, of the original request.
The header is optional and may be added to, modified, or removed, by any of the proxy servers on the path to the server.
This header is used for debugging, statistics, and generating location-dependent content.
By design, it exposes privacy sensitive information, such as the IP address of the client.
Therefore, the user's privacy must be kept in mind when using this header.
The alternative and de-facto standard versions of this header are the X-Forwarded-For, X-Forwarded-Host and X-Forwarded-Proto headers.

  
    
      Header type
      Request header
    
    
      Forbidden request header
      No
    
  
SyntaxThe syntax for the forwarding header from a single proxy is shown below.
Directives are key=value pairs, separated by a semicolon.
httpForwarded: by=<identifier>;for=<identifier>;host=<host>;proto=<http|https>

If there are multiple proxy servers between the client and server, they may each specify their own forwarding information.
This can be done by adding a new Forwarded header to the end of the header block, or by appending the information to the end of the last Forwarded header in a comma-separated list.Directives
by Optional

The interface where the request came in to the proxy server.
The identifier can be:

an obfuscated identifier (such as "hidden" or "secret").
This should be treated as the default.
an IP address (v4 or v6, optionally with a port, and ipv6 quoted and enclosed in square brackets)
"unknown" when the preceding entity is not known (and you still want to indicate that forwarding of the request was made)


for Optional

The client that initiated the request and subsequent proxies in a chain of proxies.
The identifier has the same possible values as the by directive.

host Optional

The Host request header field as received by the proxy.

proto Optional

Indicates which protocol was used to make the request (typically "http" or "https").

ExamplesUsing the Forwarded headerhttpForwarded: for="_mdn"

# case insensitive
Forwarded: For="[2001:db8:cafe::17]:4711"

# separated by semicolon
Forwarded: for=192.0.2.60;proto=http;by=203.0.113.43

# Values from multiple proxy servers can be appended using a comma
Forwarded: for=192.0.2.43, for=198.51.100.17
Transitioning from X-Forwarded-For to ForwardedIf your application, server, or proxy supports the standardized Forwarded header, the X-Forwarded-For header can be replaced.
Note that an IPv6 address is quoted and enclosed in square brackets in Forwarded (unlike in the X-Forwarded-For header).
httpX-Forwarded-For: 192.0.2.172
Forwarded: for=192.0.2.172

X-Forwarded-For: 192.0.2.43, 2001:db8:cafe::17
Forwarded: for=192.0.2.43, for="[2001:db8:cafe::17]"
SpecificationsSpecificationForwarded HTTP Extension See also
X-Forwarded-For
X-Forwarded-Host
X-Forwarded-Proto
Via – provides information about the proxy itself, not about the client connecting to it.\n\nForwardedThe HTTP Forwarded request header contains information that may be added by reverse proxy servers (load balancers, CDNs, etc.) that would otherwise be altered or lost when proxy servers are involved in the path of the request.
For example, if a client is connecting to a web server through an HTTP proxy (or load balancer), server logs will only contain the IP address, host address, and protocol of the proxy; this header can be used to identify the IP address, host, and protocol, of the original request.
The header is optional and may be added to, modified, or removed, by any of the proxy servers on the path to the server.
This header is used for debugging, statistics, and generating location-dependent content.
By design, it exposes privacy sensitive information, such as the IP address of the client.
Therefore, the user's privacy must be kept in mind when using this header.
The alternative and de-facto standard versions of this header are the X-Forwarded-For, X-Forwarded-Host and X-Forwarded-Proto headers.

  
    
      Header type
      Request header
    
    
      Forbidden request header
      No
    
  
SyntaxThe syntax for the forwarding header from a single proxy is shown below.
Directives are key=value pairs, separated by a semicolon.
httpForwarded: by=<identifier>;for=<identifier>;host=<host>;proto=<http|https>

If there are multiple proxy servers between the client and server, they may each specify their own forwarding information.
This can be done by adding a new Forwarded header to the end of the header block, or by appending the information to the end of the last Forwarded header in a comma-separated list.Directives
by Optional

The interface where the request came in to the proxy server.
The identifier can be:

an obfuscated identifier (such as "hidden" or "secret").
This should be treated as the default.
an IP address (v4 or v6, optionally with a port, and ipv6 quoted and enclosed in square brackets)
"unknown" when the preceding entity is not known (and you still want to indicate that forwarding of the request was made)


for Optional

The client that initiated the request and subsequent proxies in a chain of proxies.
The identifier has the same possible values as the by directive.

host Optional

The Host request header field as received by the proxy.

proto Optional

Indicates which protocol was used to make the request (typically "http" or "https").

ExamplesUsing the Forwarded headerhttpForwarded: for="_mdn"

# case insensitive
Forwarded: For="[2001:db8:cafe::17]:4711"

# separated by semicolon
Forwarded: for=192.0.2.60;proto=http;by=203.0.113.43

# Values from multiple proxy servers can be appended using a comma
Forwarded: for=192.0.2.43, for=198.51.100.17
Transitioning from X-Forwarded-For to ForwardedIf your application, server, or proxy supports the standardized Forwarded header, the X-Forwarded-For header can be replaced.
Note that an IPv6 address is quoted and enclosed in square brackets in Forwarded (unlike in the X-Forwarded-For header).
httpX-Forwarded-For: 192.0.2.172
Forwarded: for=192.0.2.172

X-Forwarded-For: 192.0.2.43, 2001:db8:cafe::17
Forwarded: for=192.0.2.43, for="[2001:db8:cafe::17]"
SpecificationsSpecificationForwarded HTTP Extension See also
X-Forwarded-For
X-Forwarded-Host
X-Forwarded-Proto
Via – provides information about the proxy itself, not about the client connecting to it.
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nForwardedThe HTTP Forwarded request header contains information that may be added by reverse proxy servers (load balancers, CDNs, etc.) that would otherwise be altered or lost when proxy servers are involved in the path of the request.
For example, if a client is connecting to a web server through an HTTP proxy (or load balancer), server logs will only contain the IP address, host address, and protocol of the proxy; this header can be used to identify the IP address, host, and protocol, of the original request.
The header is optional and may be added to, modified, or removed, by any of the proxy servers on the path to the server.
This header is used for debugging, statistics, and generating location-dependent content.
By design, it exposes privacy sensitive information, such as the IP address of the client.
Therefore, the user's privacy must be kept in mind when using this header.
The alternative and de-facto standard versions of this header are the X-Forwarded-For, X-Forwarded-Host and X-Forwarded-Proto headers.

  
    
      Header type
      Request header
    
    
      Forbidden request header
      No
    
  
SyntaxThe syntax for the forwarding header from a single proxy is shown below.
Directives are key=value pairs, separated by a semicolon.
httpForwarded: by=<identifier>;for=<identifier>;host=<host>;proto=<http|https>

If there are multiple proxy servers between the client and server, they may each specify their own forwarding information.
This can be done by adding a new Forwarded header to the end of the header block, or by appending the information to the end of the last Forwarded header in a comma-separated list.Directives
by Optional

The interface where the request came in to the proxy server.
The identifier can be:

an obfuscated identifier (such as "hidden" or "secret").
This should be treated as the default.
an IP address (v4 or v6, optionally with a port, and ipv6 quoted and enclosed in square brackets)
"unknown" when the preceding entity is not known (and you still want to indicate that forwarding of the request was made)


for Optional

The client that initiated the request and subsequent proxies in a chain of proxies.
The identifier has the same possible values as the by directive.

host Optional

The Host request header field as received by the proxy.

proto Optional

Indicates which protocol was used to make the request (typically "http" or "https").

ExamplesUsing the Forwarded headerhttpForwarded: for="_mdn"

# case insensitive
Forwarded: For="[2001:db8:cafe::17]:4711"

# separated by semicolon
Forwarded: for=192.0.2.60;proto=http;by=203.0.113.43

# Values from multiple proxy servers can be appended using a comma
Forwarded: for=192.0.2.43, for=198.51.100.17
Transitioning from X-Forwarded-For to ForwardedIf your application, server, or proxy supports the standardized Forwarded header, the X-Forwarded-For header can be replaced.
Note that an IPv6 address is quoted and enclosed in square brackets in Forwarded (unlike in the X-Forwarded-For header).
httpX-Forwarded-For: 192.0.2.172
Forwarded: for=192.0.2.172

X-Forwarded-For: 192.0.2.43, 2001:db8:cafe::17
Forwarded: for=192.0.2.43, for="[2001:db8:cafe::17]"
SpecificationsSpecificationForwarded HTTP Extension See also
X-Forwarded-For
X-Forwarded-Host
X-Forwarded-Proto
Via – provides information about the proxy itself, not about the client connecting to it.
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nFromBaseline Widely availableThis feature is well established and works across many devices and browser versions. It’s been available across browsers since July 2015.Learn moreSee full compatibilityReport feedbackThe HTTP From request header contains an Internet email address for an administrator who controls an automated user agent.
If you are running a robotic user agent (a web crawler, for example), the From header must be sent in requests so you can be contacted if problems occur, such as a bot sending excessive, unwanted, or invalid requests.

Warning:
You must not use the From header for access control or authentication.


  
    
      Header type
      Request header
    
    
      Forbidden request header
      No
    
  
SyntaxhttpFrom: <email>
Directives
<email>

A machine-usable email address.

ExampleshttpFrom: webmaster@example.org
SpecificationsSpecificationHTTP Semantics # field.fromBrowser compatibilitySee also
Host\n\nFromBaseline Widely availableThis feature is well established and works across many devices and browser versions. It’s been available across browsers since July 2015.Learn moreSee full compatibilityReport feedbackThe HTTP From request header contains an Internet email address for an administrator who controls an automated user agent.
If you are running a robotic user agent (a web crawler, for example), the From header must be sent in requests so you can be contacted if problems occur, such as a bot sending excessive, unwanted, or invalid requests.

Warning:
You must not use the From header for access control or authentication.


  
    
      Header type
      Request header
    
    
      Forbidden request header
      No
    
  
SyntaxhttpFrom: <email>
Directives
<email>

A machine-usable email address.

ExampleshttpFrom: webmaster@example.org
SpecificationsSpecificationHTTP Semantics # field.fromBrowser compatibilitySee also
Host
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nFromBaseline Widely availableThis feature is well established and works across many devices and browser versions. It’s been available across browsers since July 2015.Learn moreSee full compatibilityReport feedbackThe HTTP From request header contains an Internet email address for an administrator who controls an automated user agent.
If you are running a robotic user agent (a web crawler, for example), the From header must be sent in requests so you can be contacted if problems occur, such as a bot sending excessive, unwanted, or invalid requests.

Warning:
You must not use the From header for access control or authentication.


  
    
      Header type
      Request header
    
    
      Forbidden request header
      No
    
  
SyntaxhttpFrom: <email>
Directives
<email>

A machine-usable email address.

ExampleshttpFrom: webmaster@example.org
SpecificationsSpecificationHTTP Semantics # field.fromBrowser compatibilitySee also
Host
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nHostBaseline Widely availableThis feature is well established and works across many devices and browser versions. It’s been available across browsers since July 2015.Learn moreSee full compatibilityReport feedbackThe HTTP Host request header specifies the host and port number of the server to which the request is being sent.
If no port is included, the default port for the service requested is implied (e.g., 443 for an HTTPS URL, and 80 for an HTTP URL).
A Host header field must be sent in all HTTP/1.1 request messages.
A 400 Bad Request status code may be sent to any HTTP/1.1 request message that lacks or contains more than one Host header field.

  
    
      Header type
      Request header
    
    
      Forbidden request header
      Yes
    
  
SyntaxhttpHost: <host>:<port>
Directives
<host>

The domain name of the server (for virtual hosting).

<port> Optional

TCP port number on which the server is listening.

ExampleshttpHost: developer.mozilla.org
SpecificationsSpecificationHTTP Semantics # field.hostBrowser compatibilitySee also
400
<base>\n\nHostBaseline Widely availableThis feature is well established and works across many devices and browser versions. It’s been available across browsers since July 2015.Learn moreSee full compatibilityReport feedbackThe HTTP Host request header specifies the host and port number of the server to which the request is being sent.
If no port is included, the default port for the service requested is implied (e.g., 443 for an HTTPS URL, and 80 for an HTTP URL).
A Host header field must be sent in all HTTP/1.1 request messages.
A 400 Bad Request status code may be sent to any HTTP/1.1 request message that lacks or contains more than one Host header field.

  
    
      Header type
      Request header
    
    
      Forbidden request header
      Yes
    
  
SyntaxhttpHost: <host>:<port>
Directives
<host>

The domain name of the server (for virtual hosting).

<port> Optional

TCP port number on which the server is listening.

ExampleshttpHost: developer.mozilla.org
SpecificationsSpecificationHTTP Semantics # field.hostBrowser compatibilitySee also
400
<base>
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nHostBaseline Widely availableThis feature is well established and works across many devices and browser versions. It’s been available across browsers since July 2015.Learn moreSee full compatibilityReport feedbackThe HTTP Host request header specifies the host and port number of the server to which the request is being sent.
If no port is included, the default port for the service requested is implied (e.g., 443 for an HTTPS URL, and 80 for an HTTP URL).
A Host header field must be sent in all HTTP/1.1 request messages.
A 400 Bad Request status code may be sent to any HTTP/1.1 request message that lacks or contains more than one Host header field.

  
    
      Header type
      Request header
    
    
      Forbidden request header
      Yes
    
  
SyntaxhttpHost: <host>:<port>
Directives
<host>

The domain name of the server (for virtual hosting).

<port> Optional

TCP port number on which the server is listening.

ExampleshttpHost: developer.mozilla.org
SpecificationsSpecificationHTTP Semantics # field.hostBrowser compatibilitySee also
400
<base>
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nIf-MatchBaseline Widely availableThis feature is well established and works across many devices and browser versions. It’s been available across browsers since July 2015.Learn moreSee full compatibilityReport feedbackThe HTTP If-Match request header makes a request conditional.
A server will return resources for GET and HEAD methods, or upload resource for PUT and other non-safe methods, only if the resource matches one of the ETag values in the If-Match request header.
If the conditional does not match, the 412 Precondition Failed response is returned instead.
The comparison with the stored ETag uses the strong comparison algorithm, meaning two files are considered identical byte-by-byte.
If a listed ETag has the W/ prefix indicating a weak entity tag, this comparison algorithm will never match it.
There are two common use cases:

For GET and HEAD methods, used in combination with a Range header, it can guarantee that the new ranges requested
come from the same resource as the previous one.
For other methods, and in particular for PUT, If-Match can be used to prevent the lost update problem.
It can check if the modification of a resource that the user wants to upload will not override another change that has been done since the original resource was fetched.


  
    
      Header type
      Request header
    
    
      Forbidden request header
      No
    
  
SyntaxhttpIf-Match: <etag_value>
If-Match: <etag_value>, <etag_value>, …
Directives
<etag_value>

Entity tags uniquely representing the requested resources.
They are a string of ASCII characters placed between double quotes (like "675af34563dc-tr34").
They may be prefixed by W/ to indicate that they are 'weak', i.e., that they represent the resource semantically but not byte-by-byte.
However, in an If-Match header, weak entity tags will never match.

*

The asterisk is a special value representing any resource.
Note that this must match as false if the origin server does not have a current representation for the target resource.

ExampleshttpIf-Match: "bfc13a64729c4290ef5b2c2730249c88ca92d82d"

If-Match: "67ab43", "54ed21", "7892dd"

If-Match: *
SpecificationsSpecificationHTTP Semantics # field.if-matchBrowser compatibilitySee also
ETag
If-None-Match, If-Modified-Since, If-Unmodified-Since conditional request headers
412 Precondition Failed\n\nIf-MatchBaseline Widely availableThis feature is well established and works across many devices and browser versions. It’s been available across browsers since July 2015.Learn moreSee full compatibilityReport feedbackThe HTTP If-Match request header makes a request conditional.
A server will return resources for GET and HEAD methods, or upload resource for PUT and other non-safe methods, only if the resource matches one of the ETag values in the If-Match request header.
If the conditional does not match, the 412 Precondition Failed response is returned instead.
The comparison with the stored ETag uses the strong comparison algorithm, meaning two files are considered identical byte-by-byte.
If a listed ETag has the W/ prefix indicating a weak entity tag, this comparison algorithm will never match it.
There are two common use cases:

For GET and HEAD methods, used in combination with a Range header, it can guarantee that the new ranges requested
come from the same resource as the previous one.
For other methods, and in particular for PUT, If-Match can be used to prevent the lost update problem.
It can check if the modification of a resource that the user wants to upload will not override another change that has been done since the original resource was fetched.


  
    
      Header type
      Request header
    
    
      Forbidden request header
      No
    
  
SyntaxhttpIf-Match: <etag_value>
If-Match: <etag_value>, <etag_value>, …
Directives
<etag_value>

Entity tags uniquely representing the requested resources.
They are a string of ASCII characters placed between double quotes (like "675af34563dc-tr34").
They may be prefixed by W/ to indicate that they are 'weak', i.e., that they represent the resource semantically but not byte-by-byte.
However, in an If-Match header, weak entity tags will never match.

*

The asterisk is a special value representing any resource.
Note that this must match as false if the origin server does not have a current representation for the target resource.

ExampleshttpIf-Match: "bfc13a64729c4290ef5b2c2730249c88ca92d82d"

If-Match: "67ab43", "54ed21", "7892dd"

If-Match: *
SpecificationsSpecificationHTTP Semantics # field.if-matchBrowser compatibilitySee also
ETag
If-None-Match, If-Modified-Since, If-Unmodified-Since conditional request headers
412 Precondition Failed
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Apr 3, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nIf-MatchBaseline Widely availableThis feature is well established and works across many devices and browser versions. It’s been available across browsers since July 2015.Learn moreSee full compatibilityReport feedbackThe HTTP If-Match request header makes a request conditional.
A server will return resources for GET and HEAD methods, or upload resource for PUT and other non-safe methods, only if the resource matches one of the ETag values in the If-Match request header.
If the conditional does not match, the 412 Precondition Failed response is returned instead.
The comparison with the stored ETag uses the strong comparison algorithm, meaning two files are considered identical byte-by-byte.
If a listed ETag has the W/ prefix indicating a weak entity tag, this comparison algorithm will never match it.
There are two common use cases:

For GET and HEAD methods, used in combination with a Range header, it can guarantee that the new ranges requested
come from the same resource as the previous one.
For other methods, and in particular for PUT, If-Match can be used to prevent the lost update problem.
It can check if the modification of a resource that the user wants to upload will not override another change that has been done since the original resource was fetched.


  
    
      Header type
      Request header
    
    
      Forbidden request header
      No
    
  
SyntaxhttpIf-Match: <etag_value>
If-Match: <etag_value>, <etag_value>, …
Directives
<etag_value>

Entity tags uniquely representing the requested resources.
They are a string of ASCII characters placed between double quotes (like "675af34563dc-tr34").
They may be prefixed by W/ to indicate that they are 'weak', i.e., that they represent the resource semantically but not byte-by-byte.
However, in an If-Match header, weak entity tags will never match.

*

The asterisk is a special value representing any resource.
Note that this must match as false if the origin server does not have a current representation for the target resource.

ExampleshttpIf-Match: "bfc13a64729c4290ef5b2c2730249c88ca92d82d"

If-Match: "67ab43", "54ed21", "7892dd"

If-Match: *
SpecificationsSpecificationHTTP Semantics # field.if-matchBrowser compatibilitySee also
ETag
If-None-Match, If-Modified-Since, If-Unmodified-Since conditional request headers
412 Precondition Failed
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Apr 3, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\nIf-Modified-SinceBaseline Widely availableThis feature is well established and works across many devices and browser versions. It’s been available across browsers since July 2015.Learn moreSee full compatibilityReport feedbackThe HTTP If-Modified-Since request header makes a request conditional.
The server sends back the requested resource, with a 200 status, only if it has been modified after the date in the If-Modified-Since header.
If the resource has not been modified since, the response is a 304 without any body, and the Last-Modified response header of the previous request contains the date of the last modification.
Unlike If-Unmodified-Since, If-Modified-Since can only be used with a GET or HEAD.
When used in combination with If-None-Match, it is ignored, unless the server doesn't support If-None-Match.
The most common use case is to update a cached entity that has no associated ETag.

  
    
      Header type
      Request header
    
    
      Forbidden request header
      No
    
  
SyntaxhttpIf-Modified-Since: <day-name>, <day> <month> <year> <hour>:<minute>:<second> GMT
Directives
<day-name>

One of Mon, Tue, Wed, Thu, Fri, Sat, or Sun (case-sensitive).

<day>

2 digit day number, e.g., "04" or "23".

<month>

One of Jan, Feb, Mar, Apr, May, Jun, Jul, Aug, Sep, Oct, Nov, Dec (case sensitive).

<year>

4 digit year number, e.g., "1990" or "2016".

<hour>

2 digit hour number, e.g., "09" or "23".

<minute>

2 digit minute number, e.g., "04" or "59".

<second>

2 digit second number, e.g., "04" or "59".

GMT

Greenwich Mean Time. HTTP dates are always expressed in GMT, never in local time.

ExampleshttpIf-Modified-Since: Wed, 21 Oct 2015 07:28:00 GMT
SpecificationsSpecificationHTTP Semantics # field.if-modified-sinceBrowser compatibilitySee also
ETag
If-Match, If-None-Match, If-Unmodified-Since conditional request headers
304 Not Modified, 412 Precondition Failed response status codes\n\nIf-Modified-SinceBaseline Widely availableThis feature is well established and works across many devices and browser versions. It’s been available across browsers since July 2015.Learn moreSee full compatibilityReport feedbackThe HTTP If-Modified-Since request header makes a request conditional.
The server sends back the requested resource, with a 200 status, only if it has been modified after the date in the If-Modified-Since header.
If the resource has not been modified since, the response is a 304 without any body, and the Last-Modified response header of the previous request contains the date of the last modification.
Unlike If-Unmodified-Since, If-Modified-Since can only be used with a GET or HEAD.
When used in combination with If-None-Match, it is ignored, unless the server doesn't support If-None-Match.
The most common use case is to update a cached entity that has no associated ETag.

  
    
      Header type
      Request header
    
    
      Forbidden request header
      No
    
  
SyntaxhttpIf-Modified-Since: <day-name>, <day> <month> <year> <hour>:<minute>:<second> GMT
Directives
<day-name>

One of Mon, Tue, Wed, Thu, Fri, Sat, or Sun (case-sensitive).

<day>

2 digit day number, e.g., "04" or "23".

<month>

One of Jan, Feb, Mar, Apr, May, Jun, Jul, Aug, Sep, Oct, Nov, Dec (case sensitive).

<year>

4 digit year number, e.g., "1990" or "2016".

<hour>

2 digit hour number, e.g., "09" or "23".

<minute>

2 digit minute number, e.g., "04" or "59".

<second>

2 digit second number, e.g., "04" or "59".

GMT

Greenwich Mean Time. HTTP dates are always expressed in GMT, never in local time.

ExampleshttpIf-Modified-Since: Wed, 21 Oct 2015 07:28:00 GMT
SpecificationsSpecificationHTTP Semantics # field.if-modified-sinceBrowser compatibilitySee also
ETag
If-Match, If-None-Match, If-Unmodified-Since conditional request headers
304 Not Modified, 412 Precondition Failed response status codes
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\nIf-Modified-SinceBaseline Widely availableThis feature is well established and works across many devices and browser versions. It’s been available across browsers since July 2015.Learn moreSee full compatibilityReport feedbackThe HTTP If-Modified-Since request header makes a request conditional.
The server sends back the requested resource, with a 200 status, only if it has been modified after the date in the If-Modified-Since header.
If the resource has not been modified since, the response is a 304 without any body, and the Last-Modified response header of the previous request contains the date of the last modification.
Unlike If-Unmodified-Since, If-Modified-Since can only be used with a GET or HEAD.
When used in combination with If-None-Match, it is ignored, unless the server doesn't support If-None-Match.
The most common use case is to update a cached entity that has no associated ETag.

  
    
      Header type
      Request header
    
    
      Forbidden request header
      No
    
  
SyntaxhttpIf-Modified-Since: <day-name>, <day> <month> <year> <hour>:<minute>:<second> GMT
Directives
<day-name>

One of Mon, Tue, Wed, Thu, Fri, Sat, or Sun (case-sensitive).

<day>

2 digit day number, e.g., "04" or "23".

<month>

One of Jan, Feb, Mar, Apr, May, Jun, Jul, Aug, Sep, Oct, Nov, Dec (case sensitive).

<year>

4 digit year number, e.g., "1990" or "2016".

<hour>

2 digit hour number, e.g., "09" or "23".

<minute>

2 digit minute number, e.g., "04" or "59".

<second>

2 digit second number, e.g., "04" or "59".

GMT

Greenwich Mean Time. HTTP dates are always expressed in GMT, never in local time.

ExampleshttpIf-Modified-Since: Wed, 21 Oct 2015 07:28:00 GMT
SpecificationsSpecificationHTTP Semantics # field.if-modified-sinceBrowser compatibilitySee also
ETag
If-Match, If-None-Match, If-Unmodified-Since conditional request headers
304 Not Modified, 412 Precondition Failed response status codes
Help improve MDNWas this page helpful to you?YesNoLearn how to contribute.This page was last modified on Mar 13, 2025 by MDN contributors.View this page on GitHub • Report a problem with this content\n\n\n\n